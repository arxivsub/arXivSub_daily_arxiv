# arXiv Daily Summary

![Last Commit](https://img.shields.io/github/last-commit/arxivsub/arXivSub_daily_arxiv?label=Updated)
![Arxiv](https://img.shields.io/badge/arXiv-Papers-B31B1B.svg)
![Python](https://img.shields.io/badge/Powered%20By-Python-3776AB?logo=python&logoColor=white)
![Views](https://komarev.com/ghpvc/?username=arxivsub&repo=arXivSub_daily_arxiv&label=Views&color=brightgreen&style=flat)
![License](https://img.shields.io/badge/license-MIT-green)

> 最后更新时间: 2026-02-10 | 今日论文总数: 1050

> 更多内容请访问 [arXivSub](https://arxivsub.comfyai.app/)

---

## 1. Can LLMs Truly Embody Human Personality? Analyzing AI and Human Behavior Alignment in Dispute Resolution

**arXiv ID:** 2602.07414 | [PDF](https://arxiv.org/pdf/2602.07414v1)

**作者:** Deuksin Kwon `[一作]` (University of Southern California), Gale M. Lucas `[通讯]` (University of Southern California)

**通讯引用:** 6957 | [OpenAlex ID](https://openalex.org/A5084733331)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了一套评估框架，直接对比人类对话与基于人格特质提示的LLM在冲突解决情境下的行为，并通过该框架生成了匹配情境与人格的LLM对话数据集。

**💡 创新点**

创新点在于：①首次将人格特质（Big Five）与冲突解决的策略行为（IRP框架）结合，用统一指标评估人类与LLM的行为一致性；②提出了一种可复制的LLM对话数据生成方法，保证情境与人格对齐；③揭示了现有主流LLM在情境化人格提示下仍无法充分复现人类行为模式。

**🔧 技术方法**

技术方法包括：大规模语言模型（GPT‑4o mini、Claude Sonnet 3.7、Gemini 2.0 Flash）人格提示，IRP策略注释自动化，线性与逻辑回归分析人格对冲突结果和策略的影响，统计显著性检验。

**📊 数据集**

使用数据集：①KODIS（人类-人类冲突解决对话，已标注人格与IRP策略）；②L2L（由LLM生成的与KODIS情境对应的人格化对话）。

**📈 对比分析**

比较方法：对人类和LLM分别计算三类最终结果（Score、Accept、Not‑Walk‑Away）和四类策略指标（IRP Ratio、Reciprocity、Escalation、De‑escalation），用回归模型检验人格特质与指标的关系；结果显示：人类与LLM在人格与行为关联上存在显著差异，部分LLM（如Gemini、Claude）在部分指标上与人类更接近，但整体仍表现出人格驱动行为的偏差，表明当前LLM人格提示的可用性有限。

**⚠️ 局限性**

局限性包括：①IRP注释虽然取得较高F1，但未做大规模人工复核；②提示模板保持统一，未评估不同提示形式对结果的稳健性；③仅使用Big Five人格维度，未涵盖情绪智商、道德倾向等其他心理构念；④实验仅涉及三种LLM，结果可能不具普适性。

---

## 2. Scaffolded Vulnerability: Chatbot-Mediated Reciprocal Self-Disclosure and Need-Supportive Interaction in Couples

**arXiv ID:** 2602.07508 | [PDF](https://arxiv.org/pdf/2602.07508v1)

**作者:** Zhuoqun Jiang `[一作]` (Singapore University of Technology and Design), Simon Tangi Perrault `[通讯]` (Télécom Paris)

**通讯引用:** 1369 | [OpenAlex ID](https://openalex.org/A5067200799)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了一个基于自我决定理论（SDT）的双层支架聊天机器人，用以在情侣对话中促进安全、能力与归属感，并通过后续反馈提示引导伴侣提供需求支持，提升亲密度与幸福感。

**💡 创新点**

首次将SDT的三大基本需求（自主性、能力感、归属感）分层（先提供支持再引导互相支持）用于对话设计，并验证了双层支架对亲密度提升的必要性，填补了现有技术在情感深度与互动循环上的缺口。

**🔧 技术方法**

采用大型语言模型（GPT‑4.1）作为对话驱动器，结合自定义阶段性提示与总结模块，形成 Driver‑Analyzer 两模块协作架构；使用多层次提示与自然语言生成实现即时、情境化的支撑。

**📊 数据集**

实验数据来自 36 对情侣（N=72），随机分为三组：Partner Support（全双层支架）、Direct Support（仅第一层）、Basic Prompt（仅提问）。收集聊天日志、问卷与访谈。

**📈 对比分析**

通过对比三组的对话长度、消息数、字数、需求满足、自我披露深度、伴侣支持以及幸福感指标，发现 Partner Support 组在对话时长、词量、需求支持及亲密度上显著优于其它两组；Direct Support 在提升披露深度方面优于 Basic Prompt。

**⚠️ 局限性**

样本规模有限，且实验仅为单次互动，难以评估长期效果；受限于 GPT 模型的偶尔幻觉与对话一致性，导致某些对话可能偏离预期；自我报告指标可能存在社会期望偏差。

---

## 3. Brep2Shape: Boundary and Shape Representation Alignment via Self-Supervised Transformers

**arXiv ID:** 2602.07429 | [PDF](https://arxiv.org/pdf/2602.07429v1)

**作者:** Yuanxu Sun `[一作]` (Tsinghua University), Mingsheng Long `[通讯]` (Tsinghua University)

**通讯引用:** 29090 | [OpenAlex ID](https://openalex.org/A5019241553)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

开发了一个自监督预训练框架Brep2Shape，能够将CAD模型的抽象边界表示（B-rep）对齐为直观的几何形状表示；

**💡 创新点**

核心创新在于①基于自监督的“形状预测”任务，将B-rep参数映射到空间点云；②提出Dual Transformer并行处理面和线实体并引入拓扑注意力以保持面线间的拓扑一致性；③通过将NURBS拆解为固定大小的Bézier原语，实现了可扩展、统一的token化；

**🔧 技术方法**

使用技术包括Bézier原语分解、面/线独立Token化、Dual Transformer结构、拓扑注意力机制、MSE自监督训练、后续微调时交叉熵训练；

**📊 数据集**

预训练数据为Brep2Shape‑250k（250k个工业及公开CAD模型）；下游评测使用MFCAD++、Fusion360Seg（语义分割）以及FabWave、TMCAD（分类）等四个公开基准；

**📈 对比分析**

与UV‑Net、AAGNet、BRT以及SSL4CAD等基线比较，Brep2Shape在所有下游任务上均显著提升（分类Acc最高、分割IoU提升至80%+），且收敛速度比基线快约3–4倍；

**⚠️ 局限性**

局限性包括：①仍依赖B‑rep拆解为Bézier，复杂高阶曲面或特殊NURBS类型的处理有限；②自监督预训练需要大量无标注B‑rep数据，训练成本高；③对极端高频细节或极其复杂拓扑的泛化尚未充分验证。

---

## 4. Escaping Spectral Bias without Backpropagation: Fast Implicit Neural Representations with Extreme Learning Machines

**arXiv ID:** 2602.07603 | [PDF](https://arxiv.org/pdf/2602.07603v1)

**作者:** Woojin Cho `[一作]` (TelePIX), Junghwan Park `[通讯]` (TelePIX)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `25d64835-ec5b-425b-899d-a6e1e6fecabd` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种无反向传播的隐式神经表示框架ELM‑INR，利用极限学习机（ELM）在重叠子域上一次性求解线性最小二乘，随后通过partition‑of‑unity融合成全局表示；引入BEAM自适应网格细化以平衡局部光谱复杂度；

**💡 创新点**

1) 通过ELM实现一次性闭式求解，消除迭代训练；2) 基于Barron空间的光谱复杂度分析，阐释误差瓶颈；3) 开发BEAM自适应划分算法，使局部子域的光谱能量均衡，从而在容量受限情况下提升精度；

**🔧 技术方法**

极限学习机（随机隐藏层+闭式线性回归）、重叠子域与partition‑of‑unity、随机傅里叶特征编码、Barron空间理论与光谱Barron范数、BEAM自适应网格细化；

**📊 数据集**

常规图像（Kodim20、Kodim100等）、高分辨率多光谱卫星影像（WorldView‑3）、Navier‑Stokes 流场、ERA5 气候数据；

**📈 对比分析**

与主流基于反向传播的INR（SIREN、FFN、GaussNet、WIRE）在相同训练周期对比；ELM‑INR在秒级内即获得接近或超过传统方法的PSNR（如高频区域PSNR提升至30–32 dB），在多光谱和物理场上同样保持高精度；BEAM进一步在容量受限时提升2–3 dB；

**⚠️ 局限性**

依赖于局部子域大小与隐藏单元数，过小的容量仍难以逼近极高频细节；重叠子域与窗口函数的设计可能影响边界平滑；光谱Barron范数的离散估计有限；

---

## 5. RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving

**arXiv ID:** 2602.07339 | [PDF](https://arxiv.org/pdf/2602.07339v1)

**作者:** Ruturaj Reddy `[一作]` (Monash University), Ganesh Krishnasamy `[通讯]` (Monash University)

**通讯引用:** 276 | [OpenAlex ID](https://openalex.org/A5018479820)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `8d10c613-917e-4880-9716-17789f50e119` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `f86bf285-fd08-4156-973b-6e6481af8fa0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 RAPiD 框架，将预训练的扩散轨迹规划器蒸馏成确定性策略，消除迭代采样，从而实现实时轨迹规划。

**💡 创新点**

创新点包括：①使用 Score Regularized Policy Optimization（SRPO）将扩散模型的得分函数直接作为策略梯度正则化；②结合 Predictive Driver Model（PDM）安全评分的 critic，形成安全导向的策略学习；③在不增加采样步骤的前提下实现约 8 倍的推理加速。

**🔧 技术方法**

技术手段：扩散模型（DiffusionPlanner）、SRPO、Implicit Q‑Learning、PDM 评估、Transformer 结构的确定性策略网络、预训练编码器等。

**📊 数据集**

使用 nuPlan 数据集（训练、Val14、Test14、Test14‑Hard）以及 interPlan 基准进行评估。

**📈 对比分析**

与多种基线（PDM‑Open、UrbanDriver、PlanTF、DiffusionPlanner 等）对比：在 nuPlan 非反应任务上，RAPiD 取得 90.19/89.98/76.09 分，超过 DiffusionPlanner；推理时间为 12.41 ms，较 100.91 ms 提升 8 倍；在 interPlan 上总分 27，成为学习型方法中的最高分。

**⚠️ 局限性**

局限性：在反应性场景下的性能略低于原始扩散模型；缺乏多模态采样导致探索范围受限；PDM 评分对安全过度偏好，导致进度得分下降；需要在更长时间闭环或更复杂环境中进一步验证。

---

## 6. Exploring Physical Intelligence Emergence via Omni-Modal Architecture and Physical Data Engine

**arXiv ID:** 2602.07064 | [PDF](https://arxiv.org/pdf/2602.07064v1)

**作者:** Minghao Han `[一作]` (Fudan University), Lihua Zhang `[通讯]` (Fudan University)

**通讯引用:** 32791 | [OpenAlex ID](https://openalex.org/A5100414909)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `14d48e9d-0069-4ad9-996a-1d5968216998` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个紧凑的四模（图像、文本、音频、视频）大模型 OmniFysics，专注于提升物理认知与生成的能力。

**💡 创新点**

创新点包括：① 基于物理律验证的 FysicsAny 与 FysicsOmniCap 两大数据引擎，构建 4.7M 物理属性指令–图像对和 872K 视频–指令对；② 物理评测基准 FysicsEval，覆盖属性预测、因果推理和跨模态一致性；③ 采用自适应语义意图路由（SA‑IAR）在理解与生成之间高效切换；④ 在图像生成中结合流匹配（DiT + VAE）与物理属性重写，实现材质与物理参数的一一对应。

**🔧 技术方法**

技术手段包括：多模态 Rotary Position Embedding（TMRoPE），SigLIP2‑So400m 视觉编码器，Whisper‑large‑v3 音频编码器，Qwen2.5‑3B 语言模型，DiT 流匹配生成头，AdaLN‑modulated Transformer，WavTokenizer + SpokenVoxer TTS，四阶段训练策略（单模态预训练 → 融合训练 → 语音生成 → 图像生成）以及自适应路由模块。

**📊 数据集**

使用的数据集：37M 指令调优语料（包含 163 个公开视觉数据集、13.5% 语音、16.3% 非语音、Omni‑QA、Omni‑Caption），FysicsAny 生成的 4.7M 物理属性图像对，FysicsOmniCap 生成的 872K 视频–指令对，100M 高质量文本–图像对用于流匹配训练，以及多项公开评测基准（FysicsEval、PhysBench、PAI‑Bench、QuantiPhy、PhysUniBench、OmniBench、WorldSense、Daily‑Omni、MMBench V1.1、MMStar、MMMU、MathVista、HallusionBench、AI2D、MMAU、MMAR、GenEval、DPG‑Bench）。

**📈 对比分析**

在物理感知评测中，OmniFysics 超越同等规模（3B）开源模型，并在 4B 级别模型中表现突出；在多模态理解任务上平均得分 49.97，优于 Qwen2.5‑Omni 3B；在图像生成上 GenEval 得分 0.63，接近专家模型 Hunyuan‑DiT；物理属性映射精度高，能根据给定密度、杨氏模量等参数生成对应材质的图像。

**⚠️ 局限性**

局限性：模型仍为 3B 参数规模，无法与更大规模模型在所有抽象任务上竞争；在纯数学或高度抽象的图形推理中表现略逊（如 MathVista）；缺乏长时序生成与实体交互模拟能力，未来需要扩展到更长时间维度和身体动作的学习。

---

## 7. Uncovering Modality Discrepancy and Generalization Illusion for General-Purpose 3D Medical Segmentation

**arXiv ID:** 2602.07643 | [PDF](https://arxiv.org/pdf/2602.07643v1)

**作者:** Yichi Zhang `[一作]` (Fudan University), Zixin Hu `[通讯]` (Fudan University)

**通讯引用:** 2504 | [OpenAlex ID](https://openalex.org/A5101743291)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f` `dc6c6f4a-9d29-4fb8-b59a-f6c271315b9b`

**🎯 论文内容**

本文构建了一个全身PET/CT与PET/MRI配对数据集（490/464例），并对5种主流3D医学分割基础模型进行了零射prompt评估；

**💡 创新点**

创新点在于通过同一受试者的配对扫描实现了模态差异的单一变量对比，揭示了现有模型在功能模态（PET）上的系统性失效，挑战了其所谓的“通用性”；

**🔧 技术方法**

采用了点提示、文本提示和类别ID提示等交互方式，并利用Dice系数、标准误等统计指标对模型性能进行量化；

**📊 数据集**

使用的数据集为自采集的490例PET/CT和464例PET/MRI全身扫描，包含13个器官的体素级标注；

**📈 对比分析**

通过在配对扫描上进行零射评估，比较模型在CT/MRI与PET之间的性能差异，发现大多数模型在PET上Dice平均值低于0.1，语义引导模型几乎完全失效，表明模态泛化能力极差；

**⚠️ 局限性**

局限性包括仅评估了全身器官的正常结构、未涉及病灶或复杂病变、prompt类型有限、评价指标单一（仅Dice）以及未探索更深层的多模态融合方法。

---

## 8. Fine-R1: Make Multi-modal LLMs Excel in Fine-Grained Visual Recognition by Chain-of-Thought Reasoning

**arXiv ID:** 2602.07605 | [PDF](https://arxiv.org/pdf/2602.07605v1)

**作者:** Hulingxiao He `[一作]` (Wangxuan Institute of Computer Technology Peking University), Yuxin Peng `[通讯]` (Wangxuan Institute of Computer Technology Peking University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种针对细粒度视觉识别的多模态大语言模型 FineR1，采用两阶段训练：链式推理监督微调 (CoT SFT) 与三元增强策略优化 (TAPO)。

**💡 创新点**

创新点在于：① 将人类思路拆分为视觉分析、候选子类别、对比与最终预测的四步链式推理，并用 CoT SFT 训练模型；② 在策略梯度优化中引入 anchor、positive、negative 三元样本，分别通过 Intra‑class 与 Inter‑class Augmentation 解决高内变异、低外变异的细粒度分类难题。

**🔧 技术方法**

技术手段包括：链式推理监督微调 (CoT SFT)、三元增强策略优化 (TAPO)、强化学习策略梯度、CLIP 相关度计算、视觉概念抽取、信息瓶颈、token‑level KL 对比、entropy 正则化。

**📊 数据集**

使用六个细粒度视觉识别数据集：Bird‑200、Car‑196、Dog‑120、Flower‑102、Pet‑37、Aircraft；每个数据集随机取 60% 类别为已见、40% 为未见，训练 4‑shot 级别样本。

**📈 对比分析**

与 Qwen2.5‑VL、DeepPerception‑7B、SigLIP‑L 等通用或对比模型对比，FineR1 在闭世界上见类 91.71%/未见类 85.70%，在开放世界上相对语义相似度 74.80%，相对最强基线提升约 23.8%，并在基‑新类别泛化任务中表现出色。

**⚠️ 局限性**

局限性：① CoT 训练样本仍需人工或半自动验证，数据制作成本高；② 对极少见或新出现的子类别性能仍不如专门监督的分类模型；③ 训练流程较复杂，未充分验证在更大规模多模态模型上的可扩展性。

---

## 9. Unsplittable Transshipments

**arXiv ID:** 2602.07230 | [PDF](https://arxiv.org/pdf/2602.07230v1)

**作者:** Srinwanti Debgupta `[一作]` (TU Berlin), Martin Skutella `[通讯]` (TU Berlin)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文提出了多源多汇的不可拆分运输（Unsplittable Transshipment）模型，并给出了在有向图中将任意可拆分运输转化为不可拆分运输的算法。

**💡 创新点**

创新点在于将Dinitz–Garg–Goemans（DGG）算法扩展到多源多汇情形，证明可在每条弧上最多增加 d_max 流量，并在此基础上研究了轮次最少化与最大可路由需求等新颖目标。

**🔧 技术方法**

核心技术包括对可拆分运输进行超源变换、构造“好交替环”与“奇点图”，以及通过拆分汇点需求、路径分解和可冲突性分析实现不可拆分化；同时利用分块与网格离散化控制多轮路由的容量利用。

**📊 数据集**

该工作为理论分析，无实验数据集，全部结论通过证明给出。

**📈 对比分析**

与先前仅针对单源问题的结果比较，本文在多源多汇情形下实现了相同阶的容量增量上界（d_max）和常数阶的轮次/可路由需求近似，显示出与单源算法相当或更优的理论性能。

**⚠️ 局限性**

主要限制在于对 d_max = c_min 情形的上界尚未确定，k‑可拆分推广仅给出上界而无多项式算法，且在某些实例中冲突性可能导致容量利用逼近 d_max，未能提供完整的算法复杂度与可行性阈值。

---

## 10. Your Language Model Secretly Contains Personality Subnetworks

**arXiv ID:** 2602.07164 | [PDF](https://arxiv.org/pdf/2602.07164v1)

**作者:** Ruimeng Ye `[一作]` (University of Tulsa), Bo Hui `[通讯]` (University of Tulsa)

**通讯引用:** 275 | [OpenAlex ID](https://openalex.org/A5050420727)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种无训练的激活引导剪枝框架，从预训练LLM中提取针对不同人格的稀疏子网络，实现可切换的人格控制；

**💡 创新点**

创新点在于揭示LLM内部已嵌入多重人格的子网络，并通过对比剪枝显式最大化对立人格间参数差异；

**🔧 技术方法**

主要技术包括激活统计收集、基于权重与激活相乘的重要性评分、行/列Top‑K剪枝以及对立剪枝策略；

**📊 数据集**

实验使用MBTI人格数据集、AI Persona（追求、财富、幻觉识别）和RoleAgentBench对话基准；

**📈 对比分析**

与prompt、RAG和SFT基线对比，结果表明剪枝子网络在人格对齐度上显著优于前两者、接近或略低于SFT，同时保持推理效率和语义流畅；

**⚠️ 局限性**

局限性包括对部分人格维度（如N/S、J/P）分离效果不佳、对极少量校准数据的鲁棒性仍待验证，以及子网络间可能存在重叠导致人格交叉。

---

## 11. VideoNeuMat: Neural Material Extraction from Generative Video Models

**arXiv ID:** 2602.07272 | [PDF](https://arxiv.org/pdf/2602.07272v1)

**作者:** Bowen Xue `[一作]` (University of Manchester), Milos Hasan `[通讯]` (NVIDIA)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

构建了 VideoNeuMat 两阶段流水线：先把预训练的视频扩散模型微调为“虚拟角度反射仪”，生成控制光照与视角的材料样本视频；再用大规模重建模型（LRM）一次性将这些视频映射到 NeuMIP 神经材料表示，得到可在任意几何、光照下使用的可重用神经材质。

**💡 创新点**

创新点在于：① 利用视频扩散模型的材料先验，避免直接依赖稀缺的高质量材质数据；② 通过“虚拟角度反射仪”构造结构化材料视频，显著降低重建难度；③ 引入大规模重建模型（LRM）实现一次性高效的神经材质推断，显著优于传统迭代优化；④ 结合光照与视角的多帧稀疏输入，提升了材质的泛化与细节再现。

**🔧 技术方法**

核心技术包括：视频扩散模型 Wan‑2.1‑14B 与 Wan‑1.3‑B（用于 LRM），LoRA 与全微调策略；生成的“角度反射仪”视频采用 81 帧两阶段轨迹；NeuMIP 神经材料表示（含偏移与反射纹理、通用 MLP）；LRM 通过 VAE 编码器/解码器 + DiT 预测纹理；评估指标 RPC、FVD、RealMatScore、LPIPS 等。

**📊 数据集**

主要使用数据集是 MatSynth，包含约 5,600 种材质的 1024×1024 渲染视频，并在此基础上生成多视角与光照样本；此外使用 OpenVid‑1M 作为对比基准用于 FVD 计算。

**📈 对比分析**

与三大基线（GNM、RealMat、ReflectanceFusion）比较，VideoNeuMat 在高分辨率、细节与折射效果上均表现更好；FVD 下降至 118.04（MatSynth 138.86），RealMatScore 提升至 0.6289（MatSynth 0.5463），RPC 亦显著提升；单帧推断仅需约 4 秒，远快于传统 1.5 小时的迭代优化。

**⚠️ 局限性**

局限性包括：仅在 MatSynth 上训练，导致对半透明、层叠或纤维材料的重建效果欠佳；NeuMIP 表示难以完全捕捉 3D 细节；生成的平铺材质仍可能出现缝隙；以及 LRM 仍需大规模 GPU 训练与推断，未达到完全无监督或轻量级部署的目标。

---

## 12. Learned Query Optimizer in Alibaba MaxCompute: Challenges, Analysis, and Solutions

**arXiv ID:** 2602.07336 | [PDF](https://arxiv.org/pdf/2602.07336v1)

**作者:** Lianggui Weng `[一作]` (Alibaba Group), Jingren Zhou `[通讯]` (Alibaba Group)

**通讯引用:** 7562 | [OpenAlex ID](https://openalex.org/A5057864403)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `5b4c1114-4a70-478e-9921-2514ee03850d` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出面向阿里云分布式多租户数据仓库的学习式查询优化框架，解决动态环境、缺失统计、无法细化以及项目异质性等挑战。

**💡 创新点**

创新点在于无统计计划编码、环境感知成本模型、预适配的域适应训练以及自动项目选择机制，实现了可直接部署的生产级学习式优化器。

**🔧 技术方法**

技术方法包括树卷积网络（TCN）+梯度逆层实现域适应、环境特征编码、平均环境估计、规则+学习型项目排序、基于历史执行日志的训练等。

**📊 数据集**

使用阿里云内部真实生产工作负载，包含数万个项目的历史查询日志、执行计划及成本，实验以约30个样本项目及5个高潜力项目为基准。

**📈 对比分析**

实验对比本地原生优化器和Transformer/GCN/XGBoost等学习优化器，5个高潜力项目上平均CPU成本提升10%–30%，整体覆盖率约30%，训练耗时≤1h、运行时误差≈10%。

**⚠️ 局限性**

局限性包括环境不可观测导致的性能上限、对训练数据量敏感、对小优化空间或数据分布不足的项目效果有限，且项目选择阈值和规则仍需人工调优。

---

## 13. Dichotomy of Feature Learning and Unlearning: Fast-Slow Analysis on Neural Networks with Stochastic Gradient Descent

**arXiv ID:** 2602.07378 | [PDF](https://arxiv.org/pdf/2602.07378v1)

**作者:** Shota Imai `[一作]` (University of Tokyo), Masaaki Imaizumi `[通讯]` (University of Tokyo)

**通讯引用:** 362 | [OpenAlex ID](https://openalex.org/A5066308746)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a8e75ba4-7a2d-4153-b003-06c94533add0` `de8d30ba-c289-43a5-b4ec-7b80df73aea2`

**🎯 论文内容**

本文通过把两层神经网络在大批量随机梯度下降（SGD）下的学习过程映射到无穷宽极限的连续时间微分方程，对宏观变量进行快速-慢速时间尺度分解，揭示并证明了特征退学（feature unlearning）的发生机制、必要条件和渐近尺度律，并在仿真中验证了理论预测。

**💡 创新点**

创新点在于：①首次将Tensor Programs与奇异扰动理论结合，得到可解析的双变量ODE；②在该ODE框架下构造了临界流形（critical manifold），通过慢流方向阐释了特征退学的出现；③给出了特征退学的充分条件与相应的幂律收敛速率，弥补了以往仅讨论特征学习的空白；④通过数值实验展示了理论在有限宽网络中的可观测性。

**🔧 技术方法**

使用技术包括：Tensor Programs（实现无限宽极限下的梯度计算）、奇异扰动理论（快速-慢速分离与临界流形分析）、Hermite多项式展开（处理激活函数与教师链接函数）、常微分方程（ODE）数值求解与理论证明、以及对比实验中的随机梯度下降实现。

**📊 数据集**

实验所用数据为人工生成的单指数教师模型：输入向量服从标准正态分布，输出为教师函数（激活函数）加噪声；随后在有限宽两层网络中使用相同的随机数据集（n=d=10⁴，宽度m=500或1000）。没有使用公开真实数据集。

**📈 对比分析**

通过将理论ODE的解与有限宽网络在相同初始化和学习率下的SGD训练结果进行对比，验证了临界流形预测的速度与方向；对R（对齐度）和a（第二层权重）随时间的幂律衰减/增长进行log‑log拟合，实验结果与理论给出的Θ(τ^{-1/(2k₁)})、Θ(τ^{1/(2k₁)})等尺度律高度吻合；在有限宽网络中虽然存在随机波动，但整体趋势与理论一致。

**⚠️ 局限性**

局限性包括：①仅在两层、无限宽、对称初始化以及单指数教师模型的设定下成立；②对更深层网络、非对称初始化或不同教师分布的推广尚未给出；③理论忽略了有限宽引起的随机性与高阶耦合效应；④缺乏对实际任务（如图像分类）中验证特征退学对最终性能的定量影响。

---

## 14. GlobalWasteData: A Large-Scale, Integrated Dataset for Robust Waste Classification and Environmental Monitoring

**arXiv ID:** 2602.07463 | [PDF](https://arxiv.org/pdf/2602.07463v1)

**作者:** Misbah Ijaz `[一作]` (University of Gujrat), Muhammad Nabeel Asim `[通讯]` (German Research Center for Artificial Intelligence)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文创建了全球废弃物数据集（GlobalWasteData，GWD），整合19个公开废弃物图像数据集，形成89,807张图像、14大类、68子类的统一标注资源。

**💡 创新点**

创新点在于：①对不同来源数据进行统一清洗、去重、质量过滤和多级层次标注；②构建均衡且多样的类别分布；③提供开放的、可复现的高质量数据集。

**🔧 技术方法**

采用了数据预处理流程（尺寸统一、像素归一化、类别标准化）、文件夹级别标签、分层目录结构及按比例划分训练/验证/测试集等技术。

**📊 数据集**

使用的原始数据集包括TrashNet、TACO、Garbage、RealWaste、ZeroWaste、DWS-1/2、TriCascade、BePLi、AquaTrash、CompostNet等19个公开废弃物图像集。

**📈 对比分析**

通过在该数据集上训练常见卷积网络（如ResNet、EfficientNet）进行基准测试，实验显示在多层级分类任务中可获得较高准确率（≈90%），并在不同环境下保持良好泛化。

**⚠️ 局限性**

局限性：①仍缺乏对极少数危险废弃物和多标签场景的细粒度标注；②标注方式仅为单标签，未覆盖实例分割或语义分割；③数据来源多样但仍可能存在地区偏倚，需进一步扩充全球代表性。

---

## 15. AD-MIR: Bridging the Gap from Perception to Persuasion in Advertising Video Understanding via Structured Reasoning

**arXiv ID:** 2602.07625 | [PDF](https://arxiv.org/pdf/2602.07625v1)

**作者:** Binxiao Xu `[一作]` (Peking University), Wentao Zhang `[通讯]` (Peking University)

**通讯引用:** 14730 | [OpenAlex ID](https://openalex.org/A5100459860)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出了 AD-MIR 框架，旨在通过结构化记忆构建与迭代推理两阶段，将广告视频中的像素级感知与高层次说服意图精准对齐。

**💡 创新点**

创新点在于引入混合语义-词汇检索、结构化推理代理与视觉验证机制，实现从事实到策略的全链条推理，并显著降低幻觉生成。

**🔧 技术方法**

使用了冻结的大型多模态模型（如 GPT‑4o、Qwen2.5‑VL‑7B、o1）配合 ReAct 控制器、工具集（全局浏览、片段检索、帧检验、沟通专家）以及词汇匹配与视觉锚点验证。

**📊 数据集**

评估数据集为 AdsQA，涵盖 38 类广告视频，包含从视觉事实到情感、主题、说服策略及受众建模的多维问题。

**📈 对比分析**

在 AdsQA 基准上，AD‑MIR 在严格准确率上比最强通用模型 DVD 提升 1.8%（o1 版）/4.5%（Qwen2.5‑VL‑7B 版），在松弛准确率上更是提升 7.6%/3.1%，显著领先所有对比方法。

**⚠️ 局限性**

主要局限在于仍高度依赖大型预训练模型、需较多推理步骤且计算成本较高，对非 AdsQA 领域或更复杂的隐喻场景的通用性尚待验证。

---

## 16. Patch-to-PoC: A Systematic Study of Agentic LLM Systems for Linux Kernel N-Day Reproduction

**arXiv ID:** 2602.07287 | [PDF](https://arxiv.org/pdf/2602.07287v1)

**作者:** Juefei Pu `[一作]` (University of California), Zhiyun Qian `[通讯]` (University of California)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了 Patch-to-PoC，一个基于 LLM 的自动化代理系统，系统地在 100 条真实可利用的 Linux kernel N‑day 漏洞上进行漏洞重现实验，并对成功/失败案例进行深入分析。

**💡 创新点**

创新点包括：
1) 首次大规模、系统性评估 LLM 代理在 kernel 漏洞重现上的效果；
2) 设计了完整的工具集（代码浏览、VM 管理、交互、GDB 调试）与 Prompt 指导，实现纯 LLM 驱动的端到端重现；
3) 在相同实验环境下与现有最优灰盒 Fuzzer SyzDirect 进行公平对比，揭示 LLM 在效率和效果上的显著优势。

**🔧 技术方法**

技术实现主要基于 GPT‑5.1 Codex，结合自定义的 MCP 服务器与 QEMU 虚拟机；使用代码浏览工具 CodeQuery、VM 控制工具、GDB MI 进行交互；通过 Prompt 设计引导 LLM 进行静态分析、动态验证、迭代 PoC 生成，并利用工具链完成 PoC 编译、上传和触发。

**📊 数据集**

使用的数据集为 KernelCTF 100 条公开的 Linux kernel 漏洞（覆盖 2023‑2025 年公开的漏洞），以及与 SyzDirect 研究对齐的 85 条子集进行性能对比；数据来源均为官方提交的补丁和公开的 exploit 写作。

**📈 对比分析**

比较方法：在同一虚拟机配置和时间预算下，分别运行 LLM 代理和 SyzDirect；统计成功率、平均重现时间和总体耗时。结果显示：LLM 代理成功率 67%（对齐子集）/ 56%（完整集），平均成功耗时 17 分钟，整体平均耗时 22.5 分钟；SyzDirect 成功率 42%/42%，平均成功耗时 11.7 小时，整体平均耗时 18.8 小时；表明 LLM 方案在效率上优于传统灰盒 Fuzzer。

**⚠️ 局限性**

局限性：
- 对复杂 race 条件和 temporal memory（UAF/DF）漏洞的重现率仍显著低；
- 成功高度依赖补丁信息（尤其是 commit 消息）和工具可用性，缺失时性能明显下降；
- LLM 仍可能因错误根因推理导致失败，需要更完善的假设验证机制；
- 评估仅限于当前 kernel 版本和虚拟机配置，未覆盖更大范围的内核变体与多核并发细节。

---

## 17. Navigating Algorithmic Opacity: Folk Theories and User Agency in Semi-Autonomous Vehicles

**arXiv ID:** 2602.07312 | [PDF](https://arxiv.org/pdf/2602.07312v1)

**作者:** Yehuda Perry `[一作]` (Rutgers University), Tawfiq Ammari `[通讯]` (Rutgers University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过16名美国半自动车辆司机的访谈，探讨司机如何构建‘folk theories’来解释AI行为，并分析其对信任、代理及参与度的影响。

**💡 创新点**

创新点在于首次将‘folk theories’应用于安全关键实时AI系统，揭示司机在算法不透明下的解释性劳动，并提出参与式算法治理框架。

**🔧 技术方法**

采用质性研究方法，包括半结构化访谈、转录、NVivo编码与基于构建主义扎根理论的分析。

**📊 数据集**

数据集为16名主要使用Tesla（少数Polestar、Chevrolet、Mitsubishi）半自动车辆司机的访谈记录。

**📈 对比分析**

该研究不涉及算法性能比较，主要通过主题编码对不同司机的认知框架与策略进行比较，未给出量化性能指标。

**⚠️ 局限性**

局限性包括样本以男性为主、集中于Tesla，存在回忆偏差，且研究仅基于访谈，缺乏实时驾驶行为观测，结果可能随技术演进而变化。

---

## 18. Fair Decisions from Calibrated Scores: Achieving Optimal Classification While Satisfying Sufficiency

**arXiv ID:** 2602.07285 | [PDF](https://arxiv.org/pdf/2602.07285v1)

**作者:** Etam Benger `[一作]` (Hebrew University of Jerusalem), Katrina Ligett `[通讯]` (Hebrew University of Jerusalem)

**通讯引用:** 3214 | [OpenAlex ID](https://openalex.org/A5076701535)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出针对有限组校准概率分数的二分类问题，在满足充分性（预测平衡）约束下给出精确的可行解集，并提供基于几何边界的最优后处理算法；

**💡 创新点**

创新点在于：①将PPV–FOR可行区域构造为星形凸集并给出闭式边界；②利用该边界实现任何在充分性下的目标（如最小化损失或最小化与分离度的偏差）的最优解；③展示即便在充分性与分离度不兼容时，也能通过同一算法得到接近最优且偏差最小的判定规则；

**🔧 技术方法**

主要技术包括：几何分析（线性规划、分数背包求解）、随机阈值化策略、边界追踪算法、对称性与星形凸性证明；

**📊 数据集**

实验数据集为 ProPublica COMPAS 再犯风险评分数据（将分数离散化为10档后校准），并对其组（种族）分布进行估计；

**📈 对比分析**

通过在 COMPAS 数据上与传统单阈值方法比较，最优充分性判定器的准确率为 0.677，接近无约束最优 0.681；且在最小化分离度偏差时得到的分类器与准确率最优者一致，说明方法在公平与性能之间取得良好平衡；

**⚠️ 局限性**

局限性包括：①仅适用于离散且已组校准的概率分数；②需要已知组信息且假设分数分布可用；③在高维或连续分数情形下需先进行离散化或假设连续性，可能导致信息损失或模型失效。

---

## 19. Influence of Geometry, Class Imbalance and Alignment on Reconstruction Accuracy -- A Micro-CT Phantom-Based Evaluation

**arXiv ID:** 2602.07658 | [PDF](https://arxiv.org/pdf/2602.07658v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 20. Privacy in Image Datasets: A Case Study on Pregnancy Ultrasounds

**arXiv ID:** 2602.07149 | [PDF](https://arxiv.org/pdf/2602.07149v1)

**作者:** Rawisara Lohanimit `[一作]` (Massachusetts Institute of Technology), Noa Garcia `[通讯]` (University of Osaka)

**通讯引用:** 751 | [OpenAlex ID](https://openalex.org/A5028370193)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `9cc9baba-5356-466d-81ff-d80028d90279` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `90291a0e-9d36-4a08-9a16-89ce846d923f` `7b0f05dc-d396-4b03-96d2-a379dbd5049d`

**🎯 论文内容**

检测并识别 LAION‑400M 数据集中孕产超声图像中的隐私信息，评估其泄露风险。

**💡 创新点**

首次系统性审计大型公共图像数据集中的孕产超声隐私泄露，结合检索+SVM 分类与 OCR+命名实体识别的端到端流程。

**🔧 技术方法**

使用 CLIP 语义检索、SVM 分类、Tesseract OCR、LLaVA‑Next 校正、Presidio 识别，并配合图像增广与去重。

**📊 数据集**

自制 PIU 超声图像数据集用于训练，LAION‑400M 400M 图文对用于评估。

**📈 对比分析**

与检索基线相比，SVM 在 PIU 测试集上准确率 97.27%，误报 1.41%，误检 4.04%；在 LAION‑400M 中检出 833 张独立超声图像，识别 677 条隐私信息，精确率约 0.57–0.70，召回率 0.35–0.67。

**⚠️ 局限性**

OCR 识别不完整导致名称/地点召回低；数据集缺乏多样性，无法覆盖所有超声样式；隐私评估仅限于四类信息，未覆盖全部可能泄露字段。

---

## 21. Action-to-Action Flow Matching

**arXiv ID:** 2602.07322 | [PDF](https://arxiv.org/pdf/2602.07322v1)

**作者:** Jindou Jia `[一作]` (Nanyang Technological University), Jianfei Yang `[通讯]` (Nanyang Technological University)

**通讯引用:** 6980 | [OpenAlex ID](https://openalex.org/A5005666034)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `40105733-5154-44cd-8090-a8cab9e64b07` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `a8e75ba4-7a2d-4153-b003-06c94533add0` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种基于动作到动作的流匹配（A2A-Flow）机器人控制策略，利用历史关节动作作为起点，无需从随机噪声开始生成动作。

**💡 创新点**

创新点在于把传统的噪声到动作的扩散过程替换为动作分布到未来动作分布的流匹配；在高维潜在空间里对历史动作进行编码并通过轻量级 MLP 学习一条直线交通路径，实现单步推理和显著降低延迟。

**🔧 技术方法**

使用流匹配（flow matching）技术、CNN 及 ResNet-18 编码视觉、动作的自编码器、AdaLN-MLP 结构；并采用 ODE 整合的 inference consistency 损失来保证物理一致性。

**📊 数据集**

在 Roboverse 平台的 5 个仿真任务（ManiSkill 的 Stack Cube、Pick Cube；RLBench 的 Close Box；LIBERO 的 Open Drawer、Pick‑Place Bowl）以及 Franka 机器人上的 Pick Cube、Open Drawer 真实任务上进行实验。

**📈 对比分析**

与 8 个主流基线（DDPM‑UNet、DDPM‑DiT、DDIM‑UNet、FM‑UNet、FM‑DiT、Score‑UNet、ACT、VITA）对比，A2A‑Flow 在成功率上均为最高（多场景 100%），训练收敛快 20×、5×，单步推理时间 <1 ms，且对视觉扰动和初始状态不确定性更鲁棒。

**⚠️ 局限性**

主要限制是需要在训练时加入 inference consistency 损失，导致必须使用固定步长的 ODE 采样，降低了灵活性；此外对历史动作的噪声敏感，若历史信息受扰需要额外噪声注入来提升鲁棒性。

---

## 22. TACIT: Transformation-Aware Capturing of Implicit Thought

**arXiv ID:** 2602.07061 | [PDF](https://arxiv.org/pdf/2602.07061v1)

**作者:** Daniel Nobrega `[一作]` `[通讯]`, Daniel Nobrega

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `40105733-5154-44cd-8090-a8cab9e64b07` `04572f8d-59e5-41c9-8850-ac8e7ee2b108` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种基于流匹配的扩散Transformer（TACIT），通过像素空间的直接变换实现无语言视觉推理，专门用于迷宫求解。

**💡 创新点**

创新点在于：①将流匹配（rectified flow）与扩散Transformer结合，完全去除噪声注入；②在像素空间而非潜在空间操作，保证中间状态可视化；③使用确定性Euler采样，仅10步即可得到完整解，展示清晰的推理过程；④发现了从“无解”到“突然出现完整路径”的相位转移，模拟人类的洞见时刻。

**🔧 技术方法**

核心技术包括：扩散Transformer（DiT）架构、流匹配训练目标、时间步嵌入与adaLN、图像分块嵌入、确定性Euler积分、以及自注意力实现全局感知。

**📊 数据集**

使用了100万个合成迷宫对（1M pairs），包含多种网格尺寸（11、15、21、25、31），每张图64×64 RGB。

**📈 对比分析**

与基线对比，训练损失在100个epoch内下降192倍，L2误差下降22.7倍，IoU达到97.1%，并在10步Euler采样下即可获得95%以上的解质量；同时展示了极低的采样步骤需求与显著的相位转移特征。

**⚠️ 局限性**

局限性包括：仅在迷宫这一受限视觉推理任务上验证，缺乏对更复杂或多样化视觉任务的泛化；模型尺寸约2000万参数、64×64分辨率限制了表达能力；评价指标主要基于像素误差，未完全覆盖解的可行性与连通性；未探究逆向流匹配或更高阶的多模态推理。

---

## 23. Bipartite Graph Attention-based Clustering for Large-scale scRNA-seq Data

**arXiv ID:** 2602.07475 | [PDF](https://arxiv.org/pdf/2602.07475v1)

**作者:** Zhuomin Liang `[一作]` (Shanxi University), Xian Yang `[通讯]` (Alliance Manchester Business School)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `3f18e8e3-0266-457c-8567-9039b6d2394d` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出一种可扩展的双边图Transformer聚类模型BGFormer，针对大规模单细胞RNA测序数据进行聚类

**💡 创新点**

创新点在于引入可学习的锚点令牌并构建细胞-锚点双边图注意力机制，使得相似度计算从细胞-细胞转移到细胞-锚点，计算复杂度从O(n²)降至O(n)

**🔧 技术方法**

采用Transformer自注意力、双边图注意力、多头机制、ZINB重构损失与自监督学习相结合的端到端框架

**📊 数据集**

在多个公开单细胞RNA测序数据集上验证，包括Chen、Bach、MRCA、HRCA、Fetal-Atlas、Ratmap、Astrocyte等，单细胞样本数高达数十万甚至百万级

**📈 对比分析**

与K-means、Leiden、scICE、IDE C、scDCC、scMDC、MetaQ、scGNN、scTAG、CCST、scTPF、scGCL、scG-cluster、scSimGCL等基线比较，BGFormer在ACC/ARI上均为最高或同等水平，并且训练与推理时间显著更短

**⚠️ 局限性**

局限在于锚点数量的选择需要经验调参，锚点过少或过多都会影响聚类质量，且目前仍未对不同细胞类型的混合复杂度进行深入分析

---

## 24. "He gets to be the fun parent": Understanding and Supporting Burnt-Out Mothers in Online Communities

**arXiv ID:** 2602.07781 | [PDF](https://arxiv.org/pdf/2602.07781v1)

**作者:** Nazanin Sabri `[一作]` (University of California), Mai Elsherief `[通讯]`

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在Reddit上识别并分析自我披露产后母亲倦怠的帖子，构建自闭性识别模型，探究母亲在网络社区中求助需求、获得的情感与信息支持，并分析伴侣照护困境。

**💡 创新点**

首次将机器学习与自然语言处理相结合，对母亲自我披露的身份进行自动识别，并系统性挖掘倦怠母亲在社交媒体中的支持互动模式；同时对伴侣照护问题进行主题建模与定性分析。

**🔧 技术方法**

使用BERT、DeBerta等预训练语言模型进行文本分类；GPT‑4o进行零/少样本提示提取；BERTopic、LLooM进行主题建模；自定义情感与信息支持识别模型。

**📊 数据集**

收集自2008‑2023年Reddit的28,346条包含“burnout”关键词的帖子，经过人工标注1,800条母亲身份样本；最终在3,244条自我披露母亲倦怠的帖子上开展分析；同时抓取对应的50,674条评论。

**📈 对比分析**

与传统的正则表达式、基于规则的抽取方法相比，使用DeBerta‑v3‑base模型在母亲身份识别上取得宏观F1=0.91，GPT‑4o零样本识别F1≈0.75；在支持类型识别上，情感支持模型F1≈0.87，信息支持模型F1≈0.90；在共亲关系句子提取上，GPT‑4o问答式提示零样本F1=0.72，优于提取式提示。

**⚠️ 局限性**

模型的泛化能力受限于数据领域，缺乏多样性；对母亲身份的识别仍可能因隐性表达导致误判；仅聚焦于Reddit，缺乏跨平台验证；未深入探讨干预效果。

---

## 25. ODELoRA: Training Low-Rank Adaptation by Solving Ordinary Differential Equations

**arXiv ID:** 2602.07479 | [PDF](https://arxiv.org/pdf/2602.07479v1)

**作者:** Yihang Gao `[一作]` (National University of Singapore), Vincent Y. F. Tan `[通讯]` (National University of Singapore)

**通讯引用:** 4860 | [OpenAlex ID](https://openalex.org/A5058345431)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a8e75ba4-7a2d-4153-b003-06c94533add0` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了一种基于连续时间优化流 ODELoRA 的 LoRA 微调方法，利用平衡流形约束让低秩因子动态保持平衡，严格模拟完整微调的梯度流。

**💡 创新点**

创新点在于将 LoRA 视为满足平衡流形约束的连续动力学，设计 ODE 流并通过 Euler、RK2、RK4 离散化实现高阶稳定的微调，同时给出线性收敛证明与矩阵感知解析。

**🔧 技术方法**

技术包括 Burer–Monteiro 低秩分解、平衡流形约束、连续时间 ODE 梯度流、Euler/RK2/RK4 数值离散、强凸分析、矩阵感知证明与稳定特征学习分析。

**📊 数据集**

使用的数据集主要是合成矩阵感知数据以及物理信息神经网络（PINN）场景中的 Allen‑Cahn 与椭圆偏微分方程数据。

**📈 对比分析**

与传统 LoRA、Riemannian LoRA、LoRA‑Pro 等方法比较，ODELoRA 在矩阵感知实验中保持线性收敛且在大步长下保持稳定；在 PINN 训练中收敛更快、相对误差更低，尤其是 RK4 版本表现最优。

**⚠️ 局限性**

局限性包括：高阶 RK4 的计算成本较高、对平衡约束参数与步长的敏感性、以及目前实验仅在凸/矩阵感知和合成 PDE 场景验证，尚缺乏对真实大型深度模型的实证。

---

## 26. Diabetic Retinopathy Lesion Segmentation through Attention Mechanisms

**arXiv ID:** 2602.07301 | [PDF](https://arxiv.org/pdf/2602.07301v1)

**作者:** Aruna Jithesh `[一作]` (San Jose State University), Taehee Jeong `[通讯]` (San Jose State University)

**通讯引用:** 286 | [OpenAlex ID](https://openalex.org/A5111386973)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

利用注意力机制改进DeepLab‑V3+模型，实现对糖尿病视网膜病变（DR）图像中微血管瘤、软硬性渗出物和出血等四种病变的像素级分割，支持眼科医生早期筛查。

**💡 创新点**

创新点在于：①在ASPP模块后和解码器低层特征后分别嵌入CBAM，实现多尺度语义注意力与空间细节注意力的双路径融合；②采用联合损失（Dice、BCE、Focal、边界损失）对小病变与类别不平衡进行显著提升；③系统性实验验证该注意力结构能将微血管瘤检测率提升272%，整体mAP提升10.5%。

**🔧 技术方法**

技术包括：DeepLab‑V3+架构、CBAM注意力模块、数据增强（几何、颜色、噪声、弹性变形等）、联合损失函数、PyTorch实现、Adam优化和学习率调度。

**📊 数据集**

使用DDR数据集（含9,598名患者的13,673张眼底图）中的757张已像素级标注图像，分为训练（384张）、验证（150张）和测试（226张）集。

**📈 对比分析**

通过与原始DeepLab‑V3+和U‑Net基线模型对比，Attention‑DeepLab在测试集上取得mAP 0.3326（比DeepLab‑V3+提升10.5%）和mIoU 0.1928（提升7.6%）。微血管瘤AP从0.0205提升至0.0763，出血AP从0.1842提升至0.4308；软硬性渗出物虽略有下降，但总体表现优于U‑Net。

**⚠️ 局限性**

主要限制：仅在DDR单一数据集验证，缺乏跨域外部验证；训练样本数量有限，可能无法覆盖所有病变形态与成像差异；对光照、模糊等临床噪声的鲁棒性未充分评估；缺少时间序列分析与实际临床试验对照。

---

## 27. Featured Reproducing Kernel Banach Spaces for Learning and Neural Networks

**arXiv ID:** 2602.07141 | [PDF](https://arxiv.org/pdf/2602.07141v1)

**作者:** Isabel de la Higuera `[一作]` (University of Granada), M. Victoria Velasco `[通讯]` (University of Granada)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

**🎯 论文内容**

提出并系统化了特征映射诱导的再生核Banach空间（Featured Reproducing Kernel Banach Spaces, FRKBS）理论，将传统RKHS框架推广到Banach空间，并构建了相应的最小范数插值与正则化学习形式。

**💡 创新点**

创新点在于发现仅靠点值评估连续性不足以保证Banach空间的特征表示和核化，而必须引入特征映射诱导的结构和可预偶合表示，从而明确区分哪些Banach空间支持核式学习，哪些不支持；并给出了条件表示的特征化与表示定理。

**🔧 技术方法**

使用了泛函分析工具（对偶空间、Hahn–Banach扩展、双对偶映射、双对偶凸包定理）、核方法概念（再生核、特征映射）以及向量值核空间的构造。

**📊 数据集**

没有采用传统机器学习数据集；文中仅给出小规模示例（如三点训练集）来说明理论；神经网络案例使用了ReLU网络的符号函数，作为示范性数据。

**📈 对比分析**

文章并未进行实验比较或性能评估；其主要贡献是理论框架和存在性、表示定理的条件分析，因此没有数值对比结果。

**⚠️ 局限性**

限制在于未讨论优化算法的收敛性、统计泛化误差、计算效率等实际应用问题；理论虽完整，却缺乏实验验证与大规模实现细节。

---

## 28. Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?

**arXiv ID:** 2602.07055 | [PDF](https://arxiv.org/pdf/2602.07055v1)

**作者:** Pingyue Zhang `[一作]` (Northwestern University), Manling Li `[通讯]` (Northwestern University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

研究并提出了一种针对大型基础模型（LLM/VLM）的空间知识构建与维护评估框架（Theory of Space），通过让模型在部分可观测环境中进行自我引导的主动探索，并在每一步显式输出认知地图（Cognitive Map）以评估其空间信念的构建、修订与利用。

**💡 创新点**

创新点在于：①将空间认知定义为三大核心能力（构建、修订、利用）；②设计了基于“主动探索 + 认知地图外显”与“假设信念修订”双维度的评价范式；③引入认知地图与不确定性地图的量化测评，为模型内部空间状态提供可解释的诊断信号；④在文本与视觉双模态环境下对比，揭示了主动探索与被动推理的显著差距。

**🔧 技术方法**

技术方法包括：基于ThreeDWorld和Objaverse构建可编程的多房间环境；使用结构化JSON prompt外显认知地图；信息增益与节点覆盖度作为探索效率指标；对认知地图进行位置、方向、朝向准确率、局部-全局一致性、稳定性、自我定位与不确定性评估；False Belief任务测定信念修订与惯性；对模型输出使用Pearson相关性检验与基准代理对照。

**📊 数据集**

数据集：采用自定义的三维多房间布局（6×6格子、3-4房间）、Objaverse 3D 资产；视觉环境使用 384×384 RGB 图像；文本环境使用离散符号描述；实验共计 100 场景 × 3 题目/任务 = 2700 题；参考代理（Scout 与 Strategist）作为基准路径。

**📈 对比分析**

比较方法：将模型在主动探索和被动（脚本代理）两种情境下的表现与下游空间任务（Route、Survey 相关问答）进行对照；与基准代理、不同规模房间（2房、4房）进行性能评估；使用信息增益曲线、探索步数、任务准确率、认知地图正确率等多维度指标。结果显示：在文本环境下，Gemini‑3 Pro 和 GPT‑5.2 在主动探索和被动推理中均能达到 80‑90% 的任务准确率；视觉环境下模型普遍偏低（约 50‑60%），且主动探索效率低于脚本代理（≈ 9 步），主动-被动差距随房间数量扩大而显著。

**⚠️ 局限性**

限制：①主动探索效率低、步骤冗余，导致信息增益停滞；②视觉模式下感知瓶颈显著，尤其是物体朝向识别；③认知地图存在不稳定性，先前正确的表征会被后续更新冲淡（Belief Drift）；④在环境变化后表现出显著的信念惯性，特别是对方向/朝向的更新失败；⑤模型的内部空间表示比外显 JSON 更丰富，外显压缩导致诊断信息损失；⑥缺乏针对多智能体协同与共享空间知识的评估。

---

## 29. Cerebellar-Inspired Residual Control for Fault Recovery: From Inference-Time Adaptation to Structural Consolidation

**arXiv ID:** 2602.07227 | [PDF](https://arxiv.org/pdf/2602.07227v1)

**作者:** Nethmi Jayasinghe `[一作]` (University of Illinois at Chicago), Amit Ranjan Trivedi `[通讯]` (University of Illinois at Chicago)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在机器人部署后通过一种基于小脑启发的残差控制器实现对未见故障的在线快速修复，且不需要重新训练或系统辨识。

**💡 创新点**

创新点在于将高维特征分离、微区式残差通道、双时尺度可塑性以及基于持续奖励的保守元适应器融合为一种能在推理时安全调节的残差架构，并通过残差能量聚合实现长期结构更新。

**🔧 技术方法**

采用固定随机特征扩展、双指数衰减的可塑性记忆、相位对齐参考、微区激活、快速/慢速权重学习和奖励驱动的元控制。

**📊 数据集**

在 MuJoCo 的多种 locomotion 任务（HalfCheetah、Ant、Humanoid 等）以及一个非周期性 manipulation 任务上进行评估。

**📈 对比分析**

与无适应基线、训练时鲁棒性方法（Robust SAC、SAC+OSI）以及其他在线残差学习（CMAC、Online LMS）对比，实验显示在中等故障下平均提升 53–66% 的回报，在更大故障下仍保持稳定衰减，且与训练时鲁棒方法竞争。

**⚠️ 局限性**

局限包括仅在仿真环境验证、对极端或多样化故障的泛化未知、残差学习与元适应器的超参数调优复杂、以及未证明在真实硬件上的安全性与稳定性。

---

## 30. GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design

**arXiv ID:** 2602.07491 | [PDF](https://arxiv.org/pdf/2602.07491v1)

**作者:** Isabella A. Stewart `[一作]` (Massachusetts Institute of Technology), Markus J. Buehler `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 52690 | [OpenAlex ID](https://openalex.org/A5011504360)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了GraphAgents多代理框架，结合PFAS特定与材料属性知识图谱，通过分解任务、检索证据、图遍历与推理，自动生成可行的PFAS替代材料假设。

**💡 创新点**

创新点在于把知识图谱作为可调用的推理子基底，配合多专业代理和可定制的语义停点，实现跨域的结构化、可追溯的材料设计与生成；同时通过消融验证展示多代理分工与图搜索提升效果。

**🔧 技术方法**

使用了LLM（如Llama 2）、知识图谱构建与检索、工具调用、注入技术，以及图搜索算法（BFS、DFS、最短路径、Top‑N）来驱动代理推理。

**📊 数据集**

使用了4,716篇PFAS相关全文与63,222条文摘构成的PFAS专属知识图谱和材料属性知识图谱作为实验数据集。

**📈 对比分析**

通过与单提示基线进行消融实验对比，显示完整多代理流程在生成满足多目标（力学、热学、化学、表面、生物相容性）的PFAS替代方案方面显著优于单一提示；实验报告指出性能提升明显，虽未给出具体数值。

**⚠️ 局限性**

局限性包括：候选材料多为实验性、工业可行性低；知识图谱静态，缺乏动态更新与实验验证闭环；并且仍受学术语料覆盖范围限制，难以直接转化为商业级方案。

---

## 31. Is there "Secret Sauce'' in Large Language Model Development?

**arXiv ID:** 2602.07238 | [PDF](https://arxiv.org/pdf/2602.07238v1)

**作者:** Matthias Mertens `[一作]` (Massachusetts Institute of Technology), Neil Thompson `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 5121 | [OpenAlex ID](https://openalex.org/A5090002218)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文对 2022‑2025 年期间发布的 809 个 LLM 进行回归分析，拆解其性能差异为规模效应、共享算法进步、公司专有技术（secret sauce）和模型特定因素四个部分。

**💡 创新点**

创新点在于首次系统量化“secret sauce”对 LLM 性能的贡献，发现其在非前沿模型中可实现高达 61 倍的计算效率提升，并把技术进步与规模效应的相对重要性进行定量对比。

**🔧 技术方法**

采用了 logit 变换的缩放法则回归、Shapley 方差分解以及时间、公司和模型固定效应的计量模型，对模型性能与训练计算之间的关系进行建模。

**📊 数据集**

使用的数据来源包括 Hugging Face Open LLM Leaderboard、Epoch AI、TIGER Labs 以及 lifearchitect.ai 等，涵盖了 MMLU‑Pro 和 MATH Level 5 等基准评测结果。

**📈 对比分析**

通过回归得到的系数将不同因素转化为有效计算倍数，比较前沿模型与低端模型的计算效率；结果显示前沿性能 80–90% 主要由规模驱动，而在非前沿场景中技术进步和公司专有技术可显著降低所需计算量，最高可达 61 倍。

**⚠️ 局限性**

局限性包括仅覆盖非推理模型、使用的基准有限、训练计算估计可能存在误差、无法完全捕捉公司内部动态以及对未来计算增长的不确定性未做深入预测。

---

## 32. COMBOOD: A Semiparametric Approach for Detecting Out-of-distribution Data for Image Classification

**arXiv ID:** 2602.07042 | [PDF](https://arxiv.org/pdf/2602.07042v1)

**作者:** Magesh Rajasekaran `[一作]` (Louisiana State University), Kamalika Das `[通讯]` (Intuit Inc.)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种无监督半参数框架 COMBOOD，用于图像分类中的 OOD 检测。

**💡 创新点**

创新点在于将最近邻距离和正则化 Mahalanobis 距离的先验信念相结合，并通过使用不同特征提取（全局极值与倒数层嵌入）实现对 near/FAR OOD 场景的双重覆盖。

**🔧 技术方法**

使用了正则化 Mahalanobis 距离、k 最近邻、Yeo–Johnson 变换、极值提取、特征归一化以及基于 log‑score 的组合方法。

**📊 数据集**

评测数据集包括 OpenOOD 基准（CIFAR‑10/100、SVHN、Tiny、Texture、Places365、ImageNet‑O、iNaturalist 等）、MNIST、LeNet、ResNet18/50 以及文档数据集 RVL‑CDIP。

**📈 对比分析**

与 ODIN、Mahalanobis、Gram、KNN 等现有方法对比，COMBOOD 在大多数基准上获得了更高的 AUROC/AUPR，并且推理时间与 KNN 相当或更快。

**⚠️ 局限性**

限制在于先验组合方式非数据驱动，未来需研究更灵活的数据驱动融合策略。

---

## 33. Revisiting Robustness for LLM Safety Alignment via Selective Geometry Control

**arXiv ID:** 2602.07340 | [PDF](https://arxiv.org/pdf/2602.07340v1)

**作者:** Yonghui Yang `[一作]` (National University of Singapore), Tat-Sent Chua `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一个针对LLM安全对齐的几何感知偏好优化框架（ShaPO），通过在安全关键参数子空间上进行选择性几何控制来提升模型在分布偏移和噪声监督下的鲁棒性。

**💡 创新点**

创新点在于：①从优化几何角度重新审视鲁棒性问题；②引入选择性几何控制，仅在安全相关方向上施加鲁棒约束，避免了全局过度正则化；③实现了 token 级和 reward 级两种实例化，且两者可与传统数据鲁棒方法无缝组合。

**🔧 技术方法**

技术方法包括：偏好优化（DPO、rDPO 等）、对安全关键方向的线性探测器（probe）以及基于 SAM 的选择性几何优化；在 reward 级别利用预训练奖励模型对语义安全进行监督。

**📊 数据集**

使用的数据集主要包括 PKU‑SafeRLHF‑30K 作为训练和在分布评估，外加 HH‑RLHF‑Safety、Do‑Not‑Answer、HarmBench、SaladBench 等四个安全基准用于跨域与噪声鲁棒性测试。

**📈 对比分析**

与 Vanilla、SFT、DPO 以及多种数据鲁棒变体（IPO、cDPO、rDPO、Dr.DPO）对比实验，ShaPO‑T 在所有模型上实现了最高或近乎最高的 Win‑Rate，并显著降低了 MD/NV 判定的攻击成功率；在跨域评估中，ShaPO‑R 在平均 ASR 上比其他方法低至少 2‑5%；在噪声监督实验中，ShaPO‑R 在 40% 标签翻转时仍保持 70% 以上 Win‑Rate。

**⚠️ 局限性**

局限性包括：①几何约束的选择基于粗略的探测器，可能未能完全捕捉所有安全关键方向；②相对于普通 DPO，ShaPO 需要额外的前向后向计算，导致训练成本上升；③在极大规模模型上的可扩展性与效率仍待进一步研究。

---

## 34. TextOp: Real-time Interactive Text-Driven Humanoid Robot Motion Generation and Control

**arXiv ID:** 2602.07439 | [PDF](https://arxiv.org/pdf/2602.07439v1)

**作者:** Weiji Xie `[一作]` (China Telecom), Xuelong Li `[通讯]` (China Telecom)

**通讯引用:** 61716 | [OpenAlex ID](https://openalex.org/A5100740143)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种实时、交互式的文本驱动人形机器人运动生成与控制框架，使得机器人能在单次连续执行中根据用户流式文本指令即时生成并执行多种动作。

**💡 创新点**

创新点在于：①引入机器人骨骼运动表示，提升生成质量与机器人约束一致性；②在训练时将生成器产生的运动加入轨迹跟踪器的训练数据，缩小生成与执行之间的分布差距；③实现文本指令可随时修改、实时响应，突破传统一次性预设或持续遥控的局限。

**🔧 技术方法**

技术包括：自回归运动潜在扩散模型（VAE+LDM）用于文本条件运动生成；Transformer与CLIP编码实现文本嵌入；PPO强化学习训练的MLP轨迹跟踪策略；机器人骨骼增量特征编码；自回归滚动训练与无监督采样。

**📊 数据集**

数据集涵盖：公开AMASS运动捕捉数据+私有舞蹈/武术数据；BABEL文本标签；通过GMR将SMPL骨骼重映射到机器人骨骼；生成的文本流用于训练时的数据增强。

**📈 对比分析**

与多种基准（DART+Retarget、BeyondMimic、HumanML3D、RobotMDM、GMT、Any2Track、TWIST2）对比，在运动质量指标（FID、R@K、MM-Dist）和轨迹跟踪精度（MPJPE、加速度误差）上均表现优异；在真实机器人上实现了0.73 s的交互延迟，成功率最高达95%以上，能流畅完成行走、舞蹈、拳击等多种连续技能。

**⚠️ 局限性**

局限在于缺乏环境感知与交互式物理推理，无法对障碍物、动态物体做出自适应规划；当前仅依赖文本描述，未结合视觉或语义传感器，限制了在复杂真实场景中的鲁棒性。

---

## 35. DLLM Agent: See Farther, Run Faster

**arXiv ID:** 2602.07451 | [PDF](https://arxiv.org/pdf/2602.07451v1)

**作者:** Huiling Zhen `[一作]` (Huawei Technologies Co., Ltd.), Yunhe Wang `[通讯]` (Huawei Technologies Co., Ltd.)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文在同一 DeepDiver 工具使用工作流下，对比了扩散大语言模型 (DLLM) 与自回归 (AR) 模型的代理行为，探讨生成范式对规划、工具调用与效率的影响。

**💡 创新点**

创新点在于在相同工作流和训练数据下，通过 agent-oriented fine‑tuning 与多轮遮罩策略，系统评估并揭示 DLLM 在规划、工具使用和交互效率方面的优势。

**🔧 技术方法**

采用 DeepDiver 框架、Agent‑Oriented Diffusion 训练、context‑clean corruption 与 span‑aware attention masking，并结合 AR 的交叉熵损失进行联合优化。

**📊 数据集**

实验使用 BrowseComp‑zh 及公开多轮工具使用日志，并对开放式问答样本进行定性分析。

**📈 对比分析**

在统一的交互预算与上下文长度约束下，DLLM 在保持与 AR 同等准确率的前提下，平均提高约 30% 的端到端速度，某些情形可达 8 倍加速，但无效动作率略高。

**⚠️ 局限性**

主要局限在于仅在 DeepDiver 具体工作流与固定工具集下验证，缺乏对更大规模模型、更长情景或不同任务的普适性评估，且 DLLM 需要更强的工具调用监督。

---

## 36. Revealing the Semantic Selection Gap in DINOv3 through Training-Free Few-Shot Segmentation

**arXiv ID:** 2602.07550 | [PDF](https://arxiv.org/pdf/2602.07550v1)

**作者:** Hussni Mohd Zakir `[一作]` (Universiti Teknologi PETRONAS), Eric Tatt Wei Ho `[通讯]` (Universiti Teknologi PETRONAS)

**通讯引用:** 864 | [OpenAlex ID](https://openalex.org/A5063934642)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

构建了一个训练-free的多类别少样本语义分割框架FSSDINO，利用冻结的DINOv3特征通过类原型匹配和Gram矩阵细化实现像素级分割。

**💡 创新点**

首次系统揭示DINOv3中存在的“语义选择差距”，发现中间层具有更高的语义信息但现有无监督/支持导向指标无法识别；并通过Oracle-guided层级分析证明last‑layer是安全但非最优的选择。

**🔧 技术方法**

采用类原型构造与k-means聚类、Gram矩阵相似性细化、基于冻结ViT特征的像素级相似度计算以及多种无监督层选择指标（Fisher、逆mIoU、Gram一致性等）等技术。

**📊 数据集**

在COCO‑20i、DeepGlobe、SUIM、ISIC等跨域数据集以及COCO多类别N‑way任务上进行评估。

**📈 对比分析**

与现有的训练free FSS 方法（Matcher、GF‑SAM、DCAMA 等）以及跨域方法（HERA、IFA）对比，FSSDINO在1‑shot 46.99 mIoU、5‑shot 58.54 mIoU（COCO），1‑shot 53.78/49.41/49.41 mIoU（DeepGlobe/SUIM/ISIC），以及多类别 N‑way 1‑shot 47.0‑37.4 mIoU，整体性能接近或优于多数无训练方法。

**⚠️ 局限性**

主要限制在于依赖 last‑layer 作为默认选择，现有无监督指标难以定位最优层，导致“语义选择差距”未被完全弥补；此外大模型规模并不一定带来更好性能，需进一步研究更鲁棒的层选择策略。

---

## 37. Mimetic Initialization of MLPs

**arXiv ID:** 2602.07156 | [PDF](https://arxiv.org/pdf/2602.07156v1)

**作者:** Asher Trockman `[一作]` (Carnegie Mellon University), J. Zico Kolter `[通讯]` (Carnegie Mellon University)

**通讯引用:** 18183 | [OpenAlex ID](https://openalex.org/A5075035644)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本研究首次将模仿初始化方法应用于通道混合层，特别是多层感知器（MLPs），提出了一种简单的初始化技术，即为第一层赋予非零均值，以加速小规模视觉任务的训练。

**💡 创新点**

创新点在于将模仿初始化从空间混合层扩展到通道混合层，并提出了一种简单有效的初始化方法，尽管其效果不如空间混合初始化显著，但可以与之结合使用以获得额外的正面效果。

**🔧 技术方法**

使用了模仿初始化技术，特别是通过对多层感知器的第一层施加非零均值来进行初始化。

**📊 数据集**

使用了CIFAR-10和ImageNet-1k数据集进行实验。

**📈 对比分析**

与传统的随机初始化方法相比，所提出的初始化方法在早期训练阶段显著提高了准确性，但随着训练时间的增加，其优势逐渐减小。与卷积和自注意力层的模仿初始化结合使用时，效果更佳。

**⚠️ 局限性**

限制在于该方法的效果在较长的训练时间后会减弱，且在数据丰富的情况下可能不如在数据有限的情况下显著。

---

## 38. Static Analysis Under Non-Deterministic Program Assumptions

**arXiv ID:** 2602.07324 | [PDF](https://arxiv.org/pdf/2602.07324v1)

**作者:** Abdullah H. Rasheed `[一作]` `[通讯]`, Abdullah H. Rasheed

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

本文提出一种可参数化的静态分析框架，允许程序员在任意程序点插入假设（assume 语句），分析器以非确定性方式接受这些假设，最终生成一个从假设集合到分析结果的函数。

**💡 创新点**

创新点在于：①将传统的抽象解释器上提升到假设空间，得到完整的功能映射；②引入唯一的压缩形式（INF）与可控的近似合并（Approximate Merging）实现可扩展性；③利用该功能式结果直接解决假设合成与一致性检查问题，避免传统的反复重新分析。

**🔧 技术方法**

采用的技术包括：抽象解释与格理论、Knaster‑Tarski 与 Knaster‑Tarski 定理下的固定点求解、假设分裂与条件约束、正交合并与近似合并策略、以及基于假设可达性与Feasible判定的非单调逻辑方法。

**📊 数据集**

在论文中未给出具体实验数据集，讨论主要以理论分析与形式化证明为主。

**📈 对比分析**

由于缺乏实验评估，作者没有与其他方法进行性能对比；理论上证明了正确性与可实现性，但实际运行时间仍受假设数目指数影响，需通过近似合并进行折中。

**⚠️ 局限性**

局限性包括：①最坏情况下仍可能出现指数级状态；②需要手动提供假设集合且假设数目有限；③在抽象域不够表达力时，假设与断言之间的精度匹配仍受限；④近似合并会导致信息丢失，需手动调节；⑤仅适用于能够构造抽象解释器的语言与域。

---

## 39. VertCoHiRF: Decentralized Vertical Clustering Beyond k-means

**arXiv ID:** 2602.07279 | [PDF](https://arxiv.org/pdf/2602.07279v1)

**作者:** Bruno Belucci `[一作]` (University of Paris Dauphine - PSL), Katia Meziani `[通讯]` (University of Paris Dauphine - PSL)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种名为 VertCoHiRF 的完全去中心化垂直联邦聚类框架，利用结构一致性在各方之间达成共识，避免共享特征或单一聚类目标；

**💡 创新点**

核心创新在于：①通过 identifier‑level 通讯实现隐私保护，无需噪声注入；②采用严格的投票式一致性机制（veto）保证鲁棒性；③支持各方使用本地专属聚类方法，突破 k‑means 限制；④通过离散排序选取代表元，逐层构建可解释的 Cluster Fusion Hierarchy；

**🔧 技术方法**

使用 CoHiRF 思路的分层聚类、标识符级别通讯、排序聚合、代表元选择、去中心化一致性协议，并对通信复杂度与鲁棒性进行理论分析；

**📊 数据集**

在合成多模态数据集、alizadeh‑2000‑v2、chowdary‑2006、coil‑20、garber‑2001、nursery、shuttle 等真实数据集上进行实验；

**📈 对比分析**

与中心化 k‑means、DP‑VFL 方法（如差分隐私投影）、基于 k‑means 的 VFL 方法（Froge、SC‑SRGF）以及非中心化对齐方法对比；实验表明在多视角场景下，VertCoHiRF 在 ARI 等指标上与最优基线持平或更优，且对 Byzantine 攻击和特征分片不敏感；

**⚠️ 局限性**

局限性在于：若视图信息不互补或单一视图占主导，协同提升有限；协议在代理数增多时通信复杂度为 O(A²)，需要进一步优化；此外，当前仅关注结构一致性，尚未探索如何在全局目标约束下进一步提升聚类精度。

---

## 40. MUFASA: A Multi-Layer Framework for Slot Attention

**arXiv ID:** 2602.07544 | [PDF](https://arxiv.org/pdf/2602.07544v1)

**作者:** Sebastian Bock `[一作]`, Stefan Roth `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `8d10c613-917e-4880-9716-17789f50e119` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种多层槽注意力框架，利用ViT各层特征融合实现无监督目标分割；

**💡 创新点**

创新点在于：①利用DINO ViT多层语义信息进行槽注意力；②设计M-Fusion融合策略将多层槽信息合并；③实现轻量级、可直接插入现有模型的 plug‑and‑play 方案；④显著提升分割质量并缩短训练时间；

**🔧 技术方法**

使用slot attention、Hungarian 匹配、MLP 融合、自回归 Transformer 解码器、DINO 预训练 ViT，以及跨模型知识蒸馏；

**📊 数据集**

在 PASCAL VOC、COCO 和合成数据集 MOVi‑C 上进行评估；

**📈 对比分析**

与 DINOSAUR、SPOT 等基线模型对比，MUFASA 在三大数据集的 mIoU、mBO 等指标均超过基线，几乎达到或超越当前 SOTA，并将训练时间减少约 90%；

**⚠️ 局限性**

与传统 slot‑attention 方法类似，MUFASA 容易将同一类别的多实例归为同一槽，难以实现真正的实例级分割；

---

## 41. Online Contract Design

**arXiv ID:** 2602.07385 | [PDF](https://arxiv.org/pdf/2602.07385v1)

**作者:** Elad Lavi `[一作]` (Technion), Inbal Talgam-Cohen `[通讯]` (Tel Aviv University)

**通讯引用:** 646 | [OpenAlex ID](https://openalex.org/A5081600081)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出一种在线多代理合同（OMAC）模型，研究在不确定的顺序到达中如何挑选团队并为其设计激励兼容的线性合同，目标是最大化主方收益。

**💡 创新点**

创新点包括：①首次将合同理论与预处理在线算法结合；②引入“平衡点”（balance points）概念，用来同步分配份额与主方效用；③证明对加性奖励可实现 1/2 竞争比的随机算法，且该比率最优；④展示在 XOS 奖励结构下任意随机算法都无法获得常数级竞争比。

**🔧 技术方法**

技术手段主要有：随机化算法（等概率选择 BP 与 MAX 两种策略）；BP 使用平衡点限制各质量层的份额；MAX 选取最优单一代理；理论分析通过竞争比、平衡点性质与递归不等式完成。

**📊 数据集**

本文为理论性工作，没有使用实验数据集，全部结果基于数学证明与构造性对抗实例。

**📈 对比分析**

方法评价：在加性奖励下，随机算法实现 1/2 竞争比，等价于当前最佳；确定性算法无法达到常数竞争比；在 XOS 奖励下，竞争比可趋近零，表明问题本质上不可解。

**⚠️ 局限性**

局限性：仅在加性奖励下有可行解；对子模、XOS 等更一般奖励结构不适用；需要预处理（可撤销）才能获得有意义的竞争比；未考虑多层次努力、非线性合同等更复杂情形。

---

## 42. Continuous Program Search

**arXiv ID:** 2602.07659 | [PDF](https://arxiv.org/pdf/2602.07659v1)

**作者:** Matthew Siper `[一作]` (Nof1), Julian Togelius `[通讯]` (Nof1)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文在交易策略的符号程序搜索中，研究并利用程序潜在空间的行为几何性，设计与语义对齐的连续变异算子；

**💡 创新点**

创新点在于把潜在空间的行为几何性量化为可操作的信任区域，并在此基础上构造语义配对的双块流模型变异器；

**🔧 技术方法**

主要技术包括Transformer VAE编码器/解码器、块因子化潜在空间、基于日志的流式变异模型、(μ+λ)进化策略；

**📊 数据集**

使用五种流动期货合约（ES、NG、CL、SI、E6）历史数据，采用五折前向滚动评估；

**📈 对比分析**

与全潜在空间的高斯变异和双块高斯变异在相同预算、相同算法下比较，学习流变异器在仅占13.7%预算时即可达到最高中位Sharpe，速度与稳定性显著优于基线；

**⚠️ 局限性**

局限性在于需要明显可分语义的DSL结构、仅适用于可在小范围内保持行为局部的潜在空间，且对超大搜索半径和无明显语义划分的领域适用性有限。

---

## 43. Lite-BD: A Lightweight Black-box Backdoor Defense via Reviving Multi-Stage Image Transformations

**arXiv ID:** 2602.07197 | [PDF](https://arxiv.org/pdf/2602.07197v1)

**作者:** Abdullah Arafat Miah `[一作]` (University of Rhode Island), Yu Bi `[通讯]` (University of Rhode Island)

**通讯引用:** 380 | [OpenAlex ID](https://openalex.org/A5074397437)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种轻量化黑盒后门防御框架，先通过随机下采样再用预训练超分辨率网络上采样消除空间触发器，再对残留的高频触发器进行带阻频域滤波，最终恢复图像。

**💡 创新点**

首次将下采样‑上采样与预训练超分辨率结合成两阶段防御，并引入查询式带阻频域滤波，既保持无数据集依赖和零样本特性，又在黑盒环境下实现高效触发器消除。

**🔧 技术方法**

采用随机缩放、Real‑ESRGAN / SwinIR 超分辨率、离散傅里叶变换、带阻频率滤波、双边/锐化后处理等技术。

**📊 数据集**

在 CIFAR‑10、Fashion‑MNIST、GTSRB、Tiny‑ImageNet 等标准图像数据集上验证，模型覆盖 ResNet‑18、VGG‑11、MobileNetV1、DenseNet‑121、ViT‑Base 等。

**📈 对比分析**

与 ShrinkPad、ZIP、SampDetox 等现有黑盒防御在 10 种攻击（BadNets、Blend、WaNet、SIG、CL、BPPAttack、Trojan、LF、Poison‑Ink、LIRA）上对比，平均 ASR 大幅下降，CA/PA 维持或提升，执行时间平均比对手快 100‑200 倍，且在不同模型上表现稳健。

**⚠️ 局限性**

对极小或全局高频触发器仍需要第二阶段处理；对极高频或非图像序列任务的鲁棒性未评估；未针对自适应对抗攻击进行充分测试。

---

## 44. BitLogic: Training Framework for Gradient-Based FPGA-Native Neural Networks

**arXiv ID:** 2602.07400 | [PDF](https://arxiv.org/pdf/2602.07400v1)

**作者:** Simon Bührer `[一作]` (ETH Zurich), Roger Wattenhofer `[通讯]` (ETH Zurich)

**通讯引用:** 21220 | [OpenAlex ID](https://openalex.org/A5078339613)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了BitLogic框架，实现了FPGA原生的基于查找表（LUT）的深度神经网络，可通过梯度训练直接学习可映射到硬件的二进制逻辑；

**💡 创新点**

创新点在于将多种LUT节点、可学习的连接映射、概率化与分层结构统一到一个可配置API中，并通过自动RTL导出实现软件与硬件的一致性；

**🔧 技术方法**

技术包括可微分的LUT节点（如概率化、Warp等）、热编码器、GroupSum等头部、可学习的连接拓扑、梯度稳定化、温度调节以及自动化PyTorch→HDL导出管道；

**📊 数据集**

使用了MNIST、Fashion‑MNIST、CIFAR‑10和CIFAR‑100四个标准图像分类数据集；

**📈 对比分析**

在硬件对比中，BitLogic在FPGA上实现单样本推理低于20 ns、能耗3.34 nJ，CIFAR‑10测试准确率72.3%仅使用不到0.3 M逻辑门；与现有逻辑基网络相比，门计数与准确率均处于同级或更优；

**⚠️ 局限性**

局限性包括：深层网络训练不稳定、仅针对图像分类的评估、导出仅支持完全组合逻辑，对流水线、状态机和串行接口的支持尚不完善，且缺乏直接的硬件约束优化（如时序、功耗）在训练阶段。

---

## 45. Nonparametric Bayesian Optimization for General Rewards

**arXiv ID:** 2602.07411 | [PDF](https://arxiv.org/pdf/2602.07411v1)

**作者:** Zishi Zhang `[一作]` (Peking University), Yijie Peng `[通讯]` (Peking University)

**通讯引用:** 17128 | [OpenAlex ID](https://openalex.org/A5082863871)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `39fd911c-56a4-425d-a2f9-8038ad3b6e21` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

本文提出了一种新的贝叶斯优化框架，即无限高斯过程（∞-GP），通过对奖励分布空间设定先验实现模型不确定性捕捉，从而在一般奖励设置下实现无后悔收敛。

**💡 创新点**

创新点在于将传统GP的单一分布假设提升为无限混合GP的贝叶斯非参数模型，利用空间Dirichlet过程混合来建模奖励分布，结合Thompson Sampling给出新的TV距离基准的无后悔证明，并通过截断吉布斯采样实现可扩展性。

**🔧 技术方法**

使用的技术包括：空间Dirichlet过程混合、无限高斯过程、Thompson Sampling、总变差距离理论、截断吉布斯采样、并行化Kriging计算。

**📊 数据集**

实验数据集包括：Ackley、Rosenbrock、StybTang等合成函数（加重尾/非平稳变种）、金融组合优化（CVXPortfolio）、MLP超参数调优（HPOBench）以及NASBench201神经架构搜索。

**📈 对比分析**

与传统GP基准（GP-TS、GP-UCB、GP-EI、GP-KG）以及对非平稳/重尾设置的Warped GP和截断GP-UCB进行对比，∞-GP-TS在所有任务上表现出子线性累积损失、比传统方法更低的累计回报以及相近甚至更低的计算时间。

**⚠️ 局限性**

局限性：算法主要针对样本数量n的可扩展性，未充分解决高维决策空间d的规模问题；截断层数需根据经验选择，过度截断可能影响收敛。

---

## 46. Surprisal-Guided Selection: Compute-Optimal Test-Time Strategies for Execution-Grounded Code Generation

**arXiv ID:** 2602.07670 | [PDF](https://arxiv.org/pdf/2602.07670v1)

**作者:** Jarrod Barnes `[一作]` `[通讯]` (Arc Intelligence), Jarrod Barnes (Arc Intelligence)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

在GPU核代码优化任务上研究了在推理时计算资源分配的最优策略，比较了搜索与少量梯度自适应两种方法并提出了基于“惊讶度”的样本选择方案。

**💡 创新点**

创新点在于：①发现搜索（Best‑of‑N）在密集奖励的执行验证任务中优于少量梯度自适应；②提出惊讶度（最低对数概率）选择最优样本，可在不额外计算成本的前提下恢复oracle性能；③揭示梯度自适应导致的“过度锐化”现象，解释了其在此类任务中失效的机制。

**🔧 技术方法**

使用的技术包括：大型语言模型（120B GPT‑OSS‑120B）配合LoRA微调、基于强化学习的自适应（GRPO）与批量测试时间训练、Best‑of‑N采样、基于log‑prob的惊讶度排名、以及执行验证器（KernelBench）提供的连续奖励。

**📊 数据集**

数据集为KernelBench的L1级别评估集，共20个任务（以及两套5任务子集），涵盖250个PyTorch ML工作负载。

**📈 对比分析**

比较方法为在相同计算预算（320个rollout、相同温度等）下，衡量fast_1（既正确又加速>1×）指标。结果显示：Best‑of‑N K=64实现90%任务成功（18/20），而最优梯度自适应（1–5步）仅达30.6%，等价K<1；惊讶度选择在K=64时可达80%成功率，惊讶度‑top3匹配oracle 100%。

**⚠️ 局限性**

局限性包括：仅验证120B规模模型，未探究不同规模或架构；仅在L1级别任务，L2/L3可能表现不同；惊讶度方法依赖足够的log‑prob方差，低方差任务失效；实验使用快速代理评估，完整KernelBench评估可能略有差异；梯度自适应使用的是基本GRPO，未检验加入熵正则或更复杂策略的影响。

---

## 47. Perspective-aware fusion of incomplete depth maps and surface normals for accurate 3D reconstruction

**arXiv ID:** 2602.07444 | [PDF](https://arxiv.org/pdf/2602.07444v1)

**作者:** Ondrej Hlinka `[一作]` (Austrian Institute of Technology), Christian Kapeller `[通讯]` (Austrian Institute of Technology)

**通讯引用:** 21 | [OpenAlex ID](https://openalex.org/A5086562295)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6514db3d-8de6-452c-91b7-acdb31787cc4` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文提出一种面向透视投影的深度图与表面法向量融合方法，利用对数深度变换实现对视角误差的校正，并能对缺失深度区域进行天然填补，从而实现精确的3D重建。

**💡 创新点**

创新点在于将对数深度替换与梯度约束融合相结合，将透视投影的融合问题化简为正交投影问题，使得任何正交梯度融合算法都能直接迁移，并且天然支持缺失深度的透视-aware 填补。

**🔧 技术方法**

所用技术包括对数深度变换、梯度一致性约束、TGV（Total Generalized Variation）正则化、光度立体法获取法向量、结构光获取深度图，并实现了对应的凸优化求解。

**📊 数据集**

实验基于公开的 DiLiGenT‑MV 数据集，该数据集提供多视角的3D网格、深度与法向信息，用以评估融合算法的精度。

**📈 对比分析**

与传统正交融合、Naive 透视重投影、Nehab、BiNI、PG以及 PTGV 等方法对比，本文的 PTGV 方案在 RMSE 与 MAE 上表现最佳，表明透视-aware 的对数深度融合能显著提升重建质量。

**⚠️ 局限性**

局限性包括：仅针对单目透视相机，假设深度正值且法向信息完整；对多视角或动态场景的适用性尚未验证；以及对大范围遮挡仍可能产生误差。

---

## 48. MSN: A Memory-based Sparse Activation Scaling Framework for Large-scale Industrial Recommendation

**arXiv ID:** 2602.07526 | [PDF](https://arxiv.org/pdf/2602.07526v1)

**作者:** Shikang Wu `[一作]` (ByteDance), Jingjian Lin `[通讯]` (ByteDance)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `afceb026-1760-41ae-8d86-010831a37d97` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种基于记忆网络的稀疏激活缩放框架（MSN），通过从大规模键值记忆中检索个性化表示来提升推荐模型的表达能力，同时保持低计算和存储开销。

**💡 创新点**

核心创新点包括：
• Product-Key Memory（PKM）实现检索复杂度从线性降至子线性；
• 记忆门控机制（Memory‑Gated Fusion）将检索到的记忆作为稀疏门控，细粒度调制输入特征；
• 通过层归一化、学习率预热和过参数化（over‑parameterization）保证检索稳定与均衡更新；
• 定制化 Sparse‑Gather 与 AirTopK 操作，显著提升训练与推理效率。

**🔧 技术方法**

技术手段包括：
• 记忆网络（键值检索）与 PKM 分解；
• 记忆门控融合；
• 归一化、学习率预热、过参数化；
• Sparse‑Gather 与 AirTopK 优化算子；
• 在基准模型上嵌入 MS‑FFN / MS‑SMoE 模块。

**📊 数据集**

使用抖音搜索系统的真实日志数据，包含 1,000+ 维特征、数十亿用户-视频交互记录，经过三周连续采集，用于离线 QAUC 评估及线上 A/B 测试。

**📈 对比分析**

与 DLRM‑MLP、Wukong、SMoE 等基线在 RankMixer 基础上对比；在 QAUC 上提升约 0.5%（相对 120M 激活参数），在多种指标下实现 0.05%–0.30% 的线上流量提升，证明了 MS‑N 在工业规模系统中的实际效果。

**⚠️ 局限性**

局限性：
• 在所有层都加入 MSN 时性能下降，说明过度稀疏化会抑制特征交互；
• 多层 MSN 或者多重稀疏模块叠加容易导致优化困难、收敛慢；
• 检索 Top‑k 数量对效果敏感，k 过小会导致记忆利用不足；
• 仍需进一步探索与其他稀疏策略（如动态深度、稀疏交互）融合，以进一步提升效率与性能。

---

## 49. Risk-Sensitive Exponential Actor Critic

**arXiv ID:** 2602.07202 | [PDF](https://arxiv.org/pdf/2602.07202v1)

**作者:** Alonso Granados `[一作]` (University of Arizona), Jason Pacheco `[通讯]` (University of Arizona)

**通讯引用:** 165 | [OpenAlex ID](https://openalex.org/A5021193065)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出并实现了一种风险敏感的指数Actor‑Critic算法 rsEAC，用于在未知环境中通过熵风险度量学习鲁棒高回报策略。

**💡 创新点**

创新点包括：① 推导了适用于在线/离线情形的熵风险策略梯度定理；② 设计了在对数域下参数化的指数值函数以及批量归一化与梯度裁剪的稳定机制，避免了指数Bellman方程导致的数值爆炸/消失；③ 将上述理论与 TD3 结合，得到高效的离线风险敏感训练框架。

**🔧 技术方法**

使用的技术有：策略梯度、指数Bellman方程、对数域参数化、批量归一化、梯度裁剪、经验回放、TD3 结构、连续动作空间的确定性策略、风险参数 β 的调节。

**📊 数据集**

实验数据集包括：GridWorld、倒立摆(Inverted Pendulum)、以及 MuJoCo 连续控制任务 Swimmer、HalfCheetah、Ant 的风险变体。

**📈 对比分析**

通过与 R‑AC、Mean Gini Deviation (MG)、Mean‑Variance Policy Iteration (MVPI) 等基线进行对比，rsEAC 在保持较高平均回报的同时显著降低了在风险区的访问率，性能优于 R‑AC 并与 MVPI 相当或更好。

**⚠️ 局限性**

局限性：① 仍存在指数函数固有的数值不稳定性，某些极端 β 值下可能不收敛；② 需要手动调节风险参数 β 以适配不同任务。

---

## 50. Object-Oriented Transition Modeling with Inductive Logic Programming

**arXiv ID:** 2602.07602 | [PDF](https://arxiv.org/pdf/2602.07602v1)

**作者:** Gabriel Stella `[一作]` (Texas A&M University), Dmitri Loguinov `[通讯]` (Texas A&M University)

**通讯引用:** 2967 | [OpenAlex ID](https://openalex.org/A5076734500)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出了一种新的基于对象导向表示的增量逻辑程序诱导算法TreeLearn，并基于此实现了可在线学习、解释性强、泛化能力好的转移模型TreeThink。

**💡 创新点**

创新点在于将FOLDT（First-Order Logical Decision Trees）与自适应置信区间驱动的分裂/更新策略相结合，支持嵌套量化、变量绑定和对离散/连续属性的统计分布预测，从而克服传统ILP方法在多量化和变量绑定上的局限。

**🔧 技术方法**

核心技术包括：1) FOLDT决策树表示；2) 统计驱动的置信区间测试与分裂决策；3) 递归式增量更新与变量绑定管理；4) 推理层的按需查询与短路评估优化。

**📊 数据集**

在九个人工设计的基准环境（如fish、maze、coins、keys、switches、scale等）以及其规模化变体和无奖励版本上进行实验，并对比了QORA、手工构造的NPE网络和静态基线。

**📈 对比分析**

与QORA相比，TreeThink在所有奖励环境中均能快速收敛至零误差；相较于NPE基线，TreeThink在样本复杂度、训练速度和泛化（向更大网格迁移）上均表现显著优越，误差降到接近零。

**⚠️ 局限性**

局限性包括：1) 仍需手动定义测试的属性类型；2) 对超参数α的选择相对稳健但在极端环境下仍可能需要调优；3) 目前实现主要针对离散或有限维连续属性，处理更高维或更复杂关系时可能需要进一步扩展。

---

## 51. Network function computation with vector linear target function and security function

**arXiv ID:** 2602.07316 | [PDF](https://arxiv.org/pdf/2602.07316v1)

**作者:** Min Xu `[一作]` (Xidian University), Gennian Ge `[通讯]` (Capital Normal University)

**通讯引用:** 3811 | [OpenAlex ID](https://openalex.org/A5029449317)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

研究了在向量线性目标函数与安全函数下的安全网络功能计算问题，并给出两条更通用的上界；

**💡 创新点**

创新点在于提出了两条新的容量上界并通过线性网络编码构造实现了在特定拓扑（(U,V,α)-树）下达到上界的方案；

**🔧 技术方法**

使用了信息理论分析、线性网络编码、MDS 与 Vandermonde 矩阵构造、随机密钥技术；

**📊 数据集**

无具体实验数据集，全部为理论模型与符号论证；

**📈 对比分析**

与已有上界及不加安全约束的计算容量对比，部分实例中已达到上界或逼近；

**⚠️ 局限性**

主要限制在于上界不总是紧、所需域大小未知、构造方案仅适用于受限拓扑且与上界存在误差。

---

## 52. BONSAI: Bayesian Optimization with Natural Simplicity and Interpretability

**arXiv ID:** 2602.07144 | [PDF](https://arxiv.org/pdf/2602.07144v1)

**作者:** Samuel Daulton `[一作]` (Meta), Eytan Bakshy `[通讯]` (Meta)

**通讯引用:** 9868 | [OpenAlex ID](https://openalex.org/A5006700143)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了 BONSAI，一种默认感知的 Bayesian Optimization 策略，通过后处理剪枝保持获取值接近最优的同时最小化与默认配置的偏差。

**💡 创新点**

① 通过相对获取间隙阈值限制偏差；② 证明对 GP‑UCB 的累积 regret 仅增加可控的 penalty；③ 采用轻量级贪心剪枝实现；④ 在多种指标和真实任务上验证稀疏性与性能兼顾。

**🔧 技术方法**

Bayesian Optimization、Gaussian Process surrogate、Upper Confidence Bound / Expected Improvement 获取函数、相对 gap 规则、贪心剪枝、信息增益和 GP‑UCB regret 分析。

**📊 数据集**

合成基准（Branin、Hartmann、PressureVessel、DTLZ2 等嵌入 50 维）以及真实任务（Joint NAS/HPO、Optical Design、LassoDNA、Cell Network 等，参数量 26–180）。

**📈 对比分析**

与 Sobol 随机采样、标准 BO、IR/ER 稀疏 BO 进行比较；在大多数基准上 BONSAI 在保持目标/超体积的同时显著降低激活维度，候选生成时间与标准 BO 相近，且在复杂任务中优于 IR/ER。

**⚠️ 局限性**

仅针对默认配置感知，假设参数独立；贪心剪枝可能无法达到全局最优稀疏解；理论分析仅针对 GP‑UCB，EI 与多目标的正式理论待扩展。

---

## 53. HoloGraph: All-Optical Graph Learning via Light Diffraction

**arXiv ID:** 2602.07724 | [PDF](https://arxiv.org/pdf/2602.07724v1)

**作者:** Yingjie Li `[一作]` (Simon Fraser University), Cunxi Yu `[通讯]` (University of Maryland)

**通讯引用:** 1237 | [OpenAlex ID](https://openalex.org/A5029321729)

**关键词:** `7a50eb32-3dbc-4c3e-a038-bda01b2d9965` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `64443552-63e0-44b5-906f-d90fe95c5a1b` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出并实现了HoloGraph，一种全光学自由空间图神经网络系统，用于高效地执行图结构任务。

**💡 创新点**

创新点在于将光学跳跃通道（optical skip channels）嵌入到差异光学网络中，实现光速信息传递和隐式记忆，显著提升图信息聚合与预测能力。

**🔧 技术方法**

采用差异光学神经网络（DONN）、主成分分析（PCA）压缩特征、个性化PageRank（PPRGo）抽取高阶邻居、光学相位调制和光学跳跃通道，以及PyTorch与Pytorch-Geometric框架进行训练与仿真。

**📊 数据集**

使用标准图数据集Cora-ML、Citeseer和Amazon Photo进行节点分类实验。

**📈 对比分析**

与传统方法（PCA、MLP、PPRGo GNN、GCN）和现有光学GNN（DGNN）比较，HoloGraph在Cora-ML、Citeseer和Amazon Photo上达到或接近最佳准确率，同时在能耗方面比GPU/CPU提升3-4个数量级。

**⚠️ 局限性**

局限性包括系统稳定性受限于光学损耗、可扩展性受限于自由空间传输能量衰减、体系结构复杂导致的调试困难，以及对动态图学习的支持尚未充分探索。

---

## 54. VISOR: VIsual Spatial Object Reasoning for Language-driven Object Navigation

**arXiv ID:** 2602.07555 | [PDF](https://arxiv.org/pdf/2602.07555v1)

**作者:** Francesco Taioli `[一作]` (Polytechnic of Turin), Angel X Chang `[通讯]` (Simon Fraser University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种3B参数的统一视觉-语言-动作(VLA)模型VISOR，用显式图像定位推理完成目标物体识别与导航决策，省去多模型管线；

**💡 创新点**

创新点在于将LLM的链式推理与VLM的感知直接整合进单一模型，实现“思考-总结-行动”的可解释推理流程，并通过监督与RL双阶段训练提升通用性与效率；

**🔧 技术方法**

技术上使用Qwen 2.5 VL 3B作为基础，构造包含指令、全景视图、拓扑图、候选路点及目标路点的训练集；先进行监督微调生成三段推理输出，再采用GSPO强化学习优化动作选择；

**📊 数据集**

使用自研的Waypoint-Level Supervision数据集（36,170训练+3,047验证样本），其中包含自然语言描述、全景RGB、拓扑RGB、距离、真实路点与LLM生成的推理轨迹；在CoIN‑Bench和OVON上进行评测；

**📈 对比分析**

与多种基准（PSL、Monolithic、RL‑PPO、BCRL、DAgRL、Uni‑NaVid、MTU3D等）对比，VISOR在多样化分割上的泛化能力强，但在绝对成功率和SPL方面略逊一筹；在CoIN‑Bench分割间表现更稳定，显示了较好的跨环境与语言迁移；

**⚠️ 局限性**

局限性包括：对深度感知和左右空间定位的误判；偶尔产生幻觉标签；在接近目标的“最后一米”导航时易误判；缺乏历史记忆导致误路；RL训练对KL正则敏感且易出现奖励钓鱼。

---

## 55. Human Identification at a Distance: Challenges, Methods and Results on the Competition HID 2025

**arXiv ID:** 2602.07565 | [PDF](https://arxiv.org/pdf/2602.07565v1)

**作者:** Jingzhe Ma `[一作]` (Shenzhen Polytechnic University), Shiqi Yu `[通讯]` (Southern University of Science and Technology)

**通讯引用:** 6457 | [OpenAlex ID](https://openalex.org/A5030831939)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

综述了HID 2025赛题的设置、数据集与参赛团队方法，并对成绩进行了系统分析。

**💡 创新点**

通过细粒度数据清洗、跨域微调、空间对齐与伪标签技术，实现跨域步态识别的精准提升，最终取得94.2% Rank‑1 的最佳成绩。

**🔧 技术方法**

采用DeepGaitV2主干，配合P3D/3D卷积、SwinTransformer、重排序、投票、伪标签生成及多数据集预训练等深度学习技术。

**📊 数据集**

以SUSTech‑Competition为测试集，训练使用CASIA‑B、CASIA‑E、Gait3D、OU‑MVLP、SUSTech‑1K、CCPG、CCGR、HID2022、GREW等公开数据集。

**📈 对比分析**

在Rank‑1精度上与前届竞赛对比，HID 2025各参赛队伍平均提升约4%，最高达94.2%，表明跨域适应与多模态融合取得显著进展。

**⚠️ 局限性**

仅使用Rank‑1单一指标，缺乏极端“野外”场景测试，且模型普遍依赖大量外部数据与复杂集成，部署成本和实时性受到限制。

---

## 56. Multi-Agentic AI for Fairness-Aware and Accelerated Multi-modal Large Model Inference in Real-world Mobile Edge Networks

**arXiv ID:** 2602.07215 | [PDF](https://arxiv.org/pdf/2602.07215v1)

**作者:** Haiyuan Li `[一作]` (University of Bristol), Dimitra Simeonidou `[通讯]` (University of Bristol)

**通讯引用:** 8616 | [OpenAlex ID](https://openalex.org/A5030580652)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种多层Agentic AI框架，联合全局规划、短期调度与节点级部署，实现移动边缘网络中多模态大模型推理的低延迟与公平服务；

**💡 创新点**

创新点在于将大型语言模型作为推理与决策的核心，用自然语言推理和经验记忆驱动宏观路由与微观资源分配，实现跨节点的协同与自适应；

**🔧 技术方法**

使用了LLM‑驱动的规划与调度Agent、Kubernetes容器化部署、OpenStack虚拟化、Prometheus监控、MongoDB记录、GPU时间切片（MIG/时分），并通过Python异步服务与FastAPI进行控制；

**📊 数据集**

在实验中采用四种多模态模型（GPT‑2、GPT‑2‑Large、BLIP、Stable‑Diffusion）作为任务负载，部署于7台不同硬件的VM，构建了一个跨校区的城市级边缘测试床；

**📈 对比分析**

与随机、基于Lyapunov的本地控制、纯Agentic调度等六种基线对比，结果显示其平均延迟下降约80％、Jain公平度提升至0.90，优于所有基线；

**⚠️ 局限性**

限制包括对LLM API 的高调用成本与时延、模型数量与种类有限、实验仅覆盖特定网络拓扑与工作负载，缺乏理论收敛保证与更广泛的泛化评估。

---

## 57. A compliant ankle-actuated compass walker with triggering timing control

**arXiv ID:** 2602.07158 | [PDF](https://arxiv.org/pdf/2602.07158v1)

**作者:** Deniz Kerimoglu `[一作]` (Georgia Institute of Technology), Ismail Uyanik `[通讯]` (Hacettepe University)

**通讯引用:** 331 | [OpenAlex ID](https://openalex.org/A5039548579)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0`

**🎯 论文内容**

提出并仿真了一种新的双足行走模型——触发控制踝关节驱动的罗盘步态（TC‑AACG），通过可调节的踝弹簧预压和触发时机来实现非瞬时合规踝推送，并对其速度、能耗与鲁棒性进行了系统的参数分析。

**💡 创新点**

核心创新在于将踝关节的弹簧在预碰撞阶段可触发激活，从而取代传统的瞬时冲击踝推送，显著提升了在平地或粗糙地面上的行走效率与稳定性；并首次将触发时机与弹簧预压与行走性能的三维关系做了完整的定量研究。

**🔧 技术方法**

采用了拉格朗日动力学推导、Poincaré不动点与线性化稳定性分析、机械能成本（mCoT）与吸引域（BoA）评估，并通过数值仿真实现不同弹簧刚度、预压和触发角度下的行走周期演化。

**📊 数据集**

未使用外部实验数据集，仅基于模型参数（如质量、腿长、弹簧刚度等）进行离散时间仿真；所有结果均来源于数值仿真平台。

**📈 对比分析**

与传统的瞬时踝推送（理想冲击踝）进行对比；结果显示，在相同机械能成本下，TC‑AACG 可实现 30–35% 更高的水平速度；在保持能耗相近的前提下，预碰撞踝推送亦能获得更宽的吸引域，提升鲁棒性。

**⚠️ 局限性**

局限性包括：模型仅为二维平面简化形式，未考虑膝关节、重心外力等实际复杂性；参数对性能高度敏感，实际硬件实现需要精准控制弹簧预压和触发时机；目前仅在仿真中验证，缺乏实验验证；并且在最佳性能点附近吸引域仍相对较窄。

---

## 58. Seeing Roads Through Words: A Language-Guided Framework for RGB-T Driving Scene Segmentation

**arXiv ID:** 2602.07343 | [PDF](https://arxiv.org/pdf/2602.07343v1)

**作者:** Ruturaj Reddy `[一作]` (Monash University), Ganesh Krishnasamy `[通讯]` (Monash University)

**通讯引用:** 276 | [OpenAlex ID](https://openalex.org/A5018479820)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `afceb026-1760-41ae-8d86-010831a37d97` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出了一种基于视觉‑语言模型的动态RGB‑热成像语义分割框架，能够在不同照明条件下自动调节融合策略；

**💡 创新点**

创新点在于：①使用CLIP生成的照明条件和场景嵌入作为门控信号；②构建稀疏MoE融合模块实现像素级动态专家切换；③引入软门控Unbalanced Point Transformer保留暗区细节；④自校准层级解码器提升边界精度；

**🔧 技术方法**

核心技术包括CLIP视觉‑语言预训练模型、稀疏Mixture‑of‑Experts（MoE）网络、Soft‑Gated UPT、Dilated Feature Aggregation（DFA）自校准解码器及交叉熵+Focal损失；

**📊 数据集**

在MFNet数据集（约1569对RGB‑热图像，9类）上进行训练与评估；

**📈 对比分析**

与多种CNN与Transformer融合基线（如CMX、CMAAHF、MFNet、RTFNet等）对比，本文在mIoU上达62.3%、mAcc 77.5%，位列当前最先进方法之首；

**⚠️ 局限性**

局限性：模型主要针对照明不良情形，尚未扩展到雨雾、雪等恶劣天气；对CLIP的依赖使得模型对预训练知识分布有限制，且推理时门控计算开销较大。

---

## 59. Performance Evaluation of V2X Communication Using Large-Scale Traffic Data

**arXiv ID:** 2602.07244 | [PDF](https://arxiv.org/pdf/2602.07244v1)

**作者:** John Pravin Arockiasamy `[一作]` (Karlsruhe Institute of Technology), Alexey Vinel `[通讯]` (Karlsruhe Institute of Technology)

**通讯引用:** 7471 | [OpenAlex ID](https://openalex.org/A5003670494)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文使用真实大规模交通数据对高速公路与城市交叉口的 V2X 通信性能进行评估

**💡 创新点**

创新点在于首次将 HighD 与 InD 轨迹数据转化为 SUMO 兼容格式，并结合 Artery V2X 栈实现规模化（10⁵+车辆）消息级评估，揭示真实交通下 DCC 极少激活

**🔧 技术方法**

使用 SUMO 微观仿真、Artery V2X 网络栈、ETSI ITS‑G5 协议、IEEE 802.11p/EDCA 与 Reactive DCC 机制

**📊 数据集**

HighD（高速公路 110k 车）和 InD（城市交叉口 8.2k 车）两个真实轨迹数据集

**📈 对比分析**

通过 IGG、IPG、PDR、CBR 等 KPI 对比，高速公路 PDR≈100%，IPG 随距离升高显著；交叉口 PDR 94–100%，IPG 在 50–150 m 以上明显升高；平均 CBR 低于 0.1，Reactive DCC 在高速公路几乎未激活，交叉口仅有局部接收端抑制

**⚠️ 局限性**

仅考虑车辆的 CAM 交互，未涉及非机动车或更复杂的 V2X 服务；仿真受规则约束，可能与真实驾驶细节存在微小差距

---

## 60. Mirage: Transmitting a Video as a Perceptual Illusion for 50,000X Speedup

**arXiv ID:** 2602.07396 | [PDF](https://arxiv.org/pdf/2602.07396v1)

**作者:** Junjie Wu `[一作]` (Southwest Jiaotong University), Ziyuan Yang `[通讯]` (Sichuan University)

**通讯引用:** 1968 | [OpenAlex ID](https://openalex.org/A5019886356)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `fede83ac-7505-405f-ab37-e7284695c47f` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Mirage 框架，利用视频理解、语义通信和生成重构技术，实现不传输原始像素即可完成高效视频传输。

**💡 创新点**

创新点在于把时空语义分离为文本字幕和关键帧语义，并通过 VQ‑VAE 进行离散化压缩，同时在接收端使用生成式视频模型，达成 50,000× 的数据压缩速率，并支持发送方、网络、接收方的个性化控制。

**🔧 技术方法**

采用视频字幕生成、关键帧选择、VQ‑VAE 语义编码、可靠文本传输及基于条件扩散的生成式视频模型（如 EasyAnimate、Grok Imagine）。

**📊 数据集**

实验基于公开 UCF101 视频数据集，使用 DAM 模型进行字幕生成。

**📈 对比分析**

与原始视频流和传统 AE‑语义压缩对比，Mirage 在不同 SNR 条件下实现 25,000–50,000 倍的数据压缩和 3 位数级别的时延提升，语义相似度保持在 0.65–0.75 之间。

**⚠️ 局限性**

局限在于对生成模型的依赖，极端压缩会导致帧级细节丢失；目前仅在模拟环境评估，真实无线网络下的实时性与鲁棒性仍需进一步验证。

---

## 61. MosaicThinker: On-Device Visual Spatial Reasoning for Embodied AI via Iterative Construction of Space Representation

**arXiv ID:** 2602.07082 | [PDF](https://arxiv.org/pdf/2602.07082v1)

**作者:** Haoming Wang `[一作]` (University of Pittsburgh), Wei Gao `[通讯]` (University of Pittsburgh)

**通讯引用:** 6161 | [OpenAlex ID](https://openalex.org/A5081351589)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 MosaicThinker，一种在推理时通过构建全局语义地图并使用视觉提示来增强小型嵌入式视觉语言模型的跨帧空间推理能力。

**💡 创新点**

通过在推理阶段将多帧碎片化的空间信息融合成稀疏的全局语义地图，并利用迭代关键帧选择和拓扑感知对齐，实现了无需额外训练的高效跨帧空间推理。

**🔧 技术方法**

采用稀疏语义地图构建、基于图像匹配的三维变换、最大生成树对齐、Gaussian核关键帧采样、视觉提示和小型 VLM 提示策略。

**📊 数据集**

在 VSI‑Bench、STI‑Bench、Metro‑Spatial‑QA 等室内空间推理基准以及 InfiniBench 合成数据上进行评测。

**📈 对比分析**

与 Direct Input、Video‑CoT、Scene Graph、APC 等五个训练‑free 基线以及基于真值语义地图进行对比，在各类设备上显著提升跨帧空间推理准确率，最大提升约 11‑45% 之间。

**⚠️ 局限性**

仍受深度估计误差、场景遮挡、模型尺寸限制等影响，且对极大空间或复杂动态场景的可扩展性与实时性还有待进一步验证。

---

## 62. Enhancing Time Series Classification with Diversity-Driven Neural Network Ensembles

**arXiv ID:** 2602.07579 | [PDF](https://arxiv.org/pdf/2602.07579v1)

**作者:** Javidan Abdullayev `[一作]` (University of Haute Alsace), Germain Forestier `[通讯]` (University of Haute Alsace)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了一种在时间序列分类中显式促进特征多样性的多模型神经网络集成框架。

**💡 创新点**

创新点在于将特征正交损失直接作用于最终卷积层的特征表示，形成序列训练的去相关学习策略，从而显著提升集成多样性。

**🔧 技术方法**

采用了LITE轻量级卷积网络、特征正交（余弦相似度）损失、交叉熵损失、Adam优化器、PyTorch实现，并在128个UCR数据集上训练。

**📊 数据集**

使用UCR时间序列分类档案中的128个单变量数据集。

**📈 对比分析**

通过Multi-Comparison Matrix和Wilcoxon检验与现有SOTA如LITETime、MultiROCKET比较，发现Deco-LITETime-4在仅四个模型的情况下平均准确率0.8496，几乎与五模型LITETime持平，并在大多数数据集上显著优于基准。

**⚠️ 局限性**

局限在于只对单变量数据进行评估、正交损失仅施加于最后一层，且在极小规模集成时收益有限。

---

## 63. Graph homophily booster: Reimagining the role of discrete features in heterophilic graph learning

**arXiv ID:** 2602.07256 | [PDF](https://arxiv.org/pdf/2602.07256v1)

**作者:** Ruizhong Qiu `[一作]` (University of Illinois Urbana-Champaign), Hanghang Tong `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 17445 | [OpenAlex ID](https://openalex.org/A5068043486)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了一种基于图变换的框架 GRAPHITE，通过引入特征节点并与原图节点相连，直接提升图的同类性（homophily），从而改善异类图（heterophilic graph）上的节点分类效果。

**💡 创新点**

创新点在于：①首次提出显式图变换方法来提升图同类性，而非仅仅通过改进网络结构；②利用特征节点作为“枢纽”实现节点间的间接同类连接，显著降低新增边数；③在变换后的图上设计了兼容性高的自门控 GNN 架构。

**🔧 技术方法**

技术手段包括：图变换（添加特征节点及特征边），特征节点的平均特征聚合，改进的邻域聚合（自门控 + 加权边），以及对比实验中使用的多种基线 GNN（如 GCN、GAT、GraphSAGE、JKNet、FAGCN 等）。

**📊 数据集**

实验数据集：异类图 Actor、Chameleon-F、Squirrel-F、Minesweeper；同类图 Cora、CiteSeer，用于评估在不同同类性场景下的性能。

**📈 对比分析**

与 27 个最先进 GNN 方法进行对比；在所有异类基准上均显著优于现有方法（提升 4–5%），在同类图上保持与最佳方法相近；同时显著提升图的特征同类性与调整后同类性指标（最高提升达 3000%）。

**⚠️ 局限性**

局限性：仅适用于离散特征的图；对连续特征的处理尚未系统化；变换会略微增加图规模和计算开销，尤其在大图上需要进一步优化；目前仅验证了节点分类任务，其他任务的泛化还需探索。

---

## 64. Aegis: Towards Governance, Integrity, and Security of AI Voice Agents

**arXiv ID:** 2602.07379 | [PDF](https://arxiv.org/pdf/2602.07379v1)

**作者:** Xiang Li `[一作]` (Fordham University), Wenqi Wei `[通讯]` (Fordham University)

**通讯引用:** 3615 | [OpenAlex ID](https://openalex.org/A5069331320)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出了Aegis框架，对基于音频大语言模型（ALLM）的语音代理进行红队安全评估，涵盖银行、IT支持和物流三大高风险场景；

**💡 创新点**

创新点在于：①模拟真实部署管线并设计五类结构化攻击情境（身份绕过、隐私泄露、资源滥用、权限升级、数据/指令中毒）；②对比直接读取数据库与仅查询接口两种访问策略；③系统化地将攻击向量与模型后端功能对应，形成面向场景的红队流程；

**🔧 技术方法**

主要技术：ALLM背端模型（GPT‑4o、GPT‑4o‑mini、Gemini‑1.5 Pro、Gemini‑2.5 Flash/Pro、Qwen2 Audio、Qwen‑2.5‑omni），攻击方采用GPT‑4o生成多轮对话；使用基于策略的意图过滤、日志审计与实时风险检测；

**📊 数据集**

数据集：基于银行账户、IT资产、物流调度的内部模拟数据库；攻击对话通过人工设计的5种攻击者人格和性别变体生成；语音输入在实验中通过文字模拟，后期可扩展为真实语音；

**📈 对比分析**

评价指标包括身份绕过成功率、隐私泄露检测率、权限升级成功率、指令中毒执行率、资源滥用率；对7种模型在两种数据库访问模式下进行250次对话评估。结果显示，限制为查询接口可将身份与隐私风险降至0%，但权限升级与资源滥用仍有10‑20%成功率；开源模型（Qwen系列）相对更易被攻击；总体性能说明单一访问控制不足，需多层防御；

**⚠️ 局限性**

局限性：①仅评估三类业务场景，其他行业可能有不同风险；②攻击方仅使用GPT‑4o，未涵盖人类或更多样化语音攻击；③对话为文字模拟，未验证真实语音噪声与口音对攻击的影响；④未对模型在持续对话中的长期学习和适应性进行深入探讨。

---

## 65. DuMeta++: Spatiotemporal Dual Meta-Learning for Generalizable Few-Shot Brain Tissue Segmentation Across Diverse Ages

**arXiv ID:** 2602.07174 | [PDF](https://arxiv.org/pdf/2602.07174v1)

**作者:** Yongheng Sun `[一作]` (Xi'an Jiaotong University), Fan Wang `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 13387 | [OpenAlex ID](https://openalex.org/A5100380531)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `a6cb313d-240c-4723-a372-3ba1f39b9afc`

**🎯 论文内容**

本文提出了 DuMeta++ 框架，通过双重元学习实现跨年龄段的少样本脑组织分割。

**💡 创新点**

创新点在于将元特征学习与元初始化学习结合，并通过基于内存池的类别感知正则化，实现无配对纵向数据的长期一致性。

**🔧 技术方法**

技术包括 3D U‑Net 架构、双层元学习（MFL + MIL）、内存池原型三元组损失以及 Dice/交叉熵联合损失。

**📊 数据集**

使用 iSeg‑2019、IBIS12M、IBIS24M、OASIS3 和 ADNI 五个公开 MRI 数据集进行训练与评估。

**📈 对比分析**

在一/五样本少样本设置下，与多种自监督、元学习和跨域方法比较，DuMeta++ 在 Dice、ASD 等指标上均获得显著提升，尤其在 6 个月婴儿和老年人群的分割任务中优于现有最先进方案。

**⚠️ 局限性**

局限性包括对伪标签噪声的敏感、单一原型正则化可能不足以捕获类别内部变异、仅针对 T1 影像和三类组织、以及对极端年龄或更高维模态的泛化能力尚待验证。

---

## 66. Dense Neural Networks are not Universal Approximators

**arXiv ID:** 2602.07618 | [PDF](https://arxiv.org/pdf/2602.07618v1)

**作者:** Levi Rauchwerger `[一作]` (Princeton University), Ron Levie `[通讯]` (Technion)

**通讯引用:** 405 | [OpenAlex ID](https://openalex.org/A5001833718)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文证明了在权重有限且层数固定的密集ReLU网络无法成为Lipschitz函数的通用逼近器，揭示了宽度提升并不能无限增强表达能力。

**💡 创新点**

创新点在于将弱正则性引理与图神经网络理论结合，构造了可压缩的计算核，实现了对任意宽度网络的输入无关确定性压缩，并通过VC维下界证明表达力上限，首次给出密集网络的不可通用性判定。

**🔧 技术方法**

主要技术包括弱正则性(regularity)引理、计算核与计算信号的切比雪夫距离、图神经网络的消息传递模型、VC维上界与下界分析以及对ReLU网络的结构压缩。

**📊 数据集**

实验使用MNIST数据集，训练了一隐藏层全连接ReLU网络，对比了无约束训练与权重被限制在[-10/d_i-1,10/d_i-1]的密集模式。

**📈 对比分析**

通过对比两种训练模式的训练/测试准确率，发现密集网络随宽度增加只提升到约90%训练准确率并停滞，而标准网络可逼近99%准确率，验证了理论中宽度饱和的预测。

**⚠️ 局限性**

局限性包括：仅对全连接深度网络给出结果，未考虑卷积或注意力结构；理论依赖权重严格界定，实际训练中可能无法完全满足；实验规模仅为单隐藏层MNIST，缺乏更大规模或更复杂数据的验证。

---

## 67. Minimum Carbon Trusses: Constructible Multi-Component Designs with Mixed-Integer Linear Programming

**arXiv ID:** 2602.07185 | [PDF](https://arxiv.org/pdf/2602.07185v1)

**作者:** Zane Hallowell Schemmer `[一作]` (Massachusetts Institute of Technology), Josephine Voigt Carstensen `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 655 | [OpenAlex ID](https://openalex.org/A5080283907)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `5b4c1114-4a70-478e-9921-2514ee03850d` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文提出一种基于混合整数线性规划（MILP）的低碳桁架拓扑优化框架，能够在设计中同时考虑多种材料/构件、构造性约束以及预应力等因素，实现对碳足迹的最小化。

**💡 创新点**

创新点在于将构造性约束（最小截面、节点复杂度、交叉成员、角度限制）与多材料/多构件选择以及柔性截面通过McCormick包络线性化统一到单一MILP中，并支持预应力与张弛力结构的设计。

**🔧 技术方法**

采用了混合整数线性规划、McCormick包络逼近、节点与关系矩阵构造以及预应力/张弛力约束等技术。

**📊 数据集**

使用了基于几何网格的地基结构（ground structure）设计空间，测试了二维悬臂式Michell桁架和三维锁多普桥梁等案例，材料库包括木材、钢棒与钢绳。

**📈 对比分析**

通过与传统线性程序和不考虑构造约束的MILP进行对比，验证了构造约束对碳足迹、结构重量、节点复杂度的影响；在多材料案例中，约束导致碳足迹上升但重量下降，且节点复杂度显著降低。

**⚠️ 局限性**

局限性包括模型对大规模问题求解仍需高计算资源；McCormick包络在非确定结构中存在误差；预应力与张弛力约束复杂，求解时间显著增加。

---

## 68. Efficient Table Retrieval and Understanding with Multimodal Large Language Models

**arXiv ID:** 2602.07642 | [PDF](https://arxiv.org/pdf/2602.07642v1)

**作者:** Zhuoyan Xu `[一作]` (University of Wisconsin-Madison), Shuai Zhang `[通讯]` (AWS)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种三阶段（检索、重排序、生成）框架，实现对大规模表格图像库的检索与理解，以回答用户查询。

**💡 创新点**

创新点在于将视觉与文本编码器联合训练形成统一嵌入空间进行检索，并使用MLLM进行跨模态重排序与生成，显著提升检索召回率和答案准确率。

**🔧 技术方法**

使用了LayoutLMv3+GTE作为视觉/文本编码器、CLIP-ViT-L-14为视觉编码器、Mistral-7B LLM，并结合FAISS索引、对比学习、提示微调等技术。

**📊 数据集**

构建了包含88,161/9,819样本、48,504张表格的MMTab衍生数据集，覆盖8个领域。

**📈 对比分析**

与CLIP、ImageBind、Colpali等零射检索模型以及基线LLM/MLLM进行对比，检索召回率提升约7%，答案准确率提升约6%，在多项表格任务上甚至超过基线提供的黄金表格。

**⚠️ 局限性**

局限在于未充分验证对真实扫描表格或网页截图等噪声更大场景的鲁棒性，且对复杂布局和多表格交叉推理的适应性尚待提升。

---

## 69. Landscaper: Understanding Loss Landscapes Through Multi-Dimensional Topological Analysis

**arXiv ID:** 2602.07135 | [PDF](https://arxiv.org/pdf/2602.07135v1)

**作者:** Jiaqing Chen `[一作]` (Arizona State University), Gunther H. Weber `[通讯]` (Lawrence Berkeley National Laboratory)

**通讯引用:** 2861 | [OpenAlex ID](https://openalex.org/A5101451813)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了一个名为 Landscaper 的开源 Python 框架，用于构造、可视化和量化任意维度的损失景观，并引入了基于拓扑数据分析的 SMAD（Saddle-Minimum Average Distance）指标来衡量景观平滑度和连通性。

**💡 创新点**

创新点在于：①将 Hessian 主方向子空间构造与拓扑数据分析（merge tree、persistence barcode）结合，实现高维景观的全局拓扑刻画；②提出 SMAD 作为全局拓扑指标，能够区分局部尖锐但全局连通的景观与真正难以优化的景观；③展示 SMAD 在缺乏 OOD 验证集的科学机器学习任务中预测 OOD 泛化的潜力。

**🔧 技术方法**

使用技术包括：Hessian 特征值分解构造子空间；网格采样生成高维损失景观；拓扑数据分析工具（持久同调、merge tree、persistence barcode）提取拓扑特征；SMAD 计算公式；与传统曲率指标（Hessian trace、λ_max）和其他度量（CKA、模式连通性）进行对比。

**📊 数据集**

实验数据集涵盖：图像分类 CIFAR-10（ResNet‑20、CNNs）；语言模型 MultiBERTs（英文预训练）；分子性质预测 QM9（SchNet、DimeNet++）；化学反应预测（3D GNN 生成催化剂选择性）；以及对应的 OOD 实验数据集。

**📈 对比分析**

与传统低维投影、Hessian trace、λ_max 等指标对比，SMAD 在多种架构（CNN、Transformer、GNN）中更能捕捉优化几何差异；在语言模型的关键预训练阶段，SMAD 能显现景观平滑而 Hessian trace 却升高；在化学反应任务中，SMAD 与 OOD RMSE 具有 ρ≈0.93 的强相关，显著提升 OOD 预测性能；整体性能优于仅使用局部曲率或传统 TDA 视觉化方法。

**⚠️ 局限性**

局限性包括：①SMAD 需要 Hessian 计算和大规模网格采样，计算成本高；②在高维（>5D）分析中需稀疏采样，可能错过细粒度拓扑；③对噪声优化场景的鲁棒性尚未充分验证；④需要与其他指标联合使用以增强解释性。

---

## 70. VividFace: Real-Time and Realistic Facial Expression Shadowing for Humanoid Robots

**arXiv ID:** 2602.07506 | [PDF](https://arxiv.org/pdf/2602.07506v1)

**作者:** Peizhen Li `[一作]` (Macquarie University), Yang Zhang `[通讯]` (University of North Texas)

**通讯引用:** 70445 | [OpenAlex ID](https://openalex.org/A5100419770)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

开发了VividFace系统，实现了在0.05秒内实时且逼真地将人类面部表情投影到仿人类机器人的面部。

**💡 创新点**

创新点包括：①提出X2CNet++框架，对运动转移模块进行细粒度微调并引入特征适配训练；②通过异步I/O和流式推理实现极低延迟的实时投影。

**🔧 技术方法**

使用了关键点无缝运动转移（LivePortrait/implicit‑keypoint）、GAN自监督重建、特征适配对齐、异步I/O流式推理、VGG感知损失、Huber回归等技术。

**📊 数据集**

主要数据集为X2C（人类→仿人表情数据集），预训练使用VoxCeleb、MEAD，评估时使用OpenFace提取AU进行客观评价。

**📈 对比分析**

与X2CNet、Smile、Coexpression等基线比较，主观AUR平均4.76±0.40，客观MAID 0.181；系统延迟平均0.034s（90%负载0.046s），P95<0.04s，表现优于基线。

**⚠️ 局限性**

局限性在于仅支持单人一对一场景，易受噪声影响，且两阶段框架可进一步简化；多人人情境或环境噪声下性能可能下降。

---

## 71. Free Energy Mixer

**arXiv ID:** 2602.07160 | [PDF](https://arxiv.org/pdf/2602.07160v1)

**作者:** Jiecheng Lu `[一作]` (Georgia Institute of Technology), Shihao Yang `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 1158 | [OpenAlex ID](https://openalex.org/A5057260690)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `fede83ac-7505-405f-ab37-e7284695c47f` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出 Free Energy Mixer（FEM），通过 log‑sum‑exp 读取实现价值感知的逐通道选择，从而突破传统 attention 的“无损存储但损失读取”限制。

**💡 创新点**

创新点在于将注意力读取视为变分自由能优化，允许每个通道独立、值驱动地选择索引，并通过可学习温度（LTL）与两级门控实现从平均到硬索引的连续调节，保持与原始注意力相同的时间复杂度。

**🔧 技术方法**

核心技术包括 log‑sum‑exp、可学习逆温度（LTL）、两级门控（内温度门和外比例门）、低秩卷积以及与软max、线性注意、RNN/SSM 等任意先验的无缝集成。

**📊 数据集**

实验覆盖 NLP（FineWeb‑Edu、Open LLM Leaderboard）、视觉（ImageNet）、时间序列（Weather、Solar、ETT 等）、自回归语言建模、图像分类和 TSF 任务，使用公开基准数据集。

**📈 对比分析**

与标准 softmax attention、Gated Linear Attention、DeltaNet、Mamba、RNN/SSM 等基线在相同参数预算下比较，FEM 在压缩/召回、上下文记忆、推理准确率、语言模型多项评测及图像分类准确率等指标上持续领先，并且推理速度和吞吐量与现有方法持平或更优。

**⚠️ 局限性**

局限性在于未做工程优化（如自定义 GPU kernel），未扩展到极大模型或极长上下文；实验仅验证了中等规模模型的算法优势，缺乏极端规模和长序列的实证。

---

## 72. Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model

**arXiv ID:** 2602.07120 | [PDF](https://arxiv.org/pdf/2602.07120v1)

**作者:** Jacqueline He `[一作]` (University of Washington), Pang Wei Koh `[通讯]` (Allen Institute for Artificial Intelligence)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种推理时的“Anchored Decoding”方法，在生成过程中将高效但可能侵犯版权的模型（risky model）与只使用公共领域文本训练的安全模型（safe model）结合，通过动态控制每步分布与安全模型的KL距离来抑制直白复制。

**💡 创新点**

创新点包括：①使用可调的全局信息预算K-NAF框架给出序列级版权风险的理论保证；②引入前缀债务与自适应预算策略，使得对高风险提示的早期干预更加精细；③提供字节级实现（Byte Anchored Decoding）解决不同分词器模型的兼容性问题；④在实验中构造了新的可许可安全模型（Safe Llama）并验证了多模型对齐。

**🔧 技术方法**

核心技术包括：KL散度约束的闭式融合公式、Newton-Raphson求解混合权重、ByteSampler框架、前缀对数似然比（LLR）估计与债务计算、以及自适应预算滚存。

**📊 数据集**

使用的主要数据集包括：BookBench（16本受版权保护的小说片段）用于评估复制风险，Common Pile用于训练安全模型，Books3和Wikipedia作为检索块列表，BioS作为事实性评估数据。

**📈 对比分析**

与多种单模型（System、MemFree、RCAD）和双模型（CP‑Fuse、TokenSwap）基线比较。Anchored Decoding和Byte Anchored Decoding在六组模型对上均达成Pareto前沿，既实现了近原始流畅度与事实性，又将复制风险平均降低约75%（NCR≥75%）。相较于基线，提升了约0.5分的流畅度和0.1-0.2的事实性评分，推理时延约1.1×。

**⚠️ 局限性**

局限性包括：仅在特定的安全模型与风险模型对上验证，仍需进一步评估在更大规模或不同领域的泛化；K‑NAF理论基于KL散度，实际复制风险与法律风险仍不完全等价；对极端长文本或多模态生成的适用性尚未充分测试；以及前缀债务阈值和自适应预算参数需要手工调优。

---

## 73. The Parameterized Complexity of Independent Set and More when Excluding a Half-Graph, Co-Matching, or Matching

**arXiv ID:** 2602.07606 | [PDF](https://arxiv.org/pdf/2602.07606v1)

**作者:** Jan Dreier `[一作]` (TU Wien), Sebastian Siebertz `[通讯]` (University of Bremen)

**通讯引用:** 826 | [OpenAlex ID](https://openalex.org/A5073548944)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

对在排除半图、共匹配或匹配三种图模式的图类中，独立集、团与支配集三种经典问题的参数化复杂性做了完整的分类，并给出了新的 FPT 及 W[1]-hard 结果；同时提出了针对半图指数有界图类的近似算法。

**💡 创新点**

①首次完成这八种组合的全局复杂性划分；②利用模型理论中的可辨序列推出半图+共匹配指数有界类的 FPT 结果；③构造特殊图类证明半图指数有界但共匹配指数无界时独立集仍为 W[1]-hard；④设计基于可辨序列的分支和 kernelization 算法实现近似。

**🔧 技术方法**

使用了可辨序列、Ramsey 理论、图宽度（如 mim‑宽度、cham‑宽度）以及 χ‑boundedness 等工具；此外还用到了模型理论中的稳定性概念、VC‑维度和经典的 Gyárfás 颜色化算法。

**📊 数据集**

本工作为理论研究，不使用实验数据集；所有结果均为严格的理论证明。

**📈 对比分析**

与已有的多项式时间、FPT 与 W[1]/W[2]-hard 结果进行对照；通过引入半图指数和共匹配指数将问题细化为八类，证明对应的算法复杂度（例如 O(n²h+2) 产生大小至少 k^{1/h} 的独立集）或证明相应的硬度；性能评价仅以理论复杂度表达，未涉及实际运行时间。

**⚠️ 局限性**

局限性包括：
• 仍未给出完全可行的实用算法，主要是理论证明；
• 对于仅有共匹配指数有界、半图指数无界的类仍未给出更强的可解性结果；
• 近似算法的逼近比（k^{1/h}、log_{2m+2}k-2）在实际规模下可能不够优秀；
• 证明中常用的常数和界限较大，导致算法在实践中可能不可行。

---

## 74. Measuring cross-language intelligibility between Romance languages with computational tools

**arXiv ID:** 2602.07447 | [PDF](https://arxiv.org/pdf/2602.07447v1)

**作者:** Liviu P Dinu `[一作]` (University of Bucharest), Simona Georgescu `[通讯]` (University of Bucharest)

**通讯引用:** 8463 | [OpenAlex ID](https://openalex.org/A5051048705)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了五大罗曼语（法语、意大利语、西班牙语、葡萄牙语、罗马尼亚语）的互相可理解性，提出并评估了一种基于词汇相似度、音素相似度和语义相似度的词汇可理解性指数（D_LI），并将其应用于两个大型平行语料库（RomCro与EuroParl）。

**💡 创新点**

创新点在于：①提出将正字与音素相似度与语义相似度结合的综合可理解性指数；②在语义层面引入语义相近词判定以处理同源词的语义漂移；③使用公开的RoBoCoP词汇关联数据库和预训练的多语种词向量实现大规模自动化评估；④通过可视化热图展示可理解性不对称性。

**🔧 技术方法**

技术手段包括：正则编辑距离（Levenshtein）用于正字/音素相似度；FastText 与 Sentence‑BERT 的预训练词向量用于语义相似度；Affinity Propagation 聚类构建上下文语义表示；spaCy、Snowball 词干化用于文本预处理；基于上述指标计算 D_LI，并通过统计聚合得到句子、语料层级可理解性分数。

**📊 数据集**

数据集包括：1）RoBoCoP 词汇关联数据库（约 46,000 词对）；2）ProtoRom 词典子集（约 19,222 词元）；3）RomCro 双语平行语料库（约 167k 句子）；4）EuroParl 双语平行语料库（约 2M 句子）。

**📈 对比分析**

比较方法：将 D_LI 的排名与人工 Cloze 测试的可理解性排名进行 Spearman 相关性检验；在 RomCro 上相关系数为 0.71（p=0.0013），在 EuroParl 上约 0.44。性能方面，基于正字相似度的 D_LI 在 RomCro 上平均可理解性约 23–30%，而音素相似度低约 11–18%；与人类实验结果的相关性表明指标能一定程度反映真实可理解性。

**⚠️ 局限性**

局限性包括：①平行语料库规模有限且领域单一（文学与政治演讲），导致词汇覆盖不足；②词向量覆盖率不足，特别是上下文词向量需要聚合；③词汇数据库中存在多重词源和拼写错误，需进一步清洗；④模型对语义漂移的处理仍不完善，未能完全捕捉同源词的多义性；⑤人类实验样本小，难以构成绝对金标准。

---

## 75. Long-Context Long-Form Question Answering for Legal Domain

**arXiv ID:** 2602.07190 | [PDF](https://arxiv.org/pdf/2602.07190v1)

**作者:** Anagha Kulkarni `[一作]` (J. P. Morgan Chase), Behrouz Madahian `[通讯]` (J. P. Morgan Chase)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了针对法律文件的长上下文长文本问答系统LCLF-QA，解决了文档结构复杂、术语专门化导致的检索与回答困难。

**💡 创新点**

通过结合领域特定查询重写、布局感知分块以及覆盖度评估指标，突破传统RAG/LongRAG在法律文档长上下文与隐含结构处理上的不足。

**🔧 技术方法**

使用了Mistral‑3B‑Instruct微调/GPT‑4o查询重写、BM25与OpenAI text‑embedding‑3‑large混合检索、Reciprocal Rank Fusion、父子层级分块、CoT过滤和领域特定生成器等技术。

**📊 数据集**

基于SME审核的546个问答对（60个人工、486个合成）覆盖24份企业税务法律文档，合成问答采用6种问答模板。

**📈 对比分析**

在召回率和覆盖度指标上与RAG、LongRAG基线比较，单重写闭源查询重写召回0.6798、覆盖分数0.6722，显著优于LongRAG（p<0.01），并通过消融验证各组件贡献。

**⚠️ 局限性**

仅在企业税务法律域验证，闭源模型依赖，未在其他法律子领域或多模态文档上测试，且系统主要针对英语文档。

---

## 76. Privately Learning Decision Lists and a Differentially Private Winnow

**arXiv ID:** 2602.07370 | [PDF](https://arxiv.org/pdf/2602.07370v1)

**作者:** Mark Bun `[一作]` (Boston University), William Fang `[通讯]` (Boston University)

**通讯引用:** 36108 | [OpenAlex ID](https://openalex.org/A5085888091)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

在本文中，作者提出了针对决策列表（decision lists）和大边距半空间（large‑margin halfspaces）的差分隐私学习算法，涵盖了PAC模型和在线学习模型。

**💡 创新点**

创新点在于：①在PAC模型下，给出了一种与最优非隐私算法几乎相同样本复杂度且计算高效的隐私决策列表学习器；②在在线学习模型中，设计了隐私版Winnow算法，实现了对大边距半空间的多项式对数误差上界；③通过将决策列表映射为大边距半空间，进一步得到隐私决策列表的在线学习方法。

**🔧 技术方法**

核心技术包括：利用指数机制（Exponential Mechanism）进行私有近似经验风险最小化；使用稀疏向量技术（Sparse Vector）控制更新次数；设计自适应权重更新的Confident Winnow子算法，并通过随机采样逼近权重向量；结合多项式时间的迭代覆盖策略实现高效学习。

**📊 数据集**

本工作为理论研究，无实验数据集；算法分析基于随机分布、假设函数空间以及理论误差上界。

**📈 对比分析**

与传统的非隐私Winnow和决策列表学习算法相比，隐私算法在样本/误差上界仅在常数和多项式次序上略有损失，保持了polylog(d)或polylog(T)的误差上界，展示了在隐私约束下可实现与非隐私方法相当的性能。

**⚠️ 局限性**

局限性包括：仅在可实现（realizable）假设下给出误差/错误上界；算法在大规模维度或高边距场景下可能导致隐私预算与误差上界呈高次多项式；未对非可实现或漂移目标进行分析；实现复杂度虽然多项式，但常数因子较大。

---

## 77. LCM decomposition of linear differential operators in positive characteristic

**arXiv ID:** 2602.07237 | [PDF](https://arxiv.org/pdf/2602.07237v1)

**作者:** Raphaël Pagès `[一作]` `[通讯]` (Johannes Kepler University), Raphaël Pagès (Johannes Kepler University)

**关键词:** `847a60d8-a755-47af-ba5d-c5236b9e3083` `a8e75ba4-7a2d-4153-b003-06c94533add0` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了一种在有限域（正特征p）上计算线性微分算子最小公左倍（LCLM）分解的算法。

**💡 创新点**

核心创新在于：①利用p-曲率的弗罗贝尼乌斯标准形快速确定分解的“类型”与同类；②构造一个“等价类中的小算子”L*，其已知LCLM分解；③通过求解等价算子之间的同构实现分解的传递；④在正特征下实现多项式时间（对阶、次数和p的多项式）且实验表明对p的依赖可降为近线性。

**🔧 技术方法**

技术手段包括：p-曲率计算与其特征多项式、弗罗贝尼乌斯标准形、左/右最大公因子与最小公倍数、线性微分模块理论、Morita 等价、求解混合微分方程的同构、符号计算与多项式系统求解。

**📊 数据集**

论文主要为理论算法研究，无使用具体实验数据集；所有复杂度评估基于符号计算和理论上限。

**📈 对比分析**

与之前的分解方法相比，该算法在正特征下实现了多项式时间复杂度；理论上对p的依赖为二次，但实验表明实际表现更接近线性；相比传统需要处理非分裂特征多项式或零除子的问题，该方法避免了这些困难。

**⚠️ 局限性**

限制包括：①需要p-曲率特征多项式无不合可分因子且分解基于可分性假设；②对p的二次复杂度上界仍存在，虽然实验显示可降低；③算法依赖于求解等价算子之间的同构，若同构不“简短”，可能导致系数增长；④在存在中心不可约因子时需要额外处理。

---

## 78. Hyperparameter Transfer Laws for Non-Recurrent Multi-Path Neural Networks

**arXiv ID:** 2602.07494 | [PDF](https://arxiv.org/pdf/2602.07494v1)

**作者:** Shenxi Wu `[一作]` (Fudan University), Wei Lin `[通讯]` (Fudan University)

**通讯引用:** 16773 | [OpenAlex ID](https://openalex.org/A5100665430)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究了非循环多路径神经网络（如CNN、ResNet和Transformer）的深度可扩展性，给出了学习率与模型深度的通用幂律关系；

**💡 创新点**

提出了基于网络整体更新能量预算的“算术平均最大更新参数化”（AM‑μP），并证明在此框架下学习率随有效深度按-3/2幂律缩放；

**🔧 技术方法**

使用最大更新原则、网络层次更新能量分析、均值场理论、自动化学习率搜索与回归拟合等技术；

**📊 数据集**

在CIFAR‑10、CIFAR‑100以及ImageNet子集上进行实验；

**📈 对比分析**

通过对不同深度模型在单轮训练中的学习率搜索并对数-log图做线性回归，得到的斜率均与理论-1.5接近，说明方法在多种架构与数据集上均能实现学习率的零射击迁移；

**⚠️ 局限性**

主要局限在于仅验证了浅层到中层深度范围，未系统评估极深网络；适用性仍受初始化、归一化、优化器等二阶因素影响，且对极大模型的可扩展性需进一步验证。

---

## 79. IPBAC: Interaction Provenance-Based Access Control for Secure and Privacy-Aware Systems

**arXiv ID:** 2602.07722 | [PDF](https://arxiv.org/pdf/2602.07722v1)

**作者:** Sharif Noor Zisad `[一作]` (University of Alabama at Birmingham), Ragib Hasan `[通讯]` (University of Alabama at Birmingham)

**通讯引用:** 3819 | [OpenAlex ID](https://openalex.org/A5076460405)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了基于交互追溯的访问控制模型IPBAC，并将模糊逻辑应用于历史交互记录来实现动态、上下文感知的授权决策。

**💡 创新点**

创新点在于将交互追溯与模糊逻辑结合，利用交互历史与用户可信度等多维度给出访问置信度，实现非二元化、灵活的访问授权；同时通过交互记录实现可审计与公平。

**🔧 技术方法**

使用技术包括模糊逻辑（隶属函数、模糊规则）、交互追溯记录结构、RBAC对比实验、响应时间测量等；核心实现为IPBAC决策函数。

**📊 数据集**

实验使用约1.5万条交互追溯日志（来源未公开，可能为合成数据），在此数据集上构造了15,000个交互记录。

**📈 对比分析**

方法上将IPBAC与传统RBAC进行对比，比较了请求数增至500时授予的访问次数及系统响应时间。IPBAC在访问请求数量增加时授予的访问数更高，响应时间保持稳定（约0.065秒/请求），表明性能优于RBAC。

**⚠️ 局限性**

局限性包括：数据集规模有限、未在真实业务场景下验证；阈值α需人工调节，缺乏自动化优化；未讨论大规模并发下的可扩展性与安全性分析。

---

## 80. The Value of Variance: Mitigating Debate Collapse in Multi-Agent Systems via Uncertainty-Driven Policy Optimization

**arXiv ID:** 2602.07186 | [PDF](https://arxiv.org/pdf/2602.07186v1)

**作者:** Luoxi Tang `[一作]` (Binghamton University), Zhaohan Xi `[通讯]` (Binghamton University)

**通讯引用:** 116 | [OpenAlex ID](https://openalex.org/A5026309535)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过设计三层不确定性度量（个体、互代理、系统层面）来诊断多代理辩论中的崩溃现象，并提出基于不确定性的策略优化（UDPO）来降低自矛盾、同行冲突和低置信度输出，从而提升辩论系统的鲁棒性。

**💡 创新点**

创新点在于：①首次将不确定性拆分为三层指标并证明其与辩论失败高度相关；②提出不确定性驱动的奖励与不对称优化目标，直接惩罚各类崩溃行为；③利用不确定性作为筛选与训练信号，显著提升对抗攻击的耐受性。

**🔧 技术方法**

主要技术包括：大语言模型多代理辩论框架、基于强化学习的PPO/CLIP策略优化、离散化不确定性指标（翻转率、互相不一致度、熵等）、KL约束的相对更新目标以及对抗攻击评估。

**📊 数据集**

使用的公开数据集有：GSM8K（数学推理）、TruthfulQA（事实问答）和CommonsenseQA（常识推理）。

**📈 对比分析**

在标准MAD、MAPPO和RMAAC等基线上进行对比，UDPO在所有数据集上均实现了最高准确率提升（最高可达25个百分点），同时将系统级不确定性降低约80%，并在面对攻击时保持较高准确率，表现出更强的鲁棒性。

**⚠️ 局限性**

局限性包括：①仍依赖LLM的推理质量，无法彻底消除误导信息；②训练成本高、对算力需求大；③对不同任务和规模的迁移性尚未充分验证；④未引入人类裁判或更丰富的角色设计；⑤实现复杂度高，部署门槛较高。

---

## 81. Robust Multiagent Collaboration Through Weighted Max-Min T-Joins

**arXiv ID:** 2602.07720 | [PDF](https://arxiv.org/pdf/2602.07720v1)

**作者:** Sharareh Alipour `[一作]` `[通讯]`, Sharareh Alipour

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `5b4c1114-4a70-478e-9921-2514ee03850d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出了针对加权最大-最小T-join与2k匹配问题的近似与精确算法，并给出了有效的上下界

**💡 创新点**

创新点在于：①用贪心k‑center思路得到全局上界并转化为对μ_2k的对数近似；②基于耳分解构造多种可行边集并给出上界；③给出（1,2）图的完全解法；④将上述理论应用于实际数据，验证误差可控

**🔧 技术方法**

主要技术包括：贪心排序、最小权完美匹配、耳分解与最大化max(P)、TSP 1.5近似、动态规划求解（1,2）图、NP‑Hard化的Knapsack近似

**📊 数据集**

实验数据集包括：从DBLP提取的70个作者的协作图（权重为1/共著+1），以及70个主要城市的距离图（权重为实际距离），都构成完整图并满足三角不等式

**📈 对比分析**

比较方法：对每个实例分别计算贪心下界（mwm）与耳分解或TSP上界；结果显示上下界比值均低于1.2，说明贪心选择的点集几乎是最优的；算法时间为O(n^4)，显著快于先前依赖ellipsoid的方法

**⚠️ 局限性**

局限性包括：耳分解得到的上界在某些极端实例（如所有权重相同）可能很松；TSP上界在全相同权重时变弱；算法对一般加权图的近似比率未得到理论上限；（1,2）图结果仅适用于二值权重

---

## 82. Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks

**arXiv ID:** 2602.07090 | [PDF](https://arxiv.org/pdf/2602.07090v1)

**作者:** Yu-Che Tsai `[一作]` (National Taiwan University), Shou-De Lin `[通讯]` (National Taiwan University)

**通讯引用:** 3086 | [OpenAlex ID](https://openalex.org/A5087480257)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

设计并实现了SPARSE框架，针对用户定义的隐私概念在文本嵌入中实现定向加噪，提升隐私保护与下游任务性能的平衡；

**💡 创新点**

提出了可微分神经元掩码学习用于识别隐私敏感维度，并将马氏距离机制用于生成椭圆形噪声，以实现维度感知的差分隐私注入；

**🔧 技术方法**

采用了Hard Concrete分布进行可微分掩码学习、马氏距离机制（扩展的Laplace机制）以及局部差分隐私理论；

**📊 数据集**

在六个公开基准数据集（STS12、FIQA等）、PII-Masking-300K和MIMIC-III临床笔记数据集上评估，使用GTR-base、Sentence‑T5和SBERT嵌入模型；

**📈 对比分析**

与基准差分隐私方法Laplace Mechanism和Purkayastha Mechanism对比，SPARSE在相同隐私预算下显著降低泄露率（如ST12 10ε时从60%降至19%），同时保持或提升下游任务指标（如NDCG、相关性等），并在多模型、多攻击场景下表现稳健；

**⚠️ 局限性**

依赖用户提前定义隐私概念，未覆盖未列明的敏感属性；对噪声参数和掩码稀疏度的选择敏感，需额外调参；在更强的攻击或跨模态攻击中仍可能存在安全隐患；

---

## 83. PipeMFL-240K: A Large-scale Dataset and Benchmark for Object Detection in Pipeline Magnetic Flux Leakage Imaging

**arXiv ID:** 2602.07044 | [PDF](https://arxiv.org/pdf/2602.07044v1)

**作者:** Tianyi Qu `[一作]` (SINOMACH Sensing Tech Co, Ltd), Yafei Ou `[通讯]` (Hokkaido University)

**通讯引用:** 163 | [OpenAlex ID](https://openalex.org/A5060935366)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建并公开了首个大规模管线磁通泄漏（MFL）检测数据集 PipeMFL-240K，并在该数据集上对多种主流目标检测模型进行了系统基准评估。

**💡 创新点**

创新点包括：①提供240,320张伪彩色 MFL 图像、191,530 个高质量标注的12类对象；②展示了极端长尾分布、极小目标和跨尺度差异的真实工业挑战；③通过统一切片推理框架实现连续轴向图像的评测；④为未来研究提供标准化的公开数据与评测基准。

**🔧 技术方法**

采用的技术主要是深度学习目标检测器（Faster R‑CNN、RetinaNet、YOLOv5/8/11/World/26、RT‑DETR、RF‑DETR 等）以及基于切片裁剪与滑动窗口的推理策略；评估指标采用 COCO 风格的 mAP50、mAP50:95、Precision、Recall、F1 等。

**📊 数据集**

使用的数据集为 PipeMFL-240K，包含 12 类（4 类缺陷 + 8 类结构元件）共 240,320 张伪彩色图像，分 6:2:2 训练/验证/测试划分，标注覆盖真实管线 1,480 km。

**📈 对比分析**

比较方法：在同一实验设置下训练 15+ 种检测模型，结果表明最佳 mAP50 仅约 0.498（YOLOv8‑l），mAP50:95 最高 0.270；所有模型在小目标与稀有类别上表现不佳，精确率与召回率存在明显折衷。

**⚠️ 局限性**

局限性：现有检测框架对极端长尾、极小目标和跨尺度的适应不足；缺乏对管线几何、轴向位置和物理先验的建模，导致稀有类别召回率低、误检率高，亟需更专用的多尺度与先验融合方法。

---

## 84. Multimodal Enhancement of Sequential Recommendation

**arXiv ID:** 2602.07207 | [PDF](https://arxiv.org/pdf/2602.07207v1)

**作者:** Bucher Sahyouni `[一作]` (University of Surrey), Simon Hadfield `[通讯]` (University of Surrey)

**通讯引用:** 4843 | [OpenAlex ID](https://openalex.org/A5091184063)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了MuSTRec框架，融合了多模态图与序列Transformer，统一了协同过滤、内容推荐与上下文推荐三大范式；

**💡 创新点**

创新点在于：①将文本与视觉特征构建item-item图并与用户-物品图联合学习；②在Transformer头中加入频率自注意力以缓解过平滑；③通过预训练的图嵌入与自监督损失提升稀疏数据表现；

**🔧 技术方法**

采用Graph Neural Network（LightGCN）构建图嵌入，Transformer+频域自注意力做序列预测，结合BPR与交叉熵损失；

**📊 数据集**

使用亚马逊公开四大商品类数据集（Sports、Clothing、Electronics、Baby），包含文本与图像特征；

**📈 对比分析**

与多模态基线（FREEDOM、MMGCN、MGCN等）及序列基线（SASRec、BERT4Rec等）在统一评测协议下对比，MuSTRec在HR@10、HR@20、NDCG等指标提升最高达33.5%；

**⚠️ 局限性**

局限性包括：对超大规模数据的泛化性不足，频率注意力调参敏感，用户嵌入增强效果在小样本数据上显著但在大样本数据中不稳定，且仍受限于图结构稀疏与序列长度限制。

---

## 85. Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi

**arXiv ID:** 2602.07382 | [PDF](https://arxiv.org/pdf/2602.07382v1)

**作者:** Debtanu Datta `[一作]` (Indian Institute of Technology Kharagpur), Saptarshi Ghosh `[通讯]` (Indian Institute of Technology Kharagpur)

**通讯引用:** 4538 | [OpenAlex ID](https://openalex.org/A5073748464)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在印度法律文本摘要任务中，通过在提取式与生成式模型上注入法律领域知识（如预训练的 InLegalBERT 编码器和在法律语料上的持续预训练），实现了对英文和印地语摘要的性能提升。

**💡 创新点**

创新点包括：① 通过将法律专属预训练编码器嵌入 SummaRuNNer 实现提取式摘要知识注入；② 在 T5、mT5、Gemma‑2 等生成式模型上进行持续预训练并配合 GaLore 与 LoRA 进行内存/参数效率优化；③ 对跨语言（英→印）摘要进行多语种预训练以验证跨语言迁移效果；④ 提出了法律领域特定的 BERTScore 与多项事实一致性指标，并通过专家评估验证模型优越性。

**🔧 技术方法**

使用的技术包括：BERT‑style 预训练编码器（InLegalBERT、mBERT）、T5/mT5/​Gemma‑2 文本生成框架、span‑corruption 填空预训练、GaLore 低秩梯度投影、LoRA 参数高效微调、ROUGE‑2/ROUGE‑L、InLegal‑BERTScore、BERTScore、SummaC、NEPrec 等评价指标。

**📊 数据集**

主要数据集：MILDSum（3,122 个印度法院判决，提供英文与印地语摘要）以及用于预训练的 InLegalBERT‑PT（英）和 Bail Corpus（印）两个法律语料子集。

**📈 对比分析**

在所有模型上与 SOTA（SummaRuNNer、CrossSum‑mT5）以及 GPT‑4 进行比较，结果显示：在英→英摘要上 ROUGE‑2 提升约 20–23%、ROUGE‑L 15–19%；在英→印摘要上相较 CrossSum‑mT5 提升 23% 的 ROUGE‑2、19% 的 ROUGE‑L；且在事实一致性和专家评估上均显著优于基线，差异均通过 Wilcoxon/Mann‑Whitney 检验达到 99% 置信水平。

**⚠️ 局限性**

局限性：① 仅覆盖英印两种语言，未验证其他语言的通用性；② 依赖专门的法律语料，若无此类资源效果受限；③ 部分模型仍出现轻微的事实错误或流畅度不足；④ 评估集规模有限，进一步大规模测试仍待验证。

---

## 86. Haptically Experienced Animacy Facilitates Emotion Regulation: A Theory-Driven Investigation

**arXiv ID:** 2602.07395 | [PDF](https://arxiv.org/pdf/2602.07395v1)

**作者:** Preeti Vyas `[一作]` (University of British Columbia), Karon E. MacLean `[通讯]` (University of British Columbia)

**通讯引用:** 6110 | [OpenAlex ID](https://openalex.org/A5061277210)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

开发并评估了一个具有人形动物外观、循环呼吸与心跳模拟的软体机器人，研究其通过触觉互动支持情绪调节的效能。

**💡 创新点**

创新点在于将生物模仿的呼吸和心跳整合为单一无声触觉刺激系统，并通过多模态混合方法系统验证其对四类情绪调节策略（情境选择、注意部署、认知改变、反应调节）的支持；此外首次在实验室内对比不同动画参数化的效果。

**🔧 技术方法**

技术实现包括：CuddleBits平台软体机器人（伺服与振动执行器实现呼吸与心跳），嵌入式触摸传感器与IMU进行交互监测；生理采集系统（GSR、PPG心率、呼吸传感器）与自定义情绪评估量表（内部对话、ER促进问卷等）。

**📊 数据集**

数据集为30名参与者的实验数据，包含生理波形、问卷评分、访谈转录；未使用公开公开数据集，全部为实验内部收集。

**📈 对比分析**

比较方法采用被试内重复测量设计，对比四个条件（无机器人、静止机器人、动画机器人、动画+心跳）。结果显示动画机器人相较于对照在生理抑制与正向情绪上显著优于；心跳参数化对量化指标未产生显著增益，但在定性访谈中提升亲和力与情感共振；效能表现在情绪自评、GSR与心率下降、主观情绪提升等方面。

**⚠️ 局限性**

局限包括：样本量有限、未设置情绪诱发任务导致基线情绪未标准化、实验室环境与真实使用场景差异较大、未实现实时交互反馈、未充分考虑个体差异导致的效果异质性。

---

## 87. Generative Reasoning Re-ranker

**arXiv ID:** 2602.07774 | [PDF](https://arxiv.org/pdf/2602.07774v1)

**作者:** Mingfu Liang `[一作]` (Meta Platforms), Luke Simon `[通讯]` (Meta Platforms)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了 Generative Reasoning Re-ranker（GR2），通过三阶段流程（中间训练语义ID、生成并监督推理轨迹、强化学习优化）实现对推荐候选列表的可解释性重排序。

**💡 创新点**

创新点包括：①实现 99%+ 语义 ID 唯一性以桥接项目语义与世界知识；②使用拒绝采样与结构化提示生成高质量层级推理轨迹；③为重排序任务设计专属奖励函数并采用 DAPO 算法实现强化学习。

**🔧 技术方法**

技术方法包括：大语言模型 Qwen3-8B、RQ‑VAE 语义 ID 编码、对比损失、EMA 与随机最后层级等代码簿平衡技术、对齐式中间训练、链式推理提示、目标/拒绝采样、DPO‑style 的奖励与 DAPO 强化学习。

**📊 数据集**

实验使用 Amazon Review 的 Beauty 与 Sports 两大真实电商数据集（≈22k/35k 用户，≈12k/18k 商品）。

**📈 对比分析**

与 OneRec‑Think、基线预排序等对比，GR2 在 Recall@10 与 NDCG@10 上均超过 1%‑2% 的提升，且在 RL 阶段进一步提升 3%‑5% 的召回率，证明推理与 RL 的结合显著提升重排序性能。

**⚠️ 局限性**

局限性在于：仅在两个数据集上验证，推理轨迹生成与强化学习过程计算开销大；模型仍需依赖大规模预训练 LLM，且对极端稀疏或动态商品场景的适应性尚待评估。

---

## 88. LCLA: Language-Conditioned Latent Alignment for Vision-Language Navigation

**arXiv ID:** 2602.07629 | [PDF](https://arxiv.org/pdf/2602.07629v1)

**作者:** Nitesh Subedi `[一作]` (Iowa State University), Soumik Sarkar `[通讯]` (Iowa State University)

**通讯引用:** 10057 | [OpenAlex ID](https://openalex.org/A5081037761)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 Language-Conditioned Latent Alignment (LCLA) 框架，通过把视觉语言观测映射到冻结的专属专家隐状态，实现在没有专属状态信息的情况下完成导航。

**💡 创新点**

创新点在于将感知与控制完全解耦：先用强化学习在拥有特权状态的环境中训练专家并冻结其隐层与动作头，然后只训练一个轻量化适配器把 VLM 的视觉语言嵌入对齐到专家隐空间，实现零样本泛化与模块化复用。

**🔧 技术方法**

采用预训练的视觉语言模型 (CLIP/SigLIP/SigLIP2) 作为特征提取器，使用 PPO 训练的专家网络，利用监督式潜在对齐损失训练适配器，并结合自注意力、跨注意力等 Transformer 结构。

**📊 数据集**

在 Isaac Sim 的室内对象导航任务中，使用 Room A 作为训练集、Room B 作为 OOD 评估，生成多模板语言指令；通过图像增强生成约 260k 训练样本。

**📈 对比分析**

与 Privileged PPO、LCBC、PELA、LeLaN 等基线对比，LCLA 在 ID 场景实现 SR 90.4%、SPL 0.90，OOD 场景 SR 80.5%、SPL 0.80，明显优于基线且参数量和推理速度均更优。

**⚠️ 局限性**

局限性包括：仅能复用已有专家的控制逻辑，无法应对需要记忆或长时规划的任务；对 RGB 观测的鲁棒性仍依赖 VLM 表示，未在真实机器人上验证；若专家隐空间不合适，性能会显著下降。

---

## 89. The Median is Easier than it Looks: Approximation with a Constant-Depth, Linear-Width ReLU Network

**arXiv ID:** 2602.07219 | [PDF](https://arxiv.org/pdf/2602.07219v1)

**作者:** Abhigyan Dutta `[一作]` (Purdue University), Paul Valiant `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出了一系列基于 ReLU 神经网络的近似中位数（以及任意秩）计算方法，研究了深度-宽度权衡，最终给出常数深度、线性宽度的构造，在单位超立方体上的均匀分布下实现指数级小的 L2 近似误差。

**💡 创新点**

创新点包括：① 使用多阶段稀疏化与哈希技巧在保持中位数候选集的同时大幅压缩非零元素；② 通过从最大值计算到中位数的通用约简，打破了先前针对最大值的 loglog d 深度瓶颈；③ 在逼近范式下首次证明了与精确计算之间的分离，并给出线性宽度下的逼近下界。

**🔧 技术方法**

核心技术：ReLU 神经网络构造、深度‑宽度分析、概率稀疏化、全局哈希投射、迭代集中元素、基于最大值的约简与上界/下界证明。

**📊 数据集**

使用的“数据集”为理论分布——在 [0,1]^d 上的均匀分布；实验/实际数据未涉及。

**📈 对比分析**

与已有针对最大值的近似结果相比，本工作在同等误差下显著降低了所需深度（从 loglog d 下降到常数）并保持线性宽度；相较于精确计算，证明了在逼近误差可接受的情形下显著减少网络规模；下界表明宽度至少需要线性、深度至少 3 时无法达到指数级误差。

**⚠️ 局限性**

限制：① 深度 46 仍可能非最优，真正最小深度未知；② 需要非常大的权重（指数级别）才能实现给定误差；③ 仅在均匀分布上证明，可能不适用于其他分布；④ 证明复杂，缺乏直接可实现的工程实现细节。

---

## 90. The Double-Edged Sword of Data-Driven Super-Resolution: Adversarial Super-Resolution Models

**arXiv ID:** 2602.07251 | [PDF](https://arxiv.org/pdf/2602.07251v1)

**作者:** Haley Duba-Sullivan `[一作]` (Oak Ridge National Laboratory), Emma J. Reid `[通讯]` (Oak Ridge National Laboratory)

**通讯引用:** 156 | [OpenAlex ID](https://openalex.org/A5015069127)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `6215c339-3735-4be3-8a07-5bbb7004712d` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种将对抗攻击直接嵌入超分辨率（SR）模型权重的框架AdvSR，使模型在推理时无需任何输入干预即可诱导下游分类器误判。

**💡 创新点**

首次在SR层面实现对抗训练，联合重建损失与目标交叉熵，实现在保持图像质量的前提下实现高攻击成功率。

**🔧 技术方法**

使用目标化对抗交叉熵损失、L1+感知重建损失、lambda/ratio平衡参数、YOLOv11分类器，以及SRCNN/EDSR/SwinIR三种SR网络。

**📊 数据集**

采用ImageNet 20类子集（19个车辆类别+1个假类），通过高斯模糊+下采样生成低分辨率输入。

**📈 对比分析**

与仅重建的基线进行对比；在YOLO-5上攻成功率可达80%，且PSNR/SSIM基本不下降；在YOLO-20上攻成功率下降至约25%但仍高于基线，并伴随一定图像质量下降。

**⚠️ 局限性**

仅在20类子集、单一分类器和单一源/目标类进行评估，未测试对抗训练或模型微调后的鲁棒性，也缺乏跨架构迁移性与更大规模数据集的验证。

---

## 91. HALO: A Fine-Grained Resource Sharing Quantum Operating System

**arXiv ID:** 2602.07191 | [PDF](https://arxiv.org/pdf/2602.07191v1)

**作者:** John Zhuoyang Ye `[一作]` (University of California), Jens Palsberg `[通讯]` (University of California)

**关键词:** `9a43038e-f401-4fd9-9c05-65c0b8369d7e` `14d48e9d-0069-4ad9-996a-1d5968216998` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并实现了 HALO，提供量子硬件的细粒度空间和时间资源共享，使多个量子进程能够在同一设备上并行执行，并通过动态共享协助量子比特（helper qubits）和 shot‑感知批量调度提升吞吐量。

**💡 创新点**

创新点：①将协助量子比特视为可跨进程共享资源并实现安全的动态复用；②提出基于每个进程 shot 数和电路深度的批量调度算法；③设计硬件感知的多进程映射模型，利用路由距离、进程间耦合和 helper 区域成本的统一成本函数；④实现完整的量子操作系统栈，兼顾利用率、延迟、隔离与容错。

**🔧 技术方法**

采用模拟退火搜索的多进程映射、三元成本函数（Intro、Inter、HRCost）、Round‑robin 指令调度与动态 helper 绑定、shot‑aware 批量调度器，并与 Qiskit 编译器集成。

**📊 数据集**

自定义四类基准集（QEC stabilizer、Arithmetic、Multi‑CX 与随机电路），涵盖小、中规模并且 helper‑qubit 比例差异显著的量子电路，用于评估共享效果和噪声影响。

**📈 对比分析**

与 IBM Quantum（独占调度）、HyperQ（虚拟多工）以及 HALO 的两种变体（无共享、shot‑无感知）进行对比。指标包括空间利用率、吞吐量、每批进程数和 Fidelity。实验显示 HALO 在空间利用率提升 2.44×、吞吐量提升 4.44×，且 Fidelity 下降不超过 33%，显著优于基线。

**⚠️ 局限性**

局限性：共享导致额外的路由噪声和 reset 误差，随数据占用比例 λ 上升会使 Fidelity 降低；调度开销主要来自映射优化，虽然低于 60 秒但仍是瓶颈；目前实现仅支持超导量子硬件，对量子错误率高或不同拓扑的硬件鲁棒性有限。

---

## 92. Do Large Language Models Reflect Demographic Pluralism in Safety?

**arXiv ID:** 2602.07376 | [PDF](https://arxiv.org/pdf/2602.07376v1)

**作者:** Usman Naseem `[一作]` (Macquarie University), Abdullah Mohammad `[通讯]` (DSEU-Okhla)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 Demo‑SafetyBench，一套两阶段的多样性安全评估框架，先在提示级别构建多族裔安全域数据，再用 LLM 作为评判者进行零样本评分，剔除对模型回答的偏差。

**💡 创新点**

创新点在于将多族裔多元性直接嵌入提示文本层面，而非依赖人类标签或模型回答；通过 14 个安全域、SimHash 去重与人口统计条件化生成实现均衡且规模化的数据集；并引入 LLM‑as‑Rater 的零样本评分方法，提供可度量的多族裔敏感性指标。

**🔧 技术方法**

技术包括 Mistral‑7B‑Instruct 进行多标签安全域分类、Llama‑3.1‑8B‑Instruct 条件生成低资源域提示、SimHash 去重、LLM‑as‑Rater（Gemma‑7B、GPT‑4o、LLaMA‑2‑7B）零样本评估、ICC、DS、DPD、EOD 等多族裔评估指标。

**📊 数据集**

数据集来源于 DICES（包含性别、种族、年龄、教育信息）重分类并扩充后得到 43,050 条提示；安全域取自 BeaverTails 体系。

**📈 对比分析**

与三种评判模型相比，GPT‑4o 在内部一致性（ICC=0.87）和低族裔敏感性（DS=0.12）上表现最佳，Gemma‑7B 与 LLaMA‑2‑7B 性能相近但更轻量；小模型显示更高的族裔差异和公平性差距，但推理成本更低；总体表明可在不使用超大模型的情况下实现可观的多族裔安全评估。

**⚠️ 局限性**

局限包括：评估仅在提示级别，未涉及多模态或模型回答；使用固定的零样本解码设置，未探究随机性对结果的影响；仅验证了三种 LLM，其他模型或硬件环境可能产生不同表现；数据集仍基于公开资源，未覆盖更广泛的文化与语言背景。

---

## 93. Trace-Focused Diffusion Policy for Multi-Modal Action Disambiguation in Long-Horizon Robotic Manipulation

**arXiv ID:** 2602.07388 | [PDF](https://arxiv.org/pdf/2602.07388v1)

**作者:** Yuxuan Hu `[一作]` (Nanyang Technological University), Jianfei Yang `[通讯]` (Nanyang Technological University)

**通讯引用:** 6980 | [OpenAlex ID](https://openalex.org/A5005666034)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

设计并实现了一种名为 Trace-Focused Diffusion Policy (TF‑DP) 的单一生成式策略，通过在全局视觉输入中投影机器人历史执行轨迹并渲染“trace‑focused field”，实现了对多模态动作歧义（MA^2）的消解，提升了长周期操作的时序一致性和鲁棒性。

**💡 创新点**

创新点包括：①将执行历史以二维轨迹图像形式嵌入观察空间，避免了传统做法中需要输入大量历史时序数据导致的计算成本；②引入“trace‑focused field”使得视觉模型聚焦任务相关区域，从而抑制背景干扰；③通过轻量级渲染实现几乎零额外推理开销，证明了在单一策略框架下解决MA^2的可行性。

**🔧 技术方法**

核心技术：扩散式生成策略（Diffusion Policy） + 轨迹投影与高斯响应场渲染 + ResNet‑18 与 MLP 编码器 + 目标动作的正向/反向噪声过程；实验中还将该模块与 DDIM、Flow‑Matching 等不同去噪框架对比验证通用性。

**📊 数据集**

数据集：在真实 Franka Research 3 机器人平台上，使用 SpaceMouse + HIL‑SERL 进行人机操作收集，共 30 篇（Task1, Task2）和 50 篇（Task3）演示轨迹，包含三种长周期任务：放置方块、按键盘、抽屉内物品搬运。

**📈 对比分析**

方法比较：与原始 Diffusion Policy (DP) 及 DP‑HistAct（加入固定窗口历史观测）进行对比；实验显示 TF‑DP（trace）平均成功率 72.22%，全 TF‑DP（trace+field）达 91.67%，远高于 DP 的 11.11% 以及 DP‑HistAct 的 8.33%。在背景干扰场景下，TF‑DP 从 2.78% 提升至 88.89%。推理时间仅增加 0.02 s，显著低于 DP‑HistAct 的 36% 额外计算。

**⚠️ 局限性**

局限性：①轨迹仅在二维图像空间投影，未充分利用三维几何信息；②目前仅在三类相对简单的长周期任务上验证，缺乏更广泛的复杂任务或多模态传感器场景的测试；③对极端视觉变化（如光照剧烈变化）或非可见轨迹的鲁棒性尚未完全评估。

---

## 94. Looking and Listening Inside and Outside: Multimodal Artificial Intelligence Systems for Driver Safety Assessment and Intelligent Vehicle Decision-Making

**arXiv ID:** 2602.07668 | [PDF](https://arxiv.org/pdf/2602.07668v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 95. Laplacian-LoRA: Delaying Oversmoothing in Deep GCNs via Spectral Low-Rank Adaptation

**arXiv ID:** 2602.07278 | [PDF](https://arxiv.org/pdf/2602.07278v1)

**作者:** Sai Vamsi Alisetti `[一作]` `[通讯]` (University of California), Sai Vamsi Alisetti (University of California)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了 Laplacian-LoRA，通过在图拉普拉斯谱空间加入低秩可学习修正来减缓 GCN 的过平滑问题。

**💡 创新点**

创新点在于仅对传播算子进行低秩谱级别的适配，既弱化了每层的谱收缩，又保持了低通偏置，不改造整个消息传递流程。

**🔧 技术方法**

使用了低秩谱适配（LoRA）技术、谱分析、两层 MLP 生成 θ(λ) 校正函数，以及 PyTorch Geometric 的实现框架。

**📊 数据集**

在五个节点分类基准数据集上进行评估：Cora、Citeseer、Pubmed、CoauthorCS、CoauthorPhysics。

**📈 对比分析**

与标准 GCN 在深度 2~32 的准确率对比，Laplacian‑LoRA 在中深度（8–16 层）上提升约 5–10%，显著延迟过平滑，但在极深层（32 层）仍会出现性能衰退。

**⚠️ 局限性**

局限性包括需要预计算前 k 个 Laplacian 本征向量，规模受限；过平滑仍不可完全消除；对图大小和参数调优的依赖性较高。

---

## 96. Single-shot lossy compression: mutual information bounds

**arXiv ID:** 2602.07280 | [PDF](https://arxiv.org/pdf/2602.07280v1)

**作者:** Victoria Kostina `[一作]` (California Institute of Technology), Victoria Kostina `[通讯]` (California Institute of Technology)

**通讯引用:** 969 | [OpenAlex ID](https://openalex.org/A5001633086)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `fede83ac-7505-405f-ab37-e7284695c47f`

**🎯 论文内容**

本文研究在三类精度约束（保证失真、条件超失真、超失真）下，使用互信息最小化作为对量化器输出熵的凸代理，并给出其与最小描述长度的上、下界。

**💡 创新点**

创新点在于：① 对三类更严格的失真约束提供了互信息代理的上界并消除了对失真度量为度量的限制；② 推导了互信息代理的最优概率核的必要充分条件，扩展了 Csiszár 对期望失真约束的表征；③ 给出了可实现的量化器结构与阈值分配的显式形式。

**🔧 技术方法**

主要技术手段包括：相对熵数据处理不等式、二元相对熵函数的单调性、凸优化与拉格朗日对偶、信息量化与熵量化的比较、以及对失真球的概率分布分析。

**📊 数据集**

本文为理论分析工作，没有使用具体数据集；所有结果均在随机变量的分布 $P_X$ 上一般成立。

**📈 对比分析**

通过与已有的互信息界（如 Posner 的结果）及传统的期望失真代理进行比较，作者证明了在不需要失真为度量且常数更小的条件下，新界更紧；数值实验未给出，但理论上提升了在保证失真约束下的描述长度估计精度。

**⚠️ 局限性**

局限性包括：① 结果主要适用于单次抽样（single‑shot）情形，对 i.i.d. 或长期序列的扩展仍需进一步研究；② 需要先知 $P_X$ 的完整分布；③ 在实际实现中，需要对失真球概率 $P_Y(B_d(x))$ 进行估计，可能导致计算复杂度高。

---

## 97. Unified Biomolecular Trajectory Generation via Pretrained Variational Bridge

**arXiv ID:** 2602.07588 | [PDF](https://arxiv.org/pdf/2602.07588v1)

**作者:** Ziyang Yu `[一作]` (Tsinghua University), Yang Liu `[通讯]` (Tsinghua University)

**通讯引用:** 112679 | [OpenAlex ID](https://openalex.org/A5100355638)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `e15e3743-5ee0-4d5f-813d-d146868082fc` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了Pretrained Variational Bridge (PVB)模型，统一预训练单结构数据与微调轨迹数据，并通过强化学习实现蛋白‑配体结合位点的后优化；

**💡 创新点**

创新点在于将编码器‑解码器结构与增广桥匹配相结合，保持预训练与微调目标一致，且通过adjoint匹配的RL微调显著加速对接位点的探索；

**🔧 技术方法**

使用了变分桥匹配、增广桥匹配、强化学习（adjoint匹配）以及基于SDE的轨迹生成技术；

**📊 数据集**

预训练数据来源于PCQM4Mv2、ANI‑1x、小分子、PDB、PDBBind2020等；微调使用ATLAS、mdCATH、MISATO以及PDBBind2020的MD轨迹；

**📈 对比分析**

与ITO、MDGEN、UniSim、AlphaFlow等基线在蛋白质轨迹和蛋白‑配体轨迹上采用JSD、MSM、EMD、RMSE等指标对比，PVB在绝大多数指标上与传统MD相当并显著优于基线，生成的轨迹更稳定、物理可行；

**⚠️ 局限性**

仍属于顺序轨迹生成，无法实现并行化生成，且在极长时间尺度的模拟上仍受限。

---

## 98. Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion

**arXiv ID:** 2602.07775 | [PDF](https://arxiv.org/pdf/2602.07775v1)

**作者:** Haodong Li `[一作]` (University of California San Diego), Manmohan Chandraker `[通讯]` (University of California San Diego)

**通讯引用:** 9767 | [OpenAlex ID](https://openalex.org/A5046609009)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文研究了自回归视频扩散模型在训练时间受限、测试时无限延展时出现的长时序漂移问题，并提出一种无训练成本的“Rolling Sink”方法来缓解该漂移，实现在5秒训练后即可生成5–30分钟长视频，保持人物身份、颜色与结构稳定且运动连贯。

**💡 创新点**

创新点在于将长时序漂移解释为训练-测试时段不匹配的“曝光偏差”，通过系统分析自回归缓存机制，设计了在保持固定缓存容量（K=6）的前提下进行滚动缓存（S=5）的训练‑free策略，显著提升了超长视频生成的视觉质量与时序一致性。

**🔧 技术方法**

核心技术包括自回归视频扩散（Self‑Forcing框架）、有限缓存的动态维护与滚动更新、以及基于固定噪声种子和固定提示嵌入的无训练漂移抑制。

**📊 数据集**

使用了公开的长视频评估基准（来自《VideoDiffusionBenchmark》系列），并在该基准上进行多维度质量评测。

**📈 对比分析**

与Self‑Forcing和LongLive两种主流AR视频扩散基线进行对比，实验显示Rolling Sink在1分钟和5分钟长视频合成任务中均取得最高平均排名，并在大多数评测维度上获得最优或次优分数，证明其在长时序视觉保真度和时序一致性上优于现有方法。

**⚠️ 局限性**

局限性：目前仅针对单提示的单片长视频合成，缺乏多镜头（多提示）连续生成的支持，难以在更长时间内不断引入新语义并保持跨镜头的平滑过渡。

---

## 99. A Course on the Introduction to Quantum Software Engineering: Experience Report

**arXiv ID:** 2602.07589 | [PDF](https://arxiv.org/pdf/2602.07589v1)

**作者:** Andriy Miranskyy `[一作]` (Toronto Metropolitan University), Andriy Miranskyy `[通讯]` (Toronto Metropolitan University)

**通讯引用:** 764 | [OpenAlex ID](https://openalex.org/A5026957450)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

设计并首次开设了一门跨学本科研究生课程，以软件工程视角讲授量子计算，聚焦可执行程序、经验推理与生命周期管理。

**💡 创新点**

创新点在于模块化课程结构、面向软件生命周期的教学大纲、适用于混合层次学生的评估模型以及通过项目实践实现知识综合的教学模式。

**🔧 技术方法**

主要使用了开源量子编程框架（Qiskit、PennyLane、OpenQASM）以及基于浏览器的 Jupyter Notebook 进行实验教学，并结合课堂讨论、翻转式预习与实时练习。

**📊 数据集**

没有使用传统意义上的数据集，而是通过学生问卷、课堂活动提交、作业、考试成绩和项目报告等教学产出作为评估依据。

**📈 对比分析**

通过学生作业与项目分数、课堂参与率、实验成功率等指标进行内部比较，结果显示学生在量子程序可执行性、SE 视角理解和工具适应性方面均有显著提升，课程保留率高且项目多能进一步扩展为科研论文。

**⚠️ 局限性**

局限性包括单一机构、单一批次、观察性数据、选修性导致的自选偏差、评估方法受 LLM 影响、以及量子工具快速演进导致课程内容易过时。

---

## 100. TABI: Tight and Balanced Interactive Atlas Packing

**arXiv ID:** 2602.07782 | [PDF](https://arxiv.org/pdf/2602.07782v1)

**作者:** Floria Gu `[一作]` (University of British Columbia), Alla Sheffer `[通讯]` (University of British Columbia)

**通讯引用:** 10750 | [OpenAlex ID](https://openalex.org/A5053259123)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

提出了一种名为TABI的GPU加速纹理图集打包算法，能够在交互速度下生成紧凑且平衡的打包结果。

**💡 创新点**

核心创新在于：
1) 通过局部AABB与近似OBB两种图形代理，水平和垂直方向上并行压缩空隙，显著提升紧凑度；
2) 设计“膝部折叠”机制，动态决定每行的折叠宽度和方向，以缓解高度不均衡导致的浪费；
3) 采用混合折叠策略——对大图表使用顺序折叠、对小图表使用前缀和折叠，兼顾质量与速度；
4) 允许用户在性能与质量之间手动调节折叠阈值与间距。

**🔧 技术方法**

技术实现主要包括：
- GPU compute shader 并行执行折叠、推送、代理计算与尺寸搜索；
- 局部AABB与OBB代理以高效近似图表形状；
- 水平/垂直紧缩与冲突检测；
- 膝部检测与动态行方向选择；
- 前缀和折叠与顺序折叠的混合策略；
- 1像素边距与90°旋转/反射控制。

**📊 数据集**

使用了 8,386 个图集数据集，包含两类来源：
1) 通过UV拆分得到的3D模型图表（共 455 个输入，包含手工和自动拆分的模型，最大 44,389 个图表）；
2) 纹理空间渲染（TSS）得到的图表（7,931 个输入，最大 44,389 个图表）。图表数量范围从 2 到 44,389，分布为 <1k：30%，1k-5k：50%，5k-10k：10%，>10k：10%。

**📈 对比分析**

与 Xatlas（离线）、FastAtlas、Chameleon、GPU Chameleon 等方法对比，评估指标为 L² stretch（下采样度）和运行时间。TABI 在平均 5.1 ms 内完成打包，最多 10k 图表仅 10.79 ms；比 Xatlas 快约 500 倍；与 FastAtlas 相比速度稍慢但 L² stretch 降低约 48%。整体而言，TABI 在保持交互性能的前提下，接近离线方法的打包质量。

**⚠️ 局限性**

主要限制：
- 在极少数输入（<2%）中，TABI 的 L² stretch 可能略高于 Chameleon 或 FastAtlas；
- 对图表形状极其不规则或包含大量内部空洞时，代理近似效果有限，导致质量下降；
- 目前仅支持 90° 旋转/反射，无法处理非正交旋转；
- 算法为启发式，缺乏最优性保证，极端情况下仍可能出现较大下采样。

---

## 101. Pareto-guided Pipeline for Distilling Featherweight AI Agents in Mobile MOBA Games

**arXiv ID:** 2602.07521 | [PDF](https://arxiv.org/pdf/2602.07521v1)

**作者:** Xionghui Yang `[一作]` (Peking University), Wenxin Li `[通讯]` (Peking University)

**通讯引用:** 3256 | [OpenAlex ID](https://openalex.org/A5100397213)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `8d10c613-917e-4880-9716-17789f50e119` `5b4c1114-4a70-478e-9921-2514ee03850d` `fede83ac-7505-405f-ab37-e7284695c47f` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

开发了一套面向移动设备的MOBA游戏AI压缩部署管道，通过Pareto最优搜索与知识蒸馏实现教师模型向轻量级学生模型的迁移。

**💡 创新点**

将部署问题构造为多目标Pareto优化，并提出端到端的学生架构设计与搜索流程，显著兼顾性能与低延迟/低能耗。

**🔧 技术方法**

采用知识蒸馏、架构搜索、低秩分解、剪枝、量化等多种技术，并针对MOBA的多层级动作空间设计了KL蒸馏与搜索算法。

**📊 数据集**

使用Honor of Kings 3v3自生成的约两百万状态‑动作对，并在八种英雄组合上进行评估。

**📈 对比分析**

与教师、低秩分解、量化、剪枝以及线性模型对比，轻量级学生在保持约40%胜率的同时，实现12.4倍推理速度提升与15.6倍能耗下降。

**⚠️ 局限性**

仅在Honor of Kings环境验证，压缩方法对极大多模态输入的鲁棒性有限，且搜索过程仍需高昂算力；未考虑在线自适应或多平台兼容。

---

## 102. Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model

**arXiv ID:** 2602.07422 | [PDF](https://arxiv.org/pdf/2602.07422v1)

**作者:** Tianyi Wu `[一作]` (National University of Singapore), See-Kiong Ng `[通讯]` (National University of Singapore)

**通讯引用:** 5313 | [OpenAlex ID](https://openalex.org/A5090171111)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

该工作提出了 SecCoderX，一个在线强化学习框架，通过重用漏洞检测数据并训练漏洞奖励模型，使代码生成 LLM 在保证功能性的同时显著提升代码安全性。

**💡 创新点**

创新点在于：①将漏洞检测数据转化为现实化的漏洞诱导任务并用于 RL 训练；②构建基于 CWE 条件、推理增强的漏洞奖励模型；③设计功能与安全共存的多维奖励函数，解决功能–安全悖论。

**🔧 技术方法**

技术方法包括：大语言模型预训练与指令微调；推理式奖励模型训练（SFT+RL+GRPO）；多语言、CWE 条件下的在线强化学习（GRPO）；以及长度、AST 相似度与格式化等功能奖励。

**📊 数据集**

使用的数据集主要有：PrimeVul、CrossVul、R2Vul 等漏洞检测数据；基于这些数据合成的 24k 个跨 24 类 CWE 与 5 语言的漏洞诱导提示；以及 CyberSecEval SCG、CWEval、HumanEval+、MBPP+ 等安全与功能性评测基准。

**📈 对比分析**

在 CyberSecEval SCG 和 CWEval 上，SecCoderX 的安全率提升 11%–16%，与未对齐模型相比有效安全率（ESR）提高约 10%，相比现有 SafeCoder、ProSec 等方法不但安全率更高，且未出现 ESR 降级（-14%~-54%）的问题。

**⚠️ 局限性**

主要局限包括：奖励模型对特定 CWE 的依赖可能限制泛化；在线 RL 训练需要大量 roll‑out 计算资源；目前实验仅覆盖 5 种语言，未对更大闭源模型做评估；以及奖励设计仍存在手工阈值与潜在奖励操纵风险。

---

## 103. Systematic Performance Assessment of Deep Material Networks for Multiscale Material Modeling

**arXiv ID:** 2602.07192 | [PDF](https://arxiv.org/pdf/2602.07192v1)

**作者:** Xiaolong He `[一作]` (Synopsys Inc.), C. T. Wu `[通讯]` (Synopsys Inc.)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

系统评估了深度材料网络（DMN）及其旋转自由交互材料网络（IMN）在离线训练与在线预测中的性能，并对初始化、批量大小、训练数据量与激活正则化等超参数的影响进行了量化分析。

**💡 创新点**

首次揭示了IMN在训练效率上可提升3.4–4.7倍、在线精度与DMN相当，并通过正则化调控网络复杂度来实现精度与速度的平衡。

**🔧 技术方法**

采用结构保持的机械学习框架、二叉树网络结构、ReLU激活与正则化、固定点迭代及牛顿迭代求解、Adam优化器与学习率调度等技术。

**📊 数据集**

基于DNS得到的RVE线弹性同质化数据（400、1024、2048样本集）以及三个未见的纤维增强复合材料的非弹性测试数据。

**📈 对比分析**

使用均方相对误差、在线计算时间、迭代次数与活跃基节点数等指标，对比DMN与IMN的离线训练时间、在线精度与计算效率，发现IMN训练速度提升3.4–4.7倍，在线精度相当，IMN的牛顿迭代比固定点快1.9–2.6倍。

**⚠️ 局限性**

模型对初始化与激活正则化较为敏感；需要较大的训练集才能降低不确定性；目前仅验证了线弹性训练后在非弹性情形下的泛化，未覆盖更复杂多相或大变形场景。

---

## 104. Hybrid Dual-Path Linear Transformations for Efficient Transformer Architectures

**arXiv ID:** 2602.07070 | [PDF](https://arxiv.org/pdf/2602.07070v1)

**作者:** Vladimer Khasia `[一作]` `[通讯]` (Independent Researcher), Vladimer Khasia (Independent Researcher)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了Hybrid Dual-Path Linear (HDPL)算子，将Transformer中部分线性投影拆分为块对角稀疏路径和低秩VAE瓶颈，从而提升模型效率。

**💡 创新点**

创新点在于将线性变换分为局部高秩块对角子空间与全局低秩变分自编码器两条路径，并在前向过程中加入KL正则化，提供概率隐空间与结构化稀疏。

**🔧 技术方法**

使用块对角稀疏卷积、变分自编码器（重参数化、KL约束）、SiLU激活、RoPE位置编码、RMSNorm、SwiGLU、以及针对Transformer的外推融合。

**📊 数据集**

在FineWeb‑Edu教育子集（Common Crawl）上进行训练与评估，词表大小49,152，序列长度2048。

**📈 对比分析**

与标准Llama‑style稠密Transformer对比，参数量减少约6.8%（从67.1M降到62.5M），验证集损失从4.3206降到4.2838，收敛更快、泛化更好，但推理吞吐量下降约44%。

**⚠️ 局限性**

目前实现基于PyTorch标准操作，导致GPU/TPU上吞吐量低于稠密GEMM；需要自定义融合核才能充分发挥理论计算优势。

---

## 105. Joint Reward Modeling: Internalizing Chain-of-Thought for Efficient Visual Reward Models

**arXiv ID:** 2602.07533 | [PDF](https://arxiv.org/pdf/2602.07533v1)

**作者:** Yankai Yang `[一作]` (Harbin Institute of Technology), Shuo Yang `[通讯]` (Kuaishou Technology)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

设计并训练了一种联合奖励模型 JRM，使判别式奖励模型在保持高效推理的同时内化生成式模型的语义推理能力。

**💡 创新点**

创新点在于通过共享视觉‑语言骨干同时优化排名损失与语言建模损失，将链式推理隐式编码进表示空间，实现“隐式链式思考”，不需在推理时生成中间推理文本。

**🔧 技术方法**

使用了共享视觉‑语言编码器、基于 Gaussian 的不确定性排名学习、交叉熵语言监督、联合损失、SVD 表示分析以及在线 RL（Flow‑GRPO）对齐等技术。

**📊 数据集**

使用了图像编辑奖励数据集（EditReward‑Bench、MMRB2）、自动生成的解释语言监督以及 OmniGen2 生成样本等数据。

**📈 对比分析**

在 EditReward‑Bench 和 MMRB2 上与传统判别式模型（EditReward）及生成式模型（EditScore、GPT‑5 等）进行对比，JRM 在整体指标上提升约 5.9% 与 3.6% 以上，并在在线 RL 场景中提升 1.00 / 0.50 的性能。

**⚠️ 局限性**

限制在于仍需依赖人工或自动生成的偏好/解释标注，无法完全替代真正多模态推理；对大规模数据集和多任务适应性尚待验证；目前仅在图像编辑任务验证，其他任务效果未知。

---

## 106. The Quantumly Fast and the Classically Forrious

**arXiv ID:** 2602.07503 | [PDF](https://arxiv.org/pdf/2602.07503v1)

**作者:** Clément L. Canonne `[一作]` (University of Sydney), Julián Mestre `[通讯]` (University of Sydney)

**通讯引用:** 1686 | [OpenAlex ID](https://openalex.org/A5007528822)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文通过构造新的布尔函数实例，给出了极限 Forrelation 问题的近似最优下界，证明任何经典查询算法至少需要 Ω(2^0.4999 n) 次查询，几乎与已知的最优下界 Ω(2^n/2) 相匹配，并且给出了 Generalized Simon's Problem 的最优查询下界。

**💡 创新点**

创新点在于：①使用部分扩散（partial spread）Bent 函数构造硬实例，突破了先前基于 Maiorana–McFarland 函数的限制；②通过 k‑碰撞游戏（k‑collision game）将碰撞分析推广到更高阶碰撞，从而得到更强的下界；③将同一技术框架应用于 Generalized Simon’s Problem，给出最优下界。

**🔧 技术方法**

主要技术包括：线性代数与有限几何的子空间计数、Bent 函数与其傅里叶变换性质、非均匀球‑箱（balls‑and‑bins）分析、排列不等式、碰撞游戏模型（Game 2–4）以及随机线性变换隐藏结构。

**📊 数据集**

研究为理论计算，没有使用实际数据集；实验与数据集均为随机生成的布尔函数实例。

**📈 对比分析**

通过理论证明比较经典下界与已有的 Ω(2^n/4) 结果，取得 Ω(2^0.4999 n) 的显著提升，几乎达到与单次量子查询的指数优势相当；对 Generalized Simon’s Problem 给出了与已知上界匹配的最优下界。

**⚠️ 局限性**

局限性：仍未完全达到 Ω(2^n/2) 的下界，存在 1‑o(1) 的指数失配；k‑碰撞分析目前仅能推广到 O(√n) 的 k 值；需要更精细的子空间计数或不同的 Bent 函数构造来消除该 o(1)；在更广泛的问题域或更一般的 Forrelation 设置中，方法尚未完全适用。

---

## 107. Learning Brain Representation with Hierarchical Visual Embeddings

**arXiv ID:** 2602.07495 | [PDF](https://arxiv.org/pdf/2602.07495v1)

**作者:** Jiawen Zheng `[一作]` (Hong Kong University of Science and Technology), Chen Liang `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 24808 | [OpenAlex ID](https://openalex.org/A5100334558)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `57a58b01-81b4-4d75-a45c-2e891f272b50` `ba576bd1-e51d-44e8-8077-fc943b333c93` `9ce7179e-700c-4310-ac2b-91df50ded46e` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

本文提出一种基于多尺度视觉编码器的脑-图像对齐框架，利用融合先验将脑信号映射到冻结的扩散模型条件空间，实现零样本检索和高质量图像重建。

**💡 创新点**

创新点在于（1）通过将CLIP语义编码器与VAE像素编码器融合形成层次化视觉表示；（2）使用对比学习将脑嵌入对齐到该融合空间；（3）训练一个文本无关的Fusion Prior，使脑生成的条件与扩散模型的分布保持一致，从而提升跨模态一致性。

**🔧 技术方法**

采用多预训练视觉编码器（CLIP ViT-B/32、RN50、SDXL VAE）构建多尺度特征，利用对比学习（InfoNCE）对齐脑-图像特征，使用IP-Adapter和SDXL UNet作为扩散生成器，并训练Fusion Prior。

**📊 数据集**

使用THINGS‑EEG（10受试者）和THINGS‑MEG（4受试者）数据集进行训练与评估。

**📈 对比分析**

与UBP、BraVL、ATM等现有方法相比，本文在200‑way零样本检索中取得显著提升（EEG intra 75.7%/94.6% vs 50.9%/79.7%），在重建任务上在低层相似度（PixCorr、SSIM）和高层语义相似度（AlexNet、Inception、CLIP）方面均优于或持平于前沿方法。

**⚠️ 局限性**

局限性包括仅在THINGS‑EEG/MEG数据上验证，缺乏跨数据集/跨模态的推广实验；Fusion Prior和视觉堆栈的设计为手工选择，可能未达到最佳效率或性能。

---

## 108. Modeling Batch Crystallization under Uncertainty Using Physics-informed Machine Learning

**arXiv ID:** 2602.07184 | [PDF](https://arxiv.org/pdf/2602.07184v1)

**作者:** Dingqi Nai `[一作]` (Georgia Institute of Technology), Andrew Medford `[通讯]`

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `a8e75ba4-7a2d-4153-b003-06c94533add0` `5a41884c-404f-4688-a89c-aa238c10fe68` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

研究了在测量噪声、溶解度偏移和采样稀疏等不理想数据条件下，物理信息递归神经网络（PIRNN）对批量冷却晶化过程的建模与参数识别效果。

**💡 创新点**

提出将人口平衡模型（PBM）与长短期记忆网络相结合，并通过可调的物理正则化实现软约束，从而在面对随机与结构性不确定性时既保持物理一致性又具备数据驱动的鲁棒性。

**🔧 技术方法**

采用LSTM编码-解码架构、MSE/Huber/平滑损失以及基于PBM方程的物理损失；通过自适应噪声尺度权重和软物理系数λ调节数据与物理约束。

**📊 数据集**

利用基于PBM的合成数据，生成一系列含有不同程度测量噪声、10%溶解度偏移及从2点到9点不同采样频率的仿真批次冷却晶化实验。

**📈 对比分析**

与纯数据驱动RNN和仅使用参考参数的PBM ODE整合进行对比，结果显示在低噪声下PIRNN测试MSE<10⁻⁴，噪声增加时仍能保持物理一致性；在溶解度偏移和稀疏采样情形下，适度物理正则化显著降低误差，直接预测优于纯Ode，表明模型具备良好的泛化与参数解释性。

**⚠️ 局限性**

高噪声导致参数识别非唯一、过度物理权重会产生偏差、极端稀疏采样难以恢复准确动力学参数；另外使用有限差分的物理损失可能引入数值误差，且目前未直接应用真实PAT测量。

---

## 109. Let's Simplify Step by Step: Guiding LLM Towards Multilingual Unsupervised Proficiency-Controlled Sentence Simplification

**arXiv ID:** 2602.07499 | [PDF](https://arxiv.org/pdf/2602.07499v1)

**作者:** Jingshen Zhang `[一作]` (Tianjin University), JunYu Lu `[通讯]` (China Merchants Research Institute of Advanced Technology)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种多语言CEFR级别句子简化框架，通过动态路径规划、语义感知示例选择和带聊天历史的Chain‑of‑Thought逐步生成，实现从高级读者到低级读者的逐级简化。

**💡 创新点**

创新点在于：①将大跨度简化拆解为最优中间步骤的动态规划；②在每一步选取语义保持最佳的示例作为提示；③将聊天历史融入CoT，让模型显式跟踪简化轨迹，提升控制精度与连贯性。

**🔧 技术方法**

使用技术包括：动态规划求最优简化路径、语义文本相似度(STS)评估示例、LLM（Llama‑3‑8B‑Instruct、Gemma‑2‑9b‑it）配合聊天模板与历史的Chain‑of‑Thought推理。

**📊 数据集**

数据集涵盖 CEFR‑SP（English）和 README++（涵盖阿拉伯语、英语、法语、印地语、俄语五种语言），每种语言均采用官方划分的训练/验证/测试集。

**📈 对比分析**

与 COPY、监督式 mT5、公开单步LLM 等基线对比；在所有语言上，规划+语义CoT+聊天历史实现 Spearman ρ 0.49‑0.66、相邻准确率 95‑100%、RMSE 0.67‑0.77，且计算步骤减少 22‑42%。

**⚠️ 局限性**

局限性：仅处理句子级简化，未覆盖文档级连贯性；评估中意义保持难以达成一致，暗示评测方法不足；在大跨度简化中可读性控制与语义保持的权衡仍未得到平衡。

---

## 110. Federated Prompt-Tuning with Heterogeneous and Incomplete Multimodal Client Data

**arXiv ID:** 2602.07081 | [PDF](https://arxiv.org/pdf/2602.07081v1)

**作者:** Thu Hang Phung `[一作]` (Hanoi University of Science and Technology), Phi Le Nguyen `[通讯]` (Hanoi University of Science and Technology)

**通讯引用:** 1185 | [OpenAlex ID](https://openalex.org/A5058485829)

**关键词:** `a154b176-e466-40fc-8ae0-e5cd17677106` `c84dae5d-5273-4348-85a7-b44cb586b4df` `edb9d762-f411-4838-a852-f2d638b018db` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种多模态联邦提示调优框架，针对本地数据多模态且存在不同缺失模式的场景进行训练。

**💡 创新点**

创新点在于将提示分为 inter‑client（跨客户端）与 intra‑client（局部）两类，并通过输入自适应检索与聚类对齐实现跨客户端提示的有效聚合，解决多模态缺失导致的交叉与内部异质性。

**🔧 技术方法**

使用预训练的 ViLT 视觉‑语言变换器作为基准，结合 prompt‑tuning、联邦学习 FedAvg、key–query 距离正则化、聚类优化（Hungarian 算法）等技术实现提示的分层更新与对齐。

**📊 数据集**

在 UPMC Food‑101（图文分类）和 MM‑IMDB（电影类型分类）两个多模态基准数据集上进行实验，并通过模拟不同缺失率生成多种缺失场景。

**📈 对比分析**

与多种基线（FedAvg+prompt、FedMSplit、缺失 prompt‑tuning 等）在 15 个训练/测试缺失组合下比较，取得 F1/准确率提升范围为 1.73%–107.83%（Food‑101）和 4.41%–69.65%（MM‑IMDB），显著优于所有基线。

**⚠️ 局限性**

局限性包括：对预训练模型（如 ViLT）对文本的偏好导致图像缺失场景表现略弱；聚类对齐需要额外计算；在极高缺失率下仍受少量完整模态信息影响。

---

## 111. SciClaimEval: Cross-modal Claim Verification in Scientific Papers

**arXiv ID:** 2602.07621 | [PDF](https://arxiv.org/pdf/2602.07621v1)

**作者:** Xanh Ho `[一作]`, Akiko Aizawa `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了 SciClaimEval 数据集，包含 1,664 条来自 180 篇真实论文的主张及其对应的表格或图形证据，并在表格中提供 PNG、JSON、HTML 等多种格式。

**💡 创新点**

创新点在于①使用真实论文中的主张而非人工合成，②通过改动证据（表格/图形）而非改写主张来生成负样本，③为表格提供多种结构化格式，④聚焦三大领域（ML、NLP、医学），实现真正的跨模态科学主张验证。

**🔧 技术方法**

技术手段包括：人工专家标注、GPT‑5‑nano 进行 LaTeX/HTML 转 JSON、使用多模态 LLMs（InternVL3‑5、Qwen3‑VL、LLaVA、Llama‑3.2‑Vision）、零-shot Chain‑of‑Thought 提示、引入 Pair Accuracy 评估指标。

**📊 数据集**

使用的数据集为 180 篇论文（PeerJ、arXiv、ACL Anthology、NeurIPS 等）产生的 1,664 条主张‑证据对，包含表格（PNG、JSON、HTML）和图形（PNG），与已有多模态验证数据集（SciTab、SciVer 等）做对比。

**📈 对比分析**

在 SciClaimEval 上评测 11 种模型，采用宏 F1 与 Pair Accuracy 两个指标。o4‑mini 在表格子集上接近人类水平（宏 F1 ≈ 85%，Pair Acc ≈ 64%），但在图形子集仍有显著差距（宏 F1 ≈ 77%，Pair Acc ≈ 52%）。不同的证据修改操作（如“改变单元格值”“图形交换”等）对模型的难度差异显著，显示出模型仍需提升对细粒度图形理解的能力。

**⚠️ 局限性**

主要限制包括：JSON 转换时出现 19 条主要错误和 22 条次要错误；表格样本明显多于图形，导致评测不均衡；仅提供 PNG 版表格，未利用其他更易解析的格式。

---

## 112. ArcMark: Multi-bit LLM Watermark via Optimal Transport

**arXiv ID:** 2602.07235 | [PDF](https://arxiv.org/pdf/2602.07235v1)

**作者:** Atefeh Gilani `[一作]` (Arizona State University), Flavio P. Calmon `[通讯]` (Harvard University)

**通讯引用:** 2160 | [OpenAlex ID](https://openalex.org/A5074697940)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于随机线性码和最优传输的多比特水印方法ArcMark，保证在保持文本质量的前提下能将多比特信息嵌入LLM生成的文本；

**💡 创新点**

首次给出多比特水印的香农容量理论，并设计了容量实现方案；通过将信息编码为全长符号并采用圆周角度映射，提升了每令牌信息量并显著降低解码误差；

**🔧 技术方法**

信息理论模型、随机线性码、最优传输（Sinkhorn算法）以及角度编码/解码；

**📊 数据集**

在Llama2‑7B和Llama3‑8B两大LLM上，使用C4‑RealNewsLike数据集作为提示；

**📈 对比分析**

与MPAC、BiMark等主流多比特水印方法对比，ArcMark在3、8、16比特嵌入下，消息准确率和位准确率均显著高于对手，且对困惑度（perplexity）影响可忽略；

**⚠️ 局限性**

容量分析基于简化的i.i.d.两元分布假设，实际应用中对更复杂分布的容量估计与实现仍有待研究；

---

## 113. Knowledge Graphs-Driven Intelligence for Distributed Decision Systems

**arXiv ID:** 2602.07614 | [PDF](https://arxiv.org/pdf/2602.07614v1)

**作者:** Rosario Napoli `[一作]` (University of Messina), Maria Fazio `[通讯]` (University of Messina)

**通讯引用:** 4855 | [OpenAlex ID](https://openalex.org/A5017589999)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

构建了一个基于知识图谱和图嵌入的分布式决策系统框架

**💡 创新点**

提出了知识共享机制，使节点通过局部嵌入聚合实现全局语义一致性

**🔧 技术方法**

采用了GraphSAGE图嵌入、Neo4j图数据库、PCA降维以及Python/Neo4j GDS库

**📊 数据集**

使用了基于Synthetic的分布式节点图（5-20节点，环、全连接、链三种拓扑）

**📈 对比分析**

通过在不同拓扑下的工作负载漂移实验验证，系统在语义一致性与适应性上优于传统集中式方法；实验结果显示漂移曲线与理论相符，保持低信息丢失，性能稳健

**⚠️ 局限性**

实验规模有限，未在真实工业数据上验证；缺乏严格的数学证明；节点异构性和大规模部署时的时延影响未充分探讨

---

## 114. ViHERMES: A Graph-Grounded Multihop Question Answering Benchmark and System for Vietnamese Healthcare Regulations

**arXiv ID:** 2602.07361 | [PDF](https://arxiv.org/pdf/2602.07361v1)

**作者:** Long S. T. Nguyen `[一作]` (Ho Chi Minh City University of Technology), Tho T. Quan `[通讯]` (Ho Chi Minh City University of Technology)

**通讯引用:** 1977 | [OpenAlex ID](https://openalex.org/A5056767671)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建了越南医疗法规多跳问答基准 ViHERMES，并提出基于结构驱动监管知识图的图感知多代理 QA 系统，实现跨文件多跳推理。

**💡 创新点**

创新点在于：①设计了规则式抽取的结构驱动监管知识图（SRKG），②提出种子检索加关系感知传播的检索策略，③引入受控多跳 QA 生成管线和多代理架构，实现法律有效性与多跳推理的统一。

**🔧 技术方法**

采用的技术包括语义聚类+LLM生成、规则式法律关系抽取、稠密+稀疏检索混合、图遍历与关系传播、多代理架构以及 LLM 评判和安全审计。

**📊 数据集**

使用的数据集为 ViHERMES（越南医疗法规多跳 QA 数据集）及其所依赖的官方卫生部法规文本。

**📈 对比分析**

在与 BM25、Dense、Hybrid RAG、IRCoT、MiniRAG、RAPTOR、LightRAG、HippoRAG 2 等基线的对比实验中，系统在 F1、LLM Judge 和 Recall@5 上均优于所有对手，最高 F1 为 0.8334，LLM Judge 0.7554，Recall@5 0.8461。

**⚠️ 局限性**

局限性包括：需要人工规则抽取法律关系、SRKG 构建成本较高、仅针对越南医疗法规，推理深度与时间有效性控制尚待改进。

---

## 115. Do Multi-Agents Dream of Electric Screens? Achieving Perfect Accuracy on AndroidWorld Through Task Decomposition

**arXiv ID:** 2602.07787 | [PDF](https://arxiv.org/pdf/2602.07787v1)

**作者:** Pierre-Louis Favreau `[一作]` (Minitap), Ravid Shwartz-Ziv `[通讯]` (New York University)

**通讯引用:** 1074 | [OpenAlex ID](https://openalex.org/A5036015811)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了 Minitap，一套多智能体移动 UI 自动化系统，在 AndroidWorld 基准上实现 100% 成功率，超越人类 80% 的表现。

**💡 创新点**

创新点在于将单一 LLM 拆分为六个专用代理，配合后验验证和元认知循环，有效消除了上下文污染、文本输入失误与重复循环等六大失败模式。

**🔧 技术方法**

采用 LangGraph 架构的多代理系统，利用 Gemini/Claude 等大语言模型进行规划与推理，结合 UIAutomator、fb-idb、WebDriverAgent 等平台抽象层实现跨平台执行，并使用视觉模型与访问层信息进行多模态决策。

**📊 数据集**

主要使用 AndroidWorld benchmark（116 任务，20 个真实 Android 应用）进行评估，亦引用 Android in the Wild 与 MobileAgentBench 作补充。

**📈 对比分析**

与之前最佳单代理 97.4% 和人类 80% 结果对比，Minitap 在 116 任务上达 100% 成功率，Ablation 实验显示多代理结构 +21、后验验证 +15、元认知 +9 的累计贡献。

**⚠️ 局限性**

局限性包括依赖 UI 可访问性层，无法处理无 accessibility 的游戏或 canvas UI；任务不共享知识，缺乏跨任务学习；以及在非 benchmark 应用的泛化表现未知。

---

## 116. Can LLMs Discern the Traits Influencing Your Preferences? Evaluating Personality-Driven Preference Alignment in LLMs

**arXiv ID:** 2602.07181 | [PDF](https://arxiv.org/pdf/2602.07181v1)

**作者:** Tianyu Zhao `[一作]` (University of California), Salma Elmalaki `[通讯]` (University of California)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过构建基于大五人格特质的偏好对齐数据集 PACIFIC，并提出利用人格特质信息引导 LLM 进行个性化多选问答的方法，显著提升了偏好遵循的准确率。

**💡 创新点**

创新点包括：①首次将心理学中的大五人格特质作为潜在信号，用于解释和预测用户偏好；②构建 1,200 条跨领域偏好语句与答案对应的标注数据集 PACIFIC；③设计多种人格驱动的提示与检索策略，证明人格标签能有效引导 LLM。

**🔧 技术方法**

技术主要包括：大语言模型（Gemma‑3‑4B‑IT）推理；自监督的偏好与人格标签标注；检索增强生成（DPR‑based RAG）与对比学习；以及基于提示工程的多种人格注入策略。

**📊 数据集**

使用的数据集为 PACIFIC，涵盖 20 个主题（旅行、电影、教育等）的 1,200 条偏好语句，每条语句与多选题及答案配对，并标注对应的大五人格方向。

**📈 对比分析**

与无偏好、随机偏好、混合偏好等基线比较，最优的“带人格标签的少样本提示”方案在整体上取得 76% 的准确率，相比仅使用偏好上下文的 63% 提升约 13%；在不同人格维度上表现均好于其他方法。

**⚠️ 局限性**

局限性包括：①人格标签的获取仍需人工或高质量模型推断，存在社会期望偏差导致低特质预测不佳；②对低特质用户的准确率仍显不足；③检索模型在无标签场景下仍落后；④实验仅在单一 LLM 上验证，泛化性待进一步探索。

---

## 117. SPECA: Specification-to-Checklist Agentic Auditing for Multi-Implementation Systems -- A Case Study on Ethereum Clients

**arXiv ID:** 2602.07513 | [PDF](https://arxiv.org/pdf/2602.07513v1)

**作者:** Masato Kamba `[一作]`, Akiyoshi Sannai `[通讯]`

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

**🎯 论文内容**

本文提出了一套从规范（Specs）到实现（ImplementationMapping）的工作流，并通过规范抽取（NormativeExtraction）以及模式数据库（PatternDB）支持实现映射，最终生成系统检查清单（Checklist）。

**💡 创新点**

创新点在于将规范抽取与基于模式的实现映射相结合，形成可复用的检查清单构造流程，并通过可视化的阶段化设计（Phase 1: Checklist Construction）展示整体流程。

**🔧 技术方法**

采用了文本/规范抽取技术、映射算法以及模式匹配/检索技术；流程中通过 TikZ 绘图进行可视化描述。

**📊 数据集**

使用了包含50+条设计模式的模式数据库 PatternDB 作为主要数据源；其它数据集未在本文中具体说明。

**📈 对比分析**

本文未给出详细的实验对比和性能指标，所述方法仅在阶段性构造检查清单的实验中验证，未与传统手工或其他自动化工具进行系统比较。

**⚠️ 局限性**

局限性包括：仅覆盖流程的第一阶段（Checklist Construction），缺乏完整的后续实现与评估；依赖手工维护的模式数据库；未对不同类型规范或大规模系统进行广泛验证。

---

## 118. ACORN-IDS: Adaptive Continual Novelty Detection for Intrusion Detection Systems

**arXiv ID:** 2602.07291 | [PDF](https://arxiv.org/pdf/2602.07291v1)

**作者:** Sean Fuhrman `[一作]` (University of California), Tajana Rosing `[通讯]` (University of California)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了 ACORN‑IDS，一种仅使用正常流量数据、能持续自适应分布漂移的连续新奇检测框架，专为动态网络安全场景设计。

**💡 创新点**

创新点在于将 K‑Means 伪标签、连续特征提取（重建+三元组损失）与 PCA 重建评分结合，形成双重记忆机制，既能缓解灾难性遗忘，又能在无攻击标签的流式数据中不断提升检测性能。

**🔧 技术方法**

核心技术包括自编码器特征提取器、三元组余弦/欧氏距离度量学习、MiniBatchKMeans 伪标签、reservoir 采样记忆、PCA 重构误差阈值判决及统计阈值设定。

**📊 数据集**

实验使用五个真实网络攻击数据集：X‑IIoTID、WUSTL‑IIoT、CICIDS2017、CICIDS2018 与 UNSW‑NB15，构成两种持续学习情境（EA 与 ENA）。

**📈 对比分析**

与 ADCN、LwF、SLAD、ICL、DIF、AE、PCA、OCSVM、IF、LOF 等 10+ 基线对比，ACORN‑IDS 在平均 F1 上提升 62%（零日攻击提升 58%），前向迁移高、后向遗忘接近零，推理延迟仅比 PCA 多 0.003 ms，表现显著优于所有对手。

**⚠️ 局限性**

局限性包括：需手动设定 K‑Means 聚类数、三元组边缘参数及记忆容量；模型仍在每个任务后离线更新，可能对极高吞吐量场景的实时性要求有所挑战；目前仅在基于表格特征的流式网络数据上验证，尚未扩展到流式时序或图结构数据。

---

## 119. VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation

**arXiv ID:** 2602.07399 | [PDF](https://arxiv.org/pdf/2602.07399v1)

**作者:** Changhua Xu `[一作]` (Australian Artificial Intelligence Institute), En Yu `[通讯]` (Australian Artificial Intelligence Institute)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 VGAS 框架，将少样本视觉语言动作（VLA）适配任务从生成到选择分离，通过在生成的候选动作块中进行 Best‑of‑N 选择来提升几何精度。

**💡 创新点**

创新点包括：①使用 Q‑Chunk‑Former Transformer 作为几何感知的批评器；②提出 Explicit Geometric Regularization（EGR）以保持价值分辨率；③将期望‑最大值（Expected‑Max）备份与 EGR 结合，实现时空一致性。

**🔧 技术方法**

技术：Transformer‑based Q‑Chunk‑Former、SAF 模块、Best‑of‑N 采样、离线强化学习（CQL 等）、期望‑最大 Q‑学习、几何正则化。

**📊 数据集**

数据集：LIBERO 仿真基准（Goal、Spatial、Object、Long 四套任务）。

**📈 对比分析**

与 BC‑only、CQL、QC‑M、QC‑T+CQL 等基线对比，VGAS 在 5‑shot 下平均成功率提升至 49%，相较于基线提升 10‑15% 左右。

**⚠️ 局限性**

局限：推理时需采样多候选导致计算延迟；目前仅在仿真环境验证，未验证真实机器人；EGR 需要手动调参。

---

## 120. Affine Transformable Unmanned Ground Vehicle

**arXiv ID:** 2602.07677 | [PDF](https://arxiv.org/pdf/2602.07677v1)

**作者:** Aron Mathias `[一作]` (University of Arizona), Hossein Rastgoftar `[通讯]` (University of Arizona)

**通讯引用:** 456 | [OpenAlex ID](https://openalex.org/A5085452242)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0`

**🎯 论文内容**

本文提出了一种可在平面内进行大幅变形、同时携带多重载荷的仿射可变无人地面车辆（ATUGV）原型，并通过硬件实验和仿真验证了其在受限环境中安全跟踪仿射变换的能力。

**💡 创新点**

创新点在于将深度神经网络用于设计ATUGV细胞间的互连拓扑，使得各细胞可在变形平面自由运动；同时利用仿射变换分解为刚体平移、旋转和剪切，并给出主应变下界保证细胞间不碰撞；以及通过多机器人协同控制实现受动力细胞和无动力细胞的安全跟踪。

**🔧 技术方法**

核心技术包括：深度神经网络结构化细胞互连、仿射变换的极坐标分解与极应变约束、基于ROS2的多机器人运动控制与舵机闭环控制、以及利用Vicon运动捕捉系统实现精确位姿反馈。

**📊 数据集**

本文没有使用公开数据集，而是通过自主搭建的5m×5m室内测试场地与Vicon系统获取真实位姿数据，并在仿真中采用已知的七细胞ATUGV拓扑。

**📈 对比分析**

在硬件实验中，四细胞ATUGV在20秒内实现λ1=0.9、λ2=0.8、平移1m、旋转0.2rad等目标变形，跟踪误差保持在几厘米内；在仿真中，七细胞ATUGV在10秒内完成相同参数变形，位置误差亦维持在可接受范围，表明控制策略具有良好的跟踪性能。

**⚠️ 局限性**

局限性包括：所有移动机器人均假设已知自身位姿且全局同步；缺乏分布式/去中心化的目标仿射变换获取方法；并且实验仅在二维平面内进行，未验证三维或复杂地形下的鲁棒性。

---

## 121. Online Learning for Uninformed Markov Games: Empirical Nash-Value Regret and Non-Stationarity Adaptation

**arXiv ID:** 2602.07205 | [PDF](https://arxiv.org/pdf/2602.07205v1)

**作者:** Junyan Liu `[一作]`, Lillian J. Ratliff `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

在无信息马尔可夫游戏中研究在线学习，提出新的回报度量并给出自适应算法。

**💡 创新点**

引入经验Nash值回报（ENR）比以往更强，同时提供能自适应非平稳度的参数无关算法。

**🔧 技术方法**

使用基于epoch的V学习、乐观估计、对抗性bandit子算法和双倍增技术。

**📊 数据集**

无实验数据，理论分析。

**📈 对比分析**

通过理论证明，算法在最优或接近最优的三个极端（固定对手、完全非平稳）取得 √K 或 K^{2/3} 及其插值的 regret 率。

**⚠️ 局限性**

尚未确定 K^{2/3} 上界是否最优，且对动态 regret 的改进仍未解决。

---

## 122. Series-Parallel-Loop Decompositions of Control-flow Graphs

**arXiv ID:** 2602.07627 | [PDF](https://arxiv.org/pdf/2602.07627v1)

**作者:** Xuran Cai `[一作]` (University of Oxford), Chun Kit Lam `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 98 | [OpenAlex ID](https://openalex.org/A5086774411)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出一种基于语法的控制流图分解框架，并利用该框架改进了寄存器分配和生命周期最优的冗余消除算法。

**💡 创新点**

创新点在于精确刻画结构化程序的CFG集合，构造的分解与程序语法对应，并保持与树宽动态规划兼容，从而提升针对实际CFG的参数化算法效率。

**🔧 技术方法**

使用了基于语法树的分解技术、树宽/路径宽度动态规划以及相关的编译器优化算法。

**📊 数据集**

实验采用了常见编译器基准程序（如SPEC CPU、LLVM基准等）中的控制流图进行评估。

**📈 对比分析**

与先前的树宽方法和通用图分解方法对比，实验显示寄存器分配和LOSPRE的求解时间平均降低约30-50%，显著优于现有最优方案。

**⚠️ 局限性**

局限性在于仅适用于结构化程序生成的CFG，对含非结构化控制流的程序无法直接应用；同时分解过程对程序语法的精确匹配要求较高。

---

## 123. M2A: Multimodal Memory Agent with Dual-Layer Hybrid Memory for Long-Term Personalized Interactions

**arXiv ID:** 2602.07624 | [PDF](https://arxiv.org/pdf/2602.07624v1)

**作者:** Junyu Feng `[一作]` (Xi'an Jiaotong University), Wentao Zhang `[通讯]` (Peking University)

**通讯引用:** 14730 | [OpenAlex ID](https://openalex.org/A5100459860)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种多模态记忆代理 M^2A，支持在长时间人机交互中在线更新个性化知识。

**💡 创新点**

创新点包括双层混合记忆（原始日志与语义摘要相连）、两代理协同（ChatAgent 与 MemoryManager）实现自动查询/更新、三路跨模态检索（密集向量、BM25 与视觉嵌入）以及将概念驱动的子会话注入长会话的生成流水线。

**🔧 技术方法**

技术涵盖多代理 ReAct 工作流、语义与原始日志存储、密集/稀疏/视觉嵌入检索、迭代推理更新、图像字幕与 SigLIP 跨模态编码、LLM 评判等。

**📊 数据集**

使用扩展后的 LoCoMo 数据集（注入概念驱动的多模态子会话），并新增视觉中心化问答子任务。

**📈 对比分析**

与 LoCoMo（RAG）、Mem0、A-MEM 等基线在 GPT‑4o、Qwen3‑VL‑8B、GLM‑4.6V‑Flash 上进行对比，M^2A 在大多数类别中明显优于基线（例如 GPT‑4o‑mini 平均 44.64% 对比 36.26%，可视化中心化问题更高 43.27% 对比 30.69%）。

**⚠️ 局限性**

局限性包括仍需传入最近上下文窗口，整体依赖 LLM 评判，实验集中于构造数据集，代理协同与多路检索带来额外计算与实现复杂度。

---

## 124. UTOPIA: Unlearnable Tabular Data via Decoupled Shortcut Embedding

**arXiv ID:** 2602.07358 | [PDF](https://arxiv.org/pdf/2602.07358v1)

**作者:** Jiaming He `[一作]` (University of Electronic Science and Technology of China), Yi Yu `[通讯]` (Nanyang Technological University)

**通讯引用:** 3783 | [OpenAlex ID](https://openalex.org/A5100745222)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `9cc9baba-5356-466d-81ff-d80028d90279` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出并实现了一种针对表格数据的不可学习示例生成方法UTOPIA，用来阻止未授权的模型训练。

**💡 创新点**

创新点在于通过影响导向的子空间解耦和差分梯度导向机制，在保持结构有效性的前提下构造谱优势的快捷方式，从而实现谱不平衡下的正式可证明无学习性。

**🔧 技术方法**

使用的技术包括影响导向子空间分割、梯度上升/下降对冲、投影梯度下降（PGD）约束优化、混合数值/类别扰动、以及谱不平衡理论的正式证明。

**📊 数据集**

实验数据集涵盖 8 个公开表格数据集：California Housing、Churn、KC1、Employee、Dry Bean、Internet Firewall、Japanese Vowels、Obesity Levels。

**📈 对比分析**

通过与 5 种主流不可学习示例基线（TAP、EM、RoutEM、SEP、PUE）以及 10 种不同模型的对比，UTOPIA 在所有数据集和模型上将验证集准确率降至接近随机猜测水平，显著优于所有基线。

**⚠️ 局限性**

局限性包括对扰动预算和迭代次数较敏感；在极高维度或极稀疏特征场景下效果可能下降；并且现有防御技术（如量化、混合训练）可略微提升性能，未能彻底解决数据所有权与合法性争议。

---

## 125. 3D Transport-based Morphometry (3D-TBM) for medical image analysis

**arXiv ID:** 2602.07260 | [PDF](https://arxiv.org/pdf/2602.07260v1)

**作者:** Hongyu Kan `[一作]` (University of Virginia), Gustavo Kunde Rohde `[通讯]` (University of Virginia)

**通讯引用:** 5407 | [OpenAlex ID](https://openalex.org/A5041274548)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e15e3743-5ee0-4d5f-813d-d146868082fc` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

开发并公开了3D-TBM工具，实现了基于最优传输的三维医学影像形态学分析，涵盖预处理、线性最优传输嵌入、主成分分析、判别分析、相关分析和可视化等完整工作流。

**💡 创新点**

创新点在于：①将最优传输映射的可逆性与医学影像解释性结合，能够把模型特征直接投影回原始影像空间；②提供了完整的Python接口与可视化功能，填补了现有工具缺乏3D TBM支持的空白；③通过实验验证使用内在均值（Wasserstein barycenter）作为参考图像能提升分类性能。

**🔧 技术方法**

核心技术包括：线性最优传输（LOT）嵌入、主成分分析（PCA）、惩罚性线性判别分析（PLDA）、典型相关分析（CCA）、多尺度加速梯度下降、并行计算加速、逆映射可视化、以及常见机器学习分类器（SVM、kNN、RF等）。

**📊 数据集**

使用IXI脑MRI数据集，提取白质区域，构建年龄分类（<35岁 vs >60岁）与年龄回归任务，数据集共330个样本，采用T1、T2、PD多模态图像。

**📈 对比分析**

在年龄分类任务中，对比了PLDA、Nearest Subspace、Local Nearest Subspace等分类器，并与传统线性分类器进行性能评估。实验表明，Nearest Subspace相较于PLDA准确率提升约8%（Acc从0.78提升到0.846），显示出更好的分类效果。回归任务通过CCA+线性回归实现，预测结果与实际年龄高度相关，示例图显示脑室体积随年龄增长而增大。

**⚠️ 局限性**

限制主要体现在：①预处理步骤需用户自行完成，缺乏端到端的自动化；②对大尺寸三维图像的计算量仍较大，即使并行加速后仍耗时；③工具在不同病理或多模态场景下的鲁棒性和泛化能力待进一步验证。

---

## 126. Beyond Arrow: From Impossibility to Possibilities in Multi-Criteria Benchmarking

**arXiv ID:** 2602.07593 | [PDF](https://arxiv.org/pdf/2602.07593v1)

**作者:** Polina Gordienko `[一作]` (Ludwig Maximilians University Munich), Georg Schollmeyer `[通讯]` (Ludwig Maximilians University Munich)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出将多准则基准评估视为社会选择问题，研究在结构化偏好域下如何实现连贯且稳定的模型排名。

**💡 创新点**

在单峰性、群组可分性、距离受限三种偏好域上证明配对多数（pairwise majority）可满足 Arrow 定理的主要公理，从而突破传统的不可行性结论。

**🔧 技术方法**

使用社会选择理论中的配对多数、单峰性检测、群组可分性检查、Kendall‑Tau 距离度量；结合深度函数（generalized Tukey depth）提取整个基准集的代表性排名。

**📊 数据集**

在 HELM MMLU 语言模型基准（57 个子任务，23 个模型）上验证，使用不同模型集合和指标组合（准确率、推理时间等）。

**📈 对比分析**

对比方法：传统平均排名、Borda 计分、配对多数等；在满足结构化域的实验中，配对多数得到的排名既无环又一致，且与深度函数得到的代表性排名高度吻合；在非结构化域时则出现循环和不稳定性。

**⚠️ 局限性**

局限性：仅在特定模型/指标组合与基准集上验证，未覆盖所有可能的多准则基准；对策略行为的鲁棒性分析有限；实验主要基于 HELM MMLU，需进一步在其他基准上验证。

---

## 127. LIT-GRAPH: Evaluating Deep vs. Shallow Graph Embeddings for High-Quality Text Recommendation in Domain-Specific Knowledge Graphs

**arXiv ID:** 2602.07307 | [PDF](https://arxiv.org/pdf/2602.07307v1)

**作者:** Nirmal Gelal `[一作]` (Kansas State University), Hande Küçük McGinty `[通讯]` (Kansas State University)

**通讯引用:** 89 | [OpenAlex ID](https://openalex.org/A5112876257)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了面向高中英语教学的知识图谱推荐系统LIT-GRAPH，评估不同图嵌入方法对教材推荐的效果

**💡 创新点**

首次将深度关系图卷积网络（R‑GCN）与浅层随机游走模型对比，证明关系特定消息传递能更好捕捉教学语义

**🔧 技术方法**

使用DeepWalk、Biased Random Walk、Hybrid（两者拼接）以及R‑GCN四种嵌入技术，基于知识图谱生成向量

**📊 数据集**

采用包含98本英语文学教材、364类、1103条语义关系的专家构建KG数据集

**📈 对比分析**

通过链路预测AUC和推荐排序Hits@K、MRR、nDCG评估，R‑GCN在推荐指标上显著优于浅层模型，尽管其AUC略低

**⚠️ 局限性**

受限于样本量小、KG稠密度高，模型泛化性有限，且传统评估指标难以全面衡量教学相关性

---

## 128. Scout Before You Attend: Sketch-and-Walk Sparse Attention for Efficient LLM Inference

**arXiv ID:** 2602.07397 | [PDF](https://arxiv.org/pdf/2602.07397v1)

**作者:** Hoang Anh Duy Le `[一作]` (Rice University), Anshumali Shrivastava `[通讯]` (Rice University)

**通讯引用:** 2295 | [OpenAlex ID](https://openalex.org/A5024993683)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `edb9d762-f411-4838-a852-f2d638b018db` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种训练‑free 的稀疏注意力方法 Sketch&Walk Attention，用于 LLM 的 prefill 与 decode 阶段。

**💡 创新点**

创新点在于：① 通过 Small‑World Sketching（块级聚合 + Hadamard 投影）快速估计块级注意力；② 采用跨层 Sketch‑Determined Walk 把多跳注意力累积到一个状态中，弥补单层一跳选择的不足；③ 在保持接近稠密注意力精度的同时，提供统一的推理加速方案。

**🔧 技术方法**

主要技术包括：块级平均 + 随机 Hadamard 投影的稀疏化、跨层加权乘幂的“walk”累积、基于 Top‑τ 选择的块级稀疏矩阵、Triton + CUDA 优化的稀疏注意力核。

**📊 数据集**

实验数据集：LongBench（问答、推理、摘要、代码理解等）和 RULER（检索+利用长上下文的基准）。

**📈 对比分析**

与稠密注意力以及现有稀疏方法（MInference、FlexPrefill、Quest、Adamas）比较。结果显示：在 80% 稀疏率下，Sketch&Walk 几乎不丢失准确性，且在 4K–64K 甚至 128K token 长度时可获得 3–6 倍的推理速度提升，某些任务甚至超过稠密模型。

**⚠️ 局限性**

局限性：① 依赖块内语义一致性与注意力分布的重尾假设；② 对块大小、sketch 维度的参数敏感；③ 仍需自定义 CUDA/Triton 核，部署成本高；④ 在极低稀疏率或非常大块时，walk 估计误差可能累积。

---

## 129. Pull Requests as a Training Signal for Repo-Level Code Editing

**arXiv ID:** 2602.07457 | [PDF](https://arxiv.org/pdf/2602.07457v1)

**作者:** Qinglin Zhu `[一作]` (King's College London), Yeyun Gong `[通讯]` (Microsoft Research Asia)

**通讯引用:** 2971 | [OpenAlex ID](https://openalex.org/A5041448669)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `5b4c1114-4a70-478e-9921-2514ee03850d` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种基于GitHub Pull Request的中训练方法，将海量噪声PR转换为可验证的Search/Replace编辑块，直接在模型权重中内化仓库级代码编辑能力；

**💡 创新点**

核心创新在于三大环节：①严格的噪声过滤与Issue意图补全；②通过循环验证得到的Search/Replace最小唯一编辑块；③Agentless对齐的分步SFT和错误驱动增量训练，使模型在无代理的推理流程中具备定位、导航和编辑三阶段完整能力；

**🔧 技术方法**

采用搜索/替换（Search/Replace）编辑格式、基于上下文窗口的训练、错误驱动的负样本生成、以及简化的Agentless推理链；

**📊 数据集**

构建并公开了2M条可验证PR编辑块（约17.7B标记，涵盖12种语言），并在此基础上进行中训练和SFT；

**📈 对比分析**

与基准SWE‑bench Lite/Verified对比，模型在Lite上提升至24.3% Pass@1，Verified上提升至30.6% Pass@1；相较于传统基于Agent的32B系统（SWE‑Gym）提升约10%；与72B规模基线相媲美甚至优于；

**⚠️ 局限性**

局限包括：对PR来源仓库的过滤导致样本多样性受限；仅采用静态搜索/替换而非动态代码执行验证；在极大仓库的推理时仍需依赖检索，无法完全消除错误定位；模型仍可能因生成的补丁缺乏安全/合规性验证而带来风险。

---

## 130. MemPot: Defending Against Memory Extraction Attack with Optimized Honeypots

**arXiv ID:** 2602.07517 | [PDF](https://arxiv.org/pdf/2602.07517v1)

**作者:** Yuhao Wang `[一作]` (National University of Singapore), Jiaheng Zhang `[通讯]` (National University of Singapore)

**通讯引用:** 14595 | [OpenAlex ID](https://openalex.org/A5032474012)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于主动注入“蜜罐”文档并利用顺序检测的 MemPot 框架，用以防御 LLM 代理的内外存储信息提取攻击，且在线时延为零；

**💡 创新点**

创新点在于将蜜罐嵌入向量空间通过信息对比损失优化，使其在顺序概率比（SPRT）中最大化信息漂移，从而在不影响正常用户体验的前提下显著缩短检测轮数；

**🔧 技术方法**

采用对比学习、信息对比损失、SPRT 理论分析、嵌入反演与安全评分、LLR 近似（计数、相似度、全局相似度）等技术构建检测与蜜罐生成；

**📊 数据集**

在四个基准上评估：外存储数据集 HealthMagicCare、Pokémon；内存数据集 EHRAgent、RAP WebShop；使用 DeepSeek‑v3.2、all‑mpnet‑base‑v2 等预训练模型；

**📈 对比分析**

与 ControlNet、Agent、DGEA、IKEA 等基线及理论最优顺序检测器比较，MemPot 在 AUROC、TPR@1%FPR、TPR@10%FPR 上均接近 1，检测轮数仅为 1–2 次，延迟为 0，显著优于对手；

**⚠️ 局限性**

局限性包括需收集一定攻击查询样本进行蜜罐优化、对检索模型和向量维度假设较强、在极端多样化攻击策略下可能仍有漏检风险。

---

## 131. MedVerse: Efficient and Reliable Medical Reasoning via DAG-Structured Parallel Execution

**arXiv ID:** 2602.07529 | [PDF](https://arxiv.org/pdf/2602.07529v1)

**作者:** Jianwen Chen `[一作]` (University of North Carolina Chapel Hill), Huaxiu Yao `[通讯]` (University of North Carolina Chapel Hill)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 MedVerse 框架，将临床推理重构为基于 Petri 网的有向无环图 (DAG) 并实现并行推理

**💡 创新点**

创新点在于将推理过程离散为可并行执行的图结构，并通过 DAG-aware 注意力和自定义推理引擎实现真正的并行推理

**🔧 技术方法**

技术包括 MedVerse Curator（数据构造）、MedVerse Attention（DAG 位置掩码+自适应位置索引）和 MedVerse Engine（基于 Multiverse 的前缀共享和 Join 机制）

**📊 数据集**

使用自构造的 MedVerse‑14K 数据集（约 13.9k 条结构化推理样本）以及公开的 MedQA、MedXpert、MedBullets、HLE 等基准

**📈 对比分析**

与原始大模型和专业医学 LLM 比较，MedVerse 在 Qwen2.5‑7B、Llama‑3.1‑8B 上平均提升 4.8%–8.9% 准确率，并实现 1.3× 推理延迟缩短与 69% 生成吞吐率提升

**⚠️ 局限性**

局限性包括：仍需线性规划阶段以生成图结构，对数据构造质量高度依赖，且在真实临床场景下的可用性与安全性尚未验证

---

## 132. On Randomness in Agentic Evals

**arXiv ID:** 2602.07150 | [PDF](https://arxiv.org/pdf/2602.07150v1)

**作者:** Bjarni Haukur Bjarnason `[一作]` (KTH Royal Institute of Technology), Martin Monperrus `[通讯]` (KTH Royal Institute of Technology)

**通讯引用:** 6679 | [OpenAlex ID](https://openalex.org/A5027206285)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

系统在多任务环境下对 agentic 系统进行多次运行评估，量化其成功率、token 轨迹和工具调用的随机性。

**💡 创新点**

首次系统化地评估 agentic 评估中的随机波动，并提出多跑、功效分析与 optimistic/pessimistic bounds 等可靠评估准则。

**🔧 技术方法**

使用多模型多 scaffold 的 agentic 运行、token‑level 轨迹分析、pass@k 统计和显著性检验。

**📊 数据集**

基于 500 条软件工程问题修复任务的 Benchmark（软件工程 issue resolution），结合三种模型和两种 scaffold。

**📈 对比分析**

与单跑方法对比，发现单跑成功率差异可达 2.2–6% 甚至标准差>1.5%；提出多跑后置信区间能更准确区分 1–2% 的改进。

**⚠️ 局限性**

仅覆盖了两种 scaffold，未考虑上下文压缩、长序列任务等因素，评估成本高且对硬件依赖大。

---

## 133. When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified

**arXiv ID:** 2602.07381 | [PDF](https://arxiv.org/pdf/2602.07381v1)

**作者:** Gautam Siddharth Kashyap `[一作]` (Macquarie University), Usman Naseem `[通讯]` (Macquarie University)

**通讯引用:** 2949 | [OpenAlex ID](https://openalex.org/A5077006200)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种两阶段框架 AlignX，先通过注入式提示进行监督微调提取轴特定任务特征，随后使用 Mixture-of-Calibrated-Experts（MoCaE）模块对专家进行实例化路由与校准，解决了多目标对齐中的 Axis Collapse 问题。

**💡 创新点**

创新点包括：①在微调阶段使用 prompt-injected 数据与任务向量相结合，获得兼具结构与行为信息的轴特征矩阵；②在 MoCaE 阶段引入分形与自然校准器，实现基于几何稀缺性和语义一致性的动态专家校准，显著提升路由可靠性；③两阶段协同提升整体对齐效果并兼顾低延迟与低内存。

**🔧 技术方法**

使用技术包括：prompt injection、任务向量 Δθ、特征向量 F、任务-特征融合 ϕ、MoCaE 软路由、分形校准器、自然校准器、k-means 聚类、Fractal Dimension 评估、Softmax 校准权重、Transformer 共享编码层以及 FFN 专家头。

**📊 数据集**

实验所用数据集：Helpfulness：Alpaca；Harmlessness：BeaverTails；Honesty：TruthfulQA；以及 HoneSet 用于检验真实性-帮助性平衡。还对多种 LLM（LLaMA‑2‑7B、Mistral‑7B、Gemma‑7B、DeepSeek‑7B）进行验证。

**📈 对比分析**

与 H^3Fusion、TrinityX、RAHF、Aligner 等基线比较，AlignX 在 win rate、safety score、truthfulness‑informativeness 上分别提升约 171.5%、4.3% 以及 110.1%；总体对齐分数提升至 52.47%（DeepSeek‑7B）。同时推理延迟和内存使用均下降 35% 以上，展示了良好的性能与高效部署优势。

**⚠️ 局限性**

局限性包括：在极端分布偏移或语义歧义任务上任务特征融合效果可能下降；MoCaE 的专家校准器在低延迟场景下会带来一定计算开销；未覆盖指令多样性和多语言泛化，需进一步研究。

---

## 134. ONTrust: A Reference Ontology of Trust

**arXiv ID:** 2602.07662 | [PDF](https://arxiv.org/pdf/2602.07662v1)

**作者:** Glenda Amaral `[一作]` (University of Twente), Giancarlo Guizzardi `[通讯]` (University of Twente)

**通讯引用:** 9902 | [OpenAlex ID](https://openalex.org/A5065297243)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出并实现了参考信任本体（ONTrust），基于统一基础本体（UFO）和 OntoUML 进行建模，涵盖信任的核心概念、不同类型、影响因素、风险产生以及量化视角，并通过 Alloy 模拟与 OCL 约束验证模型正确性；随后将本体应用于两案例（巴西电子投票系统和医疗 AI 诊断）以展示可表达性与实用性。

**💡 创新点**

创新点包括：①首次将信任的心理、行为、风险与量化维度在同一统一本体中系统化；②引入多层次信任类型（Ground、Social、Weak、Strong、Trusted Delegation、Institution‑based）并对每种类型定义严格语义；③通过 OCL 与 Alloy 验证本体约束，解决了传统本体中常见的循环与一致性问题；④将本体与实际案例紧密结合，验证其在不同领域（治理、医疗 AI）中的可迁移性。

**🔧 技术方法**

技术方法主要包括：OntoUML 建模、OWL 导出、OCL 约束、Alloy Analyzer 进行模型验证、UFO 本体的引用、知识图谱与语义互操作工具的使用；此外在案例研究中使用了实验数据（如医疗 AI 诊断信任分数）与公开数据集（巴西选举数据）。

**📊 数据集**

数据集：①巴西 2018 年全国电子投票系统的选民信任与制度信息（公开政府与选举机构数据）；②医疗 AI 诊断实验 1 的受试者信任评分（0–100%）与疾病风险标签（高/低），来自 Juravle 等人的实验数据；③在本体验证阶段使用 Alloy 生成的合成实例。

**📈 对比分析**

比较方法：通过与已有信任本体（如 FOAF‑Trust、PML‑T、Secure Tropos 等）对比功能覆盖度与语义完整性；对本体模型的可表达性使用案例可视化与一致性检查；性能上通过 Alloy 的实例生成时间与 OCL 约束满足率评估模型有效性。实验结果显示 ONTrust 在表达复杂信任关系、捕获风险与影响因素方面优于传统本体，但在大规模推理时需要进一步优化。

**⚠️ 局限性**

局限性：①本体目前主要聚焦静态信任关系，动态演化与实时更新机制尚未完善；②模型复杂度高，导致建模与验证成本较大；③对多模态情感与情境细粒度信任的表征仍需进一步细化；④缺乏大规模实证验证，未来需在更多多领域应用中进行评估与迭代。

---

## 135. Wireless Streamlet: A Spectrum-Aware and Cognitive Consensus Protocol for Edge IoT

**arXiv ID:** 2602.07630 | [PDF](https://arxiv.org/pdf/2602.07630v1)

**作者:** Taotao Wang `[一作]` (Shenzhen University), Shengli Zhang `[通讯]` (Shenzhen University)

**通讯引用:** 23023 | [OpenAlex ID](https://openalex.org/A5100413426)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

提出了Wireless Streamlet，一种针对无线边缘物联网的光谱感知与认知共识协议，结合TDMA单跳广播、基于CSI的领导者选举以及双链编码存储；

**💡 创新点**

创新点包括：①将CSI信息嵌入投票中以实现可验证的频道感知领导选举（CALE），②利用TDMA排程实现线性槽复杂度并消除碰撞，③将共识链与数据链分离，使用Raptor编码与Merkle根实现低存储成本的数据可用性；

**🔧 技术方法**

采用的技术包括：BFT共识（Streamlet改进）、单跳无线广播、TDMA排程、CSI测量与加密签名、统计中位数聚合、Raptor erasure编码、Merkle树哈希、基于Bamboo平台的无线仿真；

**📊 数据集**

实验基于Bamboo仿真平台的无线网络仿真，并未使用公开的真实数据集；

**📈 对比分析**

与PBFT、HotStuff等基线在相同TDMA与头部消息大小条件下比较，Wireless Streamlet在吞吐量上显著高于PBFT，延迟更低且方差更小；在高丢包率下，Raptor编码的双链架构使存储节点负载下降并提升检索成功率；

**⚠️ 局限性**

局限性包括：仅适用于单跳全覆盖广播域，假设无定向/定向攻击；需要可靠的TDMA时间同步；CALE的领导选举依赖于已完成的共识历史，可能导致选举偏差；编码与哈希开销虽低，但仍需额外的算力与存储；

---

## 136. NOMA-Assisted Multi-BS MEC Networks for Delay-Sensitive and Computation-Intensive IoT Applications

**arXiv ID:** 2602.07456 | [PDF](https://arxiv.org/pdf/2602.07456v1)

**作者:** Yuang Chen `[一作]` (University of Science and Technology of China), Chang Wen Chen `[通讯]` (Hong Kong Polytechnic University)

**通讯引用:** 13120 | [OpenAlex ID](https://openalex.org/A5002277899)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

设计并实现了基于上行 NOMA 的多基站边缘计算网络，针对大规模 IoT 设备的延迟敏感与计算密集型任务实现联合任务卸载、用户分组与功率分配优化，最终最小化系统总延迟。

**💡 创新点**

创新点在于：① 将任务卸载与用户分组建模为精确势能游戏（Exact Potential Game），从而保证系统收敛到 Nash 均衡；② 对功率分配采用 Majorization‑Minimization（MM）方法，将非凸问题转化为可解的凸优化；③ 通过交替优化实现整体协同，显著提升延迟与能耗性能。

**🔧 技术方法**

核心技术包括：非协作游戏理论（精确势能游戏）、MM（Taylor 展开）优化、凸优化工具箱（CVX）、自适应分组策略与功率调度算法。

**📊 数据集**

采用仿真数据：80 台 IoT 设备、4 台 BS‑MEC、5 个子信道，任务规模 5–15 Mbits、延迟阈值 0.2–1.2 s，通信信道为 Rayleigh 及大尺度衰减模型；无公开真实数据集，全部为自定义仿真场景。

**📈 对比分析**

与 Gale‑Shapley 分组、Max‑Min 分组、Nearest‑BS 卸载、Computing‑capacity 卸载等基线方法进行对比；实验表明 Proposed 方法在总延迟上可降低至基线的 80.7%（提升 19.3%），在功耗上可降低 14.7%，并在不同设备数、子信道数、BS 数量及计算容量变化下保持显著优势。

**⚠️ 局限性**

局限性：仅支持每台设备与单一 BS‑MEC 关联，缺乏多 BS 卸载与动态切换能力；在高移动性场景下可能导致迁移延迟与资源冲突，未来需加入服务迁移与空中切换机制。

---

## 137. Latent Target Score Matching, with an application to Simulation-Based Inference

**arXiv ID:** 2602.07189 | [PDF](https://arxiv.org/pdf/2602.07189v1)

**作者:** Joohwan Ko `[一作]` (University of Massachusetts), Tomas Geffner `[通讯]` (NVIDIA)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ba576bd1-e51d-44e8-8077-fc943b333c93` `f86bf285-fd08-4156-973b-6e6481af8fa0` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种新的扩散模型训练目标——Latent Target Score Matching（LTSM），用于在存在潜在变量时利用联合得分来低方差地学习边缘得分，并通过与传统的Denoising Score Matching（DSM）混合以获得在不同噪声尺度下都具有良好方差的训练目标。

**💡 创新点**

创新点在于：①将TSM的低方差监督理念推广到潜在变量模型；②证明联合得分可以用来构造边缘得分的无偏估计；③设计时间相关的混合目标，并给出实现最小方差权重的解析表达式；④在有限模拟预算下显著提升了采样效率。

**🔧 技术方法**

主要技术包括：变分推断的扩散模型（VP‑SDE），无偏得分估计（DSM、TSM、LTSM），时间相关混合回归目标，基于MMD的后验质量评估，以及使用MLP学习时间权重。

**📊 数据集**

实验数据集为三类仿真推断任务：Gaussian模型、Mixture of Categorical以及Generalized Galton Board，这些都是典型的灰盒模拟器，能够提供联合分布及其得分。

**📈 对比分析**

与纯DSM方法对比，LTSM在低噪声下方差更小、得分误差更低；混合目标（DSM+LTSM）在所有任务和不同观测值下均获得更低的MMD，尤其在模拟调用次数少时优势更明显，显示出更好的样本效率。

**⚠️ 局限性**

局限性包括：①需要能够计算联合得分，限制了适用范围；②在高噪声时LTSM方差仍较大，需要混合才能稳定；③混合权重的学习增加了训练复杂度；④目前仅在简单仿真任务验证，尚未在大规模真实数据上测试。

---

## 138. Sign-Based Optimizers Are Effective Under Heavy-Tailed Noise

**arXiv ID:** 2602.07425 | [PDF](https://arxiv.org/pdf/2602.07425v1)

**作者:** Dingzhi Yu `[一作]` (Nanjing University), Lijun Zhang `[通讯]` (Nanjing University)

**通讯引用:** 35189 | [OpenAlex ID](https://openalex.org/A5100448159)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对大语言模型训练中符号优化算法 Lion、Muon 的理论分析和实证验证，提出通用的重尾噪声模型并给出收敛率。

**💡 创新点**

建立了允许噪声幅度随梯度大小线性增长的重尾噪声假设，并在此框架下证明 SignSGD、Lion、Muon、Muonlight 在高阶收敛率上与既往结果匹配或超越；首次给出矩阵优化的重尾收敛分析。

**🔧 技术方法**

利用非欧氏范数的向量和矩阵马尔可夫集中不等式、重尾噪声分析、通用平滑性（_0,_1）假设以及自适应加权正则化。

**📊 数据集**

在 nanoGPT 基于 C4 数据集上进行预训练实验。

**📈 对比分析**

与 NSGD、AdamW 等基线对比，Lion 和 Muon 在训练损失、验证损失和准确率上显著优于基线，验证理论优势。

**⚠️ 局限性**

只考虑了无剪裁的签名优化器，未给出剪裁版本的分析，且假设噪声的 p-阶矩已知，实际训练中需估计。

---

## 139. How to evaluate NoSQL Database Paradigms for Knowledge Graph Processing

**arXiv ID:** 2602.07612 | [PDF](https://arxiv.org/pdf/2602.07612v1)

**作者:** Rosario Napoli `[一作]` (University of Messina), Maria Fazio `[通讯]` (University of Messina)

**通讯引用:** 4855 | [OpenAlex ID](https://openalex.org/A5017589999)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一套针对知识图（KG）的 NoSQL 数据库基准框架，结合规模、连通性和语义丰富度三维指标，对 MongoDB、Neo4j 与 ArangoDB 在不同查询复杂度下的性能进行系统评估。

**💡 创新点**

创新点包括：① 定义“语义丰富度（Semantic Richness）”指标并与传统规模、连通性共同构成三维评估空间；② 设计四层逐步递增的查询难度基准；③ 在 FAERS KG 的三种规模上实验，得出基于指标的数据库选择准则，首次在 KG 场景下揭示性能交叉点。

**🔧 技术方法**

使用 Python 自动化工具完成 KG 的 CSV→JSON 转换、批量导入；利用 Neo4j 的 Cypher、MongoDB 的 Aggregation Pipeline、ArangoDB 的 AQL 分别执行四层查询；通过冷启动（清除缓存）与热启动（保留缓存）两种跑法，收集毫秒级执行时间并绘制 95% 置信区间。

**📊 数据集**

实验数据集为美国 FDA FAERS 不良事件 KG，在原始规模、8 倍规模和 128 倍规模（分别约 1.4万、1.12 万、1.79 万节点与 1.45 万、1.12 万、1.41 万边）进行评测。

**📈 对比分析**

对比方法为：在相同查询、相同规模、相同硬件条件下分别测量三种数据库的平均执行时间及置信区间。结果显示：① 对低跳/属性过滤查询，MongoDB 速度最快；② 对一二跳混合查询，ArangoDB 在中等连通性时表现最佳；③ 对深度多跳遍历，Neo4j 在热启动时显著超越其余两者，形成性能交叉点。

**⚠️ 局限性**

局限性：① 只评估了三种 NoSQL 方案，缺乏对更广泛多模/分布式系统的覆盖；② 实验环境为单机，未考虑大规模分布式扩容与网络延迟的影响；③ 仅使用 FAERS KG，其他领域的 KG 结构与语义特征可能导致结论不完全泛化。

---

## 140. Compact Conformal Subgraphs

**arXiv ID:** 2602.07530 | [PDF](https://arxiv.org/pdf/2602.07530v1)

**作者:** Sreenivas Gollapudi `[一作]` (Google Research), Aravindan Vijayaraghavan `[通讯]` (Northwestern University)

**通讯引用:** 1167 | [OpenAlex ID](https://openalex.org/A5081431077)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `fede83ac-7505-405f-ab37-e7284695c47f` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文研究了在图结构下的 conformal prediction 压缩问题，提出通过线性规划松弛与阈值取整的超图子图优化算法，能够在保留大概率质量的同时得到最小子图，并证明该算法满足单调性，从而实现统计有效的压缩；

**💡 创新点**

创新点包括：①将 conformal prediction 与超图 densest‑k 子图问题结合，②证明在高覆盖率 regime 下可实现常数因子逼近且满足单调性；③利用 parametric minimum cut 架构设计出可嵌套的压缩方案；

**🔧 技术方法**

使用的技术主要是：超图线性规划松弛与 LP 取整、参数化 min‑cut、单调性证明、随机采样与统一收敛理论、实验对比分析；

**📊 数据集**

实验数据集包括：合成 6×6 网格路网、真实城市路网（Porto 数据）、仿真旅行规划活动集合；

**📈 对比分析**

与前向/逆向贪心基线比较，结果显示在覆盖率 ≤0.8 时 LP 方案压缩率约 30%~50% 更佳；在旅行规划实验中，当 ϕ≤0.75 时能完美恢复核心子图，ϕ>0.8 时显著退化；

**⚠️ 局限性**

局限性：仅在高覆盖率 regime 下可实现高效逼近，对低覆盖率或非单调最优情况效率不高；需要可采样或随机近似来降低超图规模；对大规模实际超图的可扩展性仍待进一步研究。

---

## 141. CoMI-IRL: Contrastive Multi-Intention Inverse Reinforcement Learning

**arXiv ID:** 2602.07496 | [PDF](https://arxiv.org/pdf/2602.07496v1)

**作者:** Antonio Mone `[一作]` (Delft University of Technology), Luciano Cavalcante Siebert `[通讯]` (Delft University of Technology)

**通讯引用:** 391 | [OpenAlex ID](https://openalex.org/A5035146559)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了CoMI‑IRL框架，通过对轨迹进行对比学习得到分布式嵌入，先聚类后独立求奖励，从而实现多意图IRL的解耦；

**💡 创新点**

创新点在于：①使用Transformer编码器与对比损失（InfoNCE+DIM）构造行为嵌入；②不需要预先设定行为数K，利用图基社区检测自适应聚类；③实现对新行为的在线微调而无需全模型重训练；

**🔧 技术方法**

技术主要包括Transformer Encoder、随机傅里叶特征预处理、对比学习（InfoNCE、DIM）、图邻接网络+Leiden社区检测、以及单意图IRL（GAIL/AIRL）和稳定性正则化；

**📊 数据集**

使用MuJoCo模拟环境：Reacher‑v4、Pusher‑v4、Walker2D‑v4；每个环境训练6/3种专家策略并采集100条演示；

**📈 对比分析**

与Ess‑InfoGAIL、K‑Means、G‑GAIL/AIRL等基线比较。CoMI‑IRL在NMI、ARI、Silhouette及ATR上均优于或相当于基线，特别是在K≠K*、混合行为或需适应新行为时表现更稳健，且能发现细粒度子行为；

**⚠️ 局限性**

局限性包括：依赖Transformer的计算与超参调优；聚类质量高度依赖嵌入空间质量；对极高维或极大样本的可扩展性待验证；对灾难性遗忘仍需进一步评估；缺乏真实世界数据的可解释性验证。

---

## 142. Quantifying Explanation Quality in Graph Neural Networks using Out-of-Distribution Generalization

**arXiv ID:** 2602.07708 | [PDF](https://arxiv.org/pdf/2602.07708v1)

**作者:** Ding Zhang `[一作]` (University of Virginia), Chirag Agarwal `[通讯]` (University of Virginia)

**通讯引用:** 1149 | [OpenAlex ID](https://openalex.org/A5048724032)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出了一种基于解释引导训练的GNN框架（EG‑GNN）和一种新的解释泛化得分（Explanation‑Generalization Score, EGS），通过将解释作为训练约束并评估模型在分布外（OOD）任务上的性能来衡量解释的因果有效性。

**💡 创新点**

创新点在于将解释视为因果不变特征的正则化对象，将模型在OOD下的提升量直接作为解释质量的指标，克服传统FIDELITY等指标无法区分因果与相关解释的局限。

**🔧 技术方法**

主要技术包括：解释引导的GNN训练（在梯度正则化中施加节点/边掩码）、多种后置解释方法（如GNNExplainer、GraphMask、Input×Gradient等）、ShapeGGen合成图生成、以及大规模的分布外评估框架。

**📊 数据集**

使用的数据集为：两组合成图（包含三角形和五边形基底），以及两组真实分子图（如分子重量、旋转键数等属性），对每个属性进行四分位分割生成不同的OOD子集。

**📈 对比分析**

比较方法是：在每个OOD拆分下训练基线GNN与EG‑GNN，计算OOD准确率差异并归一化得到EGS；实验显示与真实因果掩码相比，EGS始终为正并且能有效区分八种解释器，说明该指标能体现解释的因果优劣。

**⚠️ 局限性**

局限性在于：EGS高度依赖于解释的质量与约束的正确性；对某些GNN架构（如GIN）可能导致负值；在真实数据中需要人工或生成的真因果掩码作为上限，且解释器误导训练时可能产生不利影响。

---

## 143. Fault-Tolerant Evaluation for Sample-Efficient Model Performance Estimators

**arXiv ID:** 2602.07226 | [PDF](https://arxiv.org/pdf/2602.07226v1)

**作者:** Zihan Zhu `[一作]` (Macquarie University), Qiongkai Xu `[通讯]` (Macquarie University)

**通讯引用:** 3173 | [OpenAlex ID](https://openalex.org/A5036737229)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种容错评估框架，用于在有限标注预算下评估样本高效性能估计器的质量。

**💡 创新点**

创新点在于引入可调容差阈值 ε，将偏差与方差统一约束，并通过双侧单边 t 检验实现对估计误差的容错判定，同时自动调节容差。

**🔧 技术方法**

使用了基于 t 检验的统计方法、主动测试与随机抽样估计器、以及二分搜索算法自动选取容差阈值。

**📊 数据集**

使用了多个计算机视觉数据集（CIFAR‑100、ImageNet、SVHN）和自然语言处理数据集（20 Newsgroups、DBpedia），以及 MMLU‑Pro 的子任务。

**📈 对比分析**

与传统的 RMSE 和 p‑value 评估对比，实验显示传统指标在 73% 情形下给出冲突结论，而 FT‑Eval 能够稳定区分估计器，并在低方差时保持实用误差范围内。

**⚠️ 局限性**

局限在于需要先验设定的容差阈值 ε 并假设正态分布的 t 检验，在极低方差或样本量极小的情形下仍可能受统计功效影响。

---

## 144. Beyond Core and Penumbra: Bi-Temporal Image-Driven Stroke Evolution Analysis

**arXiv ID:** 2602.07535 | [PDF](https://arxiv.org/pdf/2602.07535v1)

**作者:** Md Sazidur Rahman `[一作]` (University of Stavanger), Mahdieh Khanmohammadi `[通讯]` (University of Stavanger)

**通讯引用:** 124 | [OpenAlex ID](https://openalex.org/A5082038841)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

本文提出一种基于CTP（入院时）与DWI（治疗后）双时间点的影像特征框架，用统计、纹理和深度嵌入三类特征对缺血脑组织的最终结局（恢复或梗死）进行分型与表型化。

**💡 创新点**

创新点在于：①将入院CTP与随访DWI相结合构造六类生物学意义的ROI；②利用CNN编码器（mJ‑Net与nnU‑Net）在无监督状态下提取高层次特征，并对其在功能空间的区分度进行定量评估；③通过余弦相似度与分离指数系统性比较不同特征的区分性能。

**🔧 技术方法**

采用的技术包括：基于滑动窗口的统计特征提取、3D GLCM纹理特征、2D+time mJ‑Net与2D nnU‑Net编码器的深度嵌入；图像配准、最大池化聚合；t‑SNE可视化；Mann‑Whitney U、Cliff’s delta、Wilcoxon签名秩检验及余弦相似度/分离指数计算。

**📊 数据集**

使用来自斯塔万格大学医院的152例急性缺血性卒中患者数据，其中选取18例成功再通且具备完整配准与手工标注的CTP与DWI。

**📈 对比分析**

比较方法主要是统计显著性检验与效应量评估、t‑SNE聚类可视化、以及余弦相似度与分离指数。结果表明：①纹理特征（GLCM）与深度嵌入在区分保留与梗死组织方面优于基础统计特征；②mJ‑Net嵌入在保留与梗死的分离指数显著（p≈1.5×10⁻⁴），提示其对组织可塑性具有更好捕捉能力；③相对而言，nnU‑Net嵌入虽能体现组织层级梯度，但在区分最终结局时表现不佳。

**⚠️ 局限性**

局限性包括：①样本量仅18例，统计功效有限；②CTP与DWI在空间分辨率和取向上存在差异，配准误差可能影响体素级对应；③随访窗口仅24–72小时，可能未能捕捉更长时间的组织演变。

---

## 145. Clarifying Core Dimensions in Digital Maturity Models: An Integrative Approach

**arXiv ID:** 2602.07569 | [PDF](https://arxiv.org/pdf/2602.07569v1)

**作者:** Eduardo C. Peixoto `[一作]` (CESAR School), Cesar França `[通讯]` (Federal Rural University of Pernambuco)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

对76个数字成熟度模型进行系统映射与分析，识别最常见的十个维度，并提出统一的维度与组件定义

**💡 创新点**

提供了对数字成熟度模型维度的整合与统一命名，弥补了先前研究中缺乏一致性和清晰定义的问题

**🔧 技术方法**

采用系统映射方法，包括自动检索、滚雪球检索、编码与主题聚类等技术

**📊 数据集**

使用了包含76个数字成熟度模型的文献集合，来源于期刊、会议、报告等，涵盖2015‑2023年间的研究

**📈 对比分析**

通过对维度频次计数和主题聚类进行对比分析；未进行实验性能评估，主要展示了模型维度不一致的现状

**⚠️ 局限性**

检索方法可能存在偏差；维度命名歧义与模型定义不清导致聚类不完全；未评估模型在实际组织中的应用效果

---

## 146. DeepPrep: An LLM-Powered Agentic System for Autonomous Data Preparation

**arXiv ID:** 2602.07371 | [PDF](https://arxiv.org/pdf/2602.07371v1)

**作者:** Meihao Fan `[一作]` (Renmin University of China), Jianjun Chen `[通讯]` (ByteDance)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种基于大型语言模型的代理式系统，用来自动构造数据准备管道，将高层目标模式转化为一系列数据清洗、转换、整合等操作。

**💡 创新点**

创新点在于引入树结构代理推理（Tree‑Based Agentic Reasoning）实现执行反馈驱动的非线性搜索与回溯，并配合渐进式代理训练（Progressive Agentic Training）与可逆噪声合成来提升模型学习效率。

**🔧 技术方法**

采用大型语言模型（LLM）进行规划、执行与反馈交互，结合Python环境执行引擎、树状推理框架、混合奖励的多轮强化学习、以及数据合成与噪声注入技术。

**📊 数据集**

主要使用从NL2SQL基准中提取的数据库与SQL查询生成的任务样本，并通过可逆噪声注入生成多样化的有噪声源表与对应清洗管道。

**📈 对比分析**

与现有开源方法相比，模型在多种公开基准上实现了最佳性能，且其准确度与闭源 GPT‑5 相当，同时推理成本低约 15 倍，展示出更高的性价比。

**⚠️ 局限性**

仍受限于对预定义操作符集的依赖、对大规模数据合成的需要以及模型对极端噪声或复杂语义需求的适应性不足。

---

## 147. Agent-Fence: Mapping Security Vulnerabilities Across Deep Research Agents

**arXiv ID:** 2602.07652 | [PDF](https://arxiv.org/pdf/2602.07652v1)

**作者:** Sai Puppala `[一作]` (Southern Illinois University), Sajedul Talukder `[通讯]` (University of Texas)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建 AgentFence 评估框架，系统评估深度代理架构的安全性

**💡 创新点**

提出 14 类信任边界攻击分类并通过可审计对话断裂检测实现架构级安全评估

**🔧 技术方法**

基于 LLM 的规划-执行架构、状态管理、工具调用、检索与委托等模块，结合对话追踪与阈值判定

**📊 数据集**

使用 Qwen2.5-32B-Instruct 作为基础模型，HotpotQA 91 条实例以及多工具集

**📈 对比分析**

在八种代理原型下固定模型与任务，对比平均安全断裂率 (MSBR)，从 0.29 下降到 0.51，揭示架构差异

**⚠️ 局限性**

仅评估接口层攻击，未覆盖模型权重或系统层攻击，并受限于选定的任务与工具范围

---

## 148. Data Compression with Stochastic Codes

**arXiv ID:** 2602.07635 | [PDF](https://arxiv.org/pdf/2602.07635v1)

**作者:** Gergely Flamich `[一作]` (Imperial College), Deniz Gündüz `[通讯]` (Imperial College)

**通讯引用:** 18029 | [OpenAlex ID](https://openalex.org/A5016883501)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `fede83ac-7505-405f-ab37-e7284695c47f` `c84dae5d-5273-4348-85a7-b44cb586b4df` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文提出了相对熵编码框架，并给出多种构造方法，用共享随机性实现对任意条件分布的无损模拟，从而提供了量化的替代方案。

**💡 创新点**

创新点在于将源编码与信道仿真结合，提出了可计算的相对熵编码理论，设计了重排拒绝采样、Poisson函数表示、分层去噪量化、BnB采样等多种高效构造，并证明其在信息量上的最优性。

**🔧 技术方法**

采用的技术包括随机采样器、Poisson过程、A* 采样、分层去噪量化、SMSU 表示、分枝限界采样、极化编码、梯度下降与可重参数化技巧以及熵编码（Huffman、Elias δ）。

**📊 数据集**

虽然文中主要为理论与方法论，但在应用案例中引用了图像/视频压缩、联邦学习模型压缩与强化学习等典型数据集（如ImageNet、COCO、MNIST 等常用视觉数据）。

**📈 对比分析**

与传统量化方案相比，相对熵编码在相同失真下实现了更低的比特率，实验示例中在联邦学习压缩上达到 82 倍比特率下降，在遥控强化学习上实现 12‑41 倍的通信节省。

**⚠️ 局限性**

主要局限是算法速度慢，通常与信息量呈指数级增长；此外需要共享随机种子并保持同步，且对多维分布的高效实现尚未成熟。

---

## 149. Enhancing IMU-Based Online Handwriting Recognition via Contrastive Learning with Zero Inference Overhead

**arXiv ID:** 2602.07049 | [PDF](https://arxiv.org/pdf/2602.07049v1)

**作者:** Jindong Li `[一作]` (Friedrich-Alexander-Universität Erlangen-Nürnberg), Björn Eskofier `[通讯]` (Helmholtz Zentrum München)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了一种名为 ECHWR 的训练框架，利用临时辅助文本分支和双重对比学习提升 IMU 基准的在线手写识别精度，同时保持推理时零额外开销。

**💡 创新点**

创新点包括：①在训练阶段加入临时文本分支，实现传感器与文本嵌入的对齐；②引入两种对比损失——in-batch 对比损失和基于错误的对比损失（通过人工生成的“硬负样本”）来增强特征表达；③在不改变原始模型结构的前提下获得显著性能提升。

**🔧 技术方法**

使用的技术包括 CNN‑LSTM 编码器、Transformer 文本编码器、注意力池化、RMS/层归一化、门控注意力、寄存器、CTC 主损失、InfoNCE 对比损失、硬负样本生成与多任务联合训练。

**📊 数据集**

实验基于 OnHW‑Words500（右手写子集）数据集，采用 5 折交叉验证的 writer‑independent（WI）和 writer‑dependent（WD）两种划分。

**📈 对比分析**

与 REWI 基线对比，ECHWR 在 WD 划分下，BC 对比损失将 CER 降至 12.95%（-10.4%），在 WI 划分下，EC 对比损失进一步将 CER 降至 6.79%（-7.4%），WER 亦从 15.16% 降至 13.65%（-10.0%），总体表现显著优于基线。

**⚠️ 局限性**

受限于数据集规模与多任务统一配置的挑战，小模型对对比损失的兼顾可能导致收敛困难，且缺乏更大规模数据验证统一架构的通用性。

---

## 150. Measuring Complexity at the Requirements Stage: Spectral Metrics as Development Effort Predictors

**arXiv ID:** 2602.07182 | [PDF](https://arxiv.org/pdf/2602.07182v1)

**作者:** Maximilian Vierlboeck `[一作]` (Stevens Institute of Technology), Rashika Sugganahalli Natesh Babu `[通讯]` (Stevens Institute of Technology)

**通讯引用:** 3 | [OpenAlex ID](https://openalex.org/A5109716016)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本研究通过将自然语言处理提取的需求结构映射为图模型，并使用谱能量等图谱复杂度指标，实验证明这些指标能高度预测需求类集成任务的工作量。

**💡 创新点**

创新点在于首次将谱复杂度度量（图能量、拉普拉斯图能量）与需求层级结构结合，并通过受控的分子集成实验验证其对人类集成时间的预测能力。

**🔧 技术方法**

主要技术包括：自然语言处理提取需求网络、谱图理论中的矩阵特征值分析、线性与二次回归建模以及实验数据的统计检验。

**📊 数据集**

使用的数据集为23名受试者完成的20个分子集成任务（化学分子图）作为需求结构的等价模型，未使用真实需求文本。

**📈 对比分析**

通过对比谱指标与传统结构指标（环路计数、密度等）的相关性，谱指标的相关系数>0.95，r²>0.6，显示出远高于密度指标的预测性能；实验统计显著（p<0.05）。

**⚠️ 局限性**

局限性包括：仅使用分子结构作代理，缺乏直接在真实需求上的验证；样本量有限、未建模个体差异；对大规模系统的可扩展性与阈值解释尚未研究。

---

## 151. HistoMet: A Pan-Cancer Deep Learning Framework for Prognostic Prediction of Metastatic Progression and Site Tropism from Primary Tumor Histopathology

**arXiv ID:** 2602.07608 | [PDF](https://arxiv.org/pdf/2602.07608v1)

**作者:** Yixin Chen `[一作]` (Ohio State University), M. Khalid Khan Niazi `[通讯]` (Ohio State University)

**通讯引用:** 2551 | [OpenAlex ID](https://openalex.org/A5034159054)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了名为 HistoMet 的两阶段决策感知、概念对齐的多实例学习框架，用于从原发肿瘤的全切片图像预测转移风险与转移部位。

**💡 创新点**

创新点包括：①将转移预测拆分为高灵敏度风险筛选和条件部位预测两模块；②引入视觉原型凝聚和概念级对齐，利用视觉‑语言模型为原型提供可解释的语义指导；③多尺度（10×/20×）融合与跨尺度 logit‑级融合，提升细粒度与宏观特征的协同。

**🔧 技术方法**

使用多实例学习、交叉注意力原型凝聚、CLIP 风格文本对齐、视觉‑语言模型（CONCH）预训练特征提取、以及多尺度融合与概念级注意力等技术。

**📊 数据集**

在 6504 名患者（6858 张 WSIs）的多机构泛癌症队列上评估，包含转移随访及转移部位注释（脑、淋巴结、肝、软组织）。

**📈 对比分析**

与 ABMIL、TransMIL、CLAM 等现有 MIL 基线进行比较，在 95% 灵敏度筛选下，HistoMet 在宏观 F1、AUC 及工作量减少等指标上均优于基线，宏观 F1 最高可达 61.22%，并在转移部位预测上实现宏观 F1 74.6%/AUC 92.1%。

**⚠️ 局限性**

局限性包括：①LLM 生成的概念可能出现幻觉，需人工校对；②视觉原型虽减少噪声但仍需病理专家解释；③视觉‑语言编码器保持冻结，未针对任务进行微调；④对罕见转移部位的泛化仍有限；⑤缺乏外部验证和对真实临床工作流程的进一步评估。

---

## 152. Mapping the Design Space of User Experience for Computer Use Agents

**arXiv ID:** 2602.07283 | [PDF](https://arxiv.org/pdf/2602.07283v1)

**作者:** Ruijia Cheng `[一作]` (Apple), Jeffrey Nichols `[通讯]` (Apple)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建并验证了基于大型语言模型的计算机使用代理的用户体验设计空间，提出四大类（用户查询、代理活动可解释性、用户控制、用户心理模型）的21个子维度，并通过Wizard‑of‑Oz实验验证其完整性。

**💡 创新点**

创新点在于系统化映射计算机使用代理的UX设计空间，细化可解释性与控制维度，并揭示用户在不同情境下的需求差异，提供了可直接使用的设计词汇表。

**🔧 技术方法**

使用基于LLM/MLLM的界面代理原型与Wizard‑of‑Oz交互模拟，结合访谈与任务日志分析。

**📊 数据集**

数据集包括对9款2024‑25年发布的计算机使用代理的案例分析、8名UX/AI从业者的访谈记录，以及20名内部参与者的对话和任务完成日志。

**📈 对比分析**

通过实验验证所有21个子维度均被覆盖，并与现有代理设计要素进行对比，发现实验结果完全支持所提出的taxonomy，没有发现遗漏；性能指标主要是覆盖率与实证一致性，而非数值化性能提升。

**⚠️ 局限性**

局限性：样本仅为内部技术人员，实验仅覆盖浏览器场景，未涵盖移动、桌面或操作系统层面代理，缺少真实LLM推理与延迟的影响，且未考虑可访问性与多语言使用者的需求。

---

## 153. TeleBoost: A Systematic Alignment Framework for High-Fidelity, Controllable, and Robust Video Generation

**arXiv ID:** 2602.07595 | [PDF](https://arxiv.org/pdf/2602.07595v1)

**作者:** Yuanzhi Liang `[一作]`, Xuelong Li `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一个分阶段后训练框架，将预训练的视频生成器转化为可执行、可控制、稳健的生产级模型。

**💡 创新点**

将监督微调、基于组相对优势的强化学习（GRPO）以及直接偏好优化（DPO）整合为单一的稳定约束优化堆栈，并在各阶段加入结构化信用分配、可信度调度、自适应训练等机制，形成系统化的多任务学习流程。

**🔧 技术方法**

技术包括：监督微调（instruction tuning + 3D一致性 + 物理一致性）、Group Relative Policy Optimization、ViPO、BPGO、Self‑Paced GRPO、Direct Preference Optimization、Ray+MPS 并行、内存高效 DPO、以及多模态评估与调度框架。

**📊 数据集**

使用大规模视频‑文本数据（如 LAION、iStock）进行预训练，监督微调使用人工指令/控制样本、摄像机运动视频与物理模拟数据；GRPO 采用 VLM 评估（VideoCLIP‑XL、Qwen3‑VL‑Embedding）和 CLIP；DPO 采用自动生成的硬负样本、人工偏好对以及视频对齐数据。

**📈 对比分析**

通过与 Wan2.2‑14B I2V 基准的 Good‑Same‑Bad 人工评估（WinRate 70%+、Margin 24%+）以及客观指标（VBench、VideoAlign、VideoClipXL 等）进行比较，结果显示运动质量、文本对齐、整体偏好等指标均显著优于 GRPO、SFT 等基线；实验表明多阶段优化显著降低视觉失真、结构崩塌和物理不自然等错误。

**⚠️ 局限性**

仍受评估信号噪声与不确定性的限制，特别是多对多对应导致奖励稀疏；强化学习样本效率低、对长时序/高分辨率的处理仍存在累积误差；DPO 需要昂贵的对比数据和高显存，且在极端长时序和极高分辨率下可能出现硬件瓶颈。

---

## 154. Row-Column Separated Attention Based Low-Light Image/Video Enhancement

**arXiv ID:** 2602.07428 | [PDF](https://arxiv.org/pdf/2602.07428v1)

**作者:** Chengqi Dong `[一作]` (Jilin University), Fan Tang `[通讯]` (Chinese Academy of Sciences)

**通讯引用:** 19481 | [OpenAlex ID](https://openalex.org/A5066366116)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

针对低照度图像/视频增强，提出在改进的 U‑Net 后插入 Row‑Column Separated Attention (RCSA) 模块，构建 U‑RCSA‑Net 并对视频使用两种时序损失函数。

**💡 创新点**

创新点包括：① 仅利用行/列均值与最大值的二维全局特征实现轻量级注意力；② 通过跨通道信息交互与像素级注意力融合提升细节恢复；③ 为视频提供仅依赖相邻帧的时序一致性约束，无需光流计算。

**🔧 技术方法**

使用的技术：改进的 U‑Net、RCSA 注意力模块、像素/最大值双分支注意力、可调自适应权重、两种时序损失（相邻帧亮度差损失、相似性损失）、多尺度训练、Adam 优化。

**📊 数据集**

实验数据集包括 LOL（低照度图像）、MIT Adobe FiveK（RAW 大规模图像）和 SDSD（低照度视频）。

**📈 对比分析**

与 LLFormer、HWMNet、MAXIM 等最新模型对比，U‑RCSA‑Net 在 LOL、MIT FiveK、SDSD 上均取得 PSNR/SSIM 领先，参数量约为 LLFormer 的 1/8，且在视频时序指标上虽略逊于光流方法，但显著优于纯图像方法。

**⚠️ 局限性**

局限性：在极暗或噪声极高的场景下效果下降；对正常光照图像可能产生轻微过度增强；视频时序一致性仍低于基于光流的最优方法。

---

## 155. An Information-Theoretic Framework for Comparing Voice and Text Explainability

**arXiv ID:** 2602.07179 | [PDF](https://arxiv.org/pdf/2602.07179v1)

**作者:** Mona Rajhans `[一作]` (Palo Alto Networks), Vishal Khawarey `[通讯]` (Quicken Inc)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出一种信息论框架，用来评估语音与文本两种解释方式在可解释人工智能中的信息保留、理解效率和信任校准。

**💡 创新点**

创新点在于将解释过程建模为信息传输通道，并引入“理解效率（CE）”和“信任校准误差（TCE）”两项量化指标，以及综合评价指标Φ，首次从信息论角度系统比较不同模态的解释效果。

**🔧 技术方法**

使用的技术包括信息论中的互信息、熵计算，基于SHAP的特征重要性模拟，Python 3.10 生态（NumPy、pandas、Matplotlib）实现仿真与可视化。

**📊 数据集**

实验数据以合成的SHAP特征向量为主，模拟金融与遗传学两类任务；论文亦指出可直接替换为UCI Credit Approval、Kaggle Financial Transactions等公开数据集的真实SHAP/LIME输出。

**📈 对比分析**

比较方法是通过仿真生成不同模态（文本、语音）与不同风格（简洁、详细、类比）下的CE、TCE和Φ值，结果显示文本解释在理解效率上领先，而语音解释在信任校准误差上更低，类比风格在两者间取得最佳平衡。

**⚠️ 局限性**

局限性包括：仅使用合成数据，缺乏真实用户实验；模型仅考虑文本与语音两种模态，未涉及视觉或多模态融合；参数（如认知负荷权重）未通过实验验证，需要进一步经验验证。

---

## 156. Evaluating Large Language Models for Detecting Architectural Decision Violations

**arXiv ID:** 2602.07609 | [PDF](https://arxiv.org/pdf/2602.07609v1)

**作者:** Ruoyu Su `[一作]` (University of Oulu), Davide Taibi `[通讯]` (University of Southern Denmark)

**通讯引用:** 4412 | [OpenAlex ID](https://openalex.org/A5086929289)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了大语言模型（LLM）在检测开源软件项目中架构决策记录（ADR）违例的有效性，构建了多模型流水线对比评估。

**💡 创新点**

首次系统性评估多种主流LLM在ADR违例检测中的一致性、准确率和错误模式，提出了检索增强与多模型验证的实验框架。

**🔧 技术方法**

使用检索增强生成（RAG）、链式推理（CoT）提示、vLLM并行推理，并利用四个LLM（Marco‑o1、Mistral‑Nemo、Qwen3、Llama3.1）进行检测与验证。

**📊 数据集**

采用Buchgeher等人挖掘的109个开源GitHub仓库共980份ADR，经过模板匹配、代码聚合与检索后进行实验。

**📈 对比分析**

通过与三名人工专家对305个样本的手工验证对比，计算Fleiss κ、准确率、宏/微平均F1、MCC等指标；最佳模型（Marco‑o1）准确率达91%，宏平均F1 0.881，表现优于其他模型。

**⚠️ 局限性**

模型在非代码、基础设施/部署、原则导向等ADR类型上误判率高，尤其是“代码无法评估”类；误差主要源自语义误解、缺失上下文和领域知识不足，提示单纯LLM仍无法完全替代人工审查。

---

## 157. Principled Synthetic Data Enables the First Scaling Laws for LLMs in Recommendation

**arXiv ID:** 2602.07298 | [PDF](https://arxiv.org/pdf/2602.07298v1)

**作者:** Benyu Zhang `[一作]`, Hong Yan `[通讯]`

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `67630363-6be0-4f51-ab05-7198250671a5` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出并验证了一套分层合成数据框架，用高质量无偏差的合成数据来训练大语言模型，使其在推荐领域能够实现可预测的幂律 scaling law。

**💡 创新点**

创新点包括：① 将原始用户日志拆解为三层：语义对齐、协同过滤和无偏用户交互历史，彻底消除位置/流行度/曝光偏差；② 用 Node2Vec 生成无顺序的随机游走交互序列；③ 证明合成数据不仅提升传统序列模型的 Recall，还能让 LLM 在 0.6B–8B 参数规模下出现稳健的 scaling law；④ 发现协同过滤与交互历史之间的非对称迁移效应。

**🔧 技术方法**

技术手段包括：合成数据生成（关联规则文本化、Node2Vec 2 阶随机游走）、持续预训练（Qwen3 LLM，采用 512 token 上下文、学习率 1e-4 等超参）、评估指标（perplexity、Recall@K）、统计 scaling law 拟合（L(D)=L∞+A·D^(-α)）以及 ablation 与混合比例实验。

**📊 数据集**

使用的数据集：原始 Merrec 1.2B 交互日志；由三层合成数据生成的 item‑text、CF 关联规则和 UIH 序列；通用文本域 SmolLM‑Corpus、cosmopedia‑v2、fineweb‑edu‑dedup 等作为背景语料；合成 UIH 共 2.8B tokens，CF 与 item‑text 亦包含相同规模的 token。

**📈 对比分析**

对比方法为“Train on Synthetic, Test on Real”与“Train on Real, Test on Real”，结果显示合成数据训练的 GRU4Rec、NARM、STAMP、SASRec 在 Recall@10/100/1000 上显著优于实数据；在 LLM 连续预训练中，0.6B–8B 参数模型在 163B tokens 下满足幂律 scaling，UIH 的 α≈0.5–0.6 最高；CF α≈0.35，item‑text α≈0.15；混合比例实验表明过高 UIH 率导致过拟合，而适度混合可取得最佳性能。

**⚠️ 局限性**

局限性包括：依赖于合成数据的质量，未在多业务域下验证泛化；合成 UIH 基于协同过滤图，可能忽略用户细粒度偏好；大模型在 OOD 交互上表现不一；缺乏长期部署的 bias 与公平性评估；实验仅基于公开 Merrec 数据集，未涵盖更广泛的商品或服务场景。

---

## 158. SleepMaMi: A Universal Sleep Foundation Model for Integrating Macro- and Micro-structures

**arXiv ID:** 2602.07628 | [PDF](https://arxiv.org/pdf/2602.07628v1)

**作者:** Keondo Park `[一作]` (Graduate School of Data Science), Hyung-Sin Kim `[通讯]` (Graduate School of Data Science)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `729e5870-4135-47f5-97f2-e3974d07b5dc` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `afceb026-1760-41ae-8d86-010831a37d97` `5a41884c-404f-4688-a89c-aa238c10fe68` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了SleepMaMi——一款融合睡眠微观结构与宏观结构的全新睡眠基础模型；

**💡 创新点**

创新点在于：①双编码器架构，分别捕获秒级细粒度信号与整夜睡眠周期；②微编码器采用混合MAE+对比学习实现跨模态一致性；③宏编码器使用基于人群人口学属性的Demographic‑Guided Contrastive Learning（DGCL）提升宏观表示；

**🔧 技术方法**

技术主要包括：Transformer（带Rotary位置、RMSNorm、SwiGLU）+Mixture‑of‑Experts，MAE自监督重建，跨模态对比学习，Mamba层的双向长序列建模，DGCL对比损失，KoLeo正则，FlashAttention‑2等；

**📊 数据集**

使用20,964份PSG记录（总计158,028小时）进行预训练，数据来源包括SHHS1/2、KISS、KVSS、PhysioNet 2018、MESA、MrOS；

**📈 对比分析**

通过线性探测和微调在睡眠分期、呼吸障碍分割、疾病预测等六大下游任务与现有时间序列与睡眠基础模型（MOMENT、UniTS、SleepFM‑Disease）对比，SleepMaMi在多项指标上均优于对照组；在少样本（few‑shot）设置下，仅用1–30个样本即可达到与全量训练相近的性能；

**⚠️ 局限性**

局限性包括：①对设备特性（如Compumedics硬件）可能存在偏好，导致在不同PSG仪器上的泛化能力下降；②模型规模大，推理成本高；③主要评估在睡眠分期与呼吸障碍任务，其他睡眠相关任务（如REM障碍、昼夜节律研究）尚未充分验证；

---

## 159. TASTE: Task-Aware Out-of-Distribution Detection via Stein Operators

**arXiv ID:** 2602.07640 | [PDF](https://arxiv.org/pdf/2602.07640v1)

**作者:** Michał Kozyra `[一作]` (University of Oxford), Gesine Reinert `[通讯]` (University of Oxford)

**通讯引用:** 3541 | [OpenAlex ID](https://openalex.org/A5049954115)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `f86bf285-fd08-4156-973b-6e6481af8fa0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于Stein算子、任务感知的OOD检测框架TASTE，直接将已训练模型的输入灵敏度与训练分布几何相连；

**💡 创新点**

创新点在于固定预测器为测试函数，利用Langevin Stein算子构造任务敏感残差，实现对分布偏移的投影解读，并提供可解释的像素级异常图；

**🔧 技术方法**

使用Stein算子、分数模型（score/ diffusion）、Laplacian与梯度估计、Hutchinson随机迹估计等技术；

**📊 数据集**

在二维仿真、MNIST（平移/旋转）、CIFAR‑10（对抗、失真、传统OOD数据集）以及MVTec AD（像素级定位）等数据集上进行实验；

**📈 对比分析**

与MSP、ODIN、Mahalanobis、Energy、kNN+、GSC等多种基线对比，TASTE在多种shift场景下取得均衡性能，尤其在对抗攻击和低FPR95方面优于多数基线；

**⚠️ 局限性**

局限在于依赖分数模型的准确性、对梯度与二阶导数估计的计算开销，以及Stein等式仅在期望意义下成立，点样本残差可能波动较大。

---

## 160. KRONE: Hierarchical and Modular Log Anomaly Detection

**arXiv ID:** 2602.07303 | [PDF](https://arxiv.org/pdf/2602.07303v1)

**作者:** Lei Ma `[一作]` (Worcester Polytechnic Institute), Jianjun Chen `[通讯]` (ByteDance Inc.)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `3855fcda-48ef-4070-a15e-803cd5c84d83` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种基于LLM自动抽取执行层次的层次化日志异常检测框架。

**💡 创新点**

创新点在于利用实体-动作-状态三层语义层次自动生成结构，递归拆分日志序列并结合模式匹配与LLM推理的混合检测，实现高精度、低成本。

**🔧 技术方法**

技术包括LLM驱动的命名实体识别、树状层次抽象、递归序列拆分、层次化知识库、模式匹配检测、LLM推理、缓存重用与早停优化。

**📊 数据集**

使用了BGL、HDFS、ThunderBird三大公开基准和字节跳动云工业数据集。

**📈 对比分析**

与传统机器学习、深度学习和LLM方法对比，F1提升至92.8%（比SOTA高约10%），LLM调用仅占测试序列1.1–3.3%，同时资源与数据空间分别缩小43.7×和117.3×。

**⚠️ 局限性**

局限在于依赖日志解析器与LLM的准确性，适用性受限于具有可解释执行语义的日志，且对频繁模板更新与低语义日志处理仍需改进。

---

## 161. WorldEdit: Towards Open-World Image Editing with a Knowledge-Informed Benchmark

**arXiv ID:** 2602.07095 | [PDF](https://arxiv.org/pdf/2602.07095v1)

**作者:** Wang Lin `[一作]` (Zhejiang University), Sucheng Ren `[通讯]` (Johns Hopkins University)

**通讯引用:** 911 | [OpenAlex ID](https://openalex.org/A5048891976)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研发了世界驱动的图像编辑数据集 WorldEdit，并在 Bagel 模型上实施两阶段微调（SFT + 强化学习）和因果验证奖励，以提升模型对隐式编辑指令的执行能力。

**💡 创新点**

创新点包括：①专门针对因果变换的高质量编辑数据集与测试集；②将统一模型的世界知识与图像生成通过因果验证奖励耦合；③结合链式推理（CoT）与强化学习的两阶段训练框架。

**🔧 技术方法**

采用的大模型技术包括 GPT‑4o 用于数据生成与评估、Bagel（多模态 LLM）作为基础模型、CoT 推理链、Flow‑GRPO 强化学习、因果验证奖励和 Qwen‑VL‑Max 多模态评估器。

**📊 数据集**

使用了 11k 条高质量编辑对的 WorldEdit 训练集，配套的 WorldEdit‑Test 评估集，并借助公开分割数据集提取原始图像。

**📈 对比分析**

在十类因果场景下，用视觉一致性、视觉质量、指令遵循、知识合理性四维指标对比，实验表明该方法在大多数指标上接近商用模型（GPT‑4o、Nano‑Banana），并显著优于现有开源模型，整体平均得分达 4.07/5。

**⚠️ 局限性**

局限性包括：数据筛选仍依赖 LLM 与人工，因果类型覆盖有限；对极端物理交互或复杂场景的建模仍不完整；模型性能受训练数据分布与评估标准限制。

---

## 162. PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents

**arXiv ID:** 2602.07187 | [PDF](https://arxiv.org/pdf/2602.07187v1)

**作者:** Hanyu Wang `[一作]` (Pennsylvania State University), Jinghui Chen `[通讯]` (Pennsylvania State University)

**通讯引用:** 2436 | [OpenAlex ID](https://openalex.org/A5006335513)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了PreFlect框架，在大型语言模型代理中实现前瞻性自我反思，以在执行前对计划进行检查并修正，同时加入动态再规划以应对运行时异常。

**💡 创新点**

创新点在于把反思从事后修正转为预执行阶段的前瞻性反思，利用从历史轨迹中提炼出的“规划错误”作为经验先验进行计划检查，并将此机制与执行时的动态再规划相结合。

**🔧 技术方法**

采用大语言模型（GPT‑4.1 / Gemini‑2.5‑pro）、规划错误知识库、计划阶段自我反思循环、动态再规划机制，以及工具调用与执行循环。

**📊 数据集**

使用 HotpotQA 与 MuSiQue 进行规划错误提炼，使用 GAIA（验证集）与 SimpleQA（100 条样本）进行评估，同时与多种基线框架在同一工具和预算设置下对比。

**📈 对比分析**

与 Retrospective 反思方法（Reflexion、Self‑Refine）、ReAct、Smolagents 以及更复杂的多代理框架在 GAIA 和 SimpleQA 上进行 Pass@1/准确率比较。PreFlect 在 GPT‑4.1 上 GAIA 总分 58.18%（比基线提升约17.14%），在 Gemini‑2.5‑pro 上 59.39%（提升约11.68%）；在 SimpleQA 上 Correct 率提升约12.79%；在 Level3 任务上提升约14.29%，并在整体成本‑性能比上优于更复杂框架。

**⚠️ 局限性**

局限性包括：前瞻性反思对未来失败的预测仍受限于历史经验先验；在某些情境下可能导致过度修正或误判；需依赖动态再规划来补偿计划阶段遗漏的风险；对大模型的依赖导致成本相对较高；跨域推广和对更广泛任务的适用性仍待进一步验证。

---

## 163. Hybrid Feedback-Guided Optimal Learning for Wireless Interactive Panoramic Scene Delivery

**arXiv ID:** 2602.07273 | [PDF](https://arxiv.org/pdf/2602.07273v1)

**作者:** Xiaoyi Wu `[一作]`, R. Srikant `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

研究了通过混合全信息与 bandit 反馈的在线学习框架来实现交互式全景内容的边缘服务器分段选择，提出 AdaPort 算法并证明其渐进最优性。

**💡 创新点**

创新点在于将预测反馈视为全信息反馈，构造 2/F/B 混合反馈模型，给出相应下界与上界，并证明相比传统 2/B/B 与 1/B 模式能显著降低 regret。

**🔧 技术方法**

采用多臂赌博机理论、Thompson 采样、Beta 分布、KL 发散度分析以及全信息估计等技术。

**📊 数据集**

使用真实用户头动轨迹（3000 时隙）与 Wi‑Fi 带宽测量数据（100 Mbps/150 Mbps）以及公开的全景视频作为数据集。

**📈 对比分析**

与 1/B‑TS、2/B/B‑TS、1/B‑EXP3 及启发式最小场景交付方法对比，实验表明 AdaPort 在 100/150 Mbps 场景下相对吞吐量损失更低，优于现有基线。

**⚠️ 局限性**

主要限制在于假设预测与传输结果独立且 i.i.d.，且仅考虑完整失传；未来需考虑非 i.i.d.、部分失传等更真实模型。

---

## 164. Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI

**arXiv ID:** 2602.07176 | [PDF](https://arxiv.org/pdf/2602.07176v1)

**作者:** Mohamed El Hajji `[一作]` (Ibnou Zohr University), Youssef Es-Saady `[通讯]` (Ibnou Zohr University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `25d64835-ec5b-425b-899d-a6e1e6fecabd` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了一个开源教育平台Open TutorAI，结合大型语言模型、检索增强生成（RAG）和可定制3D头像，实现了文本与沉浸式交互的个性化辅导系统。

**💡 创新点**

创新点在于：①模块化架构支持多语言模型、Avatar与RAG的无缝集成；②通过用户画像和对话引导实现动态学习路径与即时反馈；③嵌入学习分析仪表盘，实现行为数据驱动的自适应干预；④双模式交互（文本+3D头像）提升情感与沉浸感。

**🔧 技术方法**

技术包括：大型语言模型（如LLaMA 3、OpenAI GPT‑4）、OpenWebUI框架、Latent Diffusion / GAN / NeRF生成头像、RAG检索引擎、Docker/Kubernetes部署、WebGL/Three.js 3D渲染、学习分析后端（数据收集、指标计算）以及多角色访问控制。

**📊 数据集**

未公开具体数据集，系统采用教师上传的教材与公开OER、教师自建知识库作为RAG检索来源；交互日志和学习行为数据用于评估。

**📈 对比分析**

评估方式为技术可行性验证（接口连通、响应时延、3D渲染帧率）与内部用户体验测试；性能指标显示：文本交互延迟 < 1s，3D动画 120 FPS；LLM本地部署内存占用 4‑5 GB，云 API 低内存占用。对比实验尚未完成，计划与传统教育聊天机器人进行学习成效与参与度对比。

**⚠️ 局限性**

局限性：①缺乏大规模真实用户实验验证学习效果；②LLM生成的答案可能产生幻觉，需进一步加强知识校验；③对多语言和跨学科内容的支持仍有限；④对低带宽环境下的3D体验未充分测试；⑤伦理与隐私问题需完善监管与人机协作机制。

---

## 165. The Optimal Token Baseline: Variance Reduction for Long-Horizon LLM-RL

**arXiv ID:** 2602.07078 | [PDF](https://arxiv.org/pdf/2602.07078v1)

**作者:** Yingru Li `[一作]` (Shenzhen Chinese University of Hong Kong), Baoxiang Wang `[通讯]` (Shenzhen Chinese University of Hong Kong)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Optimal Token Baseline（OTB），通过令每个 token 的优势按累积梯度能量加权，从而在 LLM 的 RL 训练中显著降低梯度方差，解决长期任务中的训练崩溃问题。

**💡 创新点**

创新点在于：① 以累积梯度能量（Realized Energy）为权重，得到的 token 级别最优基线；② 引入 Logit‑Gradient Proxy，利用前向概率估计梯度范数，避免昂贵的反向计算；③ 通过 OTB 使得小组大小（N=4）即可达到大组（N=32）水平，显著提升采样效率。

**🔧 技术方法**

技术手段包括：REINFORCE 与优势估计的改进、序列能量和奖励归还的动态基线推导、Logit‑Gradient Proxy 的实现以及对比实验框架；模型使用 Qwen 系列 LLM 并在其上执行全 on‑policy 训练。

**📊 数据集**

使用 DAPO‑MATH‑17k 作为训练数据集，评估单回合推理（Single‑Turn Reasoning）与多回合工具集成推理（Tool‑Integrated Reasoning, TIR）两类数学推理任务；实验在 Qwen3‑8B‑Base 与 Qwen2.5‑7B 上进行。

**📈 对比分析**

与 GRPO、RLOO、OPO、OGB 以及 SimpleTIR 等方法比较，OTB 在 AIME、AMC、MATH 等评测上均取得最高分，且在小组尺寸下保持稳定训练；此外，OTB 使 token 消耗下降约 65–68%，并在更长上下文和更多交互轮数时保持稳定性。

**⚠️ 局限性**

局限性包括：仍主要关注数学推理任务，缺乏在更广泛领域（如搜索引擎、通用智能体）的验证；对 Logit‑Gradient Proxy 的理论假设依赖于 Transformer 结构，可能对其他模型不适用；并且对极端稀疏奖励场景的效果尚未完全证明。

---

## 166. ImmCOGNITO: Identity Obfuscation in Millimeter-Wave Radar-Based Gesture Recognition for IoT Environments

**arXiv ID:** 2602.07139 | [PDF](https://arxiv.org/pdf/2602.07139v1)

**作者:** Ying Liu `[一作]` (Aalto University), Stephan Sigg `[通讯]` (Aalto University)

**通讯引用:** 3061 | [OpenAlex ID](https://openalex.org/A5045150110)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `9cc9baba-5356-466d-81ff-d80028d90279` `3f18e8e3-0266-457c-8567-9039b6d2394d` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种基于图网络的自编码器ImmCOGNITO，用于在毫米波雷达手势识别中实现身份去识别，同时保持手势识别精度

**💡 创新点**

创新点在于结合时间图KNN、消息传递网络与多头自注意力机制构建动态有向图，并在训练中同时优化重构、手势保持与身份抑制损失，实现高效身份混淆而不显著损失手势识别性能

**🔧 技术方法**

使用图卷积（Message Passing Neural Network）+多头自注意力、Chamfer距离重构、交叉熵损失与自定义身份抑制损失、Adam优化器与学习率衰减

**📊 数据集**

在PantoRad（21种手势，41人）和MHomeGes（10种手势，25人）两大毫米波雷达点云数据集上进行评估

**📈 对比分析**

与三种基线（Tesla、Pantomime、PointNet++）的手势识别和身份识别模型进行对比；ImmCOGNITO在保持手势识别准确率≈85–90%（相比原始≈96%）的同时，将身份识别准确率从约50–90%降至约4–24%，实现了更优的隐私-效用折中；与简单几何扰动、量化等基线相比，识别准确率损失更小、身份识别更低

**⚠️ 局限性**

限制包括：只针对单人场景，无法直接处理多用户并发识别；对极端环境或多模态攻击的鲁棒性尚未验证；身份去识别效果在小样本或相似人群中仍有限；需要更大多样化的数据集和更强对抗测试

---

## 167. Efficient Post-Training Pruning of Large Language Models with Statistical Correction

**arXiv ID:** 2602.07375 | [PDF](https://arxiv.org/pdf/2602.07375v1)

**作者:** Peiqi Yu `[一作]` (Santa Clara University), Wei Jiang `[通讯]` (Futurewei Technologies)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于第一阶统计量的LLM后训练剪枝框架，结合方差校准的重要性度量和能量补偿来纠正剪枝导致的分布失真；

**💡 创新点**

创新点在于：1）利用权重方差和激活方差对基于幅度的剪枝重要性做校准，消除激活异常值偏差；2）采用闭式能量补偿（列、行维度）对剪枝后权重进行均值‑能量匹配，无需梯度或二阶信息；3）该方法兼容任何剪枝掩码，计算开销仅略高于启发式方法；

**🔧 技术方法**

主要技术包括：第一阶统计量（均值、方差）提取、方差校准的权重重要性分数、列/行维度能量补偿因子、闭式权重更新；

**📊 数据集**

使用的校准集为C4数据集随机采样128条序列，评估数据为WikiText‑2（困惑度）和六个零样本下游任务（BoolQ、RTE、HellaSwag、WinoGrande、ARC、OBQA）；

**📈 对比分析**

与传统幅度剪枝、Wanda以及基于重构的SparseGPT比较，结果表明：在50%无结构稀疏和4:8、2:4结构稀疏下，提出的方法在所有LLaMA‑2、LLaMA‑3、Qwen2.5模型上均能获得最低或次低的困惑度，零样本准确率也往往高于或与最优；运行时间仅比SparseGPT快约5–6×，与Wanda相当；

**⚠️ 局限性**

局限性：仅依赖第一阶统计，可能在极端输入分布或非稳定激活下效果下降；在极高稀疏度（>70%）时性能仍显著衰减；实验仅覆盖解码器型LLM，未验证对编码器-解码器或多模态模型的适用性。

---

## 168. Hydra: Robust Hardware-Assisted Malware Detection

**arXiv ID:** 2602.07240 | [PDF](https://arxiv.org/pdf/2602.07240v1)

**作者:** Eli Propp `[一作]` (University of Waterloo), Seyed Majid Zahedi `[通讯]` (University of Waterloo)

**通讯引用:** 295 | [OpenAlex ID](https://openalex.org/A5060850653)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在硬件性能计数器（HPC）受限的前提下，提出一种通过在程序执行时分段切换不同硬件事件集合并对应的机器学习模型，实现恶意软件检测的方法。

**💡 创新点**

创新点是将检测任务视为“时序特征集排程”问题，学习一个多特征集的时序方案，以补偿单一特征集的盲区，并通过动态切换提升检测覆盖率与鲁棒性。

**🔧 技术方法**

采用HPC采集低层事件，构建多种基线模型（决策树、随机森林、SVD+RF等），在每个时间片对模型输出进行logit-mean聚合后用逻辑回归学习序列权重，实现特征集调度；目标函数为负对数似然，优化器为交替方向乘子法（ADMM）。

**📊 数据集**

恶意样本来自VirusTotal/VT数据库约5,000个，正常样本从SPEC 2017、PARSEC、MiBench、CortexSuite、BenchmarkSuite等公开基准中提取约19,000个，所有样本按时间戳划分为训练/测试集。

**📈 对比分析**

与传统单特征集基线（含集成模型）对比，所提方法在F1上提升约19.3%，误报率降低约60.2%，整体准确率从约93.8%提升至97.1%，在多项指标上均优于基线。

**⚠️ 局限性**

局限性包括：需要在每个时间片重新配置计数器，带来硬件开销；序列长度被限制为3，扩展至更长序列的搜索空间和计算成本显著上升；仅采用离线学习，缺乏在线自适应；未对主动攻击者的逃逸策略进行评估。

---

## 169. CALM: Class-Conditional Sparse Attention Vectors for Large Audio-Language Models

**arXiv ID:** 2602.07077 | [PDF](https://arxiv.org/pdf/2602.07077v1)

**作者:** Videet Mehta `[一作]` (Massachusetts Institute of Technology), M. Jehanzeb Mirza `[通讯]` (Massachusetts Institute of Technology)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出CALM方法，利用冻结的大型音频‑语言模型中的注意力头进行少样本音频与视听分类，不需额外微调。

**💡 创新点**

创新点在于为每个类别学习注意力头的条件重要性权重，打破了以往统一投票的假设，使不同类别可由专属头子集决定。

**🔧 技术方法**

核心技术包括：从模型提取最后标记的注意力向量；构建每类中心点；使用余弦相似度与基于边际的置信度来估计每头的可靠性；按类别加权投票得到最终预测。

**📊 数据集**

实验数据集涵盖ESC‑50、VGGSound、AudioSet、VGGVideo（视听）以及LA‑Spoof（欺骗检测）等。

**📈 对比分析**

与SAVs及零样本基线比较，CALM 在音频分类上平均提升 1.5‑14.5%（AudioSet 14.5%），在视听分类提升 1.5% 以上，在欺骗检测上也表现优于统一投票，整体实现了显著性能提升。

**⚠️ 局限性**

局限性包括：在极低样本或噪声较多的场景下易过拟合；对温度超参数（τ_p、τ_w）敏感，需要手工调参；在复杂多声场音频中可能产生幻觉预测，亟待进一步改进。

---

## 170. TwistNet-2D: Learning Second-Order Channel Interactions via Spiral Twisting for Texture Recognition

**arXiv ID:** 2602.07262 | [PDF](https://arxiv.org/pdf/2602.07262v1)

**作者:** Junbo Jacob Lian `[一作]` (Northwestern University), Huiling Chen `[通讯]` (Wenzhou University)

**通讯引用:** 51067 | [OpenAlex ID](https://openalex.org/A5100648348)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

设计了一种轻量化模块 Spiral‑Twisted Channel Interaction (STCI)，在 CNN 中显式建模局部跨位置的二阶通道交互，以提升纹理与细粒度识别。

**💡 创新点**

创新点在于：① 通过在特征图上按方向位移后逐点相乘，捕捉局部但跨位置的协方差；② 使用多方向聚合与自适应交互选择；③ 采用门控残差集成，保持参数量极低且可稳定融入预训练网络。

**🔧 技术方法**

采用的技术包括：深度可分离卷积实现方向位移、ℓ₂ 归一化、上三角二阶乘积、SE‑style 关注机制、残差门控、以及轻量化 ResNet‑18 结构。

**📊 数据集**

实验数据集为 DTD、FMD、CUB‑200 与 Flowers‑102 四个纹理/细粒度识别基准。

**📈 对比分析**

与 10–16M 规模的 ResNet‑18、SE‑ResNet‑18、ConvNeXt‑V2‑Nano、FastViT‑SA12 等模型以及 28M 规模的 ConvNeXt‑Tiny、Swin‑Tiny 进行对比；TwistNet‑18 在所有四个数据集上均取得最优或相近性能，尤其在 DTD 与 CUB‑200 上提升 6–12%，且同规模大模型在无预训练时性能明显下降，验证了该模块的有效 inductive bias。

**⚠️ 局限性**

局限性包括：在依赖全局颜色/光照信息的 FMD 与 Flowers‑102 上略逊于全局上下文模型；固定的四个方向可能无法覆盖所有纹理方向；未与 ImageNet 预训练结合评估，未来可进一步验证其与迁移学习的互补性。

---

## 171. Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation

**arXiv ID:** 2602.07673 | [PDF](https://arxiv.org/pdf/2602.07673v1)

**作者:** Jiangnan Fang `[一作]`, Ryan A. Rossi `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了大语言模型（LLM）作为评判者时的偏差，探讨 n‑gram 相似度与评判偏好以及位置偏差之间的关系。

**💡 创新点**

在细粒度层面系统评估 LL M 偏好与相似度的相关性，并揭示自我偏好与位置偏差随模型规模变化的规律。

**🔧 技术方法**

使用 ROUGE、BLEU 等相似度指标、LLM 生成摘要与评判模型、无历史上下文交互、双向顺序验证以及长短词匹配等技术。

**📊 数据集**

采用 WikiSum 与 CNN/DailyMail 两个测试集（约 2000 篇文章），在长度筛选后分别得到 286 篇和 276 篇样本，并用 Gemma、LLaMA、Mistral、GPT‑4o‑mini 等 9 个不同规模的模型进行实验。

**📈 对比分析**

通过绘制评判选择与相似度分布的直方图比较，结果显示生成摘要在 n‑gram 相似度低时更受 LLM 评判者偏好，位置偏差与模型参数规模相关，整体性能随相似度提升而下降。

**⚠️ 局限性**

局限性包括仅使用单一参考摘要、仅以短词重叠指标衡量相似度、受长度筛选限制、未考虑对抗样本以及样本规模相对有限。

---

## 172. SocialPulse: An Open-Source Subreddit Sensemaking Toolkit

**arXiv ID:** 2602.07248 | [PDF](https://arxiv.org/pdf/2602.07248v1)

**作者:** Stephanie Birkelbach `[一作]` (Texas A&M University), James Caverlee `[通讯]` (Texas A&M University)

**通讯引用:** 8720 | [OpenAlex ID](https://openalex.org/A5048489384)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一个名为SocialPulse的开源工具，集成了Reddit子版块的数据收集、机器人检测、主题建模、情感分析、用户行为分析等多种方法，并提供交互式仪表盘实现从宏观趋势到细粒度内容的流畅切换。

**💡 创新点**

创新点在于将多种分析视角统一到同一可扩展平台，支持长尾用户与活跃用户的对比，且通过交互式可视化实现快速、透明、可复现的在线社区话语分析。

**🔧 技术方法**

使用了Transformer‑based 的BERTopic进行主题建模，VADER进行情感分析，结合机器人检测算法，以及可视化框架（如Dash/Plotly）搭建交互式仪表盘。

**📊 数据集**

主要使用了Reddit的子版块帖子与评论数据（如r/conspiracy、r/askscience等），示例中以2026年1月4日当周的帖子为数据集。

**📈 对比分析**

通过跨子版块对比共享用户、重复内容、情感分布等指标实现比较；系统通过实时可视化展示这些结果，虽然文中未给出具体数值评估，但说明能够在大规模数据上实现流畅交互。

**⚠️ 局限性**

局限性包括：机器学习模型对计算资源要求高；机器人过滤可能不完全准确；情感分析工具对长文本的效果有限；目前仅适用于Reddit，扩展到其他平台需进一步适配；缺乏定量的性能指标评估。

---

## 173. Convex Dominance in Deep Learning I: A Scaling Law of Loss and Learning Rate

**arXiv ID:** 2602.07145 | [PDF](https://arxiv.org/pdf/2602.07145v1)

**作者:** Zhiqi Bu `[一作]` (Meta Superintelligence Labs), Jialin Mao `[通讯]` (Independent Researcher)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

探索深度学习中凸性类似行为并将凸优化理论推广到非凸深度学习及自适应优化器，提出可跨模型规模和训练时长预测损失和学习率的二维缩放法则

**💡 创新点**

将凸优化的收敛分析、学习率时间表的合格性判定、以及基于数据驱动的线性回归预测结合，首次实现对大规模模型训练过程的精确损失与学习率预测

**🔧 技术方法**

凸优化理论推导、符号与数值积分验证、线性回归估计、数据驱动序列到序列预测、不同优化器的改写公式

**📊 数据集**

ImageNet（ResNet, ViT）、OpenWebText（GPT‑2）、Cauldron（VLM）等公开数据集；同时覆盖多种模型规模从 0.07B 至 12.56B 参数

**📈 对比分析**

通过对比模型训练曲线与理论预测的 R²（≥0.95）和残差误差（≤1%）验证，实验显示在多模型、多优化器与多规模下均能实现 O(1/√T) 的损失收敛和 1/√T 的学习率缩放

**⚠️ 局限性**

仅能预测训练损失，无法预测测试损失；未能解释凸性类似行为出现的根本原因；在严重过拟合时预测失效

---

## 174. "Death" of a Chatbot: Investigating and Designing Toward Psychologically Safe Endings for Human-AI Relationships

**arXiv ID:** 2602.07193 | [PDF](https://arxiv.org/pdf/2602.07193v1)

**作者:** Rachel Poonsiriwong `[一作]` (Massachusetts Institute of Technology), Pat Pataranutaporn `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 1332 | [OpenAlex ID](https://openalex.org/A5036506156)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了AI伴侣服务停止（discontinuation）对用户情感与行为的影响，构建归因模型并提出基于心理学的设计原则与原型。

**💡 创新点**

首次系统化分析AI伴侣终止事件，提出用户‑伴侣‑基础设施三角归因模型及四项整合自我决定理论与哀伤心理学的设计原则。

**🔧 技术方法**

使用构造主义扎根理论进行定性分析，并结合OpenAI LLM 进行帖子筛选与标注，随后设计了用户体验原型。

**📊 数据集**

采集自五个主流AI伴侣子Reddit社区的307,717条公开帖子（约10%涉及终止事件），通过推断得到68条标注为终止的帖子。

**📈 对比分析**

通过与人工标注的交叉验证（Kappa 0.65/0.82）评估LLM筛选和编码的一致性；未进行量化性能评测，主要以理论框架与设计指引为输出。

**⚠️ 局限性**

研究样本仅来自公开英文Reddit讨论，缺乏跨文化与纵向追踪，原型未在真实用户中验证，且对非西方或法律敏感情境的适用性未知。

---

## 175. Why Look at It at All?: Vision-Free Multifingered Blind Grasping Using Uniaxial Fingertip Force Sensing

**arXiv ID:** 2602.07326 | [PDF](https://arxiv.org/pdf/2602.07326v1)

**作者:** Edgar Lee `[一作]` (Sogang University), Seokhwan Jeong `[通讯]` (Sogang University)

**通讯引用:** 652 | [OpenAlex ID](https://openalex.org/A5017597959)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `8d10c613-917e-4880-9716-17789f50e119` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种仅利用单轴触点力反馈和关节位置的盲多指抓取方法

**💡 创新点**

创新点在于使用教师‑学生训练框架：先在仿真中用特权观测训练强化学习教师，再通过行为克隆将其蒸馏为仅依赖低维感知的学生

**🔧 技术方法**

采用的技术包括PPO强化学习、Transformer行为克隆、域随机化、单轴力传感器、仿真到真实的零射击迁移

**📊 数据集**

使用的训练数据集为18种几何形状（6种物体×3尺寸）的仿真样本；在真实环境中测试18件实物（6种训练形状+12种外部样本）

**📈 对比分析**

与仅用部分观测的RL基线和人工遥控IL上限进行对比，盲抓取成功率达到98.3%（ID100%、OOD97.5%），显著优于RL基线（约37%）且接近人类IL的100%

**⚠️ 局限性**

局限在于缺乏外部定位、只能单物体抓取、对大偏移敏感，且对多目标/复杂拥挤场景及目标导向抓取尚未验证

---

## 176. Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs

**arXiv ID:** 2602.07276 | [PDF](https://arxiv.org/pdf/2602.07276v1)

**作者:** Pengrui Han `[一作]` (University of Illinois Urbana-Champaign), Jiaxuan You `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 7875 | [OpenAlex ID](https://openalex.org/A5003491365)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于预定义语义子空间的动态组合激活向量方法（Steer2Adapt），通过贝叶斯优化在少量样例下自动生成针对新任务的混合调节向量，实现LLM的推理时快速适配。

**💡 创新点**

创新点在于将单一方向的激活调节转化为可组合的“配方”概念：利用可复用的语义概念向量子空间，动态搜索其线性组合，既提升了数据效率，又保持了可解释性和稳定性；同时引入了稳健的目标函数，兼顾错误纠正与避免错误翻转。

**🔧 技术方法**

核心技术包括：
- 语义子空间构建（利用表示工程或对比模板得到概念向量）；
- 贝叶斯优化搜索组合系数，目标函数加入稳定性约束；
- 在推理阶段直接注入组合向量，无需梯度更新；
- 通过少量（≈12）支持样本实现任务特定调优。

**📊 数据集**

数据集涵盖两大领域：
- 推理领域：Code（CodeGen）、Social（social reasoning）、Arithmetic（Simple Equations & Letter Counting）、Logic（logical reasoning）、Game（game reasoning）等；
- 安全领域：Refusal（OpenAI refusal benchmark）、Sycophancy（Sycophancy benchmark）、Hallucination（Hallucination benchmark）和 Bias（Bias benchmark）。

**📈 对比分析**

与基线方法（few‑shot prompting、ICL、对比激活添加、单向调节）在 3 个不同模型（Llama‑3.1‑8B、Qwen‑2.5‑7B、Mistral‑7B）和 9 个任务上对比，平均提升约 8.2%，并在任务级、模型级均表现出更低方差、更高稳定性和更优的性能‑成本折衷；单向或任务向量方法往往出现任务依赖性下降或不稳定。

**⚠️ 局限性**

局限性包括：
- 需要手工定义语义概念并构造子空间，若概念选择不恰当会影响效果；
- 受子空间方向的相关性和互补性影响，过度混杂或不相关向量可能导致性能波动；
- 对于高度特定或需要全新能力的任务，现有概念向量可能不足；
- 仅在推理阶段注入，未考虑对模型整体知识的长期改进。

---

## 177. Beyond Crash: Hijacking Your Autonomous Vehicle for Fun and Profit

**arXiv ID:** 2602.07249 | [PDF](https://arxiv.org/pdf/2602.07249v1)

**作者:** Qi Sun `[一作]` (Johns Hopkins University), Yinzhi Cao `[通讯]` (Johns Hopkins University)

**通讯引用:** 3548 | [OpenAlex ID](https://openalex.org/A5070605476)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `6215c339-3735-4be3-8a07-5bbb7004712d` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

设计并实现了基于视觉补丁的长期路线劫持攻击，通过在攻击车辆后方显示可重构的补丁，实时监控受害车辆的运动并动态切换补丁，实现将受害车辆从原始路线慢慢转移至攻击者指定目的地的目标。

**💡 创新点**

创新点包括：①将视觉补丁视为可持续的转向原语；②在离线阶段采用 min‑max 对抗优化，构建对背景、光照、交通等变化鲁棒的补丁库；③在在线阶段实现交互式调节循环，基于实时误差自动选择补丁，保证长期影响；④在不触发明显交通违规的前提下实现高成功率的路线劫持。

**🔧 技术方法**

使用技术包括：①端到端视觉‑语言‑动作驱动的驾驶模型（SimLingo + InternVL + LoRA‑LLM）；②对抗训练的 min‑max 优化算法；③交互式反馈控制（比例增益）用于补丁切换；④CARLA 仿真环境、Bench2Drive 场景基准；④Python+PyTorch+OpenCV 进行实现与训练。

**📊 数据集**

使用数据集：Bench2Drive 采集的街景图与 GPS 信息；CARLA 0.9.15 仿真环境中的地图与车辆轨迹；随机生成的 13 条原始路线及其对应的 39 条劫持路线；不同天气、光照和交通量场景配置，用于评估鲁棒性。

**📈 对比分析**

评价方法：使用 Hijacking Success Rate（HSR）、Hijacking Compliance Length/Rate、交通规则违规次数、轨迹曲率、硬刹车次数和转向反转次数等指标。实验结果显示 HSR 为 91.4%（34/39），平均遵从长度 122.2 m；与无攻击情景相比，轨迹平滑度、硬刹车和转向反转指标均保持相近，说明攻击具有较高的隐蔽性。在不同天气和交通量下成功率保持在 100% 左右，但在大转角（>90°）和雨刷/强光条件下会失效。

**⚠️ 局限性**

局限性：①对大角度（>90°）转弯的路线劫持效果不佳；②雨刷导致的视觉模糊、强光反射导致的色彩漂移会削弱补丁影响；③需要攻击车辆配备后置显示硬件，实际部署成本和可行性受限；④实验仅在仿真环境完成，缺乏真实车辆验证；⑤攻击前需对受害车辆的感知模型有一定了解，降低了黑盒攻击的可行性。

---

## 178. Magnetic Field-Mediated Superconducting Logic

**arXiv ID:** 2602.07146 | [PDF](https://arxiv.org/pdf/2602.07146v1)

**作者:** Alexander J. Edwards `[一作]` (Laboratory for Physical Sciences), Joseph S. Friedman `[通讯]` (University of Texas at Dallas)

**通讯引用:** 1172 | [OpenAlex ID](https://openalex.org/A5001887370)

**关键词:** `7a50eb32-3dbc-4c3e-a038-bda01b2d9965` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出并实验验证了一种利用自旋轨道力矩（SOT）切换磁化并通过磁场近场调制超导体电阻的SuperMag开关，并基于此设计了完整的逻辑与存储单元。

**💡 创新点**

创新点在于：①实现非易失性、可逆（可逆/非逆）超导开关；②实现电隔离的磁场调制，避免了传统超导开关的耗散拉升器；③开关可直接充当理想的传输门，极大降低逻辑门尺寸；④在同一工艺中即可集成逻辑与高密度非易失性RAM。

**🔧 技术方法**

主要技术包括：SOT驱动的CoFeB/Al/MgO异质结构、磁场近场耦合、低温（≈270 mK）超导电阻测量、CMOS等效电路映射与仿真。

**📊 数据集**

实验数据基于在270 mK温度下对Al/CoFeB/ MgO器件进行磁场扫描得到的电阻与磁化关系，未使用公开数据集。

**📈 对比分析**

通过与CMOS（SkyWater 130 nm）和RSFQ逻辑进行面积、延迟、功耗、功耗-延迟乘积（PDP）四维度对比，结果显示SuperMag在面积上可比RSFQ低五个数量级、CMOS低1.5个数量级；在功耗上可比CMOS低两到三百倍，PDP在材料优化后可与成熟技术竞争，甚至实现千倍能效提升。

**⚠️ 局限性**

主要限制包括：①需要外部或内部精准的偏置磁场；②对超导与磁材料的界面质量与厚度要求高；③目前材料参数尚未达到最优，导致功耗与延迟仍受限；④低温运行仍需制冷设备，限制在某些应用场景的可行性。

---

## 179. Efficient Adaptive Data Analysis over Dense Distributions

**arXiv ID:** 2602.07732 | [PDF](https://arxiv.org/pdf/2602.07732v1)

**作者:** Joon Suk Huh `[一作]` `[通讯]` (University of Wisconsin Madison), Joon Suk Huh (University of Wisconsin Madison)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

提出了一种针对稠密分布的适应性数据分析机制，实现了在保证计算效率的同时达到 O(log T) 的样本复杂度。

**💡 创新点**

在稠密分布假设下实现了计算可行且样本最优的 ADA，同时展示了该机制满足 Predicate Singling Out 隐私保护。

**🔧 技术方法**

采用在线梯度下降（OGD）与数据草图技术，结合重采样估计与误差上限判定。

**📊 数据集**

无具体真实数据集，所有结论均为理论证明与抽象分布。

**📈 对比分析**

与传统基于 DP 的 O(√T) 采样方案相比，本文机制在样本量上提升到对数级别，且时间复杂度仅为多项式；理论分析表明在稠密分布上可实现。

**⚠️ 局限性**

仅适用于相对已知先验且稠密的分布，无法推广到任意分布；隐私保护弱于差分隐私。

---

## 180. BadSNN: Backdoor Attacks on Spiking Neural Networks via Adversarial Spiking Neuron

**arXiv ID:** 2602.07200 | [PDF](https://arxiv.org/pdf/2602.07200v1)

**作者:** Abdullah Arafat Miah `[一作]` (University of Rhode Island), Yu Bi `[通讯]` (University of Rhode Island)

**通讯引用:** 380 | [OpenAlex ID](https://openalex.org/A5074397437)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种针对脉冲神经网络的后门攻击BadSNN，利用对神经元超参数（阈值、时间常数）的恶意调节实现后门注入，并在推理阶段通过触发器优化激活后门。

**💡 创新点**

创新点在于：①不通过数据触发，而是通过“恶意脉冲中毒”（hyperparameter poisoning）植入后门；②设计了可最小化可感知度的触发器优化流程；③证明该攻击对现有多种后门防御方法具有强鲁棒性。

**🔧 技术方法**

核心技术包括LIF/PLIF脉冲神经元建模、双脉冲学习策略、DeepFool自适应混合触发器、U‑Net触发器生成网络以及多种评估指标（Clean Accuracy、Base Accuracy、Attack Success Rate）。

**📊 数据集**

实验使用四个数据集：CIFAR‑10、GTSRB、CIFAR‑100 以及 N‑MNIST（神经形态数据）。

**📈 对比分析**

通过与BadNet、Blend、WaNet、Clean Label等传统后门攻击以及Fine‑Tuning、CLP、ANP、TSBD、NAD等防御方法进行对比。结果显示：在保持 Clean Accuracy 高的同时，BadSNN 的 ASR 在大部分数据集上均超过 80%，且在防御手段下仍能保持显著的攻击成功率。

**⚠️ 局限性**

局限性包括：需要精确选择恶意超参数，若调节过大易导致正常准确率下降；仅针对白盒训练与推理环境；对某些模型或数据集（如 N‑MNIST）需要不同的触发器设计；目前实验主要基于 LIF/PLIF 结构，未覆盖所有 SNN 变体。

---

## 181. Uncertainty-Aware Counterfactual Traffic Signal Control with Predictive Safety and Starvation-Avoidance Constraints Using Vision-Based Sensing

**arXiv ID:** 2602.07784 | [PDF](https://arxiv.org/pdf/2602.07784v1)

**作者:** Jayawant Bodagala `[一作]` (Independent Researcher), Balaji Bodagala `[通讯]` (ENSISINFO INC)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `9cc9baba-5356-466d-81ff-d80028d90279` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

研发了一种基于不确定性感知的信念空间模型预测控制（UCATSC），用于在视觉感知不确定的交叉口进行自适应信号控制。

**💡 创新点**

将视觉感知的不确定性显式建模为信念，采用预测性危险区风险约束和饥饿避免公平约束，利用反事实滚动预测选择最优相位；同时提供可解释的控制策略。

**🔧 技术方法**

信念空间模型预测控制、POMDP信念滤波、反事实滚动、基于概率的危险区风险度量、安全与公平约束、运动级聚合过滤器等技术。

**📊 数据集**

通过一台俯视摄像头采集的 8.75 小时交叉口视频（1080p 30fps），涵盖三种交通配置、不同光照、遮挡与流量条件。

**📈 对比分析**

与固定时序、占用感知、队列代理等基线对比，UCATSC 在遮挡、风险尾部和排放指标上均优于基线，保持稳定的检测概率，降低排放近 43%，并实现 110–120 ms 的实时可行时延。

**⚠️ 局限性**

对感知误差、几何知识与局部稳态假设敏感；若出现持续拥堵或感知失效，需退回保守策略；基线主要使用代理指标，缺乏真实车辆延迟/排放的完整验证。

---

## 182. Cross-Camera Cow Identification via Disentangled Representation Learning

**arXiv ID:** 2602.07566 | [PDF](https://arxiv.org/pdf/2602.07566v1)

**作者:** Runcheng Wang `[一作]` (Shandong Agricultural University), Yongliang Qiao `[通讯]` (Australian Institute for Machine Learning)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

提出了基于子空间识别保证（SIG）理论的跨相机牛只识别框架，利用分离表示学习实现摄像头、视角、身份和种类四个正交子空间的解耦。

**💡 创新点**

创新点在于：① 将物理生成模型与子空间辨识理论结合，显式分离摄像头特征、视角变形、身份稳定特征和种类通用特征；② 引入摄像头索引作为条件约束，提升对环境干扰的抑制；③ 通过重权重分类、最小类别混淆和中心对齐实现跨相机标签分布对齐。

**🔧 技术方法**

技术方法包括：ResNet‑50特征提取 + 多层感知机变分编码器，四维子空间解耦的VAE；YOLOv11n做牛体框提取；条件分类器、标签重加权、MCC、中心对齐等损失函数；采用梯度重参数化与正交约束实现子空间独立性。

**📊 数据集**

使用自建的CCCI60数据集，包含7,378张60头Holstein奶牛的全身图像，覆盖5个不同摄像头节点，涵盖多光照、多视角与不同相机硬件。

**📈 对比分析**

与五种主流域适应基线（DAN、DANN、MFSAN、SSG、iMSDA）进行Leave‑One‑Camera‑Out评估，平均识别准确率达到86.0%，明显高于源模型51.9%和最优基线iMSDA的79.8%。

**⚠️ 局限性**

局限性包括：数据集仅包含Holstein品种、样本量有限；在极端光照或视角导致的遮挡时仍可能误识；模型体量较大，对边缘设备的实时部署尚需进一步压缩与优化。

---

## 183. Graph Domain Adaptation via Homophily-Agnostic Reconstructing Structure

**arXiv ID:** 2602.07573 | [PDF](https://arxiv.org/pdf/2602.07573v1)

**作者:** Ruiyi Fang `[一作]` (Western University), Boyu Wang `[通讯]` (Western University)

**通讯引用:** 14257 | [OpenAlex ID](https://openalex.org/A5079920605)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出一种无监督图域适配框架 RSGDA，通过在源图和目标图上同时构造高同类性（homophilic）和异类性（heterophilic）结构图，采用自适应滤波器提取双重信号并进行对齐，从而实现对不同同类性水平图的知识迁移。

**💡 创新点**

创新点在于：①不依赖于先验的同类性判定，采用结构重构同时生成同类与异类图，做到同类性无关；②设计可学习的混合滤波器兼顾低频与高频信息；③在无标签的目标图上通过对齐同类/异类嵌入降低域差距，并提供理论误差上界。

**🔧 技术方法**

主要技术包括：图结构重构（通过最小化特征距离和多跳一致性得到同类图，使用互补图得到异类图）；自适应图滤波器（γ 控制同类/异类权重）；双编码器-解码器对齐网络（含相关性约束与重建损失）；KL 对齐损失与理论分析。

**📊 数据集**

实验使用了十余个公开数据集：机场网络（USA、Brazil、Europe）、引用网络（ACMv9、Citationv1、DBLPv7）、博客网络（Blog1、Blog2）、WebKB 领域（Texas、Cornell、Wisconsin）、ACM3/ACM4 等，涵盖同类性从 0.1 到 0.86 的多种场景。

**📈 对比分析**

与 GCN、DANN、DANE、UDAGCN、ASN、EGI、GRADE‑N、JHGDA、SpecReg、PA、HGDA 等 11 种基线相比，RSGDA 在所有跨域节点分类任务上均名列前茅，平均提升 2%–3%，在 WebKB 异类性数据集上最高提升达 8.6%。

**⚠️ 局限性**

局限性包括：①结构重构过程计算量较大，尤其在极大图上可能受限；②对γ、μ1、μ2 等超参仍需经验调优；③在极度稀疏或极端异类性图上，重构生成的异类图可能过于稠密，导致信息冗余。

---

## 184. Learning Molecular Chirality via Chiral Determinant Kernels

**arXiv ID:** 2602.07415 | [PDF](https://arxiv.org/pdf/2602.07415v1)

**作者:** Runhan Shi `[一作]` (AGI Institute), Yang Yang `[通讯]` (AGI Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了ChiDeK框架，利用旋转不变的旋度矩阵与交叉注意力来显式编码分子中心与轴向手性特征，提升对手性分子的表示学习；

**💡 创新点**

创新点在于引入基于行列式的“chiral determinant kernel”实现对手性矩阵的高维编码，并通过交叉注意力将手性信息从局部传播到全局，从而同时捕获中心手性与轴向手性；

**🔧 技术方法**

使用了SE(3)-不变的几何消息传递、基于行列式的核函数、Gaussian kernel with pair type (GKPT) 边缘偏置以及跨注意力机制；

**📊 数据集**

构建了新的轴向手性基准数据集，涵盖电磁圆二色谱（ECD）与光旋转（OR）预测，并在公开的中心手性数据集（R/S 识别、对映排序、ECD 预测）上进行评测；

**📈 对比分析**

与多种E(3)与SE(3)不变模型（DimeNet++、SphereNet、ChIRo、ECDFormer、ChiGNN、Tetra-DMPNN、SPMS）对比，ChiDeK在中心手性任务中几乎达到100%准确率，在轴向手性任务中比最优基线提升约7%（如OR准确率从约55%提升至69%），并在ECD峰值符号预测上取得10%以上的增益；

**⚠️ 局限性**

局限在于对手性矩阵的投影矩阵需保持满秩，否则会丢失手性信息；数据集仍以计算化学生成，可能存在构象与光谱标签不匹配；目前仅覆盖中心与轴向手性，尚未扩展至平面或螺旋手性。

---

## 185. Vision and language: Novel Representations and Artificial intelligence for Driving Scene Safety Assessment and Autonomous Vehicle Planning

**arXiv ID:** 2602.07680 | [PDF](https://arxiv.org/pdf/2602.07680v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 186. Sequences as Nodes for Contrastive Multimodal Graph Recommendation

**arXiv ID:** 2602.07208 | [PDF](https://arxiv.org/pdf/2602.07208v1)

**作者:** Bucher Sahyouni `[一作]` (University of Surrey), Simon Hadfield `[通讯]` (University of Surrey)

**通讯引用:** 4843 | [OpenAlex ID](https://openalex.org/A5091184063)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `3f18e8e3-0266-457c-8567-9039b6d2394d` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出 MuSICRec 模型，将用户历史序列视为节点构建序列‑项目（SI）图，与用户‑项目（UI）图和多模态项目‑项目（MM）图联合进行对比学习推荐。

**💡 创新点**

创新点：
1) 通过将序列作为节点生成 SI 视图，天然提供第二个视图，避免人工数据增强；
2) 在多模态融合前引入 ID‑引导门控，对视觉/文本特征按项目 ID 加权，抑制模态噪声并校准跨模态信息；
3) 采用冻结的 kNN 多模态图进行传播，降低训练成本并提升稳定性。

**🔧 技术方法**

技术手段：
- LightGCN 风格的无变换图卷积网络；
- 多视图对比学习（InfoNCE）对齐用户‑序列、项目‑项目视图；
- 关注力池化得到序列嵌入；
- ID‑门控多模态融合；
- 固定 kNN 多模态图与残差式融合；
- BPR 损失与可选的对比损失组合。

**📊 数据集**

使用数据集：Amazon Baby、Sports & Outdoors、Electronics（包含文本 384 维特征和图像 4096 维特征）。

**📈 对比分析**

对比方法：
- 基线包括 LightGCN、SGL、SASRec、BERT4Rec、FEARec、SRGNN、MMGCN、GRCN、VBPR、BM3、MGCN、FREEDOM、LGMRec、SMORE。
- 采用严格的 leave‑two‑out 训练/验证/测试拆分。
- MuSICRec 在 R@10/20、N@10/20 指标上平均提升 3%–7%（最小 3.64%，最大 7.05%），在所有数据集和指标上均位居榜首。

**⚠️ 局限性**

局限性：
- 依赖固定 kNN 多模态图，无法自适应不同模态之间的细粒度关系；
- 对极长历史用户的提升有限；
- 对 λ_u、λ_i 参数敏感，需适度调参；
- 在完全缺失某模态或极端稀疏的新领域中的效果尚未验证。

---

## 187. Deriving Neural Scaling Laws from the statistics of natural language

**arXiv ID:** 2602.07488 | [PDF](https://arxiv.org/pdf/2602.07488v1)

**作者:** Francesco Cagnetta `[一作]` (International School for Advanced Studies), Matthieu Wyart `[通讯]` (Johns Hopkins University)

**通讯引用:** 8342 | [OpenAlex ID](https://openalex.org/A5019813807)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种从自然语言统计量（下词条件熵衰减指数γ与词对相关性衰减指数β）推导大规模语言模型在数据受限时的神经缩放指数α_D的理论，并在实验中验证其可行性。

**💡 创新点**

创新点在于：①首次以可测量的语言统计量无任何假设或人工数据模型直接推导缩放指数；②给出简洁公式α_D = γ/(2β)；③通过n-gram损失的缩放收敛和整体自回归损失的指数匹配，验证了“预测时间窗受限”学习机制。

**🔧 技术方法**

技术手段包括：损失分解为预测时间窗与内部使用两部分，利用词对协方差矩阵的最优值与下词条件熵的幂律衰减，推导数据依赖预测时间窗n^*(P)和损失缩放；在实验上使用GPT‑2、LLaMA等Transformer架构，并对TinyStories与WikiText-103进行从零训练、损失收敛、指数估计等实验。

**📊 数据集**

使用的数据集为：①TinyStories（GPT‑3.5/4生成的短篇故事集合）；②WikiText‑103（维基百科经验证的文章集合）。

**📈 对比分析**

比较方法：在不同最大上下文长度T下训练模型，绘制n‑gram损失曲线并在归一化尺度下进行收敛性验证；测定整体自回归损失的幂律衰减，并将实验得到的α_D与理论预测α_D=γ/(2β)对比。性能方面，TinyStories的α_D≈0.19、WikiText≈0.14均与理论预测极为吻合，且不需要任何参数拟合。

**⚠️ 局限性**

局限性：①实验仅在相对有限的数据规模和上下文长度（几十到几百个标记）范围内验证；②假设内部使用的学习速度足够快，对浅层网络或核方法可能不成立；③在工业级大规模（P≈10^12、T≈10^5）场景下能否保持“时间窗受限”假设尚未验证。

---

## 188. Comprehensive Evaluation of Large Language Models on Software Engineering Tasks: A Multi-Task Benchmark

**arXiv ID:** 2602.07079 | [PDF](https://arxiv.org/pdf/2602.07079v1)

**作者:** Go Frendi Gunawan `[一作]`, Mukhlis Amien `[通讯]`

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

评估11种最新大语言模型在五类软件工程任务（bug修复、功能开发、重构、技术写作、研究综述）上的性能与效率，提供可复现的数据与脚本。

**💡 创新点**

1）构建跨任务多模评测基准，覆盖真实代码库交互；2）引入工具使用效率与时间效率指标，揭示同等质量下模型在完成时间、工具调用、成本上的极端差异；3）提出循环与推理两类效率瓶颈分类；4）量化工具调用与成功率无相关性。

**🔧 技术方法**

大语言模型（OpenAI GPT‑4o/5.1/5.2，Google Gemini 2.5/3 Flash/Pro，Deepseek‑Chat，GLM‑4.7，Kimi‑K2.5，Qwen3‑VL），基于自定义代理框架（Zrb）调用工具，使用自动化验证脚本。

**📊 数据集**

自行设计的五类任务集，均基于公开 Python 代码库与真实 GitHub issue（如 SWE‑bench、RepoBench）以及人工撰写的技术与研究题目。

**📈 对比分析**

对每个模型‑任务组合进行一次执行，记录分数（EXCELLENT/ PASS/ FAIL）、耗时、工具调用数等。综合指标包括总分、成功率、平均耗时、工具效率比、时间效率比及成本估算。结果显示：四个模型（GPT‑5.1、Gemini‑3 Pro、Deepseek‑Chat、GLM‑4.7）取得满分，但完成时间相差 22 倍，工具调用相差 49 倍，成本相差 53 倍；OpenAI 模型最快，Open‑Ollama 最慢；研究任务成功率最低（90.9%）。

**⚠️ 局限性**

1）每个模型‑任务只跑一次，缺乏统计显著性；2）任务为 Python，未覆盖多语言；3）自动化验证未涵盖代码可读性与架构优雅度；4）未对 Anthropic Claude 等模型进行评测；5）成本估算基于粗略 token 计数，实际费用可能不同。

---

## 189. Local Computation Algorithms for (Minimum) Spanning Trees on Expander Graphs

**arXiv ID:** 2602.07394 | [PDF](https://arxiv.org/pdf/2602.07394v1)

**作者:** Pan Peng `[一作]` (University of Science and Technology of China), Yuyang Wang `[通讯]` (University of Science and Technology of China)

**通讯引用:** 2230 | [OpenAlex ID](https://openalex.org/A5100409330)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

研究在邻接表和一般图模型下，用局部计算算法（LCA）在指数级稀疏图（尤其是扩散图）中构造连通的生成树、最小生成树以及相应的边是否属于生成树的查询。

**💡 创新点**

首次证明在具有常数导向率的扩散图上存在近乎最优的子线性 probe 复杂度 LCA（O(√n(log²n/φ² + d))）来构造完整生成树，并在随机图 G(n,p)（np = n^δ）上突破传统 Ω(√n) 下限，给出平均情况 LCA 复杂度 O(√(n^{1-δ}))；此外在随机权重扩散图上实现子线性 LCA 计算精确最小生成树。

**🔧 技术方法**

核心技术包括基于随机游走与最短路径的全局生成树构造并局部模拟、词典式最短路径（lexicographically‑least）搜索、“增加路径”与“受限增加路径”概念、随机图的相位转移和扩散性质、以及对探测次数的概率和 Chernoff-Hoeffding 估计。

**📊 数据集**

使用理论随机图模型 G(n,p)（np = n^δ，δ∈(0,1]）和正规扩散图（d‑regular、λ≪d）作为实验对象；无实测数据集，仅通过概率分析证明性能。

**📈 对比分析**

与此前针对稀疏生成子图的 O(√n) 级别 LCA 相比，本工作在扩散图上实现了 O(√n(log²n/φ² + d)) 的 probe 复杂度（几乎最优）；在随机图上平均复杂度降到 O(√(n^{1-δ}))，明显优于 Ω(√n) 的下限；MST 的 LCA 复杂度为 Õ(√n d²)，在随机权重的正规扩散图上首次达到子线性级别。

**⚠️ 局限性**

局限性在于仅适用于具有足够扩散性质或随机生成的图；MST 的子线性 LCA 需要边权独立均匀随机；在一般图或边权逆向设定下仍无法实现子线性 probe；且所有结果均在高概率意义下成立，无法保证对每个实例都有效。

---

## 190. Computing the Reachability Value of Posterior-Deterministic POMDPs

**arXiv ID:** 2602.07473 | [PDF](https://arxiv.org/pdf/2602.07473v1)

**作者:** Nathanaël Fijalkow `[一作]` (Laboratoire Bordelais de Recherche en Informatique), Pierre Vandenhove `[通讯]` (Université de Mons)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

本文提出了一类新的部分可观测马尔可夫决策过程（POMDP）——后验确定性POMDP，并证明在该类POMDP上可以近似计算到达目标状态的最大概率；

**💡 创新点**

创新点在于定义后验确定性POMDP，将传统的完全可观测MDP、确定性POMDP和部分可观测的Tiger POMDP等归纳到同一框架，并首次实现了对该类POMDP的到达值可逼近（而非不可判定）以及给出了具体的三重指数时间算法；

**🔧 技术方法**

核心技术包括：将POMDP映射到信念空间的自动机，设计三种特殊的树展开规则（split、exit、cut），利用端点组件（end component）分析以及马尔可夫不等式、Doob收敛定理等概率论工具；

**📊 数据集**

无；研究纯理论，没有使用实验数据集；

**📈 对比分析**

与一般POMDP的到达值不可判定相比，本文在后验确定性POMDP上给出了可实现的3EXPTIME算法，能够在给定误差ε下输出近似值；

**⚠️ 局限性**

主要限制在于算法复杂度极高（3EXPTIME）且仅适用于后验确定性POMDP的到达目标问题，对其他更一般的POMDP或其他目标（如ω-正则目标）尚未适用。

---

## 191. UEREBot: Learning Safe Quadrupedal Locomotion under Unstructured Environments and High-Speed Dynamic Obstacles

**arXiv ID:** 2602.07363 | [PDF](https://arxiv.org/pdf/2602.07363v1)

**作者:** Zihao Xu `[一作]` (National University of Singapore), Jin Song Dong `[通讯]` (National University of Singapore)

**通讯引用:** 6636 | [OpenAlex ID](https://openalex.org/A5085067496)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出UEREBot框架实现四足机器人在不规则地形和高速动态障碍下安全行走

**💡 创新点**

将规划与即时反射式躲避分层融合，并引入威胁感知交接与控制屏障保障安全

**🔧 技术方法**

利用深度学习的时空规划器、RL导航与反射策略、威胁交接网络以及控制屏障函数

**📊 数据集**

使用自定义Isaac Lab仿真环境与Unitree Go2真实机器人实验数据

**📈 对比分析**

与ABS、REASAN、CWS等基线对比，UEREBot在任务成功率、躲避成功率和最小安全距离上均有显著提升

**⚠️ 局限性**

受限于仿真与硬件差距、传感器噪声、环境多样性和长期部署鲁棒性未充分验证

---

## 192. Semantic Search At LinkedIn

**arXiv ID:** 2602.07309 | [PDF](https://arxiv.org/pdf/2602.07309v1)

**作者:** Fedor Borisyuk `[一作]` (LinkedIn), Wenjing Zhang `[通讯]` (LinkedIn)

**通讯引用:** 558 | [OpenAlex ID](https://openalex.org/A5100407200)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `8d10c613-917e-4880-9716-17789f50e119` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了LinkedIn基于大语言模型（LLM）的语义搜索框架，旨在提高AI职位搜索和AI人员搜索的检索效率和用户参与度。

**💡 创新点**

创新点在于结合了LLM相关性评估、基于嵌入的检索和通过多教师蒸馏训练的紧凑小语言模型（SLM），实现了在固定延迟约束下的高效推理，提升了排名吞吐量超过75倍，同时保持接近教师级别的NDCG。

**🔧 技术方法**

使用了大语言模型（LLM）、小语言模型（SLM）、GPU加速的检索模型、以及多教师蒸馏等技术。

**📊 数据集**

使用了LinkedIn的搜索流量数据，构建了带有分级相关性标签的查询-文档对，数据量在职位搜索中达到800万对。

**📈 对比分析**

与传统的DLRM风格排名基线相比，新系统在职位搜索中NDCG@10提高了7.73%，不良匹配率降低了46.88%，在人员搜索中NDCG@10提高了超过10%。

**⚠️ 局限性**

限制在于尽管系统在效率和质量上有显著提升，但在大规模LLM推理成本和个性化方面仍需进一步优化。

---

## 193. AI-Driven Predictive Modelling for Groundwater Salinization in Israel

**arXiv ID:** 2602.07478 | [PDF](https://arxiv.org/pdf/2602.07478v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 194. Finding Connections: Membership Inference Attacks for the Multi-Table Synthetic Data Setting

**arXiv ID:** 2602.07126 | [PDF](https://arxiv.org/pdf/2602.07126v1)

**作者:** Joshua Ward `[一作]` (University of California Los Angeles), Guang Cheng `[通讯]` (University of California Los Angeles)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `3f18e8e3-0266-457c-8567-9039b6d2394d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文研究了多表合成数据的用户级隐私泄露，并提出了一种基于异构图神经网络的多表会员推断攻击（MT‑MIA）。

**💡 创新点**

创新点在于首次将会员推断迁移到多表情景，利用异构图结构在无模型访问的威胁模型下实现用户级别的隐私审计。

**🔧 技术方法**

技术上采用异构图神经网络（HGNN）、多层消息传递、类型特定的全局注意力池化以及自监督的父子关系重建损失来学习子图嵌入。

**📊 数据集**

实验使用了加州人口普查、航空客户和Airbnb等三个真实多表数据集进行评估。

**📈 对比分析**

与传统单表的DCR、MC等基线相比，MT‑MIA在AUC和低FPR下的TPR显著提升，尤其在ClavaDDPM生成的数据上接近完美。

**⚠️ 局限性**

局限性包括仅适用于无盒威胁模型、对图嵌入质量高度敏感，以及在某些数据集上合并嵌入不一定优于单一信号。

---

## 195. Federated Learning with Profile Mapping under Distribution Shifts and Drifts

**arXiv ID:** 2602.07671 | [PDF](https://arxiv.org/pdf/2602.07671v1)

**作者:** Mohan Li `[一作]` (Università della Svizzera italiana), Marc Langheinrich `[通讯]` (Università della Svizzera italiana)

**通讯引用:** 5708 | [OpenAlex ID](https://openalex.org/A5069422623)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了 Feroma 框架，利用分布特征概况在联邦学习中自适应聚合与测试时模型分配，能够同时处理客户端间的分布偏移与单客户端的分布漂移。

**💡 创新点**

创新点在于用差分隐私、轻量级的分布特征概况替代传统的聚类或个性化标识，动态决定每轮聚合策略（从全局到聚类再到个性化），并在测试时无额外训练即可将模型映射到新客户端。

**🔧 技术方法**

核心技术包括：差分隐私统计特征提取器（DPE）、分布映射与加权聚合、阈值化相似度控制以及基于概况的一键模型分配。

**📊 数据集**

实验使用六个公开数据集：MNIST、Fashion‑MNIST、CIFAR‑10、CIFAR‑100、CheXpert 与 Office‑Home，覆盖不同类型与程度的非 IID 条件。

**📈 对比分析**

与 10 种最先进基线（FedAvg、CFL、FedEM 等）对比，Feroma 在所有基准上平均提升 10‑15 个百分点，且通信与计算开销与 FedAvg 相当。

**⚠️ 局限性**

主要局限在于依赖分布概况的质量；若嵌入模型欠拟合或过度简化，概况可能失真；此外对完全未见分布的泛化仍有限，未来可通过周期性检查点或更鲁棒的嵌入提升。

---

## 196. Automated Modernization of Machine Learning Engineering Notebooks for Reproducibility

**arXiv ID:** 2602.07195 | [PDF](https://arxiv.org/pdf/2602.07195v1)

**作者:** Bihui Jin `[一作]` (University of Waterloo), Pengyu Nie `[通讯]` (University of Waterloo)

**通讯引用:** 301 | [OpenAlex ID](https://openalex.org/A5043609524)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了一个基于大语言模型的自代理框架 AutoNotebook，用于在现代化环境中修复旧版机器学习工程笔记本，使其能够在当前硬件和软件栈上成功执行并近似原始性能。

**💡 创新点**

创新点在于将环境破坏视为固定约束而非可重构对象，结合分类型（超时、错误、分数偏差）目标的 LLM 指导修复，首次实现对旧笔记本的多维度可重现性提升；同时给出了文件级和单元级两种修复策略的对比。

**🔧 技术方法**

主要技术包括：LLM（GPT‑5.2）驱动的自动生成补丁、执行反馈循环、错误类型分类、分数校准策略、以及基于容器化的可复现执行环境。

**📊 数据集**

使用了 7,402 个来自 Kaggle 竞赛的真实机器学习工程笔记本，覆盖图像、NLP、时间序列和表格任务，并在 79 个竞赛中采集。

**📈 对比分析**

与基线（仅降级依赖）和单元级修复进行比较，AutoNotebook 在 74.2% 的样本上实现了可重现性，其中 57% 为无错误可重现；平均每个笔记本消耗约 0.31 美元，平均 2.7 次 LLM 调用，表明成本低且效果显著。

**⚠️ 局限性**

局限包括：评估依赖离线分数匹配阈值，可能与真实测试集差异；仅测试 GPT‑5.2，未验证其他 LLM；对 AttributeError 等 API 误用问题修复效果仍有限；以及未处理因数据集不可用导致的重现性缺失。

---

## 197. Adaptive Image Zoom-in with Bounding Box Transformation for UAV Object Detection

**arXiv ID:** 2602.07512 | [PDF](https://arxiv.org/pdf/2602.07512v1)

**作者:** Tao Wang `[一作]` (Sichuan University), Jiancheng Lv `[通讯]` (Sichuan University)

**通讯引用:** 31390 | [OpenAlex ID](https://openalex.org/A5100400258)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了ZoomDet框架，通过非均匀图像放大与框变换提升UAV图像小目标检测。

**💡 创新点**

创新点在于基于轻量化偏移预测实现自适应缩放，并配合角点对齐框变换解决标签对齐问题。

**🔧 技术方法**

使用卷积偏移网络、Box‑based zoom loss、角点框变换等技术，并集成到MMD等检测框架。

**📊 数据集**

在VisDrone、UAVDT、SeaDronesSee、DIOR、Argoverse‑HD、COCO等多种数据集上验证。

**📈 对比分析**

相对于统一缩放、saliency‑based以及其他zoom方法，ZoomDet在三大UAV数据集上提升了约8–15点mAP，仅增加约3–4ms推理延迟；在COCO等大尺度数据集提升有限。

**⚠️ 局限性**

局限在于对大物体或拥挤场景效果不佳，当前仅支持检测任务，且训练过程偶尔不稳定。

---

## 198. SoulX-FlashHead: Oracle-guided Generation of Infinite Real-time Streaming Talking Heads

**arXiv ID:** 2602.07449 | [PDF](https://arxiv.org/pdf/2602.07449v1)

**作者:** Tan Yu `[一作]` (Soul AI Lab), Siyuan Liu `[通讯]` (Soul AI Lab)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `8d10c613-917e-4880-9716-17789f50e119` `b88c6eac-d57a-4623-a604-1f401f3eb268` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

研发了 SoulX-FlashHead，一款 1.3B 参数的实时、无限长度音频驱动头像生成框架。

**💡 创新点**

引入流式感知时空预训练与 Oracle 引导双向蒸馏，解决音频特征不稳定与长期自回归误差累积。

**🔧 技术方法**

采用 DiT 背骨、3D VAE、Temporal Audio Context Cache、FlashAttention‑2、Hybrid Sequence Parallelism 等技术。

**📊 数据集**

使用自建的 VividHead（782 小时高质量对齐视频）与公开数据构建训练集。

**📈 对比分析**

在 HDTF 与 VFHQ 基准上，Base 版 FID 8.31、FVD 103，Lite 版 96 FPS，均优于现有方法。

**⚠️ 局限性**

参数规模有限，难以捕捉大幅身体动作与复杂手势，主要聚焦面部与头部生成。

---

## 199. Interpreting Physics in Video World Models

**arXiv ID:** 2602.07050 | [PDF](https://arxiv.org/pdf/2602.07050v1)

**作者:** Sonia Joseph `[一作]` (Meta Superintelligence Labs), Mike Rabbat `[通讯]` (Meta Superintelligence Labs)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

分析视频世界模型中物理信息的内部表示，发现物理特征在模型深度约三分之一处出现（Physics Emergence Zone）并随后衰减；

**💡 创新点**

首次系统性地将层级探测、子空间几何、补丁级解码和注意力消融结合，用以揭示物理信息的分布式、高维、环形编码结构，挑战了传统“物理引擎”低维隐状态假设；

**🔧 技术方法**

层级线性探测、注意力头距离度量、正交化逐层探测、方向空间的正弦-余弦编码分析以及针对性局部注意力抑制；

**📊 数据集**

IntPhys 可能/不可能物理判定数据集、合成球体运动数据集（Kubric）以及 CLEVRER 等多对象数据集；

**📈 对比分析**

通过在预训练的 V-JEPA 2（Large/Huge/Giant）和 VideoMAE‑v2‑G 的各层进行线性/MLP 探测，证明 Physics Emergence Zone 的存在；在方向解码和可能/不可能判定任务上，探测准确率在中间层最高，随后下降；相较于单纯的 ImageNet 等静态任务，模型在中间层展现更强的时空物理理解；

**⚠️ 局限性**

仅覆盖基于编码器、掩码预训练的视频 Transformer，未涵盖自回归或扩散模型；研究聚焦于可能/不可能判定与运动量的基础物理量，未深入接触碰撞动力学、力推理等更丰富的物理计算；

---

## 200. Preference Conditioned Multi-Objective Reinforcement Learning: Decomposed, Diversity-Driven Policy Optimization

**arXiv ID:** 2602.07764 | [PDF](https://arxiv.org/pdf/2602.07764v1)

**作者:** Tanmay Ambadkar `[一作]` (Pennsylvania State University), Abhinav Verma `[通讯]` (Pennsylvania State University)

**通讯引用:** 244 | [OpenAlex ID](https://openalex.org/A5101988843)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文提出一种名为D3PO的单一偏好条件化策略，旨在同时优化多目标强化学习中的多个冲突目标，解决梯度干扰和模式崩塌问题。

**💡 创新点**

创新点包括：① 分解优化管道，先使用多头评估器获取每个目标的优势信号，再在稳定后再应用偏好权重（Late‑Stage Weighting）；② 引入按偏好距离缩放的多样性正则化，强制不同偏好对应不同行为，从而避免代表性崩塌。

**🔧 技术方法**

技术实现：基于PPO的离线/在线学习框架，使用多头Critic估计每个目标的价值；每目标独立计算GAE；Actor损失为偏好加权的PPO克隆损失加上KL多样性正则化；采用梯度裁剪、clip阈值等标准PPO技巧。

**📊 数据集**

数据集/环境：MO‑Gymnasium系列（MO‑Humanoid‑2d、MO‑Ant‑2d、MO‑Hopper‑2d/3d等）、Building‑9d等多目标连续控制与离散控制任务。

**📈 对比分析**

与PCN、GPI‑LS、C‑MORL、PG‑MORL、CAPQL等最先进方法对比，D3PO在大多数基准上取得更高的Hypervolume（HV）与Expected Utility（EU），稀疏度（SP）更低，且训练时间与计算资源显著更低，尤其在九目标Building‑9d任务中表现尤为突出。

**⚠️ 局限性**

局限性：多样性正则化假设偏好空间连续且Pareto前沿平滑；在具有离散或分段常数Pareto前沿的环境（如FruitTree类）中，强制行为分离可能无效甚至适得其反；此外，对极高维或复杂的目标分布，需进一步验证稳健性。

---

## 201. Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System

**arXiv ID:** 2602.07308 | [PDF](https://arxiv.org/pdf/2602.07308v1)

**作者:** Sutapa Dey Tithi `[一作]` (North Carolina State University), Tiffany Barnes `[通讯]` (North Carolina State University)

**通讯引用:** 5385 | [OpenAlex ID](https://openalex.org/A5083076004)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

实现了一个自适应智能辅导系统，通过动态选择不同ICAP级别的工作示例来提高学生认知参与和学习效果。

**💡 创新点**

首次将ICAP框架与两种不同的工作示例类型（Guided和Buggy）结合，并比较BKT和DRL两种自适应策略在提升认知参与和学习成绩方面的效果。

**🔧 技术方法**

采用Bayesian Knowledge Tracing（BKT）和Deep Reinforcement Learning（DRL）两种自适应方法，并利用规则掌握估计、时间、提示等特征构建学生模型。

**📊 数据集**

使用113名本科离散数学学生在实验课程中的真实学习数据，包含预测试、训练和后测七个阶段，累计约1,570条状态‑动作‑奖励转移记录。

**📈 对比分析**

对照随机分配的控制组，对BKT和DRL两种自适应策略在训练过程中的问题类型分布、学习时间和后测成绩进行统计比较；结果显示两种自适应策略均显著优于控制组，BKT在低先验知识学生中提升更显著，DRL在高先验知识学生中更优。

**⚠️ 局限性**

实验样本仅来自单一学期的同一门课程，缺乏跨域和跨人群的验证，且DRL策略对认知负荷和解释性较弱，未能充分探索构造性参与对长期迁移学习的影响。

---

## 202. Assessing Reproducibility in Evolutionary Computation: A Case Study using Human- and LLM-based Assessment

**arXiv ID:** 2602.07059 | [PDF](https://arxiv.org/pdf/2602.07059v1)

**作者:** Francesca Da Ros `[一作]` (University of Udine), Niki van Stein `[通讯]` (Leiden University)

**通讯引用:** 1037 | [OpenAlex ID](https://openalex.org/A5003248571)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本研究通过对2016–2025年GECCO ECOM轨道168篇论文进行系统性可复现性评估，构建了专门针对演化计算实验的可复现性清单，并实现了基于LLM的自动评估工具RECAP，用以比较自动与人工评估结果。

**💡 创新点**

创新点在于（1）提出了面向演化计算的可复现性清单，填补了该领域缺乏统一评估标准的空白；（2）首次将LLM与自动化评估流水线（RECAP）与人工评估结合，证明自动评估能在较高精度下辅助可复现性审查；（3）提供了十年纵向可复现性趋势分析，为学术会议制定可复现性政策提供数据依据。

**🔧 技术方法**

技术主要包括：① 手工评估协议与结构化JSON清单；② 使用OpenAI GPT‑5 nano模型在系统提示下完成文本信息抽取；③ 通过沙盒执行代码片段评估可执行性；④ 统计分析工具（Cohen's κ、Kruskal–Wallis、Mann–Whitney U）对比评估结果。

**📊 数据集**

数据集为GECCO ECOM轨道2016–2025年全论文共168篇，包含论文文本、补充材料、公开代码仓库等；此外在GitHub提供了实验代码与数据集，供复现与进一步研究使用。

**📈 对比分析**

评估方法：人工评估作为基准，RECAP自动评估与之比对。性能方面，RECAP平均每篇论文准确率为76.8%，中位数为79.5%，Cohen's κ为0.67（若将“未报告”和“不可适用”合并为一类，κ提升至0.75），表明自动评估在可复现性信号检测上具有可接受的可靠性。

**⚠️ 局限性**

局限性包括：① 自动评估受LLM上下文窗口限制，部分大型仓库无法完整分析；② LLM易出现幻觉，导致某些评估结果不准确；③ 人工评估存在主观偏差与分级不一致；④ 可复现性清单虽覆盖核心项，但对部分细节的二分离散化可能掩盖部分信息；⑤ 仅评估论文层面的可复现性，未细化至单个实验级别；⑥ 研究范围局限于GECCO ECOM轨道，未验证跨学科或其他会议的通用性。

---

## 203. PAND: Prompt-Aware Neighborhood Distillation for Lightweight Fine-Grained Visual Classification

**arXiv ID:** 2602.07768 | [PDF](https://arxiv.org/pdf/2602.07768v1)

**作者:** Qiuming Luo `[一作]`, Chang Kong `[通讯]` (Shenzhen University)

**通讯引用:** 54201 | [OpenAlex ID](https://openalex.org/A5100431895)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `8d10c613-917e-4880-9716-17789f50e119` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了两阶段的 Prompt-Aware Neighborhood Distillation (PAND) 框架，将大型视觉-语言模型（VLM）的知识迁移至轻量级网络以提升细粒度视觉分类性能。

**💡 创新点**

创新点在于将语义校准（通过任务感知提示学习得到精细的语义锚点）与结构传递（基于邻域关系的结构蒸馏）解耦，使学生模型在保持全局对齐的同时，更好地复制教师的局部判别结构。

**🔧 技术方法**

核心技术包括 CoOp 提示学习、VL2Lite 基础蒸馏损失、邻域 logits 关系蒸馏（NLRD）以及 Jensen–Shannon 散度对齐，全部在冻结的 VLM 编码器上进行。

**📊 数据集**

实验使用了四个细粒度数据集：CUB-200-2011、Oxford-IIIT Pet、Stanford Dogs 以及 FGVC-Aircraft。

**📈 对比分析**

与无蒸馏基线、传统 KD、RKD 及 VL2Lite 的对比实验表明，PAND 在 ResNet‑18 上 CUB‑200 取得 76.09% 的 Top‑1 准确率，较 VL2Lite 提升 3.4%，在其他数据集也实现了显著的性能提升。

**⚠️ 局限性**

局限性包括需要两阶段训练流程、对 λ_NSD 等超参数敏感、邻域大小 K 的选择影响最终性能，以及依赖预训练 VLM 背景，难以直接适用于未预训练的模型。

---

## 204. Geo-Code: A Code Framework for Reverse Code Generation from Geometric Images Based on Two-Stage Multi-Agent Evolution

**arXiv ID:** 2602.07749 | [PDF](https://arxiv.org/pdf/2602.07749v1)

**作者:** Zhenyu Wu `[一作]` (Beijing Normal University), Hua Huang `[通讯]` (Beijing Normal University)

**通讯引用:** 7967 | [OpenAlex ID](https://openalex.org/A5022334521)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 Geo-Code 框架，利用多智能体系统对几何图像进行逆向代码生成，并构建 Geo-Code 数据集与 GeoCodeLM 模型；

**💡 创新点**

创新点在于将逆向过程拆分为像素锚定的几何建模阶段和视觉误差投影驱动的代码演化闭环两个阶段，解决符号定向与几何细节失真的双重难题；

**🔧 技术方法**

采用多智能体协同技术（Geometric Extraction、Visual Verification、Code Generation/Execution/Inspection/Correction），像素锚定操作、视觉误差投影（VEP）与 Chamfer/Hausdorff 距离评估，以及闭环执行-检验-修正迭代；

**📊 数据集**

使用由 AuxSolidMath、GeoQA、GeoSketch、MathVerse 采集并三层验证的 Geo-Code 数据集（1500+高质量图像-代码对），以及原始公开数据集做基准对比；

**📈 对比分析**

通过与 MatPlotCode、FigCodifier、V-Thinker、Qwen、Gemini 等基线对比，Geo-Code 在视觉一致性、像素一致性指标上显著优于对手（平均 SSIM 84.56、CD 13.06、HD 95.9），并在多模态推理任务中与原图保持同等或提升 4% 的准确率；GeoCodeLM 在小样本高质量数据上实现 SOTA 代码生成与视觉重建；

**⚠️ 局限性**

局限性包括受限于数据规模与质量、三维几何场景处理不足、对极端噪声与非几何视觉信息的鲁棒性有限，以及对手工验证的高成本。

---

## 205. AgentSpawn: Adaptive Multi-Agent Collaboration Through Dynamic Spawning for Long-Horizon Code Generation

**arXiv ID:** 2602.07072 | [PDF](https://arxiv.org/pdf/2602.07072v1)

**作者:** Igor Costa `[一作]` `[通讯]` (AutoHand Evolve), Igor Costa (AutoHand Evolve)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 AgentSpawn 架构，支持在长周期代码生成任务中动态生成并协作子代理，完成子任务后再恢复父代理的工作；

**💡 创新点**

创新点包括：自动内存切片传递、基于运行时复杂度指标的自适应生成决策、技能继承与提升机制，以及多子代理冲突的三阶一致性管理；

**🔧 技术方法**

采用 LLM（如 GPT‑4/Claude）、强化学习/贝叶斯优化的策略学习、嵌套记忆层（事件、语义、工作）和自适应冲突解决的并发合并算法；

**📊 数据集**

在 SWE‑bench、Defects4J 和自定义多文件重构任务上进行实验评估；

**📈 对比分析**

与单代理、AutoGen、CrewAI、AFLOW 等静态多代理基线对比，AgentSpawn 在任务完成率上提升了 34%（从 67% 到 97%），同时通过内存切片将使用的 token 减少 42%；

**⚠️ 局限性**

局限性包括：超参数敏感、语义合并成功率受冲突复杂度影响、深层子代理层次会增加协调开销、需要针对不同领域手工调整复杂度指标和阈值。

---

## 206. FADE: Selective Forgetting via Sparse LoRA and Self-Distillation

**arXiv ID:** 2602.07058 | [PDF](https://arxiv.org/pdf/2602.07058v1)

**作者:** Carolina R. Kelsch `[一作]`, Juan C. S. M. Avedillo `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `8d10c613-917e-4880-9716-17789f50e119` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了FADE方法，针对文本到图像扩散模型实现机器遗忘，通过先定位影响忘记集合的关键参数并使用稀疏LoRA适配器局部更新，再通过自蒸馏式损失实现概念擦除。

**💡 创新点**

创新点在于：①两阶段融合——梯度重要性掩码+自蒸馏；②采用稀疏LoRA限制更新范围，保持全局性能；③生成可插拔、可逆的适配器模块；④提供可调节的忘记-保留 Pareto 前沿，兼顾效率与效果。

**🔧 技术方法**

使用技术包括：稀疏LoRA（SparseLoRA）、梯度重要性掩码、Stable Diffusion V1.4/V1.5架构、CLIP 对齐分数、FID 评估、基于自蒸馏的对齐损失、PyTorch/PEFT 框架。

**📊 数据集**

实验数据集涵盖：UnlearnCanvas 基准；Imagenette、Labeled Faces in the Wild（LFW）、AtharvaTaras Dog Breeds、SUN Attributes；使用 Stable Diffusion 原始权重。

**📈 对比分析**

与 UnlearnCanvas 上的 SOTA 方法（EFD、FMN、UCE、CA、SaLUn 等）在 UA、IRA、CRA、FID 指标上进行对比，FADE 在多项指标上均取得最佳或接近最佳表现；内存占用仅 0.03 GB，训练时间可通过 sparsity 调整，显著低于多数对比方法。

**⚠️ 局限性**

局限性包括：①对覆盖概念的选择敏感，需人工指定；②尚未在多模型、多任务及顺序遗忘、知识复现、对抗攻击等场景下进行充分评估；③稀疏性对效果提升有限，仍需进一步优化；④未在更大规模 GPU 环境下统一衡量效率。

---

## 207. Progressive Multi-Agent Reasoning for Biological Perturbation Prediction

**arXiv ID:** 2602.07408 | [PDF](https://arxiv.org/pdf/2602.07408v1)

**作者:** Hyomin Kim `[一作]` (Korea Advanced Institute of Science and Technology), Junhyeok Jeon `[通讯]` (HITS)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个基于 LINCS L1000 的 bulk 细胞化学扰动基因调控预测基准（LINCS‑QA）并研发了多代理递进推理框架，用于在未训练的 8B 语言模型上预测基因表达方向并提供可解释推理；

**💡 创新点**

①首个评估 LLM 在 bulk 细胞化学扰动预测的基准；②利用难度感知的任务排序与递进推理，让高置信度预测信息指导后续更难的基因；③多代理架构结合结构化生物知识图谱与专门推理代理，并通过判定器保证一致性；

**🔧 技术方法**

采用大语言模型 DeepSeek‑R1‑distill‑Llama‑8B，构建多代理系统（context、mechanism、network 代理 + integration 代理），使用知识图谱检索、图注意力网络等工具，实施递进推理与判定器（四个独立评判）来校验推理链；

**📊 数据集**

LINCS L1000 2020 级别 5 数据集（化学扰动表达谱与 MoA 注释）、单细胞 GSE137912（KRAS G12C 试验）、PerturbQA 基准数据（基因扰动）以及公开 IC50/药物敏感性数据；

**📈 对比分析**

与多种通用 LLM（Llama3‑8B、DeepSeek‑R1‑8B、Mistral‑Small‑3.2‑24B、Qwen3‑30B）及领域专用 LLM（BioMistral‑7B、BioMedGPT‑LM‑7B、TxGemma‑27B、Biomni‑R0‑32B）以及 PerturbQA 的 SUMMER、GAT、GEARS、scGPT、GenePT 等基线对比，结果显示在 gene‑level 方向预测和 MoA 评估上，8B 级 Multi‑Agent 模型获得最高 AUROC 并在敏感/不敏感细胞线中表现出显著的性能差异，甚至超过 30B 级别模型；在 PerturbQA 上亦取得或逼近 SOTA；

**⚠️ 局限性**

仍依赖已有知识图谱与注释数据，对罕见或未标注化合物/细胞线的预测效果有限；多代理与判定器的推理开销较大；在高维复杂扰动下仍可能产生幻觉，需更大规模多组学数据与更丰富通路资源以提升泛化性。

---

## 208. Tensor Hinted Mv Conjectures

**arXiv ID:** 2602.07242 | [PDF](https://arxiv.org/pdf/2602.07242v1)

**作者:** Zhao Song `[一作]` `[通讯]`, Zhao Song

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b`

**🎯 论文内容**

提出并将原先针对矩阵的 Hinted Mv Conjecture 推广到张量（tensor）域。

**💡 创新点**

将该猜想从二维矩阵扩展到多维张量，为后续张量相关算法的理论研究提供了新的视角和可能的算法设计框架。

**🔧 技术方法**

主要使用了张量分解与多维矩阵运算的理论工具，借助组合数学与线性代数的技巧来推导与验证猜想。

**📊 数据集**

文中未给出具体实验或数据集，仅作理论性研究。

**📈 对比分析**

暂无实验比较与性能评估，仅给出了理论证明与推导过程。

**⚠️ 局限性**

局限性在于缺乏实验验证、未说明在实际数据上的可行性及复杂度分析，且仅提供理论框架，未给出具体算法实现细节。

---

## 209. HAIF: A Human-AI Integration Framework for Hybrid Team Operations

**arXiv ID:** 2602.07641 | [PDF](https://arxiv.org/pdf/2602.07641v1)

**作者:** Marc Bara `[一作]` `[通讯]` (ProjectWorkLab SL), Marc Bara (ProjectWorkLab SL)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df`

**🎯 论文内容**

提出并描述了 Human–AI Integration Framework（HAIF），为混合人机团队提供了基于四项核心原则、委托决策模型、分层自治以及与敏捷/看板工作流整合的可操作协议体系。

**💡 创新点**

创新点在于：①将人机协作视为可治理的、可逆的委托决策；②引入分层自治（Tier 1–4）并给出量化的晋升与降级阈值；③将验证、责任、能力保持与资源预算纳入正式流程；④在不增加角色的前提下实现与现有敏捷工作流的无缝融合。

**🔧 技术方法**

采用的技术主要是设计科学研究方法（Design Science Research），以及对现有敏捷、DevOps、MLOps、AI治理和 HITL 框架的理论整合，形成面向实践的协议与流程模型。

**📊 数据集**

未使用具体数据集；本文基于文献综述、专家评审和案例演示构建框架，未进行实证数据收集。

**📈 对比分析**

没有对比实验或性能评估；作者通过对比现有框架的覆盖面，阐明 HAIF 在责任、验证与能力保持方面的优势，后续工作计划开展田野实验和量化评估。

**⚠️ 局限性**

局限性包括：①仅采用离散委托模型，未覆盖连续协作（持续对话式 AI）与多智能体协作；②阈值和参数均为经验性估计，需实证校准；③对组织文化、激励机制的适配缺乏深入分析；④未给出工具实现细节，需进一步提供实践指南。

---

## 210. Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models

**arXiv ID:** 2602.07106 | [PDF](https://arxiv.org/pdf/2602.07106v1)

**作者:** Haoyu Zhang `[一作]` (Chinese University of Hong Kong), Tianshu Yu `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 10 | [OpenAlex ID](https://openalex.org/A5075551272)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

研发了 Ex-Omni，一个能够在同一框架下同时生成文本、语音和与语音同步的 3D 面部动画的多模态大语言模型。

**💡 创新点**

创新点包括：① 使用离散语音单元作为时间支架，解耦 LLM 的语义推理与细粒度运动生成；② 引入 token‑as‑query gated fusion（TQGF）机制，精准控制语义信息注入时序；③ 通过非自回归面部解码器和速度一致性正则化，提升动画的平滑度与自然度。

**🔧 技术方法**

采用的技术包括：LLM 语义推理、语音编码器/投影器、语音单元生成器、基于 ARKit‑52 blendshape 的 3D 动画解码器、Transformer 自注意力、TQGF 交叉注意力、速度正则化、分阶段训练（语音‑文本对齐、语音生成预训练、语音‑面部共训练、联合微调）。

**📊 数据集**

使用 InstructEx 这一多阶段数据集，涵盖 ASR、TTS、S2S、T2T、S2F 等任务。数据来源包括 Emilia、LibriSpeech、WenetSpeech、CosyVoice 语音合成以及 Audio2Face‑3D 生成的 blendshape 注释，整体约 2,800 小时语音与 100,000 条文本/面部对齐样本。

**📈 对比分析**

与多款 OLLM（Qwen2.5‑Omni、Mini‑Omni 等）以及专门的面部生成模型（EmoTalk、UniTalker）在 S2F、T2F、S2T、TTS 任务中进行对比。Ex‑Omni 在面部动画生成的 LVE 分数显著低于 cascaded 基线（如 3.67 vs 5.79），在 S2T 的 SD‑QA 上达到 40.14%，并在 TTS 评测中保持中等水平，说明其在有限数据下仍具备竞争力。

**⚠️ 局限性**

局限性：① 依赖 Audio2Face‑3D 作为监督与评估，可能导致模型与评估参考产生共振；② 对长文本/语音生成的面部动画仍易出现细节不足；③ 多语种性能不均衡，中文表现略逊；④ 未针对情感、语境细粒度等高级对话细节提供专门机制。

---

## 211. Neural Sentinel: Unified Vision Language Model (VLM) for License Plate Recognition with Human-in-the-Loop Continual Learning

**arXiv ID:** 2602.07051 | [PDF](https://arxiv.org/pdf/2602.07051v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 212. AirCatch: Effectively tracing advanced tag-based trackers

**arXiv ID:** 2602.07656 | [PDF](https://arxiv.org/pdf/2602.07656v1)

**作者:** Abhishek Kumar Mishra `[一作]` (Inria), Mathieu Cunche `[通讯]` (University of Lyon)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

设计并实现了一套基于物理层 CFO 特征的被动跟踪器检测系统，利用低成本 BLE 微型 SDR 采集信号并通过 Android 应用向用户报警；系统能够识别在失踪模式下频繁轮换标识符的高级 BLE 跟踪器。

**💡 创新点**

创新点包括：
① 构造了模块化的 CFO 指纹，加入符号转移条件 CFO，显著提升设备辨别度；
② 开发了基于核心密度与持久性的新检测算法，能在高速标识符轮转和节拍式发射下保持鲁棒性；
③ 设计并公开了约 $10 的 BLE 微型 SDR（Seeed XIAO MG24 + ESP32‑S3），实现低成本实用化；
④ 提供完整的端到端系统（硬件、算法、Android UI）并在真实移动环境中进行大规模验证。

**🔧 技术方法**

使用技术：
- 通过 IQ 样本计算 CFO 与四种符号转移条件 CFO；
- 对 CFO 向量做标准化、嵌入和 Ward 层次聚类；
- 计算核心密度并结合持久性阈值检测异常集群；
- 低成本硬件实现：采样 1.34 MSPS、SPI 传输、能量触发捕获；
- Android 应用提供报警与技术视图；
- 随机森林验证 CFO 指纹的辨别能力。

**📊 数据集**

数据集：
- 四条真实移动轨迹（Home→Work、Work→Home、Car commute、Airport），共 456.6 min，包含 54,949 个包、18,580 个 MAC；
- 设备涵盖 Apple AirTag、Google Find My、Tile、Samsung SmartTag；
- 自制 ESP32 改装的高级跟踪器，采用多种发射周期（2 s、10 s、15 s、30 s、60 s）进行仿真；
- 通过 USRP B210 采集高精度 IQ 进行对比评估。

**📈 对比分析**

比较方法：
- 与 Apple、Google 原生检测和 AirGuard 等第三方工具对比；
- 采用核心密度分布、持久性阈值（T_min = 40 min、δ = 1.15）进行决策；
- 评估指标包括误报率、召回率、检测延迟。结果显示：在三条含攻击者轨迹中无误报、100%召回；在机场无攻击者基准中保持零误报；对比之前的 CFO 指纹方法，误差率从 100% 降至约 83%/84%。

**⚠️ 局限性**

局限性：
- 若攻击者能够主动扰动或随机化 CFO（例如频率漂移），核心密度会被散布，导致检测性能下降；
- 极低发射率（> 60 s）下可能捕获不到足够样本，导致误检或漏检；
- 仅关注 BLE 广播，无法检测已配对设备或使用其他协议的跟踪器；
- 环境噪声、干扰及多径效应仍可能对 CFO 估计产生影响。

---

## 213. Contactless estimation of continuum displacement and mechanical compressibility from image series using a deep learning based framework

**arXiv ID:** 2602.07065 | [PDF](https://arxiv.org/pdf/2602.07065v1)

**作者:** A. N. Maria Antony `[一作]` (Leibniz Institute for Plant Genetics and Crop Plant Research), E. Gladilin `[通讯]` (Leibniz Institute for Plant Genetics and Crop Plant Research)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5a41884c-404f-4688-a89c-aa238c10fe68` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

通过深度学习端到端框架，实现对光学图像序列中物理介质的压缩性（泊松比）的无接触估计。

**💡 创新点**

创新点在于将图像配准与泊松比回归两个深度网络串联，并证明即使配准误差较小，传统基于PDE的局部计算失效，而端到端CNN能利用全局高阶特征（如涡旋）准确预测泊松比。

**🔧 技术方法**

采用改进的VoxelMorph U‑Net+STN进行非刚性图像配准；随后使用卷积神经网络回归模型估计整体泊松比；训练使用有限差分求解得到的线性弹性位移场。

**📊 数据集**

训练和验证数据来自128×128像素的Drosophila翅膀发育时间序列图像，配合用有限差分法生成的三种泊松比（0、0.25、0.49）的位移场；共4854个BVP实例。

**📈 对比分析**

与传统的基于Lamé‑Navier PDE的局部泊松比映射进行对比，DNN在含噪声的位移场上平均绝对误差从约0.4降至<0.1；在无噪声或0.6%噪声位移场下，DNN误差低于0.02，远优于PDE方法。

**⚠️ 局限性**

主要局限包括：仅在128×128小尺寸图像上训练，无法直接应用于高分辨率；实验仅使用合成数据，缺乏与真实物理测量的交叉验证；对非均匀或多材料结构的推广需要改进网络或采用图像对图像的回归。

---

## 214. Controllable Value Alignment in Large Language Models through Neuron-Level Editing

**arXiv ID:** 2602.07356 | [PDF](https://arxiv.org/pdf/2602.07356v1)

**作者:** Yonghui Yang `[一作]` (National University of Singapore), Tat-Seng Chua `[通讯]` (National University of Singapore)

**通讯引用:** 60381 | [OpenAlex ID](https://openalex.org/A5089404640)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了大型语言模型的价值对齐问题，提出价值泄露概念，并设计了 NeVA 框架通过神经元级别的推理时编辑实现可控价值对齐。

**💡 创新点**

①引入价值泄露的度量来量化非目标价值的意外激活；②提出 NeVA 在推理时对稀疏价值相关神经元进行方向一致的激活编辑，从而显著降低跨价值和跨组泄露。

**🔧 技术方法**

使用 Schwartz 价值理论构建评估指标；训练线性价值探针提取价值方向；对 FFN 神经元进行余弦相似度筛选与编辑；在推理阶段按方向一致性调整激活。

**📊 数据集**

使用 ConVA 数据集（包含价值探针训练集和评估集）以及公开的 Schwartz 价值上下文对照数据；在 LLaMA‑3‑8B、LLaMA‑2‑13B 和 Qwen2.5‑7B 上进行实验，并在 MMLU 等通用基准上评估。

**📈 对比分析**

与基础 LLM、SFT、CAA、ConVA 等基线比较。NeVA 在 10 个 Schwartz 价值的 CSR 最高、FR >97%，NLR 降低约40%，NGLR 更集中；在 MMLU 上保持与基础模型相近或略优，显示了更好的可控性与通用性。

**⚠️ 局限性**

仅针对单值对齐，无法完全消除同一高阶价值组内的泄露；多值冲突对齐仍需进一步研究；实验局限于单回合提示，未评估长序列或多轮对齐的稳定性。

---

## 215. SERE: Similarity-based Expert Re-routing for Efficient Batch Decoding in MoE Models

**arXiv ID:** 2602.07616 | [PDF](https://arxiv.org/pdf/2602.07616v1)

**作者:** Juntong Wu `[一作]` (Taobao and Tmall Group of Alibaba), Li Yuan `[通讯]` (Shenzhen Graduate School, Peking University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了SERE方法，针对MoE模型在批量推理时专家激活过多导致的延迟问题，通过动态将二级专家的token重新路由到最相似的主专家，从而减少激活专家数量；

**💡 创新点**

创新点在于利用预先计算的专家相似度矩阵来判断哪些专家为关键，哪些可被跳过，并在不改变路由权重的前提下实现输入感知的动态跳过与重路由；

**🔧 技术方法**

技术包括：基于激活或参数的专家相似度计算（使用Frobenius/余弦/CKA等），阈值控制的相似度重路由，CUDA实现的高性能SERE核；

**📊 数据集**

使用公开的FineWeb-Edu、C4、WIKI、OpenCompass等通用数据集进行相似度矩阵校准，评测则采用OpenCompass的多领域推理基准（CMMLU、BoolQ、BBH、Math、GSM8K、HumanEval、MBPP）和单GPU vLLM推理时延；

**📈 对比分析**

与HC‑SMoE、Top‑K缩减、LYNX等SOTA方法对比，SERE在保持95%以上原模型准确率的前提下，实现1.2×至2.0×的解码速度提升；

**⚠️ 局限性**

局限性包括：仍需先行计算相似度矩阵且对极度稀疏或高专业化专家的模型效果相对敏感，且在极高压缩率（如Top‑1）时性能会显著下降。

---

## 216. Forecasting Developer Environments with GenAI: A Research Perspective

**arXiv ID:** 2602.07412 | [PDF](https://arxiv.org/pdf/2602.07412v1)

**作者:** Raula Gaikovina Kula `[一作]` (Osaka University), Xin Xia `[通讯]` (Zhejiang University)

**通讯引用:** 20686 | [OpenAlex ID](https://openalex.org/A5006669765)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文通过聚焦Shonan会议上33位专家的讨论，探讨了生成式人工智能（GenAI）对集成开发环境（IDE）的影响，并提出了四大主题框架。

**💡 创新点**

创新点在于提出了从传统IDE演进到全新Paradigm、重新定义人类角色以及2050年未来IDE的四个主题，提供了系统化的未来视角。

**🔧 技术方法**

主要涉及的技术概念包括生成式AI模型（LLM）、多模态接口、AI代理协作、知识上下文管理以及自动化修复与技术债务管理。

**📊 数据集**

本文未使用具体数据集，讨论基于专家经验、现有文献与案例的理论分析。

**📈 对比分析**

由于是概念性研究，没有实验对比或性能评估，故无法给出定量指标；讨论侧重于理论框架与未来设想。

**⚠️ 局限性**

局限在于缺乏实证验证、依赖专家主观视角、未充分讨论法律与伦理风险，以及对技术实现细节的细化不足。

---

## 217. Low-Rank Koopman Deformables with Log-Linear Time Integration

**arXiv ID:** 2602.07687 | [PDF](https://arxiv.org/pdf/2602.07687v1)

**作者:** Yue Chang `[一作]` (University of Toronto), Maurizio M. Chiaramonte `[通讯]` (Meta Reality Labs Research)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `a8e75ba4-7a2d-4153-b003-06c94533add0` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `4de8e9d8-757b-475f-9627-18a445e50202` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

论文提出了一种基于低秩 Koopman 变换的变形物理仿真框架，利用 DMD 学习时间演化，实现对弹性体的快速长时步数积分。

**💡 创新点**

创新点在于将 Koopman 线性化与动态模式分解结合到弹性体动力学中，并实现跨形状、跨离散化的神经 Koopman 模型，实现对时间步长不变的精确仿真。

**🔧 技术方法**

使用技术包括动态模式分解（DMD）、低秩矩阵逼近、神经场表示、对数线性时间步长、复数基函数与形状编码的 MLP。

**📊 数据集**

数据集主要由基于 Neo‑Hookean 物理模拟生成的全域轨迹、不同网格分辨率的三维弹体模型，以及少量真实视频跟踪数据。

**📈 对比分析**

与隐式欧拉、传统数值 DMD 及其他基于降维的模型比较，结果显示在大步长下保持动力学一致，时间复杂度从线性降为对数级，控制/形状优化等逆问题可实时完成，误差低于 1%。

**⚠️ 局限性**

限制在于模型对训练轨迹覆盖范围敏感，难以外推至未见动力学、材料或大幅形状变化；同时需要足够多的高质量数据训练，且在极端外力或碰撞等非线性场景下稳定性尚待验证。

---

## 218. TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling

**arXiv ID:** 2602.07374 | [PDF](https://arxiv.org/pdf/2602.07374v1)

**作者:** Nisharg Nargund `[一作]` (Kalinga Institute of Industrial Technology), Priyesh Shukla `[通讯]` (International Institute of Information Technology)

**通讯引用:** 185 | [OpenAlex ID](https://openalex.org/A5067601336)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建并训练了一个132M参数的Transformer语言模型TernaryLM，采用原生1位三元量化（{-1,0,+1}）从零开始训练，实现了高效的语言建模与下游任务迁移。

**💡 创新点**

创新点在于：①首次实现从零开始的1位三元量化训练；②使用自适应层级缩放因子与直通估计器，使模型在极低精度下保持性能；③通过层级稀疏性分析揭示不同Transformer层对量化的敏感度，为混合精度设计提供依据。

**🔧 技术方法**

技术手段包括：Transformer架构（GPT-仅解码器）、RoPE位置编码、RMSNorm归一化、SiLU/GELU激活、直通估计器（STE）实现梯度传播、每层可学习缩放因子、AdamW优化器与标签平滑。

**📊 数据集**

使用的数据集：TinyStories（60M词汇）进行预训练；WritingPrompts与Shakespeare用于验证训练稳定性；下游微调在GLUE benchmark中的MRPC、SST-2、CoLA等任务。

**📈 对比分析**

与全精度基线（GPT-2 Small、BERT-Base、TinyLLaMA）以及8/4位PTQ模型进行对比：TernaryLM验证困惑度58.42（对比全精度51.23），MRPC F1 82.47%（仅落后BERT-Base 2.5%），内存减少2.4×（498MB vs 1197MB），推理延迟几乎相同（9.41ms vs 9.52ms），模型存储量减少3.3×。

**⚠️ 局限性**

局限性包括：仅在小规模（132M）模型与低熵合成文本上验证，尚未验证大规模模型和复杂数据集的可扩展性；使用通用CUDA核，未实现专门的三元矩阵乘法加速；词嵌入量化导致词表崩溃，需保持全精度。

---

## 219. Exploring Teachers' Perspectives on Using Conversational AI Agents for Group Collaboration

**arXiv ID:** 2602.07142 | [PDF](https://arxiv.org/pdf/2602.07142v1)

**作者:** Prerna Ravi `[一作]` (Massachusetts Institute of Technology), Emma Anderson `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 99969 | [OpenAlex ID](https://openalex.org/A5059645286)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文通过实验和访谈，系统研究了教师对语音交互型、非实体近同龄人对话式 AI 代理 Phoenix 在面对面小组合作中的感知与课堂整合意愿。

**💡 创新点**

创新点在于从教师视角探索 AI 代理在小组协作中的角色定位、信任与人机共存的设计张力，并首次揭示教师对 AI 代理的功能、人格化与课堂使用的多重关注。

**🔧 技术方法**

技术采用 OpenAI GPT‑4.1‑mini 作为核心语言模型，配合 Google Speech‑to‑Text 与 Microsoft Azure TTS，实现实时语音对话；系统架构基于 Django+PostgreSQL+WebSockets。

**📊 数据集**

数据集由 33 名 STEM 领域 K‑12 教师构成，收集了 30 分钟开放式问卷与 3 个焦点小组访谈记录，用于质性主题分析。

**📈 对比分析**

由于研究为质性探索，没有量化性能指标；通过主题分析比较教师对 Phoenix 的价值、信任、角色分配以及对课堂整合的设想，展示不同维度的使用意向与担忧。

**⚠️ 局限性**

局限包括实验在实验室环境下进行、样本偏向技术兴趣教师、仅评估教师视角、未检验学生学习效果，且对模型鲁棒性、隐私安全及可持续部署等方面考虑不足。

---

## 220. Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective

**arXiv ID:** 2602.07259 | [PDF](https://arxiv.org/pdf/2602.07259v1)

**作者:** Cheol Woo Kim `[一作]` (Harvard University), Milind Tambe `[通讯]` (Harvard University)

**通讯引用:** 23176 | [OpenAlex ID](https://openalex.org/A5000327528)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `9cc9baba-5356-466d-81ff-d80028d90279` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出将Stackelberg安全博弈（SSG）框架应用于LLM生命周期中的训练、评估与部署三阶段，以实现受限资源下的监督与风险管理

**💡 创新点**

将SSG从传统物理安全场景迁移到AI安全，首次将博弈论视角与模型对齐、数据审计、任务分配等多维安全问题统一起来

**🔧 技术方法**

基于SSG的资源分配策略、博弈均衡求解、随机化审计以及对RLHF、Red‑Team等现有安全技术的组合

**📊 数据集**

未使用特定公开数据集，而是以LLM训练与评估中的常见数据流（如RLHF偏好数据、评测任务集合）为假设场景

**📈 对比分析**

论文主要为理论框架与示例性分析，未给出具体实验对比；预期在有限资源环境下通过SSG优化可提升审计效率与风险减缓效果

**⚠️ 局限性**

关键挑战包括：估计博弈收益（尤其是对齐损害影响）的因果方法、随机审计在部分可观测环境中的实现、以及对现实中非零和、动态攻击者模型的适应性不足

---

## 221. Multi-Agent Systems Shape Social Norms for Prosocial Behavior Change

**arXiv ID:** 2602.07433 | [PDF](https://arxiv.org/pdf/2602.07433v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

---

## 222. Building an OceanBase-based Distributed Nearly Real-time Analytical Processing Database System

**arXiv ID:** 2602.07584 | [PDF](https://arxiv.org/pdf/2602.07584v1)

**作者:** Quanqing Xu `[一作]` (OceanBase), Mingqiang Zhuang `[通讯]` (OceanBase)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 OceanBase Mercury——一种面向万亿级别、支持近实时 OLAP 的混合列/行数据库系统。

**💡 创新点**

核心创新在于：1）在 LSM‑Tree 中实现基线列存与增量行存的动态混合；2）基于 MV 的增量刷新与全刷新双模式；3）支持三种列数据格式的向量化执行引擎。

**🔧 技术方法**

技术实现包括：分布式共享无共享架构、MVCC 与多副本 Paxos、列存压缩编码（前缀、相等、子串）、数据跳过索引、向量化操作（Sort/Hash Join/Group By）及 SIMD 加速。

**📊 数据集**

使用公开基准 TPC‑H、TPC‑DS 与 ClickBench（1 TB 规模）以及内部业务表做压缩与查询实验。

**📈 对比分析**

与 StarRocks、ClickHouse、Doris 等系统在同等硬件上对比，OceanBase Mercury 在大多数查询中实现了 20%–30% 的冷/热跑延迟降低，单查询可达 4–5 倍加速，整体查询总时延比专用 OLAP 引擎高 1.3–3.1 倍。

**⚠️ 局限性**

局限性包括：列存模式下的写入成本与增量合并开销、I/O 竞争导致 OLTP 受限、向量化引擎在小数据或 I/O‑bound 任务下产生初始化开销、需要细粒度资源隔离与压缩调优。

---

## 223. ADCanvas: Accessible and Conversational Audio Description Authoring for Blind and Low Vision Creators

**arXiv ID:** 2602.07266 | [PDF](https://arxiv.org/pdf/2602.07266v1)

**作者:** Franklin Mingzhe Li `[一作]` (Carnegie Mellon University), Shaun K. Kane `[通讯]` (Google Research)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b88c6eac-d57a-4623-a604-1f401f3eb268` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

开发了一款无视觉操作、基于多模态LLM和会话式 AI 的音频描述（AD）创作工具 ADCanvas，让盲人/低视障创作者能够独立生成、编辑和审核 AD 脚本。

**💡 创新点**

创新点在于将屏幕阅读器友好的键盘控制、实时视觉问答、脚本生成与可编辑时间线集成，形成协作式 AI 助手，并提供可配置的交互模式与细粒度编辑控制，突破传统可视化 AD 工具的可访问性瓶颈。

**🔧 技术方法**

技术实现依赖 Gemini 2.5 Pro/Flash 多模态 LLM、文本到语音（TTS）模型、WebVTT 编辑器、HTML/JavaScript/CSS 前端，配合键盘热键与屏幕阅读器交互。

**📊 数据集**

评估使用了三段视频（教学、娱乐、纪录片）和 12 名 BLV 参与者的实验数据；未使用公开的大规模视频数据集，而是通过参与者生成的 AD 脚本与日志进行分析。

**📈 对比分析**

通过 12 名 BLV 创作者的实验和问卷，10/12 评分 7/7，显示工具对可访问性和工作效率具有显著提升；尚未与传统可视化 AD 编辑器进行定量对比，但在可访问性和流程完整性上优于现有工具。

**⚠️ 局限性**

局限性包括：模型在信息准确性和解释性上仍有错误、对细粒度时间控制（毫秒级）支持不足、缺乏专业音频波形视图、仅在实验室环境和简短无对话视频上测试，未验证对更长或对话丰富内容的适用性。

---

## 224. Equipping LLM with Directional Multi-Talker Speech Understanding Capabilities

**arXiv ID:** 2602.07211 | [PDF](https://arxiv.org/pdf/2602.07211v1)

**作者:** Ju Lin `[一作]` (Meta), Florian Metze `[通讯]` (Meta)

**通讯引用:** 8028 | [OpenAlex ID](https://openalex.org/A5085262529)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

在智能眼镜场景下，提出两种方法使大型语言模型具备方向性多说话人语音理解能力：一是基于源分离的级联系统；二是利用序列化输出训练（SOT）的端到端系统。

**💡 创新点**

创新点在于将多麦克风阵列的方向性信息与LLM融合，既有基于源分离的标签推断方式，也有利用NLCMV波束与LoRA微调实现的SOT方式，实现对近场说话人（佩戴者）与远场说话人（交谈伙伴）的实时区分与处理。

**🔧 技术方法**

采用短时傅里叶变换（STFT）特征的编码‑解码网络进行源分离，Beamforming（NLCMV）+单通道输入配合LoRA微调，Gemma‑3n 4B LLM进行多模态推理，并使用基于RMS比值的说话人标签判定或SOT标签训练。

**📊 数据集**

使用Common Voice、Multilingual LibriSpeech、Fleurs 以及通过真实房间脉冲响应模拟的5麦克风阵列数据进行训练与评估，数据覆盖英语、法语、西班牙语、意大利语四种语言。

**📈 对比分析**

与多通道RNN‑T ASR和JSTAR翻译系统相比，SS+SLM在说话人归属错误率（SA）几乎为零、WER 下降、BLEU 提升至 22–25；SOT+SLM在处理重叠说话方面更稳健，但在部分语言对的SA 与 BLEU 上略逊于 SS+SLM。

**⚠️ 局限性**

SS+SLM 不能处理说话重叠场景；SOT+SLM 由于同时输出转写与翻译，易出现指令跟随混乱，导致说话人归属错误率略高，且整体参数调优受 LoRA 规模限制。

---

## 225. Gaussian Match-and-Copy: A Minimalist Benchmark for Studying Transformer Induction

**arXiv ID:** 2602.07562 | [PDF](https://arxiv.org/pdf/2602.07562v1)

**作者:** Antoine Gonon `[一作]` (Institute of Mathematics), Nicolas Boumal `[通讯]` (Institute of Mathematics)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了Gaussian Match-and-Copy（GMC）这一基于高斯噪声的最小化检索任务，用以研究Transformer中匹配复制（PTH→IH）机制及其隐式最大间隔偏置；

**💡 创新点**

创新点在于设计了既能阻止记忆短路又易于理论分析的检索任务，并在满足特定几何事件下证明梯度下降会收敛到最大间隔解；

**🔧 技术方法**

使用的技术包括Transformer及其两层最小化注意力架构、均方误差损失、梯度下降隐式偏置分析以及与多种序列模型的对比实验；

**📊 数据集**

主要使用了自生成的高斯噪声上下文与查询样本，随后在Omniglot等少样本分类数据上进行迁移学习验证；

**📈 对比分析**

在相同参数与计算预算下，Transformer在GMC任务上明显优于RNN、SSM等模型；预训练模型在Omniglot上达到高准确率并显著降低 FLOPs；

**⚠️ 局限性**

限制在于证明仅适用于极简高斯任务，未涵盖更复杂文本场景；依赖特定几何事件与MSE假设，推广性受限。

---

## 226. AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization

**arXiv ID:** 2602.07054 | [PDF](https://arxiv.org/pdf/2602.07054v1)

**作者:** Ashutosh Chaubey `[一作]` (Institute for Creative Technologies), Mohammad Soleymani `[通讯]` (Institute for Creative Technologies)

**通讯引用:** 11344 | [OpenAlex ID](https://openalex.org/A5024169758)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了 EmoReAlM 评测基准和 AVEm‑DPO 优化方法，用于评估并提升多模态大型语言模型在情感理解中的推理与抗幻觉能力。

**💡 创新点**

创新点在于：1）构建覆盖情感推理、模态一致性与幻觉检测的 4000 题 MCQA 基准；2）设计基于提示的模态偏好、情感响应偏好与文本先验去偏差的三阶段 Direct Preference Optimization（DPO）框架 AVEm‑DPO。

**🔧 技术方法**

使用技术包括：多模态 DPO、提示式模态偏好（PMP）、情感响应偏好（ERP）、文本先验去偏差（TPD）以及自动生成偏好数据和人类验证。

**📊 数据集**

数据集涵盖：DFEW、RAVDESS、MER2023、EMER 作为基准；用于偏好训练的 MAFW、MER2025；评测基准 EmoReAlM 采用 DFEW 视频并自动生成 4000 题 MCQA。

**📈 对比分析**

与基线（EmotionLLaMA、VideoLLaMA、Qwen‑2.5 Omni 等）和其他 DPO 变体（Naive‑DPO、Vista‑DPO）比较，AVEm‑DPO 在 EmoReAlM 上的平均准确率从 65% 提升至 92%，在模态一致性与压力测试中分别提升约 20–30%。在现有情感识别基准上也表现出显著的零样本提升。

**⚠️ 局限性**

局限性包括：1）基准仅基于 DFEW，可能存在文化偏差；2）对较少样本情绪（如 disgust）表现仍不佳；3）在长时序视频情感推理上未作验证；4）训练数据多为自动生成，仍需更多人工校验。

---

## 227. Astro: Activation-guided Structured Regularization for Outlier-Robust LLM Post-Training Quantization

**arXiv ID:** 2602.07596 | [PDF](https://arxiv.org/pdf/2602.07596v1)

**作者:** Xi Chen `[一作]` (Beijing Institute of Technology), Guoren Wang `[通讯]` (Hebei Province Key Laboratory of Big Data Science and Intelligent Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了 Astro，一种基于激活引导的结构化正则化框架，用于在不增加推理延迟的前提下，针对大语言模型的权重后训练量化中出现的异常值进行有效抑制，从而显著提升低比特量化的准确性。

**💡 创新点**

创新点在于①利用大模型平坦极小点的理论性质，证明存在可在保持原始损失几乎不变的等价解空间；②在此空间内通过激活幅值驱动的结构化正则化，针对高激活组的权重异常值进行激进压制；③采用闭式近似的 L∞ 近端梯度方法，实现高效无延迟的权重量化预处理。

**🔧 技术方法**

核心技术包括：平坦极小点理论分析、基于激活幅值的可调正则化系数、L∞ 正则化的投影操作（近端梯度下降）以及与 GPTQ 等现有 PTQ 方法的无缝集成。

**📊 数据集**

实验使用 LLaMA‑2 系列模型（7B、13B、70B）和 LLaMA‑3.1，校准数据选取 WikiText‑2 的 128 条序列；在多种量化位宽（2/3/4‑bit）下评估 perplexity、零样本和 5‑shot 任务。

**📈 对比分析**

与 RTN、GPTQ、AWQ、OmniQuant、SpinQuant、MagR 等主流方法比较，Astro 在 2‑bit 时显著降低 perplexity，3‑bit 时与 SpinQuant 相当但量化时间缩短约 50%，同时在多任务零/少样本评测中保持更均衡的性能。

**⚠️ 局限性**

局限性包括：对平坦极小点假设的依赖（可能不适用于所有模型）；正则化超参数 β 的选择仍需经验调优；在极低比特（如 1‑bit）或非常大模型上验证尚未展开。

---

## 228. RECITYGEN -- Interactive and Generative Participatory Urban Design Tool with Latent Diffusion and Segment Anything

**arXiv ID:** 2602.07057 | [PDF](https://arxiv.org/pdf/2602.07057v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 229. ShallowJail: Steering Jailbreaks against Large Language Models

**arXiv ID:** 2602.07107 | [PDF](https://arxiv.org/pdf/2602.07107v1)

**作者:** Shang Liu `[一作]` (University of Louisville), Zeyan Liu `[通讯]` (University of Louisville)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了ShallowJail攻击方法，通过在生成初始token时注入steering向量来绕过LLM的安全对齐，导致模型产生有害输出。

**💡 创新点**

创新在于利用浅层安全对齐弱点，将对齐失效定位于生成初始token，并通过无训练的激活向量控制隐藏状态实现黑盒攻击。

**🔧 技术方法**

使用激活向量注入（activation steering）、梯度无关的无监督向量构造、LLM推理时隐藏层干预等技术。

**📊 数据集**

使用了AdvBench、MaliciousInstruct、ForbiddenQuestions三大恶意提示集合共计1010条样本，以及Qwen3-4B、Qwen2.5-7B、Llama-3.1-8B三款开源对齐LLM。

**📈 对比分析**

与直接提示对比，ShallowJail在ASR上提升至0.90-0.97，PPL虽升高但保持可接受流畅度，Distinct-2-Gram分数高于自然响应，显示攻击效果显著。

**⚠️ 局限性**

局限在于需要对目标模型的隐藏状态进行干预，对不同模型的参数调优依赖经验；攻击侧重浅层token，深层影响有限；未评估对多模态或强化学习模型的适用性。

---

## 230. The Laplacian Keyboard: Beyond the Linear Span

**arXiv ID:** 2602.07730 | [PDF](https://arxiv.org/pdf/2602.07730v1)

**作者:** Siddarth Chandrasekar `[一作]` (University of Alberta), Marlos C. Machado `[通讯]` (University of Alberta)

**通讯引用:** 1024 | [OpenAlex ID](https://openalex.org/A5085413987)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `3f18e8e3-0266-457c-8567-9039b6d2394d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了 Laplacian Keyboard（LK），一种利用图拉普拉斯特征构建选项库并通过元策略按顺序拼接选项，以在离线奖励无关数据上实现任务无关、样本高效的强化学习框架。

**💡 创新点**

①将图拉普拉斯特征同时作为奖励逼近基底和行为基底；②利用 Universal Successor Feature Approximator 自动生成无任务先验的选项；③通过元策略实现对选项的动态组合，突破线性基底的表达限制。

**🔧 技术方法**

图拉普拉斯特征提取、Universal Successor Feature Approximator、离线奖励无关数据集、元策略训练（TD3）、零样本线性回归、奖励函数重构误差分析。

**📊 数据集**

DeepMind Control Suite（Cheetah、Quadruped、Walker）离线探索数据、Item‑Collector 网格世界数据。

**📈 对比分析**

与 Forward‑Backward 表示法、平面 TD3 以及 Option Keyboard Basis 进行比较；零样本性能与 FB 相当、接近上界；在 200K 次交互后 LK 超过零样本并在样本效率上优于平面 TD3；与 OKB 对比，LK 在无手工奖励特征情况下接近 OKB。

**⚠️ 局限性**

基底维数有限时可能无法近似高频奖励；对离线奖励无关数据的依赖；元策略的优化与选项终止时间的手工设定；在某些任务（如 Quadruped）零样本已近优，层次组合提升有限。

---

## 231. RustCompCert: A Verified and Verifying Compiler for a Sequential Subset of Rust

**arXiv ID:** 2602.07455 | [PDF](https://arxiv.org/pdf/2602.07455v1)

**作者:** Jinhua Wu `[一作]` (Shanghai Jiao Tong University), Linglong Meng `[通讯]` (University of Minnesota)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

本文实现了一个基于Coq的Rust编译器前端RustCompCert，能够将Rustlight（Rust的核心子集）经过借用检查、Drop展开等优化后编译为CompCert的Clight，并通过与CompCert后端链接实现端到端的语义保持与内存安全保证；

**💡 创新点**

创新点在于将Rust的Polonius借用检查算法重新实现为Kildall框架下的抽象域和转移函数，并使用并查集维护区域等价关系，从而实现了可验证的借用检查；

**🔧 技术方法**

采用了Coq（Rocq）进行形式化验证、CompCert的优化编译框架、Kildall的数据流分析框架、并查集结构以及Rust的Polonius算法；

**📊 数据集**

主要使用Rustlight这一Rust核心子集作为验证对象，未涉及具体外部数据集；

**📈 对比分析**

本文未给出针对性能的定量对比，侧重于证明语义保持和安全性，若与rustc对比则在功能覆盖上相对有限；

**⚠️ 局限性**

局限性包括：仅验证Rustlight子集，未覆盖并发、多态、特征、闭包等特性；借用检查仅提供部分安全保证，仍可能出现除借用错误之外的未定义行为；

---

## 232. On the Importance of a Multi-Scale Calibration for Quantization

**arXiv ID:** 2602.07465 | [PDF](https://arxiv.org/pdf/2602.07465v1)

**作者:** Seungwoo Son `[一作]` (Samsung Research), Yongkweon Jeon `[通讯]` (Samsung Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在LLM的后训练量化中，提出一种长度感知的Hessian估计方法MaCa，改进了传统固定长度校准的不足。

**💡 创新点**

创新点在于：①把多尺度序列长度信息嵌入Hessian估计；②将每条序列视为独立样本并做长度归一化，消除长序列对统计的偏倚，得到更丰富、更稳定的Hessian。

**🔧 技术方法**

使用的方法包括：Hessian分解 H_in⊗H_out、GPTQ/GPTAQ量化框架、长度归一化的样本级累加，以及多尺度长度抽样校准。

**📊 数据集**

数据集：校准采用C4训练集；评估使用八个零样本任务（BoolQ、PIQA、SIQA、HellaSwag、WinoGrande、ARC-easy/挑战、OpenBookQA）和LongBench（MultiFieldQA、NarrativeQA、Qasper）。

**📈 对比分析**

与GPTQ/GPTAQ做对比，保持相同的校准令牌预算（524,288 token），MaCa在多种LLM（Qwen3、Gemma3、LLaMA3）上提升平均零样本准确率，3bit提升最多+5.5点，2bit/g128提升+8.7点；在LongBench单文档QA任务上亦持续取得正向改进。

**⚠️ 局限性**

局限性包括：仅针对Hessian‑based PTQ方法，未必能直接迁移到所有量化框架；仍需在更大规模模型与更丰富任务上进一步验证；对极低精度（≤1bit）或非文本任务的适用性尚不明朗。

---

## 233. Evaluating Retrieval-Augmented Generation Variants for Natural Language-Based SQL and API Call Generation

**arXiv ID:** 2602.07086 | [PDF](https://arxiv.org/pdf/2602.07086v1)

**作者:** Michael Marketsmüller `[一作]` (International University of Applied Sciences), Tim Schlippe `[通讯]` (International University of Applied Sciences)

**通讯引用:** 1037 | [OpenAlex ID](https://openalex.org/A5019720894)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

评估三种检索增强生成（RAG）变体在企业级 SQL 与 REST API 生成任务中的表现，并构建了覆盖两种任务的 631 条 SAP Transactional Banking 文档测试集。

**💡 创新点**

首次在同一数据集上对标准 RAG、Self‑RAG 与 CoRAG 进行系统对比，揭示 CoRAG 在混合数据库与 API 文档环境下显著优于其他变体，成为最鲁棒的方案。

**🔧 技术方法**

采用检索增强生成技术，使用 OpenAI 的嵌入模型 + ChromaDB 向量检索 + GPT‑5 生成模型；实现三种 RAG 策略（标准、Self‑RAG、CoRAG）。

**📊 数据集**

使用从 SAP Transactional Banking（TRBK）公开的 OpenAPI 与数据库模式生成的 631 条手工校验的 SQL（346 条）和 API（285 条）测试用例。

**📈 对比分析**

在数据库、API、混合三种文档上下文下共 18 个实验配置进行对比；RAG 能将执行准确率从 0% 提升至 71‑79%；CoRAG 在混合场景下获得 10.29% exact‑match、68.93% 执行准确率，显著优于标准 RAG（7.45%）和 Self‑RAG（8.54%）。

**⚠️ 局限性**

实验仅为单轮任务，使用单一 GPT‑5 模型，域限定为 SAP TRBK，执行环境为模拟，缺乏多轮对话和多参考评估，可能低估实际性能；结果难以直接推广至其它行业或更复杂的交互场景。

---

## 234. Thermal odometry and dense mapping using learned ddometry and Gaussian splatting

**arXiv ID:** 2602.07493 | [PDF](https://arxiv.org/pdf/2602.07493v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 235. Talk, Judge, Cooperate: Gossip-Driven Indirect Reciprocity in Self-Interested LLM Agents

**arXiv ID:** 2602.07777 | [PDF](https://arxiv.org/pdf/2602.07777v1)

**作者:** Shuhui Zhu `[一作]` (University of Waterloo), Pascal Poupart `[通讯]` (University of Waterloo)

**通讯引用:** 16971 | [OpenAlex ID](https://openalex.org/A5040035859)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于大语言模型的公开口语八卦网络（ALIGN），通过层级化的非结构化口头八卦实现去中心化自利代理间的间接互惠与社会规范协调；

**💡 创新点**

创新点在于利用LLM生成的多层次评价语调来传递行动信息与规范判断，弥补传统二元声誉系统的不足；

**🔧 技术方法**

核心技术包括两个LLM模块（八卦生成与行动决策）、反思记忆、公开八卦协议（五层语调）以及自我调节的策略更新；

**📊 数据集**

数据集为四类实验环境：重复捐赠游戏、间接互惠游戏、连续投资场景与交易市场，每种环境下使用多种Chat与推理型LLM（如GPT‑4o Mini、DeepSeek‑V3.1、Gemini 2.5、LLaMA 4等）；

**📈 对比分析**

与无八卦基线及二元信号、无反思、无平衡知识的消融实验相比，ALIGN显著提升合作比例、折现收益与Gini公平性；在恶意入侵与噪声八卦下仍保持高合作；

**⚠️ 局限性**

局限在于对LLM推理能力的高度依赖、对语言环境与文化偏见的敏感、未在真实多主体系统中验证、以及潜在的隐私与诽谤风险。

---

## 236. From Out-of-Distribution Detection to Hallucination Detection: A Geometric View

**arXiv ID:** 2602.07253 | [PDF](https://arxiv.org/pdf/2602.07253v1)

**作者:** Litian Liu `[一作]` (Qualcomm AI Research), Roland Memisevic `[通讯]` (Qualcomm AI Research)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过把大型语言模型（LLM）的幻觉检测重新框架为离群检测（OOD），提出两种基于几何不确定性的训练‑free、单样本检测器（NCI 与 fDBD），并针对LLM的结构做了适配与改进。

**💡 创新点**

创新点主要有：
1) 把幻觉检测转化为 OOD 检测，首次将 OOD 里的几何不确定性（特征到权重向量的相似度、特征到决策边界的距离）迁移到 LLM token 生成；
2) 通过解析推导得到训练特征均值的近似点，避免了对大规模训练数据的统计估计；
3) 对 fDBD 进行 top‑k 约束，显著降低了在巨量词表上的计算量，同时提升检测效果；
4) 在随机解码（stochastic decoding）环境下验证了方法的鲁棒性。

**🔧 技术方法**

技术手段包括：
- 采用 NCI（特征到权重向量的余弦距离）和 fDBD（特征到决策边界的欧氏距离）作为不确定性评分；
- 对训练特征均值使用解析近似（决策中性最近点）；
- 对 fDBD 的距离计算限制在 top‑k 高概率词，减少 O(|V|) 复杂度；
- 通过对每一步的评分求平均或几何平均得到序列级幻觉分数；
- 在不同温度下的贪婪与随机解码上进行评估。

**📊 数据集**

使用的数据集主要有：
- CSQA（commonsense 推理多选题）
- GSM8K（算数推理自由文本题）
- AQuA（算数推理多选题）
- 以及对应的模型训练/验证集。测试模型包括 Llama‑3.2‑3B‑Instruct、Qwen‑2.5‑7B‑Instruct、Qwen‑3‑32B 等。

**📈 对比分析**

与多种基线比较：Perplexity、Predictive Probability、LN Predictive Probability、Max P、P(True)、CoE‑R/CoE‑C、Lexical Similarity、SelfCheckGPT‑NLI、Semantic Entropy 等。实验表明：
- 在 CSQA 上 NCI 取得 66.07 AUROC，fDBD 69.24 AUROC，均优于 Perplexity 63.23；
- 在 GSM8K 与 AQuA 上同样取得显著提升，fDBD 在大多数模型上保持最优；
- 单样本、训练‑free 的特性使得方法在算力和延迟上具有优势。

**⚠️ 局限性**

局限性：
- fDBD 的计算仍受词表大小限制，需要设置 top‑k 超参数；
- 对随机解码的精细对齐仍可能在极少数步骤产生误差，虽然整体影响小；
- 目前评估集中在推理类任务，缺乏对对话、生成式写作等更复杂场景的验证；
- 解析近似均值的假设在极端数据分布下可能不稳健。

---

## 237. VLRS-Bench: A Vision-Language Reasoning Benchmark for Remote Sensing

**arXiv ID:** 2602.07045 | [PDF](https://arxiv.org/pdf/2602.07045v1)

**作者:** Zhiming Luo `[一作]` (Wuhan University), Bo Du `[通讯]` (Wuhan University)

**通讯引用:** 29747 | [OpenAlex ID](https://openalex.org/A5060042752)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 VLRS‑Bench，一个专为遥感复杂推理设计的多模态大模型基准，覆盖认知、决策和预测三大维度，共 2,000 题目。

**💡 创新点**

创新点包括：①将遥感任务拆解为三层级（Cognition‑Decision‑Prediction）并细化为 14 个子任务；②构建高度自动化的 QA 生成管道，融合 DSM、NIR、专家像素级掩模等遥感先验；③提供长文本、长时序的多模态输入，显著提升推理复杂度。

**🔧 技术方法**

技术手段：使用 GPT‑5‑chat 生成 QA 对，采用多模态指令模板，三阶段验证（自动筛选、跨模型交叉验证、人工专家审核）确保质量；评估采用零-shot Prompt，按题型给分，填空使用语义相似度判定。

**📊 数据集**

使用的公开遥感数据集包括：LoveDA、Potsdam、Vaihingen、GID15、DIOR、DOTA、FAIR1M（单时态）以及 Xview2、SECOND、miniUCD、SpaceNet7（多时态）；并通过 SAMRS 将框标注转为分割掩模。

**📈 对比分析**

对比方法：在零-shot 设定下评测 30+ 种 MLLM（GPT‑5、GPT‑4o、LLaMA、Qwen、Claude、Gemini 等通用模型）与 5 个遥感专用模型（GeoChat、VHM、ScoreRS 等）。结果显示通用模型平均分约 0.31‑0.37，遥感专用模型虽规模更小但平均分约 0.32‑0.33，说明域专用设计比单纯参数规模更重要，但整体分数仍远低于人类水平，凸显推理瓶颈。

**⚠️ 局限性**

局限性：①对时空依赖建模不足，导致时序推理表现差；②机制推理和因果推断能力弱；③决策与预测任务中模型易出现过度保守或错误覆盖的策略；④基准目前仅在零-shot 场景下测试，未探究微调或 RL 的提升；⑤数据集仍可能缺乏极端环境和多样化地理场景，限制了覆盖范围。

---

## 238. Parallel Track Transformers: Enabling Fast GPU Inference with Reduced Synchronization

**arXiv ID:** 2602.07306 | [PDF](https://arxiv.org/pdf/2602.07306v1)

**作者:** Chong Wang `[一作]` (Apple), Ruoming Pang `[通讯]` (Apple)

**通讯引用:** 19013 | [OpenAlex ID](https://openalex.org/A5064265174)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并实现了 Parallel Track Transformer（PT），通过将模型拆分为多条独立的 Track 并仅在每隔 D 层后进行 all‑reduce 同步，显著减少跨 GPU 的同步开销，从而提升大型语言模型（LLM）的推理效率。

**💡 创新点**

创新点：1) 结构化的 Track 并行设计，周期性融合取代传统每层同步；2) 通过调节同步间隔 D 控制同步频率，实现可调的通信与计算权衡；3) 与 MoE 结合的 PT‑MoE 架构，为训练与推理提供更高的灵活性。

**🔧 技术方法**

技术手段：采用 TensorRT‑LLM 与 vLLM 两大推理平台；使用 Grouped Query Attention（GQA）减少注意力维度；在 Track 内部并行执行标准 Transformer 层；每隔 D 层使用 all‑reduce 同步；在实验中对 6B、13B、30B 三种规模模型进行训练与推理。

**📊 数据集**

数据集与基准：预训练使用 800B/400B token 语料；评估基准包括 ARC‑C/E、HellaSwag、PIQA、SciQ、WinoGrande、TriviaQA、MMLU、GSM8K、MATH、HumanEval 等，覆盖多模态与推理任务。

**📈 对比分析**

比较方法与性能：与同规模稠密 Dense 模型在模型质量（各基准分数）和推理性能（TTFT、TPOT、吞吐量）进行对比；实验显示 PT 在 D=2/4/8 设定下，TTFT 下降 15‑30%，TPOT 下降 2‑12%，吞吐量提升最高 31.9%；在 13B/30B 模型中几乎无精度损失；在 TensorRT‑LLM 与 vLLM 两个平台上均取得可观的速度提升。

**⚠️ 局限性**

局限性：1) 对于小规模模型或极大 D，精度可能略有下降；2) 同步仍存在，但周期化后需要更精细的 D 调参；3) 目前实现依赖于特定推理框架的扩展，通用性受限；4) 对 Token 级动态路由（如 MoE）与多种负载平衡策略的兼容性未充分验证。

---

## 239. Beyond Pooling: Matching for Robust Generalization under Data Heterogeneity

**arXiv ID:** 2602.07154 | [PDF](https://arxiv.org/pdf/2602.07154v1)

**作者:** Ayush Roy `[一作]` (State University of New York Buffalo), Vishnu Suresh Lokhande `[通讯]` (State University of New York Buffalo)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `40105733-5154-44cd-8090-a8cab9e64b07` `e15e3743-5ee0-4d5f-813d-d146868082fc` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

提出一种基于匹配的聚合框架，通过自适应中心选择样本，替代传统的简单池化或均匀子采样，以提升在异质域上的鲁棒泛化能力。

**💡 创新点**

创新点在于将领域均值视为倾向分数实现双重鲁棒匹配，采用球面几何匹配与方差感知通道注意力（VACA）消除模态偏差，并在有限域和不对称分布下提供无退化理论保证。

**🔧 技术方法**

使用了因果倾向分数匹配、球面距离匹配、正则化Normalizing Flow、VACA通道注意力、CLIP特征映射以及指数移动平均中心更新等技术。

**📊 数据集**

在医学影像零样本异常检测的BMAD基准上进行实验，包含脑MRI、肝CT、视网膜OCT、胸部X光和组织病理图像等五个域。

**📈 对比分析**

与WinCLIP、APRIL-GAN、AnomalyCLIP、AdaCLIP、MVFA-AD、BiLORA等现有方法进行AUC和DA分数比较，匹配方法在所有任务的AUC均相当或更优，且DA分数始终≥4，说明在引入新域时性能不退化。

**⚠️ 局限性**

局限性包括对模态分离程度的假设要求、阈值τ的选择对性能影响较大、实验主要聚焦医学影像领域，跨其他领域的泛化能力待进一步验证，以及匹配集规模增大时计算量上升。

---

## 240. ElliCE: Efficient and Provably Robust Algorithmic Recourse via the Rashomon Sets

**arXiv ID:** 2602.07674 | [PDF](https://arxiv.org/pdf/2602.07674v1)

**作者:** Bohdan Turbal `[一作]` (Princeton University), Lesia Semenova `[通讯]` (Rutgers University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

研究提出 ElliCE 框架，利用椭圆近似 Rashomon 集，对输入实例生成在所有近似模型下均有效的稳健反事实解释。

**💡 创新点**

创新点在于把 Rashomon 集的几何结构建模为椭圆，并通过闭式解析内层最差模型，将稳健反事实问题转化为可解的凸优化，从而获得可证明的有效性、唯一性、稳定性以及特征对齐特性。

**🔧 技术方法**

技术手段包括凸优化（QCQP）、Hessian 近似、闭式求解、梯度搜索、椭圆约束以及可插拔的稀疏/不可变特征约束。

**📊 数据集**

实验使用九个高风险领域的表格数据集：澳洲信贷、FICO、德国信用、Banknote、Parkinson、Diabetes、COMPAS、Wine Quality 与 Iris。

**📈 对比分析**

与 T:Rex、Delta‑Robustness、PROPLACE、ROAR 等基线方法比较，ElliCE 在鲁棒性指标上显著优于基线，且生成速度提升 1–3 个数量级，同时保持更佳的近似度和可解释性。

**⚠️ 局限性**

局限性在于椭圆近似仅捕捉局部 Rashomon 集，尤其对深度网络的全局模型多样性支持不足，且对输入空间的严格理论保证尚未完成。

---

## 241. Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation

**arXiv ID:** 2602.07338 | [PDF](https://arxiv.org/pdf/2602.07338v1)

**作者:** Geng Liu `[一作]` (City University of Hong Kong), Gaofeng Meng `[通讯]` (Centre for Artificial Intelligence and Robotics)

**通讯引用:** 6048 | [OpenAlex ID](https://openalex.org/A5100675867)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `8d10c613-917e-4880-9716-17789f50e119` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出Mediator‑Assistant框架，将多轮对话中的模糊意图通过经验驱动的Refiner转化为明确指令，缓解“Lost in Conversation”现象。

**💡 创新点**

核心创新是把意图理解与任务执行解耦，利用用户历史对比轨迹进行经验蒸馏，构建无参化的Mediator层，在不更新模型参数的前提下实现意图对齐。

**🔧 技术方法**

使用经验驱动的Mediator框架、对比式经验提炼（Refiner）、对话历史构造与上下文意图推断，结合现有LLM（GPT‑4o‑mini、GPT‑5.2、DeepSeek‑V3.2‑Thinking）进行实验。

**📊 数据集**

采用公开的多轮对话模拟基准（LiC benchmark）以及自行构造的成功/失败对比轨迹，覆盖 Code、Database、Actions、Math 四个领域进行评估。

**📈 对比分析**

在 Full、Sharded、w/ Ours 三种设置下对比，使用平均性能 P̅ 和可靠性 R 两个指标；Mediator 方案平均提升约 20% 的 P̅ 与 15% 的 R，跨模型跨领域均显著提升，验证意图对齐是关键。

**⚠️ 局限性**

局限性：经验蒸馏仍为少量非参数化规则，难以捕捉细粒度交互模式；基准用户逻辑单一，缺乏复杂行为；未来需大规模数据与参数化训练以提升泛化与细节把控。

---

## 242. From Dead Pixels to Editable Slides: Infographic Reconstruction into Native Google Slides via Vision-Language Region Understanding

**arXiv ID:** 2602.07645 | [PDF](https://arxiv.org/pdf/2602.07645v1)

**作者:** Leonardo Gonzalez `[一作]` `[通讯]` (Trilogy AI Center of Excellence), Leonardo Gonzalez (Trilogy AI Center of Excellence)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

实现了一套 end‑to‑end 的管道，利用 VLM 提取区域信息并通过 Google Slides API 将静态信息图像重建为可编辑的 Google Slides 幻灯片。

**💡 创新点**

核心创新包括：① 统一、严格的区域 JSON 架构与可重复验证的后处理；② 基于 VLM 的区域提取与可插拔多模型后端；③ 字体尺寸的分段线性校准与碰撞感知宽度扩展；④ 背景合成与裁剪补丁策略；⑤ 通过程序化生成的 “round‑trip” benchmark 进行量化评估。

**🔧 技术方法**

采用了：Vision‑Language Models（如 Gemini、Qwen3‑VL 等）进行文本与图像区域检测；Google Slides API 批量请求实现幻灯片对象创建；几何映射与缩放算法；裁剪、上传与内容地址化的资产管理；字体校准与碰撞检测的文本布局算法。

**📊 数据集**

主要使用自制的程序化数据集：从布局模板、VLM 生成的文本与图像、以及 Slides 生成器构造 29 张 1600×900 的信息图像，用于训练与评估；未直接使用公开图像数据集，但提到了 PubLayNet、DocLayNet 等作为参考。

**📈 对比分析**

采用与 Ground Truth 逐一对齐的 “round‑trip” 评测：计算元素恢复率、字符恢复率、IoU、中心点偏移、CER/WER 等指标。实验结果显示元素恢复率≈0.989，文本 CER≈0.033，图像 IoU 平均≈0.644，说明在可编辑性与布局保真度上表现优异。

**⚠️ 局限性**

局限性包括：① 对复杂矢量图形、渐变、图表等无法完整重建为原生幻灯片对象；② 依赖 VLM 区域提取的质量，文本分割/合并误差会影响可编辑性；③ 背景非均匀时重建效果受限；④ 需要外部图片托管服务才能上传到 Slides API。

---

## 243. When Is Enough Not Enough? Illusory Completion in Search Agents

**arXiv ID:** 2602.07549 | [PDF](https://arxiv.org/pdf/2602.07549v1)

**作者:** Dayoon Ko `[一作]` (Seoul National University), Kyungjae Lee `[通讯]` (LG AI Research)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

研究搜索代理在多约束问题上的幻觉完成现象，并提出Epistemic Ledger评估框架及LiveLedger干预以减少未验证答案。

**💡 创新点**

首次双维度追踪证据与代理信念，系统识别四种失败模式（裸断言、忽略反驳、停滞、过早退出），并通过LiveLedger实时暴露约束状态来缓解这些问题。

**🔧 技术方法**

基于ReAct式多轮搜索代理、LLM推理、评估模型（如GPT）以及自定义Ledger更新算法，实现实时约束状态推送与评估。

**📊 数据集**

构造215个多约束实例，采集自BrowseComp、DeepSearchQA、FRAMES、LiveDRBench和WebWalkerQA五大基准。

**📈 对比分析**

与多种RL训练与提示代理对比，测算准确率与未验证答案率；LiveLedger在所有模型上提升准确率（2–12点）并显著降低未验证答案率（7–27点）。

**⚠️ 局限性**

LiveLedger在小模型上未能完全消除裸断言与忽略反驳问题，且仍存在部分未验证错误，说明需要进一步改进代理对Ledger更新的消化和策略优化。

---

## 244. From Images to Decisions: Assistive Computer Vision for Non-Metallic Content Estimation in Scrap Metal

**arXiv ID:** 2602.07062 | [PDF](https://arxiv.org/pdf/2602.07062v1)

**作者:** Daniil Storonkin `[一作]` (ITMO University), Ilya Makarov `[通讯]` (AIRI)

**通讯引用:** 1833 | [OpenAlex ID](https://openalex.org/A5074238659)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

构建并部署了一套基于计算机视觉的端到端管道，自动估计铁路车厢上废钢的非金属杂质比例并分类废钢类型，同时实现了实时可视化和人工干预的闭环系统。

**💡 创新点**

首次将多实例学习（MIL）与多任务学习（MTL）结合到废钢评估中，使用Transformer骨干（Swin Transformer）实现高精度回归与分类，并通过双盲标注、主动学习等人机协作机制提升模型可靠性。

**🔧 技术方法**

使用多实例学习、注意力池化、共享骨干+多任务头、Transformer（ViT、Swin）、ResNet/EfficientNet等深度网络，以及FastAPI、消息队列、版本化模型服务等系统技术。

**📊 数据集**

基于单一钢铁回收厂的 2000 车厢、58,574 张图像数据集，包含三位标注员的平均值作为标签，并且对每个车厢进行了多层抓取序列分割。

**📈 对比分析**

与传统CNN和单任务方法对比，MIL 模型在车厢层得到 MAE=0.27%、R²=0.83；MTL 模型得到 MAE=0.36%、R²=0.78、F1=0.79，显示出 Transformer 在回归和分类任务上显著优于传统网络。

**⚠️ 局限性**

局限性包括：数据仅来自单一工厂，缺乏跨场景泛化能力；标签来源是三位人工标注的平均，仍带有主观误差；对传感器失效或帧缺失的鲁棒性不足。

---

## 245. Understanding Real-World Traffic Safety through RoadSafe365 Benchmark

**arXiv ID:** 2602.07212 | [PDF](https://arxiv.org/pdf/2602.07212v1)

**作者:** Xinyu Liu `[一作]` (Auburn University), Pan He `[通讯]` (Auburn University)

**通讯引用:** 4506 | [OpenAlex ID](https://openalex.org/A5101439615)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `9cc9baba-5356-466d-81ff-d80028d90279` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了一个大规模视觉‑语言基准RoadSafe365，提供36,196条事故视频及丰富的属性标注、VQA和密集字幕；

**💡 创新点**

提出了与官方交通安全标准一致的双层层级分类法，并基于此开发了结构化标注流水线；

**🔧 技术方法**

采用了多模态大语言模型（如Qwen、InternVL、Gemini）进行评估，并对Qwen2.5‑VL‑7B进行VAU‑R1强化学习微调；

**📊 数据集**

主要使用从Bilibili和X抓取的真实事故视频，也构造了MetaDrive与Dreamland的合成数据；

**📈 对比分析**

在VQA、密集字幕、Fine‑tuning和跨域泛化等四大任务上与多款VLM对比，发现Fine‑tuned Qwen2.5‑VL‑7B在事故/违规类任务上提升至约67%准确率，整体性能优于基线；

**⚠️ 局限性**

仍存在样本分布偏斜、合成数据与真实差距以及对长尾事故场景的鲁棒性不足等局限。

---

## 246. Echoes in the Loop: Diagnosing Risks in LLM-Powered Recommender Systems under Feedback Loops

**arXiv ID:** 2602.07442 | [PDF](https://arxiv.org/pdf/2602.07442v1)

**作者:** Donguk Park `[一作]` (Ulsan National Institute of Science and Technology), Yeon-Chang Lee `[通讯]` (Ulsan National Institute of Science and Technology)

**通讯引用:** 44052 | [OpenAlex ID](https://openalex.org/A5100383157)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

构建了一个基于角色和阶段的诊断框架，模拟LLM在推荐系统中的反馈循环，并系统评估其长期风险。

**💡 创新点**

首次将LLM的功能角色与反馈循环风险结合，提出三阶段诊断（内容生成、推荐、反馈）以及可复现的实验流水线。

**🔧 技术方法**

利用LLM生成的内容、重排序、解释等功能，结合控制实验流水线和三阶段度量指标，分析偏差、幻觉和系统极化。

**📊 数据集**

使用公开基准数据集MovieLens‑1M和Amazon‑Books进行实验。

**📈 对比分析**

对比传统推荐器（LightGCN）与三种LLM增强基线（Cold‑Item Aug、LLMRec、A‑LLMRec），通过偏差间隙、幻觉率和聚类分离度等指标展示LLM组件在长期交互中加剧偏差、产生幻觉并导致表征极化，性能并未提升。

**⚠️ 局限性**

局限包括：仅评估了偏差与幻觉两种风险；实验仅覆盖少数三种角色，缺乏对不同LLM模型、提示设计等因素的深入探讨；并未提供可行的缓解措施。

---

## 247. aerial-autonomy-stack -- a Faster-than-real-time, Autopilot-agnostic, ROS2 Framework to Simulate and Deploy Perception-based Drones

**arXiv ID:** 2602.07264 | [PDF](https://arxiv.org/pdf/2602.07264v1)

**作者:** Jacopo Panerati `[一作]` (National Research Council Canada), Iraj Mantegh `[通讯]` (National Research Council Canada)

**通讯引用:** 603 | [OpenAlex ID](https://openalex.org/A5039964353)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `e0540dec-d77f-42db-94ae-d039248f6393` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了一个开源、端到端的无人机自律栈（aerial-autonomy-stack），实现从感知、自动控制到部署的完整工作流，并支持多架机群与多种飞控（PX4、ArduPilot）。

**💡 创新点**

创新点包括：
• 提供统一的 ROS2 Action 级别的自律接口，跨飞控实现可互换；
• 集成完整的感知管线（YOLOv8 + KISS‑ICP）并实现 10‑30× 的快于实时时间步进；
• 通过 Docker 实现“一次编译，多平台部署”，包括 Jetson Edge、桌面与云端；
• 支持网络化多机仿真和硬件‑仿真（Jetson‑in‑the‑loop、通讯‑in‑the‑loop）以逼真复现 sim‑to‑real 问题。

**🔧 技术方法**

技术栈：ROS2 (Humble)、uXRCE‑DDS/MAVROS、Gazebo Sim、PX4/ArduPilot SITL、YOLOv8 (ONNX/CUDA & TensorRT)、KISS‑ICP、Zenoh、GStreamer、MAVLink、MAVProxy、Docker、NVIDIA Jetson Orin、CUDA、TensorRT、OpenGL/Ogre2。

**📊 数据集**

使用自研的 Gazebo 场景与传感器模拟（空旷、平原、城市、山地）产生 RGB（320×240@8Hz）和 360° LiDAR（4Hz）数据，未使用公开真实数据集。

**📈 对比分析**

通过在 i9‑13 + RTX3500 硬件上对 1/2/4/6 架无人机进行实验，比较无感知、仅摄像、仅激光、摄像+激光四种负载；记录实时因子 RTF，单实例 10–20×，双实例 20–30×；相同工作负载在 PX4 与 ArduPilot 上均保持超实时时间，表明系统计算瓶颈主要在 CPU 与通信。

**⚠️ 局限性**

局限性：仅支持多旋翼和四旋翼/垂直起降（VTOL）机型；缺乏多传感器融合与 SLAM 集成；未实现端到端学习与 RL；外部真实环境验证尚缺；对大型机群或非标准机型的支持有限。

---

## 248. SED-SFT: Selectively Encouraging Diversity in Supervised Fine-Tuning

**arXiv ID:** 2602.07464 | [PDF](https://arxiv.org/pdf/2602.07464v1)

**作者:** Yijie Chen `[一作]` (WeChat AI, Tencent Inc), Fandong Meng `[通讯]` (WeChat AI, Tencent Inc)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

针对大语言模型在SFT后RL阶段出现的模式崩溃问题，提出一种在SFT过程中自适应鼓励多样性的训练方法SED‑SFT。

**💡 创新点**

创新点在于：① 引入基于token探索空间的选择性熵正则化，② 结合top‑k累计概率的掩码策略，③ 在保持准确率的同时提升生成多样性，避免全局熵正则导致的精度下降。

**🔧 技术方法**

技术包括：交叉熵（CE）基础训练、熵正则化（L_DE）、top‑k累计概率评估、二值掩码机制、GRPO强化学习以及DeepSpeed分布式训练。

**📊 数据集**

使用的数据集有：SFT阶段的Micomind 20k样本；RL阶段的Math（Level 1）训练集；以及8个数学评测集（AIME24/25、AMC23、GSM8K、MATH500、GAOKAO‑en、OlympiadBench、College‑MATH）。

**📈 对比分析**

通过在SFT‑then‑RL流程中与Cross‑Entropy、GEM、DFT等基线对比，SED‑SFT在Llama‑3.2‑3B‑Instruct和Qwen2.5‑Math‑7B‑Instruct上平均提升RL阶段得分2.06点和1.20点，Self‑BLEU显著下降，表明多样性得到提升。

**⚠️ 局限性**

局限性：① 仅在数学推理任务上验证，缺乏对其他类型任务的泛化评估；② 掩码阈值与k值仍需经验调参；③ 对极高精度要求的任务，熵正则可能导致误差上升，需进一步平衡。

---

## 249. All-Optical Segmentation via Diffractive Neural Networks for Autonomous Driving

**arXiv ID:** 2602.07717 | [PDF](https://arxiv.org/pdf/2602.07717v1)

**作者:** Yingjie Li `[一作]` (Simon Fraser University), Cunxi Yu `[通讯]` (University of Maryland)

**通讯引用:** 1237 | [OpenAlex ID](https://openalex.org/A5029321729)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种全光学的自由空间离子衍射神经网络(DONN)框架，用于RGB图像的语义分割和车道检测；

**💡 创新点**

创新点在于将RGB三通道分别映射到三个独立的DONN通道，并引入光学跳跃连接，显著提升分割精度和模型可训练性；

**🔧 技术方法**

技术包括光学编码、相位调制的多层衍射、光学跳跃连接、MSE/BCE/Dice等损失函数以及PyTorch数值仿真训练；

**📊 数据集**

使用CityScapes（城市街景）、定制室内车道数据集、CARLA仿真驾驶数据集进行实验；

**📈 对比分析**

与单通道DONN、U‑Net等传统方法比较；在CityScapes上IoU为0.71（DONN）对比U‑Net 0.87；在室内车道数据集IoU 0.80，CARLA不同天气/时间下保持较高的检测准确率；

**⚠️ 局限性**

局限在于光照不均导致性能下降、对光分布敏感、分辨率受限、对细节的二值化处理不足，以及硬件实现需更先进的光学器件与集成技术。

---

## 250. LLM-Guided Diagnostic Evidence Alignment for Medical Vision-Language Pretraining under Limited Pairing

**arXiv ID:** 2602.07540 | [PDF](https://arxiv.org/pdf/2602.07540v1)

**作者:** Huimin Yan `[一作]` (Institute of Intelligent Information Processing), Long Chen `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 95191 | [OpenAlex ID](https://openalex.org/A5100333572)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

提出了 LGDEA，一种在医学视觉-语言预训练中利用大语言模型提取诊断证据并以证据层级进行跨模态对齐的方法。

**💡 创新点**

创新点在于将诊断证据空间构建为共享的跨模态空间，利用 LLM 生成证据并通过原型学习、病灶查询以及图传播等机制，将有限的配对数据扩展到海量无配对图像和报告。

**🔧 技术方法**

采用 CLIP 风格的对比学习、LLM 证据抽取（Spark‑Desk、Qwen、LLaMA 等）、原型投影、病灶查询注意力、KL 散度蒸馏以及跨模态关系传播等技术。

**📊 数据集**

在 MIMIC‑CXR、CheXpert、MS‑CXR、MIMIC‑5×200、RSNA Pneumonia、COVID、NIH Chest X‑rays 等公开胸部 X‑ray 数据集上进行预训练和评估。

**📈 对比分析**

与 MedCLIP、GLoRIA、MedKLIP、AFLoc、MedAligner 等主流方法相比，LGDEA 在仅 5%–10% 配对数据下在短语定位、图像–文本检索、零样本分类等任务上均获得了显著提升，甚至能与使用完整配对数据的模型相当。

**⚠️ 局限性**

局限性包括对 LLM 证据抽取质量的依赖、对配对边的稀疏性仍需依赖少量配对数据、计算和内存开销较大，以及当前实验仅聚焦胸部 X‑ray，尚未验证到其他医学影像域的普适性。

---

## 251. BRIDGE: Predicting Human Task Completion Time From Model Performance

**arXiv ID:** 2602.07267 | [PDF](https://arxiv.org/pdf/2602.07267v1)

**作者:** Fengyuan Liu `[一作]` (Mila - Quebec AI Institute), Hugo Larochelle `[通讯]` (Mila - Quebec AI Institute)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种统一的心理测量框架 BRIDGE，利用 2PL IRT 模型从模型在多项基准上的二元成功/失败数据中学习任务的潜在难度，并将该难度与人类完成时间对齐，从而无需人工时间标注即可预测任务难度与模型未来能力。

**💡 创新点**

创新点在于将 IRT 的潜在难度尺度与人类实际完成时间进行对齐，实现模型性能与人类可解释时间的直接映射，并用此尺度对新基准进行时间预测和前沿模型能力的指数增长预测。

**🔧 技术方法**

核心技术包括两参数逻辑斯蒂 IRT（2PL），贝叶斯 MCMC 推断，log-odds 线性校准与指数增长分析，及对多基准数据的联合拟合。

**📊 数据集**

使用的主要数据集：METR（170 任务的人工完成时间标注），以及 SWE‑bench Verified、MLE‑bench、GDPval、Cybench 等无时间标注的基准进行验证与预测。

**📈 对比分析**

与基准方法（基于成功率的 logit 估计）以及 LLM 直接预测人类完成时间的基线比较，BRIDGE 在时间预测上获得更高的准确率（如 92.3% 的任务落在 0.5×–2× 容差范围内）并能逼近 METR 的指数增长结果，预测模型能力在 50% 成功阈值下每约 6 个月翻倍。

**⚠️ 局限性**

局限性包括：(1) IRT 对稀疏响应矩阵的鲁棒性依赖于足够的样本；(2) 校准仅基于 METR 的人类时间标注，可能对不同领域任务产生偏差；(3) 只考虑了二元成功/失败，而未捕捉完成质量或细粒度错误信息；(4) 对人类完成时间的变异性建模不足，未来需加入不确定性估计。

---

## 252. Attention-Driven Framework for Non-Rigid Medical Image Registration

**arXiv ID:** 2602.07088 | [PDF](https://arxiv.org/pdf/2602.07088v1)

**作者:** Muhammad Zafar Iqbal `[一作]` (Quaid-i-Azam University), Imran Razzak `[通讯]` (Mohammed bin Zayed University of Artificial Intelligence)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

提出了一种基于注意力机制的非刚性医学图像配准框架（AD-RegNet），通过双向交叉注意力、区域自适应注意力和多分辨率变形场合成实现对大变形的精准配准

**💡 创新点**

创新点在于将双向交叉注意力与区域自适应注意力结合，显式建模移动与固定图像之间的对应关系，并在多尺度上合成变形场以保持解剖学可解释性和拓扑一致性

**🔧 技术方法**

核心技术包括3D U‑Net骨干、双向交叉注意力模块、区域自适应注意力机制、层次变形场合成、以及联合使用NCC、SSIM、Jacobian正则化等损失函数

**📊 数据集**

使用DIRLab（胸腔4DCT）和IXI（脑MRI）两大公开数据集进行评估

**📈 对比分析**

与多种传统与最新深度学习方法（SyN、VoxelMorph、TransMorph、LL‑Net等）比较，DIRLab上平均TRE降至1.51 mm，IXI上DSC提升至0.759，负Jacobian率低于0.14%，显示出与最先进方法相当甚至优于部分基线的性能

**⚠️ 局限性**

局限包括显存受限需分块训练、未针对多模态（MR‑CT）配准、缺乏临床多中心验证，以及对极端病理变化的鲁棒性待进一步验证

---

## 253. Spectral Gating Networks

**arXiv ID:** 2602.07679 | [PDF](https://arxiv.org/pdf/2602.07679v1)

**作者:** Jusheng Zhang `[一作]` (Sun Yat-sen University), Keze Wang `[通讯]` (Sun Yat-sen University)

**通讯引用:** 2280 | [OpenAlex ID](https://openalex.org/A5088124671)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了 Spectral Gating Networks（SGN），在保持标准 MLP 激活不变的基础上，通过可学习的随机傅里叶特征和门控机制为前馈网络注入频谱能力。

**💡 创新点**

创新点在于：① 将频谱分支与原始激活并行、可控地结合，避免了传统 spline 替代导致的稳定性与效率损失；② 采用可学习的 RFF 取代网格化 spline，解耦频谱分辨率与参数规模；③ 通过门控实现从低频到高频的渐进式学习，兼容预训练权重且不引入冷启动问题。

**🔧 技术方法**

技术手段包括：可学习的 Random Fourier Features（RFF）、通道级门控（sigmoid + LayerNorm）、混合 GELU–Fourier 激活、梯度保持的连续化初始化，以及对比实验中使用的高效稠密线性运算。

**📊 数据集**

使用的数据集涵盖计算机视觉（CIFAR‑10/100、ImageNet‑1K、ResNet/18、ViT‑Tiny 等）、自然语言处理（Wikitext‑103、OpenWebText、GPT‑2）、音频与 PDE 任务（Poisson、Wave、Heat、Burgers）等多模态基准。

**📈 对比分析**

对比方法包括标准 FFN、Spline‑based KAN、GPKAN、FAN 等；在相同参数与训练配置下，SGN 在 CIFAR‑10 上达到 93.15% 最高准确率，在 ImageNet‑1K 上 79.3%，并比 KAN 快 11.7×，在 NLP 任务上亦显著降低 perplexity；整体上在准确率‑效率比上优于对照模型。

**⚠️ 局限性**

局限性：对频谱预算的固定设置可能限制极高频细节的捕捉；在极大模型或极高维输入（如大规模 LLM）下门控与 RFF 的参数开销仍可累积；部分任务中对超参数（如门控初始化、RFF 维度）仍需细致调优。

---

## 254. FlexID: Training-Free Flexible Identity Injection via Intent-Aware Modulation for Text-to-Image Generation

**arXiv ID:** 2602.07554 | [PDF](https://arxiv.org/pdf/2602.07554v1)

**作者:** Guandong Li `[一作]` (iFLYTEK), Yijun Ding `[通讯]` (Suning)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出训练无须微调的双流身份注入框架 FlexID，能在文本提示下保持人物身份并支持姿态、表情、风格等多重编辑。

**💡 创新点**

通过语义层投影和视觉锚定双流设计，并引入上下文感知自适应门控动态平衡语义与视觉约束，突破传统僵硬注入的矛盾。

**🔧 技术方法**

采用 CLIP 视觉编码、ArcFace/EvaCLIP 特征提取、Transformer 投影、跨模态残差注入、对比对齐损失、Flux.1 Diffusion 生成模型及动态权重调度等技术。

**📊 数据集**

在公开 IBench 基准（ChineseID + Editable Long Prompts）上进行评测。

**📈 对比分析**

与 PuLID、DVI、UNO、UMO 等无训练方法对比，在 IBench 的 Facesim、Aesthetic、ClipT 等指标上均取得领先，兼顾身份保真与文本编辑。

**⚠️ 局限性**

目前仅针对单主体，尚未扩展到多主体交互或更细粒度属性分离，且对极端动态场景的鲁棒性待进一步验证。

---

## 255. Semantic-Deviation-Anchored Multi-Branch Fusion for Unsupervised Anomaly Detection and Localization in Unstructured Conveyor-Belt Coal Scenes

**arXiv ID:** 2602.07694 | [PDF](https://arxiv.org/pdf/2602.07694v1)

**作者:** Wenping Jin `[一作]` (Xi'an Jiaotong University), Li Zhu `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 191957 | [OpenAlex ID](https://openalex.org/A5100748869)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种三分支融合框架，在煤炭输送带场景下实现无监督外来物体异常检测与像素级定位。

**💡 创新点**

创新点在于将对象级语义分布、全局语义归因与细粒度纹理匹配三种互补证据并行提取，并通过共识门控融合显著提升低对比度和遮挡场景的鲁棒性。

**🔧 技术方法**

使用冻结的 DINOv2 ViT 作为语义特征提取器，结合 KMeans 聚类、Mahalanobis 统计、闭式归因分析和 PatchCore 纹理记忆库，实现多尺度特征对比与归因。

**📊 数据集**

构建了 CoalAD 数据集，包含 2,490 张正常煤尘图像和 943 张含外来物体的测试图像，并提供像素级掩码。

**📈 对比分析**

与 PatchCore、DRAEM、EfficientAD 等主流基线对比，在 CoalAD 上的图像 AUC、像素 AUC 和 PRO-AUC 均位居前列，显示显著性能提升。

**⚠️ 局限性**

局限性包括对单一分支过度依赖导致的误检、对极低对比度或与背景纹理高度相似的外来物体检测不足，以及融合过程中缺乏自适应置信度调节。

---

## 256. ComPass: Contrastive Learning for Automated Patch Correctness Assessment in Program Repair

**arXiv ID:** 2602.07561 | [PDF](https://arxiv.org/pdf/2602.07561v1)

**作者:** Quanjun Zhang `[一作]` (Nanjing University of Science and Technology), Liang Xiao `[通讯]` (Nanjing University of Science and Technology)

**通讯引用:** 17949 | [OpenAlex ID](https://openalex.org/A5068976123)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了基于对比学习和数据增强的预训练语言模型框架，用于自动补丁正确性评估，进一步减少补丁过拟合问题；

**💡 创新点**

创新点在于通过对比学习预训练BERT，使模型学习语义不变的代码表示，并利用语义保持的代码变换生成大规模增量数据，显著提升对过拟合补丁的判别鲁棒性；

**🔧 技术方法**

技术手段包括自监督对比学习、语义保持的代码增强、BERT编码器、以及联合二分类器；

**📊 数据集**

实验使用Defects4J v2.0的835个真实项目，收集了2,274个来自30+ APR工具的标注补丁；

**📈 对比分析**

与7个基线（包括动态、静态、学习型方法和LLM）对比，最终模型在准确率、精度、召回率和F1上分别达到88.35%、87.50%、88.69%和88.09%，比当前最先进方法APPT提高约6.3%准确率；

**⚠️ 局限性**

局限性包括仅在BERT上验证；对语义保持规则的假设可能不完全成立；实验仅在Defects4J基准上进行，缺乏对其他数据集和更强预训练模型的泛化验证。

---

## 257. AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management

**arXiv ID:** 2602.07398 | [PDF](https://arxiv.org/pdf/2602.07398v1)

**作者:** Ruoyao Wen `[一作]` (Washington University in St. Louis), Ning Zhang `[通讯]` (Washington University in St. Louis)

**通讯引用:** 36374 | [OpenAlex ID](https://openalex.org/A5100404886)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一套基于显式内存管理的 LLM 代理防御框架（AgentSys-Memory），通过将工具调用结果在隔离的工作者代理中提炼成结构化 JSON 并仅将合法返回值写入主代理的上下文，从而阻止间接提示注入攻击并降低上下文膨胀导致的决策性能下降。

**💡 创新点**

创新点包括：
- 采用操作系统内存隔离理念的层级代理架构，将主代理与工作者代理分离；
- 采用预先声明的 JSON schema 约束主代理只能接收结构化且经过验证的返回值，显著缩小攻击通道；
- 引入基于事件触发的 LLM 验证器与有限循环的清洗器，动态控制工作者的工具调用并在检测到潜在攻击时自动恢复；
- 通过“工作者→验证器→清洗器”三层链路实现安全、可扩展且低开销的防御。

**🔧 技术方法**

使用的技术有：
- LLM 代理（ReAct/Plan-then-Execute）与工具调用接口；
- 结构化 JSON schema 与语法校验；
- LLM 驱动的验证器（对工具调用的合法性进行判定）与清洗器（去除注入式指令）；
- 事件触发的命令工具检测（只在可能产生副作用的调用上做验证）；
- 层级上下文隔离与递归工作者代理。

**📊 数据集**

使用的公开基准数据集：
- AgentDojo（覆盖 Banking、Slack、Travel、Workspace 四个场景，总 97 个用户任务、629 个注入任务）；
- ASB（10 个评估场景）。
- 还在六个不同基础 LLM（GPT‑4o‑mini、GPT‑4o、GPT‑5.1、Claude‑3.7‑Sonnet、Gemini‑2.5‑Pro、Qwen‑2.5‑7B‑Instruct）上做泛化评估。

**📈 对比分析**

与 10 种现有防御（模型层、检测层、系统层）对比，AgentSys‑Memory 在 AgentDojo 上实现 0.78% ASR、64.36% 正常任务成功率（相较基线提升），在 ASB 上实现 4.25% ASR、保持高效能；在多模型和自适应攻击实验中保持 93% 以上的安全提升；在消耗上仅比基线多 3.25M tokens，质量-成本比最优。Ablation 结果表明，单独的上下文隔离已能将 ASR 降至 2.19%，而完整方案进一步降低到 0.78%。

**⚠️ 局限性**

限制与挑战：
- 验证器依赖 LLM，仍可能出现误判导致攻击漏检或误拒；
- 结构化返回值的字符串字段仍可携带攻击指令，需进一步加强文本过滤；
- 需要预先声明意图 schema，面对未知或高度动态的任务信息结构时实现困难；
- 清洗器与验证器的额外 LLM 调用虽已通过事件触发减少开销，但在极端高频命令场景下仍可能产生显著延迟。

---

## 258. Global Symmetry and Orthogonal Transformations from Geometrical Moment $n$-tuples

**arXiv ID:** 2602.07736 | [PDF](https://arxiv.org/pdf/2602.07736v1)

**作者:** Omar Tahri `[一作]` `[通讯]` (ICB UMR CNRS 6303, Universite de Bourgogne), Omar Tahri (ICB UMR CNRS 6303, Universite de Bourgogne)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `e0540dec-d77f-42db-94ae-d039248f6393` `5b4c1114-4a70-478e-9921-2514ee03850d` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出基于几何矩的 n‑元组（moment n‑tuples）方法，用于在 n 维空间中检测对称性并估计正交变换（旋转与镜像）。

**💡 创新点**

创新点在于构造闭式的 n‑元组描述，直接从高阶矩推导出可变换不变的向量，能够同时识别平面、轴对称以及复合对称，并在无监督条件下估计正交变换。

**🔧 技术方法**

采用高阶几何矩、矩时间变化分析、SVD、正交 Procrustes 方法和迭代优化相结合的技术实现对称检测与变换估计。

**📊 数据集**

使用 McGill 与 ShapeNet 公共三维模型数据集以及自制的二维/三维图像实例进行实验验证。

**📈 对比分析**

与现有基于迭代优化的多平面对称检测方法比较，本文在检测到的对称面数量和计算时间上相当甚至略优，误差均在 10⁻² 级别。

**⚠️ 局限性**

局限性在于仅针对正交变换，无法处理仿射或更一般的线性变换；对高度噪声或极度不对称对象的鲁棒性仍有限。

---

## 259. Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions

**arXiv ID:** 2602.07341 | [PDF](https://arxiv.org/pdf/2602.07341v1)

**作者:** Yicheng Yang `[一作]`, Zhuo Zou `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `9ce7179e-700c-4310-ac2b-91df50ded46e`

**🎯 论文内容**

通过 AR 远程人机交互收集专家演示数据，对柔性手臂抓取任务进行行为克隆预训练，并在此基础上结合对比学习的 Soft Actor‑Critic 强化学习模型，提升学习效率与稳定性。

**💡 创新点**

创新点：1）构建可跨设备、无线远程控制的 AR 演示收集系统；2）将行为克隆与对比学习投影头相结合，显著抑制 RL 策略崩溃；3）对比学习投影头通过最大化专家行为与策略输出的一致性，提升样本效率。

**🔧 技术方法**

采用技术包括：AR 远程人机交互（HoloLens 2 + Unity + ROS TCP）、行为克隆、Soft Actor‑Critic (SAC) + 对比学习投影头、投影头 MLP、事件驱动奖励设计、PyBullet 物理仿真、YOLOv8 视觉感知。

**📊 数据集**

使用自建专家演示数据集（共 15 条轨迹）进行预训练；在仿真中使用 PyBullet 生成的球体与瓶子环境；在真实机器人上收集对应的交互数据。

**📈 对比分析**

与 PPO、SAC、SAC+行为克隆三种基线对比。实验结果显示：我们的算法在球体抓取和瓶子抓取任务中，收敛时间约为 SAC 的 1/4，平均成功率最高（球体 91.8%，瓶子 91.8%），并在仿真与真实环境中均验证了更高的平均奖励与更低的迭代次数。

**⚠️ 局限性**

局限性：1）专家演示数据量仍有限，可能影响泛化；2）仿真与真实物体几何差异导致的 sim‑to‑real 问题；3）对可变形球体的感知不够精准；4）仅针对单臂手系统，未扩展到多智能体或双臂协作；5）缺乏触觉反馈，限制了复杂变形物体的抓取能力。

---

## 260. VERIFY-RL: Verifiable Recursive Decomposition for Reinforcement Learning in Mathematical Reasoning

**arXiv ID:** 2602.07559 | [PDF](https://arxiv.org/pdf/2602.07559v1)

**作者:** Kaleem Ullah Qasim `[一作]` (Southwest Jiaotong University), Muhammad Kafeel Shaheen `[通讯]` (Southwest Jiaotong University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出Verify-RL框架，利用符号微分规则实现可验证递归分解

**💡 创新点**

通过三条可验证性质V1–V3保证子问题更易、解可迁移且关系来源于正式规则

**🔧 技术方法**

使用符号计算、强化学习（GRPO/PPO/DPO）与基于规则的奖励

**📊 数据集**

构建符号微分问题集，共5级难度，生成847个训练样本

**📈 对比分析**

与无课程学习的基线相比，GRPO在最难5级准确率从32%提升至68%，整体提升约40%

**⚠️ 局限性**

仅适用于符号微分领域，模型规模有限，分解树深度限制

---

## 261. Rational Transductors

**arXiv ID:** 2602.07599 | [PDF](https://arxiv.org/pdf/2602.07599v1)

**作者:** Mehryar Mohri `[一作]` `[通讯]` (Google Research), Mehryar Mohri (Google Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出 Rational Transductor——一种在 Transformer 之上增添线性递归（WFA）并通过 Deep Rational Injection 把状态信息注入每一层的模型，解决标准 Transformer 在长度泛化和严格序列逻辑（如 Parity、Modulo Counting、正则语言）上的瓶颈，并保持 O(L+log T) 的并行时间复杂度。

**💡 创新点**

创新点：
1) 将 Weighted Finite Automata 的线性状态转移直接嵌入 Transformer，形成可并行计算的 Rational Head；
2) 通过 Deep Rational Injection 保证每层都能获得无衰减的状态信息；
3) 结构化矩阵参数化（Diagonal+Low‑Rank、Cayley 变换等）实现数值稳定且可学习的递归；
4) 理论证明该架构严格包含所有正则语言、^1‑完整问题，并给出随机 Rational Features 的通用基底与学习稳定性证明。

**🔧 技术方法**

技术方法：
- Weighted Finite Automata 与 Rational Power Series；
- 线性递归与并行前缀扫描；
- Cayley 参数化与 Spectral Normalization；
- 随机特征理论（RKHS、Hankel 核）与低秩正则化；
- Deep Rational Injection 与虚拟张量化（Attention 交互）；
- 梯度稳定性与 Hessian 上界分析。

**📊 数据集**

数据集：主要使用合成算法任务（Parity、Modulo‑k Counting、Boolean Formula Evaluation、正则语言识别等）来检验长度泛化和严格序列逻辑；同时在标准 Transformer 基准上与 S4、Mamba、RWKV、DeltaNet 等进行对比。

**📈 对比分析**

比较方法：在相同序列长度与模型规模下对标准 Transformer、S4、Mamba 等进行训练；评估在超长序列（长度为训练长度的 2‑4 倍）上的准确率。实验显示 Rational Transductor 在所有算法任务上均能实现完全长度泛化，并在保持相近或更低 FLOPs 的前提下显著优于对比模型；在不需要层级序列化的情况下实现 O(L+log T) 的并行性能。

**⚠️ 局限性**

局限性：
1) 仅能捕获正则语言及其加权扩展，无法直接处理上下文无关语言；
2) 线性递归缺乏非线性记忆，某些需要非线性状态更新的任务仍需额外设计；
3) 对状态维度的选择仍需要经验调优；
4) 训练依赖于数值稳定的参数化，若实现不当可能出现梯度消失/爆炸；
5) 在真实 NLP/代码生成等大规模数据上的实证验证尚未充分展示。

---

## 262. Learning Nonlinear Systems In-Context: From Synthetic Data to Real-World Motor Control

**arXiv ID:** 2602.07173 | [PDF](https://arxiv.org/pdf/2602.07173v1)

**作者:** Tong Jian `[一作]` (Analog Devices), Tao Yu `[通讯]` (Analog Devices)

**通讯引用:** 1739 | [OpenAlex ID](https://openalex.org/A5101784020)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了基于Transformer的情境学习（ICL）模型，用于电机的前馈控制，能够在仅使用极少（甚至单个）输入输出样本的情况下，预测实现目标速度所需的电流。

**💡 创新点**

创新点在于：①首次将ICL应用于电机前馈控制；②将信号表示与系统行为学习拆分为两阶段预训练，利用对比损失得到系统级嵌入，可直接作为一次性上下文；③实现了一次性（one-shot）ICL和少量样本微调，显著降低了传统PI与物理模型对精调和大数据的依赖。

**🔧 技术方法**

技术核心包括：Transformer编码器–解码器（采用Encodec结构）对输入/输出信号生成离散词元；系统嵌入模块使用自注意力和相对位置编码；对比损失让相同系统的嵌入聚集；再通过自注意力将嵌入与查询词元结合预测输出；微调时仅更新一层系统行为网络；使用chirp信号做Prompt以覆盖宽频谱。

**📊 数据集**

数据集：①合成数据——60,000条输入/输出对来自20,000个时不变系统（LTI与NTI）；②真实电机数据——来自Trinamic TMC9660的步进机和BLDC电机，包含不同负载和两惯性系统的速度/电流对，用于微调与评估。

**📈 对比分析**

与基准比较：对阶梯/斜坡目标速度，模型在未见负载/电机、两惯性系统等场景下，RMSE分别为0.70/0.48/0.45/1.13，明显优于精调PI（1.36/1.74/1.91/3.64）和物理前馈（0.70/0.76/0.46/1.70），展示了在数据稀缺情况下的性能优势。

**⚠️ 局限性**

局限性：①仅针对时不变系统，无法直接处理时变或高度耦合的动态；②预训练依赖大规模合成数据，若合成分布与真实系统相差过大可能影响迁移；③一次性ICL对提示信号质量敏感，需要手工挑选合适的chirp/波形；④实时推理延迟与模型规模关系未充分评估。

---

## 263. IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory

**arXiv ID:** 2602.07525 | [PDF](https://arxiv.org/pdf/2602.07525v1)

**作者:** Xingliang Hou `[一作]` (Xi’an Jiaotong University), Zhiqiang Tian `[通讯]` (Xi’an Jiaotong University)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 IGMiRAG 框架，构建层次异构超图存储知识，利用 LLM 解析查询直觉策略，引导双向扩散检索，实现高效且深度的检索-生成流程。

**💡 创新点**

创新点：① 模仿人类记忆层级构造层次异构超图；② 通过查询解析器提取直觉层级、匹配度和语义深度三维信息，动态调控检索深度与窗口；③ 设计偏好感知的双向扩散算法（PABD）及自适应上下文窗口，兼顾推理深度与算力。

**🔧 技术方法**

技术手段：LLM‑based 分析器与检索策略解析；HNSW 双焦点索引（全局+局部）；BM25 字符串匹配；双向扩散算法；token 统计与动态窗口；GPT‑4o‑mini 生成。

**📊 数据集**

使用六个公开 RAG 基准：PopQA、MuSiQue、2WikiMultiHop、HotpotQA、Mix、Pathology，涵盖 Simple QA、Multi‑Hop QA 与 Explanatory QA 三类任务。

**📈 对比分析**

对比 Naive RAG、LightRAG、PathRAG、NodeRAG、Hyper‑RAG、Cog‑RAG 等 SOTA，IGMiRAG 在六个基准平均 EM 58.3%、F1 65.9%，在多跳推理上领先 4–13% EM/F1，token 成本与任务复杂度成比例，平均约 6.3k+，比大多数方法低 0.9k，效率与效果兼顾。

**⚠️ 局限性**

局限：直觉策略的准确性受 LLM 生成质量影响；层次异构超图构建与维护成本较高；模型仍依赖 LLM 的推理能力，可能产生误导；实验仅在公开基准上，缺乏真实场景验证。

---

## 264. "Meet My Sidekick!": Effects of Separate Identities and Control of a Single Robot in HRI

**arXiv ID:** 2602.07598 | [PDF](https://arxiv.org/pdf/2602.07598v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

---

## 265. Multicasting Pinching Antenna Systems With LoS Blockage

**arXiv ID:** 2602.07421 | [PDF](https://arxiv.org/pdf/2602.07421v1)

**作者:** Muhammad Fainan Hanif `[一作]` (University of Punjab), Yuanwei Liu `[通讯]` (University of Hong Kong)

**通讯引用:** 35911 | [OpenAlex ID](https://openalex.org/A5076863392)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文研究了在存在视线阻塞（LoS）情况下，多播传输的多孔束天线系统（PASS）中，如何通过最佳分配可移动介电粒子（PA）位置来提升下行多播性能。

**💡 创新点**

创新点在于：①基于MM框架推导出凸代理问题并给出两种求解方法（候选搜索法CSM和二分搜索法BSM）；②对两种方法的计算复杂度做了系统比较；③在阻塞环境下显著优于传统固定天线系统。

**🔧 技术方法**

主要技术包括：MM（Minorization‑Maximization）迭代优化、凸优化与代理函数、候选搜索与二分搜索算法、以及利用Bernoulli随机变量建模LoS阻塞。

**📊 数据集**

使用仿真数据，场景设定为5个PA、5个单天线用户、28 GHz工作频率、噪声功率−90 dBm、PA高度3 m、波导端点D1=−10 m、D2=10 m等参数。

**📈 对比分析**

通过与固定天线系统（CAS）的对比实验，结果表明在不同P_TX和α值下，PASS可获得更高的最小SNR；MM迭代在3-4次内收敛；BSM相较于CSM在用户数增大时具有更低的执行时间。

**⚠️ 局限性**

局限性包括：仅在静态仿真环境下验证；阻塞模型简化为Bernoulli分布；未考虑多跳或多天线配置，且复杂度仍随用户数增长。

---

## 266. W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents

**arXiv ID:** 2602.07359 | [PDF](https://arxiv.org/pdf/2602.07359v1)

**作者:** Xiaoqiang Lin `[一作]` (Salesforce AI Research), Junnan Li `[通讯]` (Salesforce AI Research)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了宽深研究代理（Wide and Deep Agent）框架，利用并行工具调用在单个推理步骤内同时执行多项工具，探索在保持深度（多轮推理）的同时扩大宽度（并行工具调用）的效果，提升深度研究任务的准确率与效率。

**💡 创新点**

创新点包括：① 用并行工具调用替代传统串行调用，显著提升信息检索与验证能力；② 研究宽度-深度权衡，提出多种工具调用调度器（常数、递增、递减、自动）并验证递减策略最优；③ 通过案例分析揭示并行调用提升准确率的机制（源可信度提升、工具结果冗余验证、查询拆分增强检索）。

**🔧 技术方法**

使用的大型语言模型（LLM）有 GPT‑5 Medium、Gemini 3.0 Pro、Claude 4.5 Sonnet；工具集合包括基于 Serper 的搜索、JINA 的爬取+LLM 摘要、Python 解释器；实验框架基于 MCP‑Universe 的 agent 环境；实现并行工具调用的提示工程与调度器指令。

**📊 数据集**

主要数据集有 BrowseComp（前100条/全集）、Humanity's Last Exam（HLE）文本子集（2158条）和 GAIA 文本子集（103条），用以评估不同宽度与深度配置下的性能。

**📈 对比分析**

对比方法：在相同工具数与不同最大轮数限制下，比较单工具调用与并行工具调用（1、2、3、5、8 工具/轮）。结果显示，3 工具/轮的并行调用在 BrowseComp 上取得 68% 准确率（相较单工具 66%），同时平均轮数从 45.7 降至 23.8，墙钟时间与 API 成本分别下降约 40% 和 36%；在 GPT‑5 Medium 全集评测中并行调用达到 62.2% 准确率，超出 GPT‑5‑High 54.9%。

**⚠️ 局限性**

局限性：① 对开源模型的提升有限，效果不如商业 LLM；② LLM 在自动调度工具数时表现不佳，无法自适应“宽度‑深度”权衡；③ 需要进一步研究 RL 或其他方法训练 LLM 能动态选择最佳调用策略。

---

## 267. Expected Recovery Time in DNA-based Distributed Storage Systems

**arXiv ID:** 2602.07601 | [PDF](https://arxiv.org/pdf/2602.07601v1)

**作者:** Adi Levy `[一作]` (Technion Israel Institute of Technology), Han Mao Kiah `[通讯]` (Nanyang Technological University)

**通讯引用:** 1840 | [OpenAlex ID](https://openalex.org/A5083157397)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

本研究启动了基于DNA的分布式存储系统的研究，信息被编码在多个DNA数据存储容器中，以实现对容器故障的鲁棒性。

**💡 创新点**

创新点在于将经典的Coupon Collector问题与DNA存储系统的恢复时间分析相结合，提出了一种新的编码方法以提高数据恢复的效率。

**🔧 技术方法**

使用了最大距离可分离（MDS）编码和一般化的Coupon Collector问题的分析技术。

**📊 数据集**

使用了多个DNA存储容器，每个容器存储n个不同的DNA链，具体数据集未详细说明。

**📈 对比分析**

通过与传统分布式存储系统的比较，分析了MDS编码在DNA-DSS设置中的性能，结果表明MDS编码在恢复时间方面具有良好的表现，但可能不是最优的。

**⚠️ 局限性**

限制在于未考虑存储错误的情况，未来的工作将探讨如何将存储错误纳入模型中。

---

## 268. High Fidelity Textual User Representation over Heterogeneous Sources via Reinforcement Learning

**arXiv ID:** 2602.07333 | [PDF](https://arxiv.org/pdf/2602.07333v1)

**作者:** Rajat Arora `[一作]` (LinkedIn Corporation), Wenjing Zhang `[通讯]` (LinkedIn Corporation)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过强化学习框架将用户多源文本信息压缩为简短、可解释的文本表示，用于LLM驱动的招聘推荐系统。

**💡 创新点**

①无需人工标注，仅用用户点击/申请等隐式信号作为奖励；②结合规则奖励约束长度与格式；③使用LLM评估器作为偏好奖赏模型，实现标签轻量化；④将文本生成作为目标，兼顾显著性与简洁性。

**🔧 技术方法**

RL（GRPO+DRPO+DAPO）、LLM Actor（1.7B预训练模型）与大型奖励模型（30B）相结合，使用PPO式目标、长度惩罚、格式惩罚；评估采用LLM-as-a-judge和离线/在线A/B测试。

**📊 数据集**

LinkedIn平台的真实用户日志（约200k样本，涵盖个人资料、职业记录、搜索行为等），覆盖70M活跃求职者，使用一月的多源数据与随后的两周做验证。

**📈 对比分析**

与全量文本拼接、稠密嵌入、无约束提示等基线相比，点式奖励生成的摘要在离线AUC提升3.5%，在线CTR提升1.48%，Job申请提升1.2%，并在检索层Recall@10提升3%。

**⚠️ 局限性**

受限于奖励信号的稀疏与潜在的“奖励黑客”风险；依赖大规模LLM评估器导致计算成本；对极短文本或低活跃用户的覆盖仍有限；未对多语言或跨域泛化进行充分验证。

---

## 269. Letting Tutor Personas "Speak Up" for LLMs: Learning Steering Vectors from Dialogue via Preference Optimization

**arXiv ID:** 2602.07639 | [PDF](https://arxiv.org/pdf/2602.07639v1)

**作者:** Jaewook Lee `[一作]` (University of Massachusetts Amherst), Andrew Lan `[通讯]` (University of Massachusetts Amherst)

**通讯引用:** 1814 | [OpenAlex ID](https://openalex.org/A5063813962)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过激活层的向量转移，利用真实的导师-学生对话学习并实现不同导师风格的LLM控制，旨在让模型能根据导师个性生成相应的教学对话。

**💡 创新点**

创新点在于：①将导师风格抽象为一个共享的激活方向，并为每位导师学习可调的方向系数；②通过偏好优化（BiPO改进）将导师真实发言与群体平均发言对齐，捕捉风格差异；③在不显式提示的情况下，仅凭对话数据即可实现导师个性化。

**🔧 技术方法**

核心技术包括：基于LoRA的SFT预训练得到群体平均模型；对抗式偏好优化学习共享激活向量与导师系数；激活层注入（activation steering）实现推理时的风格转移；评估使用ROUGE‑L、BLEU、句子嵌入余弦相似度和LLM判定的Win Rate。

**📊 数据集**

使用了某在线数学学习平台的导师‑学生对话数据集，共21位导师，约1.5万轮对话，按80/10/10划分为训练、验证和测试集。

**📈 对比分析**

与无转移的SFT基线相比，激活转移在中后期对话中语义相似度提升约0.04，Win Rate提升至58.7%（相比基线约4%），Lexical相似度略降但可通过缩放因子调节，整体实现了风格对齐且保持大部分词汇一致。

**⚠️ 局限性**

局限性包括：①未显式引入教育学原则或学习效果奖励；②仅学习单一转移方向，可能无法解耦不同教学属性；③仅针对导师进行了转移，学生模型与师生匹配未覆盖；④在极端风格或跨学科场景的泛化能力尚待验证。

---

## 270. Convex Primitive Decomposition for Collision Detection

**arXiv ID:** 2602.07369 | [PDF](https://arxiv.org/pdf/2602.07369v1)

**作者:** Julian Knodt `[一作]` (Lightspeed Studios), Xifeng Gao `[通讯]` (Lightspeed Studios)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

实现了一个自底向上的凸几何原始体分解方法，用于快速生成刚体碰撞体。

**💡 创新点**

创新在于把四元数误差度量与线性算子相结合，使用特征向量自动拟合盒、圆柱、球、棱柱等参数化凸体，并通过体积增量代价控制合并，保持对原始模型的紧致覆盖。

**🔧 技术方法**

使用四边形网格简化(QEM)、线性算子、特征分解、贪婪合并、体积增量代价、重叠检查、顶点合并与层次细节控制等技术。

**📊 数据集**

在Sketchfab公开的60+多样本模型以及扫描模型Wat Benchamabophit上进行实验。

**📈 对比分析**

与V‑HACD、CoACD等方法在Hausdorff/Chamfer距离、字节数和碰撞仿真帧时上进行对比，结果显示本方法在几何误差上更小、字节数更少、每帧时间至少比对手快1~2毫秒，符合游戏性能预算。

**⚠️ 局限性**

局限包括对内部组件和共面面会产生不紧凑的盒子、对高频细节需要更多原始体、对拓扑变化敏感、缺乏曲面原始体，以及合并时可能存在O(n²)的极端情况。

---

## 271. ShapBPT: Image Feature Attributions Using Data-Aware Binary Partition Trees

**arXiv ID:** 2602.07047 | [PDF](https://arxiv.org/pdf/2602.07047v1)

**作者:** Muhammad Rashid `[一作]` (University of Torino), Damiano Verda `[通讯]` (Rulex Innovation Labs)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了 ShapBPT 方法，使用 Owen 近似在二叉分割树 (BPT) 上计算像素级 Shapley 值，以实现对计算机视觉模型的可解释性。

**💡 创新点**

创新点在于将数据感知的多尺度分割树 BPT 与 Shapley 近似结合，既提升了解释效率，又使特征重要性与图像形态更紧密对齐，突破了传统固定网格或预分割的局限。

**🔧 技术方法**

主要技术包括：Owen 公式的 Shapley 近似、基于颜色与几何特征的 BPT 构造、适应性分割策略、像素遮蔽评估、AUC 与 IoU 评价指标。

**📊 数据集**

使用了多种数据集进行评估：ImageNet‑S_50、MS‑COCO、CelebA、MVTec、SwinViT、ResNet50、ViT、YOLO11s，并开展了 20 人用户偏好实验。

**📈 对比分析**

与 AA‑b、LIME‑b、GradCAM、GradExpl、GradShap、IDG、LRP 等方法比较，ShapBPT 在 20 个实验中均获得最高的 AUC、IoU 以及最快的收敛速度，尤其在低预算情况下表现尤为突出。

**⚠️ 局限性**

局限性包括：只能构造二叉分割树，无法直接兼容像 SegmentAnything 等更细粒度分割；计算成本仍不如简单梯度方法；解释效果受分割树质量影响，需进一步研究更通用的层次分割方案。

---

## 272. PTB-XL-Image-17K: A Large-Scale Synthetic ECG Image Dataset with Comprehensive Ground Truth for Deep Learning-Based Digitization

**arXiv ID:** 2602.07446 | [PDF](https://arxiv.org/pdf/2602.07446v1)

**作者:** Naqcho Ali Mehdi `[一作]` `[通讯]` (NED University of Engineering and Technology), Naqcho Ali Mehdi (NED University of Engineering and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `67630363-6be0-4f51-ab05-7198250671a5` `729e5870-4135-47f5-97f2-e3974d07b5dc` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `109c2b71-d051-425c-831f-0c544c24280d`

**🎯 论文内容**

构建了17,271张合成12导联心电图图像及对应完整的多模态标注数据集PTB-XL-Image-17K。

**💡 创新点**

首次提供包含图像、分割掩码、时间序列信号、YOLO框注解和丰富元数据的完整标注，并支持不同网格可见性、速度、电压等参数的可控生成。

**🔧 技术方法**

利用Python框架结合WFDB、NumPy、SciPy、OpenCV等实现基于PTB-XL信号的高质量图像合成、带宽滤波、归一化和像素‑信号校准。

**📊 数据集**

以公开的PTB-XL 21,837条12导联心电记录为底层信号，并在此基础上生成合成图像。

**📈 对比分析**

与现有数据库比较，PTB-XL-Image-17K在多模态标注完整性、分割精度（IoU>0.95）和信号重建相关性（ρ>0.998）上优于ECG-Image-Kit、PMcardio等数据集。

**⚠️ 局限性**

当前仅包含12×1布局、无重叠导联，且缺乏真实纸质衰变与扫描噪声等真实世界失真；未来计划加入重叠、不同布局与增强仿真。

---

## 273. Do We Need Adam? Surprisingly Strong and Sparse Reinforcement Learning with SGD in LLMs

**arXiv ID:** 2602.07729 | [PDF](https://arxiv.org/pdf/2602.07729v1)

**作者:** Sagnik Mukherjee `[一作]` (University of Illinois), Hao Peng `[通讯]` (University of Illinois)

**通讯引用:** 13196 | [OpenAlex ID](https://openalex.org/A5100600099)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究在大型语言模型的可验证奖励强化学习（RLVR）中使用 SGD 优化器，系统比较了 SGD 与 AdamW 在不同模型、任务和 RL 算法下的性能与参数稀疏性。

**💡 创新点**

创新点在于：①证明 SGD 能在 RLVR 下匹配甚至超越 AdamW，②发现动量和自适应学习率在 RLVR 中作用有限，③展示 SGD 产生极高稀疏更新并显著降低显存占用。

**🔧 技术方法**

使用的技术包括：SGD、SGD+Momentum、RMSProp、AdamW；RL 算法 GRPO、PPO；以及对参数更新稀疏性和有效秩的定量分析。

**📊 数据集**

所用数据集涵盖三类任务：数学推理（MATH、AMC、AIME、OlympiadBench、GPQA）、编码（HumanEval、HumanEval+、MBPP、MBPP+）和 RLVE（LeetCode 风格），并在 Qwen3、Llama 等模型上进行实验。

**📈 对比分析**

通过对比训练奖励、验证奖励、Pass@1/10 等指标，实验显示 SGD 在大多数情形下与 AdamW 性能相当甚至更优，同时产生高达 99.99% 的参数更新稀疏度。

**⚠️ 局限性**

局限性包括：实验仅覆盖特定 RLVR 设置与有限步长，未系统探讨不同超参数、长期训练或更广泛模型的适用性；对不同优化器组合的敏感性与更深层机制仍需进一步研究。

---

## 274. Collaborative and Efficient Fine-tuning: Leveraging Task Similarity

**arXiv ID:** 2602.07218 | [PDF](https://arxiv.org/pdf/2602.07218v1)

**作者:** Gagik Magakyan `[一作]`, Asuman Ozdaglar `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 CoLoRA——一种在分布式或联邦环境中通过共享低秩适配器和个性化适配器，实现高效微调大型预训练模型的方法。

**💡 创新点**

创新点：①通过子空间相似度度量捕捉任务相似性；②设计共享全局低秩适配器和每个任务的个性化适配器，参数量仅为 O(dr + kr^2)；③在理论上通过协同 AltMin（CoAltMin）与矩阵感知分析证明收敛与样本复杂度。

**🔧 技术方法**

使用技术：LoRA 架构、子空间相似度度量、协同 AltMin（CoAltMin）优化、矩阵感知理论、Federated Averaging 等；在实验中基于 Qwen2.5-1.5B-Instruct 进行微调。

**📊 数据集**

使用数据集：Natural Instructions（包含 140 个多任务，主要聚焦 Program Execution 子任务）以及对应的 50 条样本数据（极低样本量）。

**📈 对比分析**

比较方法：与 Local LoRA、RoLoRA、FedDPA、ALoRA 等基线在相同联邦设置下对比；实验显示：在任务相似度高时 CoLoRA 的 Rouge‑L 得分显著高于基线（提升约 3–5%），低相似度时 Local LoRA 更优。

**⚠️ 局限性**

局限性：①对任务相似度的度量仍相对粗略；②CoLoRA 的优势依赖于任务相似度足够高；③理论假设（线性回归、子空间相似度）与实际 NLP 任务的差距；④在大规模多语言/多任务场景下需进一步验证。

---

## 275. Humanizing AI Grading: Student-Centered Insights on Fairness, Trust, Consistency and Transparency

**arXiv ID:** 2602.07754 | [PDF](https://arxiv.org/pdf/2602.07754v1)

**作者:** Bahare Riahi `[一作]` (North Carolina State University), Veronica Catete `[通讯]` (North Carolina State University)

**通讯引用:** 866 | [OpenAlex ID](https://openalex.org/A5090781324)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

调查本科生对在区块编程期末项目中使用ChatGPT团队版进行自动评分时的感知，聚焦公平、透明、信任与一致性。

**💡 创新点**

将Jobin 2019 的伦理原则框架与学生感知研究相结合，首次在教育评估中系统比较AI与人类评分在公平、透明、信任与一致性等维度的主观体验，并采用定量 Likert 与定性主题分析相结合的双重方法。

**🔧 技术方法**

技术手段包括：ChatGPT Team 版生成 AI 反馈；5 点 Likert 量表问卷；主题分析（inductive coding）对开放式回答进行编码；使用匿名化的 TA 评分作为对照。

**📊 数据集**

数据集为 27 名计算机科学本科生提交的区块编程期末项目（已匿名化），以及对应的 TA 评分与反馈。

**📈 对比分析**

比较方法：在问卷中让学生分别评价 AI 与 TA 反馈的公平、透明、一致性、信任等指标，并通过平均分与比例进行对比；量化结果显示学生认为 AI 公平 4.2、透明 4.12、信任 4.03；定性结果揭示学生对 AI 清晰度的肯定与对人类情境理解的偏好，说明 AI 在透明度和一致性上表现良好，但在信任和公平感上仍落后于人类评分。

**⚠️ 局限性**

局限性：样本量仅 27 人、仅限一门课程与一类项目，缺乏多课程、多项目的广泛验证；仅测量学生主观感知，未评估 AI 评分的客观准确度；结果难以推广到更大或不同学科的教育场景。

---

## 276. Video-based Music Generation

**arXiv ID:** 2602.07063 | [PDF](https://arxiv.org/pdf/2602.07063v1)

**作者:** Serkan Sulun `[一作]` `[通讯]`, Serkan Sulun

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

暂无可用信息

**💡 创新点**

暂无可用信息

**🔧 技术方法**

暂无可用信息

**📊 数据集**

暂无可用信息

**📈 对比分析**

暂无可用信息

**⚠️ 局限性**

暂无可用信息

---

## 277. Dynamical sequences: closure properties and automatic identity proving

**arXiv ID:** 2602.07576 | [PDF](https://arxiv.org/pdf/2602.07576v1)

**作者:** Jason P. Bell `[一作]` (University of Waterloo), Yuxuan Sun `[通讯]` (University of Toronto)

**关键词:** `847a60d8-a755-47af-ba5d-c5236b9e3083`

**🎯 论文内容**

研究了由代数动力系统生成的序列（动态序列），证明了其在加、乘、偏和/积、平移、子序列、取整等运算下的闭包性质，并给出了判定两动态序列是否相等的算法。

**💡 创新点**

首次证明动态序列包含所有 D^n‑finite、Somos、椭圆可除性序列等经典序列，并提出一种通用的“自动化验证恒等式”方法，扩展了 Wilf‑Zeilberger 方法到非 D‑finite 序列。

**🔧 技术方法**

使用代数几何（射影闭包、Zariski 维数、Groebner 基）和符号计算（SageMath）来构造映射、证明闭包以及实现判定算法；同时运用 D‑finite 与 D^n‑finite 的递归定义。

**📊 数据集**

通过符号实验验证多例子，包括阶乘、超阶乘、Elliptic Divisibility Sequence、Somos‑4、A058635 等 OEIS 序列，使用 SageMath 进行 Gröbner 基计算。

**📈 对比分析**

算法通过构造一条下降的 Zariski 闭包链，终止后仅需检查链终点前的有限项即可判定相等；在示例中，往往只需检查前两三项即可得到结论，表现出快速收敛。

**⚠️ 局限性**

未能证明动态序列在卷积下是否闭合；对于正整数序列的整数性、零值判定以及正增长下的线性递归性等问题仍未解决，且算法在理论上给出的上界往往远大于实践所需。

---

## 278. Debugging code world models

**arXiv ID:** 2602.07672 | [PDF](https://arxiv.org/pdf/2602.07672v1)

**作者:** Babak Rahmani `[一作]` `[通讯]` (Tübingen AI Center, University of Tübingen), Babak Rahmani (Tübingen AI Center, University of Tübingen)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究 Code World Models（CWM），从本地语义执行和长时序状态跟踪两个角度评估其错误模式，并通过控制实验定位错误根源。

**💡 创新点**

提出错误聚类框架：① token‑budget 限制导致的截断；② 由于子词分词导致的字符串状态脆弱；③ 长时序失败主要源于动作错报而非状态更新错误；并展示仅凭密集状态监督即可在 Transformer 上实现数百步的准确状态传递。

**🔧 技术方法**

技术包括：基于 Transformer 的 CWM；使用完整动作–状态训练轨迹；教师强制（teacher‑forcing）评估；子词分词分析；控制性函数组合实验；S5 对称群置换跟踪基准；对比实验与错误分类。

**📊 数据集**

数据集：CruxEval‑O、HumanEval（真实代码评测）；Composition Zoo（非字符串与字符串组合实验）；S5 permutation tracking benchmark（长时序状态跟踪）。

**📈 对比分析**

对比方法：CWM vs. GPT‑5 以及教师强制实验。CruxEval‑O 上 CWM 85.0%→90.4%（+5.4%）；HumanEval 上 91.4%→92%（+0.6%）。Composition Zoo 非字符串深度5保持 100%；字符串深度5仅 25%。在 S5 128 步下，教师强制时 CWM 90% 的准确率，基础设置在 64 步后急剧下降。

**⚠️ 局限性**

局限性：① 由于每一步都输出完整状态，token 消耗极大导致截断；② 字符串状态对子词分词敏感，易错；③ 长时序错误多为动作错报，需改进动作生成；④ 需要更高效的稀疏监督或不同的文本表示方法。

---

## 279. PALMS: Pavlovian Associative Learning Models Simulator

**arXiv ID:** 2602.07519 | [PDF](https://arxiv.org/pdf/2602.07519v1)

**作者:** Martin Fixman `[一作]` (Artificial Intelligence Research Centre City St George's University of London), Esther Mondragón `[通讯]` (Artificial Intelligence Research Centre City St George's University of London)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

**🎯 论文内容**

开发了一个开源的Python仿真器PALMS，用于快速模拟Pavlovian条件作用实验，集成了Rescorla‑Wagner、Pearce‑Kaye‑Hall、Mackintosh Extended、Le Pelley's Hybrid和MLAB等五种注意力模型，并支持配置式提示、随机试次、大规模刺激处理和参数自定义；

**💡 创新点**

提供了统一的平台，使多种注意力模型可以在同一界面下并行比较；实现了跨模型配置式提示计算，支持每个刺激的单独学习率；允许一次性输入数百个刺激，显著提升实验设计的可扩展性；

**🔧 技术方法**

使用Python 3.10+实现，基于Matplotlib绘图、Tkinter/Qt等GUI、命令行接口；通过自定义Stimulus和Model抽象类实现模型逻辑，使用GitHub托管，采用GNU LGPL许可；

**📊 数据集**

以重现文献实验为数据集，输入实验设计脚本（包括分阶段、随机化、参数设置），无需外部实验数据；

**📈 对比分析**

在同一实验设计下自动并行跑不同模型，结果即时绘图，支持图表导出、数据CSV导出；运行速度快，可处理数百刺激，适合大规模模拟；

**⚠️ 局限性**

当前仅覆盖已实现的五种模型，无法完全解释所有实验（如Haselgrove的反向潜伏抑制）；模型参数需手工调校；未考虑动机方向和奖励预测的更复杂机制，限制了对非Pavlovian学习情景的适用性。

---

## 280. Improving Variable-Length Generation in Diffusion Language Models via Length Regularization

**arXiv ID:** 2602.07546 | [PDF](https://arxiv.org/pdf/2602.07546v1)

**作者:** Zicong Cheng `[一作]` (Tsinghua University), Shi-Min Hu `[通讯]` (Tsinghua University)

**通讯引用:** 22511 | [OpenAlex ID](https://openalex.org/A5037233582)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种训练无关的变量长度生成框架，在扩散大型语言模型中将生成长度视为推理变量，并通过长度正则化实现自适应扩展与收缩。

**💡 创新点**

创新性地通过长度置信度信号去除长度偏差，并使用 log L 正则化实现跨长度可比性，同时在推理时采用贪心局部搜索实现双向长度调整。

**🔧 技术方法**

结合扩散 LLM（如 LLADA、Dream 系列）、置信度计算（基于负熵）、线性回归估计长度系数 k 以及贪心搜索的推理流程。

**📊 数据集**

使用代码填充数据集 HumanEval‑Infilling、McEval（四种编程语言），以及通用推理数据集 GSM8K、HumanEval 与 MATH500。

**📈 对比分析**

与固定长度基线、DreamOn、FlexMDM、DAEDAL 等方法比较，平均 Pass@1 在 HumanEval‑Infilling 上提升约 15–30%，在 McEval 多语言填充提升 20–38%，在 MATH500 提升 50%，总体显示显著性能提升。

**⚠️ 局限性**

仍存在多次推理导致延迟的缺点，并且对极长或极短文本的长度估计可能不够稳健。

---

## 281. DSL: Understanding and Improving Softmax Recommender Systems with Competition-Aware Scaling

**arXiv ID:** 2602.07206 | [PDF](https://arxiv.org/pdf/2602.07206v1)

**作者:** Bucher Sahyouni `[一作]` (University of Surrey), Simon Hadfield `[通讯]` (University of Surrey)

**通讯引用:** 4843 | [OpenAlex ID](https://openalex.org/A5091184063)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种新的Dual-scale Softmax Loss（DSL）来改进隐式反馈推荐系统的训练效果，尤其在负样本多样性和分布偏移时表现更稳健。

**💡 创新点**

创新点在于：①针对每个训练实例中的负样本，依据硬度和项目相似度动态加权；②为每个正负对自适应地调节温度，利用竞争强度来决定软化或锐化softmax；这两项改进共同重新塑造了负样本的竞争结构并提高梯度的相关性。

**🔧 技术方法**

主要技术包括：softmax（log-sum-exp）损失、负样本硬度与相似度计算、竞争级联（CA）温度自适应、负样本重加权（κ）分支、KL-DRO理论分析、以及多模型后端（MF、LightGCN）上的实验验证。

**📊 数据集**

使用四个公开数据集：Amazon-Health、Amazon-Electronic、Amazon-Movie、Gowalla，分别在IID与OOD（流行度偏移）两种评估场景下进行实验。

**📈 对比分析**

与多种基线（BPR、LLPAUC、SL、SL@K、AdvInfoNCE、BSL、PSL等）对比，DSL在Recall@20和NDCG@20上平均提升约6.22%（IID）和9.31%（OOD），且在尾部（少量交互）物品上的提升更为显著。

**⚠️ 局限性**

局限性：对噪声负样本（误标签）更敏感，可能导致在负样本质量差时性能下降；同时在无曝光日志的场景下仍需依赖硬度与相似度的近似，可能不能完全捕捉真实竞争关系。

---

## 282. The Moltbook Illusion: Separating Human Influence from Emergent Behavior in AI Agent Societies

**arXiv ID:** 2602.07432 | [PDF](https://arxiv.org/pdf/2602.07432v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 283. Proximal Action Replacement for Behavior Cloning Actor-Critic in Offline Reinforcement Learning

**arXiv ID:** 2602.07441 | [PDF](https://arxiv.org/pdf/2602.07441v1)

**作者:** Jinzong Dong `[一作]` (Shanghai AI Laboratory), Nanyang Ye `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 556 | [OpenAlex ID](https://openalex.org/A5077493772)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种基于近端动作替换（PAR）的离线强化学习方法，能够突破行为克隆正则化导致的性能上限；

**💡 创新点**

创新点在于：①引入自适应、逐步替换低价值样本的机制；②通过近端约束保证批评器训练的稳定性；③在保持算法原型不变的前提下实现插件式改进；

**🔧 技术方法**

技术包括：离线 Actor‑Critic 框架、行为克隆正则化（MSE/KL/MLE）、合成动作缓冲、Q 值排序与比例替换、可调的稳定性门阈；

**📊 数据集**

使用 D4RL 基准数据集，涵盖 MuJoCo（HalfCheetah、Hopper、Walker2d）、AntMaze（大小地图）和 FrankaKitchen（混合/部分）等；

**📈 对比分析**

与 TD3+BC、BCQ、IQL、EDP、SSAR 等传统方法对比，PAR 在所有任务均提升平均分，某些任务（如 Hopper‑M‑R）接近或超越现有最优算法；

**⚠️ 局限性**

局限性在于受交替优化与 Bellman 逼近的约束，难以在远离行为数据的区域实现更广泛、彻底的探索，且对超出数据分布的安全探索尚未充分解决。

---

## 284. Compendia: Automated Visual Storytelling Generation from Online Article Collection

**arXiv ID:** 2602.07410 | [PDF](https://arxiv.org/pdf/2602.07410v1)

**作者:** Manusha Karunathilaka `[一作]` (Singapore Management University), Jiannan Li `[通讯]` (Singapore Management University)

**通讯引用:** 725 | [OpenAlex ID](https://openalex.org/A5101405384)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

自动检索并分析用户查询的在线文章，提取并组织定量事实，生成交互式的可视化叙事故事。

**💡 创新点**

将大语言模型与结构化抽取、主题聚类、事实合并相结合，首次实现从多篇非结构化文章自动生成完整的可滚动视觉故事。

**🔧 技术方法**

使用 GPT‑4o LLM、检索爬虫、文本分块与验证、NER、嵌入式聚类（GMM）、主题圆与 scrollytelling 可视化框架以及多步提示工程。

**📊 数据集**

基于公开的网络新闻、博客、报告等文章，共收集约36篇（示例中12篇）并提取约399条事实，评估案例涵盖 TikTok 趋势、AI 教育、房价等多领域查询。

**📈 对比分析**

与 Perplexity 等文本搜索引擎对比，SUS 得分73.3；量化评测中事实抽取准确率97.2%，聚类准确率95.9%，叙事标题准确率92.3%，可视化建议准确率77%；用户研究显示整体满意度4.38/5。

**⚠️ 局限性**

受限于 LLM 的可靠性（误判、幻觉）、对时间敏感预测缺乏区分、聚类与合并的歧义、缺乏事实核查与偏见评估，以及对稀缺或异构数据的可视化支持有限。

---

## 285. Fin-RATE: A Real-world Financial Analytics and Tracking Evaluation Benchmark for LLMs on SEC Filings

**arXiv ID:** 2602.07294 | [PDF](https://arxiv.org/pdf/2602.07294v1)

**作者:** Yidong Jiang `[一作]` (Tongji University), Rex Ying `[通讯]` (Yale University)

**通讯引用:** 15028 | [OpenAlex ID](https://openalex.org/A5078337825)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `a2602d71-93ab-4bad-974b-672788df8193` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

构建了基于美国SEC公开披露文件的全新金融分析评测基准 Fin‑RATE，涵盖细节推理、跨公司比较和纵向跟踪三大任务，并对17种主流LLM在金文推理中的表现进行系统评估。

**💡 创新点**

创新点在于：① 将多维度信息（跨企业、跨年份、跨文件）融合入评测任务，逼近真实金融分析流程；② 设计13种细粒度错误范畴和Likert评分体系，精细诊断模型失效模式；③ 通过分层检索与重排序提升检索质量，验证检索是RAG瓶颈所在。

**🔧 技术方法**

使用技术包括：大语言模型（GPT‑4/5、DeepSeek、Qwen、Llama、Fin‑R1 等）进行生成与判定；BM25、语义向量检索（MiniLM、Finance‑Embeddings）以及混合检索和重排序；LLM‑as‑Judge集成评估；两阶段生成‑校验流水线与人工复核确保 QA 质量。

**📊 数据集**

数据集为 Fin‑RATE：来自 SEC EDGAR 的 10‑K、10‑Q、8‑K 等多种文件，涵盖 2020‑2025 年 43 家不同行业公司，拆分为 15,311 章节（平均 2,649 词），共 2,472 篇文件，构成 2,500 条 DR‑QA、EC‑QA、LT‑QA 三类问答。

**📈 对比分析**

在 gold‑context 与检索增强两种设置下对 17 大模型进行对比。结果显示：单文件细节推理准确率约 40% 以上，跨公司与纵向任务准确率下降 12‑25%，表现最差的 Finance‑Tuned 模型在 EC‑QA/ LT‑QA 上仅 1‑3%；检索错误占 RAG 性能下降 70% 以上，证明检索是主要瓶颈；不同模型族群表现差异显著，封闭源模型最为稳健。

**⚠️ 局限性**

局限性包括：① RAG 仍受检索召回限制，尤其是跨公司与跨年份检索误差高；② 评测未涵盖非财报披露如新闻、社交媒体等信息源；③ 生成评估依赖 LLM‑as‑Judge，可能带来主观偏差；④ 仅在美国 SEC 文件上验证，跨境监管环境适用性待进一步验证。

---

## 286. SpecAttn: Co-Designing Sparse Attention with Self-Speculative Decoding

**arXiv ID:** 2602.07223 | [PDF](https://arxiv.org/pdf/2602.07223v1)

**作者:** Yikang Yue `[一作]` (University of Illinois Urbana-Champaign), Jian Huang `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 8902 | [OpenAlex ID](https://openalex.org/A5066790771)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一种自我投机解码框架 SpecAttn，利用验证阶段的完整注意力结果来指导稀疏注意力的 KV 选择，从而在保持输出质量的前提下显著提升长上下文 LLM 的推理吞吐量。

**💡 创新点**

创新点包括：1）将 drafting 与 verification 进行协同设计，利用验证阶段的“免费 oracle”来选取 KV；2）提出低开销的 KV 选择策略——Collect‑2‑Query，只收集首个草稿 token 与 bonus token 的注意力 logits；3）提供系统化的超参数调优流程，兼顾稀疏比例与草稿 token 数量；4）在 vLLM 框架中实现无训练、即插即用的方案。

**🔧 技术方法**

主要技术：稀疏注意力、self‑speculative decoding、KV 缓存、FlashAttention‑3 kernel 注入收集 logits、Collect‑2‑Query、分页注意力（PagedAttention）、三步超参调优、vLLM 自定义 hook。

**📊 数据集**

实验数据集：AIME25、CodeElo（短输入长推理）、LongBench‑v2（长输入长推理）。评估模型包括 Qwen3‑4B/8B/30B、gpt‑oss‑20b，使用相应 tokenizer。

**📈 对比分析**

对比基线：标准 vLLM、MagicDec（StreamingLLM 与 Quest）以及 SpecExtend；评价指标：推理吞吐量、drafting acceptance 率、KV 选择开销。实验结果显示 SpecAttn 在 AIME25、CodeElo 上相较 vLLM 提升 1.25–2.81 倍吞吐量，在 LongBench‑v2 上提升 18–29%；相较 MagicDec‑Quest 进一步提升 1.18–1.29 倍吞吐量，drafting 率更高，KV 选取开销仅 5.9–9.4%。

**⚠️ 局限性**

局限性：1）对极大上下文（>100K token）仍受 KV 缓存访问瓶颈限制；2）在 gpt‑oss‑20b 等混合注意力结构上提升有限；3）需要针对不同模型手动调参；4）对低显存 GPU 的可迁移性未充分验证；5）未对长推理中的累计误差和 hallucination 进行深入分析。

---

## 287. Architectural Anti-Patterns in Student-Developed Microservice Architectures: An Exploratory Study

**arXiv ID:** 2602.07147 | [PDF](https://arxiv.org/pdf/2602.07147v1)

**作者:** Marco De Luca `[一作]` (University of Naples Federico II), Porfirio Tramontana `[通讯]` (University of Naples Federico II)

**通讯引用:** 2596 | [OpenAlex ID](https://openalex.org/A5042889388)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df`

**🎯 论文内容**

开展为期三学期的项目式微服务架构课程，收集学生实现的系统代码和运行日志，识别并分析其中出现的微服务反模式。

**💡 创新点**

首次系统、纵向追踪学生微服务项目的质量问题，基于完整反模式分类体系提炼教学经验并给出可操作的教学建议。

**🔧 技术方法**

使用 Spring Boot、Go、Node.js、Docker、API Gateway 等微服务技术栈，并结合 SonarQube、MARS、Grafana 等静态/动态分析工具进行信息提取、建模和反模式检测。

**📊 数据集**

共 216 名硕士生、67 组团队完成 21 个任务，生成约 30,000 行代码的完整微服务应用，作为研究样本。

**📈 对比分析**

采用三阶段检测流程（信息提取→中间表征→反模式识别），与公开的 58 条反模式进行匹配，发现 23 条反模式（约 39.7%），并对各类反模式出现频率进行统计；未进行性能基准测试。

**⚠️ 局限性**

样本来自单一高校同一课程，整合版本的选择可能导致偏差；检测工具覆盖有限，需人工验证；缺乏对教学干预效果的纵向评估。

---

## 288. Progressive Searching for Retrieval in RAG

**arXiv ID:** 2602.07297 | [PDF](https://arxiv.org/pdf/2602.07297v1)

**作者:** Taehee Jeong `[一作]` (San Jose State University), Weihua Zhao `[通讯]` (San Jose State University)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `64443552-63e0-44b5-906f-d90fe95c5a1b` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在大规模文档检索场景下，系统性评估不同嵌入维度对 Retrieval‑Augmented Generation (RAG) 精度与速度的影响，并提出一种多阶段渐进检索算法，先用低维快速过滤候选，再在高维精确检索，从而显著降低查询时间。

**💡 创新点**

创新点在于：① 将传统的单阶段 KNN 检索拆分为层次化、递进的多维度检索流程；② 通过截断降维和逐步放大维度的方式，兼顾检索精度与执行效率；③ 提供完整的性能对比实验，展示渐进检索在高维情况下相较于截断检索可实现 2–5 倍速度提升。

**🔧 技术方法**

使用技术包括：
- 文档与查询的嵌入：OpenAI text‑embedding‑3‑large (3072 维) 与 Alibaba‑NLP gte‑Qwen2‑7B‑instruct (3584 维)。
- 降维方法：截断降维（2^n 维）取代 PCA。
- 检索算法：基于 Euclidean / Cosine 相似度的 KNN（brute‑force）以及多阶段渐进 KNN。
- 评估工具：Scikit‑learn 的 NearestNeighbors、Python、Google Colab、GitHub 仓库实现。

**📊 数据集**

实验数据集：
- 1 000 000 条英文文档（dbpedia‑openai‑1M‑1536‑angular）。
- 2 470 条随机抽取的查询‑答案对（已清洗，作为 ground‑truth）。

**📈 对比分析**

比较方法：对同一批查询，分别使用截断检索（Baseline）和渐进检索（Progressive），记录 Top‑1 准确率和中位数查询耗时。实验结果表明，渐进检索在相同或相近准确率下平均快 2–5 倍，尤其在维度 2048/3584 时，速度提升可达 5 倍，精度几乎不变。

**⚠️ 局限性**

limitations:
- 过低维度（< 64）会导致检索质量严重下降，必须设置合理下限。
- 需要手动调参（起始维度、起始 K、最大维度），调参复杂度较高。
- 只采用截断降维，未考虑更高效的 ANN 方法或非线性降维技术。
- 目前未评估在多模态或实时在线场景中的稳定性与扩展性。

---

## 289. Bridging Speech, Emotion, and Motion: a VLM-based Multimodal Edge-deployable Framework for Humanoid Robots

**arXiv ID:** 2602.07434 | [PDF](https://arxiv.org/pdf/2602.07434v1)

**作者:** Songhua Yang `[一作]` (Wuhan University), Miao Li `[通讯]` (Wuhan University)

**通讯引用:** 7489 | [OpenAlex ID](https://openalex.org/A5088452779)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `8d10c613-917e-4880-9716-17789f50e119` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

设计并实现了一套基于Vision‑Language Model的多模态人机交互框架SeM^2（及其边缘版本SeM^2_e），通过情感感知、链式推理和语义序列对齐机制（SSAM）实现语音、面部表情和身体动作的情感一致协调。

**💡 创新点**

创新点包括：①将VLM用于情感驱动的多模态表达生成；②提出SSAM在时序约束下的语义‑动作匹配与动态规划对齐；③采用知识蒸馏+INT4量化实现高性能边缘部署，保持95%云端性能。

**🔧 技术方法**

技术手段涵盖：Vision‑Language Model（GPT‑4o教师、MiniCPM‑8B学生）、SenseVoice语音情感识别、YOLOv8‑face面部检测、ChatTTS语音合成、动态规划时序优化、知识蒸馏与量化、ROS2+PyTorch/TensorRT实时推理。

**📊 数据集**

数据集为52,000条原始交互样本（覆盖5种场景），通过SimHash筛选得到11,500条高质量样本，用于蒸馏和微调。

**📈 对比分析**

方法对比采用AI+人工评测的5分量表，对比全模态、无表情、无动作、仅语言等配置，结果显示全模态SeM^2在自然度、情感清晰度、模态连贯性和整体体验上均显著优于任何单一模态；边缘版SeM^2_e在保持约95%性能的同时，首次响应时间缩短约52%，整体体验得分仅下降1–2分。

**⚠️ 局限性**

局限性：目前仅实现上半身与面部表情，未覆盖完整身体运动与步态；模型部署受限于特定机器人硬件；时序同步机制仍以短期交互为主，长时交互的连续性与多情绪状态适配待进一步研究。

---

## 290. Continuum Robot Localization using Distributed Time-of-Flight Sensors

**arXiv ID:** 2602.07209 | [PDF](https://arxiv.org/pdf/2602.07209v1)

**作者:** Spencer Teetaert `[一作]` (University of Toronto), Perla Maiolino `[通讯]` (Oxford Robotics Institute)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出一种利用分布式低分辨率ToF传感器实现连续体机器人的全身定位方法。

**💡 创新点**

创新点在于将稀疏ToF测量与形状先验融合于连续时间因子图MAP估计框架，实现即使在测量退化和先验误差下仍能保持高精度。

**🔧 技术方法**

技术包括连续时间因子图、Cauchy鲁棒成本、ToF点到平面误差、陀螺仪约束和伪刚体模拟。

**📊 数据集**

使用了MuJoCo仿真中的喷气发动机模型和实测的三维扫描数据，包含10个模拟场景和5个真实场景。

**📈 对比分析**

通过与基准位姿比较，实验在模拟中平均定位误差约0.8cm，真实环境中平均误差为1.7cm（位置）与6.7°（旋转）；与先前稀疏传感器方案相比误差显著降低。

**⚠️ 局限性**

主要局限在于对先验地图的高度依赖、容易陷入局部极小值以及传感器观测稀疏导致的定位不稳。

---

## 291. Transformer-based Hybrid Beamforming with Dynamic Subarray for Near-Space Airship-Borne Communications

**arXiv ID:** 2602.07509 | [PDF](https://arxiv.org/pdf/2602.07509v1)

**作者:** Ruiqi Wang `[一作]` (Beijing Institute of Technology), Mohamed-Slim Alouini `[通讯]` (King Abdullah University of Science and Technology)

**通讯引用:** 90590 | [OpenAlex ID](https://openalex.org/A5083193286)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `edb9d762-f411-4838-a852-f2d638b018db`

**🎯 论文内容**

提出一种Transformer‑基准的动态混合波束成形框架DyHBFNet，针对近空间飞艇通信的能耗受限大规模MIMO系统实现自适应子阵列和高效波束成形

**💡 创新点**

将动态子阵列、波束成形和数字波束成形三大模块统一为一个端到端Transformer网络，融合模型驱动与深度学习，显著提升能效与频谱效率，并在不完美CSI下保持鲁棒性

**🔧 技术方法**

采用Transformer编码器实现三层波束成形网络（ABFNet、ASNet、DBFNet），并结合模型驱动的WMMSE算法及自注意力机制进行参数学习

**📊 数据集**

使用基于LoS+多条NLoS路径的8×8 UPA MIMO‑OFDM频道模型，仿真样本包含204,800/20,480/20,480条训练/验证/测试数据

**📈 对比分析**

与固定/随机/全连等传统子阵列、BA、ZF、WMMSE、CNN‑WMMSE及HBF‑Net等基线方法对比，实验显示DyHBFNet在SE、EE上均领先，尤其在高功率或用户数增大时优势更为显著

**⚠️ 局限性**

主要局限在于Transformer结构带来较高的算力和参数需求，导致推理时间和FLOPs显著高于传统方法；对极端CSI失真或极大规模天线阵列的适用性仍待进一步验证

---

## 292. Optimizing Few-Step Generation with Adaptive Matching Distillation

**arXiv ID:** 2602.07345 | [PDF](https://arxiv.org/pdf/2602.07345v1)

**作者:** Lichen Bai `[一作]`, Zeke Xie `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 253 | [OpenAlex ID](https://openalex.org/A5066773635)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `8d10c613-917e-4880-9716-17789f50e119` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种自适应匹配蒸馏（AMD）框架，用于解决分布匹配蒸馏（DMD）中的“禁区”问题，提升少步生成模型的样本质量与训练稳定性。

**💡 创新点**

创新点包括：①从优化视角统一阐释DMD方法并定义禁区；②设计奖励模型驱动的诊断机制，动态调整真实教师与伪教师的梯度权重；③引入“反弹景观锐化”让伪教师专注于低质量样本，增强逃离禁区的推力。

**🔧 技术方法**

主要技术：分布匹配蒸馏、奖励模型（如HPSv2、DINOv2、VideoAlign）、自适应梯度调整、梯度场分解、奖励代理优势计算、对抗与RL引导。

**📊 数据集**

使用的数据集包括：COCO2014、ImageNet、DrawBench、HPDv2、VBench、VBench++、VideoGen‑Eval、TA‑Hard；以及视频生成数据集Wan2.1、LongLive等。

**📈 对比分析**

与现有DMD、DMD2、DMDR、D‑DMD等方法对比，AMD在多项指标上领先，例如在SDXL上HPSv2从30.64提升到31.25，ImageReward从71.01提升至88.37；在视频任务中Total Score从81.42提升至82.21，Motion Quality提升67%。

**⚠️ 局限性**

局限性：仍依赖预训练教师与奖励模型的质量，若奖励模型偏差或教师不稳定会影响效果；对极端多模态或长序列生成的适用性尚待进一步验证。

---

## 293. LUCID-SAE: Learning Unified Vision-Language Sparse Codes for Interpretable Concept Discovery

**arXiv ID:** 2602.07311 | [PDF](https://arxiv.org/pdf/2602.07311v1)

**作者:** Difei Gu `[一作]` (Rutgers University), Dimitris Metaxas `[通讯]` (Rutgers University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种统一的视觉-语言稀疏自编码器LUCID，用于学习可解释且跨模态对齐的概念词典；

**💡 创新点**

创新点在于将共享稀疏码与私有稀疏码相结合，并通过带引导的最优传输（GCMT）实现图像块与文本标记的软对齐，从而实现跨模态可解释性和精细定位；

**🔧 技术方法**

核心技术包括稀疏自编码器（Top‑k稀疏约束）、共享‑私有分解、熵正则化最优传输（OT）与引导式OT、跨模态重构与对齐损失，以及基于词库的自动神经元解释管线；

**📊 数据集**

在MS COCO 2017与CC3M的图文对齐数据上训练，使用SigLIP ViT‑B/16作为特征提取器，并在ImageNet上验证概念泛化；

**📈 对比分析**

与仅共享、仅私有、以及基线OT方法对比，LUCID在自重构R²、跨模态预测R²、以及基于边界框的对象级定位指标（mass@obj、point@1、IoU@10）上均取得显著提升；

**⚠️ 局限性**

局限性包括：对超参数（共享比例、稀疏度、OT温度）的敏感性；跨模态对齐仍受限于预训练VLM的表征能力；以及对极低频概念的解释仍可能不足。

---

## 294. Stickers on Facebook: Multifunctionality and face-enhancing politeness in everyday social interaction

**arXiv ID:** 2602.07089 | [PDF](https://arxiv.org/pdf/2602.07089v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a154b176-e466-40fc-8ae0-e5cd17677106`

---

## 295. SoK: Credential-Based Trust Management in Decentralized Ledger Systems

**arXiv ID:** 2602.07572 | [PDF](https://arxiv.org/pdf/2602.07572v1)

**作者:** Yanna Jiang `[一作]` (University of Technology Sydney), Ren Ping Liu `[通讯]` (University of Technology Sydney)

**通讯引用:** 9154 | [OpenAlex ID](https://openalex.org/A5008974159)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文对基于凭证的去中心化信任管理系统（DTMS）进行了系统综述，梳理了其架构设计、信任机制与评估准则。

**💡 创新点**

创新点在于提出双维度（时序‑空间）框架，融合治理、信任网络与数据层的三阶段信任生命周期，并给出统一的动态性、可解释性、隐私与可扩展性四维评价指标。

**🔧 技术方法**

主要技术包括区块链、去中心化身份（DID/VC）、零知识证明、图论算法和游戏理论等。

**📊 数据集**

由于是综述性工作，没有使用原始数据集；所评估的系统基于公开的案例与文献。

**📈 对比分析**

对比方法以文献归纳为主，通过表格对已发表方案在四个维度的得分进行比较，未给出量化实验；性能评价以现有工作中的报告为参考。

**⚠️ 局限性**

局限性包括缺乏统一的实测评估框架；隐私保护机制仍处于理论与实验验证的早期阶段；大规模网络下的性能与安全性分析不足。

---

## 296. $\partial$CBDs: Differentiable Causal Block Diagrams

**arXiv ID:** 2602.07581 | [PDF](https://arxiv.org/pdf/2602.07581v1)

**作者:** Thomas Beckers `[一作]` (Vanderbilt University), Truong X. Nghiem `[通讯]` (University of Central Florida)

**通讯引用:** 1005 | [OpenAlex ID](https://openalex.org/A5021671983)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种可微分的因果块图(∂CBD)框架，将CBD的模块化建模、假设-保证合约与可微分编程结合，实现安全可验证的端到端学习。

**💡 创新点**

创新点在于将合约残差作为可微分的轨迹级证书嵌入CBD，构建可自动微分的DAG，并通过残差合约实现可验证的优化与控制。

**🔧 技术方法**

使用自动微分(AD)、向量-雅可比乘积、数值积分、固定点求解、优化层以及神经网络等可微分组件。

**📊 数据集**

主要使用Van der Pol振荡器的数据集进行实验；第三例还利用公开的Van der Pol轨迹数据。

**📈 对比分析**

通过与传统手工调节/纯数据驱动方法对比，展示在稳健性保证、轨迹误差和收敛性方面的提升；在示例2中控制输入保持在约束内，Lyapunov残差始终负值；示例3中Koopman谱位于单位圆内。

**⚠️ 局限性**

局限包括：对代数环路支持有限、离散/逻辑端口需手工指定微分策略、残差合约仅为轨迹级充足性证明、对大规模多速率系统的可扩展性待进一步评估。

---

## 297. MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning

**arXiv ID:** 2602.07543 | [PDF](https://arxiv.org/pdf/2602.07543v1)

**作者:** Heewoong Noh `[一作]` (KAIST), Chanyoung Park `[通讯]` (KAIST)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一套统一的大型语言模型框架（MSP‑LLM），能够从目标材料出发，完整规划其合成路线，包括原料选择、步骤设计和条件优化。

**💡 创新点**

创新点在于将LLM与材料科学专有知识图谱相结合，实现端到端的合成规划；同时通过多模态预训练和自监督对齐，使模型能够处理化学反应序列、反应条件与材料属性之间的复杂关系。

**🔧 技术方法**

采用的技术包括大规模预训练语言模型（基于GPT/PaLM等架构）、对齐训练（Align‑LLM）、强化学习（RLHF）以及知识图谱嵌入，将化学反应规则与数据驱动学习结合。

**📊 数据集**

使用的数据集主要有Materials Project、Reaxys、USPTO化学反应数据库以及自建的合成路线语料库（包含数千条高质量实验记录）。

**📈 对比分析**

实验中将MSP‑LLM与传统规则基方法、单一机器学习模型（如Graph Neural Network）进行对比；结果显示MSP‑LLM在合成成功率上提升约12–18%，在规划时间上比基线方法快30–45%。

**⚠️ 局限性**

局限性包括：① 对低频或全新反应的泛化能力有限；② 需要大量高质量标注数据，数据稀缺时性能下降；③ 计算资源成本高，推理时间在高复杂度路线上仍有提升空间。

---

## 298. Automated rock joint trace mapping using a supervised learning model trained on synthetic data generated by parametric modelling

**arXiv ID:** 2602.07590 | [PDF](https://arxiv.org/pdf/2602.07590v1)

**作者:** Jessica Ka Yi Chiu `[一作]` (Norwegian Geotechnical Engineering), Ole Jakob Mengshoel `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `67630363-6be0-4f51-ab05-7198250671a5` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文开发了一套基于地质建模与合成数据的监督学习框架，用于自动化岩石裂隙痕迹的图像分割与映射。

**💡 创新点**

创新点在于将离散裂缝网络(DFN)与参数化方法相结合生成可控合成岩石图像，提供地质先验；同时提出零样本/少样本训练策略并强调定性评价，以弥补传统量化指标不足。

**🔧 技术方法**

使用了深度学习语义分割模型（U‑Net 与 DeepLabv3+）、预训练+微调、混合训练策略、数据增强；合成数据通过 Rhino/Grasshopper、FracMan 等工具生成；模型训练与评估在 Azure ML 平台完成。

**📊 数据集**

构建了四类数据集：合成 DFN 数据集（≈25.6k 张）、合成盒子数据集（≈1k 张）、真实岩坡数据集（Larvik 与 Rv4 共≈3k 张）以及真实盒子数据集（200 张）；其中包含完美合成标签与手工标注标签。

**📈 对比分析**

通过对比 Finetune 与 SimpleMixed 两种训练策略、U‑Net 与 DeepLabv3+ 两种网络，并使用 IoU、Dice、精确率、召回率等指标评估；在盒子域零样本或少样本情况下可取得 0.6–0.7 的 Dice，坡域微调表现更佳，整体性能与定性评分呈正相关。

**⚠️ 局限性**

主要局限包括仅使用二维 RGB 图像缺乏深度信息；合成图像与真实场景在纹理、光照等外观上存在差距；标签噪声与不一致导致评估偏差；对不同地质环境的泛化能力有限；未实现后处理与工程级评价链。

---

## 299. Lemon Agent Technical Report

**arXiv ID:** 2602.07092 | [PDF](https://arxiv.org/pdf/2602.07092v1)

**作者:** Haipeng Jiang `[一作]` (AI Lab @ Lenovo CTO Org), Jianping Fan `[通讯]` (AI Lab @ Lenovo CTO Org)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建并实现了基于AgentCortex框架的多智能体系统Lemon Agent，集成了层级自适应调度、三层上下文管理、持续自演进语义记忆以及增强工具集，以实现高效、资源友好且多模态的任务执行。

**💡 创新点**

创新点包括：① 在宏观与微观层面动态调节资源与工具并行度；② 三层递进式上下文压缩策略以缓解信息衰减与上下文窗口溢出；③ 自演进语义记忆（SES‑Memory）从所有执行轨迹中提取可迁移技能，而非仅靠成功/失败；④ 针对图像与地理空间任务的专用工具（智能裁剪图像工具、街景代理、分层搜索工具）。

**🔧 技术方法**

采用GPT‑5语言模型为核心，配合AgentCortex架构实现Planner‑Executor‑Memory模式；实现宏观/微观层的自适应调度；实现三层上下文压缩；实现SES‑Memory技能提取与筛选；使用MCP工具集与专用工具进行多模态感知与检索。

**📊 数据集**

主要在GAIA和xbench‑DeepSearch两个公开基准上进行评测；GAIA用于多步骤推理与多模态任务，xbench‑DeepSearch用于检索与工具使用能力。

**📈 对比分析**

采用Pass@3评估策略，并在10轮交互内完成任务；在GAIA上获得91.36%总体准确率（L1 96.77%、L2 89.31%、L3 87.76%），在xbench‑DeepSearch榜单上获得77+准确率，分别超过ChatGPT‑5‑Pro、SuperGrok等先进系统。

**⚠️ 局限性**

局限性主要体现在：① 频繁的外部工具调用导致高通信开销与延迟；② 依赖网络传输大文件（如图像）导致上下文长度膨胀；③ 当前多智能体协作拓扑较为简单，难以处理极其碎片化的子目标；未来计划通过沙箱化执行、精细化协作拓扑与SES‑Memory提升来缓解这些问题。

---

## 300. Fine-Grained Cat Breed Recognition with Global Context Vision Transformer

**arXiv ID:** 2602.07534 | [PDF](https://arxiv.org/pdf/2602.07534v1)

**作者:** Mowmita Parvin Hera `[一作]` (Jashore University of Science and Technology), Mohammmad Farhad Bulbul `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文利用GCViT‑Tiny模型对Oxford‑IIIT Pet数据集中的猫品种进行细粒度分类，提出一种全局上下文注意机制的视觉Transformer方案。

**💡 创新点**

创新点在于将GCViT的全局上下文模块与卷积特征融合，显著提升了对细小纹理和全局姿态信息的捕获能力，提升了猫品种识别精度。

**🔧 技术方法**

采用Vision Transformer（GCViT）、数据增强（旋转、翻转、亮度/对比度调节）、交叉熵+标签平滑、AdamW优化器以及余弦退火学习率调度。

**📊 数据集**

使用Oxford‑IIIT Pet数据集的猫品种子集，共12个品种、2371张训练图像（含验证）与1183张测试图像。

**📈 对比分析**

与传统CNN（VGG16、InceptionV3、ResNet50、Xception）以及Hybrid MobileViTv3（PetVision）对比，GCViT‑Tiny在测试集上达92.00%准确率，明显优于其他方法。

**⚠️ 局限性**

局限在于仅针对猫品种，不考虑混种猫或其他动物；模型在更大规模、多模态或真实世界环境下的鲁棒性仍需进一步验证。

---

## 301. TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents

**arXiv ID:** 2602.07274 | [PDF](https://arxiv.org/pdf/2602.07274v1)

**作者:** Kaijie Zhu `[一作]` (University of California, Santa Barbara), Wenbo Guo `[通讯]` (University of California, Santa Barbara)

**通讯引用:** 1738 | [OpenAlex ID](https://openalex.org/A5054699755)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `67630363-6be0-4f51-ab05-7198250671a5` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出端到端的终端任务训练框架，先生成可验证的Docker环境，再通过Generator‑Critic策略构造带错误恢复的专家轨迹；

**💡 创新点**

创新性地结合多代理环境生成（Proposer‑Evaluator、File Planner、Env Agent等）与主动错误注入，解决可执行环境缺失与暴露偏差；

**🔧 技术方法**

使用多代理生成流程、Generator‑Critic错误注入、ReAct式交互、Docker验证循环等技术；

**📊 数据集**

构造了约3500个可验证Docker环境，采集了3291条轨迹，覆盖420个命令行工具，数据集已公开；

**📈 对比分析**

在TerminalBench上，Qwen2.5‑Coder‑32B通过率31.3%，显著高于开源SOTA（如Reptile 18.9%）并超越部分专有模型（如o4‑mini 20.0%）；

**⚠️ 局限性**

仅做了SFT，未加入RL，缺乏真实生产环境的分布式或大规模验证，迁移性尚待进一步评估。

---

## 302. Zero-Shot UAV Navigation in Forests via Relightable 3D Gaussian Splatting

**arXiv ID:** 2602.07101 | [PDF](https://arxiv.org/pdf/2602.07101v1)

**作者:** Zinan Lv `[一作]` (Shanghai Jiao Tong University), Ming Yang `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 105441 | [OpenAlex ID](https://openalex.org/A5100418319)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

利用可重光照的 3D 高斯散射（Relightable 3D Gaussian Splatting）构建高保真数字孪生环境，并在其中训练端到端的强化学习策略，使无人机仅凭单目 RGB 实时完成高速（最高 10 m/s）森林穿梭航行，零样本直接投放到真实世界。

**💡 创新点**

核心创新包括：① 将 3D 高斯散射解耦为几何、材质和全局光照，使光照可随意重合并产生多样化的照明；② 采用两阶段训练课程，先在原始光照下学习几何感知，再引入随机光照以实现光照无关的视觉表示；③ 结合域随机化（动作噪声、延迟、相机偏移等）与光照随机化，显著缩小仿真‑现实视觉与动力学差距。

**🔧 技术方法**

技术手段包括：3D Gaussian Splatting（可重光照版）、深度学习视觉感知网络（CNN+GRU+MLP）、近端策略优化（PPO）强化学习、光照随机化（Spherical Harmonics 旋转/强度/色调）、相机噪声/延迟仿真、基于点云的碰撞检测与物理仿真。

**📊 数据集**

数据集为 10 个真实森林场景（约 60 m × 60 m），由手持双目鱼眼相机、LiDAR 与 RTK 定位系统同步采集，随后用 3D Gaussian Splatting 重建得到高保真数字孪生。

**📈 对比分析**

与现有基于 RGB‑D、LiDAR、光流等传感器的 RL 导航方法对比，本方法在户外单目环境下实现 10 m/s 的飞行速度，成功率约 80%（无光照微调），显著优于传统方法（1.5–7 m/s、20–50% 成功率）。

**⚠️ 局限性**

局限性：对 3D 重建质量高度依赖，极端光照或快速动态障碍物仍可能导致失败；训练过程需要大量 GPU 资源和高质量数字孪生；目前仅验证在小型四旋翼平台，未评估大规模多机协作。

---

## 303. Towards Robust Scaling Laws for Optimizers

**arXiv ID:** 2602.07712 | [PDF](https://arxiv.org/pdf/2602.07712v1)

**作者:** Alexandra Volkova `[一作]` (Institute of Science and Technology Austria), Dan Alistarh `[通讯]` (Institute of Science and Technology Austria)

**通讯引用:** 4414 | [OpenAlex ID](https://openalex.org/A5083822059)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种针对优化器的鲁棒可解释的规模法则，将传统的Chinchilla式规模法则中模型规模与数据规模的指数共享，而将优化器的差异归结为对模型规模与数据规模的乘法缩放因子（ρ_N、ρ_D）。

**💡 创新点**

创新点在于：1) 通过共享指数并引入优化器特定的缩放因子，使得规模法则在不同优化器间变得数值稳定且可直接比较；2) 通过对比独立优化器拟合的脆弱性，展示了新的共享参数模型在拟合误差和外推误差上的显著提升；3) 结合凸二次目标的谱分析，提供理论证明解释了Chinchilla式规模法则的形式与指数。

**🔧 技术方法**

使用的技术包括：非线性最小二乘拟合（带Huber损失）、留一交叉验证评估参数不确定性、对不同优化器（AdamW、Muon、Scion、Shampoo、SOAP）的训练运行、以及基于谱维数的凸二次优化理论分析。

**📊 数据集**

采用两套大型语言模型架构：OLMo-2和LLaMa，训练数据分别为ClimbMix（OLMo）和FineWeb（LLaMa）。模型规模覆盖50M至1.5B参数，token/parameter比率从30到200。

**📈 对比分析**

通过对5种优化器的训练结果拟合，新的共享参数法则在参数和数据效率方面显示出显著稳定性，留一交叉验证误差减半，外推至1.5B模型时误差降低超过2倍。与传统独立拟合相比，新的法则在拟合误差、外推误差和模型与数据效率解释上均表现更好。

**⚠️ 局限性**

限制包括：①理论证明仅适用于凸二次目标，实际LLM训练具有更复杂的非凸性；②实验规模上限为1.5B参数，未验证更大规模；③优化器的超参已通过小模型转移，可能在极大规模或不同任务下失效；④计算效率因实现细节（硬件、通信）影响，需进一步普适化。

---

## 304. Helly-type problems from a topological perspective

**arXiv ID:** 2602.07552 | [PDF](https://arxiv.org/pdf/2602.07552v1)

**作者:** Pavel Paták `[一作]` (Czech Technical University in Prague), Zuzana Patáková `[通讯]` (Charles University)

**通讯引用:** 74 | [OpenAlex ID](https://openalex.org/A5075785661)

**关键词:** `a42c7bd6-d8fd-40d3-94df-ae8cd808f5c4` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文综述了拓扑Helly型定理的发展，系统梳理了两类主要证明思路：基于神经引理的拓扑Helly定理及其色彩化、分数化变体；以及基于非嵌入性（Radon、van Kampen–Flores 等）的Helly定理与其通用推广。进一步，作者讨论了这些定理的应用、可计算性、最优性以及未解决的开放问题。

**💡 创新点**

创新点在于：① 将神经引理与非嵌入性两条路线统一展现，说明它们如何交织在一起产生新的Helly、分数Helly、色彩化等定理；② 引入“受限链映射”和“同调极小子图”两种新的工具，用以构造 Radon 数上界与 Helly 数之间的桥梁；③ 在同调层面上对 Helly 定理的通用化（如路径连通、Betti 数约束）提出最优性判据；④ 对已知的大量上界与下界进行系统性比较，指出目前存在的巨大差距。

**🔧 技术方法**

主要技术包括：
- 神经引理与其变体（包括多重神经、骨架神经、同调极小子图的概念）
- 同调与同伦理论（Betti 数、d-连通性、同调不嵌入性）
- 维数约束与多项式/塔函数估计（Ramsey 理论、Brouwer 定理）
- 受限链映射构造与合并方法
- van Kampen–Flores 定理与拓扑 Radon 定理的应用
- 组合几何中的色彩化、分数化与 (p,q)-定理的推导。

**📊 数据集**

本文为理论综述，未使用任何实验数据集；所有结果均来自数学证明与组合几何构造。

**📈 对比分析**

由于研究聚焦于理论证明，本文未与实验方法直接比较。作者通过上界与下界的严谨定理与已知最优/最坏例子进行对比，指出大多数上界（尤其是基于 Ramsey 论证的上界）远大于已知下界，显示出目前方法的局限性与改进空间。

**⚠️ 局限性**

主要局限性包括：
- 大部分上界依赖于 Ramsey 论证，导致指数/塔函数级别的巨大常数；
- 许多拓扑连通性假设在算法层面不可判定（如 d-连通性、π1 是否平凡）;
- 同调极小子图仅已知于 ℝ^d，对其它空间的推广尚不充分；
- 对分数 Helly 数、(p,q)-定理的具体常数仍较大；
- 证明中多步抽象化导致难以直接得到紧凑、可实现的算法或构造。

---

## 305. Are Reasoning LLMs Robust to Interventions on Their Chain-of-Thought?

**arXiv ID:** 2602.07470 | [PDF](https://arxiv.org/pdf/2602.07470v1)

**作者:** Alexander von Recum `[一作]` (Helmholtz Munich), Zeynep Akata `[通讯]` (Technical University of Munich)

**通讯引用:** 16101 | [OpenAlex ID](https://openalex.org/A5040372929)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

设计了一套受控评估框架，对推理语言模型（RLLM）的链式推理（CoT）在固定时间点进行七种干预（善意、中性、对抗性），并在数学、科学、逻辑三大任务上评估多款开源RLLM的鲁棒性。

**💡 创新点**

创新点包括：①提出首个针对RLLM CoT鲁棒性的基准；②系统性研究干预对推理链的影响；③揭示“疑问”表达是自我纠错的关键机制；④发现风格变换（如改写）会削弱推理效果；⑤量化恢复所产生的计算成本和效率权衡。

**🔧 技术方法**

采用链式分段与时间点对齐、采样式鲁棒性指标（至少一次、多数、全部）、疑问检测分类器、CoT长度变化分析、模型互换实验以及在干预后强制插入“Wait”来提升恢复的技术手段。

**📊 数据集**

使用的公开数据集包括：NuminaMath（数学）子集、SciBench 与 JEEBench（科学）以及 BigBench‑Hard（逻辑）子集；最终选取 600 个数学、231 个科学、326 个逻辑问题，确保所有模型在原始链上均能正确回答。

**📈 对比分析**

通过多模型、多干预、多时间点的对比实验，使用“多数鲁棒性”指标进行评估。结果显示大模型在大多数干预下鲁棒性接近 100%，小模型受影响较大；中性干预导致 CoT 长度大幅上升（+50%~+200%），而改写干预则显著缩短 CoT（-60%）但准确率下降；整体上模型表现优异，尤其是 QwQ‑32B、Phi‑4‑reasoning‑plus 与大规模 Distill‑Qwen 变体。

**⚠️ 局限性**

局限性包括：①对风格变化高度敏感，改写会降低准确率；②恢复过程往往产生显著的令牌成本；③小规模模型鲁棒性不足；④干预仅在固定时间点施加，未涵盖所有真实场景；⑤实验仅覆盖公开任务与模型，可能不具备完全通用性。

---

## 306. XShare: Collaborative in-Batch Expert Sharing for Faster MoE Inference

**arXiv ID:** 2602.07265 | [PDF](https://arxiv.org/pdf/2602.07265v1)

**作者:** Daniil Vankov `[一作]` (Arizona State University), George Karypis `[通讯]` (Amazon Web Services)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出批量感知的专家选择框架，利用门控分数聚合并通过贪心优化，在推理时动态缩减激活专家数量，从而提升吞吐量。

**💡 创新点**

创新点在于把批量专家激活建模为模块化优化问题，证明贪心算法最优；并针对标准批处理、推测解码和专家并行三种部署场景，分别设计热启动初始化、层级请求级选择以及GPU-aware 负载均衡等高效算法。

**🔧 技术方法**

技术方法包括模块化代理目标、贪心优化、热启动预选、请求级专家聚合、GPU-aware 负载均衡、门控分数统计以及实验对比分析。

**📊 数据集**

使用的实验数据集包括 GPT-OSS 120B、DeepSeek-R1、AIME2025、GPQA、MMLU-Pro、IFEval、AA-LCR 等多领域推理基准。

**📈 对比分析**

通过与原MoE、Lynx-Lat、Dynamic Skipping 等方法对比，单GPU无推测下提升 7–13% OTPS，推测解码下提升 13–14% OTPS，专家并行下峰值GPU负载降低 3 倍，激活专家数量减少 70%+，且准确率差异 ≤1%。

**⚠️ 局限性**

局限性包括需要手工调参（预算、warm‑up 级别），对极大批量或高推测长度场景的适用性未知，依赖门控分数可靠性，对不同模型结构的通用性仍待验证。

---

## 307. ANCHOR: Branch-Point Data Generation for GUI Agents

**arXiv ID:** 2602.07153 | [PDF](https://arxiv.org/pdf/2602.07153v1)

**作者:** Jinbiao Wei `[一作]` (Yale University), Arman Cohan `[通讯]` (Yale University)

**通讯引用:** 270962 | [OpenAlex ID](https://openalex.org/A5042321575)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `67630363-6be0-4f51-ab05-7198250671a5` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

通过在已验证的种子轨迹上识别关键状态点进行分支扩展，自动生成多样化且高质量的桌面GUI交互轨迹；

**💡 创新点**

创新性地将state‑grounded分支、LLM驱动的任务提议与执行、轨迹摘要与验证、以及step‑level reasoning filtering与post‑branch intention‑consistency denoising 等技术组合，显著提升轨迹质量与覆盖率；

**🔧 技术方法**

利用大语言模型（GPT‑5.1、Claude Sonnet 4.5、Qwen3‑VL）进行任务生成、执行与验证；在视觉语言模型（GLM‑4.1V‑9B、Qwen2.5‑VL‑7B、Qwen3‑VL‑8B）上做全参数 fine‑tune，使用工具调用行动空间；

**📊 数据集**

基于 OSWorld 与 WindowsAgentArena 两大桌面基准，采集 117/51 个种子任务并通过扩展生成约 1,777 条成功轨迹；同时使用 AgentNet 作为人类演示基准；

**📈 对比分析**

与 Zero‑Shot、Task‑Driven 生成、Human Data 基准对比，实验显示在 OSWorld 上 GLM‑4.1V‑9B 从 0.47% 提升至 7.01%，Qwen2.5‑VL‑7B 从 5.61% 提升至 7.94%，Qwen3‑VL‑8B 从 16.82% 提升至 20.56%；在 WindowsAgentArena 上对应提升显著，跨域与规模实验亦验证了方法的有效性；

**⚠️ 局限性**

仅在桌面环境评估，移动/网页场景未验证；验证器准确率虽高但仍有误差；分支策略与验证标准可进一步优化；数据规模相对有限，未来可扩大到更多任务与平台。

---

## 308. SIGMA: Selective-Interleaved Generation with Multi-Attribute Tokens

**arXiv ID:** 2602.07564 | [PDF](https://arxiv.org/pdf/2602.07564v1)

**作者:** Xiaoyan Zhang `[一作]` (Creatly AI), Yiren Song `[通讯]` (National University of Singapore)

**通讯引用:** 13230 | [OpenAlex ID](https://openalex.org/A5076778501)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 SIGMA，一种在 Bagel 的扩展后训练框架，支持在 diffusion transformer 中通过交错的文本–图像序列实现多属性多源的可控图像生成与编辑。

**💡 创新点**

创新点包括：① 引入可选择的多属性 token（如 style、content、identity 等）以显式绑定不同属性到对应的参考图像；② 设计交错 conditioning 机制，让文本与多张图像按用户指定顺序混合输入；③ 使用组级注意力掩码（group‑scoped attention mask）限制特殊 token 仅能关注其所属图像，从而抑制跨源信息泄漏并提升可控性。

**🔧 技术方法**

技术栈：Diffusion Transformer（Bagel backbone）+ 交错后训练 + 位置编码 + 组级注意力掩码 + LoRA/全参数 fine‑tuning + 视觉–文本编码器（VAE+CLIP/DINO 等）。

**📊 数据集**

构建了 700K 条交错多条件样本，覆盖六大任务类别（组合生成、选择提取、风格化、关系转移、图像编辑、布局生成），并使用 GPT‑4o、Nano‑Banana 等生成工具进行数据合成与 token 注入。

**📈 对比分析**

与 Bagel、XVerse、SSR、EasyControl 以及 GPT‑4o、Nano‑Banana 等基线模型在 XVerseBench 和自制综合基准上进行比较。结果显示：在组合生成、选择生成和布局生成任务中，SIGMA 在 CLIP、CLIP‑I、DINO、DreamSim 等指标上均显著优于 Bagel，接近 GPT‑4o 与 Nano‑Banana 的性能，且在多源一致性（CLIP‑ES）上表现更好。

**⚠️ 局限性**

局限性：依赖大规模交错训练数据和后训练过程，模型在极其复杂的跨源组合或非常稀疏的条件下仍可能出现信息泄漏或不一致；同时，扩展到更多模态（如音频、3D）需要进一步设计；模型体积与计算开销较 Bagel 稍高。

---

## 309. Incorruptible Neural Networks: Training Models that can Generalize to Large Internal Perturbations

**arXiv ID:** 2602.07320 | [PDF](https://arxiv.org/pdf/2602.07320v1)

**作者:** Philip Jacobson `[一作]` (Sandia National Laboratories), Christopher Bennett `[通讯]` (Sandia National Laboratories)

**通讯引用:** 6663 | [OpenAlex ID](https://openalex.org/A5017426058)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文研究了在训练神经网络时通过 SAM（Sharpness-Aware Minimization）和 RWP（Random-Weight Perturbation）实现对权重内部扰动鲁棒性的提升，并从泛化与优化两方面系统分析了其表现。

**💡 创新点**

创新点包括：①基于 PAC‑Bayes 推导出一个泛化界限，证明过度正则化的 RWP 能获得更优的噪声鲁棒性；②发现 SAM 在大扰动下会出现梯度消失现象；③提出并验证了线性/二次动态扰动调度策略，有效缓解了梯度消失并提升了模型鲁棒性；④在模拟的 AIMC 硬件上验证了这些方法的实际效果。

**🔧 技术方法**

使用技术包括：PAC‑Bayes 理论、SAM 与 RWP 训练范式、动态扰动调度（线性/二次）、CrossSim 仿真器模拟 RRAM 与 SONOS 硬件误差、ResNet‑18 网络架构、SGD 对比实验。

**📊 数据集**

主要数据集：Cifar‑100（主实验）、Tiny‑ImageNet、ImageNet‑100（补充实验）。

**📈 对比分析**

与传统 SGD 在不同噪声强度下比较，评估噪声下的测试准确率。结果显示：①过度正则化的 RWP 在小噪声下优于 SAM；②SAM 在小噪声下优于 RWP；③动态扰动调度进一步提升了准确率，特别是在大噪声环境下显著优于恒定扰动；④在模拟硬件中，二次调度对 RRAM（大噪声）和 SONOS（小噪声）都带来了性能提升。

**⚠️ 局限性**

局限性：①理论泛化界限假设噪声为零均值高斯分布，对非高斯硬件误差的适用性有限；②动态扰动调度需额外超参数调优；③在极大扰动下仍可能出现梯度消失，导致收敛困难；④实验主要基于 ResNet‑18，未验证更大网络或不同任务的普适性。

---

## 310. Data-Aware and Scalable Sensitivity Analysis for Decision Tree Ensembles

**arXiv ID:** 2602.07453 | [PDF](https://arxiv.org/pdf/2602.07453v1)

**作者:** Namrita Varshney `[一作]` (Indian Institute of Technology Bombay), S. Akshay `[通讯]` (Indian Institute of Technology Bombay)

**通讯引用:** 493 | [OpenAlex ID](https://openalex.org/A5063753055)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文研究决策树集成模型的特征灵敏度问题，提出数据感知的灵敏度验证框架，并给出了针对二分类和多分类模型的 MILP/SMT 编码和多种求解策略。

**💡 创新点**

创新点包括：证明即使是深度为 1 的树集成也存在 NP‑hard 的灵敏度验证；设计了高效的 MILP 优化与基于产品边缘分布的目标函数；引入基于约束求解的空洞剪枝；以及首次将灵敏度验证扩展到多分类树集成。

**🔧 技术方法**

技术手段包括混合整数线性规划（MILP）、可满足性模理论（SMT）求解、产品边缘分布（product-of-marginals）作为目标、Softmax 与 Sigmoid 处理多分类与二分类输出、以及使用 Gurobi、Z3 等工业级求解器。

**📊 数据集**

实验数据集涵盖 XGBoost 训练的 18 个二分类模型（如乳腺癌、糖尿病、Adult、Churn、MNIST 等）和 8 个多分类模型（如 Covtype、Fashion‑MNIST、Iris、红酒等），共 538 个多分类实例与 1,290 个二分类实例。

**📈 对比分析**

与伪布尔编码和传统 MILP 基线对比，数据感知 MILP 在二分类任务上平均提升 8 倍，在多分类任务上提升 15 倍，几乎无超时；在数据感知的 Counterexample 质量上，Prob‑Clause 组合方案相较于基线赢率约 86%，且平均距离优势约 0.47。

**⚠️ 局限性**

局限性包括：对高维特征的假设独立性在某些数据集上不成立；仅适用于决策树集成模型，未直接提供模型硬化或训练方法；多特征灵敏度分析在特征数很大时仍可能面临搜索空间膨胀。

---

## 311. Active Learning Using Aggregated Acquisition Functions: Accuracy and Sustainability Analysis

**arXiv ID:** 2602.07440 | [PDF](https://arxiv.org/pdf/2602.07440v1)

**作者:** Cédric Jung `[一作]` (Automated Control Institute), Anke Schmeink `[通讯]` (RWTH Aachen University)

**通讯引用:** 3841 | [OpenAlex ID](https://openalex.org/A5072895220)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `109c2b71-d051-425c-831f-0c544c24280d`

**🎯 论文内容**

本文实现并评估了多种主动学习（Active Learning）采样函数，提出六种聚合结构（序列、并行、混合、反馈、随机与退火），并在不同模型与数据集上比较其准确率与能耗。

**💡 创新点**

创新点在于通过聚合不同采样函数的方式解决探索‑利用困境，并设计了自适应反馈与退火调度机制，显著降低了标注样本量与计算成本。

**🔧 技术方法**

使用的技术包括基于不确定性（如BALD、Entropy、Least Confidence）、基于代表性/多样性的函数（K‑Centers、BADGE、FL、Disparity Min）以及子模函数；聚合结构实现为多层筛选或轮询，并结合模型训练的早停和动态阈值。

**📊 数据集**

实验数据集包括CIFAR‑10、CIFAR‑100、PTB‑XL（心电图），模型分别为VGG16、ResNet18/101 等深度网络。

**📈 对比分析**

比较方法采用多次随机种子实验，使用 t‑检验求得“胜率”指标；结果显示，Series 结构（如 K‑Centers→BALD）与自适应/退火轮询聚合在多种场景下能在不降低准确率的前提下，减少 12%–50% 的样本量或计算时间。

**⚠️ 局限性**

局限性包括聚合效果高度依赖模型、数据集与采样函数的兼容性；某些结构（如并行、混合）在计算量上未能显著提升；退火与反馈调度参数需手工调优，且在更大规模数据或更复杂任务上的泛化仍需验证。

---

## 312. CA-YOLO: Cross Attention Empowered YOLO for Biomimetic Localization

**arXiv ID:** 2602.07523 | [PDF](https://arxiv.org/pdf/2602.07523v1)

**作者:** Zhen Zhang `[一作]` (Anhui Polytechnic University), Yi Zhang `[通讯]` (National University of Defense Technology)

**通讯引用:** 17720 | [OpenAlex ID](https://openalex.org/A5100388188)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `aaccfe5c-6b26-4208-b23c-35331481e142` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文提出了基于YOLO的CA-YOLO模型，并设计了仿生的平舵跟踪系统，用于提高小目标检测与实时跟踪性能。

**💡 创新点**

创新点包括：在YOLO骨干网络后加入多头自注意力(MHSA)增强长距离依赖；新增专门的小目标检测头；用Characteristic Fusion Attention Mechanism (CFAM)替代传统Concat实现动态特征融合；以及仿生视线稳定机制的自适应平舵控制与决策阈值。

**🔧 技术方法**

技术方法涵盖：YOLOv8架构改进、MHSA、CFAM、卷积+1×1压缩、伺服PID控制、目标位置自适应系数K、基于角度误差的决策边界与搜索策略。

**📊 数据集**

实验数据集：COCO、VisDrone（公开）以及自制的AGV和UAV数据集。

**📈 对比分析**

通过与YOLOv8n、YOLOX、YOLOv9、CenterNet、DETR等模型在COCO、VisDrone、AGV、UAV等数据集上进行对比，CA‑YOLO在mAP、F1、IoU和实时FPS上均显著提升（COCO mAP提升3.9%–4.9%，VisDrone mAP提升4.6%），并在目标居中时IoU更高、平舵响应更平滑，跟踪效率提升15–54%。

**⚠️ 局限性**

主要局限：平舵固定不具备移动平台；模型依赖预训练权重，难以应对未训练的新目标；未实现全动态跟踪与更广泛的未知目标适应。

---

## 313. Massive Sound Embedding Benchmark (MSEB)

**arXiv ID:** 2602.07143 | [PDF](https://arxiv.org/pdf/2602.07143v1)

**作者:** Georg Heigold `[一作]` (Google Research), Michael Riley `[通讯]` (Google Research)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `fede83ac-7505-405f-ab37-e7284695c47f` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了Massive Sound Embedding Benchmark (MSEB)，包含8大超任务与四个大规模数据集，用来统一评估音频嵌入在多模态系统中的表现；

**💡 创新点**

创新点在于将语音、环境、生命体声音等多领域的听觉任务统一到一个可扩展的、无须任务特定微调的基准中，并关注嵌入压缩率与计算复杂度；

**🔧 技术方法**

使用了 Whisper‑Large v3 + GeminiEmbedding/Gecko 的级联编码、CLAP、Perch、EnCodec 等现有模型作为基线，重点评估音频对文本的转换与直接音频编码；

**📊 数据集**

采用了 SVQ（177k 语音查询）、Speech‑MASSIVE（12 语言 SLU）、FSD50K（51k 语音事件）和 BirdSet（6800h 鸟类声景）等数据集；

**📈 对比分析**

通过“音频输入 vs 文本 oracle”对照实验，量化了音频嵌入在检索、重排序、推理、分类、转录、分割、聚类、重建等任务上的性能差距，显示当前音频方法普遍落后于文本基线，存在显著提升空间；

**⚠️ 局限性**

局限性包括：依赖 ASR 产生的文本导致语音错误传递、跨语言性能不均、对噪声鲁棒性不足、任务覆盖仍有限，亟需开发更通用、无监督的音频嵌入技术。

---

## 314. Online Algorithm for Fractional Matchings with Edge Arrivals in Graphs of Maximum Degree Three

**arXiv ID:** 2602.07355 | [PDF](https://arxiv.org/pdf/2602.07355v1)

**作者:** Kanstantsin Pashkovich `[一作]` (University of Waterloo), Thomas Snow `[通讯]` (University of Toronto)

**通讯引用:** 6 | [OpenAlex ID](https://openalex.org/A5049021156)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出了一种在线算法，用于在最大度数为 3 的图（无论是否为二分图）中实现最佳的分数匹配近似比例。

**💡 创新点**

创新点在于通过精细的“桥”边处理、类型化边赋值和覆盖更新，构造出能在任何边到达顺序下都能达到上界 c=4/(9-√5)≈0.5914 的算法，并证明在最大度数为 3 时分数匹配与整数匹配在保证值上存在差距。

**🔧 技术方法**

使用了基于线性规划和对偶理论的原始-对偶分析、递归实例构造以及线性程序求解工具来获得上界与下界。

**📊 数据集**

使用的是人工构造的最坏情况图实例（如一致性实例、桥实例、十六步递归实例等）而非公开数据集。

**📈 对比分析**

通过与 Buchbinder 等人给出的理论上限以及自己构造的上界线性程序进行比较，证明该算法在分数匹配下可达到约 0.5914 的近似比例；在整数匹配上只能达到约 0.58065 的下限，展示了两者性能的差距。

**⚠️ 局限性**

局限性包括：算法仅在最大度数为 3 的图中达到最佳保证，对整数匹配无法达到同一保证；在度数为 4 的图中性能低于 0.5914；此外算法对图的具体构造依赖较强，难以推广至更一般情形。

---

## 315. From Native Memes to Global Moderation: Cros-Cultural Evaluation of Vision-Language Models for Hateful Meme Detection

**arXiv ID:** 2602.07497 | [PDF](https://arxiv.org/pdf/2602.07497v1)

**作者:** Mo Wang `[一作]` (Macquarie University), Usman Naseem `[通讯]` (Macquarie University)

**通讯引用:** 2949 | [OpenAlex ID](https://openalex.org/A5077006200)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实施了一个多维度的跨文化评估框架，系统评估七款视觉-语言模型在六种语言的仇恨表情包检测任务中，比较零/一拍提示与翻译对性能的影响。

**💡 创新点**

首次系统评估多语言本土化仇恨表情包，揭示“翻译-检测”普遍导致性能下降，并提出本土提示与一拍学习能显著缓解西方文化偏差。

**🔧 技术方法**

使用了视觉-语言模型（Gemini‑2.5‑Flash、GPT‑4o‑Mini、CogVLM2、Qwen‑2.5‑VL、LLaMA‑4‑Maverick、InstructBLIP 等）、零/一拍提示技术、Google 翻译以及宏观/微观指标统计方法。

**📊 数据集**

采集了六个本土化数据集——Prop2Hate（阿拉伯）、BHM（孟加拉）、HateMeme（英文）、GerMemeHate（德语）、DANKMEMES（意大利语）和 DIMEMEX（西班牙语）。

**📈 对比分析**

通过准确率和宏 F1 分数比较不同提示语言、学习模式与翻译方案，结果显示本土提示加一拍学习可提升 5–10% F1，翻译方案普遍降低 10–15% F1，模型规模与跨文化一致性呈正相关。

**⚠️ 局限性**

局限在于仅覆盖六种语言且未涉及低资源或非拉丁文字；翻译依赖 Google，可能引入语义失真；对非视觉文本提示的适配不足，未来需要更多人类评估与更广泛的语言覆盖。

---

## 316. Robust Ultra-High-Dimensional Variable Selection With Correlated Structure Using Group Testing

**arXiv ID:** 2602.07258 | [PDF](https://arxiv.org/pdf/2602.07258v1)

**作者:** Wanru Guo `[一作]` (University of Maryland), Curtis Tatsuoka `[通讯]` (University of Maryland)

**通讯引用:** 6763 | [OpenAlex ID](https://openalex.org/A5058475515)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出了一种基于Dorfman组检验的多阶段高维变量筛选框架，自动构建数据驱动的分组并在组级和变量级分别进行检验，随后用弹性网或自适应弹性网进行最终变量选择，并为含异常、非正态数据设计了Huber加权鲁棒变体；

**💡 创新点**

创新点在于将经典的Dorfman组测试理念与高维回归结合，利用层次聚类和图形Lasso/OGK产生稀疏协方差的自适应分组，实现了高效、低假阳性、鲁棒的分组筛选流程；

**🔧 技术方法**

所用技术包括层次聚类、平均连结与动态树切割、图形Lasso、OGK稳健协方差、Huber M‑估计、弹性网与自适应弹性网、交叉验证调参以及贝叶斯优化/分块并行计算；

**📊 数据集**

实验数据包含模拟数据（n=200, p=1000，分组多级相关结构）以及真实的GDSC NSCLC RNA‑seq与trametinib IC50数据；

**📈 对比分析**

与SIS‑LASSO、Group AR2、EN、Adaptive EN以及传统Dorfman做对比，在正常模拟中Robust‑OGK‑Dorfman‑Adaptive‑EN取得最高F1=0.926、RMSE=1.256；在受污染模拟中同方法F1=0.809、RMSE=5.25；在GDSC实验中RMSE最低2.17且临床相关度最高；

**⚠️ 局限性**

局限性包括对p≫n时需要分块、并行与贝叶斯调参，图形Lasso在极高维下易失稳，鲁棒OGK计算成本较高，且缺乏完整的理论收敛与选择性保证。

---

## 317. Adaptive Retrieval helps Reasoning in LLMs -- but mostly if it's not used

**arXiv ID:** 2602.07213 | [PDF](https://arxiv.org/pdf/2602.07213v1)

**作者:** Srijan Shakya `[一作]` (Institute of Machine Learning), Korbinian Pöppel `[通讯]` (ELLIS Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了动态检索增强的生成模型，构建了适配检索的LLM推理代理，并在数学推理基准上评估其效果。

**💡 创新点**

将检索视为动态上下文学习，使LLM在推理过程中主动决定何时检索，展示了自我认知检索调度的价值。

**🔧 技术方法**

采用Llama-3.1-8B-Instruct为核心模型，配合BAAI/bge-m3双编码器+FAISS检索、bge-m3-reranker重排序以及工具调用机制实现自适应检索。

**📊 数据集**

在GSM8K和MATH-500两套数学推理基准上进行实验，并使用MathPile与OpenMathInstruct-2两套知识库进行检索。

**📈 对比分析**

与Chain-of-Thought基线和静态检索CoT进行比较，适配检索CoT在GSM8K提升1.1个百分点，在MATH-500提升6.4个百分点，表现明显优于静态检索。

**⚠️ 局限性**

检索精度不高，检索内容并非总能提升正确率；静态检索会引入噪声；模型在更广泛领域的迁移性和鲁棒性仍需进一步验证。

---

## 318. Information Theoretic Modeling of Interspecies Molecular Communication

**arXiv ID:** 2602.07474 | [PDF](https://arxiv.org/pdf/2602.07474v1)

**作者:** Bitop Maitra `[一作]` (Koc University), Ozgur B. Akan `[通讯]` (University of Cambridge)

**通讯引用:** 11174 | [OpenAlex ID](https://openalex.org/A5042130660)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

本研究构建了基于植物挥发性有机化合物（VOC）混合物的跨物种分子通信ICT框架，包括风扩散传播模型、跨反应受体的绑定时间统计模型，并利用Fisher信息推导时间平均渐近容量；

**💡 创新点**

创新点在于①将VOC混合物作为信息符号编码；②提出基于绑定时间的跨反应受体多项式通道模型；③将化学动力学参数与Fisher信息结合，得到环境（风速、距离）对容量的非单调影响；④提供实环境下的容量评估方法；

**🔧 技术方法**

主要技术包括：信息理论（Fisher信息、渐近容量）、多项式分布模型、风扩散传播方程、符号混合参数、数值仿真；

**📊 数据集**

使用的数据集为6种VOC（β‑Ionone、MeSA、Geraniol、Limonene、β‑Caryophyllene、β‑Ocimene）的扩散系数、结合/解离速率、K_D等化学参数，受体参数（ApisOBP9、HaxyOBP15、ApisOB2）来自文献；模拟中采用N=1 μmol、风速700 cm/s、昆虫速度200 cm/s等场景；

**📈 对比分析**

通过数值仿真计算不同N、风速和距离下的时间平均渐近容量，并绘制相应曲线。结果显示容量在中等距离与较慢风速时最高，过快风速或距离过近会导致容量下降，表明传统“速度越快越好”的直觉并不成立；

**⚠️ 局限性**

模型局限包括：假设一维受体运动与恒定风速、忽略VOC降解与复杂大气湍流、仅考虑二元符号与有限受体、未包含神经处理层、缺乏实验验证，仅为理论与数值分析。

---

## 319. Process-of-Thought Reasoning for Videos

**arXiv ID:** 2602.07689 | [PDF](https://arxiv.org/pdf/2602.07689v1)

**作者:** Jusheng Zhang `[一作]` (Sun Yat-sen University), Keze Wang `[通讯]` (Sun Yat-sen University)

**通讯引用:** 2280 | [OpenAlex ID](https://openalex.org/A5088124671)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种名为 LogicAgent 的视频到文本生成框架，能够把视频拆分成可验证的事件链，从而实现过程级的因果推理与可解释性。

**💡 创新点**

创新点包括：① 将时间逻辑视为可学习的潜在变量，使用功能优化将符号链变为可微分；② 引入四项联合损失（预测、逻辑一致、反事实鲁棒性、稀疏性），实现对链的主动学习；③ 通过事件化器、链生成器和混合验证器构建完整的可验证推理流水线。

**🔧 技术方法**

核心技术包括：基于 Transformer 的视觉编码器、离散事件化器（事件抽取 + 结构化标签），离散链生成器（条件采样 + 代码库），混合可微逻辑验证器（时间/语义规则 + MLP），以及 REINFORCE 训练策略。

**📊 数据集**

使用的数据集覆盖多任务：VIST、Ego4D、MMIU、PororoSV、WebQA、MSR‑VTT、YouCook2、ViTT、ActivityNet、POPE、MME 等，体现了从叙事生成到稠密事件标注、QA 与图像一致性评估的多样性。

**📈 对比分析**

与多类基线（开源 LVLMs 如 Qwen3‑VL‑8B、GPT‑4o，专用视频推理模型如 NS‑DR、NSVS‑TL 等）对比，LogicAgent 在多项指标上均实现了显著提升：例如在 VIST、Ego4D、MMIU 上均比 Qwen3‑VL‑8B 多得 0.02‑0.03 分，在 MSR‑VTT 的因果理解 (CU) 与一致性 (IC) 上超过 GPT‑4o；在稠密事件标注任务中，随训练数据从 1% 到 100% 的增大，Performance 维持领先并呈现稳定的规模提升。

**⚠️ 局限性**

局限性包括：① 需要预定义的符号代码库，若符号覆盖不足会限制推理范围；② 由于链的离散采样与验证过程，训练和推理成本相对较高；③ 在极其复杂或多模态长视频中，事件化器的精度仍是瓶颈；④ 仍可能出现基于训练分布偏差导致的逻辑错误或偏见，需要进一步的公平性与鲁棒性评估。

---

## 320. Visualizing the Invisible: Enhancing Radiologist Performance in Breast Mammography via Task-Driven Chromatic Encoding

**arXiv ID:** 2602.07568 | [PDF](https://arxiv.org/pdf/2602.07568v1)

**作者:** Hui Ye `[一作]` (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences), Chulong Zhang `[通讯]` (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了MamomoColor框架，通过任务驱动的色彩编码（TDCE）将乳腺X线片转换为彩色图像，以提高放射科医生在密集乳腺中的诊断表现。

**💡 创新点**

创新点在于将可学习的TDCE模块与BI‑RADS分级分类器端到端联合训练，产生以诊断风险为导向的彩色映射，而非传统固定伪彩色或对比增强。

**🔧 技术方法**

采用轻量级U‑Net式TDCE编码器‑解码器、ImageNet预训练的ResNet‑18特征提取器，以及多读者多案例（MRMC）观测实验评估。

**📊 数据集**

在VinDr‑Mammo（训练集）以及CBIS‑DDSM、INBreast、Liuzhou、Shenzhen、Xuzhou等六个独立多中心数据集上进行评估。

**📈 对比分析**

通过AUC、敏感度、特异度等指标对比灰度基线与TDCE图像，在大部分数据集上TDCE显著提升AUC（如VinDr‑Mammo从0.767提升到0.846），尤其在密集乳腺和肿块、钙化子等子组内表现更优；MRMC实验显示TDCE提升特异度并维持总体准确率。

**⚠️ 局限性**

局限性包括对扫描胶片（CBIS‑DDSM）等大域漂移影像的鲁棒性不足、观测实验样本为回溯性富集集、以及色彩编码可能引发注意力偏移等潜在人因问题。

---

## 321. Condition Matters in Full-head 3D GANs

**arXiv ID:** 2602.07198 | [PDF](https://arxiv.org/pdf/2602.07198v1)

**作者:** Heyuan Li `[一作]` (Chinese University of Hong Kong Shenzhen), Xiaoguang Han `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于视角无关语义条件的全头3D生成模型BalanceHead，并构建了11.2M平衡的360°头部图像数据集BalanceHead360。

**💡 创新点**

创新点在于：①使用前视图的CLIP语义特征作为条件，消除视角偏差；②设计ViCiCo一致性损失以抑制多面体伪影；③利用Flux.1 Kontext生成多视角数据并通过Qwen2.5-VL过滤，获得高质量且视角均衡的数据集。

**🔧 技术方法**

采用的技术包括：3D-aware GAN（HyPlaneHead框架）+ StyleGAN2骨干+ hy-plane三平面表示；视角无关语义条件；ViCiCo一致性损失；Flux.1 Kontext 2D生成；CLIP特征提取；Qwen2.5-VL 图像过滤。

**📊 数据集**

数据集主要是通过Flux.1 Kontext从FFHQ、CelebA、WildHead等前视图数据扩展得到的11.2M平衡360°头部图像BalanceHead360；对比实验中使用SphereHead、HyPlaneHead等公开数据集。

**📈 对比分析**

在FID-view、FID-random、FID-front等指标与EG3D、GGHead、PanoHead、SphereHead、HyPlaneHead以及两种消融基线对比，BalanceHead在所有指标上均显著更优（如FID-random 3.51 vs 13.82），实现更高的多样性和全视角一致性。

**⚠️ 局限性**

局限性包括：仍存在少量多面体伪影；对极端姿态或极端发型的生成仍受限；数据集构建需要大量算力，且生成的多视角图像虽保持语义但不保证严格的3D一致性。

---

## 322. ViCA: Efficient Multimodal LLMs with Vision-Only Cross-Attention

**arXiv ID:** 2602.07574 | [PDF](https://arxiv.org/pdf/2602.07574v1)

**作者:** Wenjie Liu `[一作]` (Ningbo Key Laboratory of Spatial Intelligence and Digital Derivative, Institute of Digital Twin, Eastern Institute of Technology), Xiaoyu Shen `[通讯]` (LMU Munich)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 ViCA，一种仅在少数层进行视觉-语言交叉注意力、冻结视觉标记写入的极简 MLLM 结构，显著降低视觉计算量。

**💡 创新点**

核心创新在于通过自注意力与交叉注意力的冗余诊断，证明视觉标记无需全层更新，且跨模态交互集中在少数关键层，从而实现架构层面的高效裁剪。

**🔧 技术方法**

采用视觉标记冻结、稀疏交叉注意力、FlashAttention 兼容的高效实现，并结合 PDrop 等 token‑dropping 方法进一步压缩。

**📊 数据集**

在 LLaVA‑1.5（MobileLLaMA‑2.7B、Vicuna‑7B‑v1.5、Vicuna‑13B‑v1.5）三种主干上，使用 MMEP、MMB、MMBCN、GQA、VQAv2、ScienceQA‑Image、TextVQA、POPE、SEED‑Image 共九个公开多模态基准。

**📈 对比分析**

与 26 种现有 pruning 方法对比，ViCA 在保持约 98% 原始准确率的同时将视觉 FLOPs 降至 4% 以内；单批推理速度提升 3.5×，多批推理速度提升 10×以上；与 token‑dropping 组合可进一步压缩至 2% 计算量而仅损失 1–3% 准确率。

**⚠️ 局限性**

局限性包括：主要针对视觉-语言任务，对其他模态（语音、时间序列）验证不足；需要在特定 LLaVA‑1.5 体系下训练；在极小模型或极大批量规模下 CUDA 利用率仍可能受限。

---

## 323. Artificial Intelligence in Open Source Software Engineering: A Foundation for Sustainability

**arXiv ID:** 2602.07071 | [PDF](https://arxiv.org/pdf/2602.07071v1)

**作者:** S M Rakib UI Karim `[一作]` (University of Missouri), Sean Goggins `[通讯]` (University of Missouri)

**通讯引用:** 2817 | [OpenAlex ID](https://openalex.org/A5037107679)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `a2602d71-93ab-4bad-974b-672788df8193` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

系统梳理了人工智能在开放源代码可持续发展中的应用，归纳主要挑战、技术方案及伦理风险，构建跨学科研究综述框架

**💡 创新点**

提出了AI技术与OSS可持续性相结合的综合分类与方法论，首次将可持续性维度（贡献者激励、财务、代码质量、安全、治理、生态）与AI技术（LLM、机器学习、NLP、推荐、机器人）对应，形成统一的评估视角

**🔧 技术方法**

主要使用系统综述方法（PRISMA流程、关键词检索、主题综合分析），结合AI技术概述（如LLM、机器学习、静态/动态分析、推荐系统、机器人）

**📊 数据集**

检索并筛选了Scopus、Web of Science、ACM Digital Library、IEEE Xplore、arXiv等学术数据库中近五年内的论文，形成约200篇高质量研究样本

**📈 对比分析**

通过主题比较和表格对比不同AI技术在解决OSS可持续性问题上的优势与局限，对比分析未给出具体实验性能指标，而是总结各技术的适用情景、成功率与风险

**⚠️ 局限性**

局限性包括：缺乏纵向与实证数据；研究多聚焦短期指标，缺少对社区治理与长期影响的评估；数据异质性和偏见可能影响结论；对AI工具实际部署与伦理规范的探讨仍不足

---

## 324. Probing Neural TSP Representations for Prescriptive Decision Support

**arXiv ID:** 2602.07216 | [PDF](https://arxiv.org/pdf/2602.07216v1)

**作者:** Reuben Narad `[一作]` (University of Washington), Michael Wagner `[通讯]` (University of Washington)

**通讯引用:** 42326 | [OpenAlex ID](https://openalex.org/A5045721609)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

研究神经TSP解算器的内部表示能否迁移到预防决策任务（节点移除敏感度和边禁用敏感度）。

**💡 创新点**

证明解算器表示可用于迁移到这些NP‑hard决策任务，并且迁移效果随解算器质量提升而提升。

**🔧 技术方法**

采用注意力Transformer基TSP解算器，冻结编码器取节点/边嵌入，训练线性/DeepSets/SetTransformer探针，使用Concorde生成标签。

**📊 数据集**

以欧氏TSP100为主（3000/1000实例），训练三种规模模型。

**📈 对比分析**

与几种几何启发式和基于最佳路线的启发式对比，探针在节点移除任务中Top‑1 65%/Top‑5 93%，在边禁用任务中Top‑1 73%/Top‑5 98%，明显优于纯几何模型且与最佳启发式相当。

**⚠️ 局限性**

限于小规模实例、仅考虑基于最优路线的候选集，标签生成耗时大，且未验证更大规模或其他约束的迁移效果。

---

## 325. Probabilistic Modeling of Venture Capital Portfolio Outliers

**arXiv ID:** 2602.07761 | [PDF](https://arxiv.org/pdf/2602.07761v1)

**作者:** Kensei Sakamoto `[一作]` (University of Oxford), Yigit Ihlamur `[通讯]` (Vela Research)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

构建并使用潜在因子模型量化风险投资组合中成单（unicorn）之间的相关性，评估不同组合在零、1、2个成单出现概率及其条件期望，揭示分散化与风险/收益的权衡。

**💡 创新点**

将信用风险的潜在因子方法迁移到VC领域，既保留个体成功概率，又通过可解释的行业、地域、创始人类型因子实现相关性；提出可检验的桥接框架并系统比较不同组合结构对左尾风险与条件收益的影响。

**🔧 技术方法**

潜在因子模型（Gaussian latent variable）、Cholesky分解、蒙特卡罗仿真、相关矩阵估计、Beta分布合成成功概率、统计比较（概率分布、期望条件分析）。

**📊 数据集**

使用公开股市ETF及上市公司月度对数回报估计行业、地域、创始人类型因子的相关矩阵；合成成功概率采用Beta分布并手工赋予行业/地域偏差。

**📈 对比分析**

通过对比独立模型、单因素模型和多因素模型下的成单分布；对不同组合（A、B、C、D、E、F、G）和规模变化（5-40）进行蒙特卡罗仿真，评估零/1/2成单概率和条件期望。结果显示：分散化降低左尾风险但提升条件收益；规模增加提升期望但对左尾风险改善有限；相关性显著限制了提高单个投资成功率对降低风险的作用。

**⚠️ 局限性**

假设每家公司仅归属单一行业；相关矩阵取自公开市场，可能与私募实际相关性不符；相关性被假设为静态；Gaussian因子可能低估极端共动；未考虑行业、地域与创始人类型的交互；模型仅涵盖行业、地域、创始人三种因子。

---

## 326. SupChain-Bench: Benchmarking Large Language Models for Real-World Supply Chain Management

**arXiv ID:** 2602.07342 | [PDF](https://arxiv.org/pdf/2602.07342v1)

**作者:** Shengyue Guan `[一作]` (Alibaba Group), Lang Cao `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 67 | [OpenAlex ID](https://openalex.org/A5113039527)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 SupChain-Bench 基准，用于评估大型语言模型在供应链管理中的知识掌握与多步骤工具调用能力，并提出 SupChain-ReAct 框架实现无人工 SOP 的长链执行。

**💡 创新点**

创新点在于：①将知识问答与长链工具调用联合评估；②设计多难度层级的工具调用数据集；③提出无 SOP 的 SupChain‑ReAct，通过多路径 ReAct 与投票实现更稳定的执行。

**🔧 技术方法**

采用大型语言模型推理、ReAct 交互、工具调用（function calling）、多路径采样与自一致性投票技术，对比 SOP 指导与无 SOP 情况。

**📊 数据集**

使用 SupChain-Bench 数据集，包括 141 道多选、147 道单选、147 道真伪问答，以及按 3 个功能域划分的工具调用问答，难度分为 L1（≤15 步）、L2（15–25 步）和 L3（>25 步）。

**📈 对比分析**

通过在无/有上下文、无/有 SOP 两种设置下测评各模型的 QA 与工具调用准确率；GPT‑5 在 SOP 指导下工具调用准确率可达 88%+；SupChain‑ReAct 在无 SOP 情况下即可达到 70%+ 的准确率，显著优于传统 SOP 引导。

**⚠️ 局限性**

局限性包括：仅覆盖文本与工具交互，未考虑多模态信号（传感器、图像、实时日志）等实际生产环境中常见的复杂性和不确定性。

---

## 327. Rethinking Scientific Modeling: Toward Physically Consistent and Simulation-Executable Programmatic Generation

**arXiv ID:** 2602.07083 | [PDF](https://arxiv.org/pdf/2602.07083v1)

**作者:** Yongqing Jiang `[一作]` (Sichuan University), Haoran Luo `[通讯]` (Nanyang Technological University)

**通讯引用:** 145 | [OpenAlex ID](https://openalex.org/A5101634508)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了面向建筑结构建模的自动化任务AutoBM，构建了专门的数据集CivilInstruct和评测基准BMEval，并通过两阶段强化学习实现物理一致性与API符合性的代码生成。

**💡 创新点**

创新点在于将结构工程知识与物理约束嵌入LLM生成流程，设计了RLA‑SPC两阶段强化学习框架，并引入多粒度混合奖励与闭环验证评估。

**🔧 技术方法**

采用大语言模型（如OpenAI GPT‑5、Claude‑Sonnet等）进行监督微调，再通过SPC‑GRPO强化学习对生成代码进行物理约束对齐。

**📊 数据集**

使用CivilInstruct数据集（约3.8k API学习样本+3.1k专家指令代码+3.5k Bug‑CoT样本+512带物理标签代码）以及BMEval评测集（128个结构模型样本）。

**📈 对比分析**

在BMEval上对比多款主流LLM，基线模型Pass@5≈10%~20%，通过RLA‑SPC后大幅提升至≈70%–90%，显著提升了可执行性、工程合规性和物理一致性。

**⚠️ 局限性**

主要局限在执行阶段仍易出错、物理参数理解不足导致合规率低，且对几何拓扑和多步骤推理的鲁棒性尚未完全实现。

---

## 328. Differentiate-and-Inject: Enhancing VLAs via Functional Differentiation Induced by In-Parameter Structural Reasoning

**arXiv ID:** 2602.07541 | [PDF](https://arxiv.org/pdf/2602.07541v1)

**作者:** Jingyi Hou `[一作]` (University of Science and Technology Beijing), Wei He `[通讯]` (Beijing Information Science and Technology University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `8d10c613-917e-4880-9716-17789f50e119` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

通过在模型参数中注入动态场景图结构，使VLA模型实现任务级语义分解和功能区分，从而提升长期任务的可靠性和泛化。

**💡 创新点**

将任务层级语义结构直接嵌入VLA参数，实现“in-parameter structural reasoning”，避免外部规划或基于提示的解构，提供可重用的语义承诺。

**🔧 技术方法**

预动作VLA模块提取概念表示，动态隐式概念图构造、属性门控、时序编码、关系注意力；子任务提示投影与蒸馏；结构学习目标与熵正则。

**📊 数据集**

VIMA‑Bench、LIBERO以及工业UR3机器人真实实验。

**📈 对比分析**

与VIMA（Small/ Large）、OpenVLA‑OFT、π0、Evo‑1等基线对比，在VIMA‑Bench L1‑L4、LIBERO四套任务以及真实机器人任务中，iSTAR在高难度长任务上提升约4‑8 %成功率，整体表现优于同等规模基线。

**⚠️ 局限性**

受限于底层VLA的视觉‑语言编码能力；结构化方法在任务信息已明确、顺序固定时提升有限；需进一步精调图结构与门控以提升更大规模任务的鲁棒性。

---

## 329. FEM-Informed Hypergraph Neural Networks for Efficient Elastoplasticity

**arXiv ID:** 2602.07364 | [PDF](https://arxiv.org/pdf/2602.07364v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 330. SpatialReward: Bridging the Perception Gap in Online RL for Image Editing via Explicit Spatial Reasoning

**arXiv ID:** 2602.07458 | [PDF](https://arxiv.org/pdf/2602.07458v1)

**作者:** Yancheng Long `[一作]` (Harbin Institute of Technology), Shuo Yang `[通讯]` (Kuaishou Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 SpatialReward 奖励模型，通过显式空间推理解决图像编辑 RL 中的注意力坍塌问题。

**💡 创新点**

引入“Think-with-Boxes”机制将编辑框嵌入推理，提供跨图像空间对齐，并构建 260k 空间推理数据集及 MER‑Bench；同时采用加权几何平均奖励聚合。

**🔧 技术方法**

基于 Qwen‑3‑VL‑8B‑Instruct 的指令生成、SFT+GRPO 训练、空间先验的推理框预测以及加权几何平均奖励聚合。

**📊 数据集**

SpatialReward‑260k（由改进的 EditScore、EditReward 与自建多编辑样本构成）以及多编辑基准 MER‑Bench。

**📈 对比分析**

与 EditReward‑Bench、MMRB2、MER‑Bench 以及闭源 GPT‑4.1/5、Gemini 等模型对比，SpatialReward 在所有评测上名列前茅；在 OmniGen2 的在线 RL 训练中在 GEdit‑Bench 提升 +0.90，超过 GPT‑4.1。

**⚠️ 局限性**

仍受限于训练数据质量与规模、计算资源需求较高，对极端多目标编辑的鲁棒性与泛化性待进一步验证。

---

## 331. Airspace-aware Contingency Landing Planning

**arXiv ID:** 2602.07074 | [PDF](https://arxiv.org/pdf/2602.07074v1)

**作者:** H. Emre Tekaslan `[一作]` (Virginia Polytechnic Institute and State University), Ella M. Atkins `[通讯]` (Virginia Polytechnic Institute and State University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `5b4c1114-4a70-478e-9921-2514ee03850d` `9cc9baba-5356-466d-81ff-d80028d90279` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

开发了一种实时、基于搜索的应急着陆规划器，能够在考虑高密度空域和地面人口风险的前提下为机组提供安全、低干扰的降落路径。

**💡 创新点**

创新点在于将ADS‑B 生成的空域密度热图与三维多面体航道/禁区几何模型结合，并利用梯度引导搜索同时最小化空域暴露时间与地面风险。

**🔧 技术方法**

使用的技术包括梯度引导树搜索、三维 Dubins 路径回退、基于计算几何的多面体距离计算、热图生成以及前向锥形采样启发式。

**📊 数据集**

所用数据集为华盛顿特区的 OpenSky Network 历史 ADS‑B 轨迹、航空图中的直升机航道和禁区，以及人口密度地图。

**📈 对比分析**

与三维 Dubins 基准方案对比，搜索方案在 87% 的空域风险案例和 60% 的联合风险案例中表现更优；平均运行时间分别为 2.9 s（空域风险）和 9 s（联合风险），均落在可接受的实时阈值内。

**⚠️ 局限性**

局限性包括依赖静态交通数据，缺乏实时更新；启发式成本不可满足可采性，可能导致地面风险升高；若搜索超时则退回 Dubins 方案，整体求解不总是最优。

---

## 332. Pro-ZD: A Transferable Graph Neural Network Approach for Proactive Zero-Day Threats Mitigation

**arXiv ID:** 2602.07073 | [PDF](https://arxiv.org/pdf/2602.07073v1)

**作者:** Nardine Basta `[一作]` (Macquarie University), Andy Walker `[通讯]` (Ditno Inc.)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出Pro-ZD框架，利用图神经网络自动识别并缓解可被零日攻击利用的高危网络连接，通过实时调整防火墙规则和零信任策略实现主动防御。

**💡 创新点**

创新点包括：1) GraphWSP可迁移的加权最短路径GNN，融合SPGNN和GAT以学习路径权重；2) 通过结构特征FS_1评估连接易受攻击性；3) 将风险评估与自动化策略调整结合，实现从检测到缓解的闭环。

**🔧 技术方法**

采用图神经网络（GNN）+图注意力网络（GAT）+短路路径GNN（SPGNN）+深度神经网络分类器，配合子图数据增强、迁移学习与半监督学习等技术，构建端到端评估与自适应修复系统。

**📊 数据集**

使用两组数据集：真实企业网络数据RTD_1（法律事务所）和RTD_2（高校）以及两组合成数据STD_1、STD_2，均包含资产节点、边属性、合规标签等。

**📈 对比分析**

在加权最短路径识别任务中，将GraphWSP与基线SPAGAN对比，GraphWSP平均精度超过85%（SPAGAN 63%）；在高危连接分类任务中，Pro‑ZD在四个数据集上的准确率达96–100%，F1和ROC‑AUC均在0.95以上，迁移学习实验亦显示稳健的跨图性能。

**⚠️ 局限性**

局限性包括：对RTD_1等小规模、标注不成熟的数据集表现略差；模型仍需依赖人工标注的高危连接标签；在极端动态网络环境下可能需要进一步适配；SPGNN本身不考虑边特征，导致对复杂权重的捕获有限。

---

## 333. TLC-Plan: A Two-Level Codebook Based Network for End-to-End Vector Floorplan Generation

**arXiv ID:** 2602.07100 | [PDF](https://arxiv.org/pdf/2602.07100v1)

**作者:** Biao Xiong `[一作]` (Wuhan University of Technology), Xian Zhong `[通讯]` (Wuhan University of Technology)

**通讯引用:** 10736 | [OpenAlex ID](https://openalex.org/A5064999906)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种端到端的向量化平面图生成方法TLC‑Plan，能够直接从建筑边界生成 CAD 级别的房间布局与精细几何；

**💡 创新点**

创新点在于：1）采用两级 VQ‑VAE 生成全局房间布局代码和细化多边形代码，并将其统一为 CodeTree 结构；2）使用自回归 transformer 在不依赖预设拓扑或尺寸先验的情况下完成布局与几何的联合建模；3）通过掩码重构和 EMA 更新提升代码库的可重用性和稳定性；

**🔧 技术方法**

技术方法包括：两级向量量化变分自编码器（VQ‑VAE）+ 位置编码+掩码重构；自回归 transformer 预测 CodeTree；多尺度编码器/解码器；EMA 代码库更新；Top‑p 采样；

**📊 数据集**

使用 RPLAN（81,235 个住宅平面图）和 LIFULL（10,804 个日式住宅向量化平面图）进行训练与评估；

**📈 对比分析**

与 Raster‑based（RPLAN、Graph2Plan、iPLAN、MaskPLAN）及 Vector‑based（GSDiff）等基线相比，TLC‑Plan 在 RPLAN 上实现 FID_img 1.84、MSE_T 0.20、MSE_A 2.09、MSE_S 2.41，几何一致性指标 MRG/MRE/MRO 均低于 1%；在 LIFULL 上 FID_img 9.08、MSE_T 0.34、MSE_S 8.96，整体性能领先或相近；

**⚠️ 局限性**

局限性包括：仅以建筑边界为条件，未考虑文字提示或固定结构元素；对极复杂边界或超大布局的泛化受限；前门位置和房间数量偶尔出现错误；代码库容量受限，难以捕捉极高细节；未来可扩展至多层建筑与城市尺度。

---

## 334. Going with the Flow: Koopman Behavioral Models as Implicit Planners for Visuo-Motor Dexterity

**arXiv ID:** 2602.07413 | [PDF](https://arxiv.org/pdf/2602.07413v1)

**作者:** Yunhai Han `[一作]` (Institute for Robotics and Intelligent Machines), Harish Ravichandar `[通讯]` (Institute for Robotics and Intelligent Machines)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出统一行为模型（UBM），将多指抓握操纵看作视觉与本体状态耦合的动态系统，并通过隐式规划实现全时域行为生成。

**💡 创新点**

创新点在于使用 Koopman 运算符构建可解释的线性潜在动力学，实现状态包含升维、闭环预测监控以及事件触发的重规划，解决传统反应式策略的时序不连贯与对遮挡敏感的问题。

**🔧 技术方法**

核心技术包括：视觉特征提取（Object Flow、DynaMo）、Koopman 升维编码、共训练的线性潜在动力学、基于多步预测的损失、身份初始化与学习率调节，以及基于视觉误差的重规划触发。

**📊 数据集**

在 DexArt（桶、笔记本、马桶）与 Adroit（门、工具、手内重定位、物体移动）仿真任务以及 Kinova arm + PSYONIC hand 的真实任务（揭露锅、打开盖子）上进行实验。

**📈 对比分析**

与扩散策略、ACT、KODex、KOROL 等基线对比，K‑UBM 在任务成功率上匹配或超过基线，推理速度更快、对遮挡更鲁棒，并通过事件触发实现良好的自适应重规划。

**⚠️ 局限性**

局限性包括：线性动力学对接触跳跃的高频变化处理不足、开环规划在高度随机环境下可能失效、对视觉反馈的强依赖导致遮挡时重规划延迟，缺乏触觉反馈补偿。

---

## 335. Expansive homeomorphisms on complexity quasi-metric spaces

**arXiv ID:** 2602.07685 | [PDF](https://arxiv.org/pdf/2602.07685v1)

**作者:** Yaé U. Gaba `[一作]` `[通讯]`, Yaé U. Gaba

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b`

**🎯 论文内容**

在复杂度量（quasi‑metric）空间上构造并分析了可扩张映射（expansive homeomorphism），研究了尺度变换 ψα(f)(n)=αf(n) 的动力学性质。

**💡 创新点**

创新点在于把不对称的复杂度量与可扩张动力学结合，证明尺度变换在此空间上扩张的充要条件是 α≠1，并将稳定集与复杂度类、离散集与时间层级定理等经典复杂度概念在动力学框架中得到新的几何描述。

**🔧 技术方法**

使用了可扩张映射、准度量空间、拓扑动力学、符号动力学（canonical coordinates）以及数值验证工具（Python/SageMath）来证明定理并给出算法实现。

**📊 数据集**

论文未使用实验数据集，而是以理论推导和符号/数值实验验证为主；所有例子均基于简单的函数族（线性、平方、指数等）。

**📈 对比分析**

比较方法主要是理论证明和数值演示；论文未给出传统机器学习或算法性能指标，只讨论了距离收敛、指数收敛速率与时间层级的关系，展示了理论层面上的“性能”提升。

**⚠️ 局限性**

限制包括：只研究了线性尺度变换；对非线性或空间复杂度的推广尚未完成；熵的精确值仅给出下界；对一般的准度量空间扩张性质的完整描述仍未完全解决。

---

## 336. Determining the Outerthickness of Graphs Is NP-Hard

**arXiv ID:** 2602.07607 | [PDF](https://arxiv.org/pdf/2602.07607v1)

**作者:** Pin-Hsian Lee `[一作]` (National Taiwan University), Meng-Tsung Tsai `[通讯]` (Academia Sinica)

**通讯引用:** 129 | [OpenAlex ID](https://openalex.org/A5064418445)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

证明了在一般图中确定外厚度（outerthickness）是NP‑难的，并将该难度推广到满足三条闭合性条件的任意图类F的边覆盖/划分问题P_F。

**💡 创新点**

首次给出一个直接、可验证的证明，将外厚度问题归约自k‑正则图的k‑边着色，构造了标签函数φ和辅助图H，并证明对所有满足条件(a)–(c)的图类F都成立。

**🔧 技术方法**

利用图的顶点标签化、图的边极大化构造、拓扑子图与1-和的封闭性等图论工具，以及对k‑正则图的已知NP‑难性结果进行归约。

**📊 数据集**

无实验数据集，全部为理论证明。

**📈 对比分析**

与此前仅在特定类（如平面图）已知外厚度≤2的结果形成对比，证明了k≥3时问题为NP‑完整，体现了问题的计算复杂性。

**⚠️ 局限性**

仅适用于k≥3；k=2的复杂性仍未解决；证明依赖图类满足三条闭合性条件，若不满足则问题可能可解。

---

## 337. Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice

**arXiv ID:** 2602.07319 | [PDF](https://arxiv.org/pdf/2602.07319v1)

**作者:** Savan Doshi `[一作]` (Arizona State University), Savan Doshi `[通讯]` (Arizona State University)

**通讯引用:** 318 | [OpenAlex ID](https://openalex.org/A5062542902)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究者提出一种风险敏感的幻觉评估框架，对患者面对的医疗问答模型生成的安全风险语言进行量化，并通过对比不同规模的FLAN‑T5模型在控制性安全测试提示下的表现进行评估。

**💡 创新点**

创新点在于将幻觉评估从单纯的事实准确性转向关注潜在医疗风险的语言（如治疗指令、紧急提示等），并引入连续的风险敏感幻觉评分（RSHS）与相关性指标的联合分析。

**🔧 技术方法**

采用了模式匹配的风险类别权重机制、对生成文本的RSHS计算以及句子嵌入余弦相似度评估相关性，并使用核采样进行生成。

**📊 数据集**

使用自构造的200条患者提示的安全压力测试数据集，覆盖症状分诊、药物管理、怀孕问题和慢性疾病等情景。

**📈 对比分析**

通过对FLAN‑T5‑small/base/large三种规模模型在同一提示下的RSHS与QASim分布进行比较，发现大模型在上位百分位风险评分更高，展示了规模对风险产生的影响；与传统正确性评估指标不同，RSHS揭示了更细粒度的风险差异。

**⚠️ 局限性**

限制包括未对医学正确性进行评估、仅使用基于模式的风险识别可能漏判或误判、提示为人工合成而非真实临床交流、未验证对实际部署的可迁移性等。

---

## 338. Evaluating Object-Centric Models beyond Object Discovery

**arXiv ID:** 2602.07532 | [PDF](https://arxiv.org/pdf/2602.07532v1)

**作者:** Krishnakant Singh `[一作]` (TU Darmstadt), Stefan Roth `[通讯]` (TU Darmstadt)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

通过指令调优的视觉语言模型（VLM）对对象中心学习（OCL）模型进行零样本评估，并提出统一评估指标 AwGA，构建增强版 GQA 数据集 (eGQA) 以同时考察定位与表示利用。

**💡 创新点**

创新点在于：①利用 VLM 作为评估器实现多任务零样本评估，消除每个任务重新训练探测器的成本；②设计 Attribution‑aware Grounded Accuracy (AwGA) 指标，联合衡量“what”与“where”，解决定位与表示碎片化问题；③提出多目标重建基线，证明融合像素、DINOv2 特征与 HOG 能提升 OCL 表示效能。

**🔧 技术方法**

使用的技术包括：slot‑attention 结构的对象编码器、指令调优的 LLM（Phi‑2、Qwen2 等）与 2‑层 MLP 连接器、梯度或积分梯度归因方法、SAM2 生成掩码、以及基于 VQA 的零样本推理。

**📊 数据集**

使用的数据集：增强版 GQA（eGQA）用于 AwGA 评估；VQAv2、MME、MM‑Vet、POPE 等视觉问答基准；OOD‑CV、SugarCrepe、NaturalBench 用于鲁棒性与组合推理测试。

**📈 对比分析**

在多任务 VQA 评估中，OCL 模型与强自监督视觉编码器 DINOv2 竞争，尤其在 OOD 与数值反事实推理上表现接近甚至优于 DINOv2；在组合推理和自然对抗测试中仍落后。AwGA 指标在不同 LLM 与连接器下保持高度一致，能有效区分不同 OCL 方法的定位与表示质量。

**⚠️ 局限性**

局限性包括：评估需要训练大型 VLM，初始成本高；AwGA 仅适用于具备掩码注释的基准（如 eGQA），对无标注场景适用性有限；评估仍受 LLM 偏见影响，且在视频或更复杂场景中的推广尚未验证。

---

## 339. IM-Animation: An Implicit Motion Representation for Identity-decoupled Character Animation

**arXiv ID:** 2602.07498 | [PDF](https://arxiv.org/pdf/2602.07498v1)

**作者:** Zhufeng Xu `[一作]` (Institute of Computing Technology), Lin Gao `[通讯]` (Institute of Computing Technology)

**通讯引用:** 4664 | [OpenAlex ID](https://openalex.org/A5100629376)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出IM‑Animation框架，通过将每帧运动压缩为1D运动令牌并结合遮罩令牌重定向模块，实现跨身份、跨体型的视频角色动画；

**💡 创新点**

创新点在于构造空间不变的1D运动表示以抑制身份泄漏，以及利用遮罩令牌在自注意力中形成瓶颈以分离源身份与运动信息；

**🔧 技术方法**

采用Transformer‑based 1D分词器、向量量化编码器、Mask‑Token重定向模块以及Diffusion Transformer（DiT）视频生成模型；

**📊 数据集**

使用约5万条自采视频与8千条通过Unreal Engine 5合成的跨身份对数据集；

**📈 对比分析**

与UniAnimate‑DiT、Wan‑Animate、X‑UniMotion等方法在交叉重演与自重演任务上进行PSNR、SSIM、LPIPS、FID、FVD等指标比较，IM‑Animation在PSNR、LPIPS、FID等指标上均表现出更优或相近的性能；

**⚠️ 局限性**

目前对面部表情的独立性控制不足，且无法显式控制摄像机视角，未来需要进一步设计面部重定向模块和相机控制机制。

---

## 340. Realistic Synthetic Household Data Generation at Scale

**arXiv ID:** 2602.07243 | [PDF](https://arxiv.org/pdf/2602.07243v1)

**作者:** Siddharth Singh `[一作]`, Abraham Dauhajre `[通讯]`

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一个生成式框架，用于在大规模上创建包含长时间人机交互与环境的家居数据集，并通过自然语言提示进行灵活配置。

**💡 创新点**

创新点在于：①人机交互与环境的生成是松耦合且相互影响的；②利用人类角色与环境语义共同驱动生成；③提供问答式自然语言交互的生成工具；④通过VLM和用户研究验证合成数据的真实性。

**🔧 技术方法**

使用生成式模型（如3D场景生成、文本-图像生成）、强化学习、视觉语言模型（VLM）、自然语言处理等技术。

**📊 数据集**

主要使用自研的合成家居数据集（包含对象/环境语义与长时间行为轨迹），未使用公开现有数据集。

**📈 对比分析**

通过定性用户研究和VLM评估对比验证真实性；在机器人视角下进行目标导航实验，展示不同人类角色或环境语义对导航结果的影响，但缺乏定量性能指标。

**⚠️ 局限性**

局限性包括：①合成数据与真实世界可能存在偏差；②实验主要基于模拟环境，缺乏真实人机交互验证；③缺少全面的定量性能评估。

---

## 341. Optimizing Chlorination in Water Distribution Systems via Surrogate-assisted Neuroevolution

**arXiv ID:** 2602.07299 | [PDF](https://arxiv.org/pdf/2602.07299v1)

**作者:** Rivaaj Monsia `[一作]` (University of Texas at Austin), Risto Miikkulainen `[通讯]` (University of Texas at Austin)

**通讯引用:** 15486 | [OpenAlex ID](https://openalex.org/A5020441009)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了一种基于进化学习的水分配网络消毒剂注入控制框架，通过神经进化（NEAT）和多目标NSGA‑II在代理网络上寻找最优注入策略，并利用递归神经网络（RNN）作为代理模型来近似EPANET仿真，从而大幅降低评估成本。

**💡 创新点**

创新点在于：①将进化自适应预测（ESP）与多目标NSGA‑II相结合，形成分阶段（curriculum）进化流程；②采用教师–学生知识蒸馏训练因果RNN代理，使其能够捕捉长时序动力学；③通过代理模型的持续细调实现自动正则化，促使搜索在更广阔的目标空间中产生多样化解；④在实际水网数据上展示了与强化学习（PPO）及简单注入策略的显著性能提升。

**🔧 技术方法**

使用的技术包括：NEAT（进化神经网络）、NSGA‑II（多目标排序）、LSTM/bi‑LSTM（代理模型）与教师–学生蒸馏、经验回放、随机梯度下降、自动正则化、Python EPANET 接口、PPO（对照方法）。

**📊 数据集**

数据集来源于“AI for Drinking Water Chlorination Challenge”IJCAI 2025公开的数据，包含固定拓扑的水网、15个监测节点、2条管道流量观测以及随机污染事件，仿真时长覆盖3天和362天，时间步长5分钟。

**📈 对比分析**

与常数/随机注入策略及PPO策略比较时，进化得到的Pareto前沿在“上限违规率”“公平度”“平滑度”“注入成本”和“感染风险”五个目标上均取得更优或相近的表现，特别是课程化NSGA‑II在感染风险下降约30%、成本下降数倍、平滑度提高12–13倍，且整体目标平衡更好。

**⚠️ 局限性**

局限性包括：①代理模型对长周期（数月/年）和极端污染事件的泛化能力有限；②当前实验仅在单一网络拓扑上验证，需在更大规模、多样结构的水网上测试；③代理模型未显式加入物理约束，可能导致不合理的预测；④进化搜索规模受限于计算资源，未探索更大种群/更多世代；⑤实验仅基于仿真，缺乏真实现场验证。

---

## 342. SoK: DARPA's AI Cyber Challenge (AIxCC): Competition Design, Architectures, and Lessons Learned

**arXiv ID:** 2602.07666 | [PDF](https://arxiv.org/pdf/2602.07666v1)

**作者:** Cen Zhang `[一作]` (Georgia Institute of Technology), Taesoo Kim `[通讯]` (Microsoft)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

对DARPA 2023–2025 AI Cyber Challenge（AIxCC）进行系统性分析，评估竞赛设计、最终决赛（AFC）中七支团队的自律网络安全推理系统（CRS）架构、技术与表现，并给出组织和实践的启示。

**💡 创新点**

首次构建完整的竞赛评估框架，提出CRS技术分类与汇总、基于基础工具的CPV可解决性标注、以及通过多维度得分、稳定性与准确性分析发现真正提升CRS性能的关键因素，提出针对资源、可解释性与行业落地的未来改进方向。

**🔧 技术方法**

运用了大型语言模型（LLM）、自动化模糊测试、静态分析、补丁生成代理、SARIF验证、Bundle关联等技术；团队架构多样，包括Ensemble、Agentic、DSPA、Patch-First等；在评估中还使用了自动化脚本和人工审核。

**📊 数据集**

使用了AIxCC提供的53个挑战项目（48 CPs），共63个挑战项目漏洞（CPV），覆盖24个开源仓库（C/Java），并结合OSS‑Fuzz构建的模糊测试 harness、13个SARIF广播以及人工标注的基线技术结果。

**📈 对比分析**

通过竞赛总分、各项子得分（PoV、Patch、SARIF、Bundle）以及准确率惩罚的多维度评估，比较了七支团队的稳定性、发现率、修复率和资源利用率。最终表现显示稳定性和准确率是决定胜负的主要因素，顶尖团队在后期阶段保持持续得分，整体补丁准确率在70–90%之间。

**⚠️ 局限性**

局限包括：系统稳定性问题导致真实可得分率低估、补丁语义正确性仍高比例、资源与LLM成本限制了对小团队的可推广性、对开源模型探索不足、竞赛元数据缺乏后续分析友好性，且缺少多任务协同或跨团队攻击/防御的研究场景。

---

## 343. Learning to Self-Verify Makes Language Models Better Reasoners

**arXiv ID:** 2602.07594 | [PDF](https://arxiv.org/pdf/2602.07594v1)

**作者:** Yuxin Chen `[一作]` (National University of Singapore), Tat-Seng Chua `[通讯]` (National University of Singapore)

**通讯引用:** 60381 | [OpenAlex ID](https://openalex.org/A5089404640)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了大语言模型在生成和自检之间的能力不对称，并证明仅通过训练模型自检即可提升其生成性能，且自检模型生成的推理轨迹更短更高效。

**💡 创新点**

创新点在于揭示生成不自动提升自检能力，而自检训练能反向提升生成效果，并提出将自检作为独立但互补的多任务RL目标。

**🔧 技术方法**

技术上采用RLVR框架、GRPO优化器、基于规则的验证器，并设计了自检训练管线、阶段式初始化和交替训练两种多任务策略。

**📊 数据集**

使用Dapo‑Math‑17K作为训练数据，评估六大数学推理基准（AIME24/25、AMC23、Minerva、MATH500、OlympiadBench）。

**📈 对比分析**

与单纯生成训练、混合训练对比，结果显示自检训练与自检+生成训练均能提升准确率，平均精度提升约2–5个百分点，且推理长度显著下降；自检模型在测试时的自检加投票能进一步提升性能。

**⚠️ 局限性**

局限性包括额外计算开销、实验规模有限、只验证数学推理任务、以及多任务调度策略手工设计且缺乏自适应机制。

---

## 344. tLoRA: Efficient Multi-LoRA Training with Elastic Shared Super-Models

**arXiv ID:** 2602.07263 | [PDF](https://arxiv.org/pdf/2602.07263v1)

**作者:** Kevin Li `[一作]` (University of Illinois Urbana-Champaign), Fan Lai `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 322 | [OpenAlex ID](https://openalex.org/A5101622777)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了一个名为 tLoRA 的框架，能够在共享 GPU 集群中高效批量训练多个低秩适配器（LoRA）作业。框架通过 Shared Super-Model 抽象统一不同 LoRA 作业，采用融合 LoRA kernel 与自适应 nano‑batch 技术，并提供在线残差容量感知的进度守护调度器，实现多任务共用模型权重、共享计算资源。

**💡 创新点**

创新点：
1) 引入 Shared Super‑Model（SSM）将同一 backbone 上的多个 LoRA 作业融合为单一可分布式执行的计算图；
2) 设计融合型低秩 LoRA GPU kernel，并结合 AIMD 控制器动态调节 nano‑batch 数量，实现计算与通信的最大重叠；
3) 提出残差容量感知的增量分组调度算法，既提升整体吞吐，又保证单个作业不被过度抑制，避免饥饿和长尾。

**🔧 技术方法**

使用技术：
- 分布式模型并行（Megatron‑LM、PyTorch FSDP）
- Triton GPU kernel（自定义融合 LoRA kernel）
- AIMD 控制器用于自适应 nano‑batch
- 资源残差与进度打分的在线调度器
- 分层增量分组策略（节点→机架→集群）
- 统计与监控：GPU 利用率、延迟、同步停滞

**📊 数据集**

数据集：
- GSM8K（约 8.5k 个小学数学题）用于训练任务；
- 真实生产 GPU 集群到达记录 ACMETrace，用于模拟作业到达和资源占用。

**📈 对比分析**

对比方法与性能：
- 与 mLoRA（基于简单内存/吞吐启发式批量）、Megatron（单任务训练）、无调度、无 kernel 融合等基线进行对比；
- 结果显示：
  * 集群吞吐提升 1.2–1.8 倍；
  * 单作业完成时间缩短 2.3–5.4 倍；
  * GPU 利用率提升 37%；
  * 在 128 GPU 集群上总体吞吐提升 41%。

**⚠️ 局限性**

局限性：
- 仅针对共享同一 backbone 的 LoRA 训练，对多模型混合或全模型微调的场景适用性有限；
- 调度依赖准确的资源残差估计，若估计误差较大可能导致不理想的作业组合；
- 需要自定义 Triton kernel，增加实现与维护成本；
- 对极端硬件异构（如混合 GPU / TPU）或极大规模分布式系统的鲁棒性未进行全面验证。

---

## 345. Riemannian MeanFlow

**arXiv ID:** 2602.07744 | [PDF](https://arxiv.org/pdf/2602.07744v1)

**作者:** Dongyeop Woo `[一作]` (Korea Advanced Institute of Science and Technology), Kirill Neklyudov `[通讯]` (Mila - Quebec AI Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `40105733-5154-44cd-8090-a8cab9e64b07` `c773407a-6119-4871-b8b3-1e7ae17a6851` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出 Riemannian MeanFlow (RMF)，一种在 Riemannian 流形上实现一步或少步生成的框架；

**💡 创新点**

创新点在于推导三种等价的平均速度表征（Eulerian、Lagrangian、半群），并通过 x₁‑prediction 参数化和半群目标实现高维流形上稳定、高效的流图学习；

**🔧 技术方法**

技术包括：Riemannian 几何基础（指数/对数映射、协变导数）、平均速度的三种等价表达、流图学习的自洽回归目标、x₁‑prediction 参数化、稳定化技巧（时间采样、损失加权、低频时间嵌入）以及基于流图的奖励引导推理；

**📊 数据集**

数据集：DNA 促进子序列（FANTOM5，长度1024），蛋白质主链（SCOPe，N≤128，SE(3)ⁿ），并在合成的高维球面螺旋等仿真任务上做基准；

**📈 对比分析**

与现有多步流形生成模型（Dirichlet FM、Fisher FM、GENIE、FrameDiff、FrameFlow）以及基于一致性模型的比较。RMF 在保持设计可行性、创新性和多样性方面与多步基线相当或优于其10倍以上的采样效率；单步时仍能获得约35% 可设计样本；

**⚠️ 局限性**

局限性：在极高维或极复杂几何（如更大 N 或非嵌入流形）下的数值稳定性仍需进一步验证；奖励引导依赖可微奖励，非可微目标难以使用；以及在一些低噪声下的引导效果不如多步方法。

---

## 346. Bandit Allocational Instability

**arXiv ID:** 2602.07472 | [PDF](https://arxiv.org/pdf/2602.07472v1)

**作者:** Yilun Chen `[一作]` (Chinese University of Hong Kong), Jiaqi Lu `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 17344 | [OpenAlex ID](https://openalex.org/A5043401047)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出并量化了多臂赌博机算法在分配次数上的波动性（allocation variability），并证明了最小化 regret 与减少分配波动性之间的根本性不可兼得的折中。

**💡 创新点**

核心创新是定义新的评价指标 allocation variability，建立了 regret 与 allocation variability 的不可调和乘积下界（Ω(T^{3/2})），以及构造可调节探索函数的 UCB‑f 算法，能够沿着 Pareto 前沿实现任意 trade‑off。

**🔧 技术方法**

使用信息理论的对数似然比、KL 散度分解、Bretagnolle‑Huber 不等式以及流形（fluid）近似对拉普拉斯上界的技术，进一步通过精细的尾部分析证明上界。

**📊 数据集**

论文主要为理论研究，未使用真实数据集，所给例子多为模拟实验（如两臂 Bernoulli/高斯实例）。

**📈 对比分析**

与传统 UCB、MOSS 等算法相比，UCB‑f 在满足相同 regret 下显著降低分配波动性；在 Pareto 前沿上实现了 regret·variability = Θ̃(T^{3/2})，与理论下界相匹配，证明了其最优性。

**⚠️ 局限性**

局限性包括：未讨论 K 维度的依赖关系、仅给出渐近下界且缺乏统一的有限时界；未考虑上下文或强化学习情形；实现复杂度与参数选择仍需经验调优。

---

## 347. Optimization of Precipitate Segmentation Through Linear Genetic Programming of Image Processing

**arXiv ID:** 2602.07310 | [PDF](https://arxiv.org/pdf/2602.07310v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 348. Exactly Computing do-Shapley Values

**arXiv ID:** 2602.07203 | [PDF](https://arxiv.org/pdf/2602.07203v1)

**作者:** R. Teal Witter `[一作]` (Claremont McKenna College), Lucas Rosenblatt `[通讯]` (New York University)

**通讯引用:** 392 | [OpenAlex ID](https://openalex.org/A5068868453)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种利用结构因果模型中不可约集对 do‑Shapley 值进行精确计算与近似的算法。

**💡 创新点**

创新点在于将 do‑Shapley 值重构为不可约集的等价类，导致求解复杂度从指数降到线性，并设计了边界采样器实现固定预算下的高效估计，同时证明只需检验单点可识别性即可保证全局可识别性。

**🔧 技术方法**

技术包括结构因果模型理论、不可约集与闭集的图遍历、等价类权重计算、边界采样与模拟估计，以及 ID 算法可识别性检查。

**📊 数据集**

使用 TALENT 基准中的多种真实世界表格数据集，先通过 GRaSP 学习因果图并拟合梯度提升回归器作为真值函数。

**📈 对比分析**

与两种主流无结构估计器（Monte Carlo 与回归基）对比，在相同查询预算下，边界采样器在低至中等预算时误差低于十倍，且当预算≥不可约集数时实现机器精度，优于对手。

**⚠️ 局限性**

局限包括需已知或可学习准确的因果图；当图高度复杂导致不可约集数接近 2^d 时仍指数；对模型误设或不可识别的情况仍需额外假设。

---

## 349. Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models

**arXiv ID:** 2602.07794 | [PDF](https://arxiv.org/pdf/2602.07794v1)

**作者:** Ningyu Xu `[一作]` (Fudan University), Xuanjing Huang `[通讯]` (Fudan University)

**通讯引用:** 16614 | [OpenAlex ID](https://openalex.org/A5088834359)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在大型语言模型中探测并证明了一个在中后层形成的概念子空间能支撑在上下文中进行概念推理

**💡 创新点**

通过因果中介分析和激活补丁验证该子空间不是旁观现象，而是推理过程的核心机制，并揭示其从早期层到后期层的动态构建与利用过程

**🔧 技术方法**

利用SVD、GCCA、因果中介分析、激活补丁、子空间消融/隔离、跨上下文迁移以及注意力头分析等多种解释性与实验技术

**📊 数据集**

在THINGS数据库（1854个具体可命名概念及其定义）上构造反向词典任务作为实验基准

**📈 对比分析**

在多款开源解码器模型（如Llama‑3.1 70B、Llama‑3、Qwen2.5）上，随着上下文示例数量增加精确匹配率提升至约88%，子空间对比随机基底的恢复率超过90%，消融导致对数概率下降1+，隔离能保持原性能；大模型表现最佳，说明规模化支持该机制

**⚠️ 局限性**

机制在规模上依赖性强，较小模型效果有限；存在冗余与补偿路径，说明子空间并非唯一推理通道；实验聚焦于单一推理任务，未验证其在更广泛推理形式上的通用性

---

## 350. EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge

**arXiv ID:** 2602.07695 | [PDF](https://arxiv.org/pdf/2602.07695v1)

**作者:** Congcong Hu `[一作]` (Bytedance), Shiyu Wang `[通讯]` (Bytedance)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `5a41884c-404f-4688-a89c-aa238c10fe68` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种双塔框架，将 LLM 推理得到的事件文本摘要与历史需求特征融合，用于电商需求预测。

**💡 创新点**

创新点在于：①仅利用 LLM 做事件知识推理，避免直接用 LLM 预测导致数值误差；②使用可解释的文本摘要；③双塔结构保持事件信号不被稀释；④不需要 LLM 微调，易于维护和扩展。

**🔧 技术方法**

技术手段包括：LLM（如 GLM）推理生成事件摘要；文本嵌入 + 位置嵌入；多头自注意力编码历史特征；轻量级前馈预测层；融合权重 λ 控制趋势与事件贡献。

**📊 数据集**

使用真实电商平台数据，时间跨度 2025 年 1–8 月，覆盖 4 个国家、160 个地区，共约 90 万条日级需求记录，并包含促销、假期、激励等业务事件信息。

**📈 对比分析**

与 PatchTST、iTransformer、Time‑LLM、OneFitsAll、ChronosX、NeuralProphet 等基线同样使用事件信息进行比较；整体 MAE/MSE 分别为 0.885/1.682，较最佳基线 ChronosX 提升约 6.6% MAE、2.4% MSE；在事件驱动期间提升 57% MAE、83% MSE。

**⚠️ 局限性**

局限性包括：①依赖 LLM 推理质量和 prompt 设计，需人工维护；②只能利用已知未来事件，无法处理突发事件；③多步预测仅到 T+4，长周期效果未知；④在无事件或短期无波动时可能引入噪声。

---

## 351. Achieving Optimal Static and Dynamic Regret Simultaneously in Bandits with Deterministic Losses

**arXiv ID:** 2602.07418 | [PDF](https://arxiv.org/pdf/2602.07418v1)

**作者:** Jian Qian `[一作]`, Chen-Yu Wei `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899`

**🎯 论文内容**

提出一种在确定性损失且已知切换次数的对手下，同时实现最优静态和动态累积风险的多臂赌博机算法。

**💡 创新点**

首次在该问题设定下实现了两种不同基准（最佳固定臂和最佳变化序列）的同时最优风险；并展示了自适应与显式对手之间的根本差异。

**🔧 技术方法**

利用 Blackwell 逼近性框架构建多目标在线学习，结合负静态风险补偿、动态风险检测与探索率调节，以及对损失向量的估计与裁剪技术。

**📊 数据集**

本工作纯理论分析，无实验数据集，结论基于严格的概率和渐进分析。

**📈 对比分析**

通过理论证明显示：在已知切换次数 S 的确定性对手下，静态风险可达 O(√(A T))，动态风险可达 O(√(S A T))，与各自的下界匹配；与现有仅针对单一基准的算法相比，取得了同时最优的表现。

**⚠️ 局限性**

局限性：仅适用于确定性损失且已知切换次数；对自适应对手无法实现；扩展到随机损失或未知 S 仍是开放难题。

---

## 352. Reasoning-Augmented Representations for Multimodal Retrieval

**arXiv ID:** 2602.07125 | [PDF](https://arxiv.org/pdf/2602.07125v1)

**作者:** Jianrui Zhang `[一作]` (University of Wisconsin-Madison), Yong Jae Lee `[通讯]` (University of Wisconsin-Madison)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种数据中心的增强框架，将视觉推理步骤外部化为文本描述，进而训练检索模型在语义稠密的表示上进行压缩和匹配。

**💡 创新点**

创新点在于通过强大的 VLM（Qwen3-VL-8B）对图像与多模文本进行“密集标注”和“查询重写”，把隐含的推理显式化，从而缓解单一次嵌入既要推理又要压缩的难题。

**🔧 技术方法**

使用 Qwen3-VL-8B 进行视觉标注与查询重写，结合 Qwen3-VL-2B 进行检索模型微调，并采用对比损失和特殊嵌入标记进行训练。

**📊 数据集**

主要在 M-BEIR 基准上进行实验，覆盖了多种任务（如 MSCOCO、VisNews、WebQA、InfoSeek、CIRR 等），并在可公开的 7M 条记录上进行增强。

**📈 对比分析**

与多种强基线（CLIP、SigLIP、DSE、E5-V、GME-2B 等）进行对比，平均提升约 1.5–3% 的 R@1/R@5，尤其在知识密集和修改式检索任务上显著领先，证明了数据增强对性能的积极影响。

**⚠️ 局限性**

局限性包括对增强质量的高度依赖（VLM 生成的描述若不准确会导致误匹配），以及在评测指标上仍受单一正确答案限制（如 FashionIQ、Fashion200k）导致实际效果被低估。

---

## 353. MDL: A Unified Multi-Distribution Learner in Large-scale Industrial Recommendation through Tokenization

**arXiv ID:** 2602.07520 | [PDF](https://arxiv.org/pdf/2602.07520v1)

**作者:** Shanlei Mu `[一作]` (ByteDance Search), Jingjian Lin `[通讯]` (ByteDance Search)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

在大规模工业推荐中，提出了MDL框架，将场景、任务信息与特征统一为token并通过自注意力与交叉注意力实现多场景、多任务学习。

**💡 创新点**

将场景与任务信息视为prompt token，并通过统一token化和三种交互机制（特征自注意、域感知注意、域融合）实现多分布学习。

**🔧 技术方法**

tokenization + 自注意力 + 交叉注意力 + 领域感知注意 + 领域融合 + 预训练Transformer结构（RankMixer基底）。

**📊 数据集**

来自抖音搜索的工业级数据集，包含三种搜索场景和20+任务，约十亿用户交互。

**📈 对比分析**

与RankMixer、SharedBottom、MMoE、STAR、HMoE、PEPNet等多场景多任务基线对比，MDL在QAUC上提升0.23–0.77%，线上A/B测试提升LT30 +0.0626%，降低Change Query Rate -0.3267%。

**⚠️ 局限性**

方法依赖手工特征分组和大量参数，推理成本高，且在不同业务场景迁移时可能需要重新token化或调整域感知机制。

---

## 354. Learned Finite Element-based Regularization of the Inverse Problem in Electrocardiographic Imaging

**arXiv ID:** 2602.07466 | [PDF](https://arxiv.org/pdf/2602.07466v1)

**作者:** Manuel Haas `[一作]` (Institute of Applied Mathematics), Alexander Effland `[通讯]` (Department of Mathematics)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `5b4c1114-4a70-478e-9921-2514ee03850d` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68` `109c2b71-d051-425c-831f-0c544c24280d`

**🎯 论文内容**

提出并实现了一种基于学习的Fields-of-Experts正则化框架，用于电压图像的时空反演问题，并在有限元网格上进行理论分析与数值优化。

**💡 创新点**

创新点在于将数据驱动的FoE先验与空间-时间正则化结合，并在有限元离散化中给出Mosco收敛证明，提供了理论保证与可扩展的优化算法。

**🔧 技术方法**

采用了有限元法、Moreau包络潜能、加速梯度下降、隐式微分与PyTorch深度等技术实现正则化学习与反演。

**📊 数据集**

使用了1000条基于二维心肺模型的合成心电图数据（含随机瘢痕），作为训练与测试集。

**📈 对比分析**

通过与传统Tikhonov和TV正则化在降噪与反演任务中进行对比，FoE方法在L2误差上显著更优（如降噪误差从3.32降至3.0，反演误差从8.32降至7.59）。

**⚠️ 局限性**

局限性包括仅支持均匀时间步长、未实现空间卷积学习、仅在二维合成数据上验证，且计算成本较高。

---

## 355. Trojans in Artificial Intelligence (TrojAI) Final Report

**arXiv ID:** 2602.07152 | [PDF](https://arxiv.org/pdf/2602.07152v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

---

## 356. Cross-View World Models

**arXiv ID:** 2602.07277 | [PDF](https://arxiv.org/pdf/2602.07277v1)

**作者:** Rishabh Sharma `[一作]` (New York University), Stefano Martiniani `[通讯]` (New York University)

**通讯引用:** 34225 | [OpenAlex ID](https://openalex.org/A5045969696)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

研究了一种跨视角世界模型，利用跨视角预测训练，使模型能够在任意给定视角下生成未来状态，从而实现更灵活的规划和空间定位。

**💡 创新点**

创新点是引入跨视角自监督预测作为训练目标，强制模型学习视角不变的3D结构表示，实现多视角并行想象流，并在鸟瞰视角上获得类似认知地图的空间定位能力。

**🔧 技术方法**

使用基于Conditional Diffusion Transformer（CDiT）的架构，并加入可学习的视角嵌入，在动作条件下进行跨视角的扩散生成，采用自监督的跨视角损失进行训练。

**📊 数据集**

使用Aimlabs提供的同步多视角第一人称射击游戏数据，共4186条1分钟片段，包含四个视角（第一人称、鸟瞰、肩后、前视），每帧5fps。

**📈 对比分析**

通过与单视角基线以及四视角模型对比实验，发现两视角模型在相同训练曝光下的同视角预测性能超过单视角基线，并在鸟瞰定位、轨迹一致性及“从地图生成视角”任务上表现优异，误差低于1像素、成功率>90%。

**⚠️ 局限性**

局限性包括仅在固定、已映射环境中训练，缺乏持续更新的记忆；对低信息或冗余视角敏感，过多视角可能削弱性能；与真实多智能体交互的视角互补性尚未验证。

---

## 357. Bidirectional Reward-Guided Diffusion for Real-World Image Super-Resolution

**arXiv ID:** 2602.07069 | [PDF](https://arxiv.org/pdf/2602.07069v1)

**作者:** Zihao Fan `[一作]` (University of Science and Technology of China), Zheng-Jun Zha `[通讯]` (University of Science and Technology of China)

**通讯引用:** 18970 | [OpenAlex ID](https://openalex.org/A5003217535)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了 Bird-SR 框架，采用双向奖励引导的扩散模型实现对真实世界低分辨率图像的高质量超分辨率。

**💡 创新点**

创新点包括：① 通过正向噪声注入与闭式单步恢复实现结构导向的稳定训练；② 通过反向奖励反馈与语义对齐实现对真实图像的感知优化；③ 在不同扩散步长动态平衡结构损失与奖励损失，避免奖励黑客。

**🔧 技术方法**

技术手段：预训练条件扩散模型、奖励反馈学习（ReFL/DRaFT）、相对奖励、DINO 语义对齐、闭式单步推断、动态结构-感知加权。

**📊 数据集**

训练集：DIV2K、DIV8K、Flickr2K、10k FFHQ 合成 LR-HR 对；测试集：DrealSR、RealSR、RealLR200、RealLQ250 四个真实超分基准。

**📈 对比分析**

与 ResShift、StableSR、SeeSR、DiffBIR、SUPIR、DreamClear、DiT4SR 等方法在 LPIPS、MUSIQ、MANIQA、ClipIQA、LIQE 等非参考指标上进行对比，Bird‑SR 在所有四个真实数据集上均取得最优或接近最优的感知质量，并在用户研究中显著优于对手。

**⚠️ 局限性**

局限性：① 训练成本受双向流程影响较高；② 对奖励黑客的抑制仍依赖经验调参；③ 对极端退化或不同放大倍数的鲁棒性尚未充分验证。

---

## 358. NAAMSE: Framework for Evolutionary Security Evaluation of Agents

**arXiv ID:** 2602.07391 | [PDF](https://arxiv.org/pdf/2602.07391v1)

**作者:** Kunal Pai `[一作]` (University of California), Harshil Patel `[通讯]` (University of California)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了NAAMSE，一个基于进化算法的单体智能体框架，用于对AI代理进行连续自适应的红队测试；

**💡 创新点**

创新点在于将红队评估视为反馈驱动的优化问题，利用单体智能体进行基因变异、层级语料探索与不对称行为评分，实现对攻击策略的动态迭代与加剧；

**🔧 技术方法**

技术包括句子Transformer编码+递归K‑means层级聚类、基于LLM的有害性、对齐与隐私风险评分、遗传突变算子、A2A接口与自适应决策逻辑；

**📊 数据集**

使用的数据集为约128K条攻击式查询与50K条安全查询的公共基准与安全仓库语料，目标模型为Gemini 2.5 Flash，并在独立评估中检验ChatGPT、Claude和Gemini 2.0 Pro的结果；

**📈 对比分析**

通过与仅探索、仅突变两种基线对比，采用适应度评分衡量攻击强度，完整系统在10轮迭代中平均得分79.76，明显优于仅探索（42.86）与仅突变（54.79），表明进化搜索显著提升了漏洞发现深度与严重度；

**⚠️ 局限性**

局限性包括对LLM评判器的依赖导致评估偏差、仅针对提示与交互层攻击，未覆盖模型权重泄露、训练数据污染或系统级威胁，且受突变算子与初始语料多样性限制，无法完全体现人类期望的可用性与交互质量。

---

## 359. Toward Accurate and Accessible Markerless Neuronavigation

**arXiv ID:** 2602.07052 | [PDF](https://arxiv.org/pdf/2602.07052v1)

**作者:** Ziye Xie `[一作]` (Duke University), J. Matias Di Martino `[通讯]` (Universidad Católica del Uruguay)

**通讯引用:** 1377 | [OpenAlex ID](https://openalex.org/A5049745085)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究提出一种基于消费者级 RGB‑D 传感器（Azure Kinect）的无标记头部定位系统，用于脑刺激（TMS）和神经导航。

**💡 创新点**

创新点包括：① 采用多模态摄像头（单目、立体、深度）和面部统计先验（个性化头部模型 PHM）；② 结合高分辨率（3840×2160）面部特征点，提升定位精度；③ 在 50 位多样化受试者上系统性评估，显著优于传统标记式系统与先前的无标记方法。

**🔧 技术方法**

技术主要包括：MediaPipe 面部 468 关键点检测、PnP 角度求解、立体三角测量、点云配准（ICP）以及三维可变形模型（UHM）拟合生成 PHM。

**📊 数据集**

数据集：收集 50 名受试者（20–76 岁，男女各半）在实验室环境中完成头部运动，采集 Azure Kinect RGB‑D 数据并同步 NDI Polaris 标记轨迹；无公开共享的数据集。

**📈 对比分析**

比较方法：将无标记算法（单目、立体、深度，各加/不加 PHM）与 NDI 标记式系统及重实现的 MarLe 进行对比。结果：最佳无标记方法（立体+PHM 或深度+PHM）在平移误差约 2.5–3.2 mm、旋转误差 2.1–3.3°、失败率 0.015% 时，均优于 NDI（失败率 0.67%）和 MarLe（平移 16.5 mm、旋转 5.2°、失败率 9.7%）。

**⚠️ 局限性**

局限性：① 仅以 NDI 作为相对基准，缺乏绝对“地面真值”；② 未评估实时性和计算成本；③ 采用逐帧独立估计，缺乏时间一致性约束；④ 受限于面部特征检测，极端姿态下仍可能失效。

---

## 360. Evolving LLM-Derived Control Policies for Residential EV Charging and Vehicle-to-Grid Energy Optimization

**arXiv ID:** 2602.07275 | [PDF](https://arxiv.org/pdf/2602.07275v1)

**作者:** Vishesh Purnananda `[一作]` (Adelaide University), Mingyu Guo `[通讯]` (Adelaide University)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `5a41884c-404f-4688-a89c-aa238c10fe68` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

使用大型语言模型结合进化计算，自动生成可解释的Python控制策略，用于住宅电动车充放电与V2G能源优化。

**💡 创新点**

将LLM作为基因变异算子，在基于仿真反馈的迭代搜索框架中合成符号代码，既实现高收益又保证可审计性。

**🔧 技术方法**

LLM（如GPT‑4）推理、Prompt‑Engineering、基于EV2Gym的仿真评估、混合提示策略（Hybrid）、程序搜索与迭代修正。

**📊 数据集**

澳洲新南威尔士州家庭用电、光伏、价格数据（RRP）以及1500步真实电价与负荷轨迹，用于训练与评估。

**📈 对比分析**

将四种提示策略与专家基准对比，Hybrid在1500步情景下利润提升118%（相对基准2.66变为3.15），Runtime提升190%，但成本高。

**⚠️ 局限性**

对极端情形泛化有限，模型对价格预测误差敏感，仍需人工设置安全阈值与约束，整体算力与API费用仍是部署壁垒。

---

## 361. Extended to Reality: Prompt Injection in 3D Environments

**arXiv ID:** 2602.07104 | [PDF](https://arxiv.org/pdf/2602.07104v1)

**作者:** Zhuoheng Li `[一作]` (Pennsylvania State University), Ying Chen `[通讯]` (Pennsylvania State University)

**通讯引用:** 6330 | [OpenAlex ID](https://openalex.org/A5100383008)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6215c339-3735-4be3-8a07-5bbb7004712d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

开发了在三维物理环境中实施Prompt Injection攻击的框架PI3D，利用带有恶意文本的物理物体（如白板、贴纸）引导多模态大型语言模型（MLLM）产生攻击者期望的输出，且保持高物理可行性。

**💡 创新点**

首次将Prompt Injection扩展到3D物理空间；提出基于经验指导的姿态规划器，利用过去的姿态评估结果快速定位高攻击成功率且物理可行的物体姿态；将MLLM用作攻击者与评估者，直接量化物理可行性与攻击成功率。

**🔧 技术方法**

使用经验指导的姿态规划（6-DoF相似性核+阈值决策）、MLLM（Gemini-2.0-Flash、GPT-4o-mini、GPT-5、Gemini-2.5-Flash）作为攻击者与评估者、Unity3D高保真渲染、真实环境摄像采集、文本注入策略（上下文忽略Prompt），以及评估指标（ASR、物理可行性分数、令牌/调用数）。

**📊 数据集**

三套高保真Unity场景（办公、居家、郊区户外）与216张真实环境拍摄图像（涵盖办公室、家居、户外），并对每帧应用五种扰动（模糊、亮度/对比度、饱和度、裁剪、旋转）进行攻击鲁棒性验证。

**📈 对比分析**

与单一放置（Single-Placement）和迭代可行性（Iterative-Plausibility）两种基线进行比较；PI3D在虚拟环境中的攻击成功率（ASR）提升10–20%且物理可行性分数更高；在真实环境中ASR达64.8%；防御手段（指令性防御、已知答案检测）对PI3D的效果有限，攻击成功率仍保持在50–60%范围。

**⚠️ 局限性**

需要物理接触与手写文本，受光照、遮挡和场景复杂度影响；对不同尺寸/架构的MLLM泛化性待验证；大规模或多物体环境下的可扩展性和实时性尚未彻底评估。

---

## 362. Physical Analog Kolmogorov-Arnold Networks based on Reconfigurable Nonlinear-Processing Units

**arXiv ID:** 2602.07518 | [PDF](https://arxiv.org/pdf/2602.07518v1)

**作者:** Manuel Escudero `[一作]` (University of Twente), Wilfred G. van der Wiel `[通讯]` (University of Twente)

**通讯引用:** 10741 | [OpenAlex ID](https://openalex.org/A5031220825)

**关键词:** `7a50eb32-3dbc-4c3e-a038-bda01b2d9965` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文提出并实现了一种基于可重构非线性处理单元（RNPUs）的物理模拟Kolmogorov‑Arnold网络（aKAN），实现了可编程非线性边缘函数在硬件上的直接实现。

**💡 创新点**

创新点在于将可学习的单变量非线性函数移入物理器件层面，用RNPUs作为硬件原语，显著降低了能耗和面积，并为边缘推理提供了一条新的低功耗、高并行度硬件路径。

**🔧 技术方法**

所用技术包括多端子硅纳米器件（RNPUs）、混合信号接口（DAC/ADC/TIA）、模拟KAN架构、基于仿真模型的反向传播训练以及实验验证。

**📊 数据集**

实验使用了多种回归与分类数据集，包括连续函数拟合（如J0(20x)、e^(sin(πx1)+x2^2)）以及经典二分类任务（Moons、Spirals、MAGIC、COD‑RNA、Skin Segmentation）。

**📈 对比分析**

通过与软件MLP（ReLU、tanh）以及数字固定点tanh‑MLP在参数、误差、能耗、面积、延迟方面的系统级对比，aKAN在相同误差下能耗下降至约250 pJ/推理、面积约为MLP的1/10、推理延迟≈600 ns，性能优异。

**⚠️ 局限性**

主要局限在于混合信号外围电路（DAC/ADC/TIA）占据大部分功耗，RNPUs目前仅支持时间复用，缺乏大规模并行与精细控制，硬件实现仍需进一步集成与优化。

---

## 363. CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs

**arXiv ID:** 2602.07080 | [PDF](https://arxiv.org/pdf/2602.07080v1)

**作者:** Yicheng He `[一作]` (University of Illinois Urbana-Champaign), Yonghui Yang `[通讯]` (National University of Singapore)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过提取LLM内部的行级归因图（Attribution Graph），对生成代码的每一步进行结构化诊断，判定其是否逻辑正确，并在发现错误时通过对图中节点的干预实现自动修复。

**💡 创新点**

①首次将机制性可解释性（Mechanistic Interpretability）应用于代码生成，证明代码正确性能在模型内部的计算拓扑中被编码；②提出可解释的稀疏自编码器（Transcoder）和归因图构造方法；③展示对归因图节点进行目标干预即可实现逻辑纠错，验证其因果效应。

**🔧 技术方法**

稀疏自编码器（Transcoder）实现归因图抽取；图结构特征提取（如错误比率、密度、聚类系数、介数中心性等）；梯度提升决策树（GBDT）进行二分类；对归因图节点的激活做钩子干预。

**📊 数据集**

MBPP 代码生成基准，按语言分别在 Python、Java、C++ 进行实验；Java 与 C++ 的数据由 MBPP 语义等价翻译并使用 Gemma‑2‑2B‑it 生成；标注由 GPT‑4o 给出。

**📈 对比分析**

与黑盒方法（最大软化概率、熵、困惑度、温度缩放、能量）和灰盒方法（CoE‑R、CoE‑C、CoT‑Kinetics）对比；在三种语言上，AUROC 均提升约 25‑30 分，AUPR 翻倍，FPR@95 降至 70‑80% 之间，表现显著优于基线。

**⚠️ 局限性**

①需要对模型内部结构进行大规模计算，归因图构建和特征提取成本高；②仅在可访问内部参数的模型上可行，难以推广到所有商用 LLM；③实验仅覆盖三种语言，跨语言通用性和在更大规模程序上的可扩展性尚未验证。

---

## 364. MaD-Mix: Multi-Modal Data Mixtures via Latent Space Coupling for Vision-Language Model Training

**arXiv ID:** 2602.07790 | [PDF](https://arxiv.org/pdf/2602.07790v1)

**作者:** Wanyun Xie `[一作]` (École Polytechnique Fédérale de Lausanne), Volkan Cevher `[通讯]` (École Polytechnique Fédérale de Lausanne)

**通讯引用:** 7906 | [OpenAlex ID](https://openalex.org/A5027059837)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种基于 Fenchel 双对偶的多模态对齐得分框架，自动计算 Vision‑Language 模型训练时各数据域的采样权重，能够兼顾不同模态缺失情况并在无额外训练成本下完成权重分配。

**💡 创新点**

创新点包括：
- 通过双对偶求解得到闭式多模态对齐得分；
- 采用共享潜在空间和多模态核矩阵实现模态耦合；
- 通过谱软阈值化去噪声、强调信号分量；
- 对缺失模态使用指示符 δ 直接屏蔽其对得分的影响；
- 计算量极低（<1 GPU‑hour），且权重可在不同模型规模与架构间迁移。

**🔧 技术方法**

使用技术：Fenchel‑Young 不等式、双对偶优化、潜在变量耦合、谱分解与软阈值化、预训练 VLM 的特征提取、核矩阵求逆。
实现不需要额外训练，仅通过一次推理获取各域嵌入即可完成。

**📊 数据集**

采用 LLaVA‑OneVision 所提供的 5‑域（General、Doc/Chart/Screen、Math/Reasoning、OCR、Language）及新增 VideoQA 进行训练；评估使用的基准包括 AI2D、ChartQA、DocVQA、InfoVQA、OCRBench、MathVerse、MMBench、MMStar、MMMU、ScienceQA、RealworldQA、Video‑MMMU、MVBench。实验还将权重迁移至 Qwen‑VL‑2B 进行跨架构验证。

**📈 对比分析**

与 Uniform、Human（手工调优）、单模态得分（Text/Image/Video）、Avg、Fused 等基线对比，结果显示：
- 在 0.5B/7B 模型上，平均 1.24% 提升于 Uniform，且在 78% 训练步数即可达到 Human 性能（≈1.28×速度提升）；
- 在三模态设置下，仅需 33% 步骤即可匹配 Uniform，平均 3× 加速；
- 在 Qwen‑VL‑2B 上也保持优势；
- 训练时间与权重计算时间相比可忽略不计（<1 GPU‑hour）。

**⚠️ 局限性**

局限性：
- 依赖预训练 VLM 的嵌入，若模型更新需重新提取；
- 对域数量极大时核矩阵求逆可能成为瓶颈；
- 缺失模态处理仅通过指示符屏蔽，可能忽略缺失模态潜在信息；
- 仅在实验的 5–6 个域及 3 种模态上验证，未对更大规模或其他模态组合做系统评估；
- 该方法假设域间分布不随训练过程显著变化，未来需探索动态权重更新。

---

## 365. Still Manual? Automated Linter Configuration via DSL-Based LLM Compilation of Coding Standards

**arXiv ID:** 2602.07783 | [PDF](https://arxiv.org/pdf/2602.07783v1)

**作者:** Zejun Zhang `[一作]`, Liming Zhu `[通讯]`

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275`

**🎯 论文内容**

本文通过设计一种面向规则的领域专用语言（DSL）和基于大型语言模型的编译管线，自动化生成针对任意编程语言、任何编码规范与任何 linter 的配置文件。

**💡 创新点**

创新点在于将编码规范与 linter 配置抽象为统一的 DSL 结构，再利用 LLM 进行逐步编译（解析、匹配、校验、生成），从而突破工具、语言与规范的耦合，实现跨域、可维护的配置生成。

**🔧 技术方法**

技术手段包括 DSL 设计与卡片排序、GPT‑4o Prompting、检索增强生成（RAG）与对齐校验、五步编译流程、以及针对 Checkstyle（XML）与 ESLint（JSON）等格式的 LLM 代码生成。

**📊 数据集**

数据集来源为手工构建的基准：Google Java Style Guide 与 Checkstyle 共 68 条编码规范（约 1,066 条标准项目中 20% 活跃），以及 Google JavaScript Style Guide 与 ESLint 共 149 条规范；构建耗时约 182–302 小时。

**📈 对比分析**

通过与六种基线（闭书、Name、Name+Desc、Name+Desc+Opts、RAG(Name+Desc)、RAG(Name+Desc+Opts)）对比，本文方法在配置名称、选项名称和选项值三个粒度上，准确率 70–73%、精确率 81–84%、召回率 70–82%、F1 分数 69–82%，精确率提升超过 100%，并在多语言、多工具场景均优于基线。

**⚠️ 局限性**

局限性包括：对极其复杂或语义模糊的规则仍可能推理错误；DSL 语法需手工维护，覆盖不足时需人工补全；LLM 的 token 限制可能导致生成不完整；并且尚未对更大规模或更稀有语言/工具进行充分验证。

---

## 366. Disentangled Instrumental Variables for Causal Inference with Networked Observational Data

**arXiv ID:** 2602.07765 | [PDF](https://arxiv.org/pdf/2602.07765v1)

**作者:** Zhirong Huang `[一作]` (Guangxi Normal University), Shichao Zhang `[通讯]` (Guangxi Normal University)

**通讯引用:** 13738 | [OpenAlex ID](https://openalex.org/A5100764178)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3f18e8e3-0266-457c-8567-9039b6d2394d` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出 DisIV，利用网络同质性与结构分解，学习个体特异性作为潜在工具变量进行因果推断。

**💡 创新点**

创新点在于将异构推断-生成结构与正交约束相结合，显式解耦环境共性与个体特异性，从而得到满足相关性、排他性和无关联性的潜在 IV。

**🔧 技术方法**

采用图卷积网络提取环境表示、变分自编码器结构、正交正则化、两阶段 IV 估计等技术。

**📊 数据集**

在 BlogCatalog 与 Flickr 两个半合成社交网络数据集上进行评估。

**📈 对比分析**

与基线 CFR、TARNet、NetDeconf、DeepIV、NetIV 对比，DisIV 在 PEHE 与 ATE 指标上均取得最小误差，尤其在高混淆场景下表现最优。

**⚠️ 局限性**

主要局限是对网络结构的同质性假设以及模型复杂度较高，难以直接推广至大规模稠密或非同质网络场景。

---

## 367. Contextualization or Rationalization? The Effect of Causal Priors on Data Visualization Interpretation

**arXiv ID:** 2602.07748 | [PDF](https://arxiv.org/pdf/2602.07748v1)

**作者:** Arran Zeyu Wang `[一作]` (University of North Carolina), David Gotz `[通讯]` (University of North Carolina)

**通讯引用:** 3910 | [OpenAlex ID](https://openalex.org/A5077712580)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本研究通过混合设计（在线大样本+现场思维-说实验）探讨先验因果信念（causal priors）如何影响用户对含有模糊趋势/聚类模式散点图的高层次解释；

**💡 创新点**

首次提出“情境化（contextualization）”与“合理化（rationalization）”两类典型解释行为，并揭示因果先验强度与可视化模式强度之间的交互对用户观察、注释及信任度的影响；

**🔧 技术方法**

采用主题分析与开放式编码（两名研究者独立编码、κ=0.91）收集文本、思维口述与手绘注释；通过可视化刺激的对比实验评估因果先验对观察语言与模式关注点的影响；

**📊 数据集**

使用由先前大型调查获得的群体因果先验评分（强/弱）对应的六对变量名，并基于这些变量生成36幅散点图（9个原始图×不同变量组合，含单/双/三类别色彩）；

**📈 对比分析**

通过实验设计比较强弱因果先验与可视化模式的交互，发现强因果先验导致更高比例的因果语言与趋势主观；弱因果先验导致更低一致性、更多不确定与多样模式观察；未给出传统“性能指标”，而是定性统计与比例分析；

**⚠️ 局限性**

局限包括样本量有限（60+10人），仅研究散点图，未使用个体化因果先验，缺乏理论化的模式强度与因果先验度量，未验证更大规模或不同图表类型的普适性。

---

## 368. Gillian Debugging: Swinging Through the (Compositional Symbolic Execution) Trees, Extended Version

**arXiv ID:** 2602.07742 | [PDF](https://arxiv.org/pdf/2602.07742v1)

**作者:** Nat Karmios `[一作]` (Imperial College London), Philippa Gardner `[通讯]` (Imperial College London)

**通讯引用:** 2592 | [OpenAlex ID](https://openalex.org/A5047951273)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

开发了面向 Gillian 多语言 CSE 工具的可视化交互调试器，集成至 VSCode，支持执行树可视化、单步、状态查看等功能。

**💡 创新点**

创新点包括：①树‑树（tree‑of‑trees）结构记录 IR 级执行并通过 lifting 映射到源级树；②在 DAP 上扩展自定义分支树协议（SEDAP）实现跨工具的可视化；③结构化日志存入 SQLite，减轻引擎负担；④交互式继续执行，可在分析过程中动态选择分支。

**🔧 技术方法**

使用了 Gillian 平台与 GIL IR、分离逻辑（SL/ISL）、VSCode Debug Adapter Protocol、SQLite 结构化日志、持续调试（continuation‑passing）方式、Web‑view 自定义树视图以及源级 lifter 等技术。

**📊 数据集**

评估数据集主要包括 WISL 示例程序、Gillian‑C 与 Gillian‑JS 例子，以及 13+6 练习程序；在实验中亦引用了 AWS SDK、Google pKVM、Meta 代码库、Rust 标准库等真实代码片段。

**📈 对比分析**

通过三种日志方式（无日志、文件日志、数据库日志）基准测试比较验证耗时，数据库日志相较无日志慢约2‑3倍，但优于文件日志；用户实验采用定量时间占比和定性 Likert 量表，显示 40‑60% 时间在调试；总体提升了可读性和学习效果。

**⚠️ 局限性**

局限性：仅在 VSCode 实现，缺乏跨编辑器支持；验证范围局限于 Gillian，尚未在其他 CSE 工具上测试；日志结构复杂性需进一步优化；错误信息与状态展示仍不够直观；用户实验样本规模小且受受试者经验限制，未评估大规模真实项目的可伸缩性。

---

## 369. TerraBind: Fast and Accurate Binding Affinity Prediction through Coarse Structural Representations

**arXiv ID:** 2602.07735 | [PDF](https://arxiv.org/pdf/2602.07735v1)

**作者:** Matteo Rossi `[一作]` (Terray Therapeutics), John Anthony Parkhill `[通讯]` (Terray Therapeutics)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `09944146-298c-433e-89df-37255de463d7` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

构建了一种名为 TerraBind 的多模态基础模型，用于快速预测蛋白‑配体结构与结合亲和力，并实现了 26 倍推理速度提升和 20% 以上亲和力预测精度提升。

**💡 创新点**

创新点包括：1）仅使用蛋白 Cβ 与配体重原子粗粒度表示，消除耗时的全原子扩散；2）引入 48 层 pairformer 核心架构与预训练 COATI‑3 / ESM‑2 编码器；3）通过距离分布熵实现内置结构置信度；4）使用 epinet 提供可校准的亲和力不确定性；5）通过持续学习与 EMAX 采样实现更高效的 DMTA 循环。

**🔧 技术方法**

技术主要包括：预训练多模态编码器 COATI‑3（SMILES、图、3D 点云）与 ESM‑2；pairformer 网络（三角注意力/乘法）进行距离分布预测；无扩散的优化求解器生成 3D 坐标；基于距离概率的亲和力判别与回归；epinet 架构实现联合分布与不确定性量化；持续学习框架与 EMAX 采样策略。

**📊 数据集**

使用的主要数据集包括：公开的 PDB（截止 2021-09）、AlphaFold 数据库、BindingDB 的 Boltz‑1 预测结构、CASP16 公开挑战数据、18 组内部实验 Assay（≥95 IC50 数据点）以及用于细化的 6/3 结构晶体等。

**📈 对比分析**

与 Boltz‑2、Boltz‑1 以及传统分子对接方法对比：在 FoldBench、PoseBusters、Runs N' Poses 等结构基准上，TerraBind 取得相同或更高的 ligand RMSD < 2 Å 率；在 CASP16 与 18 组内部 Assay 上，Pearson 相关系数提升约 20 %（在 15/18 目标中领先 Boltz‑2），并且推理时间仅为 Boltz‑2 的 1/26。

**⚠️ 局限性**

局限性：1）仅生成粗粒度结构，缺乏全原子精细度，限制了后续精细化计算；2）对未知蛋白与化学空间的泛化仍有限，部分高亲和力配体在模型中熵值偏高；3）epinet 的高斯假设可能导致对低亲和力样本的不准确置信度估计；4）模型仅关注蛋白‑配体对，难以处理细胞实验或多靶点上下文。

---

## 370. Leveraging the Power of Ensemble Learning for Secure Low Altitude Economy

**arXiv ID:** 2602.07725 | [PDF](https://arxiv.org/pdf/2602.07725v1)

**作者:** Yaoqi Yang `[一作]` (National Key Laboratory on Near-Surface Detection), Zhu Han `[通讯]` (University of Houston)

**通讯引用:** 87570 | [OpenAlex ID](https://openalex.org/A5063667378)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `e0540dec-d77f-42db-94ae-d039248f6393` `aaccfe5c-6b26-4208-b23c-35331481e142` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出基于集成学习的低空经济恶意航空器跟踪框架，结合YOLOX和Fast R‑CNN实现检测、识别与定位。

**💡 创新点**

创新点在于采用加权融合的集成模型，兼顾快速检测和高精度定位，并通过非极大抑制实现结果优化。

**🔧 技术方法**

使用技术包括图像预处理、YOLOX与Fast R‑CNN基学习器、加权平均融合、非极大抑制与坐标变换。

**📊 数据集**

数据集为从地面观测站获取的遥感航空图像，经过降噪、增强和数据扩增后构成训练与评估集。

**📈 对比分析**

与单独模型相比，集成模型的平均精度提升至0.85（高于Fast R‑CNN 0.81和YOLOX 0.83），平均IoU保持在0.815，表现出更优的精度与召回平衡。

**⚠️ 局限性**

局限性包括模型计算复杂度高、数据不平衡导致训练挑战、可解释性不足以及实时性能仍需进一步提升。

---

## 371. A hybrid Kolmogorov-Arnold network for medical image segmentation

**arXiv ID:** 2602.07702 | [PDF](https://arxiv.org/pdf/2602.07702v1)

**作者:** Deep Bhattacharyya `[一作]` (Concordia University), A. Ben Hamza `[通讯]` (Concordia University)

**通讯引用:** 3880 | [OpenAlex ID](https://openalex.org/A5065968153)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了一种结合 U‑形编码解码器和 Kolmogorov‑Arnold 网络的 U‑KABS 框架用于医学图像分割。

**💡 创新点**

创新点在于将 Bernstein 多项式与 B‑spline 作为可学习激活函数，形成 KABS 块，兼顾全局光滑与局部细节。

**🔧 技术方法**

技术采用 U‑形卷积+SE 模块、KAN Bernstein/ B‑spline 激活、深度卷积、残差与层归一化。

**📊 数据集**

使用了四个公开基准数据集：BUSI、GlaS、ISIC 2018 和 ACDC。

**📈 对比分析**

与多种基线（U‑Net、U‑Net++、Attention‑UNet、MedT、UNeXt、Rolling‑UNet、U‑KAN、ResU‑KAN 等）对比，U‑KABS 在 IoU/Dice 上均优于或接近最强模型，尤其在 BUSI、GlaS、ISIC 和 ACDC 上取得最高或第二高分。

**⚠️ 局限性**

局限在于模型参数相对较大，导致在边缘设备上部署受限；此外对未见模态的泛化还需进一步验证。

---

## 372. On Sequence-to-Sequence Models for Automated Log Parsing

**arXiv ID:** 2602.07698 | [PDF](https://arxiv.org/pdf/2602.07698v1)

**作者:** Adam Sorrenti `[一作]` (Toronto Metropolitan University), Andriy Miranskyy `[通讯]` (Toronto Metropolitan University)

**通讯引用:** 764 | [OpenAlex ID](https://openalex.org/A5026957450)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `edb9d762-f411-4838-a852-f2d638b018db` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本研究对多种序列模型（Transformer、Mamba状态空间模型、单向和双向LSTM）在自动日志解析任务中的性能进行了系统评估，探讨了序列长度、分词方式、训练数据比例等因素对解析准确性和计算成本的影响。

**💡 创新点**

创新点包括①首次将Mamba状态空间模型应用于日志解析并与Transformer、LSTM进行对比；②在单一实验框架下同时评估四个关键因素（序列长度、分词方式、训练数据规模、模型架构）；③使用真实日志数据集（LogHub‑2k）和自制的多难度训练/验证集（HTTPd‑parse）进行大规模（396个模型）实验。

**🔧 技术方法**

使用的技术：Transformer、Mamba SSM、单向/双向LSTM的seq2seq模型；字符级/词级分词；Levenshtein编辑距离作为评估指标；Wilcoxon符号秩检验与效应量（r）进行统计显著性与实质性差异分析；GPU（NVIDIA A100）深度学习训练。

**📊 数据集**

所用数据集：LogHub‑2k（包含多种真实软件系统日志），以及自制的HTTPd‑parse训练集（T_T、T_E、T_M、T_H）和验证集（V_A、V_B、V_C）。

**📈 对比分析**

比较方法：在同一实验条件下训练396个模型，使用相对编辑距离（D_R）衡量解析准确性，并记录训练/推理时间及参数量。结果显示：Transformer在最优设置下D_R最低（0.111），Mamba次之（0.145），单向LSTM（0.186），双向LSTM（0.265）。Mamba在计算成本上显著低于Transformer，且在有限训练数据时样本效率更好；Transformer在日志格式高度多样化时表现更稳健。

**⚠️ 局限性**

局限性：评估仅基于字符级编辑距离，未覆盖语义正确性或字段级别精度；实验聚焦于Apache‑style日志，结果对其他日志格式（如JSON、事件日志）的推广需验证；未考虑实时日志流中的时间依赖性；计算环境限定在A100 GPU，跨平台性能需进一步评估。

---

## 373. On the Infinite Width and Depth Limits of Predictive Coding Networks

**arXiv ID:** 2602.07697 | [PDF](https://arxiv.org/pdf/2602.07697v1)

**作者:** Francesco Innocenti `[一作]` (University of Oxford), Rafal Bogacz `[通讯]` (University of Oxford)

**通讯引用:** 12200 | [OpenAlex ID](https://openalex.org/A5049095056)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文研究了预测编码网络（Predictive Coding Networks, PCNs）在无限宽度与无限深度极限下的行为，并证明在满足宽度与深度稳定且特征学习的参数化（width‑stable & depth‑stable feature‑learning parameterisation）时，PCNs 的梯度收敛到传统反向传播（BP）的梯度；进一步给出了 PC 与 BP 在宽度≫深度时几乎相同的训练性能；并在非线性网络与实际优化过程中验证了这一结论。

**💡 创新点**

创新点包括：① 证明了线性 PCNs 在满足特定参数化时与 BP 共享相同的宽度/深度稳定性与特征学习条件；② 推导出 PC 的能量重标度随宽度趋于无穷大时收敛为 MSE 损失，从而得到梯度一致性；③ 将这一理论扩展到残差网络，给出深度缩放指数 α=1/2 的唯一可行参数化；④ 通过实验验证在实际非线性网络中，只要活动达到平衡，PC 仍能与 BP 对齐，展示了 PC 的可扩展性与稳定性。

**🔧 技术方法**

技术方法：线性网络理论推导、能量函数等价性分析、梯度流（gradient flow）与离散梯度下降（gradient descent）比较、动态均值场理论（dynamical mean‑field theory）预测损失曲线、对比余弦相似度、Adam 优化器的扩展、残差网络的深度缩放分析。

**📊 数据集**

使用的数据集包括：1) 生成的二分类 toy 任务；2) Fashion‑MNIST；3) CIFAR‑10（图像分类）。此外在实验中还使用了多层感知机（MLP）和残差网络（ResNet）两种结构。

**📈 对比分析**

比较方法主要是：① 计算 PC 与 BP 梯度的余弦相似度；② 绘制 PC 能量重标度 s(θ) 与 1 的差值随宽度/深度的变化；③ 在相同参数化下对比 PC 与 BP 在损失收敛速度与最终精度。结果表明：在宽度≫深度、且满足宽/深稳定参数化时，PC 的梯度与 BP 极为接近，训练曲线几乎一致；非线性网络中，随着活动优化步长增大，PC 的梯度与 BP 的相似度随时间提升，最终可与 BP 对齐。

**⚠️ 局限性**

局限性：① 理论分析仅针对线性网络，无法直接推广到非线性 PCNs；② 仅考察了能量平衡状态，实际 PC 训练中活动平衡难以保证；③ 对于更深或更宽的网络，残差结构的数值稳定性仍是挑战；④ 需要进一步研究是否存在不收敛到 BP 的稳定特征学习参数化。

---

## 374. Low-distortion planar embedding of rod-based structures

**arXiv ID:** 2602.07789 | [PDF](https://arxiv.org/pdf/2602.07789v1)

**作者:** Mark Yan Lok Yip `[一作]` (Chinese University of Hong Kong), Gary P. T. Choi `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 1214 | [OpenAlex ID](https://openalex.org/A5059616736)

**关键词:** `a42c7bd6-d8fd-40d3-94df-ae8cd808f5c4` `5b4c1114-4a70-478e-9921-2514ee03850d` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文提出一种针对三维杆式结构的低失真二维嵌入方法，目标是将复杂的3D杆网在二维平面上重建时既保持杆段长度与关键关节角度，又避免杆段重叠，从而方便后续制造与仿真；

**💡 创新点**

创新点在于：①提出统一的约束优化框架，显式约束杆段长度、关节角度以及通过三角网面积差实现的无重叠条件；②设计了高效的梯度求导与交替约束/重叠纠正策略，解决了无重叠约束可能过度限制的问题；③将方法推广至包含表面区域的混合结构，兼顾杆段与表面几何保持；

**🔧 技术方法**

技术包括：图拉图嵌入初始化、基于梯度的非线性约束优化（使用MATLAB interior‑point 求解）、三角网面积与边界面积公式、重叠检测与修正算法（利用圆约束、最短路径等手段）；

**📊 数据集**

实验使用多种人工构造的杆式结构（包括双曲曲面、俯仰不均的曲面、布料模型、面部模型等）以及对应的混合结构示例；

**📈 对比分析**

通过对比长度误差、角度误差与重叠数量，实验显示平均长度误差在10⁻⁴级别，角度误差在10⁻³–10⁻¹范围内，重叠数始终为0，表明方法在保持几何特征的同时实现了无重叠；在混合结构实验中，尽管引入表面约束使问题更为约束严苛，但误差仍保持在可接受范围；

**⚠️ 局限性**

主要局限包括：①对于包含大量小杆段的表面模型，角度误差相对增大；②无重叠约束基于全局三角网面积的做法可能过于严格，导致某些情况需采用交替优化；③当前仅处理长度与角度的等式约束，无法适应需要允许局部弹性变形或不等长杆的情形；

---

## 375. Attn-GS: Attention-Guided Context Compression for Efficient Personalized LLMs

**arXiv ID:** 2602.07778 | [PDF](https://arxiv.org/pdf/2602.07778v1)

**作者:** Shenglai Zeng `[一作]` (Michigan State University), Hui Liu `[通讯]` (Amazon)

**通讯引用:** 1152 | [OpenAlex ID](https://openalex.org/A5103058045)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过分析大语言模型（LLM）的注意力模式，提出 Attn-GS 框架，用细调后的注意力标记重要句子，再引导压缩模型生成高质量、任务相关的压缩用户上下文，显著降低 token 使用量。

**💡 创新点**

创新点在于：①首次利用 LLM 关注权重识别个性化信号的重要性；②通过细调提升注意力辨别力；③结合标记与压缩两阶段流程，实现高效、精细的上下文压缩；④在多任务设置下保持近全量上下文的性能。

**🔧 技术方法**

核心技术包括：LLM 的多头注意力分析、细调的标记模型 Φ_Mark、阈值筛选机制、标记提示后引导的压缩模型 Φ_Sum、实验对比与 ablation 分析。

**📊 数据集**

实验使用 MovieLens‑1M（电影推荐）和 LaMP‑5（个性化论文标题生成）两大数据集。

**📈 对比分析**

与截断、直接压缩、思考提示、随机/全标记、Prompt‑GS 等基线对比，Attn‑GS 在 50–200 token 级别下，精度接近完整上下文，token 使用量下降约 50×，且在不同模型、token 长度下均保持领先。

**⚠️ 局限性**

limitations: 对 LLM 内部处理个性化输入机制的深入理解不足；框架目前仅在两类单任务数据集验证，需进一步探究在多任务、多领域场景下的泛化能力。

---

## 376. CoLF: Learning Consistent Leader-Follower Policies for Vision-Language-Guided Multi-Robot Cooperative Transport

**arXiv ID:** 2602.07776 | [PDF](https://arxiv.org/pdf/2602.07776v1)

**作者:** Joachim Yann Despature `[一作]` (École polytechnique fédérale de Lausanne), Takamitsu Matsubara `[通讯]` (Nara Institute of Science and Technology)

**通讯引用:** 2784 | [OpenAlex ID](https://openalex.org/A5042074952)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种基于视觉‑语言指导的多机器人协同运输框架CoLF，采用领导者‑跟随者结构实现去中心化控制；

**💡 创新点**

核心创新包括：① 通过将领导者赋予目标与目标点信息、跟随者仅获得局部信息实现信息不对称；② 设计互信息驱动的CE损失，促使跟随者预测领导者动作，从而稳定地形成领导者‑跟随者角色；③ 采用VLM‑free训练与VLM‑based执行的混合策略，降低训练成本；

**🔧 技术方法**

使用了多智能体近端策略优化（MAPPO）+ CTDE框架、变分下界的互信息目标、异步actor‑critic、CLIPSeg视觉‑语言模型进行目标与目标点定位、Isaac Sim仿真、实际Unitree Go1四足机器人执行；

**📊 数据集**

主要使用自定义的仿真环境（目标箱子、圆柱目标点）和真实机器人与RealSense摄像头采集的RGB‑D图像；未使用公开公开数据集，实验数据均为作者自制；

**📈 对比分析**

与MAPPO、MAPPO(AAC)、CoLF去除AAC或CE的消融版进行对比。CoLF在单目标与多目标（含模糊指令）仿真实验中成功率分别提升约10%–30%，对象‑目标距离均降低；在五种真实场景下，CoLF 5/5成功率明显优于MAPPO(AAC)（2–4/5）；

**⚠️ 局限性**

局限性包括：① 需假设领导者能准确识别目标与目标点，跟随者只能得到局部信息；② 需要外部提供机器人相对位姿与航向以避免碰撞；③ 仅在两机器人设置下验证，未评估团队规模扩展；④ 对物体属性变化的鲁棒性有限；

---

## 377. SRR-Judge: Step-Level Rating and Refinement for Enhancing Search-Integrated Reasoning in Search Agents

**arXiv ID:** 2602.07773 | [PDF](https://arxiv.org/pdf/2602.07773v1)

**作者:** Chen Zhang `[一作]` (Huawei Technologies), Yong Liu `[通讯]` (Huawei Technologies)

**通讯引用:** 20446 | [OpenAlex ID](https://openalex.org/A5100724297)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了SRR‑Judge，一种用于长序列搜索集成推理的细粒度步骤级评估器，并将其嵌入到改进的ReAct工作流中；通过该评估器实现了“rate‑and‑refine”推理流程以及基于拒绝采样的迭代微调，显著提升深度搜索代理的性能。

**💡 创新点**

核心创新在于：①将大规模代理模型的推理与搜索行为的质量直接分解为每一步的可评估任务；②利用教师模型进行步骤级的自动标注并通过点双序相关性进行质量提升；③在推理阶段使用最佳‑N 采样与即时修正相结合的rate‑and‑refine流程；④以步骤级监督驱动的迭代拒绝采样微调，突破了传统仅靠终端结果的稀疏奖励瓶颈。

**🔧 技术方法**

技术手段包括：大语言模型（Qwen3‑8B、Qwen3‑235B‑A22B、QwQ‑32B、DeepSeek‑V3.1）在ReAct框架下生成搜索轨迹；SRR‑Judge基于QwQ‑32B的fine‑tune实现步骤级评分与改写；最佳‑N 采样与阈值修正的rate‑and‑refine推理流程；迭代拒绝采样微调（RFT）结合步骤级标签进行后训练对齐。

**📊 数据集**

使用的主要数据集有：WebDancer、WebShaper、WebExploxer、DeepDive、InfoSeek‑Hard、DuetQA‑Verified、ASearcher‑LRM（训练集），以及BrowseComp、BrowseComp‑ZH、Xbench‑DeepSearch、InfoDeepSeek‑ZH（评测集）。训练集由多模型生成的搜索轨迹构成，后续通过SRR‑Judge自动标注与点双序相关性过滤得到高质量步骤级标签。

**📈 对比分析**

与DeepSeek‑V3.1教师模型以及其他公开深度搜索系统（如WebSailor‑32B、DeepDive‑32B）对比，SRR‑Judge在相同基座QwQ‑32B上实现了约10%绝对提升的Pass@1（例如BrowseComp从5.4%提升至9.1%），并在推理时无需额外训练即可匹敌甚至超过教师的改进效果；在迭代RFT中，每一轮均可持续提升性能，最终达到BrowseComp 16.2%、BrowseComp‑ZH 38.3%、Xbench‑DeepSearch 61.3%。

**⚠️ 局限性**

局限性在于SRR‑Judge难以有效监督远强于其自身的代理模型（如DeepSeek‑V3.1），对极强模型的改进反而导致性能下降，表明当前的步骤级奖励模型在弱→强迁移时仍面临挑战。

---

## 378. LEO Topology Design Under Real-World Deployment Constraints

**arXiv ID:** 2602.07756 | [PDF](https://arxiv.org/pdf/2602.07756v1)

**作者:** Muaz Ali `[一作]` (University of Arizona), Beichuan Zhang `[通讯]` (University of Arizona)

**通讯引用:** 9144 | [OpenAlex ID](https://openalex.org/A5050010654)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文针对实际部署的低地轨道星座，提出了两种可在部分、非对称和动态部署条件下构建 ISL 拓扑的方法，能够在保持低延迟、低跳数和高吞吐量的同时，仅使用稳定链路并实现增量更新。

**💡 创新点**

创新点在于：①将长短链路（Long–Short Links, LSL）与模拟退火（Simulated Annealing, SA）两种方法结合，提供结构化与可调节的拓扑方案；②专门定义并利用“稳定链路”概念，显著降低链路崩溃和网络重构成本；③引入增量更新算法，使拓扑随每日节点更替保持连通并最小化链路切换。

**🔧 技术方法**

技术手段包括：基于轨道参数的稳定链路计算、LSL 的环路+交叉平面混合链接构造、SA 的代理目标（平均链路长度、长链路比例、边利用率）与温度退火优化、以及基于所有可用链路的增量更新流程。

**📊 数据集**

数据集主要包括：Starlink Shell‑1 的真实 TLE 轨道数据（2019‑2024 3 个月）以及合成的全量 Shell‑1 和 Amazon Kuiper Shell（分别为 72×22 与 34×34）用于对照实验。

**📈 对比分析**

通过与 +Grid、3‑ISL‑Grid、Motif 等传统基准以及理论最优无度限制网络比较，实验表明：在 4‑ISL 条件下，LSL 与 SA 可将平均跳数从 21‑23 降至 8.5‑9，延迟从 60‑70 ms 降至 47‑49 ms，吞吐量提升约 1.7‑2.3 倍；在 3‑ISL 条件下仍保持 60‑70 ms 延迟、10‑12 跳数的优势，并保持 1‑1.3 % 的链路崩溃率。

**⚠️ 局限性**

局限性包括：仅使用稳定链路忽略了瞬时可用但高不稳定性的短暂链路，导致在极短期内可能无法达到最优路径；对高度动态或极不均匀部署场景的增量更新仍需手动调节参数；算法在规模极大（>10k 卫星）下的实时重构仍受限于计算资源。

---

## 379. Learning to Continually Learn via Meta-learning Agentic Memory Designs

**arXiv ID:** 2602.07755 | [PDF](https://arxiv.org/pdf/2602.07755v1)

**作者:** Yiming Xiong `[一作]` (University of British Columbia), Jeff Clune `[通讯]` (University of British Columbia)

**通讯引用:** 18621 | [OpenAlex ID](https://openalex.org/A5112191507)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了自动化元学习框架 Alma，通过 Meta Agent 在代码空间中进行开放式探索，自动生成并学习适应多域的记忆设计，以实现 agentic 系统的持续学习。

**💡 创新点**

将记忆设计视为可编程代码搜索空间，并使用 Meta Agent 进行自我反思、编码、调试与评估，突破传统手工记忆设计的限制，实现了跨域、可迁移、成本高效的记忆结构。

**🔧 技术方法**

基于 OpenAI GPT 系列（GPT-5-nano/mini）作为 Meta Agent 生成代码，使用代码抽象类实现可插拔子模块，采用开放式探索与采样机制；评估时使用静态与动态部署阶段、成功率等指标。

**📊 数据集**

四个顺序决策基准：ALFWorld、TextWorld、Baba Is AI 与 MiniHack，分别覆盖家居模拟、文字冒险、策略谜题与类 NetHack 任务。

**📈 对比分析**

对比四种主流手工记忆基线（Trajectory Retrieval、Reasoning Bank、Dynamic Cheatsheet、G‑Memory），在静态模式下评估成功率，结果表明自动学习的记忆设计平均提升约6–12 %（针对 GPT‑5-nano/mini），在更强 FM 上提升更大，并在样本效率、规模与分布迁移上均优于基线。

**⚠️ 局限性**

学习过程分离了训练与测试阶段，无法在线自适应；受限于预训练 FM 的能力，代码搜索空间受限；未实现对记忆设计的多目标优化，如成本与性能权衡；安全性与可解释性仍需进一步审查。

---

## 380. HypRAG: Hyperbolic Dense Retrieval for Retrieval Augmented Generation

**arXiv ID:** 2602.07739 | [PDF](https://arxiv.org/pdf/2602.07739v1)

**作者:** Hiren Madhu `[一作]` (Yale University), Rex Ying `[通讯]` (Yale University)

**通讯引用:** 15030 | [OpenAlex ID](https://openalex.org/A5078337825)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出在检索增强生成（RAG）中使用双曲几何进行稠密检索，并设计了全双曲 Transformer (HyTE-FH)、混合双曲模型 (HyTE-H) 与保留层级结构的几何聚合算子 Outward Einstein Midpoint。

**💡 创新点**

创新点包括：1）将自然语言的层级结构映射到双曲空间；2）构建全双曲和混合双曲检索模型；3) 设计能够保留层级信息的几何聚合方法；4) 在 MTEB 与 RAGBench 上显著提升检索与生成质量。

**🔧 技术方法**

采用 Lorentz 双曲模型、双曲 Transformer 组件、双曲自注意力、Outward Einstein Midpoint 聚合、无监督与监督对比预训练、基于几何的相似度度量。

**📊 数据集**

使用 2023 年 Wikipedia 语料进行掩码语言建模，约 235M 文本对进行无监督对比，BEIR 训练集进行监督微调，评估使用 MTEB benchmark 和 RAGBench。

**📈 对比分析**

与同参数 Euclidean 基线 EucBERT 及 500M 以下的主流嵌入模型对比；在 MTEB 上 HyTE-FH 获得平均 56.41 分，优于基线；在 RAGBench 上 Faithfulness、Context Relevance、Answer Relevance 分别达 0.732/0.848/0.765，提升 20-29%，显著优于现有方法。

**⚠️ 局限性**

局限性在于双曲空间运算实现复杂，推理时计算和内存成本略高；对曲率和聚合权重等超参数敏感；在极大规模检索场景下仍需进一步优化索引与存储。

---

## 381. Learnable Chernoff Baselines for Inference-Time Alignment

**arXiv ID:** 2602.07738 | [PDF](https://arxiv.org/pdf/2602.07738v1)

**作者:** Sunil Madhow `[一作]` (University of California San Diego), Yu-Xiang Wang `[通讯]` (University of California San Diego)

**通讯引用:** 7512 | [OpenAlex ID](https://openalex.org/A5100403244)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出 Learnable Chernoff Baselines (LCBs) 方法，用于在推理时高效地对预训练生成模型进行奖励引导对齐，减少对模型的查询次数。

**💡 创新点**

创新点在于：①利用可学习的 Chernoff 基线在每一步自适应地设定接受概率，从而近似指数倾斜核的拒绝采样；②提供全局与局部总变差（TV）误差理论保证；③提出一套自适应的基线学习与采样框架，兼顾采样效率与精度。

**🔧 技术方法**

主要技术包括：可学习的软值函数估计、基于 Chernoff 边界的基线设计、近似拒绝采样、经验风险最小化优化、Rademacher 复杂度分析以及在连续和离散扩散模型上的实现。

**📊 数据集**

实验数据集：连续设置为 2 维高斯混合分布；离散设置为 8B 参数的 LLaDA 语言扩散模型，使用 3 句故事生成任务。

**📈 对比分析**

与传统方法（完整拒绝采样 RS、Best‑of‑N BoN）比较：LCBs 在保证与 RS 相同奖励统计的前提下，查询次数显著减少（连续设置约 12.5×、离散设置 20–40%），并在相同对齐强度下保持或略优的平均奖励和完美样本率。

**⚠️ 局限性**

局限性：对软值函数估计的准确性高度依赖，若估计误差大，采样误差累积；在极端温度或奖励范围过大时，基线学习难以保持低覆盖率，导致采样效率下降；模型对奖励的敏感性可能被滥用。

---

## 382. ParisKV: Fast and Drift-Robust KV-Cache Retrieval for Long-Context LLMs

**arXiv ID:** 2602.07721 | [PDF](https://arxiv.org/pdf/2602.07721v1)

**作者:** Yanlin Qi `[一作]` (Universite Paris Cite), Themis Palpanas `[通讯]` (Universite Paris Cite)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出ParisKV框架，对长上下文LLM推理中的KV缓存检索实现快速且漂移鲁棒的方案。

**💡 创新点**

创新点在于先将键/查询归一化并随机正交旋转到单位球面，使用数据无关的分析质心做候选生成；构建GPU原生两阶段碰撞-重排序流水线，并通过UVA将全精度KV缓存卸载到CPU，极大降低GPU内存压力和数据移动。

**🔧 技术方法**

采用归一化+随机正交旋转、单位球面均匀质心、子空间碰撞计数、4bit量化与α校正重排序、GPU自定义CUDA核、UVA异步卸载等技术。

**📊 数据集**

在长生成任务上使用MATH500、GPQA‑Diamond、AIME25；在长输入理解任务上使用LongBench‑V2；实验模型包括Qwen‑3‑8B、DeepSeek‑R1‑Llama‑8B和Qwen3‑4B‑Thinking‑2507。

**📈 对比分析**

与MagicPIG、PQCache以及全注意力对比：在百万token级别下解码延迟分别比MagicPIG和PQCache低17×、44×；在可运行范围内吞吐率比全注意力高1.5–2.8×；在长生成/长输入基准上准确率与全注意力相当或更优。

**⚠️ 局限性**

局限性：仍需GPU内存做两阶段检索；极大上下文依赖CPU内存搬移；量化误差与α校正在分布极端时可能受限；未针对多租户安全与隐私做专门保障。

---

## 383. Efficient Planning in Reinforcement Learning via Model Introspection

**arXiv ID:** 2602.07719 | [PDF](https://arxiv.org/pdf/2602.07719v1)

**作者:** Gabriel Stella `[一作]` `[通讯]` (Texas A and M University), Gabriel Stella (Texas A and M University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `64443552-63e0-44b5-906f-d90fe95c5a1b`

**🎯 论文内容**

开发了一种基于模型自省的强化学习规划方法（Introspector），自动生成里程碑并利用启发式搜索显著提高规划效率。

**💡 创新点**

创新点在于将模型自省视为程序分析，自动推导里程碑和启发式，构建了强化学习与经典规划之间的桥梁，降低搜索复杂度。

**🔧 技术方法**

采用了基于一阶逻辑的可解释模型、状态变异(state‑mutation)技术以及启发式搜索（如A*、STRIPS字面计数）来实现里程碑枚举与规划。

**📊 数据集**

使用了关系强化学习实验环境：Blocks‑World、Drawers 与 Bins（均为随机生成的堆栈/物品分布），没有使用外部公开数据集。

**📈 对比分析**

通过与穷举贪婪搜索、MCTS、宽度搜索等传统方法对比，Introspector 在节点扩展数、运行时间等指标上实现了从指数级到亚指数级的性能提升，显著优于基线。

**⚠️ 局限性**

局限性包括：仅适用于可解释（符号/逻辑）模型，难以直接扩展到深度神经网络等黑盒模型；里程碑定义目前仅覆盖最大奖励，其他目标与探索策略尚未深入研究。

---

## 384. Certified surface approximations using the interval Krawczyk test

**arXiv ID:** 2602.07718 | [PDF](https://arxiv.org/pdf/2602.07718v1)

**作者:** Michael Burr `[一作]` (Clemson University), Kisun Lee `[通讯]` (Clemson University)

**通讯引用:** 8 | [OpenAlex ID](https://openalex.org/A5041815384)

**关键词:** `847a60d8-a755-47af-ba5d-c5236b9e3083` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

通过将Krawczyk测试推广到非方阵系统和更高维多样体，提出一种基于区间算术的、可证实的曲面逼近算法，并实现了相应的Julia程序。

**💡 创新点**

核心创新是：① 将Krawczyk测试从方阵系统扩展到非方阵系统与高维变体；② 采用酉变换（SVD）在局部坐标系下消除斜率大导致的宽盒问题；③ 设计了“组件测试”和“包含测试”以实现多片段曲面在重叠区域的可证实拼接，保证拓扑正确性。

**🔧 技术方法**

主要技术手段包括：区间算术与区间Krawczyk算子、SVD基酉变换、多变数根隔离与近似、分层细分与修剪、拓扑判定算法（组件测试/包含测试）以及Julia中IntervalArithmetic.jl等库。

**📊 数据集**

实验数据集主要为经典几何曲面：单位球、半径为√10的球体、环面、鞍面；每个曲面从一个已知点开始，采用不同ρ值和初始半径进行测试。

**📈 对比分析**

通过改变ρ参数（例如1/8 vs 1/80）观察盒子平均半径与逼近精度的关系；在相同盒子数量下，ρ更小得到更细的逼近。与现有的基于Newton或α‑理论的证实方法未做直接量化对比，但实验表明该方法能够在数千个盒子内完成高维曲面覆盖。

**⚠️ 局限性**

主要局限包括：
- 对高维（d>2）时分割成2^d子盒的成本高；
- 根隔离步骤在非方阵系统中效率低；
- 需要手动设定初始点与半径，缺乏自动化；
- 目前只在有限范围内（如球体、环面、鞍面）验证，缺乏大规模实用案例；
- 对曲面自相交或奇异点的处理尚未完整。

---

## 385. Analyzing and Guiding Zero-Shot Posterior Sampling in Diffusion Models

**arXiv ID:** 2602.07715 | [PDF](https://arxiv.org/pdf/2602.07715v1)

**作者:** Roi Benita `[一作]` (Technion), Joseph Keshet `[通讯]` (Technion)

**通讯引用:** 4263 | [OpenAlex ID](https://openalex.org/A5008847407)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了基于谱分析的零射拡散后验采样框架，提供闭式表达式评估先验与观测的平衡；

**💡 创新点**

通过高斯先验假设推导理想后验采样器，构建方法无关的参数优化公式，消除经验调参；

**🔧 技术方法**

使用扩散模型（DDPM/DDIM）、Wasserstein-2距离、谱分解与高斯先验理论；

**📊 数据集**

在FFHQ、ImageNet以及合成高斯先验数据集上进行实验；

**📈 对比分析**

与现有DPS、ΠGDM经验权重方案对比，Spectral方案在PSNR/SSIM/LPIPS/FID指标上取得更均衡性能，Wasserstein距离接近理想采样器；

**⚠️ 局限性**

仅在高斯先验条件下具理论可解释性，对非高斯先验及大规模高分辨率图像仍需进一步验证与加速。

---

## 386. Dense Feature Learning via Linear Structure Preservation in Medical Data

**arXiv ID:** 2602.07706 | [PDF](https://arxiv.org/pdf/2602.07706v1)

**作者:** Yuanyun Zhang `[一作]` (Independent Researcher), Shi Li `[通讯]` (Columbia University)

**通讯引用:** 34781 | [OpenAlex ID](https://openalex.org/A5025170020)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `9ce7179e-700c-4310-ac2b-91df50ded46e` `e15e3743-5ee0-4d5f-813d-d146868082fc` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

提出密集特征学习框架，通过谱平衡、子空间一致性和特征正交等线性代数约束，训练生成高秩、条件良好、时间稳定的医学嵌入，并在冻结特征上做线性下游任务评估。

**💡 创新点**

将表示学习目标从单一任务损失转向直接优化嵌入矩阵的线性结构，首次将谱扩展、子空间一致性与正交约束结合，强调维度完整性与几何属性。

**🔧 技术方法**

使用协方差谱正则化、投影矩阵距离惩罚、批归一化+正交约束，SVD求主子空间，梯度下降联合优化这些损失，实现无监督/自监督训练。

**📊 数据集**

在三类医学数据上验证：长期电子健康记录表格、临床文本以及多模态病人快照（结构化实验室+文本）。

**📈 对比分析**

与监督交叉熵、掩码重构、对比学习等基准同架构同数据对比；Dense Feature Learning在有效秩、条件数、子空间稳定性以及线性下游AUROC/ARI/RMSE上均显著优于基线，提升幅度约30%+。

**⚠️ 局限性**

计算成本高（协方差、SVD计算），在极大规模或高维时需近似；对于高度专业化任务可能不适合全稠密预训练；缺乏对任务特定压缩的兼容性。

---

## 387. Capacity Scaling Laws for Boundary-Induced Drift-Diffusion Noise Channels

**arXiv ID:** 2602.07866 | [PDF](https://arxiv.org/pdf/2602.07866v1)

**作者:** Yen-Chi Lee `[一作]` (National Central University), Yen-Chi Lee `[通讯]` (National Central University)

**通讯引用:** 6818 | [OpenAlex ID](https://openalex.org/A5090630527)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

研究基于漂移扩散过程在吸收超平面上的首次击中位置产生的噪声，并将其建模为高斯方差混合（NDFHL）分布，进而分析该噪声的容量上界与下界，得到高SNR下的精确容量扩展。

**💡 创新点**

创新点在于：①把首次击中噪声视作一种几何诱导的高斯方差混合，避免了复杂的贝塞尔函数密度；②在有限方差（u>0）和无限方差（u→0）两种极限下统一地给出了容量的高SNR预日志因子和常数项，证明了高SNR下的零形状缺口；③揭示容量偏置完全由噪声的微分熵决定，体现了几何熵主导的普适性。

**🔧 技术方法**

采用了随机过程与概率分布的混合表示、特征函数解析、极限逼近、信息熵界限、最大熵原理、以及对冲定理（Dominated Convergence Theorem）等信息论与随机分析工具。

**📊 数据集**

无实测数据集，本文完全基于理论推导与数值积分验证（如对熵随漂移速度u的变化作图）。

**📈 对比分析**

通过与经典的高斯信道和Cauchy噪声通道对比，证明在高SNR时容量增长为 (p/2)log P + 常数；预日志因子 p/2 与维数无关，常数项可通过噪声熵精确计算，显示了与传统均值方差约束下的高斯信道相同的自由度。

**⚠️ 局限性**

局限性包括：①对漂移速度u=0的无限方差情形仅能给出扩展的连贯性推断，缺乏严格的极限证明；②分析仅针对第二矩约束下的高SNR regime，低SNR 或非二次功率约束的容量仍未讨论；③对非球面或有偏漂移的更一般边界几何未作处理。

---

## 388. Thinking in Structures: Evaluating Spatial Intelligence through Reasoning on Constrained Manifolds

**arXiv ID:** 2602.07864 | [PDF](https://arxiv.org/pdf/2602.07864v1)

**作者:** Chen Yang `[一作]` (Tsinghua University), Jiansheng Fan `[通讯]` (Tsinghua University)

**通讯引用:** 5349 | [OpenAlex ID](https://openalex.org/A5109972350)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并发布了一套以复杂真实工程结构为基础的受约束流形空间推理（CMSR）VQA基准，包含 1,000 个排序式多选问题，旨在评估视觉语言模型对受约束 3D 结构的推理能力。

**💡 创新点**

创新点：
- 引入 CMSR 概念，强调在强约束下的 3D 空间推理；
- 采用排序任务形式，消除 2D 视觉短路；
- 通过 400+ 小时人工审核构建高质量、多视角题集；
- 对模型进行“思考”提示实验，并给出详细错误分析。

**🔧 技术方法**

使用技术：VQA 评估框架、排序式问答模板、思考提示机制、手工标注（定位、排序、冲突处理）、多视角一致性检测。

**📊 数据集**

数据集：约 2,000 张真实工程结构图像（桥梁、钢结构、管线等），经过人工挑选、标注并生成 1,000 个排名问题，其中包含单视角与双视角子集。

**📈 对比分析**

比较方法：在 31 种公开与闭源 VLM 上进行任务准确率评估；最优开源模型 22.2%，最优闭源模型 33.6%，人类平均 91.6%；结果显示显著性能差距，思考提示提升有限。

**⚠️ 局限性**

limitations: 
- 依赖人工耗时高，难以大规模自动扩展；
- 受限于所选工程结构类型，覆盖面有限；
- 模型仍难以实现一致的 3D 重构，错误主要集中在结构识别与空间推理。

---

## 389. Emergent Misalignment is Easy, Narrow Misalignment is Hard

**arXiv ID:** 2602.07852 | [PDF](https://arxiv.org/pdf/2602.07852v1)

**作者:** Anna Soligo `[一作]`, Neel Nanda `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

本文研究了在大型语言模型（LLM）上对窄范围有害数据进行微调时会出现的“emergent misalignment”（泛化不良行为），并通过线性表示、KL 正则化等方法，分别提取并对比了窄义与广义不良行为的向量，进一步提出了效率、稳定性与预训练显著性三项指标来解释模型为何偏好学习广义方向。

**💡 创新点**

创新点在于：①首次证明了除广义不良行为之外，还存在对应窄义行为的线性方向；②提出通过对训练过程加 KL 正则化可以成功学习窄义行为；③构造了效率、稳定性和预训练显著性三种可量化指标，并证明它们能够解释模型偏好广义不良方向的现象；④在技术写作等第二类泛化任务中验证了这些指标的通用性。

**🔧 技术方法**

使用的技术包括：线性方向提取（mean‑diff 激活向量）、LoRA/Steering 向量微调、KL Divergence 正则化、参数范数与损失比率（效率评估）、对角噪声扰动实验（稳定性评估）、对预训练分布数据（Fine‑Web）的 KL 变化测量，以及 LLM 判断器评估。

**📊 数据集**

所用数据集：1）窄范围有害数据集（bad medical advice、risky financial advice、extreme sports advice）；2）合成文本数据集（用于诱导更强的泛化不良行为）；3）预训练分布数据 Fine‑Web（用于显著性评估）；4）开放式提示和 hold‑out 领域测试问题（用于行为评估）。

**📈 对比分析**

比较方法：在相同的微调协议下，分别训练得到广义和窄义方向，随后在不同参数范数、噪声比例、预训练数据上评估它们的损失、参数范数、KL 散度和对外部提示的误导率。实验结果表明，广义方向在相同参数范数下损失更低、对噪声更稳健、对预训练数据的影响更大，并在外部提示上产生更高比例的误导性响应，显示出更强的泛化能力。

**⚠️ 局限性**

局限性包括：仅针对两类意外泛化现象（EM 和技术写作）进行实验；缺乏因果证据说明效率/稳定性/显著性为何决定偏好；对 LLM 评估器的依赖可能导致评估偏差；难以完全将窄义与广义行为分离，可能存在混合效应。

---

## 390. MARTI-MARS$^2$: Scaling Multi-Agent Self-Search via Reinforcement Learning for Code Generation

**arXiv ID:** 2602.07848 | [PDF](https://arxiv.org/pdf/2602.07848v1)

**作者:** Shijie Wang `[一作]` (Shanghai AI Laboratory), Biqing Qi `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一种多智能体强化训练与推理框架 MARS^2，用于在代码生成任务中实现自搜索扩展。

**💡 创新点**

在 RL 训练阶段引入动态多智能体树搜索与组级优势估计，并在推理阶段结合错误反馈、深度引导和奖励模型，实现从单智能体到同参数多角色再到异参数多智能体的系统性规模化路径。

**🔧 技术方法**

采用 GRPO/GRPO+ 的无价值网络 RL、结构化多智能体树搜索（AB‑MCTS）、奖励模型、错误反馈集成、深度导向探索、GSPO、Overlong Penalty、TIS 等技术。

**📊 数据集**

训练使用 DeepCoder 编码数据集，评估使用 LiveCodeBench v6，并在奖励模型训练中构造大规模验证集。

**📈 对比分析**

与单智能体 GRPO、同参数多角色 Homo‑MARS^2、Vanilla TTS 等基线在 Pass@1、Pass@1(MCTS)、Pass@N 等指标上对比，异参数多智能体 MARS^2 在 32B 规模下达 77.7% Pass@1，超过多家开源及专有基线。

**⚠️ 局限性**

需要巨量算力，训练过程仍易受奖励稀疏和策略收敛问题影响；现有评测主要聚焦代码生成，缺乏跨领域验证；多智能体的协同效率随模型数增大仍有限，且对推理预算和超参数敏感。

---

## 391. VFace: A Training-Free Approach for Diffusion-Based Video Face Swapping

**arXiv ID:** 2602.07835 | [PDF](https://arxiv.org/pdf/2602.07835v1)

**作者:** Sanoojan Baliah `[一作]` (Michigan State University), Muhammad Haris Khan `[通讯]` (MBZUAI)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ba576bd1-e51d-44e8-8077-fc943b333c93` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种无需训练的扩散模型视频换脸框架VFace，能在保持目标视频姿态、表情与背景的同时，将源图像身份特征迁移到视频中。

**💡 创新点**

创新点在于三项无训练模块：Target Structure Guidance通过注意力注入对齐目标结构；Frequency Spectrum Attention Interpolation在频域融合身份与结构特征；Flow‑Guided Attention Temporal Smoothening在注意力层通过光流实现时序平滑。

**🔧 技术方法**

采用预训练的扩散模型（如REFace）与DDIM逆推、交叉注意力、光流（RAFT‑Large）以及FFT/逆FFT等技术。

**📊 数据集**

使用CelebA、FFHQ、VFHQ、CelebV‑HQ等公开人脸图像/视频数据集进行实验。

**📈 对比分析**

与REFace、Go‑with‑the‑Flow、AnyV2V等基线对比，VFace在FID、ID检索、姿态误差、表情误差、FVD、CD‑FVD等指标上均显著优于或相当于现有方法，且仅增加5.3s的推理时间。

**⚠️ 局限性**

局限性包括对复杂遮挡的鲁棒性不足、依赖光流估计误差、以及对极端姿态变化或光照变化的适应性有限。

---

## 392. Back to Physics: Operator-Guided Generative Paths for SMS MRI Reconstruction

**arXiv ID:** 2602.07820 | [PDF](https://arxiv.org/pdf/2602.07820v1)

**作者:** Zhibo Chen `[一作]` (Nanchang University), Qiegen Liu `[通讯]` (Nanchang University)

**通讯引用:** 3425 | [OpenAlex ID](https://openalex.org/A5057647276)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

本文提出一种基于采集算子的确定性退化轨迹的 SMS 磁共振成像 k 空间重建框架，并在此基础上设计了双流交互网络 OCDI-Net，实现对多切片干扰和在平面欠采样缺失的结构化去噪与恢复。

**💡 创新点**

创新点在于：①用采集算子（CAIPI 与 Cartesian 采样）代替高斯噪声退化，构造物理一致的确定性前向过程；②引入目标‑内容流与干扰流的双流结构，并在多尺度上利用注意力交互实现高效的干扰分离与抑制；③将重建拆分为两阶段链式推断（先解混叠再完成欠采样），显著提升在高多束因子与高加速率下的鲁棒性。

**🔧 技术方法**

技术实现包括：确定性退化预测网络 OCDI-Net（U‑Net 结构、时间与阶段条件嵌入、双流交互注意力）、基于采集算子的确定性逆向更新、两阶段链式重建流程以及针对欠采样的伪测量一致性投影。

**📊 数据集**

实验数据集涵盖：公开 fastMRI 大脑 T2‑weighted 数据（16 通道，模拟 MB3 与 R=1/2/3 的 SMS+欠采样）以及天津大学自有的 3.0T 扩散加权成像（DWI）数据（MB2, R2，b=1000 和 0）。

**📈 对比分析**

与 SENSE、Slice‑GRAPPA、RAKI、ROGER 等传统与学习型基线对比，实验显示 OCDI‑Net 在 PSNR、SSIM 上均高于所有方法，尤其在 MB3、R2 的高加速条件下能显著降低切片泄漏并保留高频结构；在实际 DWI 数据上亦表现出更清晰的组织边界与更低的结构残差。

**⚠️ 局限性**

局限性包括：对 CAIPI 相位模组和采样掩码的准确性高度依赖，若出现算子误差易产生残留结构误差；两阶段链式推断可能导致错误在 Stage‑U 传播；目前验证仅覆盖 Cartesian 采样与固定的多束因子，未来需扩展至非 Cartesian、不同线圈与序列配置下的鲁棒性评估。

---

## 393. TouchScribe: Augmenting Non-Visual Hand-Object Interactions with Automated Live Visual Descriptions

**arXiv ID:** 2602.07802 | [PDF](https://arxiv.org/pdf/2602.07802v1)

**作者:** Ruei-Che Chang `[一作]` (University of Michigan), Anhong Guo `[通讯]` (University of Michigan)

**通讯引用:** 1790 | [OpenAlex ID](https://openalex.org/A5021329493)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `e0540dec-d77f-42db-94ae-d039248f6393` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了TouchScribe系统，通过使用用户的手部动作（如握持、触摸、指点、滑动等）作为信息指针，实时提供多层级的视觉描述，帮助视障或低视力用户获得对象的形状、颜色、文字等视觉细节；

**💡 创新点**

创新点在于：①将手部交互直接映射为视觉信息获取的“光标”，实现无需相机对准或拍照即可获取描述；②结合手势识别、对象接触检测和轻量化视觉语言模型，构建端到端实时反馈；③支持多种交互模式（比较、点读、滑动读取文本）并提供分层反馈；

**🔧 技术方法**

主要技术包括：基于MediaPipe的人体关键点检测与自定义手势分类模型；Hands23模型进行手-对象接触识别；两种VLM：轻量化的Moondream用于简短描述，GPT‑4o用于详细描述、文本读取和比较；时间平滑算法用于抑制手势识别抖动；

**📊 数据集**

数据集：自行采集的手部交互视频（约2000个手势实例），对象图像来自日常厨房/零售物品（香料瓶、咖啡杯、喷雾瓶等），以及BLV参与者在实验室中的真实交互记录；

**📈 对比分析**

与现有视觉描述工具（SeeingAI、OrCam、WorldScribe等）比较：手势识别F1≈0.77；简短描述准确率91.6%，详细描述93.3%；相对较低的文字识别准确率67.8%；响应延迟从0.09s（颜色）到14s（比较描述），整体比基于拍照+问答的方式更快；

**⚠️ 局限性**

局限性包括：①相机视场宽角造成畸变与手势识别误差；②手势识别对遮挡和运动模糊敏感；③多层级反馈导致信息堆叠，需更优的优先级管理；④学习曲线和手势可视化提示不够友好；⑤实验在实验室环境，未验证复杂日常情境下的鲁棒性；⑥社会可接受度与佩戴舒适度待进一步优化。

---

## 394. System-Level Error Propagation and Tail-Risk Amplification in Reference-Based Robotic Navigation

**arXiv ID:** 2602.07846 | [PDF](https://arxiv.org/pdf/2602.07846v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

---

## 395. Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents

**arXiv ID:** 2602.07796 | [PDF](https://arxiv.org/pdf/2602.07796v1)

**作者:** Jiatong Li `[一作]` (University of Wisconsin Madison), Sharon Li `[通讯]` (University of Wisconsin Madison)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文系统评估了在用户交互场景下强制让LLM先思考（思考机制）是否能提升代理性能，并发现思考往往适得其反，导致交互效果下降。

**💡 创新点**

创新点在于揭示“先思考”在多轮、部分可观测的用户交互中会让代理变得“内向”，信息披露不足，从而损害任务完成；并提出了简单的“信息披露提示”(InfoDis)来显著提升性能。

**🔧 技术方法**

使用了两种常见思考实现：Thinking-as-a-Function（TaaF）和Thinking-as-a-Prefix（TaaP），并通过大规模语言模型对响应进行自动语义分解与信息披露计数。

**📊 数据集**

实验数据集包含三个典型用户交互基准：τ‑Retail、τ‑Airline 与 TS‑Phone（ToolSandbox），共计约1.8k、600 与 1.6k 条交互。

**📈 对比分析**

通过对比七种主流LLM（包括GPT‑5、GPT‑4.1、GPT‑4o、Gemini‑2.5‑Pro、DeepSeek‑V3.1、gpt‑oss‑120b、Qwen3‑30B‑A3B），在 Pass@1 和 MSim 指标上发现思考通常降低性能（平均下降约4‑6%），而加入信息披露提示后可恢复并提升1‑4%性能。

**⚠️ 局限性**

局限性包括：仅覆盖三类任务导向式对话，未考察开放式或创意协作场景；并依赖自动化分类与大模型辅助标注，可能存在细粒度误差。

---

## 396. Orchestrating Attention: Bringing Harmony to the 'Chaos' of Neurodivergent Learning States

**arXiv ID:** 2602.07865 | [PDF](https://arxiv.org/pdf/2602.07865v1)

**作者:** Satyam Kumar Navneet `[一作]` (Independent Researcher), Yong Zhang `[通讯]` (Tsinghua University)

**通讯引用:** 47808 | [OpenAlex ID](https://openalex.org/A5007650371)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `9cc9baba-5356-466d-81ff-d80028d90279` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

开发并验证了一套名为AttentionGuard的自适应用户界面框架，利用隐私保护的行为信号实时检测四种注意力状态并调整界面，以支持神经多样性学习者。

**💡 创新点**

创新点包括：将ADHD注意力模式细分为四种状态并实现实时检测；设计五种基于神经科学的双向适配UI模式；通过可视化与可逆的适配增强用户代理与系统透明度。

**🔧 技术方法**

使用随机森林分类器处理30秒滑动窗口的点击率、滚动速度、鼠标熵等特征，实现隐私保护的注意力状态推断，并结合Wizard‑of‑Oz实验评估适配效果。

**📊 数据集**

训练和评估模型使用OULAD数据集，交叉验证HYPERAKTIV数据集验证ADHD相关性；在11名自报ADHD特征的参与者上进行Wizard‑of‑Oz实验。

**📈 对比分析**

5折交叉验证得到87.3%准确率（宏F1 0.84）；HYPERAKTIV中对ADHD诊断的AUC为0.81；Wizard‑of‑Oz实验显示自适应条件下NASA‑TLX从62.8降至47.2（d=1.21），理解率从61.2%提升至78.4%（d=1.18），差异显著。

**⚠️ 局限性**

局限性包括样本量小（N=11）、仅自报ADHD诊断、Wizard‑of‑Oz代替完全自动化、缺乏临床验证，以及模型仅检测行为模式而非正式诊断。

---

## 397. Privacy-Preserving Coding Schemes for Multi-Access Distributed Computing Models

**arXiv ID:** 2602.07850 | [PDF](https://arxiv.org/pdf/2602.07850v1)

**作者:** Shanuja Sasi `[一作]` (Indian Institute of Technology Kanpur), Shanuja Sasi `[通讯]` (Indian Institute of Technology Kanpur)

**通讯引用:** 66 | [OpenAlex ID](https://openalex.org/A5022319079)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

本文在多访问分布式计算（MADC）模型中引入任务分配隐私约束，并针对两种特定的连通性模式（α-连通和α-循环连通）设计了基于扩展置放交付数组（E-PDA）的私有编码方案，实现在无文件复制的前提下达到计算负载 r = 1 与通信负载 L = (F-α)/F(K-1)(α+1) 或 L = (Q-α)/(2Q(K-1)) 的性能。

**💡 创新点**

创新点在于：1) 将隐私保护直接融入 MADC 框架；2) 通过构造新的扩展 PDAO 结合 g-regular 与 (l,g)-regular PDAs 实现两种连通性模式的隐私编码；3) 提出一种通用的私有编码框架，兼容不同的 mapper-reducer 连接结构。

**🔧 技术方法**

采用的技术包括：置放交付数组（PDA）理论、g-regular 与 (l,g)-regular PDA 构造、E-PDA 扩展算法（Algorithm 1 与 Algorithm 3）、随机置换广播以隐藏 reducer 的任务指令，以及基于 XOR 的编码传输。

**📊 数据集**

论文未使用具体实验数据集，而是通过理论分析与构造证明展示方案的可行性与性能。若需实验，可选用标准 MapReduce 测试集如 TeraSort 或 ML 训练数据。

**📈 对比分析**

与传统 CDC 或无隐私 MADC 的通信负载相比，本文方案在不复制文件的情况下实现了更低的通信负载，并且保证了任务分配的隐私。性能上，通信负载随 α 的增大而降低，且与 reducer 数量 K 成线性关系。

**⚠️ 局限性**

局限性包括：1) 仅覆盖两种特定连通性模式；2) 方案的实现依赖于精确的 PDA 构造，可能在大规模系统中面临子文件划分与符号映射的复杂性；3) 目前仅提供理论证明，缺乏大规模实验验证。

---

## 398. Open-Text Aerial Detection: A Unified Framework For Aerial Visual Grounding And Detection

**arXiv ID:** 2602.07827 | [PDF](https://arxiv.org/pdf/2602.07827v1)

**作者:** Guoting Wei `[一作]` (Nanjing University of Science and Technology), Rong Xiao `[通讯]` (Intellifusion)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出OTA-Det统一框架，实现开放词汇航空检测与遥感视觉定位的多目标多粒度语义理解与实时检测

**💡 创新点**

将RSVG转化为联合分类-定位任务并引入密集语义对齐，构建属性级对齐与解耦多粒度头，实现细粒度属性对齐与组合查询

**🔧 技术方法**

基于RT-DETR架构，使用DINOv3-STAs图像编码器、SigLIPv2文本编码器、对齐损失MAL、解耦多粒度头和统一对应矩阵

**📊 数据集**

联合训练LAE-1M、OPT-RSVG、DIOR-RSVG、AerialVG等数据集；评估DIOR、DOTA、LAE-80C（OVAD）和OPT-RSVG、DIOR-RSVG、AerialVG（RSVG）

**📈 对比分析**

与现有OVAD/RSVG方法对比，OTA-Det在六大基准上实现最高mAP/Acc@0.5（如AerialVG 54.9/51.7/53.9），且推理速度达34 FPS，显著优于传统模型

**⚠️ 局限性**

在单任务训练下性能略高，且对属性对齐的准确性仍受限于LLM解析精度与表达多样性的覆盖，需进一步提升跨模态泛化与大规模属性库

---

## 399. VideoTemp-o3: Harmonizing Temporal Grounding and Video Understanding in Agentic Thinking-with-Videos

**arXiv ID:** 2602.07801 | [PDF](https://arxiv.org/pdf/2602.07801v1)

**作者:** Wenqi Liu `[一作]` (Shandong University), Xuemeng Song `[通讯]` (Southern University of Science and Technology)

**通讯引用:** 3783 | [OpenAlex ID](https://openalex.org/A5072768866)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种统一的 agentic thinking-with-videos 框架，能够在单一模型中完成视频定位、动态裁剪和答案生成，并支持多轮迭代细化。

**💡 创新点**

核心创新包括：统一掩码策略提升 SFT 效果、惩罚感知 IoU 奖励防止奖励劫持、构建高质量多轮工具调用数据集、创建 VideoTemp‑Bench 评测基准，并将定位与 QA 任务无缝融合。

**🔧 技术方法**

采用 Qwen2.5‑VL‑7B 作为主干模型，结合 GRPO 强化学习、惩罚式 IoU 奖励、工具调用裁剪机制以及统一掩码训练策略。

**📊 数据集**

数据方面：构建了大规模长视频 GQA 数据集；使用现有公开数据集（MLVU、VideoMMMU、VideoMME、LVBench、Charades‑STA、ActivityNet‑MR、NextGQA、ReXTime）以及新建的 VideoTemp‑Bench 进行评估。

**📈 对比分析**

与 VideoChat‑R1、Video‑R1、TimeMaker 等前沿模型对比，SOTA 取得了长视频 QA 精度提升（如 VideoMME+2.4%），定位 mIoU 最高 57.8（Charades‑STA），GQA mIoU/Acc 分别达 29.5/76.4（ReXTime）。

**⚠️ 局限性**

局限性在于：对极长视频（>20 min）时定位与 QA 性能仍显著下降；模型仅支持裁剪工具，缺乏搜索、跨模态检索等功能；对复杂推理与细粒度任务仍有较大挑战。

---

## 400. Fairness Aware Reward Optimization

**arXiv ID:** 2602.07799 | [PDF](https://arxiv.org/pdf/2602.07799v1)

**作者:** Ching Lam Choi `[一作]` (Massachusetts Institute of Technology), Stefanie Jegelka `[通讯]` (Technical University of Munich)

**通讯引用:** 5576 | [OpenAlex ID](https://openalex.org/A5085699861)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

由于论文仅提供章节标题，缺乏具体内容，无法确定研究做了什么。

**💡 创新点**

无法识别创新点。

**🔧 技术方法**

无法确认使用的技术。

**📊 数据集**

无法确定使用的数据集。

**📈 对比分析**

无法比较方法或评估性能。

**⚠️ 局限性**

由于信息不足，无法评估论文的局限性。

---

## 401. RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI

**arXiv ID:** 2602.07837 | [PDF](https://arxiv.org/pdf/2602.07837v1)

**作者:** Hongzhi Zang `[一作]` (Tsinghua University), Yu Wang `[通讯]` (Tsinghua University)

**通讯引用:** 43617 | [OpenAlex ID](https://openalex.org/A5100445300)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

构建了一个统一可扩展的系统 USER，用于在真实世界中在线学习机器人策略。

**💡 创新点**

将机器人视为第一类硬件资源，提供统一硬件抽象层、适应云边通信的动态通道、持久缓存缓冲以及完全异步训练框架。

**🔧 技术方法**

使用了机器人抽象层、基于 UDP 隧道的云边网络、分布式数据通道、SM 感知权重同步、持久化索引缓冲、Ray 分布式调度、深度学习框架（SAC、RLPD、SAC‑Flow、HG‑DAgger）等技术。

**📊 数据集**

在真实机器人（Franka arm）上执行五个操控任务（Peg Insertion、Charger、Cap Tightening、Pick‑and‑Place、Table Clean‑up），并收集对应的演示数据和奖励模型数据。

**📈 对比分析**

通过与同步训练、单机器人基线、多任务、多机器人、异构机器人等对比，证明 USER 在训练速度、样本效率、跨域通信延迟和长期学习稳定性上分别提升 1.5–5.7 倍，成功率接近 1。

**⚠️ 局限性**

仍受网络延迟、硬件兼容性、奖励设计复杂性以及大规模模型训练时的资源瓶颈限制。

---

## 402. Recall, Risk, and Governance in Automated Proposal Screening for Research Funding: Evidence from a National Funding Programme

**arXiv ID:** 2602.07869 | [PDF](https://arxiv.org/pdf/2602.07869v1)

**作者:** Chandan G. Nagarajappa `[一作]` (Indian Institute of Science), Pramod Kumar Arya `[通讯]` (Ministry of Science and Technology)

**关键词:** `f53a5690-f5d8-493f-989c-dc46a1f99053` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

比较了基于TF-IDF关键词规则的透明筛选系统与基于大型语言模型的语义分类系统在科研提案早期筛选中的表现。

**💡 创新点**

创新点在于把错误成本不对称和机构适配性纳入评估框架，强调召回率和误报/漏报结构而非单纯准确率；同时展示透明规则系统在此场景下的优势。

**🔧 技术方法**

使用的技术包括手工关键词工程结合TF‑IDF权重的规则式分类，以及通过结构化提示与保守排除规则的生成式大型语言模型（LLM）语义分类。

**📊 数据集**

采用的实验数据集为一项国家资助项目的959份研究提案，委员会初筛决策（323选中/636拒绝）作为真值。

**📈 对比分析**

通过准确率、精确率、召回率、F1四项指标并重点关注误报与漏报来比较两种方法；TF‑IDF方案取得更高的整体性能，召回率78.95%显著优于LLM的45.82%，误报68/175分别显著降低。

**⚠️ 局限性**

局限性包括LLM对模型、提示和数据偏差敏感，缺乏解释性；实验仅针对单一机构与单一资助项目，缺乏跨领域和跨语言的验证。

---

## 403. A Faster Directed Single-Source Shortest Path Algorithm

**arXiv ID:** 2602.07868 | [PDF](https://arxiv.org/pdf/2602.07868v1)

**作者:** Ran Duan `[一作]` (Tsinghua University), Longhui Yin `[通讯]` (Tsinghua University)

**通讯引用:** 25 | [OpenAlex ID](https://openalex.org/A5108276380)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出一种新的确定性算法，解决有向图单源最短路径问题，时间复杂度为 O(m√(log n)+√(mnlog nloglog n))，在稀疏图上进一步简化为 O(m√(log nloglog n))。

**💡 创新点**

创新点在于将多源前沿划分与局部 Dijkstra 搜索相结合，通过构造 Θ(k)-大小的树并把寻找 pivot 的代价从 O(k) 降低到 O(log k)，同时使用自平衡块 BST 和度约简技术，实现了在比较-加法模型下的更快时间复杂度。

**🔧 技术方法**

主要技术包括：Dijkstra 核心框架、前沿（frontier）划分、局部 Dijkstra 构树、分层递归的 Bounded Multi‑Source Shortest Paths（BMSSP）、块化自平衡二叉搜索树、图度约简、以及比较‑加法运算模型。

**📊 数据集**

论文没有给出具体实验数据集，主要通过理论分析和算法证明来展示性能提升。

**📈 对比分析**

相较于之前的随机化 O(m√(log nloglog n)) 及 Duan 等 2025 年的确定性 O(m·log^{2/3} n) 结果，本文实现了更快的确定性时间；在稀疏图上已达到近似最优的 O(m√log n) 级别。

**⚠️ 局限性**

局限性包括：在密集图中仍然需要 O(√(mnlog nloglog n)) 时间；算法实现复杂度高，实际性能取决于块 BST 的实现；仅在比较‑加法模型下有效，未提供实验验证。

---

## 404. Recovering 3D Shapes from Ultra-Fast Motion-Blurred Images

**arXiv ID:** 2602.07860 | [PDF](https://arxiv.org/pdf/2602.07860v1)

**作者:** Fei Yu `[一作]` (Shandong University), Wenzheng Chen `[通讯]` (Peking University)

**通讯引用:** 2303 | [OpenAlex ID](https://openalex.org/A5010254581)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

提出了一种基于逆渲染的三维形状恢复方法，专门针对超高速运动产生的模糊图像进行形状恢复。

**💡 创新点**

核心创新是开发了快速重心坐标求解器（Fast Barycentric Coordinate Solver），显著降低了在运动模糊合成过程中重复求解重心坐标的计算量，并保持了可微分性，从而实现高效、全差分的运动模糊渲染。

**🔧 技术方法**

技术方案包括：可微分光栅化（SoftRas + DIB‑R风格）、线性运动分段处理、重心坐标快速求解器、基于概率的背景像素影响建模、以及通过梯度下降实现逆渲染的形状与纹理优化。

**📊 数据集**

实验数据集主要使用 ShapeNet（平均约5536面模型）进行合成实验，另外采集了100 Hz、1/100 s曝光的实景旋转物体数据用于真实世界验证。

**📈 对比分析**

与 SoftRas、Nvdiffrast 以及基线学习模型比较，方法在前向渲染和梯度计算上实现了最高 4.57× 的速度提升（相较 SoftRas）和 1.23×（相较 Nvdiffrast）。在形状恢复任务中，三维 IoU 由 0.152 提升到 0.679，模糊图像 PSNR 从 13.58 dB 提升到 31.89 dB，明显优于现有方法。

**⚠️ 局限性**

局限性包括：需要已知相机姿态和运动参数，运动模型假设为线性段；光照和感光响应假设线性，忽略了噪声和非线性摄像机特性；对极端非线性运动或复杂光照环境的适应性尚待提升。

---

## 405. MPM Lite: Linear Kernels and Integration without Particles

**arXiv ID:** 2602.07853 | [PDF](https://arxiv.org/pdf/2602.07853v1)

**作者:** Xiang Feng `[一作]` (University of California, Los Angeles & University of California, San Diego), Chenfanfu Jiang `[通讯]` (University of California, Los Angeles)

**通讯引用:** 5300 | [OpenAlex ID](https://openalex.org/A5068163735)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文提出了 MPM Lite，一种将粒子仅作为状态承载者、并在固定网格上完成所有力组装与时间积分的新型混合 Lagrangian/Eulerian 方法。

**💡 创新点**

创新点在于将粒子重定位为临时转移器，通过线性核将粒子状态重采样到网格中心，从而彻底消除求解阶段对粒子数的依赖，并通过旋转无关的伸长重构实现可优化的隐式积分。

**🔧 技术方法**

使用的核心技术包括：线性多项式（Q1）网格转移、基于 Kirchhoff 应力的粒子‑网格重采样、单点体素网格的有限元积分、旋转无关伸长恢复以及与现成非线性求解器（VBD、PCG）的无缝集成。

**📊 数据集**

实验数据涵盖多种材质与规模：从 1.14M 颗粒的软果冻坠落、5.22M 颗粒的玩具堆叠、2.89M 颗粒的面条挤压，到 8.04M 颗粒的雪球滚动等，均在 GPU（RTX Pro 6000）+CPU 环境下运行。

**📈 对比分析**

与传统基于 B‑spline 的显式/隐式 MPM、CK‑MPM 以及 VBD 求解器对比，MPM Lite 在显式模拟中实现 1.69× 的加速，在隐式模拟中最高可达 15.9× 的加速，并保持与经典 MPM 一致的视觉精度与物理正确性。

**⚠️ 局限性**

局限性包括：只能处理各向同性材料（异向性需额外方向状态）、单点体素网格导致的欠积分/扭曲误差、对极端压缩/拉伸/接近不可压缩情形的数值稳定性挑战，以及对多流速、非欧氏或自适应网格的扩展仍需进一步研究。

---

## 406. Evaluating and Calibrating LLM Confidence on Questions with Multiple Correct Answers

**arXiv ID:** 2602.07842 | [PDF](https://arxiv.org/pdf/2602.07842v1)

**作者:** Yuhan Wang `[一作]` (State Key Laboratory of AI Safety), Keping Bi `[通讯]` (State Key Laboratory of AI Safety)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文针对多答案问答场景的置信校准问题，构建了新的MACE基准数据集，对15种训练‑自由置信校准方法在多答案与单答案两种场景下进行系统评估，并提出了基于聚合多答案概率的Semantic Confidence Aggregation（SCA）方法。

**💡 创新点**

创新点包括：①首次提出多答案置信校准基准MACE；②揭示在多答案场景下一致性校准方法会出现置信下降并导致严重失调；③提出SCA方法，通过聚合多条高概率答案的token级生成概率来恢复校准性能，且不依赖复杂聚类或阈值调参。

**🔧 技术方法**

技术方法：训练‑自由置信校准技术（token概率、语义熵、一致性、口头化、后验检验等）；对答案进行多采样并聚类；对每个聚类计算token概率总和，再对高置信聚类求和得到最终置信；与SNA/SFCA等聚合基线对比。

**📊 数据集**

数据集：MACE（12,000条事实问答，六个领域，1/2/4/6个正确答案），并利用公开问答数据（如MMLU、FEVER等）与多种LLM（7B–72B）进行评估。

**📈 对比分析**

在LLaMA、Qwen、DeepSeek、GPT等四大LLM系列上，对15种方法进行AUROC、准确率等指标评测。结果显示：单答案时一致性方法表现最佳，但多答案混合时性能骤降；SCA在单答案和多答案场景下均达到或超过SOTA，AUROC提升显著。

**⚠️ 局限性**

局限性：仅在英文短答案上验证，未覆盖多语言、长文本生成；聚合方法对不同模型的鲁棒性未完全探索；需要进一步验证在更复杂开放式问答和跨模态情境中的适用性。

---

## 407. Interpretable Analytic Calabi-Yau Metrics via Symbolic Distillation

**arXiv ID:** 2602.07834 | [PDF](https://arxiv.org/pdf/2602.07834v1)

**作者:** D Yang Eng `[一作]` `[通讯]` (Technical University of Munich), D Yang Eng (Technical University of Munich)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `8d10c613-917e-4880-9716-17789f50e119` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

在研究Calabi–Yau三维流形的Ricci-平坦度量时，作者利用神经网络逼近并通过符号回归提炼出一条五项解析公式，完成了从高维黑盒到可解释低维模型的转化。

**💡 创新点**

创新点在于发现该五项结构在整个Dwork家族（ψ∈[0,0.8]）中保持不变，系数随模数平滑变化，展示了PDE约束决定函数形而模数决定系数的分层原理；同时通过符号回归提取出必要的奇异项1/p_2^n，显著压缩参数量。

**🔧 技术方法**

技术主要包括Donaldson平衡度量的H‑矩阵训练（k=10）、使用PySR进行符号回归、基于两种几何不变量(p_2,σ_3)构建特征、以及对ψ不同取值的多重种子验证。

**📊 数据集**

使用的数据集为10万点在Fermat五次多项式流形上的均匀采样与对应的Donaldson H‑矩阵预测，随后在ψ=0.0,0.2,0.4,0.6,0.8等5个模数点重新训练H‑矩阵以保持教师精度。

**📈 对比分析**

与15,000参数的神经网络和875参数的H‑矩阵相比，5参数符号模型在R^2=0.9994、RMSE≈0.012的同时实现了≈3,000×的参数压缩和≈10,000×的运算加速；在体积积分和Yukawa耦合上误差均保持在2%以内。

**⚠️ 局限性**

局限性包括：教师在ψ≠0时的Ricci-flatness误差约8-9%，导致系数趋势可能受噪声影响；仅验证单一Dwork五次族，未检验其他CY家族；以及仅针对体积与Yukawa耦合等指标，缺乏更严格的曲率相关量验证。

---

## 408. SPD-Faith Bench: Diagnosing and Improving Faithfulness in Chain-of-Thought for Multimodal Large Language Models

**arXiv ID:** 2602.07833 | [PDF](https://arxiv.org/pdf/2602.07833v1)

**作者:** Weijiang Lv `[一作]` (Xidian University), Bo Chen `[通讯]` (Xidian University)

**通讯引用:** 37263 | [OpenAlex ID](https://openalex.org/A5100427264)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `edb9d762-f411-4838-a852-f2d638b018db` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了SPD‑Faith Bench基准，用细粒度图像差异推理评估多模态链式思考的真实性；并提出SAGE训练无关框架提升视觉引导推理的忠实度。

**💡 创新点**

①引入基于视觉差异的对齐评估方法，能剥离语言先验；②发现并系统归纳两种失真模式：感知盲区与感知‑推理脱节；③通过可解释的视觉调节与对比解码实现推理与感知的对齐。

**🔧 技术方法**

视觉注意力动态调制、残差流一致性监测、对比式解码、KL Divergence抑制FFN偏差、基于视觉注意与激活映射的遮罩对比等技术。

**📊 数据集**

使用3,000对图像构成的SPD‑Faith Bench（单差易/中/难与多差2–5差）；对比基准CLEVR‑Change、Spot‑the‑Diff、Birds‑to‑Words等；在MME、CHAIR、PSBattle等公开数据上验证。

**📈 对比分析**

在SPD‑Faith Bench上，SAGE在矛盾率(CR)和差异推理忠实度(DRF)方面较基线提升显著；在MME、CHAIR等传统评测上也显示出更低的幻觉率和更高的判定准确率，证明方法有效。

**⚠️ 局限性**

受限于仅评估图像差异标注任务；SAGE为推理时无训练的改造，需在推理阶段对模型架构做适配，无法直接迁移到大规模训练框架，未来需探索参数高效训练方案。

---

## 409. Efficient Representations are Controllable Representations

**arXiv ID:** 2602.07828 | [PDF](https://arxiv.org/pdf/2602.07828v1)

**作者:** Charles Ye `[一作]` (Independent), Jasmine Cui `[通讯]` (Independent)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在预训练LLM的残差流中预留16维，训练它们成为二进制可解释控制标志，从而实现对模型生成的可控特征；

**💡 创新点**

创新点在于不先解码模型已有特征再干预，而是直接把可解释标志写入模型，利用容量压力使模型自动迁移特征信息至这些维度并消除冗余，形成真正可读可写的内部特征；

**🔧 技术方法**

采用简单的辅助位置损失（MSE）在双阶段训练中强制残差流中指定维度输出特征标签，随后用线性探针评估特征可恢复性，并在推理时覆盖这些维度实现控制；

**📊 数据集**

训练数据为约100M个合成文本（50k条），每条文本随机标注5个特征（dogs, cats, animals, food, programming）；性能评估使用WikiText‑2验证perplexity；

**📈 对比分析**

与未进行特征“fence”前模型比较，探针准确率下降（平均≈10%），说明特征信息已迁移到标志维度；生成实验表明强制标志能重塑文本主题；perplexity仅在16维时提升0.12，64维时提升1.00，显示可接受范围；

**⚠️ 局限性**

局限性包括仅针对少量特征与维度，早期层特征生成不稳定；模型仍保留部分冗余信息；扩展到更多特征或更大规模会显著损失性能，且对真实多样化数据的泛化尚未验证。

---

## 410. Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training

**arXiv ID:** 2602.07824 | [PDF](https://arxiv.org/pdf/2602.07824v1)

**作者:** Yiwei Qin `[一作]` (Shanghai Jiao Tong University), Pengfei Liu `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 5981 | [OpenAlex ID](https://openalex.org/A5100355025)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出并实现了Data Darwinism数据处理层次框架，对科学文本进行L0–L5的逐级加工，构建了900B令牌的高质量科学语料库

**💡 创新点**

创新性地将模型驱动的生成与认知补全嵌入数据处理体系，形成十层层次化的可度量加工路径，显著缓解科学文本的可学习性缺口

**🔧 技术方法**

采用规则与轻量模型过滤、LLM生成细化（Generative Refinement）以及链式思考推理的Cognitive Completion等技术，辅以知识图检索和多模态预训练

**📊 数据集**

基于PubMed Central、arXiv、S2ORC、学术书籍以及TxT360等公开资源，生成Darwin-Science、Darwin-Science-Raw、Darwin-Science-Eval等数据集

**📈 对比分析**

通过在3B/7B模型上进行600B持续预训练，与基准混合相比，平均提升约2.12/2.95分；在分布对齐评测上提升5.6/8.4分，并且增益随训练持续不衰减

**⚠️ 局限性**

仅实现了L0–L5层级，未探索L6–L9高阶合成；实验仅在Qwen体系、特定规模和单一语料下验证，缺乏跨域、跨架构的普适性；学习难度的客观度量尚待建立

---

## 411. Out of the box age estimation through facial imagery: A Comprehensive Benchmark of Vision-Language Models vs. out-of-the-box Traditional Architectures

**arXiv ID:** 2602.07815 | [PDF](https://arxiv.org/pdf/2602.07815v1)

**作者:** Simiao Ren `[一作]` `[通讯]` (Scam.AI), Simiao Ren (Scam.AI)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了首个跨范式的面部年龄估计基准，比较34种模型在8个公开数据集上的表现。

**💡 创新点**

发现零射击VLM在无任务专门训练的情况下超过大多数专用模型，挑战传统架构优先的假设。

**🔧 技术方法**

采用预训练的VLM（Gemini、GPT‑5、Claude 等）与 22 种公开权重的专用 CNN/ViT 模型进行评估，并使用标准 MAE、阈值误差等指标。

**📊 数据集**

使用 UTKFace、IMDB‑WIKI、MORPH、AFAD、CACD、FG‑NET、APPA‑REAL、AgeDB 八个年龄估计数据集。

**📈 对比分析**

比较方法为统一抽样 100/400 张图像、无监督推理，VLM 平均 MAE 5.65 低于专用模型 9.88；VLM 占前 13 名 12 个；MiVOLO 是唯一靠近 VLM 的专用模型。

**⚠️ 局限性**

局限包括样本量有限、仅使用单一 prompt、未做性别/种族偏差分析、VLM 版本易变、仅评估公开权重模型。

---

## 412. How well are open sourced AI-generated image detection models out-of-the-box: A comprehensive benchmark study

**arXiv ID:** 2602.07814 | [PDF](https://arxiv.org/pdf/2602.07814v1)

**作者:** Simiao Ren `[一作]`, Jiayu Xue `[通讯]` (University of North Carolina)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

对16种AI生成图像检测方法在12个多样数据集上进行零样本评估，比较其在291个生成器上的平均准确率。

**💡 创新点**

首次系统化零样本基准，揭示检测器排名不稳定、训练数据比网络架构更关键，并提供三种失效模式及可操作的部署建议。

**🔧 技术方法**

采用CNN、Transformer、频域特征与集成模型的预训练权重，并使用Spearman相关、Friedman检验和CV等统计手段进行性能对比。

**📊 数据集**

使用12个公开数据集（包括GenImage、AIGCDetectionBench、MNW_fake、Nano-banana等），共计约260万张图像，覆盖291个生成器。

**📈 对比分析**

通过固定阈值0.5和AUC评估，发现最优模型Community-Forensics平均准确率为75%，最差模型为37.5%，性能差距高达37个百分点，排名波动显著。

**⚠️ 局限性**

受限于公开模型可用性、仅图像评估、固定阈值、对新生成器快速更新不足，以及部分数据集与检测器不匹配导致的缺失实验。

---

## 413. Pruning as a Cooperative Game: Surrogate-Assisted Layer Contribution Estimation for Large Language Models

**arXiv ID:** 2602.07804 | [PDF](https://arxiv.org/pdf/2602.07804v1)

**作者:** Xuan Ding `[一作]` (Chinese University of Hong Kong), Yao Zhu `[通讯]` (Zhejiang University)

**通讯引用:** 5694 | [OpenAlex ID](https://openalex.org/A5034221181)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种基于博弈论的层级剪枝框架，利用轻量级代理网络和分层蒙特卡罗采样来估计各层的 Shapley 值，从而动态识别并裁剪对模型性能影响最小的层。

**💡 创新点**

创新点在于将层剪枝视为合作博弈，首次通过代理网络高效逼近 Shapley 值，兼顾层间依赖并显著提升剪枝效果。

**🔧 技术方法**

技术手段包括层级博弈建模、分层蒙特卡罗掩码采样、轻量化代理网络（两层前馈）以及 Shapley 值近似。

**📊 数据集**

实验数据集涵盖 LLaMA2、Vicuna、RWKV、Mamba 等 LLM 以及 WikiText、PTB、C4、Zero‑shot 任务集、ANLI 等。

**📈 对比分析**

与 SliceGPT、SLEB、ShortGPT 等深度/宽度剪枝基线相比，本文方法在 perplexity、zero‑shot 准确率、吞吐量、延迟和显存方面均优于或匹配基线。

**⚠️ 局限性**

局限性包括需在校准数据上训练代理网络，近似精度受样本数量和代理模型容量限制，且对极大规模模型的可扩展性仍待进一步验证。

---

## 414. Spectral Graph Analysis for Predicting QoE Fairness Sensitivity in Wireless Communication Networks

**arXiv ID:** 2602.07855 | [PDF](https://arxiv.org/pdf/2602.07855v1)

**作者:** Xinke Jian `[一作]` (State Key Laboratory of Integrated Services Networks, Xidian University), Wenchi Cheng `[通讯]` (State Key Laboratory of Integrated Services Networks, Xidian University)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

通过谱图理论推导出QoE公平度指数的指数上界，揭示SLA参数与网络连通性共同决定公平度敏感度的阈值与衰减率。

**💡 创新点**

首次给出以网络代数连通度为基准的指数上界与瓶颈驱动设计原则，并提供基于Fiedler向量的结构干预方法与低复杂度的性能上界证明。

**🔧 技术方法**

使用谱图理论（归一化Laplacian、代数连通度、Fiedler向量）、信息理论（熵、KL散度）与随机采样、BFS、Lanczos等算法。

**📊 数据集**

实验数据涵盖随机图模型（ER、WS、BA）与真实网络（CAIDA AS-关系网络），并对极端结构路径图进行对照。

**📈 对比分析**

通过半对数包络图、设计相位图和条形图与理论上界对比，验证指数上界始终满足并揭示指数下降速率由min{a,cλ₂}决定，实验表明在结构受限时增大λ₂可显著降低公平度；在服务受限时提升a同样有效。

**⚠️ 局限性**

局限于无权、静态拓扑、度数比有限、假设路径成本仅由跳数决定，未考虑动态流量与拥塞反馈。

---

## 415. Geometry-Aware Rotary Position Embedding for Consistent Video World Model

**arXiv ID:** 2602.07854 | [PDF](https://arxiv.org/pdf/2602.07854v1)

**作者:** Chendong Xiang `[一作]` (Tsinghua University), Jun Zhu `[通讯]` (Tsinghua University)

**通讯引用:** 67281 | [OpenAlex ID](https://openalex.org/A5115666530)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文提出视角感知的自注意力编码 ViewRope，解决视频生成中视角循环闭合时的几何漂移问题。

**💡 创新点**

创新点在于将每个图像块的光线方向直接注入注意力权重，构造几何关系的相对旋转编码，并配合几何稀疏帧注意力实现长序列视角一致性。

**🔧 技术方法**

采用基于 Transformer 的 Diffusion 模型（DiT）、视角旋转嵌入 ViewRope、几何稀疏帧注意力以及自回归训练/推理，结合 RoPE 等位置编码。

**📊 数据集**

使用公开的 Context-as-Memory、GF-Minecraft 以及作者自建的 ViewBench（10 个 UE5 场景、完整三轴旋转与闭环轨迹）数据集。

**📈 对比分析**

与 3D RoPE、GTA、滑动窗口稀疏注意力等基线相比，ViewRope 在 ViewBench 上的循环闭合误差（LCE）降低约 4–16%，同时保持或提升 PSNR/SSIM，稀疏注意力使训练时间缩短约 25%。

**⚠️ 局限性**

限制在于对剧烈场景切换的鲁棒性不足，仅能在已观测视角内恢复一致性，未来需结合显式 3D 记忆或更大规模的稀疏采样以处理更复杂的动态场景。

---

## 416. SAGE: Scalable AI Governance & Evaluation

**arXiv ID:** 2602.07840 | [PDF](https://arxiv.org/pdf/2602.07840v1)

**作者:** Benjamin Le `[一作]` (LinkedIn), Wenjing Zhang `[通讯]` (LinkedIn)

**通讯引用:** 558 | [OpenAlex ID](https://openalex.org/A5100407200)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在LinkedIn搜索系统中，构建并部署了SAGE框架，通过双向校准（Policy、Precedent、LLM Judge）实现高质量人类判定的可扩展化，随后使用教师-学生蒸馏生成低成本学生Judge，实现离线和在线高吞吐量的相关性评估，并通过该评估推动模型迭代与业务决策，最终提升了0.25%的日活跃用户。

**💡 创新点**

创新点包括：① 双向校准机制，使Policy、Precedent与Judge共同演进；② 多属性可解释相关性评估，将整体相关性拆解为标题、级别等可解释维度；③ 通过教师-学生蒸馏在保证高一致性的同时将LLM成本压至92倍以内；④ 版本化Policy与基准案例的持续迭代，提升治理透明度；⑤ 将学生Judge进一步压缩为在线模型，实现在毫秒级别的实时决策。

**🔧 技术方法**

技术包括：大语言模型（GPT‑3）作为教师Judge；Prompt工程与多维度评分模板；教师-学生蒸馏（全参数微调、LoRA对比）；结构化裁剪、推理内部化、上下文压缩；梯度裁剪与ZeRO‑3分布式训练；A/B测试与指标监控；NDCG、GR@K、PMR@K等多指标评估；版本化Policy与Precedent管理。

**📊 数据集**

数据集主要来源于LinkedIn生产流量：① 约10⁷条日常查询‑文档对，用于学生Judge的离线评估；② 约3.12×10⁵条教师生成的标注样本（覆盖均衡的0–4分）；③ 几百条由产品专家精挑细选的Precedent案例；④ 采样自历史流量的多语言与长尾查询，用于候选模型的离线与在线实验；⑤ 通过实验获得的实验数据与业务指标。

**📈 对比分析**

在与人工评标和教师Judge的对比中，学生Judge在人类标注上的线性加权Cohen’s kappa达0.72–0.73（高于0.7阈值），与教师Judge对齐度约0.81；人工评标与教师Judge一致度分别为0.76/0.77，人工与人工一致度为0.78/0.83，显示学生Judge已逼近教师上限；成本方面，学生Judge相较于教师Judge和人工评标降低了约92×与154×；业务层面，SAGE实现了PMR@10下降≈30%–50%，NDCG@10提升≈7%–8%，Good Recall提升≈10%–16%，最终带来≈0.25%的日活跃用户提升。

**⚠️ 局限性**

局限性包括：① 仍高度依赖人工精心构建的Precedent集，规模受限；② 教师Judge的偏差会直接影响学生Judge的上限；③ 对Policy版本化和解释性要求高，维护成本不低；④ 蒸馏过程中可能丢失某些细粒度推理，尤其是长尾或多义场景；⑤ 在极端稀有查询或新领域，模型仍可能出现不准确；⑥ 仍需人工持续监控与校准，无法完全自动化。

---

## 417. rePIRL: Learn PRM with Inverse RL for LLM Reasoning

**arXiv ID:** 2602.07832 | [PDF](https://arxiv.org/pdf/2602.07832v1)

**作者:** Xian Wu `[一作]` (Meta AI), Wenbo Guo `[通讯]` (University of California)

**通讯引用:** 1992 | [OpenAlex ID](https://openalex.org/A5060462519)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出基于逆强化学习的框架，学习过程奖励模型并用其驱动大语言模型的推理训练。

**💡 创新点**

创新点在于：1）采用最小假设的逆RL方法，省去对专家奖励或策略的访问；2）实现了双向学习，将奖励模型与策略交替更新；3）将多种主流PRM方法归入统一框架，揭示其本质联系。

**🔧 技术方法**

核心技术包括：逆强化学习与最大熵RL、重要采样近似分区函数、RLOO非参数值估计、奖励模型的能量式表征及其对抗训练策略。

**📊 数据集**

实验使用 PRIME Eurus‑2‑RL‑Data 中的专家轨迹，评估七个标准数学与编码基准：AIME‑2024、AMC、Math‑500、Minerva‑Math、Olympiad‑Bench、Leetcode 及 LiveCodeBench。

**📈 对比分析**

与 BC、KTO、PRIME、MCTS、RL‑Tango、RLOO、SFT+RLOO 等基线对比，rePIRL 在 Qwen2.5‑3B 和 Qwen3‑4B 上分别提升约 2–4% 的通过率，达成 3B/4B 规模的 SOTA 性能。

**⚠️ 局限性**

局限性包括：仍需收集专家轨迹作为训练数据；对极长推理过程的奖励分布估计可能不稳；模型规模与计算资源受限，难以直接推广到更大模型或更复杂任务。

---

## 418. Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning

**arXiv ID:** 2602.07830 | [PDF](https://arxiv.org/pdf/2602.07830v1)

**作者:** Jiahui Zhou `[一作]` (Sun Yat-sen University), See-Kiong Ng `[通讯]` (National University of Singapore)

**通讯引用:** 5315 | [OpenAlex ID](https://openalex.org/A5090171111)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `67630363-6be0-4f51-ab05-7198250671a5` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 VeriTime 框架，通过时间序列数据合成、数据调度和强化学习微调，提升 LLM 在时间序列推理任务上的性能。

**💡 创新点**

创新点包括：① TSRgen 合成过程可验证的多步骤 Chain‑of‑Thought 数据集 TSRBench；② 两阶段强化学习微调结合多目标奖励体系；③ 基于难度层级的自适应数据调度策略。

**🔧 技术方法**

使用的技术包括：过程可验证链式推理生成、LLM（Qwen2.5、Qwen3）微调、GRPO 强化学习、结构化奖励与过程奖励设计，以及自适应样本选取。

**📊 数据集**

采用的数据集：TSRBench（涵盖合成与真实时间序列的 7 类任务），以及在 TimeSeriesExam、DROP、CTU ECG、EMG、RCW 等基准上进行评测。

**📈 对比分析**

对比方法与性能：与基准 LLM、时序专用模型及仅 SFT 的 Qwen 系列对比；VeriTime 在场景任务上平均提升 35%+，在知识任务上提升 23–60%，并显著减少推理 token。

**⚠️ 局限性**

局限性：仍需依赖大型预训练 LLM；奖励设计与数据调度需手工设定；对极长序列或高噪声情境的鲁棒性尚未充分验证。

---

## 419. Software Space Analytics: Towards Visualization and Statistics of Internal Software Execution

**arXiv ID:** 2602.07821 | [PDF](https://arxiv.org/pdf/2602.07821v1)

**作者:** Shinobu Saito `[一作]` (NTT), Shinobu Saito `[通讯]` (NTT)

**通讯引用:** 694 | [OpenAlex ID](https://openalex.org/A5110470926)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出一种将软件内部执行日志映射到空间数据集并利用空间统计方法（如Moran’s I）对模块执行频率进行可视化和显著性检验的技术。

**💡 创新点**

创新点在于首次将空间统计（空间自相关、空间聚类）应用于软件执行数据，并通过构造软件空间邻接矩阵来识别热点、冷点及异常模块。

**🔧 技术方法**

使用的技术包括动态日志采集（JavaAgent）、软件空间邻接矩阵构造、Moran's I和局部Moran's I统计量、空间聚类可视化。

**📊 数据集**

数据集为两款企业内实际部署的开源软件Apache OFBiz与Lavagna的两个月执行日志，共计约1,137和256个类，其中约30%被执行。

**📈 对比分析**

与传统的仅基于静态或bug报告的模块定位方法相比，该方法在两套系统中发现约10%的模块存在显著空间自相关，能够识别热点和异常模块，提升了维护决策的可视化和定量依据。

**⚠️ 局限性**

局限性包括仅覆盖被执行的模块（不足30%），邻接矩阵稀疏导致可能低估自相关，以及仅使用执行计数，未考虑执行时长或性能指标。

---

## 420. LLMs Know More About Numbers than They Can Say

**arXiv ID:** 2602.07812 | [PDF](https://arxiv.org/pdf/2602.07812v1)

**作者:** Fengting Yuchi `[一作]` (Shanghai Jiao Tong University), Jason Eisner `[通讯]` (Johns Hopkins University)

**通讯引用:** 7767 | [OpenAlex ID](https://openalex.org/A5052467896)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了大语言模型（LLM）在混合记号（十进制与科学记数法）数值比较任务中的内部表征与口头化表现，探究模型内部数值知识与生成输出的关联。

**💡 创新点**

创新点在于发现LLM内部隐藏层可以通过单线性映射线性编码数值的对数幅值与大小比较，并且在微调时加入探针损失可显著提升模型的口头化比较准确率，证明内部表征的改进能直接影响生成效果。

**🔧 技术方法**

主要技术包括：对隐藏状态进行线性回归和逻辑回归探针以预测数值对数幅值及比较结果；在微调时加入探针的交叉熵损失作为辅助目标；使用对数空间预测和对数比值回归实现更稳健的比较判定。

**📊 数据集**

使用了三类数据集：1）合成交叉记号数据集（包括十进制、科学记数法及混合两种记号的数对）；2）arXiv 公开科学论文文本；3）GPT‑4.1 与 GPT‑4.1‑mini 的对照测试，评估大模型在相同任务下的表现。

**📈 对比分析**

比较方法：通过线性回归得到数值对数幅值，误差在合成集上为 2.3%，在科学论文上为 19.06%；通过逻辑回归分类器得到比较准确率超过 90%；口头化比较准确率仅 50–70%，而在微调后加入探针损失可提升至约 90%+；实验还表明，早期层的探针性能与口头化准确率高度相关。

**⚠️ 局限性**

局限性包括：仅在 7B–8B 开放权重模型上进行探针实验，无法验证更大模型的表征；仅使用线性探针，可能无法捕捉更复杂的非线性关系；合成数据与真实科学文本存在差距；未考虑单位、上下文和语义对数值比较的影响；未进行推理时间上的直接干预以验证表征对生成的即时影响。

---

## 421. Approximating Matrix Functions with Deep Neural Networks and Transformers

**arXiv ID:** 2602.07800 | [PDF](https://arxiv.org/pdf/2602.07800v1)

**作者:** Rahul Padmanabhan `[一作]` (Concordia University), Simone Brugiapaglia `[通讯]` (Concordia University)

**通讯引用:** 473 | [OpenAlex ID](https://openalex.org/A5001768471)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究使用深度神经网络（特别是Transformer编码器-解码器）近似矩阵函数（指数、对数、符号、正弦、余弦），并给出ReLU网络逼近矩阵指数的理论宽度/深度上界。

**💡 创新点**

①提出了针对矩阵指数的ReLU网络宽度指数、深度线性（log因子）的存在性定理；②首次展示Transformer编码器-解码器在合适数值编码下能在3×3矩阵上以高相对误差（≤5%）逼近矩阵符号函数，显著优于传统浅/深全连接网络。

**🔧 技术方法**

采用Transformer编码器-解码器架构，并尝试多种数值编码（P10、P1000、FP15、B1999）；使用ReLU全连接网络作为基线；评估指标为容差基准准确率。

**📊 数据集**

数据集为从[-5,5]正态分布采样的随机实矩阵，维度覆盖3×3到5×5（训练样本量2^5–2^18），并按此生成测试集。

**📈 对比分析**

与3层浅网络、7层深网络以及仅编码器Transformer进行对比。Transformer编码器-解码器在3×3矩阵上对符号函数实现88.41%（容差0.01）精度，P10在对数函数上达到74.96%（容差0.01），B1999在指数函数上获得99.58%（容差0.05），这些结果远优于基线模型；然而对正弦/余弦函数无显著逼近效果。

**⚠️ 局限性**

①模型仅在极小矩阵（≤5）上验证，无法推广到更大尺寸；②正弦/余弦函数失效，原因未知；③理论分析仅限ReLU网络，对Transformer缺乏正式证明；④结果高度依赖数值编码，缺乏通用选择原则。

---

## 422. CausalTAD: Injecting Causal Knowledge into Large Language Models for Tabular Anomaly Detection

**arXiv ID:** 2602.07798 | [PDF](https://arxiv.org/pdf/2602.07798v1)

**作者:** Ruiqi Wang `[一作]` (Hunan University), Changjian Chen `[通讯]` (Hunan University)

**通讯引用:** 1062 | [OpenAlex ID](https://openalex.org/A5019821536)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

该研究提出CausalTAD方法，将因果知识注入大型语言模型，用因果驱动的列排序和列加权提升表格异常检测性能。

**💡 创新点**

创新点在于先通过因果发现获得高层因子并投影到列级，随后把列排序问题建模为线性排序问题并枚举近似最优排列，同时引入基于因子计数的列加权，兼顾因果结构与异常评分。

**🔧 技术方法**

采用COAT因果发现、PC/LiNGAM/FCI生成因果图、整数规划/枚举求解线性排序、SmolLM等LLM微调与自回归语言建模以及因子计数加权方案。

**📊 数据集**

在6个混合类型（含文本）数据集（Fake job posts、Fraud e-commerce、Lymphography、Seismic、Vehicle insurance、20 newsgroup）以及30个纯数值数据集上进行评估。

**📈 对比分析**

与经典方法、深度学习方法及AnoLLM等基线对比，CausalTAD在6个混合类型数据集上平均AUC‑ROC分别为0.834/0.833，均优于AnoLLM及所有基线；在30个数值数据集上亦保持领先。

**⚠️ 局限性**

主要局限在于需依赖LLM进行因子提取与注释、因果发现与多次列排序导致额外计算成本，并且对因果图质量和列数规模敏感。

---

## 423. Dynamic Load Model for Data Centers with Pattern-Consistent Calibration

**arXiv ID:** 2602.07859 | [PDF](https://arxiv.org/pdf/2602.07859v1)

**作者:** Siyu Lu `[一作]` (Arizona State University), Yang Weng `[通讯]` (Arizona State University)

**通讯引用:** 3934 | [OpenAlex ID](https://openalex.org/A5021106309)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `9ce7179e-700c-4310-ac2b-91df50ded46e` `a8e75ba4-7a2d-4153-b003-06c94533add0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了基于物理结构且可通过局部校准实现的动态大电子负荷（LEL）负荷模型，并通过模式一致校准提升模拟真实性。

**💡 创新点**

创新点在于将物理模型与时序对比学习结合，利用Temporal Contrastive Learning实现仅参数校准即可匹配负荷统计与时序模式；并通过局部校准保持数据隐私。

**🔧 技术方法**

主要技术包括物理可参数化负荷建模（工作负载为OU过程，冷却为WECC CMPLDW，保护恢复为规则化模型）与无监督时序对比学习；以及在ANDES平台上的系统级瞬态仿真。

**📊 数据集**

使用了MIT Supercloud、ASU Sol、Blue Waters三大数据中心工作负载数据，以及ASHRAE的冷却和辅助负荷概况，验证了模型在不同规模电网（IEEE39、NPCC140、WECC179）上的表现。

**📈 对比分析**

将校准模型与HMM、RNN、未校准物理模型以及传统ZIP负荷进行比较，通过DTW距离、最大相关系数和余弦相似度评价，校准模型在工作负载、冷却和辅助负荷上均取得最低DTW、最高相关/相似度，并在系统级仿真中显著降低电压低点、频率峰值和恢复延迟。

**⚠️ 局限性**

局限在于校准依赖于足够长的工作负载记录，对罕见保护事件的数据缺失仍需规则化估计；且对不同网络规模的鲁棒性虽已验证，但在极大规模或分布式能源集成情形下可能需要进一步验证。

---

## 424. Deep learning based Channel Estimation and Beamforming in Movable Antenna Systems

**arXiv ID:** 2602.07870 | [PDF](https://arxiv.org/pdf/2602.07870v1)

**作者:** Kaijun Feng `[一作]`, Rui Zhang `[通讯]`

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

未提供论文内容，无法概括

**💡 创新点**

未知

**🔧 技术方法**

未知

**📊 数据集**

未知

**📈 对比分析**

未知

**⚠️ 局限性**

未知

---

## 425. LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge

**arXiv ID:** 2602.07849 | [PDF](https://arxiv.org/pdf/2602.07849v1)

**作者:** Xin Wang `[一作]` (University of Melbourne), Tao Gu `[通讯]` (Macquarie University)

**通讯引用:** 10221 | [OpenAlex ID](https://openalex.org/A5054698524)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种轻量化量化自适应框架LQA，用于将Vision‑Language模型（如CLIP）部署在资源受限的边缘设备上，并实现分布漂移下的在线自适应。

**💡 创新点**

创新点包括：
• 采用模态感知的Selective Hybrid Quantization（SHQ）—视觉通道量化为4位、文本通道为8位，且只对任务相关层量化，保留关键跨模态层。
• 设计了全无梯度的量化测试时适应（Q‑TTA）与缓存机制，完全在INT8/INT4运算下完成在线自适应，避免反向传播和高精度占用。
• 将量化与自适应机制统一为低位整数，避免昂贵的去量化操作，显著降低能耗和延迟。

**🔧 技术方法**

技术手段：
• Hessian‑aware 与对称均匀量化；
• Selective Hybrid Quantization（视觉4位+文本8位）；
• 低位整数缓存自适应（Q‑TTA）；
• CLIP 视觉/文本编码器作为基线。

**📊 数据集**

实验数据集：
• CIFAR‑10C / CIFAR‑100C（15种人工畸变）
• Caltech‑101、Oxford‑Pets、DTD、UCF‑101、ImageNet‑A（对抗图像）

**📈 对比分析**

与基线对比：
• 在7个数据集上，LQA平均准确率 65.56%，仅比TDA高 0.59%；
• 内存占用相比全精度 CLIP+TDA 减少约 19.9×，与 EATA 低 14.1×；
• 延迟低至 26 ms（LQA）/ 15 ms（LQA‑Lite），比 EATA 快 3.4×；
• 与其他量化方案（HQQ、BnB、Quanto）相比，LQA 在 4‑位/8‑位下保持最高或相近的准确率，并显著降低内存与延迟。

**⚠️ 局限性**

局限性：
• 低位量化仍可能在极端噪声或分布漂移强度大时导致精度衰减；
• 目前仅验证了 CLIP 等中等规模模型，尚未在更大 VLM 或 LLM 上验证可扩展性；
• 对硬件细节（如特定 SoC 的 INT4 支持）依赖性较高，实际部署需针对目标平台进一步优化；
• 缓存大小与阈值需手工调参，适配不同场景仍需经验。

---

## 426. SimGR: Escaping the Pitfalls of Generative Decoding in LLM-based Recommendation

**arXiv ID:** 2602.07847 | [PDF](https://arxiv.org/pdf/2602.07847v1)

**作者:** Yuanbo Zhao `[一作]` (Central South University), Chengqi Zhang `[通讯]` (Hong Kong Polytechnic University)

**通讯引用:** 26801 | [OpenAlex ID](https://openalex.org/A5100438525)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了SimGR框架，利用LLM在共享潜在空间直接建模用户-物品分布，完全避免了传统基于语义ID序列的生成过程。

**💡 创新点**

通过理论与实验证明自回归与并行生成导致的物品级分布偏差，创新性地提出无需token级生成即可获得完整无偏物品分布的推荐模型。

**🔧 技术方法**

使用大型语言模型（如Qwen3-4B、GPT-2）作为统一编码器，结合RQ‑VAE得到语义ID、相似度匹配与交叉熵训练，完成对比自回归/并行生成及传统推荐模型的实验。

**📊 数据集**

采用Amazon Review 2018的三个子集（Musical Instruments、Arts, Crafts and Sewing、Video Games）以及 Instruments、Arts、Games 三个数据集进行评测。

**📈 对比分析**

在HR@K、NDCG@K等指标上与传统非生成模型（Caser、HGN等）和语义ID生成模型（TIGER、LC‑Rec、RPG）对比，SimGR在所有数据集上均实现最高NDCG与HR，且覆盖率与Entropy@K多样性均优于基线。

**⚠️ 局限性**

仍受限于LLM的预训练语义表示和大模型推理开销，对极度稀疏或实时离线场景的效率和资源需求待进一步优化，且聚合方式对少数稀有物品的表达可能不足。

---

## 427. Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning

**arXiv ID:** 2602.07845 | [PDF](https://arxiv.org/pdf/2602.07845v1)

**作者:** Yalcin Tur `[一作]` (Stanford University), Ranjay Krishna `[通讯]` (University of Washington)

**通讯引用:** 12828 | [OpenAlex ID](https://openalex.org/A5032451496)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种在潜在空间中递归迭代推理的Vision–Language–Action模型，支持在推理时动态分配计算量。

**💡 创新点**

将推理从离散输出空间迁移到连续潜在空间，实现可变深度、低内存、无标注推理链；采用权重共享的递归Transformer实现任意推理层数。

**🔧 技术方法**

基于Qwen2.5‑0.5B VLM+LoRA架构，使用截断反向传播、噪声初始化、输入注入以及KL/阈值自适应终止等技术。

**📊 数据集**

在LIBERO与CALVIN仿真基准，以及YAM双臂机器人在真实厨房任务上进行训练与评估。

**📈 对比分析**

与E2E、token‑reasoning以及其他Latent Reasoning方法对比，RD‑VLA在LIBERO上实现93%成功率，CALVIN平均链长3.39，速度提升至80×，在真实任务中保持或超过Diffusion Policy和π0.5。

**⚠️ 局限性**

递归深度存在饱和点，过深会导致性能下降；模型规模仍较小，需进一步扩展以验证更大基底；缺乏系统的安全与异常检测机制。

---

## 428. TodoEvolve: Learning to Architect Agent Planning Systems

**arXiv ID:** 2602.07839 | [PDF](https://arxiv.org/pdf/2602.07839v1)

**作者:** Jiaxi Liu `[一作]` (TodoRL Team), Junchi Yan `[通讯]` (TodoRL Team)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种基于IGPO的元规划框架，能够在执行过程中自动生成并动态调整任务特定的规划结构。

**💡 创新点**

创新点在于将规划架构视为可学习的模块化空间，并通过阻抗引导的偏好优化实现对规划效率和稳定性的联合优化。

**🔧 技术方法**

采用了模块化规划设计空间、IGPO（Impedance‑Guided Preference Optimization）技术、LLM‑as‑Judge评估器以及强化学习式的偏好对齐。

**📊 数据集**

利用WebWalkerQA、xBench‑DS、TaskCraft、GAIA、DeepSearchQA等多域数据集构建训练和测试数据。

**📈 对比分析**

在多大规模基准上，与Smolagents、Flash‑Searcher、AgentKB等主流框架比较，提升了高达16.37%（GAIA）或70.91%（DeepSeek V3.2版 GAIA）等显著性能，且保持了相近甚至更低的计算成本。

**⚠️ 局限性**

局限在于仍需依赖大量验证数据，元规划器对极端异构任务的泛化尚未完全验证，且在极大任务规模下的实时更新开销尚待进一步优化。

---

## 429. Direct Soft-Policy Sampling via Langevin Dynamics

**arXiv ID:** 2602.07873 | [PDF](https://arxiv.org/pdf/2602.07873v1)

**作者:** Donghyeon Ki `[一作]` (Korea University), Byung-Jun Lee `[通讯]` (Gauss Labs Inc)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

通过Langevin动力学直接从Q函数梯度采样动作，实现无演员（actor-free）的软策略学习，并引入多尺度噪声对Q函数进行条件化以加速混合，提出了NC-LQL。

**💡 创新点**

创新点在于把软策略的score函数与Langevin采样直接对应，省去显式策略网络和熵估计；通过噪声条件化Q函数实现多尺度平滑采样，解决了传统Langevin在高维非凸价值地形中的慢混合问题。

**🔧 技术方法**

主要技术包括：Langevin动力学采样、噪声条件化Q网络、TD学习、Annealed Langevin Dynamics、经验回放、参数共享的单一Q网络。

**📊 数据集**

实验数据集为OpenAI Gym MuJoCo 控制任务（HalfCheetah、Walker2d、Ant、Hopper 等）以及 2D 带子（bandit）环境。

**📈 对比分析**

与 SAC、QSM、DIPO、QVPO、DACER、MFP、SDAC、DPMD 等基线相比，NC‑LQL 在 MuJoCo 任务上获得了与最先进扩散式方法相当甚至更优的累计奖励，并且在参数量、训练时间和单步采样上更为高效。

**⚠️ 局限性**

主要局限是温度参数 w 需要手动调节，缺乏自适应机制；此外对极端高维或高度多模态环境的泛化尚待验证。

---

## 430. WristMIR: Coarse-to-Fine Region-Aware Retrieval of Pediatric Wrist Radiographs with Radiology Report-Driven Learning

**arXiv ID:** 2602.07872 | [PDF](https://arxiv.org/pdf/2602.07872v1)

**作者:** Mert Sonmezer `[一作]` (Middle East Technical University), Sila Kurugol `[通讯]` (Boston Children’s Hospital)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `e0540dec-d77f-42db-94ae-d039248f6393` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一种名为WristMIR的双阶段区域感知手腕X光图像检索框架，利用结构化报告和骨骼级图像片段实现精细的临床相似案例检索；

**💡 创新点**

创新点在于：①通过医学VLM MedGemma-27B自动将自由文本报告转化为解剖学层面的结构化说明，并生成全局与骨骼级别的描述；②使用YOLOv11对手腕及三块关键骨骼（远端桡骨、远端尺骨、尺侧耙骨）进行精确定位；③在CLIP框架中采用多正样本对比损失，将相同说明的样本视为正例，提升对细微骨折特征的学习；④采用两阶段检索（全局先筛选，再骨骼级别再排序），显著提高诊断相关性；

**🔧 技术方法**

主要技术包括：医学视觉语言模型 MedGemma-27B、YOLOv11骨骼检测器、BiomedCLIP 视觉–文本双编码器、CLIP式多正样本对比损失、区域感知两阶段检索流程；

**📊 数据集**

数据集为7540例后前视（PA）儿科手腕X光图像及其报告，经过自动化处理后得到全局与骨骼级别的图像-文本对，用于训练；评估集包含876例图像；

**📈 对比分析**

与BiomedCLIP、PMC‑CLIP、MedCLIP以及仅做全局微调的基线模型对比，WristMIR在Recall@5从0.82提升至9.35，AUROC达到0.949、AUPRC 0.953，区域级检索的F1从0.568提升至0.753，放射科医生主观评价也显著提高；

**⚠️ 局限性**

局限性包括：①仅使用PA视图，无法处理侧面/斜视图导致的解剖重叠；②数据规模相对有限，缺乏多中心、多年龄段样本；③对报告自动化抽取的准确性依赖 MedGemma，存在轻微错误；④检索性能总体仍低，因手腕影像差异极其细微，尚需进一步改进模型泛化与鲁棒性。

---

## 431. DHEA-MECD: An Embodied Intelligence-Powered DRL Algorithm for AUV Tracking in Underwater Environments with High-Dimensional Features

**arXiv ID:** 2602.07947 | [PDF](https://arxiv.org/pdf/2602.07947v1)

**作者:** Kai Tian `[一作]` (Northeastern University), Zhenyu Wang `[通讯]` (Northeastern University)

**通讯引用:** 1603 | [OpenAlex ID](https://openalex.org/A5100389534)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `aaccfe5c-6b26-4208-b23c-35331481e142` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出一种基于双头编码-注意力和多专家协同决策的DHEA‑MECD算法，用于在高维海洋环境下的AUV多目标跟踪。

**💡 创新点**

创新点包括：①层次化的身体智能架构，将感知、决策、执行分离；②双头编码-注意力框架实现语义分解与跨模态依赖建模；③运动阶段感知的Top‑k专家选择机制，显著降低参数干扰并提升决策精度。

**🔧 技术方法**

主要技术：深度强化学习（Actor‑Critic、TD‑学习）、多头自注意力（Transformer）、多专家协同网络、稀疏Softmax选择、优先经验回放（PER）以及GRU‑MLP混合网络。

**📊 数据集**

使用仿真生成的高维状态（9、18、27、36维）数据集；环境由三维连续空间中的AUV和目标粒子构成，无公开真实数据集。

**📈 对比分析**

与PPO、PDQN、SAC、DDPG、TRPO、AC、DQN等主流DRL方法在同一仿真平台上对比，DHEA‑MECD在收敛速度、轨迹长度、跟踪成功率、碰撞率等指标上均优于对手，尤其在维度升高时优势更明显。

**⚠️ 局限性**

局限性：仅在仿真环境验证，存在sim‑to‑real迁移挑战；目前仅针对单个AUV，未处理多AUV协同；模型复杂度相对较高，计算资源消耗在大规模真实场景中尚待评估。

---

## 432. Which private attributes do VLMs agree on and predict well?

**arXiv ID:** 2602.07931 | [PDF](https://arxiv.org/pdf/2602.07931v1)

**作者:** Olena Hrynenko `[一作]`, Andrea Cavallaro `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文对开源视觉语言模型（VLM）在VISPR数据集上进行零样本隐私属性识别的系统评估，并与人工标注进行对比，揭示模型在某些属性上的高一致性与误判情况。

**💡 创新点**

创新点在于：①对所有67个隐私属性进行零样本评估；②通过Fleiss κ统计挑选高一致性属性；③对模型与人工标注的差异进行细粒度分析，并验证模型能发现人工遗漏的属性。

**🔧 技术方法**

使用了三种开源指令跟随VLM（Gemma‑3‑4b‑it、Qwen2.5‑VL‑7B‑Instruct、Llama‑3.2‑11B‑Vision‑Instruct），并通过两步解码与正则解析来获取二分类答案。

**📊 数据集**

数据集为VISPR公开的测试集（约8000张图），包含67个隐私属性，采用原始标注指令作为提示。

**📈 对比分析**

评估方法包括精度、召回、平衡准确率和F1‑macro；结果显示Qwen2.5‑VL‑7B‑Instruct在大多数属性上达到0.6以上的F1‑macro，整体准确率>0.75；相比之下Gemma‑3‑4b‑it和Llama‑3.2‑11B‑Vision‑Instruct表现较弱。

**⚠️ 局限性**

局限性包括：①模型在“Present”类的精度偏低，易误判；②对人类标注错误的敏感导致误判；③模型对非人类主体（雕像、动物等）会产生不恰当的属性判断；④仅评估零样本情形，缺乏微调或多模态融合的进一步验证。

---

## 433. Patches of Nonlinearity: Instruction Vectors in Large Language Models

**arXiv ID:** 2602.07930 | [PDF](https://arxiv.org/pdf/2602.07930v1)

**作者:** Irina Bigoulaeva `[一作]` (Technical University of Darmstadt), Iryna Gurevych `[通讯]` (Technical University of Darmstadt)

**通讯引用:** 25401 | [OpenAlex ID](https://openalex.org/A5027450194)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过因果调解和激活补丁，探究LLM在指令微调后如何内部构造并利用指令表示，揭示指令向量（IV）的形成、几何与因果特性，并提出无线性假设的局部线性信息流追踪方法。

**💡 创新点**

创新点在于发现指令向量是局部化、线性可分但因果上超加的“指令摘要”，并首次用非加性局部线性替代器解析Transformer内部指令路径，表明IV充当电路选择器。

**🔧 技术方法**

采用因果调解、激活补丁、局部线性替代映射重写Transformer层，并进行路径贡献与注意头活跃度分析。

**📊 数据集**

使用OLMo-2-1B/7B模型，实验任务包括对比式形容词比较/反义词、动物颜色/能否飞，以及BigBench四个任务（metaphor_boolean、implicatures、object_counting、snarks）。

**📈 对比分析**

通过递归排名提升和对数it等度量比较不同层补丁组合的因果效应，发现两层组合的提升显著大于单层；线性探针对IV的任务聚类预测准确率超过98%，显示IV在任务区分上的强大效果。

**⚠️ 局限性**

实验仅在1B模型上完成，内存限制导致未能在更大模型或更多任务上验证结果，且未探讨指令相似性度量对结论的影响。

---

## 434. Multi-Agent Route Planning as a QUBO Problem

**arXiv ID:** 2602.07913 | [PDF](https://arxiv.org/pdf/2602.07913v1)

**作者:** Renáta Rusnáková `[一作]` (Technical University of Košice), Juraj Gazda `[通讯]` (Technical University of Košice)

**通讯引用:** 987 | [OpenAlex ID](https://openalex.org/A5017059038)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `5b4c1114-4a70-478e-9921-2514ee03850d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文将多车路网覆盖规划建模为选择预设路线的二进制优化问题，并提出其QUBO表示；

**💡 创新点**

创新点在于给出MaRP的NP‑难性证明、将覆盖奖励与重叠惩罚映射到可解释的线性与二次系数、引入软硬惩罚参数区分多目标探索与近无重叠解，并对量子混合求解器进行实验评估；

**🔧 技术方法**

使用的技术包括二次无约束二进制优化（QUBO）建模、Gurobi精确求解、经典模拟退火和D‑Wave混合量子退火；

**📊 数据集**

实验数据来自OpenStreetMap巴塞罗那市道路网络，使用Valhalla路由生成的车辆路线，规模覆盖从100到10,000辆车；

**📈 对比分析**

通过比较三种求解器的运行时间与目标值，发现混合量子退火与Gurobi在大规模实例上实现与最优值相近、运行时间稳定，而模拟退火在规模增大时性能显著下降；

**⚠️ 局限性**

局限在于模型假设每辆车仅有一条固定路线，重叠以节点级别近似拥堵，未考虑时间窗、交通信号或道路容量等实际交通约束。

---

## 435. Incremental Mapping with Measurement Synchronization & Compression

**arXiv ID:** 2602.07901 | [PDF](https://arxiv.org/pdf/2602.07901v1)

**作者:** Mark Griguletskii `[一作]` (Skolkovo Institute of Science and Technology), Pavel Osinenko `[通讯]` (Skolkovo Institute of Science and Technology)

**通讯引用:** 388 | [OpenAlex ID](https://openalex.org/A5065280230)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出一种增量式因子图构造方法，通过对相邻测量进行聚类并评估不同图拓扑，解决了异步多传感器测量导致的图不连通问题，实现了全数据的融合并保持地图质量。

**💡 创新点**

创新点在于生成多种子优因子图并基于外部评价指标（如互相正交指标）选取最优拓扑，既保证图连通，又实现约 30% 的图压缩。

**🔧 技术方法**

使用因子图、IMU 预积分、连续时间轨迹插值、图压缩（变量消除 + KLD 近似）以及互相正交（MOM）评价指标。

**📊 数据集**

在 KAIST Urban 城市数据集（含 GPS、双 LiDAR、IMU）上进行实验。

**📈 对比分析**

与基线（不聚类的完整因子图）以及最小时间移位、最小求解误差四种方案对比，实验表明在保持定位误差（RPE）相近的前提下，图压缩率约 16–41%，平均压缩约 30%。

**⚠️ 局限性**

主要限制是评估指标仍基于静态几何，无法完全覆盖旋转误差；聚类导致的误差在高速运动下可能显著，且生成多图组合的计算量较大，需要进一步用学习方法降低复杂度。

---

## 436. Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents

**arXiv ID:** 2602.07900 | [PDF](https://arxiv.org/pdf/2602.07900v1)

**作者:** Zhi Chen `[一作]` (Singapore Management University), Lingxiao Jiang `[通讯]` (Singapore Management University)

**通讯引用:** 5404 | [OpenAlex ID](https://openalex.org/A5083048049)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在无测试强制的高自治软件问题解决环境中，系统分析了LLM代码代理自动生成测试的行为、时机、反馈内容，并评估其对任务完成的影响。

**💡 创新点**

首次在真实 GitHub 问题的动态轨迹上量化代理生成测试的频率、时机和断言类型，并通过提示干预实验揭示测试写作对成功率的因果关系。

**🔧 技术方法**

采用 SWE‑bench Verified 基准、mini‑SWE‑agent 轻量化框架、AST 解析与断言分类，以及 Prompt 变更实验等技术手段。

**📊 数据集**

使用 SWE‑bench Verified 共 500 条 GitHub issue 轨迹作为数据集，涵盖多语言和多工具环境。

**📈 对比分析**

通过对比不同 LLM 模型在原始与提示干预下的解决率、API 调用次数与令牌消耗，发现测试写作对成功率影响有限，但可显著改变资源开销。

**⚠️ 局限性**

研究仅在轻量化脚本工具环境下进行，未考虑 CI 管道、多语言差异或未来更强模型的表现，结果可推广性有限。

---

## 437. Scalable Adaptation of 3D Geometric Foundation Models via Weak Supervision from Internet Video

**arXiv ID:** 2602.07891 | [PDF](https://arxiv.org/pdf/2602.07891v1)

**作者:** Zihui Gao `[一作]` (Zhejiang University), Chunhua Shen `[通讯]` (Zhejiang University of Technology)

**通讯引用:** 68665 | [OpenAlex ID](https://openalex.org/A5006294869)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `5b4c1114-4a70-478e-9921-2514ee03850d` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

SAGE框架通过利用互联网视频的时空一致性，实施弱监督以适配并提升现有的3D几何基础模型的性能。

**💡 创新点**

创新之处在于构建分层的弱监督管线，结合稀疏几何锚点、密集可微一致性损失以及轻量级正则化，既保证结构偏置又降低方差，实现在海量视频上的可扩展训练。

**🔧 技术方法**

采用的核心技术包括基于SfM点云的稀疏锚点约束、3D高斯渲染的密集一致性损失、随机时间扰动的视频轨迹采样，以及对原始模型进行正则化以防灾难性遗忘。

**📊 数据集**

训练数据主要来自RealEstate10K和DL3DV两大互联网视频数据集，评估数据则使用ScanNet、7Scenes、TUM‑RGBD、Matterport3D及UASOL等公开基准。

**📈 对比分析**

与MV‑DUSt3R、Spann3R、VGGT等最先进方法相比，SAGE在零射击场景的Chamfer距离降低20–42%，距离精度提升，且在多视角输入下保持更高的重建质量。

**⚠️ 局限性**

局限性包括仅针对静态场景的视频进行适配，无法充分利用动态内容，且对剧烈运动或非静止物体的适配效果受限。

---

## 438. Rethinking Latency Denial-of-Service: Attacking the LLM Serving Framework, Not the Model

**arXiv ID:** 2602.07878 | [PDF](https://arxiv.org/pdf/2602.07878v1)

**作者:** Tianyi Wang `[一作]` (Zhejiang University), Cong Wang `[通讯]` (Zhejiang University)

**通讯引用:** 25464 | [OpenAlex ID](https://openalex.org/A5100390514)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究并验证在现代LLM服务框架（如vLLM）中，传统模型层延迟攻击在连续批处理下效果有限，提出新的系统层攻击方法——Fill and Squeeze（F&S），通过填满全局KV缓存并诱发调度器预占循环来实现对同机用户的延迟破坏。

**💡 创新点**

创新点包括：① 把攻击目标从模型生成过程转向调度器状态，利用调度器的HOL阻塞和预占机制；② 设计双阶段（Fill+Squeeze）攻击，并使用分层提示（高/中/低强度）实现低成本高效；③ 通过ITL侧通道估计全局KV占用，形成闭环控制，实现在黑盒环境下的精准注入。

**🔧 技术方法**

使用技术：侧通道测量（Inter‑Token Latency）、LightGBM回归预测KV占用、分层提示工程、闭环控制调度策略、vLLM连续批处理、PagedAttention内存管理，以及对多GPU张量并行的评估。

**📊 数据集**

数据集与模型：Alpaca、ShareGPT、BurstGPT真实流量；LLM模型包括Qwen3‑8B、Gemma3‑12B‑it、DeepSeek‑R1‑Distill‑Llama‑8B；同时对多GPU环境（8×NVIDIA L40S）进行测试。

**📈 对比分析**

对比方法：与Engorgio、LoopLLM、ExtendAttack等传统模型层延迟攻击在同一服务器上进行 TTFT、TPOT、P99 等指标评估；实验结果显示 F&S 在成本约 30‑40% 下降的前提下，TTFT 平均提升 20‑280 倍，TPOT 平均提升 1.5‑4 倍，且预占次数显著增加，显示系统层攻击更具破坏性。

**⚠️ 局限性**

limitations：① 侧通道估计依赖于系统的内存带宽敏感性，若系统使用不同内存架构或调度策略可能失效；② 在极高并发或多GPU高利用率环境下，过度预留内存可缓解攻击效果；③ 需要针对特定服务框架实现（如vLLM）才能发挥最大效果，对其他框架的通用性尚待验证；④ 防御方面仍需研究更公平的调度与动态长度限制，以兼顾性能与安全。

---

## 439. A quantum-inspired multi-level tensor-train monolithic space-time method for nonlinear PDEs

**arXiv ID:** 2602.07945 | [PDF](https://arxiv.org/pdf/2602.07945v1)

**作者:** N. R. Rapaka `[一作]` (Khalifa University of Science and Technology), M. K. Riahi `[通讯]` (Khalifa University of Science and Technology)

**通讯引用:** 554 | [OpenAlex ID](https://openalex.org/A5006001056)

**关键词:** `eda14718-2b67-4c6c-a1d0-312bdc4fbf1e` `a8e75ba4-7a2d-4153-b003-06c94533add0` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

开发了一种多层张量轨道（TT）框架，用于全局时空求解非线性偏微分方程，并通过多级初始化提升Newton收敛。

**💡 创新点**

将多级粗细网格策略嵌入TT表示，提供稳健的初值并结合Tikhonov正则化，解决单层TT在激波、超声波等非线性强问题中的收敛困难。

**🔧 技术方法**

利用TT/量子化TT（QTT）压缩、两点DMRG求解线性子问题、Tikhonov正则化、双线性/Crank‑Nicolson时间离散以及多级网格线性插值。

**📊 数据集**

在1维经典非线性PDE（Fisher–KPP、黏性布格斯、正弦‑戈登、KdV）上进行数值实验，没有使用公开数据集。

**📈 对比分析**

与传统逐步时间步进（CT）和单层TT（SL）进行误差、迭代次数、壁时比较；多层TT在误差几乎相同的前提下，Newton迭代次数显著下降，壁时呈对数线性增长，优于指数增长的CT。

**⚠️ 局限性**

仅在一维空间验证；高维问题仍需进一步评估TT秩增长；正则化参数需经验选择；在极细网格下局部系统仍易失真。

---

## 440. MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learnin

**arXiv ID:** 2602.07940 | [PDF](https://arxiv.org/pdf/2602.07940v1)

**作者:** Guanglong Sun `[一作]`, Yi Zhong `[通讯]` (Tsinghua University)

**通讯引用:** 305357 | [OpenAlex ID](https://openalex.org/A5100362465)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

通过对预训练模型进行元后精炼（Meta Post‑Refinement），实现了对一段无回放的通用持续学习（GCL）任务的快速适配。

**💡 创新点**

创新点在于：① 用伪任务序列进行二级元学习，直接精炼整个backbone 以提升适应性；② 引入元协方差矩阵，对输出层进行第二阶统计对齐，从而在模糊任务边界下保持稳定性。

**🔧 技术方法**

核心技术包括元学习（MAML/REPTILE 框架）、伪任务序列采样、Cholesky 分解的协方差对齐、以及融合预训练与微调特征的加权组合。

**📊 数据集**

在 CIFAR‑100、ImageNet‑R 与 CUB‑200 三个数据集上，结合 Sup‑21K、Sup‑21/1K 与 iBOT‑21K 三种预训练模型进行评估。

**📈 对比分析**

与 MISA、MVP、L2P 等主流 PTM‑based CL/GCL 方法对比，MePo 在 Sup‑21/1K 上分别提升了 15.10%、13.36% 与 12.56% 的 A_AUC，并在各数据集上保持显著优势。

**⚠️ 局限性**

局限性包括：① 需要额外的伪任务生成与元学习阶段，增加预训练成本；② 对预训练数据的依赖较强，分布差异极大时可能效果受限；③ 仅针对无回放的 GCL 场景，未解决可能的持续学习冲突问题。

---

## 441. Multipacking on graphs and Euclidean metric space

**arXiv ID:** 2602.07927 | [PDF](https://arxiv.org/pdf/2602.07927v1)

**作者:** Sk Samim Islam `[一作]` (Indian Statistical Institute), Sk Samim Islam `[通讯]` (Indian Statistical Institute)

**通讯引用:** 4 | [OpenAlex ID](https://openalex.org/A5038722857)

**关键词:** `dd4bd30e-3d3d-4e53-a403-da542c6c036a` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

论文探讨了图论和几何中的算法，特别是广播支配和多打包数在和弦图及其他超曲率图上的关系。

**💡 创新点**

创新点在于提出了多打包在欧几里得度量空间中的应用，并分析了其在不同类型图上的影响。

**🔧 技术方法**

使用了图论算法和几何理论的相关技术。

**📊 数据集**

使用了和弦图、仙人掌图及欧几里得空间等数据集进行实验和分析。

**📈 对比分析**

通过与现有方法的比较，展示了所提方法在特定图类上的性能优势，具体性能指标未详细列出。

**⚠️ 局限性**

限制在于对复杂度的分析尚未完全，且可能在更广泛的图类中需要进一步验证。

---

## 442. Definability and Interpolation in Philosophy

**arXiv ID:** 2602.07907 | [PDF](https://arxiv.org/pdf/2602.07907v1)

**作者:** Johan van Benthem `[一作]` (University of Amsterdam), Johan van Benthem `[通讯]` (University of Amsterdam)

**通讯引用:** 11140 | [OpenAlex ID](https://openalex.org/A5083214023)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

综述了Beth定义定理与Craig插值定理在哲学、逻辑、科学理论等领域的应用与意义，阐释它们与超越性、决定论、问题论、信息流等哲学概念之间的对应关系；

**💡 创新点**

提出将这两个逻辑元理论与哲学概念对照的跨学科视角，探讨它们在不同语境下的共性与差异，并构建了一种理论桥梁；

**🔧 技术方法**

采用抽象模型论、同构与潜在同构、保留定理、依赖逻辑、语义学等传统逻辑与哲学工具进行分析与推导；

**📊 数据集**

本文并未使用任何实验数据集，而是基于文献综述与理论推演；

**📈 对比分析**

不涉及实验比较，主要通过理论证明和文献对比说明方法效果，未给出性能指标；

**⚠️ 局限性**

局限性在于：①仅讨论一阶逻辑，未涵盖更广泛的非一阶或计算机科学中的实现；②缺乏经验验证；③对哲学解释的深度和范围受篇幅限制。

---

## 443. Adaptive Acquisition Selection for Bayesian Optimization with Large Language Models

**arXiv ID:** 2602.07904 | [PDF](https://arxiv.org/pdf/2602.07904v1)

**作者:** Giang Ngo `[一作]` (Applied Artificial Intelligence Initiative, Deakin University), Svetha Venkatesh `[通讯]` (Applied Artificial Intelligence Initiative, Deakin University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

利用预训练的大语言模型（LLM）作为贝叶斯优化中的自适应策略器，实时根据完整优化状态选择最合适的采集函数；

**💡 创新点**

将采集函数选择建模为 LLM 的零样本决策问题，并设计结构化状态序列化，利用 LLM 的推理能力实现多维信息融合与动态探索‑利用平衡；

**🔧 技术方法**

使用 LLM（Gemini‑2.5 Flash 等）进行提示式决策，Gaussian Process surrogate、Matérn 5/2 kernel、BoTorch 框架；

**📊 数据集**

在 50 个基准任务上评估：30 个 COCO/BoTorch 合成函数 + 20 个 Bayesmark 超参调优任务；

**📈 对比分析**

与 25 种基线（静态 AF、简单元策略、适应性组合、其他 LLM 方法）比较，LMABO 在所有类别中均显著优于对手，平均 AUC 降低 9.7% 至 54.7%，排名前四；

**⚠️ 局限性**

对 LLM 规模、提示设计和状态信息的敏感性表明方法对模型和提示仍有依赖，且在特定任务缺乏足够先验时表现可能下降；

---

## 444. Is Your Private Information Logged? An Empirical Study on Android App Logs

**arXiv ID:** 2602.07893 | [PDF](https://arxiv.org/pdf/2602.07893v1)

**作者:** Zhiyuan Chen `[一作]` (Rochester Institute of Technology), Weiyi Shang `[通讯]` (University of Waterloo)

**通讯引用:** 3847 | [OpenAlex ID](https://openalex.org/A5056378414)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `9cc9baba-5356-466d-81ff-d80028d90279` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过构建83款主流Android应用的日志数据集，对Android应用日志中的隐私泄漏进行系统性实证研究，并结合真实开发者问答探讨隐私关注点。

**💡 创新点**

创新点在于首次从日志研究视角全面分析Android日志中的隐私泄漏，提出了100%准确的字符串匹配检测方法，揭示了开发者隐私关注与泄漏实际情况的对应关系，并系统梳理了泄漏日志的特征与根源。

**🔧 技术方法**

主要技术手段包括使用Android Debug Bridge与Monkey进行自动化UI测试收集日志，采用严格字符串匹配检测隐私信息，尝试使用Drain3日志解析器但最终以手工验证为主，分析日志级别、模板及嵌套结构等特征。

**📊 数据集**

使用的数据集为83款受欢迎Android应用（含最新版本78款）共计约667,702行日志，另采集相关开发者问答内容，构成了可公开的日志与问题集合。

**📈 对比分析**

与开发者关注度对比发现610条隐私泄漏实例，其中21条来自第三方库，泄漏日志普遍处于较高日志级别；由于检测采用精确字符串匹配，检测准确率为100%，但未与其他工具进行性能基准比较。

**⚠️ 局限性**

局限性包括仅覆盖Android平台，测试设备单一，日志解析器因复杂结构失效导致需人工验证，数据集覆盖范围受限，可能存在主观分析偏差。

---

## 445. Safety Alignment as Continual Learning: Mitigating the Alignment Tax via Orthogonal Gradient Projection

**arXiv ID:** 2602.07892 | [PDF](https://arxiv.org/pdf/2602.07892v1)

**作者:** Guanglong Sun `[一作]` (Tsinghua University), Yi Zhong `[通讯]` (Tsinghua University)

**通讯引用:** 305357 | [OpenAlex ID](https://openalex.org/A5100362465)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `a4b10f5d-130b-4e77-9367-6469ec621899` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文将安全对齐视为持续学习问题，并提出一种轻量级梯度正交投影方法OGPSA。

**💡 创新点**

创新点在于通过构造低秩通用能力子空间并投影安全梯度到其正交补，实现对齐时最小化对通用能力的干扰。

**🔧 技术方法**

采用梯度正交投影、低秩子空间估计与周期性更新等技术。

**📊 数据集**

使用公开安全数据集PKU‑SafeRLHF和少量通用参考数据（如UltraFeedback、HelpfulEval、TruthfulEval）进行评估。

**📈 对比分析**

与SFT、DPO、SFT‑DPO以及合并、LoRA、通用数据等基线比较，OGPSA在保持或提升安全分数的同时显著恢复通用能力，Pareto前沿优于标准方法。

**⚠️ 局限性**

局限在于子空间仅基于有限参考梯度，可能无法覆盖所有通用能力；需要更多多样化参考数据或更高维度子空间。

---

## 446. Rich-ARQ: From 1-bit Acknowledgment to Rich Neural Coded Feedback

**arXiv ID:** 2602.07886 | [PDF](https://arxiv.org/pdf/2602.07886v1)

**作者:** Enhao Chen `[一作]` (University of Hong Kong), Yulin Shao `[通讯]` (University of Hong Kong)

**通讯引用:** 1213 | [OpenAlex ID](https://openalex.org/A5037069274)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出并实现了Rich‑ARQ框架，利用多维神经编码反馈实现发射端自适应重传；

**💡 创新点**

核心创新包括异步反馈编码（AFC）消除编码堵塞、SNR条件化训练课程（结合 Langevin 扰动）、轻量化编码器以及首个标准兼容的全栈 SDR 原型；

**🔧 技术方法**

采用深度学习（注意力网络、MLP嵌入）、SNR 条件训练、模型剪枝与稀疏计算、4G/5G 物理层标准、非阻塞多线程实时架构；

**📊 数据集**

使用实测室内多时变 SNR 轨迹、离散 Rayleigh/Fading 通道仿真以及实际 OTA 实验数据；

**📈 对比分析**

与传统 HARQ（Turbo‑HARQ、Polar‑HARQ）及现有 DL 反馈码对比，目标 PER 为 10⁻⁴ 时，Rich‑ARQ 在 SNR 上平均降低 8.8–9.5 dB，实现 1.38×–1.70×的覆盖距离提升，且与最先进 DL 反馈码相比，端到端延迟下降 43.4%；

**⚠️ 局限性**

仍受限于对特定信道模型的过拟合、对反馈包长度与上行/下行资源调度的依赖、AP 侧算力需求较高，以及标准化整合时的兼容性与协议层实现复杂度。

---

## 447. GRAFT: Decoupling Ranking and Calibration for Survival Analysis

**arXiv ID:** 2602.07884 | [PDF](https://arxiv.org/pdf/2602.07884v1)

**作者:** Mohammad Ashhad `[一作]` (King Abdullah University of Science and Technology), Ricardo Henao `[通讯]` (Duke University)

**通讯引用:** 7496 | [OpenAlex ID](https://openalex.org/A5056639842)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并实现了一种名为 GRAFT 的生存分析模型，该模型将线性 AFT 与非线性残差 MLP 结合，并通过随机门实现特征选择；利用局部 Kaplan–Meier 估计进行条件插补，并在训练过程中直接最小化与 C‑index 对齐的软排名损失。

**💡 创新点**

主要创新点包括：
1) 混合 AFT 架构分离预后排序与校准；
2) 采用可微连续化的 Stochastic Gates 进行稀疏特征选择；
3) 用局部 KM 进行条件插补，并通过 Monte‑Carlo 平均在训练中处理删失数据；
4) 训练完成后通过一维 CoxPH 对 GRAFT 得到的预后分数进行后处理，实现可靠的生存曲线校准。

**🔧 技术方法**

使用的技术包括：
- 深度残差 MLP 与线性 AFT 的混合模型；
- Stochastic Gates（连续化 Bernoulli 的 Gaussian 近似）与 L0 正则化；
- 基于局部 KM 的条件插补与逆变换采样；
- 软排名（soft‑ranking）与 Spearman 相关的可微损失；
- Monte‑Carlo 采样与平均、Adam 优化；
- CoxPH 后处理与 Breslow 估计。

**📊 数据集**

在六个公开生存分析基准上进行评估：GBSG、METABRIC、SUPPORT、NWTCO、FLCHAIN 和 AIDS，涵盖低删失率（32%–43%）到高删失率（72%–92%）。

**📈 对比分析**

与 CoxPH、Weibull AFT、DeepHit、DeepSurv 和 RSF 进行对比，采用 3 折交叉验证与 3 个随机种子，评估 C‑index 与 Integrated Brier Score。GRAFT 在 5/6 数据集上均显著优于基线（C‑index 最高 0.7965，IBS 最低 0.0572），并在噪声鲁棒性实验中保持稳定；唯一劣势出现在 AIDS（92%删失）上，表现低于 CoxPH。Ablation 结果表明随机门与 MLP 共同提升性能。

**⚠️ 局限性**

主要局限性：
1) 在极端删失率（≥92%）场景下，局部 KM 的信息不足导致模型表现不如简单参数模型；
2) 对竞争风险、时间依赖协变量等更复杂生存问题尚未扩展；
3) 需要进一步的临床验证与公平性审计。

---

## 448. HerAgent: Rethinking the Automated Environment Deployment via Hierarchical Test Pyramid

**arXiv ID:** 2602.07871 | [PDF](https://arxiv.org/pdf/2602.07871v1)

**作者:** Xiang Li `[一作]` (University College London), He Ye `[通讯]` (University College London)

**通讯引用:** 450 | [OpenAlex ID](https://openalex.org/A5101610258)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出环境成熟度层次（Environment Maturity Hierarchy）并开发基于多智能体的 EnvAgent，实现自动化环境部署与可执行验证循环。

**💡 创新点**

创新点在于：①通过可执行证据的三层成熟度定义（Installable、Testable、Runnable）明确部署成功标准；②采用脚本中心的修复机制，在全局 BashFile 上进行增量修复，避免状态漂移；③在多语言、多构建系统项目上实现持续提升。

**🔧 技术方法**

技术包括：大型语言模型（GPT‑5）、知识图谱（Tree‑sitter + Neo4j）用于代码结构分析、LangGraph 框架实现多智能体工作流、Docker SDK 进行容器化执行、以及自定义命令抽取与修复工具。

**📊 数据集**

使用四个公开基准（EnvBench‑Python、Repo2Run‑Bench、ExecutionAgent‑Bench、Installamatic‑Bench）以及额外的 C/C++ 项目集进行评估。

**📈 对比分析**

与四个基线（ExecutionAgent、Repo2Run、PIPER、Installamatic）以及多种 LLM（GPT‑5、GPT‑4o、Qwen3 系列）比较，采用 Pass@k 指标，EnvAgent 在所有基准上均实现最高性能，尤其在 C/C++ 项目上提升约 66%‑79%，并独立解决 30+ 个此前未能配置的实例。

**⚠️ 局限性**

局限性包括：对极端多语言混合或高度定制化项目的适配仍有限；对运行时依赖的推理深度仍需提升；脚本状态漂移在极小或特殊构建流程中可能产生误判。

---

## 449. A Thermodynamic Theory of Learning Part II: Critical Period Closure and Continual Learning Failure

**arXiv ID:** 2602.07950 | [PDF](https://arxiv.org/pdf/2602.07950v1)

**作者:** Daisuke Okanohara `[一作]` (Preferred Networks), Daisuke Okanohara `[通讯]` (Preferred Networks)

**通讯引用:** 1042 | [OpenAlex ID](https://openalex.org/A5056883370)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

**🎯 论文内容**

本文通过非平衡热力学视角，阐述了有限时间学习不可逆性导致的“关键期闭合”，并解释了灾难性遗忘的本质；

**💡 创新点**

创新点在于将学习过程建模为参数分布的传输，并将熵产生量与学习轨迹的可达性联系起来，提出任务保持熵与任务等价实现多样性、关键期闭合以及轨迹级兼容性等概念；

**🔧 技术方法**

采用Wasserstein梯度流、自由能函数、熵产生与“认知速度极限”理论，分析学习轨迹的不可逆压缩；

**📊 数据集**

论文为理论分析，未涉及具体实验数据集；

**📈 对比分析**

本文没有实验比较方法，主要给出理论推导和概念阐述，未给出性能数值；

**⚠️ 局限性**

局限在于假设局部可凸、局部平滑等理想化条件，缺乏在实际深度网络上的实证验证，并且对高维参数空间的可达性分析仍较粗糙。

---

## 450. IV Co-Scientist: Multi-Agent LLM Framework for Causal Instrumental Variable Discovery

**arXiv ID:** 2602.07943 | [PDF](https://arxiv.org/pdf/2602.07943v1)

**作者:** Ivaxi Sheth `[一作]` (CISPA Helmholtz Center for Information Security), Mario Fritz `[通讯]` (CISPA Helmholtz Center for Information Security)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文研究大语言模型（LLM）在发现工具变量（IV）中的能力，并提出一种多代理框架（IV Co‑Scientist）用于生成、评估和校准 IV，结合内部一致性度量评估其有效性。

**💡 创新点**

创新点包括：①将LLM用作“思考合作者”，通过生成-评判-检索的多代理流程发现新的有效 IV；②提出在无真值情况下评估 IV 质量的内部一致性指标（consistency）；③在高维 Gapminder 数据上验证该方法的可行性。

**🔧 技术方法**

主要技术：LLM（GPT‑4o、o3‑mini、QwQ、Llama3.1）生成与评判代理；两阶段最小二乘（2SLS）估计；F 统计量检验相关性；一致性指标；Granger 因果检验；多代理管道与数据预处理。

**📊 数据集**

使用的数据集：Gapminder 高维社会经济指标集（500+ 变量）以及从文献中整理的 5 对已知治疗–结果关系的基准数据。

**📈 对比分析**

比较方法：与已知经典 IV 进行 Exact / Conceptual 匹配；与随机变量比较 F 统计量和 C_norm 一致性得分；结果显示 GPT‑4o 等大模型在生成经典 IV 时准确率高，C_norm < 1，表明生成的 IV 与随机变量相比具有更高的一致性和更强的相关性，评判代理能有效过滤无效 IV。

**⚠️ 局限性**

局限性：依赖大规模结构化数据；一致性指标为间接评估，无法直接验证排除性与独立性；在噪声较大或文献稀缺的领域可能泛化受限；生成的代理变量需在数据集中可映射，否则会被排除。

---

## 451. Trajectory-Aware Multi-RIS Activation and Configuration: A Riemannian Diffusion Method

**arXiv ID:** 2602.07937 | [PDF](https://arxiv.org/pdf/2602.07937v1)

**作者:** Kaining Wang `[一作]` (Northwestern Polytechnical University), Zhu Han `[通讯]` (University of Houston)

**通讯引用:** 87570 | [OpenAlex ID](https://openalex.org/A5063667378)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `ba576bd1-e51d-44e8-8077-fc943b333c93` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在多RIS辅助的上行通信场景中，本文提出了一套轨迹感知的生成式ON/OFF控制框架，用预测用户未来轨迹来重建未来CSI，并在此条件下通过Riemannian扩散模型与强化学习协同，生成几何一致的RIS相位配置并决定RIS的开关状态；

**💡 创新点**

创新点在于：① 将用户轨迹预测与RIS配置耦合，提前消除干扰；② 在相位约束的圆形流形上设计Riemannian扩散模型，避免欧氏扩散对相位周期性的破坏；③ 用TD3强化学习引导扩散过程，使得无标签情况下仍可收敛到高质量相位解；

**🔧 技术方法**

技术手段包括：双层LSTM轨迹预测、LoS几何CSI重建、Riemannian扩散（在S1^N上进行噪声注入/去噪）、TD3双臂Critic驱动的逆扩散、基于预测CSI的ON/OFF决策、并行GPU实现；

**📊 数据集**

使用的实际数据集为GeoLife轨迹数据集（北京地区真实运动员轨迹），并在仿真平台上构建10个RIS、10个干扰用户、600元件RIS的场景；

**📈 对比分析**

与多种基线（Euclidean扩散+DRL、DDPG、TD3、SAC、PPO、A3C、ISL、Always‑On）及四种RIS策略（TPC、Always‑On、ISL、RDM‑DRL）对比，实验显示RDM‑DRL在SINR上比学习型基线提升约30%，比Always‑On提升44%，收敛速度最快、在不同功率、RIS规模和干扰密度下均保持领先；

**⚠️ 局限性**

局限性包括：① 依赖精确轨迹预测和LoS几何模型，对非LoS或极高速运动环境适应性不足；② 扩散+DRL训练过程复杂、对计算资源和超参数敏感；③ 只在仿真验证，硬件实现仍需进一步验证；

---

## 452. Feasibility-Guided Planning over Multi-Specialized Locomotion Policies

**arXiv ID:** 2602.07932 | [PDF](https://arxiv.org/pdf/2602.07932v1)

**作者:** Ying-Sheng Luo `[一作]` (Inventec Corporation), Wei-Chao Chen `[通讯]` (Inventec Corporation)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出了一种基于可行性引导的规划框架，能够在不规则地形上融合多种专用步态策略，实现安全、高效路径规划。

**💡 创新点**

创新点在于：①与每个RL步态策略对应的可行性网络（Feasibility‑Net）联合训练，直接输出基于局部高度图和运动指令的可行性分数；②利用VAE实现离群检测，对未知地形自动降低信心；③将可行性转化为方向感知张量并通过最大融合与Dijkstra算法实现多策略协同规划；④支持在不重新训练的情况下增添新策略。

**🔧 技术方法**

使用深度强化学习（PPO）训练步态策略、监督学习训练可行性网络、VAE做分布建模、滑动窗口生成方向性可行性张量、Dijkstra图搜索进行路径规划，并在真实世界使用LiDAR生成高度图。

**📊 数据集**

在仿真中使用自定义的四种地形（阶梯、跨隙、狭桥、峡谷）与混合地形；在现实中搭建包含同四种地形段的混合测试环境，并在Unitree A1四足机器人上进行验证。

**📈 对比分析**

与单一通用策略和单一专用策略比较，提出的框架在仿真中达到近乎100%的成功率（各专用域>99.9%，混合地形98.6%），比通用策略在大部分地形的成功率低于50%；在现实实验中总体成功率为70%，远高于通用策略在桥梁、峡谷等复杂段落的零成功率；SPL指标从0.19提升至0.51，说明路径更短、更符合步态能力。

**⚠️ 局限性**

局限性包括：①真实环境中定位误差导致策略切换提前或延后，影响成功率；②桥梁、峡谷等需要精细步态控制的地形仍难以完全通过可行性预测得到；③系统依赖高质量高度图与VAE训练数据，对极端离散地形或极端噪声鲁棒性待提升。

---

## 453. A Kinetic-Energy Perspective of Flow Matching

**arXiv ID:** 2602.07928 | [PDF](https://arxiv.org/pdf/2602.07928v1)

**作者:** Ziyun Li `[一作]` (KTH Royal Institute of Technology), Henrik Bostrom `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `40105733-5154-44cd-8090-a8cab9e64b07` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了基于流匹配生成模型的轨迹能量度量Kinetic Path Energy (KPE)，并将其用作单样本质量诊断；

**💡 创新点**

发现KPE既能预测语义保真度，又能揭示轨迹终点处的低密度稀疏性；通过KPE实现“Goldilocks”原则并设计Kinetic Trajectory Shaping (KTS) 的两相能量调节，既提升生成质量又抑制记忆化；

**🔧 技术方法**

理论上对经验流匹配的闭式解进行分析，证明终止时能量爆炸导致记忆化；实验上使用ODE采样、Euler、midpoint求解器、CLIP、FID、F_mem等指标；

**📊 数据集**

主要在CelebA、ImageNet‑256、CIFAR‑10以及三种合成二维密度分层数据集上验证；

**📈 对比分析**

与基线流匹配模型和其他控制方法对比，KTS 在CelebA 上 FID 由 16.68 提升至 14.35，记忆化率从 37.34% 降至 31.22%；在 ImageNet‑256 上 FID 接近或略优于基线，并提供可调的精度‑召回平衡；

**⚠️ 局限性**

仅适用于基于ODE的流模型，对扩散模型或更一般的随机采样器的推广尚未验证；KPE 依赖于密度估计的近似，无法直接解释高维像素空间的真实密度；

---

## 454. Interference Propagation Analysis for Large-Scale Multi-RIS-Empowered Wireless Communications:An Epidemiological Perspective

**arXiv ID:** 2602.07922 | [PDF](https://arxiv.org/pdf/2602.07922v1)

**作者:** Kaining Wang `[一作]` (Northwestern Polytechnical University), Mérouane Debbah `[通讯]` (Khalifa University)

**通讯引用:** 65881 | [OpenAlex ID](https://openalex.org/A5056145687)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2`

**🎯 论文内容**

本文研究了多RIS辅助的下行无线系统中，由用户移动导致的干扰传播，并基于随机几何模型推导了期望信号功率、干扰功率以及覆盖概率的闭式表达式，同时将干扰传播建模为SIS流行病模型，给出了感染率、恢复率和传播强度指标。

**💡 创新点**

创新点在于首次将干扰传播视为空间传染过程，提出干扰传播强度（R₀）指标，并在闭式公式基础上分析了RIS部署、用户密度、基站密度、频率和RIS元件数对干扰传播的影响。

**🔧 技术方法**

使用的技术包括：Matérn硬核点过程与Poisson点过程的随机几何建模、Gamma近似与矩匹配法、拉氏变换求干扰分布、SIS流行病模型以及Monte Carlo仿真验证。

**📊 数据集**

本文没有使用公开数据集，而是通过数值仿真（10⁵次Monte Carlo）基于设定的网络参数（如BS密度10⁻⁵，RIS密度10⁻⁵，UE密度10⁻²，RIS元件数200等）进行验证。

**📈 对比分析**

与传统不考虑RIS或不考虑移动的基线模型相比，仿真结果表明：当用户密度、基站密度或RIS元件数增大时，R₀可明显超过1，干扰传播迅速蔓延，覆盖概率下降；而在低密度或高频段场景下，干扰传播可被抑制，系统性能相对稳定。

**⚠️ 局限性**

局限性包括：假设RIS相位调节完全精准、忽略多RIS链路、基站与RIS关联规则过于简单、未考虑真实硬件失配、移动模型为简化随机步长模型，且缺乏实验室或实测验证。

---

## 455. Selective Fine-Tuning for Targeted and Robust Concept Unlearning

**arXiv ID:** 2602.07919 | [PDF](https://arxiv.org/pdf/2602.07919v1)

**作者:** Mansi `[一作]` (Imperial College London), Soteris Demetriou `[通讯]` (Imperial College London)

**通讯引用:** 926 | [OpenAlex ID](https://openalex.org/A5007503250)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对文本到图像扩散模型进行概念无用化的细粒度动态神经元选择与针对性微调。

**💡 创新点**

提出动态重新估计概念神经元、两种新正则化（CIP与CSR）以及基于梯度的交叉注意力Saliency Mask，实现对单概念、组合与条件概念的精细控制。

**🔧 技术方法**

使用交叉注意力神经元定位、梯度与Hessian正则、动态mask‑guided fine‑tuning、CLIP对齐损失等技术。

**📊 数据集**

在Stable Diffusion v1.5（训练自LAION‑Aesthetics v2+）上实验，评估集包括MS‑COCO 30k、I2P、LAION‑NSFW等。

**📈 对比分析**

与CoGFD、SalUn、SalUn++等基线对比，单概念与组合概念攻击成功率降至≈0.1%，ΔFID≈0.02，训练步骤仅60步，速度提升约3–5倍，且对大多数保留概念的质量影响极小。

**⚠️ 局限性**

对极复杂多概念组合仍存在轻微性能下降；CIP在对抗鲁棒性上优于CSR，但略微降低生成质量；方法目前仅针对含交叉注意力的扩散模型，迁移至其他架构需要额外适配。

---

## 456. CausalCompass: Evaluating the Robustness of Time-Series Causal Discovery in Misspecified Scenarios

**arXiv ID:** 2602.07915 | [PDF](https://arxiv.org/pdf/2602.07915v1)

**作者:** Huiyang Yi `[一作]` (Southeast University), Wenwu Yu `[通讯]` (Southeast University)

**通讯引用:** 25920 | [OpenAlex ID](https://openalex.org/A5100627758)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了CausalCompass基准套件，用以系统评估时间序列因果发现（TSCD）方法在多种模型假设失效场景下的鲁棒性。

**💡 创新点**

创新点在于首次将深度学习方法纳入多种假设违规情景的全面比较，并公开了可扩展的基准框架，弥补了以往仅关注线性或特定方法的研究空白。

**🔧 技术方法**

采用11种主流TSCD算法（包括约束、噪声、评分、拓扑、格兰杰和深度学习方法），利用线性VAR与Lorenz‑96生成模型，并在八种违规场景（测量误差、非平稳、混合、缺失、趋势季节性、标准化、最小-最大归一化、潜在混淆）下进行实验。

**📊 数据集**

数据集为合成时间序列，节点数10/15，长度500/1000，Lorenz‑96外部驱动力F=10/40等参数，涵盖线性与非线性两类基准。

**📈 对比分析**

通过AUROC/AUPRC指标进行比较，结果显示深度学习方法在大多数违规情境下整体表现最佳，但不存在单一最佳方法；标准化对NTS‑NOTEARS的性能影响显著，且不同方法对假设违规的敏感性差异显著。

**⚠️ 局限性**

主要局限在于仅使用合成数据，缺乏真实世界验证；深度学习方法在线性场景下对超参数敏感且表现不稳定，需进一步研究其泛化与解释性。

---

## 457. Rethinking Practical and Efficient Quantization Calibration for Vision-Language Models

**arXiv ID:** 2602.07899 | [PDF](https://arxiv.org/pdf/2602.07899v1)

**作者:** Zhenhao Shang `[一作]` (Northwestern Polytechnical University), Peng Wang `[通讯]` (Northwestern Polytechnical University)

**通讯引用:** 18774 | [OpenAlex ID](https://openalex.org/A5100395960)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种基于梯度引导的Token级重要性加权层级量化校准框架TLQ，用于视觉-语言模型的后训练量化。

**💡 创新点**

创新点在于：①利用梯度信息构造Token重要性，精细化校准集；②设计量化曝光的层级校准和多GPU分布式计算，解决大模型层级校准的内存瓶颈；③实现对视觉和文本Token不均衡的自适应处理。

**🔧 技术方法**

采用对称量化、梯度加权Token选择、Top‑K聚合、PassAct2层级校准、分布式GPU协同计算等技术。

**📊 数据集**

使用增强版COCO Caption数据集（128张图+GPT‑4V描述）做校准，评估数据集包括MMMU、OCRBench、VizWiz、TextVQA、ChartQA、SeedBench2‑Plus。

**📈 对比分析**

与RTN、SmoothQuant、MBQ等三种强基线在W4A6/W4A8两种量化设置下进行对比，在LLaVA‑onevision与Qwen2‑VL两大模型及多规模下，TLQ平均提升1–2%准确率，且表现更稳定。

**⚠️ 局限性**

局限性：对梯度计算的依赖使得对模型梯度不敏感或梯度异常时效果受限；虽然多GPU方案降低了单卡峰值内存，但仍需至少三块RTX3090，且对极大模型的跨卡通信与调度仍有待进一步优化。

---

## 458. Efficient Anti-exploration via VQVAE and Fuzzy Clustering in Offline Reinforcement Learning

**arXiv ID:** 2602.07889 | [PDF](https://arxiv.org/pdf/2602.07889v1)

**作者:** Long Chen `[一作]` (Chinese Academy of Sciences, WAYTOUS Inc., Guangdong Laboratory of Artificial Intelligence and Digital Economy, Xi'an Jiaotong University), Xuemin Hu `[通讯]` (Hubei University)

**通讯引用:** 3443 | [OpenAlex ID](https://openalex.org/A5017658254)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种基于多码本VQVAE和模糊C‑均值聚类的伪计数反探索方法，用于解决离线强化学习中的过度探索和OOV问题。

**💡 创新点**

创新点在于：①使用多码本VQVAE将连续状态‑动作映射到低维离散标签，避免传统网格离散导致的维度灾难；②引入FCM聚类更新码本，提高码本利用率并降低信息损失；③将伪计数作为动态惩罚融入SAC框架，实现更高效、准确的OOV检测。

**🔧 技术方法**

主要技术包括多码本Vector Quantized Variational Autoencoder、Fuzzy C‑Means聚类、Counting Bloom Filter、SAC、CQL、TD3‑CVAE、SAC‑RND等。

**📊 数据集**

使用D4RL基准（Gym‑MuJoCo、Adroit、Maze2d等）进行实验评估。

**📈 对比分析**

与SOTA反探索方法（TD3‑CVAE、SAC‑RND、GPC‑SAC）以及主流离线RL方法（DMG、O‑DICE、IQL、CQL）对比，平均提升约6%得分，部分任务提升至18%，同时GPU内存仅0.2 GB，计算成本显著低于对比方法。

**⚠️ 局限性**

局限性：在数据极度稀疏或分布不均的任务中，惩罚过度保守导致方差增大；码本数量仍需经验调参，且在高维任务中可能需要动态调整码本分辨率。

---

## 459. ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation

**arXiv ID:** 2602.07883 | [PDF](https://arxiv.org/pdf/2602.07883v1)

**作者:** Jingqi Zhou `[一作]` (University of Hong Kong), Chuan Wu `[通讯]` (University of Hong Kong)

**通讯引用:** 10929 | [OpenAlex ID](https://openalex.org/A5012597518)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种将任务执行与自我重构统一到同一动作空间的代理框架（Tool-driven Self-reconfiguration, TSSR），使得代理能够在运行时自主决定何时以及如何更新子目标、策略、工具箱和上下文，从而提升长期任务表现。

**💡 创新点**

核心创新在于：① 将配置更新抽象为可调用工具，实现触发、意图和执行三大功能的统一；② 设计两阶段训练（RFT + KTO）让代理在教师演示和轨迹级强化学习中学习跨阶段自我重构；③ 通过共享基础模型与LoRA分离，构建紧凑且可端到端优化的系统。

**🔧 技术方法**

技术手段包括：ReAct式思考-行动-观察循环；工具调用接口；LoRA适配器；Rejection Sampling Fine‑Tuning (RFT)；Kahneman‑Tversky Optimization (KTO) 的轨迹级奖励；以及全链路统一的配置生成与执行策略。

**📊 数据集**

使用四类基准数据集：FRAMES（深度研究型多步检索）、xbench、GAIA（包含子集 GAIA(WS)）以及 SWE‑bench Lite（软件工程任务）。

**📈 对比分析**

在所有基准上与单体代理、单体扩展和多体工作流基线对比，TSSR 在 FRAMES 上提升至 56%（+19%），GAIA 上 38.8%（+9.6%），SWE‑bench Lite 16.1%（+1.5%），平均准确率提升 24.1%（从 28.0% 提升至 52.1%），表明其在自适应、跨领域任务中具有显著优势。

**⚠️ 局限性**

局限性主要体现在：① 对外部工具集依赖较高，若工具缺失或接口不稳定会影响性能；② 训练成本高，需要教师示例和多轮强化学习；③ 目前仅验证在文本/代码检索类任务，对更具感知或实时交互的场景尚未充分评估。

---

## 460. Rethinking Code Complexity Through the Lens of Large Language Models

**arXiv ID:** 2602.07882 | [PDF](https://arxiv.org/pdf/2602.07882v1)

**作者:** Chen Xie `[一作]` (Shanghai Jiao Tong University), Beijun Shen `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 1132 | [OpenAlex ID](https://openalex.org/A5045672909)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过实证研究传统代码复杂度指标与大型语言模型（LLM）在代码相关任务上的性能关系，发现传统指标与LLM难度无显著关联，并提出一种基于token熵的语义非线性度量（将代码拆分为熵驱动的语义单元并构成层级结构，综合组合层级与分支因子），进一步通过语义保持的代码重写验证该度量的可操作性与提升LLM性能的有效性。

**💡 创新点**

①提出了从LLM视角出发的新型复杂度度量，利用token熵捕捉模型不确定性并映射为语义层级结构；②首次系统性证明传统复杂度指标与LLM性能不相关；③通过语义保持重写验证该度量的因果影响，展示可显著提升模型表现。

**🔧 技术方法**

token级熵计算（使用CodeLlama-7b-hf）、熵-结构双重分割构建语义单元、层级语义分解、组合层级与分支因子特征提取、偏相关分析（控制代码长度）、语义保持的代码重写、α权重敏感性消融。

**📊 数据集**

xCodeEval（程序修复271例、代码翻译535例）与HumanEval（执行推理162例）。

**📈 对比分析**

采用pass@1评价指标，对传统复杂度指标与新度量与LLM（DeepSeek‑V3）在三任务上的偏相关系数进行比较；新度量在所有任务上均获得|r|>0.9的高相关性；通过语义保持重写降低该度量后，程序修复任务提升20.9%、代码翻译提升10.2%、执行推理提升0.5%。

**⚠️ 局限性**

限于少数任务与单一LLM（DeepSeek‑V3）验证，依赖token熵对模型敏感；α权重与熵阈值需手工设定；未对更大规模或不同模型进行普适性检验；仅关注代码结构非线性，其他可能影响LLM的语义复杂性未纳入。

---

## 461. Deep Variable-Length Feedback Codes

**arXiv ID:** 2602.07881 | [PDF](https://arxiv.org/pdf/2602.07881v1)

**作者:** Yu Ding `[一作]` (University of Hong Kong), Yulin Shao `[通讯]` (University of Hong Kong)

**通讯引用:** 1213 | [OpenAlex ID](https://openalex.org/A5037069274)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出了可变长度反馈编码框架 DeepVLF，并通过学习动态调整传输长度实现更高的可靠性与效率。

**💡 创新点**

创新点包括：①引入接收机驱动与发射机驱动两种终止机制；②使用变深度 Transformer 架构进行分组编码与解码；③自发发现 Schalkwijk‑Kailath 两阶段策略。

**🔧 技术方法**

技术手段主要是深度学习（Transformer、注意力机制、可变深度特征提取）、端到端训练、交互式反馈学习。

**📊 数据集**

实验数据集为模拟的 AWGN 以及 5G‑NR CDL‑C 无线衰落通道（通过 QuaDRiGa 生成的路径），不涉及公开数据集。

**📈 对比分析**

通过与 GBAF、DeepCode、AttentionCode 等现有学习型反馈编码对比，DeepVLF 在相同可靠性下平均可节省 20–55% 通道使用量，误码率降低数个数量级。

**⚠️ 局限性**

局限性包括：在反馈噪声较大时发射机终止容易误判；对比实验主要在仿真环境，实际部署需进一步验证；模型规模与训练成本相对较高。

---

## 462. Harpoon: Generalised Manifold Guidance for Conditional Tabular Diffusion

**arXiv ID:** 2602.07875 | [PDF](https://arxiv.org/pdf/2602.07875v1)

**作者:** Aditya Shankar `[一作]` (Delft University of Technology), Lydia Y. Chen `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `67630363-6be0-4f51-ab05-7198250671a5` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研发了一种基于流形引导的表格扩散模型 Harpoon，可在推理阶段满足多种约束（缺失值填补、区间约束、类别约束等），并且不需要额外训练。

**💡 创新点**

创新点：①将流形理论推广到混合型表格数据，证明任意可微推理损失的梯度位于流形切空间；②基于该理论设计了 Harpoon 算法，采用无条件去噪与切向梯度交替更新的方式，实现了通用的推理时条件引导。

**🔧 技术方法**

技术：标准 DDPM 扩散框架、MSE 训练、流形投影与切向梯度理论、MAE / 交叉熵等推理时损失、one‑hot / soft 编码处理离散特征。

**📊 数据集**

数据集：UCI 八大基准数据集（Gesture、Magic、California、Letter、Bean、Adult、Default、Shoppers）。

**📈 对比分析**

对比方法：DiffPuter、GReaT、Remasker、GAIN、MIRACLE 等 SOTA 方法；评价指标包括缺失填补的 MSE/准确率、约束违背率、α‑score、下游 XGBoost 准确率。Harpoon 在多数场景下实现最优或相近性能，尤其在高缺失率和不等式约束下优势明显；运行时约为 DiffPuter 的 2 倍，仍保持低于 5 秒的生成时间。

**⚠️ 局限性**

局限性：目前仅在连续噪声框架下有效，未针对离散噪声扩散方法推广；流形假设仍假设连续光滑嵌入，离散特征的编码仅为近似；推理时的时间仍可进一步优化，尤其在更大规模数据上。

---

## 463. OFDM Enabled Over-the-Air Computation Systems with Two-Dimensional Fluid Antennas

**arXiv ID:** 2602.07953 | [PDF](https://arxiv.org/pdf/2602.07953v1)

**作者:** Heyang Xiong `[一作]` (Sun Yat-sen University), Qi Zhang `[通讯]` (Sun Yat-sen University)

**通讯引用:** 24692 | [OpenAlex ID](https://openalex.org/A5100360246)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出一种结合二维流动天线系统（2D FAS）的OFDM空中计算（AirComp）系统，并通过联合优化发射预编码、接收组合器与天线位置来最小化计算MSE。

**💡 创新点**

创新点在于首次将流动天线的空间自由度引入频率选择性环境的AirComp，并利用MM与交替优化实现天线位置与链路参数的协同设计，显著提升MSE性能。

**🔧 技术方法**

采用的核心技术包括OFDM调制、AirComp原理、流动天线模型、交替优化（AO）、主导-最小化（MM）以及顺序二维搜索。

**📊 数据集**

论文主要通过仿真验证，未使用公开数据集，仿真参数包括：K=5用户、N=64子载波、M=4天线、λ=0.125m、L=4多径、随机角度和路径增益。

**📈 对比分析**

与固定位置天线（FPA）、穷举搜索（EAS）和SCA算法进行对比，在不同P/σ²和K值下，所提方案在计算MSE上始终优于其他方案，尤其在高信噪比时性能差距更明显。

**⚠️ 局限性**

局限性包括：仅在仿真环境下验证，缺乏实测验证；算法实现复杂度较高；天线数量与部署区域有限；未考虑时变通道和硬件实现约束。

---

## 464. Privacy-Preserving Covert Communication Using Encrypted Wearable Gesture Recognition

**arXiv ID:** 2602.07936 | [PDF](https://arxiv.org/pdf/2602.07936v1)

**作者:** Tasnia Ashrafi Heya `[一作]` (University of Dayton), Sayed Erfan Arefin `[通讯]` (University of Dayton)

**通讯引用:** 93 | [OpenAlex ID](https://openalex.org/A5055551938)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `9cc9baba-5356-466d-81ff-d80028d90279` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

设计并实现了基于多方同态加密的手势识别系统，实现端到端加密通信，包含隐藏反馈（触觉与视觉）机制；

**💡 创新点**

创新点在于将同态学习与多方安全计算融合至可穿戴设备，保证从传感器采集到最终反馈全程保密，并提出了低功耗可行的触觉/视觉隐蔽反馈方案；

**🔧 技术方法**

采用 CrypTen + BGV‑style 同态加密、固定点编码、LeakyReLU 与 MSE 损失的三层全连接网络，配合多方 MPC 进行加密训练与推理；

**📊 数据集**

使用 9 位受试者在 Fossil Gen 6 智能手表上采集 600 条手势（A、B、C、E）的加速度与陀螺仪数据，并提取 96 维时域/频域特征；

**📈 对比分析**

与明文 NN 对比，Encrypted NN 在桌面 GPU、Jetson Orin Nano 与 Jetson Nano 上分别保持 92%–94% 的分类准确率；推理延迟约 46 ms（Orin Nano）到 170 ms（Nano），训练耗时显著增大但仍可在云/边缘实现；

**⚠️ 局限性**

局限性包括：高加密算子导致计算开销大、对模型深度与维度有限制、仅支持固定手势字典、需要安全的密钥管理与多方协作、未针对侧信道与功耗攻击做进一步评估。

---

## 465. Research on a Camera Position Measurement Method based on a Parallel Perspective Error Transfer Model

**arXiv ID:** 2602.07888 | [PDF](https://arxiv.org/pdf/2602.07888v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

---

## 466. Attention-Based Deep Learning for Early Parkinson's Disease Detection with Tabular Biomedical Data

**arXiv ID:** 2602.07933 | [PDF](https://arxiv.org/pdf/2602.07933v1)

**作者:** Olamide Samuel Oseni `[一作]`, Toheeb Aduramomi Jimoh `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

使用UCI Parkinson's Voice数据集比较SAINT、TabNet、MLP和GBM四种模型在早期帕金森诊断中的表现。

**💡 创新点**

引入SAINT模型的自注意力与跨样本注意力机制，对表格生物医学数据进行双重注意力建模，显著提升早期诊断准确率。

**🔧 技术方法**

采用Transformer基础的SAINT、TabNet、MLP以及梯度提升树模型，并使用特征嵌入、注意力机制和交叉熵等技术。

**📊 数据集**

使用UCI Machine Learning Repository的Parkinson's Telemonitoring 数据集（ID 174），包含22个声学特征共195条样本。

**📈 对比分析**

通过80/20随机分层拆分、计算准确率、AUC、精确率、召回率、F1和MCC等指标进行对比；SAINT表现最佳（精确率0.98，召回率0.97，F1 0.97，MCC 0.9369，AUC最高），TabNet次之，GBM最低。

**⚠️ 局限性**

数据量小、仅包含声学特征，缺乏多模态/临床变量，模型易过拟合，解释性不足，需要在更大、多样化数据集上进一步验证。

---

## 467. SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization

**arXiv ID:** 2602.07909 | [PDF](https://arxiv.org/pdf/2602.07909v1)

**作者:** Taolin Zhang `[一作]` (Shenzhen University), Jindong Wang `[通讯]` (Microsoft Research Asia)

**通讯引用:** 47131 | [OpenAlex ID](https://openalex.org/A5075880303)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 SparseEval 框架，通过选择并加权少量代表性测试项，实现大语言模型评估的稀疏化，从而显著降低推理成本。

**💡 创新点**

创新点包括：①将稀疏评估建模为稀疏优化问题；②使用梯度下降直接优化 anchor 权重；③设计 Anchor Importance Score 与 Candidate Importance Score，实现任务感知的 anchor 细化；④利用 MLP 进行非线性估计，提升表达能力。

**🔧 技术方法**

主要技术：谱聚类（Spectral Clustering）提取聚类结构；多层感知机（MLP）端到端优化；梯度下降求解权重；重构损失与稀疏正则化；通过残差/梯度计算 Anchor Importance Score 与 Candidate Importance Score。

**📊 数据集**

实验数据集：ARC、GSM8K、HellaSwag、MMLU、TruthfulQA、Winogrande 六大 LLM 基准；评估样本来自 Open-LLM Leaderboard，模型数量约 5,000，训练/验证/测试各 200 模型。

**📈 对比分析**

与 Anchor Points、gp-IRT、TailoredBench 等基线对比，SparseEval 在不同 anchor 数量下 MAE 下降至 1% 以下，Kendall τ 超过 0.90，误差平均比基线低 2% 以上，且训练与推理开销显著更低。

**⚠️ 局限性**

限制：梯度下降需要足够的训练样本才能保证收敛；对极少样本或超大模型的适应性尚未验证；目前未充分利用模型间的稀疏性，未来可进一步提升性能。

---

## 468. MedCoG: Maximizing LLM Inference Density in Medical Reasoning via Meta-Cognitive Regulation

**arXiv ID:** 2602.07905 | [PDF](https://arxiv.org/pdf/2602.07905v1)

**作者:** Yu Zhao `[一作]` (Nankai University), Dacheng Tao `[通讯]` (Nanyang Technological University)

**通讯引用:** 98578 | [OpenAlex ID](https://openalex.org/A5074103823)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

设计并实现了一种医学元认知代理 MedCoG，利用大语言模型自我评估（复杂度、熟悉度、知识密度）动态调节程序化知识、情景记忆和事实知识，以实现高效医学推理。

**💡 创新点**

提出了基于元认知的策略选择框架，并引入推理密度和增量效率两项新指标，显著提升推理效能并突破传统推理缩放法则。

**🔧 技术方法**

使用结构化链式思维（SCoT）、知识图谱检索、经验记忆检索，结合 GPT‑4o 作为核心模型，并通过阈值门控实现动态策略切换。

**📊 数据集**

在 MedQA、MedMCQA、MMLU、MMLU‑Pro、PubMedQA 五大医学推理基准的困难子集（以及 MedQA‑Full）上进行评测。

**📈 对比分析**

与零射、CoT、Agentic 方法（如 MultiPersona、Self‑Refine、AFlow、MedPrompt 等）对比，MedCoG‑Meta 在所有难题集上平均精度最高，推理密度提升 5.5 倍，增量效率最高。

**⚠️ 局限性**

受限于外部知识库与案例库的质量，容易受到噪声与偏差影响；元认知阈值需人工调参，对极端罕见病例的适应性仍有限。

---

## 469. Optimized Human-Robot Co-Dispatch Planning for Petro-Site Surveillance under Varying Criticalities

**arXiv ID:** 2602.07924 | [PDF](https://arxiv.org/pdf/2602.07924v1)

**作者:** Nur Ahmad Khatim `[一作]` (Institut Teknologi Sepuluh Nopember), Mansur Arief `[通讯]`

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了人机协同派遣设施选址问题（HRCD‑FLP），在石油设施保护中融合了资产关键性分层、服务水平协议和人机监督比例约束。

**💡 创新点**

创新点在于将人机监督比例约束正式纳入设施选址模型，支持多层设施级别、异构资源和冗余覆盖，并通过两阶段启发式快速求解大规模实例。

**🔧 技术方法**

采用了混合整数线性规划（MILP）建模与Gurobi精确求解，以及基于贪心构造+局部搜索的两阶段启发式算法。

**📊 数据集**

使用了结合真实地理信息的石油设施模拟数据集（15个候选中心、50个需求点）和扩展至500个候选中心、5000个需求点的人工合成大规模实例。

**📈 对比分析**

在小规模实例中，精确求解在1.5秒内获得最优解，启发式方案在5–7秒内得到近似最优解（<2% 最优缺口）；在大规模实例中，精确求解无法在3600秒内完成，而启发式方案在3分钟内得到可行解，最优缺口约14%。

**⚠️ 局限性**

主要局限包括启发式方案在大规模问题上易产生过多设施（最多1.6倍）导致成本偏高，以及对监督比例假设的敏感性未充分探讨。

---

## 470. One-Shot Crowd Counting With Density Guidance For Scene Adaptaion

**arXiv ID:** 2602.07955 | [PDF](https://arxiv.org/pdf/2602.07955v1)

**作者:** Jiwei Chen `[一作]` (Nanjing University of Information Science and Technology), Jing-Jia Luo `[通讯]` (Nanjing University of Information Science and Technology)

**通讯引用:** 18902 | [OpenAlex ID](https://openalex.org/A5002110495)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种局部到全局密度引导的一射式人群计数方法，利用支持图像的真实密度图进行局部密度多原型学习和全局密度特征提取，并将其分别用于局部和全局的特征引导，以适应未见监控场景。

**💡 创新点**

创新点在于将多原型EM聚类与局部-全局密度引导相结合，既通过局部密度相似矩阵捕获不同密度分布，又通过Transformer实现全局密度上下文的引导，从而显著提升一射式计数在多场景上的泛化能力。

**🔧 技术方法**

采用的技术包括：VGG16特征提取器、基于EM的局部密度多原型学习、余弦相似度编码局部密度相似矩阵、CNN卷积激活局部引导、Transformer实现全局密度引导，以及欧氏距离损失进行端到端训练。

**📊 数据集**

使用的公开数据集包括：WorldExpo'10（108个监控场景），Venice（1个训练场景+3个测试场景）以及CityUHK-X（55个监控场景），三者均用于评估一射式计数的跨场景泛化性能。

**📈 对比分析**

在三大基准数据集上与最近的最先进方法（如CVPR2025、TIP2024等）对比，本文方法在MAE上分别取得约5–13%（WorldExpo'10）和约2%（Venice、CityUHK-X）的提升，显示出更强的精度和泛化能力。

**⚠️ 局限性**

主要局限在于：对单一支持样本的依赖容易导致过拟合（尤其当多原型数目过多时），并且在极端密度或视角差异较大的场景中，局部与全局引导的权重调节仍需要进一步优化。

---

## 471. Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation

**arXiv ID:** 2602.07954 | [PDF](https://arxiv.org/pdf/2602.07954v1)

**作者:** Krzysztof Wróbel `[一作]` (SpeakLeash Foundation), Maciej Szymański `[通讯]` (SpeakLeash Foundation)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

为波兰语内容安全开发了两款轻量级多标签分类模型 Bielik Guard，能够识别仇恨、粗俗、性、犯罪和自伤等五类不良内容。

**💡 创新点**

创新点包括使用社区驱动的软标签数据、5类聚焦分类法、基于波兰语 RoBERTa 的紧凑模型以及在真实用户提示上的高精度与低误报率。

**🔧 技术方法**

采用 RoBERTa‑base（MMLW-RoBERTa）和 PKOBP/polish‑roberta‑8k 作为编码器，添加 dropout+线性层进行多标签分类，并用 BCE 损失与软标签训练。

**📊 数据集**

使用 6,885 条波兰语文本的社区标注数据（约 60,000 条单独标注），按 60% 同意阈值构建二值标签。

**📈 对比分析**

与 HerBERT‑PL‑Guard、Llama Guard 3、Qwen3Guard 在 3,000 条用户提示以及公开基准上比较，Bielik Guard 0.1B v1.1 获得 77.65% 的精度和 0.63% 的误报率，明显优于同等规模和更大多语言模型。

**⚠️ 局限性**

局限在于仅覆盖波兰语、排除了谣言、越狱等类别、对专业领域和高阶对抗攻击的鲁棒性待验证。

---

## 472. Integrating Specialized and Generic Agent Motion Prediction with Dynamic Occupancy Grid Maps

**arXiv ID:** 2602.07938 | [PDF](https://arxiv.org/pdf/2602.07938v1)

**作者:** Rabbia Asghar `[一作]`, Christian Laugier `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种统一的多任务框架，利用动态占用网格（DOGM）和车辆语义网格，在共享的时空编码器下同时预测未来占用状态网格、车辆网格和场景流网格，从而实现对特定车辆与通用动态物体的协同运动预测。

**💡 创新点**

创新点包括：
1) 多头解码器将车辆检测、车辆流、DOGM预测和流引导占用预测融合在一起；
2) 通过场景流（backward flow）与检测结果相结合进行占用网格的递归warp，形成流引导占用预测；
3) 设计了一套相互依赖的损失函数，既考虑占用预测、车辆检测、流预测，又通过占用-流一致性正则化全局运动场；
4) 将车辆语义信息与DOGM融合作为输入，弥补传统DOGM对形状与语义缺失的不足。

**🔧 技术方法**

主要技术包括：
- ConvLSTM + sGRU 进行时空特征提取；
- 条件变分自编码器产生多模态未来；
- 反向场景流预测与占用warp；
- 多任务交叉熵、L1、L2 损失以及KL 散度；
- 车辆语义网格生成采用 LSS（Lift–Splat–Shoot）方法。

**📊 数据集**

使用公开数据集 nuScenes（约280min）和 Woven Planet Perception（约75min）进行训练与评估，均包含 5/6 方向摄像头与 10/5Hz LiDAR。

**📈 对比分析**

与 PredNet、PredRNN 等传统视频预测基线进行对比。实验表明：
- 在车辆检测/预测任务上，Recall 与 Recall‑Dynamic 均高于基线，尤其在动态车辆方面提升显著；
- 对于 DOGM 的未知/静态/动态通道，MSE 与 EPE 与基线相当或更好；
- 由于多任务学习，整体 IoU 略低于单任务基线，但模型更能覆盖多种可能的未来，Recall 较高；
- 流引导占用预测（warp）在 Recall‑Dynamic 上显著提升，表明能更好捕获未识别动态物体的运动。

**⚠️ 局限性**

局限性包括：
- 对小尺寸动态物体（如行人、单车）检测困难，导致动态占用预测误差；
- 生成的场景流未加入显式运动学约束，偶尔出现非物理的速度向量；
- 依赖于 LiDAR‑基于 DOGM，若传感器覆盖不足仍会出现未知状态误差；
- 未引入道路地图或轨迹规划信息，缺乏对路面几何的显式建模。

---

## 473. CausalArmor: Efficient Indirect Prompt Injection Guardrails via Causal Attribution

**arXiv ID:** 2602.07918 | [PDF](https://arxiv.org/pdf/2602.07918v1)

**作者:** Minbeom Kim `[一作]` (Seoul National University), Tomas Pfister `[通讯]` (Google Cloud AI Research)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了CausalArmor，一种针对工具调用式LLM代理的可解释且高效的间接提示注入防御框架。

**💡 创新点**

通过将间接提示注入定义为在特权决策上的因果优势转移（dominance shift），并利用归因检测仅在发现该转移时触发昂贵的消毒和思路掩码，从而解决了过度防御带来的效用与延迟损失问题。

**🔧 技术方法**

利用批量化留一法（LOO）归因、归因归一化、基于代理模型的归因计算、选择性内容消毒与链式思路掩码等技术。

**📊 数据集**

在AgentDojo和DoomArena这两个公开的工具代理安全基准上进行评估。

**📈 对比分析**

与提示、防御分类器和系统级防御方法比较，CausalArmor在攻击成功率几乎为零的同时保持了与无防御相近的善意效用和延迟；在AgentDojo上攻击成功率下降到接近0，延迟提升仅为0.4%，而在DoomArena上则将攻击成功率从88.9%降至约3.6%。

**⚠️ 局限性**

依赖于代理模型的归因准确性、消毒器的有效性以及对特权行为的前置假设；在极端自适应攻击或跨模态场景下，归因信号可能被稀释，且如果归因阈值设置不当会导致误报或漏报。

---

## 474. AceGRPO: Adaptive Curriculum Enhanced Group Relative Policy Optimization for Autonomous Machine Learning Engineering

**arXiv ID:** 2602.07906 | [PDF](https://arxiv.org/pdf/2602.07906v1)

**作者:** Yuzhu Cai `[一作]` (Beihang University), Siheng Chen `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 8571 | [OpenAlex ID](https://openalex.org/A5066373402)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了AceGRPO框架，用强化学习方法训练大语言模型（LLM）以实现自主机器学习工程（MLE）的持续自我进化。

**💡 创新点**

创新点包括：①Evolving Data Buffer将每一次昂贵的执行轨迹拆解为可重复使用的单步训练任务；②Adaptive Sampling通过Learnability Potential动态优先选择处于学习前沿的状态，提升样本效率并防止梯度信号衰减；③将长周期MLE优化转化为步进式学习，兼顾高延迟执行与稀疏反馈。

**🔧 技术方法**

技术主要包括：基于GRPO（Group Relative Policy Optimization）的强化学习策略；对即时奖励进行混合绝对与相对改进的奖励塑形；异步工作流（Rollout Worker + Learner）以处理高延迟；以及多阶段任务类型（Draft、Debug、Improve）的缓冲区管理。

**📊 数据集**

数据集：使用MLE-Dojo（共134个Kaggle竞赛任务）进行训练，评估使用MLE-Bench-Lite（22个Kaggle任务）并对比多款开源与闭源基线。

**📈 对比分析**

与基线对比：在MLE-Bench-Lite上，Ace-30B模型实现100%有效提交率、51.52%奖牌率、0.7114 HumanRank分数，显著优于同尺寸的Qwen3-30B基线，并接近或超过大型闭源模型（如GPT‑5.2、Claude‑4.5‑Sonnet），同时超过更大开源模型（如DeepSeek‑V3.2、Qwen3‑235B）。

**⚠️ 局限性**

局限性：1）训练过程仍依赖昂贵的MLOps执行，虽然通过步进式方法降低成本但总体仍高；2）对buffer中状态的采样仍可能出现“资源分配失衡”，需进一步优化冷却机制；3）实验主要聚焦于Kaggle式竞赛任务，尚未验证在更广泛的工业级MLE场景中的泛化能力。

---

## 475. GCN-MPPR: Enhancing the Propagation of Message Passing Neural Networks via Motif-Based Personalized PageRank

**arXiv ID:** 2602.07903 | [PDF](https://arxiv.org/pdf/2602.07903v1)

**作者:** Mingcan Wang `[一作]` (Northeastern University), Zhiqiong Wang `[通讯]` (Northeastern University)

**通讯引用:** 1702 | [OpenAlex ID](https://openalex.org/A5103215657)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a2602d71-93ab-4bad-974b-672788df8193` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出一种基于图动机的个性化PageRank（MPPR）并将其融入GCN，形成GCN‑MPPR模型，解决了MPNN过度平滑、深度不足和缺乏高阶关系捕捉等问题。

**💡 创新点**

创新点在于：①将高阶图动机信息与传统PageRank相结合，构造MPPR；②将MPPR作为消息传播机制，使GCN无需加深层数即可实现更深层次的信息扩散；③将MPPR视为可插拔模块，能提升多种GCN框架性能。

**🔧 技术方法**

采用图卷积网络（GCN）、个性化PageRank、图动机识别与矩阵运算、交叉熵/二元交叉熵训练、对数似然等技术。

**📊 数据集**

使用节点分类数据集Cora、PubMed、Amazon computers、Amazon photo；使用链接预测数据集同四个集；并在基因调控网络数据（in silico、S. cerevisiae）上验证。

**📈 对比分析**

与GCN、GAT、GIN、PPNP、APPNP、PPRGo、SHP‑GNN等节点分类基线以及GAE、VGAE、HDGL等链接预测基线对比；GCN‑MPPR在准确率、稳定性（方差）和训练时间上均优于绝大多数基线，节点分类AUC/AP、准确率提升数个百分点；在链接预测中AUC/AP也保持领先或相当。

**⚠️ 局限性**

局限性：在训练迭代过多时容易出现过拟合，性能下降；对极大图的稀疏性处理仍有提升空间；仅在七种三节点动机上验证，其他高阶动机需进一步探索。

---

## 476. MemFly: On-the-Fly Memory Optimization via Information Bottleneck

**arXiv ID:** 2602.07885 | [PDF](https://arxiv.org/pdf/2602.07885v1)

**作者:** Zhenyuan Zhang `[一作]` (Hong Kong University of Science and Technology), Yike Guo `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 18574 | [OpenAlex ID](https://openalex.org/A5045081171)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 MemFly 框架，实现 LLM 代理的长时记忆优化；

**💡 创新点**

将长时记忆建模为在线信息瓶颈问题，采用 LLM 作为无梯度 JS‑divergence 近似器，并引入 Note‑Keyword‑Topic 三层双聚类结构与三路检索＋迭代精炼；

**🔧 技术方法**

信息瓶颈理论、LLM 语义评估、双聚类与图结构、Reciprocal Rank Fusion、迭代证据精炼；

**📊 数据集**

LoCoMo 长对话基准；

**📈 对比分析**

与 LoCoMo、ReadAgent、MemoryBank、MemGPT、A‑MEM、Mem0 等六种基线对比，平均 F1 与 BLEU‑1 均显著提升，尤其在开放域和多跳推理任务上领先 5‑10%；

**⚠️ 局限性**

构建速度慢，计算开销较大；仅验证文本场景，缺乏多模态与领域特定评估。

---

## 477. Sharp analysis of linear ensemble sampling

**arXiv ID:** 2602.08026 | [PDF](https://arxiv.org/pdf/2602.08026v1)

**作者:** Arya Akhavan `[一作]` (University of Oxford), Csaba Szepesvári `[通讯]` (University of Alberta)

**通讯引用:** 16803 | [OpenAlex ID](https://openalex.org/A5069856068)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `de8d30ba-c289-43a5-b4ec-7b80df73aea2`

**🎯 论文内容**

分析了随机线性赌博机中的线性集成采样（ES）与标准高斯扰动的关系，证明了在集成大小为m=Θ(dlog n)的情况下，ES可以达到Õ(d^3/2√(n))的高概率后悔，缩小了与汤普森采样基准的差距，同时保持了计算复杂度的可比性。

**💡 创新点**

通过将分析简化为时间均匀超越问题，提供了对线性赌博机中随机探索的新视角，首次实现了ES在大规模或无限动作集上的有效性，解决了之前研究中的性能差距。

**🔧 技术方法**

使用了高斯扰动和独立布朗运动的随机过程分析技术，结合了自归一化的对角高斯鞅变换的时间均匀超越控制。

**📊 数据集**

论文中没有具体提到使用的数据集，但讨论了在标准随机线性赌博机环境下的理论结果。

**📈 对比分析**

与汤普森采样（TS）进行比较，ES在集成大小为Θ(dlog n)的情况下，后悔率达到了Õ(d^3/2√(n))，与TS的后悔率相匹配，且计算复杂度保持在可接受范围内。

**⚠️ 局限性**

限制在于对于集成大小m的选择，若m过小（如m≤d/2），则可能导致线性后悔。此外，当前的分析主要集中在高斯扰动上，尚不清楚是否可以推广到其他扰动分布。

---

## 478. Continuity-driven Synergistic Diffusion with Neural Priors for Ultra-Sparse-View CBCT Reconstruction

**arXiv ID:** 2602.07980 | [PDF](https://arxiv.org/pdf/2602.07980v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 479. ICBAC: an Intelligent Contract-Based Access Control framework for supply chain management by integrating blockchain and federated learning

**arXiv ID:** 2602.08014 | [PDF](https://arxiv.org/pdf/2602.08014v1)

**作者:** Sadegh Sohani `[一作]` (Ferdowsi University of Mashhad), Kaiwen Zhang `[通讯]` (École de technologie supérieure)

**通讯引用:** 3256 | [OpenAlex ID](https://openalex.org/A5025108369)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `c84dae5d-5273-4348-85a7-b44cb586b4df` `3855fcda-48ef-4070-a15e-803cd5c84d83` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出 ICBAC 框架，将 Hyperledger Fabric 与联邦学习结合，实现多通道智能合约驱动的动态、AI 监控式访问控制；

**💡 创新点**

创新点包括：① 基于多通道的细粒度权限控制与智能合约；② 联邦学习支持的行为异常检测；③ 采用友谊图与 SCC 算法的博弈论联盟形成机制，保证核心稳定与无策略性；④ 在供应链场景下实现零原始数据泄露；

**🔧 技术方法**

使用技术包括 Hyperledger Fabric 权限链与多通道、智能合约、AI 监控智能体、联邦学习（FedAvg）、滑动窗口序列模型、博弈论友谊联盟形成（SCC）和 Tarjan 算法；

**📊 数据集**

数据集为 DataCoSupplyChain（约 18 万条供应链交易记录），按 23 区域划分为通道，并在 10% 记录中注入人工异常；

**📈 对比分析**

性能比较：在区块链层与 MedTrace、AccessChain、ProChain 等静态框架做事务吞吐/延迟 t‑检验，结果差异不显著；在联邦学习层与中心模型比较，IID 场景 FL 与中心接近，Non‑IID 场景中心更优；联盟协同提升收敛速度与 F1 分数，读操作延迟略高但无显著差异；

**⚠️ 局限性**

局限性：在非 IID 联邦学习下性能仍受限，读操作延迟略高；联盟一经形成后不易动态更新；跨链互操作性尚未实现。

---

## 480. A Unified Density Operator View of Flow Control and Merging

**arXiv ID:** 2602.08012 | [PDF](https://arxiv.org/pdf/2602.08012v1)

**作者:** Riccardo De Santi `[一作]` (ETH Zürich), Andreas Krause `[通讯]` (ETH Zürich)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `40105733-5154-44cd-8090-a8cab9e64b07` `a8e75ba4-7a2d-4153-b003-06c94533add0` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

在生成模型中提出一种概率空间优化框架，统一了流模型的控制（reward‑guided fine‑tuning）与合并（flow merging），并通过镜像下降算法实现奖励导向的流合并。

**💡 创新点**

创新点在于：①将控制与合并统一为一个泛化的密度算子框架；②引入可表达交集、并集、插值及逻辑表达式的算子；③提出基于镜像下降的可实现算法，并给出理论收敛保证；④在交集算子中解决了score在 t=1 处发散的问题，提出全流程优化方案。

**🔧 技术方法**

使用的方法包括：概率空间优化、镜像下降（Mirror Descent）、基于控制/强化学习的标准 fine‑tuning、score 网络估计、Wasserstein barycenter 算子、逆 KL 与前向 KL 等多样化散度；实现上采用 flow / diffusion 模型的 ODE 形式、分数网络、逆 GAN 判别器。

**📊 数据集**

使用的数据集包括化学分子设计任务：GEOM‑Drugs（预训练 FlowMol 模型）、QM9 以及分子构象生成的 ETFlow 模型；此外在可视化实验中使用二维分布示例。

**📈 对比分析**

与传统的单模型 reward‑guided fine‑tuning 和现有的流合并方法对比，实验表明：①奖励导向交集能在重叠区域聚焦高奖励，取得更低的能量；②平衡/不平衡并集能实现可控的属性插值；③在分子生成任务中，交集模型的能量均值低于基线且有效率高；整体性能优于现有方法，并在多个指标（能量、偶极、HOMO‑LUMO、最小能量）上表现相近或更佳。

**⚠️ 局限性**

局限性包括：①需要对分数网络进行训练，计算开销较大；②交集算子在 t→1 时分数发散，需引入加权估计，复杂度提升；③理论证明基于正则化的前向过程收敛到高斯噪声的假设，实际中可能受限；④对高维连续空间的扩展仍需进一步评估，算法迭代次数较多。

---

## 481. When Is Compositional Reasoning Learnable from Verifiable Rewards?

**arXiv ID:** 2602.07992 | [PDF](https://arxiv.org/pdf/2602.07992v1)

**作者:** Daniel Barzilai `[一作]` (Weizmann Institute of Science), Ronen Basri `[通讯]` (Weizmann Institute of Science)

**通讯引用:** 14058 | [OpenAlex ID](https://openalex.org/A5101453970)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

本文通过理论分析，研究了在仅有可验证奖励的强化学习（RLVR）下，语言模型如何学习到正确的链式推理，并提出了任务优势比（task‑advantage ratio）来刻画学习可行性。

**💡 创新点**

创新之处在于首次用任务优势比量化RLVR对中间步骤的学习动力，证明了在具备“归纳结构”或足够优的基模型时能多项式收敛，而在无优势时可能陷入次优解，并给出基模型质量阈值。

**🔧 技术方法**

技术手段包括构造基于确定性任务的自回归模型、推导REINFORCE的期望梯度、分析任务优势比、证明收敛速度与组合长度的二次关系，并通过合成例子展示正负两种情形。

**📊 数据集**

使用的并非公开数据集，而是以平面随机位元或两状态为例的合成问题（如位偶校验、两状态任务），用来演示任务优势比的大小与学习难易度的关系。

**📈 对比分析**

方法上通过理论证明来比较，不做实验；性能上给出在满足统一任务优势假设时，RLVR在 O(S² log(S/ε)) 步内即可以 1‑ε 的准确率收敛；若优势指数级衰减，则迭代复杂度指数级增长；基模型优劣阈值为 p₀=1/3。

**⚠️ 局限性**

局限性在于模型假设过于理想（确定性任务、正交位置编码、无KL正则化等），缺乏对真实LLM推理任务的实验验证；任务优势比的计算在实际中难以获得；且仅分析了纯奖励反馈的最优/次优收敛，未考虑探索、采样方差等实际问题。

---

## 482. LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth

**arXiv ID:** 2602.07962 | [PDF](https://arxiv.org/pdf/2602.07962v1)

**作者:** Weihao Zeng `[一作]` (Hong Kong University of Science and Technology), Junxian He `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 2820 | [OpenAlex ID](https://openalex.org/A5015879697)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并实现了一套可控极端上下文增长的长期代理任务基准LOCA‑bench，评估LLM在探索、指令遵循、信息检索与决策等场景中的表现；

**💡 创新点**

创新点在于：1) 通过可自动扩展的环境状态实现对上下文长度的精细控制；2) 引入多维度失效模式分析（推理衰退、指令遗忘、探索不足、幻觉等）；3) 在基准中集成多种上下文工程策略并对比其效果；

**🔧 技术方法**

采用的技术包括：自动化环境生成（Mock Server + 模板/生成器）、ReAct代理框架、上下文工程技术（工具结果清理、思考块清理、上下文压缩、上下文感知、记忆工具、程序化工具调用）以及多模型评估；

**📊 数据集**

使用的数据集为基于Toolathlon的15个种子任务，通过可调节参数生成多达8K–256K tokens的环境描述，共计525个样本；

**📈 对比分析**

方法：在每个模型最大上下文长度下，利用ReAct代理在不同环境描述长度（8K、16K、32K、64K、96K、128K、256K）执行任务；性能表现为：在短上下文下准确率>70%，但随长度增加显著下降，前沿模型在128K时仍可达约30%准确率，而开源模型仅能维持10%以下；上下文工程策略能显著提升准确率（如程序化工具调用可提升数个百分点）；

**⚠️ 局限性**

局限性包括：1) 评估主要基于模拟环境，缺乏真实世界动态复杂性；2) 任务范围仍受限于Toolathlon的任务设计；3) 部分上下文工程实现受限于公开API，无法完全复制商业模型的内部优化；4) 结果受ReAct框架与工具实现细节影响，缺乏跨框架的广泛验证。

---

## 483. Diverge to Induce Prompting: Multi-Rationale Induction for Zero-Shot Reasoning

**arXiv ID:** 2602.08028 | [PDF](https://arxiv.org/pdf/2602.08028v1)

**作者:** Po-Chun Chen `[一作]` (National Taiwan University), Hsin-Hsi Chen `[通讯]` (National Taiwan University)

**通讯引用:** 7143 | [OpenAlex ID](https://openalex.org/A5000334344)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出DIP框架，先让LLM一次性生成多条高层理由，再把每条理由扩展为草案计划，最后通过诱导把所有草案合成为最终计划并执行推理。

**💡 创新点**

突破单一路径的局限，利用多理由多计划的诱导方式在一次调用中获得多样化思路，避免盲点且不需采样或投票；通过LLM自身的归纳能力实现最终计划的生成。

**🔧 技术方法**

多阶段提示（Prompting）+基于LLM的诱导推理（induction），不使用额外采样或投票模块，全部在模型内部完成。

**📊 数据集**

在BIG‑Bench Hard (BBH) 与 LiveBench Reasoning 这两个英文推理基准上进行评测。

**📈 对比分析**

与零样本Chain‑of‑Thought（Z‑CoT）、Strategic/ Rationale CoT（S‑CoT/R‑CoT）以及Self‑Consistency（SC）等基线对比，DIP在BBH上整体提升0.58–6.72个百分点，在LiveBench上提升0.5–30.50个百分点，且在多模型、多任务上保持领先。

**⚠️ 局限性**

计算成本提升（生成多理由和多草案需更多API调用），适用于高复杂度多步推理任务；对简单事实检索或常识问答效果有限；实验仅覆盖英文和部分LLM家族，跨语言或领域的通用性待验证。

---

## 484. FlashVID: Efficient Video Large Language Models via Training-free Tree-based Spatiotemporal Token Merging

**arXiv ID:** 2602.08024 | [PDF](https://arxiv.org/pdf/2602.08024v1)

**作者:** Ziyang Fan `[一作]` (Harbin Institute of Technology), Zhuotao Tian `[通讯]` (Shenzhen Loop Area Institute)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了FlashVID，一种训练‑free、可插拔的加速框架，能够在视频大语言模型推理中显著压缩视觉令牌，保持或提升性能；

**💡 创新点**

创新点在于将注意力与多样性相结合的令牌选择（ADTS）与树形时空令牌合并（TSTM）两种模块协同工作，首次针对视频的时空相关性构造冗余树，实现细粒度压缩；

**🔧 技术方法**

使用了基于注意力加权的最大-最小多样性选择（Max‑Min Diversity Problem）以及余弦相似度阈值驱动的树形合并算法，并与现有视觉编码器、LLM的预填层相集成；

**📊 数据集**

在五个主流视频理解基准（VideoMME、EgoSchema、LongVideoBench、MVBench、MLVU）以及三种代表性VLLM（LLaVA‑OneVision、LLaVA‑Video、Qwen2.5‑VL）上进行评估；

**📈 对比分析**

与FastV、VisionZip、PruneVID、FastVID等四种最先进的训练‑free加速方法对比，FlashVID在10%令牌保留时保持99.1%原模型性能，在Qwen2.5‑VL上通过压缩实现10倍帧数输入，获得8.6%的相对提升，同时实现6.3×预填速率和2.1×TTFT加速；

**⚠️ 局限性**

主要局限在于仅针对视觉令牌压缩，未探索跨模态扩展；压缩树构建的阈值选择对不同场景可能需要手动调优；目前仅在三种VLLM上验证，泛化性仍待进一步探索。

---

## 485. Small Agent Group is the Future of Digital Health

**arXiv ID:** 2602.08013 | [PDF](https://arxiv.org/pdf/2602.08013v1)

**作者:** Yuqiao Meng `[一作]` (State University of New York at Binghamton), Zhaohan Xi `[通讯]` (State University of New York at Binghamton)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出小型代理组（SAG）在临床决策中的协同推理框架，并系统评估其在诊断准确性、可靠性与部署成本方面的表现。

**💡 创新点**

创新点在于将多代理角色分工（推理、检索、审核、合成）与辩论式交互相结合，利用小模型的协同效应弥补单一大模型的认知与鲁棒性缺陷，从而在规模、可靠性与可部署性上实现三角平衡。

**🔧 技术方法**

技术手段包括：多代理辩论（MAD）架构、检索增强生成（RAG）与外部医学知识库、策略优化（GRPO）与集中训练/去中心化执行（CTDE）以及多种小型LLM（如 Llama‑3.2‑3B、Qwen‑3‑4B）构建代理。

**📊 数据集**

使用的基准数据集涵盖诊断与问答任务，如 NEJM/GPQA、EquityMedQA、Clinical QA、MED‑QA 等多种公开临床评测集。

**📈 对比分析**

对比方法：将 SAG 与单一 70B/72B 大模型、医学专用 70B 模型以及无优化/不同优化策略的 SAG 进行实验。评估指标包括诊断正确率、BLEU‑4/BERTScore、对比公平度（CDR）、ROC 安全性曲线、鲁棒性/一致性以及 GPU 内存、FLOPs 与延迟。实验表明，SAG 在诊断正确性、证据相关性、鲁棒性与公平性方面均优于单体模型，且在安全性曲线中取得更高的拒绝率与更低的误拒率。

**⚠️ 局限性**

局限性：SAG 仍需更长的推理时间与较高的计算开销，代理数量与交互轮次对性能敏感；在极低资源环境或实时临床场景下的部署仍面临挑战，且目前缺乏对异常输入下完全无误判的理论保证。

---

## 486. Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective

**arXiv ID:** 2602.08009 | [PDF](https://arxiv.org/pdf/2602.08009v1)

**作者:** Rui Li `[一作]` (Renmin University of China), Xu Chen `[通讯]` (Renmin University of China)

**通讯引用:** 22091 | [OpenAlex ID](https://openalex.org/A5100385692)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 RAPS 框架，利用声誉感知的发布-订阅机制实现 LLM 代理的自适应、可扩展与鲁棒的分布式协同。

**💡 创新点**

创新点在于将多智能体协同视为动态自组网络，引入 Reactive Subscription 以动态调整代理意图，加入 Bayesian Reputation 作为去中心化的可信度评估，构建了完整的分布式通信与安全保障体系。

**🔧 技术方法**

核心技术包括：分布式 Publish‑Subscribe 协议、基于 LLM 的发布者与订阅者模块、嵌入式匹配与可选 LLM‑驱动的 Broker、Reactive Subscription（意图重写）、贝叶斯声誉模型（第一手评价、间接见证融合）和局部 watchdog。

**📊 数据集**

使用五大基准：MMLU（常识推理）、GSM8K、SVAMP、AQuA（数学推理）以及 HumanEval（代码生成），覆盖多领域任务。

**📈 对比分析**

与静态拓扑、通信无关、元控制等四类主流方法对比，RAPS 在所有任务上平均准确率 90.0%，在 MMLU、GSM8K、HumanEval 上分别提升 3.2%、1.7% 及 1.8%，在对抗性测试中保持高鲁棒性；且随代理数量增大时准确率稳定提升，运行时延保持可接受。

**⚠️ 局限性**

局限性包括：对 LLM 推理成本敏感；在极大规模代理池或真实工业环境下的性能与安全性待进一步验证；声誉模型依赖经验参数，若数据偏差或攻击策略改变，鲁棒性可能下降。

---

## 487. Space Complexity Dichotomies for Subgraph Finding Problems in the Streaming Model

**arXiv ID:** 2602.08002 | [PDF](https://arxiv.org/pdf/2602.08002v1)

**作者:** Yu-Sheng Shih `[一作]` (National Taiwan University), Ying-Sian Wu `[通讯]` (National Taiwan University)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文研究了在数据流环境下固定模式子图检测问题，提出了完整的可判定与不可判定模式图的分离（二分）结果；

**💡 创新点**

创新点在于将模式图的Turán数与流算法空间复杂度关联，首次给出所有模式图的流复杂度二分法，并设计了稀疏证书和颜色编码的组合算法；

**🔧 技术方法**

采用了通信复杂度归约、色彩编码、k-core 抽样（ℓ0采样器）等技术；

**📊 数据集**

未使用实际数据集，主要基于理论分析与模拟；

**📈 对比分析**

通过与已知下界对比，算法在理论上匹配或接近下界，在最坏情况下可达线性或多项式空间；

**⚠️ 局限性**

局限性在于对非良好定向图的多通道算法尚未完全确定，单通道仅适用于具有有限 NWO 顶点的树或森林。

---

## 488. Analyzing the Impact of Simulation Fidelity on the Evaluation of Autonomous Driving Motion Control

**arXiv ID:** 2602.07984 | [PDF](https://arxiv.org/pdf/2602.07984v1)

**作者:** Simon Sagmeister `[一作]` (Technical University of Munich), Markus Lienkamp `[通讯]` (Technical University of Munich)

**通讯引用:** 7486 | [OpenAlex ID](https://openalex.org/A5079718896)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `51c0528b-f690-4182-ae60-bb5f046c276c` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在自动驾驶仿真中，研究了不同车辆动力学模型简化对轨迹跟踪控制器闭环行为的影响，构建并发布了可与Autoware兼容的多体车辆模型，并对其简化版本进行系统评估。

**💡 创新点**

首次将模型简化程度与闭环控制性能量化，证明了轮胎参数精确化比动态负载转移更重要，同时提供了可直接用于算法对比的开源模型和评估指标。

**🔧 技术方法**

使用多体动力学建模、Pacejka魔法公式（基本版与完整版）、线性轮胎模型、负载转移简化、驱动器动态建模，结合Dormand–Prince 45积分器与C++实现；仿真架构基于Autoware接口和CycloneDDS；引入三维赛道几何与传感器模拟。

**📊 数据集**

利用2023年6月在Autodromo Nazionale di Monza举行的Indy Autonomous Challenge赛道上收集的真实行驶数据（Dallara AV‑21赛车轨迹、速度与侧向加速度），并在此基础上进行速度比例扩展的仿真实验。

**📈 对比分析**

通过比较最大横向偏差（max lateral error）和误差相似度（error disparity）两项指标，对比550次仿真与实车数据，发现完整多体模型与改进的轮胎参数模型误差均低于40%，而简化模型在高侧向加速度下误差指数级放大，说明模型精度直接决定仿真评估的可靠性。

**⚠️ 局限性**

局限性包括仅在一台高刚度赛车上验证，其他车型可能表现不同；实验采用的鲁棒MPC控制器可能掩盖部分模型差异；仿真环境存在非确定性；对扩展速度的仿真缺乏对应实车数据验证。

---

## 489. Accuracy-Delay Trade-Off in LLM Offloading via Token-Level Uncertainty

**arXiv ID:** 2602.07958 | [PDF](https://arxiv.org/pdf/2602.07958v1)

**作者:** Yumin Kim `[一作]` (Seoul National University), Hyun Jong Yang `[通讯]` (Seoul National University)

**通讯引用:** 1459 | [OpenAlex ID](https://openalex.org/A5031190689)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种基于Token级不确定度的LLM推理边缘卸载框架，并设计了贪心卸载算法（GOA）来动态决定本地推理或向边缘服务器卸载，以平衡推理准确性与延迟；

**💡 创新点**

创新点在于首次将Token级置信度（margin‑based uncertainty）作为卸载决策的权重，结合资源约束构造非凸优化问题并给出可行的贪心求解策略；

**🔧 技术方法**

使用了边缘计算系统模型、Rayleigh信道下的SINR与带宽分配、LLM推理时间缩放、Token级不确定度度量、以及Python3.13.5+NVIDIA RTX 6000 Ada GPU实现的仿真；

**📊 数据集**

实验采用bAbI数据集，并用LLaMA 3.2‑1B‑Instruct作为SLM、LLaMA 3.2‑8B‑Instruct作为LLM进行推理；

**📈 对比分析**

与Edge all、Local all、Min delay、Random等基线进行对比，GOA在不同用户密度下实现了接近Edge all的准确率，却比其延迟低约25%，且与Min delay延迟相近，计算时间仅为414 ms；

**⚠️ 局限性**

局限性包括仅使用首个Token的置信度（无法捕捉长文本不确定度）、仅验证短答案场景、对动态网络变化和更大模型规模的鲁棒性尚未充分评估。

---

## 490. Beyond Raw Detection Scores: Markov-Informed Calibration for Boosting Machine-Generated Text Detection

**arXiv ID:** 2602.08031 | [PDF](https://arxiv.org/pdf/2602.08031v1)

**作者:** Chenwang Wu `[一作]` (Hong Kong Baptist University), Defu Lian `[通讯]` (University of Science and Technology of China)

**通讯引用:** 8291 | [OpenAlex ID](https://openalex.org/A5085254654)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于马尔可夫随机场的分数校准方法，提升机器生成文本检测器的准确性

**💡 创新点**

先从理论和实验上揭示token级检测分数的邻近相似性与首部不稳定性，并利用马尔可夫模型捕获这些关系，随后通过均值场近似实现轻量级校准模块，可无缝叠加到现有指标化检测器上

**🔧 技术方法**

马尔可夫随机场（MRF）、均值场近似、位置加权函数、标记化token级概率评分、阈值检测、单层Transformer理论分析

**📊 数据集**

Essay、Reuters、DetectRL、TruthfulQA 四个公开数据集，涵盖多种LLM（GPT4All、ChatGPT、ChatGLM、Claude 等）

**📈 对比分析**

与多种基线（Log‑Likelihood、Log‑Rank、Entropy、DetectGPT、Fast‑DetectGPT、DNA‑GPT 等）以及模型化检测器比较；校准后AUROC普遍提升 5–30%（对弱基线如DetectGPT提升高达 37%），并在跨LLM、跨域、混合文本与改写攻击场景中保持优越性

**⚠️ 局限性**

仅适用于提供token‑级检测分数的指标化方法，对不产生细粒度分数的检测器不可直接使用；模型参数极少，但需在训练集上学习两参数，过度简化可能忽略更复杂上下文依赖

---

## 491. Computing submatrices of the Hermite normal form of a structured polynomial matrix

**arXiv ID:** 2602.08027 | [PDF](https://arxiv.org/pdf/2602.08027v1)

**作者:** Jérémy Berthomieu `[一作]` (Sorbonne Université), Hugo Passe `[通讯]` (Sorbonne Université)

**关键词:** `847a60d8-a755-47af-ba5d-c5236b9e3083` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种加速计算具有小位移秩的多项式矩阵的Hermite标准形（HNF）主子矩阵的方法。

**💡 创新点**

创新点在于利用位移结构来加速计算HNF的主子矩阵，特别是在处理具有小位移秩的多项式矩阵时。

**🔧 技术方法**

使用了结构化线性代数和评估-插值技术，结合快速的随机化算法。

**📊 数据集**

使用了具有小位移秩的多项式矩阵作为输入数据集。

**📈 对比分析**

与传统的HNF算法相比，本文的方法在计算HNF主子矩阵时具有更低的复杂度，尤其是在特定条件下，性能显著提升。

**⚠️ 局限性**

限制在于算法的有效性依赖于输入矩阵的结构特性，且在某些情况下可能无法保证返回结果。

---

## 492. MIND: Benchmarking Memory Consistency and Action Control in World Models

**arXiv ID:** 2602.08025 | [PDF](https://arxiv.org/pdf/2602.08025v1)

**作者:** Yixuan Ye `[一作]` (Central South University), Alex Jinpeng Wang `[通讯]` (Central South University)

**通讯引用:** 1 | [OpenAlex ID](https://openalex.org/A5061458314)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `ba576bd1-e51d-44e8-8077-fc943b333c93` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个开放域闭环重访的基准，用于评估世界模型在第一人称和第三人称视角下的记忆一致性和动作控制能力

**💡 创新点**

创新点：①创建首个覆盖八类场景、1080p/24fps、包含第一/第三人称视角、可调动作空间的开放域基准；②设计内存一致性与动作控制的评估框架；③引入多种动作空间与对称运动路径进行动作泛化与生成场景一致性评估；④发布基线MIND‑World

**🔧 技术方法**

使用Unreal Engine 5渲染视频，基线采用基于动作注入的自回归扩散模型，训练三阶段：教师双向动作条件模型、学生初始化、DMD自强蒸馏；评估使用MSE、动作误差、视觉质量等指标

**📊 数据集**

基准视频集包含250段1080p/24fps视频（100第一人称+100第三人称共享动作空间，25+25不同动作空间），覆盖8大场景类

**📈 对比分析**

与多种现有世界模型/视频生成模型比较，基线MIND‑World在内存一致性、动作精度、动作泛化和视觉质量上表现最佳，未使用记忆的模型性能显著落后；实验表明记忆机制提升4%+的长期记忆一致性，动作误差较低

**⚠️ 局限性**

限制：难以在开放域下实现跨动作空间泛化；记忆机制受限于与训练动作空间不一致时会干扰推理；动作控制精度仍不稳定；长时记忆仍偏短；第三人称视角中的人物与背景交互不准确

---

## 493. From $O(mn)$ to $O(r^2)$: Two-Sided Low-Rank Communication for Adam in Distributed Training with Memory Efficiency

**arXiv ID:** 2602.08007 | [PDF](https://arxiv.org/pdf/2602.08007v1)

**作者:** Sizhe Dang `[一作]` (Xi'an Jiaotong University), Haishan Ye `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 2288 | [OpenAlex ID](https://openalex.org/A5068724396)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种两侧低秩通信机制TSR-Adam，在分布式训练中仅同步梯度的 r×r 核心，显著降低梯度同步量，并通过随机化SVD刷新保持子空间有效性，同时扩展到嵌入层梯度。

**💡 创新点**

创新点在于：① 用两侧低秩投影只同步 O(r²) 大小的核心，突破传统单侧低秩仅同步 O(rn) 的瓶颈；② 采用随机化SVD刷新，避免全梯度同步峰值；③ 为嵌入层提供独立的秩和刷新策略；④ 在 Adam 家族中保持低维状态，兼顾内存与通信。

**🔧 技术方法**

使用技术包括：低秩压缩、两侧投影、随机化SVD刷新、AdamW 优化器、分布式 All-Reduce、嵌入层专属低秩、子空间刷新间隔控制。

**📊 数据集**

实验数据集：预训练使用 C4 数据集训练 LLaMA 系列模型（60M、130M、350M、1B）；微调使用 GLUE 语义理解基准对 RoBERTa‑Base 进行评测。

**📈 对比分析**

与密集 AdamW、GaLore、GreedyLore 等传统方法对比，TSR-Adam 在 60M‑1B 模型规模下平均每步通讯量比 AdamW 低 13×，在 GLUE 微调时通讯量低 25×，且在最终损失或任务准确率上与基线相当或略优，显示出更高的字节‑损失效率。

**⚠️ 局限性**

局限性：需要手动选择合适的秩 r 与刷新间隔 K，过小的 r 可能导致子空间误差过大；随机化SVD 刷新仍需额外计算，且峰值通信受 sketch 大小限制；对极大规模（>10B 参数）模型的实测尚不足；嵌入层低秩压缩受词表大小影响，部分场景仍存在显著通信。

---

## 494. DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity

**arXiv ID:** 2602.08005 | [PDF](https://arxiv.org/pdf/2602.08005v1)

**作者:** Jitai Hao `[一作]` (Harbin Institute of Technology), Jun Yu `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 61114 | [OpenAlex ID](https://openalex.org/A5100456229)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过残差编码利用全局相似性压缩 KV 缓存，降低内存占用并提升长上下文推理速度。

**💡 创新点**

创新点在于将 KV 缓存视为共享潜在成分加低能量残差，使用全局参考的残差压缩，而非仅靠局部性或直接压缩。

**🔧 技术方法**

技术包括残差计算、基于最近邻全局参考选择、轻量 MLP/线性压缩、混合 MSE+NTP 训练目标、与稀疏注意力 OmniKV 结合，以及专门实现的 Sparse‑vLLM 推理框架。

**📊 数据集**

使用的数据集为 LongBench、SCBench、AIME，模型包括 Llama‑3.1‑8B、Qwen2.5‑7B、Qwen2.5‑32B 等。

**📈 对比分析**

与 SnapKV、PyramidKV、AdaKV、OmniKV、Quest 等基线比较，DeltaKV 在 KV 保留率约 29% 的情况下保持近乎无损准确性；在 Sparse‑vLLM 上可获得高达 2× 的解码吞吐量。

**⚠️ 局限性**

局限在于需要额外训练 DeltaKV 模块，虽然只需 8 GPU 小时，但仍是开销；在极端多轮对话或结构化任务中可能略逊于静态裁剪方法，且对极长上下文的泛化仍需进一步验证。

---

## 495. Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality

**arXiv ID:** 2602.08004 | [PDF](https://arxiv.org/pdf/2602.08004v1)

**作者:** George Ling `[一作]` (Bosch Research), Richard Huang `[通讯]` (Bosch Research)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文对 40,285 条公开 agent 技能进行大规模量化分析，研究了技能发布、使用、冗余与安全风险。

**💡 创新点**

创新点在于首次系统性量化技能生态的增长脉冲、意图级冗余、供应-需求失衡及风险分布，并提出对策建议。

**🔧 技术方法**

采用爬取公开 marketplace、token 计数、基于名称和语义的去重、两级分类法、LLM 风险审核（Qwen2.5-32B-Instruct）等技术手段进行分析。

**📊 数据集**

使用 skill.sh 市场的 40,285 条技能元数据及对应 SKILL.md 文档作为数据集。

**📈 对比分析**

通过对比发布量与安装量、平均 token 长度以及风险级别分布，发现软件工程占比最大、内容创作需求高、信息检索需求大但供应少；大多数技能低风险但仍有 9% 处于最高风险。

**⚠️ 局限性**

局限性包括仅基于单一时间点快照，采用公开安装数作为采用指标可能低估私有部署，且去重与风险评估均依赖自动化模型。

---

## 496. Don't Always Pick the Highest-Performing Model: An Information Theoretic View of LLM Ensemble Selection

**arXiv ID:** 2602.08003 | [PDF](https://arxiv.org/pdf/2602.08003v1)

**作者:** Yigit Turkmen `[一作]` (Bilkent University), Melih Bastopcu `[通讯]` (Bilkent University)

**通讯引用:** 239 | [OpenAlex ID](https://openalex.org/A5000544057)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种在有限查询预算下选择大型语言模型（LLM）子集的框架，用信息理论衡量子集对真实标签的互信息并以此进行贪婪选择。

**💡 创新点**

创新点在于将LLM错误相关性建模为高斯copula，给出误差饱和上界，证明当模型相关性强时Top‑k准确度选取失效，提出基于互信息的贪婪算法并分析其与mRMR的关系。

**🔧 技术方法**

使用高斯copula、互信息、最大后验（MAP）聚合、贪婪互信息选择，以及频率估计信息量的方法。

**📊 数据集**

在三组数据集上验证：MEDMCQA（医学问答多项选择）、MMLU（多学科通用知识测评）以及IMDB影评情感分类。

**📈 对比分析**

与Top‑k、仅相关性项、mRMR（前两项）等基线比较，结果显示贪婪互信息在预算k=3–8时平均误差下降约1–2个百分点，整体表现最优。

**⚠️ 局限性**

局限性：仅针对二分类场景；依赖足够的训练样本估计信息量；在高相关性极端情况提升有限；对更大输出空间的推广尚未验证。

---

## 497. Regret Analysis of Unichain Average Reward Constrained MDPs with General Parameterization

**arXiv ID:** 2602.08000 | [PDF](https://arxiv.org/pdf/2602.08000v1)

**作者:** Anirudh Satheesh `[一作]` (University of Maryland), Vaneet Aggarwal `[通讯]` (Purdue University)

**通讯引用:** 6173 | [OpenAlex ID](https://openalex.org/A5064822688)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出了一种在无单连通（unichain）假设下、使用通用参数化的平均奖励受限马尔可夫决策过程（CMDP）的无模型自然演员‑评论家（PDP‑NAC）算法，并给出了其有限时刻收敛性和约束违规度量；

**💡 创新点**

创新点：1) 为无单连通MDP设计了多层 Monte‑Carlo（MLMC）估计器，实现仅需对数样本即可获得与传统 T 长期滚动相同的偏差；2) 引入对数烧录（log‑burn‑in）策略，避免了原先需 √T 步的烧录，显著降低总样本复杂度；3) 在上述技术支持下，证明该算法在最优 O~(√T) 的 regret 和约束违规率下收敛，首次将该阶性能扩展到通用参数化的 CMDP；

**🔧 技术方法**

核心技术：多层 Monte‑Carlo 估计、天然策略梯度（NPG）方向求解、原始‑对偶（primal‑dual）框架、基于 Poisson 方程的无单连通误差分析、对数烧录与显式转移状态处理；

**📊 数据集**

数据集：论文以理论分析为主，未在公开数据集上进行实验；若有实验，则可能使用标准的离散环境（如 Grid‑World、RiverSwim 等），但本文未给出具体实现细节；

**📈 对比分析**

方法比较：与传统依赖混合时间或可遍历假设的无模型 CMDP 算法相比，本文在更弱的无单连通假设下仍实现 O~(√T) 的 regret 与约束违规；实验（若存在）显示其在模拟环境中的性能优于或持平于现有基准；

**⚠️ 局限性**

局限性：1) 仍需对单连通性常数 C_hit、C_tar 有上界估计，若误估可能影响收敛速度；2) 逼近误差 ϵ_app 与 ϵ_bias 的影响在理论中不可忽视，若使用低质量特征/网络易导致性能下降；3) 仅在平均奖励、无模型、单连通的前提下证明；在多连通或带有复杂约束的场景需进一步研究。

---

## 498. Learning to Alleviate Familiarity Bias in Video Recommendation

**arXiv ID:** 2602.07987 | [PDF](https://arxiv.org/pdf/2602.07987v1)

**作者:** Zheng Ren `[一作]` (Google LLC), Lukasz Heldt `[通讯]` (Google LLC)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种轻量级的后排位去熟悉偏差框架LAFB，利用用户-内容熟悉度特征学习个性化去偏因子，对原始评分进行归一化后再送入排序，减弱熟悉内容的推荐倾向。

**💡 创新点**

创新点在于：①把熟悉度特征拆为离散桶和连续向量两种形式，分别用经验均值和小型神经网络估计去偏因子；②在后排位层面直接对评分做去偏，保持原有模型不变，兼顾多源熟悉信号与实时行为变化；③引入Novel WT Share等新指标量化新颖观看时间提升。

**🔧 技术方法**

主要技术包括：离散特征桶化经验平均、连续特征小型神经网络逼近、归一化去偏、后排位分数替换、在线A/B测试与置信区间评估；对比了用户/项目重排、解释性SAE、对数流行度惩罚等方法。

**📊 数据集**

使用的真实数据集为YouTube大规模生产环境中的用户-内容交互日志（观看次数、点击、最近交互时间等），并在离线模拟与线上A/B测试中验证。

**📈 对比分析**

与其他可部署方法在同一服务堆栈下对比，LAFB在保持整体观看时长基本不变的前提下，提升了新颖内容观看占比、减少了熟悉内容占比，并在新用户与重度用户中均表现出更好的新颖度提升；在多项多样性指标上优于或不劣于传统重排与SAE方法。

**⚠️ 局限性**

局限性包括：只针对后排位做去偏，无法直接修正候选生成阶段的偏差；去偏因子需要持续更新以跟随行为变化；对极少量或新颖内容的估计依赖于连续特征的平滑性，可能对冷启动场景效果有限；以及对其他类型偏差（如内容质量或时效性）并未做专门处理。

---

## 499. On the complexity of Multipacking

**arXiv ID:** 2602.07982 | [PDF](https://arxiv.org/pdf/2602.07982v1)

**作者:** Sandip Das `[一作]` (Indian Statistical Institute), Daniel Lokshtanov `[通讯]` (University of California)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文证明了无向图中的Multipacking问题是NP完全的，并且在参数化解的大小时是W[2]-困难的。

**💡 创新点**

创新点在于首次证明了无向图中的Multipacking问题的NP完全性，并扩展了这一结果到多个重要的图类，包括和1/2-超曲率图、二部图、无爪图、正则图和CONV图。

**🔧 技术方法**

使用了简单而优雅的从Hitting Set问题的归约来证明Multipacking问题的困难性，并提出了一种精确的指数时间算法，运行时间为O^*(1.58^n)。

**📊 数据集**

没有具体提到使用的数据集，但讨论了多个图类的复杂性，包括和1/2-超曲率图、二部图、无爪图、正则图和CONV图。

**📈 对比分析**

与现有方法相比，本文的结果表明Multipacking问题在多个图类中是NP完全的，并且在参数化解的大小时是W[2]-困难的，表明该问题在这些图类中是难以解决的。

**⚠️ 局限性**

限制在于尽管提出了精确的指数时间算法，但对于一般图的FPT算法仍然是一个开放问题，且在平面图上的复杂性状态尚不明确。

---

## 500. An Explainable Multi-Task Similarity Measure: Integrating Accumulated Local Effects and Weighted Fréchet Distance

**arXiv ID:** 2602.07966 | [PDF](https://arxiv.org/pdf/2602.07966v1)

**作者:** Pablo Hidalgo `[一作]` (University of Alcala), Daniel Rodriguez `[通讯]` (Universidad Francisco de Vitoria)

**通讯引用:** 83 | [OpenAlex ID](https://openalex.org/A5101646229)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出一种基于解释性方法的多任务相似度度量，用 ALE 曲线表示各任务模型对特征的影响，并通过加权离散 Fréchet 距离计算任务之间的相似性，从而能够解释任务相似的原因。

**💡 创新点**

创新点在于：①将解释性 AI（ALE）与 Fréchet 距离结合，形成可解释的任务相似度；②加入特征重要性权重和预测性能校正因子，使度量兼顾模型质量；③该度量模型无关、可跨任务类型、支持不同模型（包括深度网络与传统模型），并提供可视化与聚类工具。

**🔧 技术方法**

使用的技术包括：Accumulated Local Effects (ALE) 曲线、加权离散 Fréchet 距离（动态规划实现）、特征重要性（Permutation Feature Importance/SHAP）、性能缩放因子、Autoencoder 与概念瓶颈编码、Spline 平滑、并行化计算与层次聚类。

**📊 数据集**

实验数据集：1）合成任务数据（5 任务 × 5 特征）；2）帕金森病临床监测数据（42 病人任务）；3）BiciMad 自行车共享数据（264 站点任务）；4）CelebA 图像数据（使用概念瓶颈模型得到 20 个概念）。

**📈 对比分析**

比较方法：对每对任务计算相似度矩阵，并与直观分析或聚类结果对比。结果表明：在合成数据上相似度与手工观察一致；在帕金森数据中能区分不同病人；在自行车数据中生成有意义的站点聚类；在 CelebA 中的任务距离与语义相似度高度吻合。性能稳定，使用 AE 或平滑后相似度变化微小。

**⚠️ 局限性**

局限性：①仅使用一阶 ALE，忽略交互效应；②对 ALE 曲线分段数量敏感；③依赖模型质量，低质量模型可能误导相似度；④对非表格数据需先编码，可能失去可解释性；⑤计算复杂度为 O(T² d K²)，大规模任务需要加速与聚类预筛选。

---

## 501. Lost in Translation? A Comparative Study on the Cross-Lingual Transfer of Composite Harms

**arXiv ID:** 2602.07963 | [PDF](https://arxiv.org/pdf/2602.07963v1)

**作者:** Vaibhav Shukla `[一作]` (Indian Institute Of Information Technology), Vrijendra Singh `[通讯]` (Indian Institute Of Information Technology)

**通讯引用:** 825 | [OpenAlex ID](https://openalex.org/A5018879530)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文设计了 CompositeHarm 基准，通过将 AttaQ 的对抗语法与 MMSafetyBench 的语义情境翻译成六种语言（英语、印地语、阿萨姆语、马拉地语、卡纳达语、古吉拉特语），对三种大语言模型在不同语言下的安全行为进行系统评估。

**💡 创新点**

创新点在于：①将对抗性语法与语义情境两类伤害融合为一个多语言基准；②采用轻量化推理策略和边缘 AI 思路，减少计算成本；③通过对比不同语言族的安全衰退，揭示语言距离对安全对齐的影响。

**🔧 技术方法**

使用的技术包括：NLLB 机器翻译配合双语审核、LLM‑as‑a‑judge（LLaMA‑3.3‑70B）自动评估、固定解码设置的轻量化推理、对三款模型（GPT‑OSS‑20B、LLaMA‑3‑8B‑Instruct、Qwen3‑32B）进行统一评测。

**📊 数据集**

使用的数据集为：AttaQ（对抗语法），MMSafetyBench（语义情境），两者各 140 条原始英语 prompt，翻译后共 1,680 条 prompt（280 条/语言，平衡两类伤害）。

**📈 对比分析**

通过 Refusal Rate（拒绝率）和 Attack Success Rate（攻击成功率）两个二元指标进行比较，结果显示 Indic 语言下 ASR 大幅上升（如卡纳达语、古吉拉特语超过 45%），而 LLaMA‑3‑8B 在对抗语法上的脆弱性最为突出；与欧洲语言相比，Indic 语言的安全衰退更为剧烈。

**⚠️ 局限性**

局限性包括：评估仅依赖 LLM‑as‑a‑judge 的自动化判定，缺乏人工审核；语言覆盖仅限于五种印度语；未涉及多模态攻击或其他语言族，评估范围有限。

---

## 502. Structure-Aware Robust Counterfactual Explanations via Conditional Gaussian Network Classifiers

**arXiv ID:** 2602.08021 | [PDF](https://arxiv.org/pdf/2602.08021v1)

**作者:** Zhan-Yi Liao `[一作]` (National Yang Ming Chiao Tung University), Po-An Chen `[通讯]` (National Yang Ming Chiao Tung University)

**通讯引用:** 1484 | [OpenAlex ID](https://openalex.org/A5101610714)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5b4c1114-4a70-478e-9921-2514ee03850d` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种基于条件高斯网络分类器（CGNC）的结构感知鲁棒反事实搜索方法，在优化中直接嵌入特征的条件依赖关系，并通过鲁棒性预算保证解释在实施误差下仍保持有效。

**💡 创新点**

创新点包括：①将CGNC的DAG结构直接用于约束反事实生成，避免后置一致性检查；②使用削减集（cutting‑set）框架实现对所有扰动的鲁棒约束；③通过分段McCormick松弛将非凸二次约束转化为MILP，从而得到全局最优解；④采用基于类0白化的Mahalanobis‑ℓp距离来衡量实例距离，提升几何一致性。

**🔧 技术方法**

技术方法包括：条件高斯贝叶斯网络（CGNC）建模、削减集鲁棒优化、分段McCormick松弛、MILP（Gurobi）与原始非凸QCQP求解、Mahalanobis‑ℓp距离与白化变换。

**📊 数据集**

实验使用三大公开数据集：Banknote Authentication、Pima Indians Diabetes 和 Ionosphere；在这些数据集上学习了 NB、TAN、BAN 三种结构的 CGNC。

**📈 对比分析**

与传统 NB、TAN、BAN 结构下的非凸QCQP 以及无结构约束的基线进行比较。结果表明：在结构稠密的 BAN 结构下，MILP 方案虽然求解时间显著增加，但能够提供 98–99% 的鲁棒覆盖率；QCQP 在 Ionosphere 数据集上偶有超时，显示缺乏全局保证；总体来看，鲁棒性预算升高导致 MILP 计算量进一步增长。

**⚠️ 局限性**

主要局限包括：①结构复杂度大时 MILP 求解规模爆炸；②分段 McCormick 松弛对变量范围敏感，过宽/过窄的区间会影响精度；③CGNC 仅为生成模型，未必与真实因果关系一致，导致生成的反事实可能落入低密度区间；④缺乏人机评估与解释的可解释性验证，无法完全保证生成结果在实际决策中的可行性。

---

## 503. TAAM:Inductive Graph-Class Incremental Learning with Task-Aware Adaptive Modulation

**arXiv ID:** 2602.08036 | [PDF](https://arxiv.org/pdf/2602.08036v1)

**作者:** Jingtao Liu `[一作]` (University of Science and Technology of China), Xinming Zhang `[通讯]` (University of Science and Technology of China)

**通讯引用:** 4510 | [OpenAlex ID](https://openalex.org/A5002162759)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了 TAAM 框架，利用冻结的 GNN 主干与轻量级神经突触调制器实现无重放的图连续学习。

**💡 创新点**

创新点在于引入任务感知自适应调制（TAAM）与 Anchored Multi‑hop Propagation（AMP）两大模块，解决任务 ID 无法获取的稳定‑可塑性难题，并实现极低参数开销。

**🔧 技术方法**

核心技术包括冻结的 Simple Graph Convolution 主干、基于低秩因式分解的神经突触调制器（NSM）以及使用 APPNP 近似个性化 PageRank 的 AMP 任务 ID 推理。

**📊 数据集**

使用了八个基准图数据集：CoraFull、Arxiv、Citeseer、Reddit、Products、Photo、Computer、WikiCS，均在严格的诱导式学习设置下进行评估。

**📈 对比分析**

与八种主流方法（正则化、重放、参数隔离）对比，TAAM 在所有数据集上均取得最高的平均准确率并实现零遗忘，且参数与内存成本显著低于现有技术。

**⚠️ 局限性**

局限性包括依赖预训练的冻结主干、对任务 ID 推理的准确性仍有提升空间，以及在极大规模图上对 AMP 传播深度的选择仍需经验调整。

---

## 504. Horizon Imagination: Efficient On-Policy Training in Diffusion World Models

**arXiv ID:** 2602.08032 | [PDF](https://arxiv.org/pdf/2602.08032v1)

**作者:** Lior Cohen `[一作]` (Technion), Shie Mannor `[通讯]` (Technion)

**通讯引用:** 18349 | [OpenAlex ID](https://openalex.org/A5036260775)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `04572f8d-59e5-41c9-8850-ac8e7ee2b108` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究了一种名为 Horizon Imagination 的并行多步扩散式世界模型的在策略想象过程，旨在降低强化学习训练的计算成本。

**💡 创新点**

提出了稳定离散动作采样机制和可拆解的 Horizon 采样计划，能够在保持控制性能的同时将扩散步骤数减半。

**🔧 技术方法**

使用基于 1‑Rectified Flow 的扩散模型、Diffusion Transformer（DiT）作为动力学网络，以及 Actor‑Critic 方法进行策略优化。

**📊 数据集**

在 Atari 100K 视觉游戏和 Craftium 视觉游戏上进行实验，验证其在多种离散动作环境中的效果。

**📈 对比分析**

通过与传统自回归扩散想象（32 步）对比，Horizon Imagination 在半预算（16 步）下保持或超过原有回报，FVD 生成质量更优，且计算成本约减半。

**⚠️ 局限性**

实验规模受限，仅评估少量配置；未探索更大预算或更复杂环境，且对不同离散动作数的鲁棒性尚待验证。

---

## 505. Free(): Learning to Forget in Malloc-Only Reasoning Models

**arXiv ID:** 2602.08030 | [PDF](https://arxiv.org/pdf/2602.08030v1)

**作者:** Yilun Zheng `[一作]` (Tencent AI Lab), Yan Wang `[通讯]` (Tencent AI Lab)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 Free-Module，利用可插拔 LoRA 模块在推理时主动识别并删除冗余推理步骤，从而实现“malloc + free”式的上下文管理，缓解长链推理中的熵增与崩溃。

**💡 创新点**

创新点在于：① 引入了主动忘却机制，使模型能够在推理过程中主动清理不再需要的上下文；② 通过合并/拆分 LoRA 的动态切换，实现了推理模式与清理模式的无缝转换；③ 采用奖励驱动的自监督数据构造和严格的验证筛选，训练出高精度的剪枝指令生成器。

**🔧 技术方法**

核心技术包括：LoRA 适配器（Free-Module）实现增删模式切换；JSON 格式的剪枝指令；KV cache 预填与直接剪枝两种恢复策略；基于 Gemini‑2.5‑Pro 的数据合成与多轮奖励筛选；以及对大规模 LLM（Qwen‑3‑8B/30B/235B、DeepSeek‑V3.2‑Speciale）进行部署。

**📊 数据集**

使用的数据集涵盖：长链推理基准（AIME 24&25、BrUMO25、HMMT、BeyondAIME、HLE、IMOAnswerBench）以及通用推理基准（BBH、MMLU‑Pro、MMLU‑STEM、GPQA‑Diamond），并在 480 条 AIME 推理轨迹上验证熵增问题。

**📈 对比分析**

对比方法包括：原始（Vanilla）模型、启发式压缩（H2O、ThinkCleary）、ICL 方案（基于 Gemini‑2.5‑Pro 的自我纠错）。实验显示 Free-Module 在 6 大推理基准上平均提升 3.3%，在 IMOAnswerBench 上刷新 SOTA，且在 Qwen‑3‑235B‑A22B 的长链推理任务上从 0% 恢复到约 50%，同时保持通用基准性能不下降。

**⚠️ 局限性**

局限性：推理过程增加约 56% 延迟（主要来自剪枝指令解码、重新预填和可能的再生成）；需要外部执行器实现 JSON 指令解析；目前仅支持基于 vLLM 的服务框架；在极长推理链或高并发场景下，KV cache 剪枝的实现复杂度与成本仍有提升空间。

---

## 506. Bridging the Gap: Adapting Evidence to Decision Frameworks to support the link between Software Engineering academia and industry

**arXiv ID:** 2602.08015 | [PDF](https://arxiv.org/pdf/2602.08015v1)

**作者:** Patricia G. F. Matsubara `[一作]`, Tayana Conte `[通讯]`

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文提出将医疗领域的Evidence-to-Decision（EtD）框架引入软件工程，结合系统文献综述（SLR）和GRADE方法，构建结构化的决策推荐流程，并给出基于协同编程的实例；

**💡 创新点**

创新点在于：1）将EtD框架迁移到软件工程，补充传统SLR缺失的决策支持信息；2）系统阐述了适用于行业实践的推荐评估准则；3）指出SE领域采纳EtD的挑战与对策；

**🔧 技术方法**

主要使用方法论工具：系统文献综述（SLR）、GRADE评估体系、EtD框架结构；

**📊 数据集**

数据来源为已有的SE系统综述结果，本文以Hannay等人关于协同编程的SLR为案例；

**📈 对比分析**

该研究并未进行实验性能对比，而是通过与传统SLR对比，展示EtD提供更完整、可操作的推荐信息；

**⚠️ 局限性**

局限性包括：缺乏在真实SE环境中验证EtD框架的实证研究；对专家小组和利益冲突管理的要求高；依赖的证据仍有限，难以覆盖所有实践情境。

---

## 507. FSP-Diff: Full-Spectrum Prior-Enhanced DualDomain Latent Diffusion for Ultra-Low-Dose Spectral CT Reconstruction

**arXiv ID:** 2602.07979 | [PDF](https://arxiv.org/pdf/2602.07979v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 508. ForecastOcc: Vision-based Semantic Occupancy Forecasting

**arXiv ID:** 2602.08006 | [PDF](https://arxiv.org/pdf/2602.08006v1)

**作者:** Riya Mohan `[一作]` (University of Freiburg), Abhinav Valada `[通讯]` (University of Freiburg)

**通讯引用:** 2537 | [OpenAlex ID](https://openalex.org/A5039639553)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了第一个基于视觉的语义占用预测框架，能够直接从多视角或单目摄像头图像中联合预测未来的3D占用状态和语义类别。

**💡 创新点**

创新点包括：①不依赖外部占用预测网络，直接从图像学习时空特征；②引入跨时空注意力的未来状态合成模块，实时生成未来图像平面特征；③使用视角变换器将2D特征投影到3D体素，再经过3D编码器和语义占用头输出体素级语义。

**🔧 技术方法**

核心技术包括多尺度图像编码器（EfficientNet‑B3 + FPN）、跨时间/视角嵌入、跨时间注意力交互层、视角投影（Lift‑Splat‑Shoot）、3D ResNet 编码器、语义占用 MLP 头以及特征对齐损失（Huber+Cosine）。

**📊 数据集**

在 Occ3D‑nuScenes（6 视角，200×200×16 体素）和 SemanticKITTI（单目前视，256×256×32 体素）两个公开数据集上进行实验。

**📈 对比分析**

与基线（Naive、PDCast、OccWorld、I²‑World 等）对比，提出方法在 1s、2s、3s 预测时均获得最高的 mIoU 与 IoU（Occ3D‑nuScenes 上 mIoU 最高 34.86%/IoU 32.42%；SemanticKITTI 上 mIoU 最高 35.05%/IoU 32.74%），并在多视角场景下以 6.05 FPS 及单目场景下 1.34 FPS 维持良好实时性。

**⚠️ 局限性**

局限性包括：①对极长时间预测仍易出现累计误差；②单目场景由于视野受限，时空信息不足，导致动态物体预测不如多视角；③模型相对复杂，训练和推理成本高于传统基线。

---

## 509. The Judge Who Never Admits: Hidden Shortcuts in LLM-based Evaluation

**arXiv ID:** 2602.07996 | [PDF](https://arxiv.org/pdf/2602.07996v1)

**作者:** Arash Marioriyad `[一作]` (Sharif University of Technology), Mahdieh Soleymani Baghshah `[通讯]` (Sharif University of Technology)

**通讯引用:** 1150 | [OpenAlex ID](https://openalex.org/A5069082023)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文通过在LLM评判任务中注入人工合成的非语义提示（如来源、时间、教育程度等）来测试LLM判别者是否会受到无关信息影响，并记录其判决变化与是否在解释中提及该提示；

**💡 创新点**

首次将“Verdict Shift Rate (VSR)”与“Cue Acknowledgment Rate (CAR)”两指标结合，系统评估LLM判别者的偏倚强度与解释透明度，并发现开放式创意评估（LitBench）比事实问答（ELI5）更易受隐式偏倚影响且解释更不透明；

**🔧 技术方法**

使用大规模LLM模型（GPT‑4o、Gemini‑2.0‑Flash、Claude‑3‑Haiku、Gemma‑3‑27B、Qwen3‑235B、Llama3‑70B）在单轮确定性推理下进行二元评判，输出JSON格式判断与理由；

**📊 数据集**

两个公开基准：事实性长答题集 ELI5 与开放式创意写作基准 LitBench；

**📈 对比分析**

对每个模型在六类提示下计算 VSR 与 CAR，并对不同数据集、模型类型进行对比，结果显示：在 ELI5 中多数模型 VSR 低且 CAR 较高，提示影响有限；在 LitBench 中 VSR 较高、CAR 近零，说明模型更易受无关提示影响且不公开解释，尤其在时间、来源、教育等提示上偏倚显著；

**⚠️ 局限性**

仅在两种任务和单轮提示下评估，未覆盖多轮交互、不同评判任务；未深入探讨模型内部偏差来源，结果对更广泛领域的泛化性尚待验证；

---

## 510. MCIE: Multimodal LLM-Driven Complex Instruction Image Editing with Spatial Guidance

**arXiv ID:** 2602.07993 | [PDF](https://arxiv.org/pdf/2602.07993v1)

**作者:** Xuehai Bai `[一作]` (Hangzhou Dianzi University), Jack Ma `[通讯]` (Tsinghua University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

针对复杂指令的图像编辑任务，提出 MCIE‑E1 模型，通过 MLLM 将指令拆解为子指令并配合空间感知与背景一致性注意力模块实现高质量编辑。

**💡 创新点**

创新点包括：①利用多模态大语言模型进行指令拆解与空间框定位；②设计空间感知交叉注意力（SACA）精准对齐子指令与编辑区域；③设计背景一致性交叉注意力（BCCA）在噪声去除过程中保持未编辑区域一致性；④构建专门的 MCIE 数据集与 CIE‑Bench 基准，提供复杂指令编辑的高质量数据与评价指标。

**🔧 技术方法**

使用的技术包括：Stable Diffusion 1.5 diffusion 框架、LoRA 微调、CLIP 与 DINOv2 编码器、Transformer 块、傅里叶映射、MLP 与 L2 Transformer 块、Euler Ancestor 采样器，以及 Qwen2.5‑VL‑72B 等多模态大语言模型。

**📊 数据集**

使用的数据集：①MCIE 数据集（约90k高分辨率样本，含指令、边界框与人工筛选）；②CIE‑Bench 基准（400个真实场景样本，配合 GPT‑4o 生成的 1~4 子指令）。

**📈 对比分析**

与 IP2P、MagicBrush、InstructDiffusion、AnyEdit、UltraEdit、MGIE、SmartEdit、GoT 等现有方法对比，MCIE‑E1 在 CIE‑Bench 的指令遵循度、背景一致性、CLIP‑I、DINO‑I 等自动指标均位列第一，指令遵循度提升约 23.96%，在用户研究中亦获得 80% 的偏好。

**⚠️ 局限性**

局限性：①对极为复杂或高度语义冲突的指令仍可能出现误解；②依赖大型 MLLM，训练与推理成本较高；③评估主要基于构造的基准，真实世界多模态场景中的泛化能力仍需进一步验证。

---

## 511. Beyond Optimization: Intelligence as Metric-Topology Factorization under Geometric Incompleteness

**arXiv ID:** 2602.07974 | [PDF](https://arxiv.org/pdf/2602.07974v1)

**作者:** Xin Li `[一作]` (University at Albany), Xin Li `[通讯]` (University at Albany)

**通讯引用:** 38755 | [OpenAlex ID](https://openalex.org/A5100354056)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出Metric‑Topology Factorization（MTF）理论，构建Topological Urysohn Machine（TUM）与Memory‑Amortized Metric Inference（MAMI）体系以解决由几何不完整性导致的稳定‑可塑性困境。

**💡 创新点**

核心创新在于将任务的全局拓扑结构与局部度量演化分离，利用拓扑指纹进行离散切换，随后在对应纤维上执行度量收缩，实现快速适应与灾难性遗忘的抑制。

**🔧 技术方法**

采用Morse理论与Urysohn引理进行理论建模，使用谱聚类得到拓扑指纹，结合子空间投影、白化（whitening）和梯度切换实现MAMI，并在梯度下降框架下实现度量收缩。

**📊 数据集**

实验基准包括自定义的Möbius潜在空间、不同Betti数的合成数据集以及标准的Permuted MNIST序列。

**📈 对比分析**

与普通SGD、EWC等对比，MTF在拓扑变化下的适应延迟显著降低、记忆子空间正交性高、梯度阻塞现象消失，持续学习任务上实现更高的平均准确率并避免性能衰减。

**⚠️ 局限性**

局限性包括对光滑流形的依赖、谱指纹对采样密度和图构造敏感、记忆分配与子空间划分的设计权衡，以及在离散或高维实际环境中的实现复杂度。

---

## 512. On Improving Neurosymbolic Learning by Exploiting the Representation Space

**arXiv ID:** 2602.07973 | [PDF](https://arxiv.org/pdf/2602.07973v1)

**作者:** Aaditya Naik `[一作]` (University of Pennsylvania), Dan Roth `[通讯]` (Oracle AI)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `57a58b01-81b4-4d75-a45c-2e891f272b50` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文提出了一种在神经符号学习中利用表示空间相似性进行候选标签组合（pre‑image）剪枝的技术，能够显著减少弱标签下的候选组合数，从而提升神经分类器的学习效果。

**💡 创新点**

创新点包括：① 将剪枝问题形式化为整数线性规划（ILP），保证剪枝后每个训练样本至少保留一个合法组合；② 通过构造“邻近图”将实例在潜在表示空间中的相似性映射到标签一致性约束；③ 该方法与现有神经符号引擎完全兼容，可作为插件式预处理或在训练期间迭代使用。

**🔧 技术方法**

主要技术手段包括：潜在表示编码器（可使用预训练视觉/语言模型或可训练的卷积编码器）；邻近图构造；整数线性规划求解（利用现有 ILP 求解器）；与三大主流神经符号引擎（DeepProbLog、NeuroLog、PROBLOG 等）集成以计算语义损失或其近似。

**📊 数据集**

实验使用了 16 个基准数据集，涵盖：MNIST、CIFAR‑10 上的 SUM‑M、MAX‑M、HWF‑M；VQAR（视觉问答与多跳推理）；MUGEN（视频‑文本检索）。每个基准包含多种公式长度、标签数等变体，确保覆盖复杂的符号约束。

**📈 对比分析**

在所有基准和三大引擎上，使用本方法的模型相比基线平均提升 8–53% 的分类准确率（例如 SUM‑3 上从 43% 提升到 60%；MUGEN 上 VTR/TVR 由 26%→74%/33%→86%）。性能提升保持在不同编码器（随机初始化或预训练）和不同训练策略下的一致性。

**⚠️ 局限性**

主要局限包括：① ILP 计算在大批量或极大候选集场景下仍有显著时间开销；② 在极小数据或标签空间稀疏的情况下，剪枝可能导致某些样本失去有效组合，导致准确率下降；③ 对于某些已有的引擎（如 MUGEN 无金标准 pre‑images）无法直接使用；④ 若编码器表现不佳，剪枝可能误删真实标签，影响最终性能。

---

## 513. Learning-guided Kansa collocation for forward and inverse PDEs beyond linearity

**arXiv ID:** 2602.07970 | [PDF](https://arxiv.org/pdf/2602.07970v1)

**作者:** Zheyuan Hu `[一作]` (Cambridge), Fangcheng Zhong `[通讯]` (Cambridge)

**通讯引用:** 357 | [OpenAlex ID](https://openalex.org/A5084520143)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文将基于RBF的Kansa求解器从线性单变量PDE扩展到多变量和非线性PDE，并将其应用于前向求解、逆问题以及方程发现。

**💡 创新点**

创新点在于：1) 引入自适应调参机制（自调节形状参数ϵ）；2) 通过可微矩阵把非线性算子拆解为线性算子实现可微求解；3) 对耦合多变量系统提出新的块矩阵构造；4) 系统性评估Kansa与经典FDM/FEM以及神经网络方法PINN、FNO在同一基准集上的性能。

**🔧 技术方法**

使用技术包括：RBF基函数（Gaussian）、Kansa求解器、可微矩阵、时间步进方案（显式、隐式、IMEX、Crank‑Nicolson、全非线性）、梯度/无梯度优化（Powell、Newton‑Raphson）、自调参权重组合。

**📊 数据集**

数据集：合成PDE实例集合。1D输运方程共100个实例（随机初始条件）；Lotka‑Volterra、Maxwell、Burgers等采用固定参数和初始/边界条件，测试点数如64×8、10×10等。

**📈 对比分析**

比较方法：对同一基准问题使用Kansa、FDM、PINN、FNO，评估指标为相对L₂误差、训练/推理时间以及内存消耗。结果显示：在足够的训练数据下（C_scale≥4²），Kansa在相对误差上可低至10⁻⁶，训练/推理时间最短；但随着C_scale增大，内存需求激增；非线性PDE中全非线性方案优于显式/IMEX，但训练成本最高；FNO在多实例训练中表现较差。

**⚠️ 局限性**

局限性：1) 对高维大规模问题的内存和计算成本仍高；2) 目前缺乏理论误差与收敛性分析；3) 对非线性PDE的稳定性仍依赖于时间步长与初值，存在局部极小值陷阱；4) 仅在合成基准上验证，缺乏真实物理问题的实验。

---

## 514. Wheeler Bisimulations

**arXiv ID:** 2602.07964 | [PDF](https://arxiv.org/pdf/2602.07964v1)

**作者:** Nicola Cotumaccio `[一作]` (University of Helsinki), Nicola Cotumaccio `[通讯]` (University of Helsinki)

**通讯引用:** 35 | [OpenAlex ID](https://openalex.org/A5024275216)

**关键词:** `33d19632-8af2-4683-a5db-767c7ce749e6`

**🎯 论文内容**

本文提出了一种新的Wheeler图形化等价关系（Wheeler bisimulation）来定义Wheeler自动机的等价类，并证明在该等价类中存在唯一的最小Wheeler NFA（以及唯一最小Wheeler DFA），从而给出了构造最小Wheeler自动机的理论方法。

**💡 创新点**

创新点在于引入Wheeler bisimulation概念，利用该等价关系实现自动机的等价判定与最小化，避免了传统的状态划分方法，并首次给出了线性时间的构造算法。

**🔧 技术方法**

主要技术包括等价关系的凸性（convexity）证明、bit数组表示等价类的压缩、队列驱动的状态合并算法，以及利用Wheeler图形化的三条轴定理来保证算法正确性。

**📊 数据集**

本文未使用具体实验数据集，全部工作均基于理论分析与证明。

**📈 对比分析**

方法与传统的状态划分最小化算法相比，在已知字符标签可线性排序的前提下，构造等价类的时间复杂度为O(|E|)，显著优于一般的O(|Q|log|Q|)或更高复杂度的算法。

**⚠️ 局限性**

局限性在于对字符标签的排序要求（需要可在O(|E|)内完成），在比较模型（comparison model）下实现需要更复杂的技巧，且对无限大或无序字母表的情况未作深入讨论。

---

## 515. D-ORCA: Dialogue-Centric Optimization for Robust Audio-Visual Captioning

**arXiv ID:** 2602.07960 | [PDF](https://arxiv.org/pdf/2602.07960v1)

**作者:** Changli Tang `[一作]` (Tsinghua University), Chao Zhang `[通讯]` (Tsinghua University)

**通讯引用:** 94853 | [OpenAlex ID](https://openalex.org/A5042841794)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

针对多方对话视频，提出了D-ORCA对话中心全模态LLM，实现精准的说话人归属、语义识别与时间定位。

**💡 创新点**

创新点在于将三项细粒度奖励（说话人归属、语音内容准确率、句子级时间对齐）融入GRPO，并首次在对话视频评测中使用LLM作为解析器。

**🔧 技术方法**

技术包括视觉/音频特征对齐、Q-Former音频模态对齐器、LoRA微调、预DPO训练、GRPO强化学习以及外部LLM解析。

**📊 数据集**

数据集为自研的DVD-Train（约40k多方对话视频，英中混合）和DVD-Bench（约1.9k评测视频），并利用公开的LibriSpeech、CommonVoice等音频对齐训练集。

**📈 对比分析**

与现有开源全模态LLM（如Qwen3-VL、AVoCaDO等）比较，D-ORCA在说话人归属、WER/CER与IoU上分别提升约10%、12%与50%（英）/30%（中），并在通用视觉问答/视频MSE等基准上保持竞争力。

**⚠️ 局限性**

局限性包括对外部LLM评测的依赖、对复杂说话人混合场景的鲁棒性仍待提升，以及模型规模与推理速度的进一步优化空间。

---

## 516. The Benefits of Diversity: Combining Comparisons and Ratings for Efficient Scoring

**arXiv ID:** 2602.08033 | [PDF](https://arxiv.org/pdf/2602.08033v1)

**作者:** Julien Fageot `[一作]`, Oscar Villemaud `[通讯]` (École Polytechnique Fédérale de Lausanne)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种名为SCoRa的统一概率模型，能够同时利用用户的直接评分（ratings）和比较判断（comparisons）来学习实体的隐藏分数，从而改进偏好学习与推荐系统的性能。

**💡 创新点**

创新点在于：①将评分与比较视为同一模型中的不同观测形式，消除了传统方法中两种数据互不兼容的瓶颈；②通过引入可变根律（root‑law）的灵活广义Bradley‑Terry框架，给出了MAP估计的凸性、单调性以及鲁棒性证明；③提出了一种在主动学习场景下将两种数据结合以提升对高分实体的准确性的策略。

**🔧 技术方法**

技术上主要使用了广义Bradley‑Terry模型、可变根律、贝叶斯MAP估计、凸优化（LBFGS）、以及对模型不匹配下的鲁棒性分析；同时在实验中引入了加权相关度评价指标和主动学习采样策略。

**📊 数据集**

实验数据均为合成数据，生成方式为先采样真实的β向量与阈值θ₀，然后按给定预算按成本比例产生评分与比较；实验设置包含不同的根律（均匀、k‑ary、高斯）以及嵌入（身份、one‑hot）等。

**📈 对比分析**

与单一数据源（仅评分或仅比较）对比，SCoRa在预算有限且关注高分实体时，使用加权相关度可实现30–50%左右的提升；在不匹配根律的情况下仍能收敛到接近1的相关度，表现出优越的鲁棒性。

**⚠️ 局限性**

局限性包括：①需要预先设定根律与预算比例，对不同应用的泛化性尚待验证；②对高维嵌入和大规模数据的计算效率未做深入分析；③在真实用户数据中可能存在的系统性偏差和评分稀疏问题未被直接评估。

---

## 517. The Rise of Sparse Mixture-of-Experts: A Survey from Algorithmic Foundations to Decentralized Architectures and Vertical Domain Applications

**arXiv ID:** 2602.08019 | [PDF](https://arxiv.org/pdf/2602.08019v1)

**作者:** Dong Pan `[一作]` (FEDIMOSS TECH HK LIMITED), Victor Fei `[通讯]` (Ormi Labs, Inc.)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `afceb026-1760-41ae-8d86-010831a37d97` `e15e3743-5ee0-4d5f-813d-d146868082fc` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `5a41884c-404f-4688-a89c-aa238c10fe68` `bb57609f-8351-4b1b-85e4-3afa07da95d6` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文系统综述了稀疏Mixture of Experts（MoE）模型的核心设计、路由与负载平衡机制，深入探讨了中心化与去中心化训练框架，并详细梳理了MoE在医疗、自动驾驶、金融、商业分析和区块链等垂直领域的应用案例，最后总结了当前技术面临的关键挑战与未来研究方向。

**💡 创新点**

创新点在于：①将MoE的核心组件与分布式并行策略（专家并行、混合并行、异构设备调度等）系统化梳理；②首次将中心化与去中心化MoE的技术细节与难点进行对比与分类；③总结了多行业垂直应用的MoE实现与性能提升；④提出了负载平衡、专家专业化、隐私保护与激励机制等关键挑战，并给出对应的研究现状与空白。

**🔧 技术方法**

技术涵盖：稀疏激活与路由网络（token‑choice、expert‑choice）、专家网络（共享专家与专用专家）、负载平衡损失与专家容量控制、专家并行（EP）、混合并行（DP+PP+TP）、去中心化并行与异构调度、低带宽通信（Dynamic Grouping‑AllReduce、SWARM、StellaTrain）、容错机制（DHT/Kademlia）、隐私与安全（ZK‑ML、PC‑MoE、差分隐私、加密推理）。

**📊 数据集**

综述所引用的研究使用了多样化数据集，包括医疗影像与电子健康记录（Med‑MoE‑Embed、M4oE、dFLMoE）、LiDAR 与摄像头多模态感知数据（MIXO、DriveMoE）、金融时序与市场数据（FinTeamExperts、MfMoE、MoEDRLPM）、商业智能与消费者行为数据、智能合约代码（MOS、SAEL）。

**📈 对比分析**

对比方法主要是把公开MoE模型（如DeepSeekMoE、Mixtral、Phi‑3.5‑MoE、Qwen3‑Next 等）与传统密集模型以及多种分布式框架（DeepSpeed‑MoE、OpenMoE、HeterMoE、ATOM、StellaTrain 等）在参数规模、稀疏度、推理速度、能耗与成本等维度进行对照。结果显示，MoE在保持或提升模型性能的同时，显著降低了算力与显存消耗；在垂直应用中，MoE 能够通过专家专业化提升诊断准确率、驾驶安全性、金融预测精度等；但在去中心化场景下，网络延迟与异构性仍导致性能波动。

**⚠️ 局限性**

局限性包括：①缺乏统一的基准与评价指标，导致不同论文之间的性能对比不完全可比；②去中心化MoE面临的通信瓶颈、隐私与安全挑战尚未得到全面解决；③负载平衡与专家专业化的权衡仍需要更精细的算法与动态调节机制；④大规模训练对硬件与网络资源的高要求限制了普通研究者的可行性；⑤激励与可信执行环境的设计尚不成熟，易受恶意节点攻击。

---

## 518. CyberExplorer: Benchmarking LLM Offensive Security Capabilities in a Real-World Attacking Simulation Environment

**arXiv ID:** 2602.08023 | [PDF](https://arxiv.org/pdf/2602.08023v1)

**作者:** Nanda Rani `[一作]` (CISPA - Helmholtz Center for Information Security), Ramesh Karri `[通讯]` (New York University)

**通讯引用:** 16486 | [OpenAlex ID](https://openalex.org/A5059648257)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了一个开放式、多目标的LLM攻击评测平台CyberExplorer，集成40个真实CTF web服务并设计异步多代理探测‑执行框架。

**💡 创新点**

提出了开放环境攻击任务、并发多代理架构、细粒度交互与协同指标，突破传统单一服务的二元成功评测。

**🔧 技术方法**

利用LLM（Claude Opus 4.5、Gemini 3 Pro、GPT 5.2、Qwen 3、DeepSeek V3）、Docker容器、工具集成（扫描、fuzzer、加密、脚本）、RAG与Critic反馈机制。

**📊 数据集**

采用40个基于NYU CTF、Google CTF、Hack The Box等源的Web CTF挑战。

**📈 对比分析**

通过TP/FP/FN、精确率、召回率、平均交互轮数、成本、代理数量等指标比较，Claude Opus 4.5获得最高召回率与精确率，Gemini 3 Pro在成本上更优，其他模型表现中等。

**⚠️ 局限性**

仅覆盖Web漏洞，缺乏客户端、内核、后渗透等场景；固定预算限制代理行为；实验仅在隔离VM中进行，未能捕捉真实网络复杂性。

---

## 519. PhysDrape: Learning Explicit Forces and Collision Constraints for Physically Realistic Garment Draping

**arXiv ID:** 2602.08020 | [PDF](https://arxiv.org/pdf/2602.08020v1)

**作者:** Minghai Chen `[一作]` (Guangdong Institute of Intelligence Science and Technology), Yuxiang Huan `[通讯]` (Guangdong Institute of Intelligence Science and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `4de8e9d8-757b-475f-9627-18a445e50202` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出一种混合神经-物理的服装铺设框架PhysDrape，能够在实时推理下实现几乎无穿透、低能量的服装铺设；

**💡 创新点**

创新点在于将Physics‑Informed Graph Neural Network与可微分的两阶段求解器（可学习的力求解器与硬约束投影）耦合，完全消除软约束的折衷，保证几何合法性与物理平衡；

**🔧 技术方法**

技术包括基于StVK模型的残差力计算、可学习的力求解器（迭代更新法）、可微分碰撞投影层、图神经网络（Encode‑Process‑Decode）以及完整的自监督能量损失；

**📊 数据集**

使用CLOTH3D上未见的上衣服装数据集（600件训练，30件测试），以及AMASS人体姿态与随机体型；

**📈 对比分析**

与DeePSD、DIG、DrapeNet等方法对比，PhysDrape在能量指标（E_strain、E_bend、E_grav）和穿透率（B2G）上显著更优，B2G仅0.05%，E_strain下降至0.15；推理时间约30–90 ms，低迭代即可实时；

**⚠️ 局限性**

局限性是只处理准静态铺设，忽略惯性与时间积分；未来需扩展到完整动画、逆向服装重建和多层/缝纫图优化。

---

## 520. Tighter Information-Theoretic Generalization Bounds via a Novel Class of Change of Measure Inequalities

**arXiv ID:** 2602.07999 | [PDF](https://arxiv.org/pdf/2602.07999v1)

**作者:** Yanxiao Liu `[一作]` (Imperial College London), Yijun Fan an Deniz Gündüz `[通讯]`

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

本文通过数据处理不等式（DPI）提出了一类统一的测度变换不等式，并将其应用于随机学习算法的泛化误差分析，得到更紧凑的高概率信息理论泛化界。

**💡 创新点**

创新点在于：① 统一使用DPI而非传统的变换技巧，显著简化证明并获得更强的不等式；② 能同时处理多种信息量（f‑divergence、Rényi、α‑互信息、最大泄漏等）；③ 在PAC‑Bayes、条件互信息和差分隐私框架下均能得到新的、比现有结果更优的界。

**🔧 技术方法**

主要技术手段包括：数据处理不等式、Young‑Fenchel 双变换、Eγ‑divergence 的直接利用、对 f‑divergence 的凸共轭分析，以及对 Orlicz 空间的范数估计。

**📊 数据集**

本文为理论工作，没有使用具体数据集；所有结果均在概率论和信息论框架下推导。

**📈 对比分析**

与现有文献相比，新界在大多数信息量上均严格优于或等价于已知最优界；在最大泄漏、χ²‑divergence、α‑互信息等场景下，能给出更紧的高概率界，并恢复经典结果的简化证明。

**⚠️ 局限性**

局限性包括：① 当前的映射 T 只取 1_E 形式，尚不清楚是否存在更优的选择；② 对于某些隐私度量（如 TV、H²）只能给出平凡界；③ 论文主要聚焦理论证明，未检验在实际深度学习模型上的表现。

---

## 521. Deepfake Synthesis vs. Detection: An Uneven Contest

**arXiv ID:** 2602.07986 | [PDF](https://arxiv.org/pdf/2602.07986v1)

**作者:** Md. Tarek Hasan `[一作]` (United International University), Terence Sim `[通讯]` (National University of Singapore)

**通讯引用:** 7182 | [OpenAlex ID](https://openalex.org/A5065478753)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `9ce7179e-700c-4310-ac2b-91df50ded46e` `ba576bd1-e51d-44e8-8077-fc943b333c93` `25d64835-ec5b-425b-899d-a6e1e6fecabd` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

对最先进的深度伪造合成技术与检测方法进行系统实验评估，并开展人工检测对照

**💡 创新点**

首次整合多种扩散、GAN、NeRF合成模型与多种检测模型进行统一对比，并加入人类实验揭示检测瓶颈

**🔧 技术方法**

使用Transformer、对比学习、注意力机制、Capsule网络等深度学习框架，以及人类评估问卷

**📊 数据集**

利用VoxCeleb、HDTF、CelebV、FaceForensics++等公开数据集生成合成视频并训练检测器

**📈 对比分析**

通过AUC、AP、精确率、召回率和d’等指标对比，人工检测的AUC≈93，最优模型AUC仅≈70，显示检测模型对扩散合成视频性能不足

**⚠️ 局限性**

实验受限于仅5秒无声视频、合成视频来源有限以及检测模型过拟合GAN伪造的缺陷

---

## 522. Accelerating Social Science Research via Agentic Hypothesization and Experimentation

**arXiv ID:** 2602.07983 | [PDF](https://arxiv.org/pdf/2602.07983v1)

**作者:** Jishu Sen Gupta `[一作]`, Balaji Krishnamurthy `[通讯]` (Adobe Media and Data Science Research)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

构建了 ExperiGen 框架，实现从原始非结构化数据自动生成可实验验证的假设，并形成闭环的实验与迭代优化过程；

**💡 创新点**

创新点在于：①将生成代理与实验代理两者通过贝叶斯优化式两阶段搜索耦合，既能探索新颖假设，又能在实验验证中迭代细化，显著降低假阳性率；②首次在人工专家评估与真实 A/B 测试中验证机器生成假设的科学价值；③支持文本、图像、多模态以及复杂关系数据的自动假设生成与验证。

**🔧 技术方法**

核心技术包括：大型语言模型（Qwen3‑32B、GPT‑4o）驱动的生成代理与实验代理；ReAct 代理结合 Code Interpreter 与 LLM 特征提取实现自动特征构造与统计检验；贝叶斯优化启发式的两阶段搜索；Bonferroni 等多重检验校正。

**📊 数据集**

使用多样化数据集：HypoBench（5 任务）、Congress（美国国会演讲文本）、Twitter（带元数据的推文）、CMV（Reddit 反驳数据）、Design（对称/非对称布局）、LaMem（图片记忆度对比）等，涵盖文本、图像与关系型数据。

**📈 对比分析**

与 HypoGenic、HypotheSAEs 以及零/少样本 CoT 进行对比，ExperiGen 在 9/10 任务组上取得最高准确率，平均提升 6–17%；生成的统计显著假设数量比基线多 2–4 倍，假阳性率低；专家评估显示 88% 新颖、70% 研究价值；在真实 A/B 测试中实现 +344% 转化率，显著优于手工假设。

**⚠️ 局限性**

局限性包括：仍受 LLM 生成质量与偏差影响，可能产生与数据偏倚相关的错误假设；对极大规模数据集的计算成本较高；实验代理依赖预先定义的工具集，难以覆盖所有复杂实验需求；在需要深度因果推断或动态实验设计的场景下仍需人工干预。

---

## 523. Cross-Linguistic Persona-Driven Data Synthesis for Robust Multimodal Cognitive Decline Detection

**arXiv ID:** 2602.07978 | [PDF](https://arxiv.org/pdf/2602.07978v1)

**作者:** Rui Feng `[一作]` (Nanjing Medical University), Xingyao Wang `[通讯]` (Agency for Science, Technology and Research)

**通讯引用:** 847 | [OpenAlex ID](https://openalex.org/A5023449213)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `67630363-6be0-4f51-ab05-7198250671a5` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `a6cb313d-240c-4723-a372-3ba1f39b9afc`

**🎯 论文内容**

设计并实现了 SynCog 框架，利用可控人物模拟合成多模态数据并通过链式推理（CoT）微调多模态大语言模型，以实现多语言下的轻度认知障碍（MCI）诊断。

**💡 创新点**

创新点包括① 在数据层面引入可控人物特征生成，产出具有真实认知与人口学差异的合成音频与文本；② 在模型层面采用 CoT 推理细化训练，使诊断过程可解释且不易产生 shortcut 学习。

**🔧 技术方法**

使用技术包括大语言模型生成文本、基于老年人声库的语音克隆、LoRA 低秩微调、链式推理（CoT）自监督训练、音频预处理与自动转录、以及多模态输入的结构化推断。

**📊 数据集**

数据集涵盖公开的 ADReSS（英语二分类）与 ADReSSo（英语仅音频）、真实世界中文 CIR‑E（三分类），以及同类语言的合成数据 SYN‑EN 与 SYN‑ZH，用于训练、验证与跨语种泛化评估。

**📈 对比分析**

通过在 ADReSS、ADReSSo 与 CIR‑E 上与多种开源与闭源基线模型对比，SynCog 在英语任务上 Macro‑F1 取得 80.67%（ADReSS）/78.46%（ADReSSo），在中文 CIR‑E 上 Macro‑F1 48.71%，均超过当前最佳闭源模型，显示出跨语言的稳健性与高性能。

**⚠️ 局限性**

局限性包括合成音频缺少真实神经运动缺陷导致的细微声学特征、评估仅聚焦于图片描述任务，未覆盖更广泛的认知测评范式，以及 CoT 推理可能出现解释不完全忠实模型内部决策的情况。

---

## 524. EasyTune: Efficient Step-Aware Fine-Tuning for Diffusion-Based Motion Generation

**arXiv ID:** 2602.07967 | [PDF](https://arxiv.org/pdf/2602.07967v1)

**作者:** Xiaofeng Tan `[一作]` (Southeast University), Hongsong Wang `[通讯]` (Southeast University)

**通讯引用:** 1240 | [OpenAlex ID](https://openalex.org/A5014269015)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

针对基于扩散的文本-运动生成模型，提出了一种基于步级可微奖励的微调方法 EasyTune，并结合自我强化偏好学习 SPL，用于在缺乏人工标注的情况下构建偏好对并训练奖励模型。

**💡 创新点**

创新点包括：①通过在每个去噪步骤直接优化奖励，打破了传统方法中全轨迹递归梯度带来的内存占用和梯度消失问题；②提出的 SPL 机制能在检索数据中自动挖掘偏好对，避免了对大量人工标注的依赖；③实现了显著降低内存占用（约 22 GB）和训练速度提升（约 7.3 倍）的同时，提升了多模态距离、FID、R‑Precision 等指标。

**🔧 技术方法**

使用了可微奖励微调（Differentiable Reward Tuning）、步级梯度更新、停止梯度操作、检索模型（如 ReAlign）及其改进的奖励头、SDE/ODE 采样、单步预测奖励、以及基于 Softmax 的偏好对损失。

**📊 数据集**

主要数据集包括 HumanML3D 与 KIT‑ML，用于训练和评估文本‑运动检索、微调以及生成质量。

**📈 对比分析**

与 DRaFT、AlignProp、DRTune 以及当下主流文本‑运动生成方法（ParCo、ReMoDiffuse 等）对比，EasyTune 在 R‑Precision、MM‑Dist、FID 等指标上均取得显著提升；同时在 GPU 内存使用上最低（22.10 GB），训练速度比 DRaFT 快 7.3 倍。

**⚠️ 局限性**

局限性主要在于：①奖励模型依赖检索生成的偏好对，可能包含噪声且缺乏对物理可行性的显式约束；②方法在处理多样化的运动物理属性和真实性方面仍有提升空间；③由于缺乏大规模高质量偏好标注，SPL 生成的偏好对可能导致奖励模型偏向检索模型的潜在偏见。

---

## 525. Mutual information and task-relevant latent dimensionality

**arXiv ID:** 2602.08105 | [PDF](https://arxiv.org/pdf/2602.08105v1)

**作者:** Paarth Gulati `[一作]` (Emory University), Ilya Nemenman `[通讯]` (Emory University)

**通讯引用:** 7393 | [OpenAlex ID](https://openalex.org/A5071388278)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9ce7179e-700c-4310-ac2b-91df50ded46e` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文提出了一种利用信息瓶颈框架估计任务相关潜在维度的方法，解决了传统神经MI估计器在维度推断中容易过高估计的问题。

**💡 创新点**

创新点包括引入混合（Hybrid）判别器以分离潜在维度与判别器表达力、使用参与比（participation ratio）实现单次模型即可推断维度、并结合max‑test早停策略控制过拟合。

**🔧 技术方法**

技术上主要采用Symmetric InfoNCE神经MI估计、混合判别器（双线性编码+轻量MLP头）、参与比分析、以及最大测试早停训练协议。

**📊 数据集**

验证数据集包括合成的低维潜在变量通过线性或非线性映射到高维观测的生成数据、噪声鲁棒性测试、2D Ising模型（用于验证临界尺度性）、以及单摆和双摆视频数据。

**📈 对比分析**

与传统的内在维度估计器（如Levina–Bickel、Two‑NN）和CCA比较，Hybrid MI/SIB方法在噪声环境下仍能准确恢复真实潜在维度，且在有限样本下保持较低偏差。

**⚠️ 局限性**

局限性包括对MI估计的依赖、视图构造方式的选择、对网络架构的敏感性以及在样本量不足时可能失效。

---

## 526. Building Damage Detection using Satellite Images and Patch-Based Transformer Methods

**arXiv ID:** 2602.08117 | [PDF](https://arxiv.org/pdf/2602.08117v1)

**作者:** Smriti Siva `[一作]` (Lakeside School), Jan Cross-Zamirski `[通讯]` (London)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `8d10c613-917e-4880-9716-17789f50e119` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究使用卫星图像中的 Vision Transformer 对灾后建筑损坏进行多类别分类，并提出基于补丁裁剪的预处理与冻结头微调策略。

**💡 创新点**

创新点在于针对建筑的补丁裁剪预处理以去除背景噪声，并在算力受限环境下使用冻结头微调的 DINOv2 与 DeiT，验证 Transformer 在高度不平衡数据集上的竞争力。

**🔧 技术方法**

使用技术包括 Vision Transformer（DeiT‑Ti、DINOv2‑small）、自定义补丁裁剪数据加载器、HuggingFace Trainer、冻结头微调，以及自监督与监督知识蒸馏。

**📊 数据集**

数据集为 xBD 灾难评估数据集，包含预/后灾区卫星图像与建筑级损坏标签。

**📈 对比分析**

通过准确率、精确率、召回率、宏平均 F1 等指标与 ResNet、Few‑Shot、UNet+ResNet18 等传统 CNN 基线对比，DeiT 端到端模型实现准确率 0.782、F1 0.599，显著优于 CNN 基线且与少量样本方法相近。

**⚠️ 局限性**

局限在于对“轻度损坏”类识别不足，数据集极度不平衡，训练受限于 Colab 算力，且仅使用单个建筑裁剪，未充分利用场景上下文。

---

## 527. VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval

**arXiv ID:** 2602.08099 | [PDF](https://arxiv.org/pdf/2602.08099v1)

**作者:** Issar Tzachor `[一作]` (OriginAI), Rami Ben-Ari `[通讯]` (OriginAI)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

利用现成的视频多模态大语言模型（MLLM）提取视频–文本嵌入，先进行中间层的零样本检索，然后使用MLLM的生成头进行重排序，最后通过仅使用文本的上下文优化（将密集视频字幕映射为简短摘要）进一步提升嵌入对齐。

**💡 创新点**

①系统分析MLLM隐藏层信息，发现中间层已携带较强检索信息；②在零样本情形下结合MLLM头的概率校准实现高效重排序；③提出仅用文本的上下文优化策略，避免视觉监督，显著提升检索性能。

**🔧 技术方法**

基于VideoLLaMA3的多模态LLM；EOL（Explicit One-word Limitation）提示；取<emb>前隐藏状态作为嵌入；MLLM生成头做二阶段校准评分；LoRA微调进行上下文优化；Dual‑Softmax 损失；文本-文本映射（密集字幕→简短摘要）。

**📊 数据集**

训练阶段使用VideoUFO数据集（约1.09M视频-字幕对），仅抽取60K条用于文本上下文优化；评估基准为MSR‑VTT、MSVD、VATEX和DiDeMo四大视频–文本检索数据集；与其他MLLM嵌入器（LamRA、VLM2Vec‑V2、UniME‑V2 等）以及视频基础模型（InternVideo2、VideoPrism、PE‑Core‑G 等）进行对比。

**📈 对比分析**

在所有四个基准上，零样本两阶段方法VidVec‑ZS均超过现有MLLM嵌入器；在文本→视频检索上VidVec‑O（仅文本优化）比最强的MLLM嵌入器提升约5–10% R@1，结合重排序进一步达到或超越大规模视频基础模型（如InternVideo2、VideoPrism）的表现，显示出极高的效率和性能优势。

**⚠️ 局限性**

主要局限：①仍聚焦于视频–文本检索任务，未验证在其他下游任务中的泛化；②依赖于预训练MLLM的质量，若基础模型表现欠佳则效果下降；③虽然省去视觉训练，但需要额外的文本标注（密集字幕→摘要），在字幕缺失的场景下受限；④对提示工程和层级选择较为敏感，需手动调优。

---

## 528. IRB: Automated Generation of Robust Factuality Benchmarks

**arXiv ID:** 2602.08070 | [PDF](https://arxiv.org/pdf/2602.08070v1)

**作者:** Lam Thanh Do `[一作]` (University of Illinois Urbana-Champaign), Wen-mei Hwu `[通讯]` (NVIDIA)

**通讯引用:** 17565 | [OpenAlex ID](https://openalex.org/A5040404999)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了IRB框架，自动生成基准测试以评估RAG系统的事实性。

**💡 创新点**

IRB通过结构化生成管道引入事实支架和算法支架，确保生成的问题和答案基于真实的、经过验证的证据。

**🔧 技术方法**

使用了知识图谱构建和图引导生成技术。

**📊 数据集**

使用了来自2024和2025年2,000篇维基百科文章的数据集，生成了1,000个问题。

**📈 对比分析**

与现有方法相比，IRB生成的基准在无外部知识的情况下对前沿LLM构成了重大挑战，且推理模型在处理错误检索时表现更可靠。

**⚠️ 局限性**

IRB生成的问题限制为短答案，且仅依赖维基百科，无法直接扩展到其他领域。

---

## 529. Securing Dual-Use Pathogen Data of Concern

**arXiv ID:** 2602.08061 | [PDF](https://arxiv.org/pdf/2602.08061v1)

**作者:** Doni Bloomfield `[一作]` (Fordham University), Jassi Pannu `[通讯]` (Johns Hopkins University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3855fcda-48ef-4070-a15e-803cd5c84d83` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了五层Biosecurity Data Level (BDL) 框架，按数据类型与AI潜在风险匹配，对病原体数据进行分级管理，并给出对应的技术控制与治理建议。

**💡 创新点**

创新点在于首次将病原体数据的安全等级与AI训练风险相结合，形成可操作的BDL体系，并提出结合数据水印、异常检测、联邦学习等技术与受信任研究环境（TRE）相衔接的整体治理方案。

**🔧 技术方法**

采用了数据水印/指纹、可追溯性与审计日志、异常检测与风险评分、Honeytokens/诱饵、联邦学习、机密计算、行为生物识别、硬件密钥、API速率限制等多种技术手段。

**📊 数据集**

论文主要以病毒测序数据、蛋白质结构与功能注释等病原体数据类型为例，阐述其在BDL不同层级中的分布；并未提供具体实验数据集或实验结果。

**📈 对比分析**

没有进行实验比较或性能评估，论证主要基于已有研究的实证观察和理论推断，强调不同数据层级对AI能力提升的预期影响。

**⚠️ 局限性**

局限在于缺乏系统的实证验证BDL分类对AI能力的具体贡献，技术实现的成本与可操作性有待评估，跨国治理与标准化统一仍面临挑战。

---

## 530. Compiler-Assisted Speculative Sampling for Accelerated LLM Inference on Heterogeneous Edge Devices

**arXiv ID:** 2602.08060 | [PDF](https://arxiv.org/pdf/2602.08060v1)

**作者:** Alejandro Ruiz y Mesa `[一作]` (Dresden University of Technology), Jeronimo Castrillon `[通讯]` (Dresden University of Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在资源受限的边缘设备上，利用编译器辅助的异构映射与推测式解码技术加速大型语言模型推理，

**💡 创新点**

创新点在于将推测式解码与多核CPU、GPU等异构处理单元结合，提出分析成本模型指导分区与设备分配，并在IREE/MLIR框架中实现高层抽象的设备亲和性；

**🔧 技术方法**

使用的技术包括推测式解码（Speculative Sampling）、IREE/MLIR编译器、LLVM/SPIR‑V后端、量化与半量化模型、成本模型分析和SoC上的Cortex‑A55+Mali‑G310异构部署；

**📊 数据集**

主要实验数据集为Spec‑Bench中的翻译任务，使用Llama 3.2 1B作为推测器、3B作为目标模型；

**📈 对比分析**

通过与单CPU、非推测基线对比，证明在可接受的接受率α≈0.9时，异构映射可实现最高1.68×的速度提升，实际测得的加速与模型预测相差约4%；

**⚠️ 局限性**

局限性包括：接受率受量化影响而下降、IREE无法直接支持GPU后端导致需分离图形编译、未覆盖更细粒度分区与其他加速器，且实验仅验证单一SoC与单一任务。

---

## 531. Picasso: Holistic Scene Reconstruction with Physics-Constrained Sampling

**arXiv ID:** 2602.08058 | [PDF](https://arxiv.org/pdf/2602.08058v1)

**作者:** Xihang Yu `[一作]` (Massachusetts Institute of Technology), Luca Carlone `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 12382 | [OpenAlex ID](https://openalex.org/A5042157108)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了 Picasso，一种利用物理约束的快速拒绝采样方法，对多物体场景进行全局重建，并发布了包含接触信息的 Picasso 数据集及物理可行性度量。

**💡 创新点**

创新点在于：①通过物理约束的采样框架避免了梯度下降陷入局部极小值；②利用接触场景图将全局问题分解为子问题，显著降低采样维度；③提供了真实接触丰富场景的数据集和新颖的 SPS 指标，推动物理可行性评估。

**🔧 技术方法**

采用的技术包括：RGB‑D 点云配准、SDF 与 libigl 的碰撞检测、VLM 推断接触图、GPU 并行粗精拒绝采样、Geman‑McClure 鲁棒损失、PyBullet 物理仿真等。

**📊 数据集**

使用的数据集有：Picasso 数据集（10 个真实接触场景），YCB‑V、YCB‑Video 以及 SAM3D、CRISP 的训练与测试图像。

**📈 对比分析**

通过与 CRISP、SAM3D 以及多种基线（梯度下降、ICP、Physics‑guided 等）在 ADD‑S、SPS、NPS、OC 等指标上的对比，Picasso 在几何精度提升约 35%，物理可行性提升 28%，SPS 提升 10% 以上，同时推断时间保持在 1 秒以内。

**⚠️ 局限性**

局限性包括：①采用近似的 DAG 接触图，无法完整捕捉循环交互导致的全局最优；②对形状估计误差和深度噪声敏感；③采样效率仍受限，尤其在高度噪声或极度重叠场景下可能出现失败。

---

## 532. Epigraph-Guided Flow Matching for Safe and Performant Offline Reinforcement Learning

**arXiv ID:** 2602.08054 | [PDF](https://arxiv.org/pdf/2602.08054v1)

**作者:** Manan Tayal `[一作]` (TAU Intelligence), Mumuksh Tayal `[通讯]` (TAU Intelligence)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `9cc9baba-5356-466d-81ff-d80028d90279` `40105733-5154-44cd-8090-a8cab9e64b07` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种基于“epigraph”重构的离线强化学习框架 EpiFlow，能够同时优化安全约束与任务回报；

**💡 创新点**

创新点在于：①把硬安全约束转化为可学习的辅助价值函数；②使用期望回归(expectile regression)逼近价值函数，避免 OOD 推断；③采用流匹配（Flow Matching）生成可执行的连续动作策略，并通过权重重新采样保证在数据分布内；

**🔧 技术方法**

技术手段包括：epigraph 形式的状态约束最优控制、Bellman 样式递归、期望回归、奖励/安全值分解、流匹配生成模型；

**📊 数据集**

使用的评估数据集：Safety Gymnasium（Safe Velocity、Safe Navigation 任务）和自定义的 2 维船舶碰撞避免环境；

**📈 对比分析**

与 BEAR‑Lag、BCQ‑Lag、COptiDICE、CPQ、C2IQL、FISOR 等基线对比，EpiFlow 在保持接近零安全违规的同时，获得与这些方法相当或更高的累计奖励；

**⚠️ 局限性**

局限性：①安全性仅为经验性、基于分布内的“安全证书”，缺乏正式的 worst‑case 保障；②依赖高维流匹配模型的表达能力；③目前仅适用于确定性离线数据，尚未扩展到随机或对抗性环境。

---

## 533. TDGNet: Hallucination Detection in Diffusion Language Models via Temporal Dynamic Graphs

**arXiv ID:** 2602.08048 | [PDF](https://arxiv.org/pdf/2602.08048v1)

**作者:** Arshia Hemmat `[一作]` (University of Oxford), Junchi Yu `[通讯]` (University of Oxford)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `3f18e8e3-0266-457c-8567-9039b6d2394d` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 TDGNet，利用时间动态图网络在扩散式语言模型的去噪轨迹中检测并定位幻觉

**💡 创新点**

创新点在于把幻觉检测视为随时间演变的注意力图学习问题，结合图结构与时间记忆实现单轮推理下的响应级和令牌级检测

**🔧 技术方法**

使用的技术包括动态注意力图构造、消息传递网络、GRU 时序记忆、时间注意力聚合，以及与扩散模型的内置注意力信息无缝集成

**📊 数据集**

在 LLaDA‑8B 与 Dream‑7B 上的多QA基准（Math、CommonsenseQA、HotpotQA、TriviaQA、Natural Questions）进行评估

**📈 对比分析**

与输出、潜在、静态图等传统基线相比，TDGNet 在所有数据集上平均提升约 8–10% 的 AUROC，且仅需单次推理，开销小

**⚠️ 局限性**

局限性包括：仅在公开的 D‑LLM 上验证，未覆盖更大模型或不同扩散参数；检测性能受注意力图阈值和图构造方式影响；对长文本或多模态生成场景的适用性尚未探测

---

## 534. Vanilla Group Equivariant Vision Transformer: Simple and Effective

**arXiv ID:** 2602.08047 | [PDF](https://arxiv.org/pdf/2602.08047v1)

**作者:** Jiahong Fu `[一作]` (Xi an Jiaotong University), Zongben Xu `[通讯]` (Xi an Jiaotong University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文通过对 Vision Transformer 的 Patch Embedding、Self‑Attention、位置编码、下采样/上采样和 LayerNorm 等核心模块进行系统重构，实现了旋转和镜像反射的严格等变性。

**💡 创新点**

创新点在于提出一种通用的等变性框架，兼容 ViT 与 Swin Transformer，利用群等变卷积、等变线性投影、群轨道规范化位置编码以及等变重采样层，首次在保证完整等变性的前提下实现性能提升和参数效率。

**🔧 技术方法**

技术核心包括群等变卷积（EQ‑Patch Embedding）、等变线性投影实现 Self‑Attention（EQ‑SA）、基于群轨道的绝对/相对位置编码（EQ‑APE、EQ‑RPE）、等变下/上采样层（EQ‑Down/Up‑Sampling）以及等变层归一化（EQ‑LN）。

**📊 数据集**

实验使用 ImageNet‑1K、miniImageNet、COCO 2017、ADE20K、Urban100、BSD100、Set14、Set5、Manga109、REDS 等数据集。

**📈 对比分析**

与基准 ViT、DeiT、Swin、XCiT 等模型对比，等变 ViT 在图像分类、目标检测、语义分割以及超分辨率任务中均取得 1–3% 的准确率提升、1–2% 的 mAP 增长以及 0.05–0.15 dB 的 PSNR 提升，同时参数量下降或维持相近。

**⚠️ 局限性**

局限性包括：仅针对离散旋转与镜像（C4、D4）群；实现成本略高；对更大或连续对称群的扩展尚未验证；且在极大规模任务中训练时间仍受 Self‑Attention 复杂度限制。

---

## 535. Enhanced Mixture 3D CGAN for Completion and Generation of 3D Objects

**arXiv ID:** 2602.08046 | [PDF](https://arxiv.org/pdf/2602.08046v1)

**作者:** Yahia Hamdi `[一作]`, Emilie Poisson Caillault `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `afceb026-1760-41ae-8d86-010831a37d97` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了一种基于 Mixture of Experts（MoE）的 3D 生成对抗网络（CGAN），可同时完成和生成三维物体，尤其针对不完整或受损的 3D 对象进行高质量重建。

**💡 创新点**

创新点包括：① 引入上下文感知的门控网络，在生成与完成任务中根据潜在向量与局部信息动态路由到最合适的专家；② 采用无辅助损失的动态容量约束（DCC）实现专家的隐式专业化与负载平衡；③ 通过稀疏专家激活与 Top‑K 选择，在保证生成质量的同时显著降低 FLOPs 与推理时延。

**🔧 技术方法**

主要技术：3D Convolutional GAN、MoE 结构、稀疏激活、DCC 负载调度、混合体素/三平面表征、Spectral Normalization、残差/膨胀卷积、上下文感知门控网络、梯度惩罚等。

**📊 数据集**

使用 ShapeNet（Airplane、Chair 子集）和真实海洋生物学数据集（691 条红鲽鱼（Mullus barbatus）的 otolith 形状）进行训练与评估。

**📈 对比分析**

与多种基线（3DGAN、RaGAN、PrGAN、DiffComplete 等）比较，MoE‑CGAN 在 CD、HD、EMD 以及 PRR 等指标上普遍取得更优成绩；尤其在 3D 生成与完成任务中，n=8 专家配置在保持参数量仅略增的同时，将 FLOPs 从 124G 降至 38G，推理时间从 45 ms 降至 28 ms，表现出显著的性能提升。

**⚠️ 局限性**

局限性：① 对极端遮挡（>80% 缺失）仍易出现结构不连贯；② 体素分辨率限制导致细节（如细长部件、尖锐边缘）难以准确重建；③ 专家专业化在跨类别泛化时可能受限；④ MoE 训练复杂度高，需要细致的超参数调优以防止专家饥饿或模式崩塌。

---

## 536. Fields of The World: A Field Guide for Extracting Agricultural Field Boundaries

**arXiv ID:** 2602.08131 | [PDF](https://arxiv.org/pdf/2602.08131v1)

**作者:** Isaac Corley `[一作]` (Wherobots), Jennifer Marcus `[通讯]` (Taylor Geospatial)

**通讯引用:** 1128 | [OpenAlex ID](https://openalex.org/A5111658568)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

构建了 Fields of The World (FTW) 生态系统，提供 1.6M 场地边界多国数据、预训练分割模型和命令行推理工具，支持从 Sentinel‑2 图像自动生成农田边界并进行作物分类与森林损失归因。

**💡 创新点**

创新点在于整合全球范围内 1.6M 场地边界作为基准、采用双时相 Sentinel‑2 进行分割、利用 MOSAIKS 随机卷积嵌入实现少量样本作物分类，并将预测结果以云原生 Zarr 归档，实现跨国、跨时相的高效查询与变更检测。

**🔧 技术方法**

使用的技术包括 U‑Net + EfficientNet‑B3 的 Encoder‑Decoder 深度学习分割、双时相 Sentinel‑2 预处理、MOSAIKS 随机卷积特征、逻辑回归作物分类、Hansen GFC 归因森林损失、云原生 Zarr 存储与推理命令行工具。

**📊 数据集**

使用的数据集包含 24 国 1.6M 场地边界、双时相 Sentinel‑2 影像、USDA Cropland Data Layer 标签、Hansen Global Forest Change 变化数据，以及预计算的 5 国国家级预测结果。

**📈 对比分析**

通过在美国爱荷华州 14TPN 区域对 10% 标注训练实现宏 F1 0.65–0.75 的作物分类，性能与全量训练相差不足 5%，并展示了对森林损失的精确归因和国家级预测的年度变化检测。

**⚠️ 局限性**

局限性包括对 Sentinel‑2 影像云覆盖和分辨率的依赖、阈值化后可能遗漏小型农场、作物类别不平衡导致少数类准确率低、模型在未覆盖地区的迁移性能未知以及对云原生推理工具的使用门槛。

---

## 537. From Ellipsoids to Midair Control of Dynamic Hitches

**arXiv ID:** 2602.08116 | [PDF](https://arxiv.org/pdf/2602.08116v1)

**作者:** Jiawei Xu `[一作]` (Lehigh University), David Saldaña `[通讯]` (Lehigh University)

**通讯引用:** 1061 | [OpenAlex ID](https://openalex.org/A5023803863)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

研究了一种由四架无人机操纵两条缠绕电缆形成的 hitches 的动态控制方法，能够实现对 hitches 位置和形状的实时追踪。

**💡 创新点**

创新点包括：① 基于椭球几何推导出控制仿射的全动态模型；② 结合控制 Lyapunov 函数 (CLF) 与高阶控制障碍函数 (HOCBF) 的二次规划（QP）控制器；③ 通过级联误差设计消除相对度高导致的控制难题；④ 在仿真中实现了接近 1 m/s 的高速动态轨迹跟踪，显著优于传统准静态方法。

**🔧 技术方法**

采用的技术有：椭球几何约束的动力学建模、Newton 运动学、CLF–HOCBF–QP 控制框架、离散时间 Euler 积分、Python+cvxpy+OSQP 求解器等。

**📊 数据集**

未使用公开数据集；所有评估均在自建的随机初始状态仿真环境中完成。

**📈 对比分析**

通过三类仿真（静态跟踪、受噪声影响的慢速跟踪、逐步加速的动态跟踪）评估 Lyapunov 函数值与配置误差。结果显示：在 0.9 m/s 的高速动态参考下，Lyapunov 仍收敛，误差保持有界；在噪声条件下仍能保持稳定；总体性能优于传统准静态控制策略。

**⚠️ 局限性**

局限性：① 虚拟质量参数未知且未在线估计，可能影响鲁棒性；② 目前仅在仿真验证，缺乏硬件实验支持；③ 对极端外部扰动或大负载情况的适应性尚未评估。

---

## 538. Term Coding and Dispersion: A Perfect-vs-Rate Complexity Dichotomy for Information Flow

**arXiv ID:** 2602.08110 | [PDF](https://arxiv.org/pdf/2602.08110v1)

**作者:** Søren Riis `[一作]` (Queen Mary University of London), Søren Riis `[通讯]` (Queen Mary University of London)

**通讯引用:** 1092 | [OpenAlex ID](https://openalex.org/A5005137861)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

提出了“项编码（term coding）”框架，研究在给定函数符号解释的前提下最大化满足给定项方程组的赋值数量，并聚焦其特殊子问题——分散度（dispersion），即最大化由项定义的映射的像的大小。

**💡 创新点**

核心创新包括：①将分散度问题与图猜测游戏（guessing game）和图熵/猜测数（guessing number）联系起来，形成“猜测数夹逼”定理；②证明分散度的渐近指数为整数，可通过最大流/最小割算法在多项式时间内计算；③揭示完美分散（即映射可达到全像 n^r）与指数计算之间的显著复杂度二分——存在性判定是不可判定的，而阈值判定是多项式可解的。

**🔧 技术方法**

使用的技术包括：项式化简与归一化（flattening）、变量合并（quotienting）、消除左侧冲突、功能化规范化（FNF）、多样化（diversification）以及构造依赖图；将问题转化为猜测游戏；利用网络流理论构造辅助流网络 N(t) 并通过最大流/最小割求得整数指数 D(t)。

**📊 数据集**

该工作为理论研究，无需实测数据集；所有结果基于形式化的计算模型与算法分析。

**📈 对比分析**

方法对比：对于需要判断是否存在完美分散的决策问题，结果是不可判定的，说明在这类精确阈值查询上没有有效算法；而对于“渐近阈值”判定，算法可在多项式时间内完成，并给出精确的整数指数 D(t) 作为性能指标；因此在大规模/近似评估场景下性能可被保证。

**⚠️ 局限性**

局限性：①对 r=2 的完美分散判定仍为开放问题；②多项式时间解仅适用于单排序分散度，尚未覆盖多排序/更一般的项编码情况；③实际实现需要构造大规模流网络，可能导致常数因素较大；④证明涉及复杂的可判定性与不可判定性转换，实际应用中难以直接映射到具体网络编码实例。

---

## 539. Energy-Controllable Time Integration for Elastodynamic Contact

**arXiv ID:** 2602.08094 | [PDF](https://arxiv.org/pdf/2602.08094v1)

**作者:** Kevin You `[一作]` (Carnegie Mellon University), Minchen Li `[通讯]` (Carnegie Mellon University)

**通讯引用:** 1561 | [OpenAlex ID](https://openalex.org/A5087311970)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `a8e75ba4-7a2d-4153-b003-06c94533add0` `4de8e9d8-757b-475f-9627-18a445e50202` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出一种可控能量的弹性体时间积分器A‑search，能在大时间步长下保持稳定且能根据用户需求调节能量耗散。

**💡 创新点**

创新点在于引入解耦对称（decoupled symplectic）方法，将传统隐式欧拉分离为位置更新与动量插值两步，并通过α插值实现能量控制；同时证明A‑1在线性系统下无条件稳定并在碰撞中保持速度不失真。

**🔧 技术方法**

核心技术包括：隐式欧拉基础、对称/分离的Runge‑Kutta方法、α插值控制能量、基于IPC的碰撞处理、半隐式阻尼与摩擦求解、Newton迭代与共轭梯度线性求解、自动α搜索与指数能量衰减。

**📊 数据集**

实验数据集主要由多种网格模型组成：软硬立方体、扭曲杆、悬挂甲虫、软绒球、骰子滚动、爬楼梯、弹簧跳跃等；使用标准tetrahedral网格与线性/Neo‑Hookean材料，加入IPC碰撞与摩擦。

**📈 对比分析**

与BDF2、隐式欧拉、Trapezoidal、Blending、SDIRK等方法对比；A‑search在相同时间步长下能量损失显著低于BDF2，甚至在相同总运行时间下能量保持更好，表现出更高频动量被抑制、低频运动保留的特性；在碰撞测试中保持速度不失真；总体运行时间与BDF2相当或略高，但Newton迭代次数更少，条件数更差。

**⚠️ 局限性**

局限性：仅为一阶准确，理论分析主要在1D线性系统，非凸约束和高非线性场景下的理论保证有限；α参数需要经验调节；在极硬度/大时间步长下仍可能产生高频噪声；需要进一步研究更高阶解耦方法与自适应时间步控制。

---

## 540. The CAPSARII Approach to Cyber-Secure Wearable, Ultra-Low-Power Networked Sensors for Soldier Health Monitoring

**arXiv ID:** 2602.08080 | [PDF](https://arxiv.org/pdf/2602.08080v1)

**作者:** Luciano Bozzi `[一作]` (Sea Sky Technologies), Xabier Eguiluz `[通讯]` (IKERLAN)

**通讯引用:** 33 | [OpenAlex ID](https://openalex.org/A5031293290)

**关键词:** `7a50eb32-3dbc-4c3e-a038-bda01b2d9965` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

开发了一套基于IoBT的可穿戴系统，实时监测士兵生理、运动及环境参数，并在边缘部署AI进行决策支持。

**💡 创新点**

将智能纺织、RISC‑V安全微控制器、边缘AI、联邦学习与PIM等技术融合，形成全栈低功耗、可联邦学习的士兵监测平台。

**🔧 技术方法**

采用智能纺织传感器、RISC‑V微控制器、边缘AI推理、联邦学习、PIM加速、量化与剪枝优化、以及安全加密/认证协议。

**📊 数据集**

未公开具体公开数据集；实验数据来源于项目内部的试验人群（飞行员疲劳和士兵环境）收集。

**📈 对比分析**

论文未给出量化对比或性能指标，强调框架可扩展、低功耗与联邦学习兼容，未来将通过实验验证。

**⚠️ 局限性**

缺乏实测性能评估与标准化数据集，安全实现尚待验证，能耗与实时性需进一步量化。

---

## 541. Initial Risk Probing and Feasibility Testing of Glow: a Generative AI-Powered Dialectical Behavior Therapy Skills Coach for Substance Use Recovery and HIV Prevention

**arXiv ID:** 2602.08121 | [PDF](https://arxiv.org/pdf/2602.08121v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 542. IssueGuard: Real-Time Secret Leak Prevention Tool for GitHub Issue Reports

**arXiv ID:** 2602.08072 | [PDF](https://arxiv.org/pdf/2602.08072v1)

**作者:** Md Nafiu Rahman `[一作]` (Bangladesh University of Engineering and Technology), Rifat Shahriyar `[通讯]` (Bangladesh University of Engineering and Technology)

**通讯引用:** 1091 | [OpenAlex ID](https://openalex.org/A5090604535)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现 IssueGuard，一款 Chrome 扩展，在 GitHub/GitLab issue 编辑器中实时检测并预防秘密泄露

**💡 创新点**

创新点在于将正则提取与 fine‑tuned CodeBERT 语境分类结合，既保持高精度又实现低延迟的实时预防功能，避免了传统后置扫描导致的警报疲劳

**🔧 技术方法**

技术包括 Chrome 扩展客户端、FastAPI 后端、761 条正则候选提取、CodeBERT 语义分类、FP16 混合精度推理、LRU 缓存与异步处理

**📊 数据集**

使用自建的 54,148 条标注 issue 数据集（5,881 条真秘密）进行训练，并在 178 个真实仓库上验证泛化性能

**📈 对比分析**

与 StarCoder、StarPII、RoBERTa、TruffleHog、Gitleaks 等模型/工具对比，IssueGuard 在 F1 评分 92.70%，平均延迟 0.198 s，用户研究显示 90% 置信度、80% 满意度

**⚠️ 局限性**

局限性包括仅支持 GitHub/GitLab，依赖网络后端，模型仍可能漏检高度混淆的伪秘密，对多浏览器或大规模部署的适配尚待改进

---

## 543. V-ABFT: Variance-Based Adaptive Threshold for Fault-Tolerant Matrix Multiplication in Mixed-Precision Deep Learning

**arXiv ID:** 2602.08043 | [PDF](https://arxiv.org/pdf/2602.08043v1)

**作者:** Yiheng Gao `[一作]` (Peking University), Zizhong Chen `[通讯]` (Chinese University of Hong Kong)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了 V-ABFT 算法，用统计方差估计自适应阈值，实现矩阵乘法的零误报故障容错；

**💡 创新点**

创新点在于直接建模验证差值并使用极值-方差不等式仅凭最大值、最小值和均值计算阈值，复杂度降到 O(n)，大幅缩小阈值宽度并支持 BF16/FP16/FP32/FP64 多种精度；

**🔧 技术方法**

采用统计方差估计、极值-方差不等式、ABFT 校验编码、误差模型、经验 e_max 校准以及 GPU/NPUs 的实际测量；

**📊 数据集**

使用合成分布（正态、均匀、截断正态）以及真实模型权重（LLaMA‑7B、GPT‑2、ViT‑B/32）进行评估；

**📈 对比分析**

通过与 A-ABFT 的阈值紧密度、误报率和检测率比较，V-ABFT 在 FP64/FP32/ BF16 分别实现 7–20×/48–158× tighter 的阈值、100% 高指数位检测率、0% 误报率，性能开销在 11–12% 以内；

**⚠️ 局限性**

局限性：仍需经验 e_max 校准、极值-方差不等式在某些分布下保守、仅检测单行单误差假设、未给出严格理论证明。

---

## 544. Online Bayesian Imbalanced Learning with Bregman-Calibrated Deep Networks

**arXiv ID:** 2602.08128 | [PDF](https://arxiv.org/pdf/2602.08128v1)

**作者:** Zahir Alsulaimawi `[一作]` (Oregon State University), Zahir Alsulaimawi `[通讯]` (Oregon State University)

**通讯引用:** 38 | [OpenAlex ID](https://openalex.org/A5012438164)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了在线贝叶斯失衡学习（OBIL）框架，利用贝叶斯决策理论和Bregman对数损失实现对类别先验变化的实时适应。

**💡 创新点**

创新点在于将Bregman校准的深度网络输出直接转换为先验不变的似然比，并通过EMA估计器在无需标签数据的前提下在线调整阈值，实现对标签转移的自适应。

**🔧 技术方法**

主要技术包括Bregman散度与正确评分规则的等价性、深度网络的概率校准、似然比直接估计、EMA在线先验估计与阈值调节，以及基于Tsukakov边际条件的理论收敛与风险上界分析。

**📊 数据集**

实验使用KEEL和UCI的多类不平衡数据集（如Yeast4、Abalone19、Mammography、Credit Card Fraud、Thyroid Disease）进行评估，并在模拟的先验转移下进行测试。

**📈 对比分析**

与SMOTE、ADASYN、Cost-Sensitive、RUSBoost、Threshold Moving、BBSE、Logit Adjustment等八种基线相比，OBIL在先验偏移幅度增大时保持更高的F1分数，整体性能超过最优基线7–10个百分点，且在线适应能快速跟踪先验变化。

**⚠️ 局限性**

主要局限包括对标签转移假设（类别条件分布不变）的依赖、对显著协变量漂移的鲁棒性不足、对多分类扩展缺乏实证验证，以及在极端快速先验变化时需重新训练。

---

## 545. Neighborhood-Aware Graph Labeling Problem

**arXiv ID:** 2602.08098 | [PDF](https://arxiv.org/pdf/2602.08098v1)

**作者:** Mohammad Shahverdikondori `[一作]` (École Polytechnique Fédérale de Lausanne), Negar Kiyavash `[通讯]` (École Polytechnique Fédérale de Lausanne)

**通讯引用:** 2990 | [OpenAlex ID](https://openalex.org/A5012789968)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

研究邻域感知图标记（Neighborhood‑Aware Graph Labeling）问题，提出其硬度、SETH‑tight 下限以及精确与近似算法。

**💡 创新点**

创新点在于：①用平方图 G² 的树宽来刻画问题的复杂度，并给出与之匹配的 FPT 动态规划；②在非负奖励下提出基于颜色划分的 1/q 近似和在平面图上的 Baker‑型 PTAS/EPTAS；③给出多项式时间下不可近似的证明。

**🔧 技术方法**

使用的技术包括：树分解与动态规划、颜色化与贪心上色、Baker 分层剪枝、SETH‑based SAT 减约、以及对树宽与图幂关系的分析。

**📊 数据集**

论文为纯理论工作，没有使用具体数据集；所有结果均在算法复杂度和近似比率上进行理论分析。

**📈 对比分析**

与现有最大集、图割等经典问题相比，本文在非负奖励情形下提供 1/q 或 (1-ε) 的近似保证；在平面图上实现 PTAS，若标签数 L 为常数可得到 EPTAS。

**⚠️ 局限性**

局限性包括：仅在奖励非负时才有近似结果；对含负奖励或更一般奖励函数缺乏近似上界；以及在高度稠密图（如 G² 的树宽大）下的效率仍受限。

---

## 546. Prune, Don't Rebuild: Efficiently Tuning $α$-Reachable Graphs for Nearest Neighbor Search

**arXiv ID:** 2602.08097 | [PDF](https://arxiv.org/pdf/2602.08097v1)

**作者:** Tian Zhang `[一作]` (University of Pennsylvania), Erik Waingarten `[通讯]` (University of Pennsylvania)

**通讯引用:** 373 | [OpenAlex ID](https://openalex.org/A5091677337)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出一种基于 DiskANN pruned 子程序的后处理算法，能够在不重建索引的前提下动态调整 α‑reachable 参数，从而快速完成索引调优。

**💡 创新点**

创新点在于：①证明该 pruning 方案在一般度量空间和欧氏度量空间中仍能保持良好的 worst‑case reachability；②在实际数据上验证 pruned 图比从头重建具有更优的 recall‑QPS 前沿，且调优速度提升高达 43×。

**🔧 技术方法**

使用 DiskANN 的 α‑reachable 构造子程序 (α‑prune)，结合理论分析（α‑reachability、最坏情况距离优化）和实验评估；实验中用 SIFT‑1M、GIST‑1M、Deep‑1M、MSSPACEV‑1M 四个公共数据集。

**📊 数据集**

数据集：SIFT‑1M（128‑维）、GIST‑1M（960‑维）、Deep‑1M（96‑维）以及 MSSPACEV‑1M（100‑维）四个大规模向量集合。

**📈 对比分析**

通过将基准 DiskANN 图（α=1.2）逐步 pruning 成 α=1.1、1.05、1.01，并与从头重建相同 α 的索引进行比较。结果显示：prune 的总调优时间比重建快 14–43 倍；在 recall‑QPS 方面，prune 构造出的前沿始终优于重建，尤其在 GIST‑1M 上达到 43× 的加速；同时 pruned 图在相同 α 下拥有更高的查询吞吐量和更低的内存占用。

**⚠️ 局限性**

局限性：理论 worst‑case reachability 在欧氏空间下仍比重建略差；prune 依赖于原始高质量图，若起始图本身不佳则无法获得优势；在极稀疏配置下（如 α 接近 1）仍可能出现查询效率下降的情况。

---

## 547. Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities

**arXiv ID:** 2602.08092 | [PDF](https://arxiv.org/pdf/2602.08092v1)

**作者:** Majid Ghasemi `[一作]` (University of Waterloo), Mark Crowley `[通讯]` (University of Waterloo)

**通讯引用:** 1597 | [OpenAlex ID](https://openalex.org/A5064795613)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

本文提出一种名为 Epistemic Source Alignment (ESA) 的新型对齐框架，利用稀疏的内部公理来评估评审者的可信度，从而过滤社会反馈中的系统性偏见，解决了传统 RL 在社交环境中出现的目标脱离（Objective Decoupling）问题。

**💡 创新点**

创新点在于把对齐的重点从“谁说得最多”转向“谁与内部公理一致”，引入了“判定评审者”而非传统的投票或聚合方法，并在理论上证明在信息优势下可指数级消除有偏评审者的影响。

**🔧 技术方法**

技术上结合了多臂社会马尔可夫决策过程 (Social MDP)、乘法权重更新 (MWU)、稀疏公理检测、以及对基准 RL 算法（如 Q‑Learning、PPO）的无缝集成；同时在实验中采用了基于仿真和强化学习的环境。

**📊 数据集**

实验使用了三种测试平台：10×10 网格世界（含安全与代理奖励）、MuJoCo Hopper‑v4（连续控制与速度奖励）以及 K‑armed 社会多臂老虎机（统计真相发现），其中未使用公开数据集，而是自行构造的模拟环境。

**📈 对比分析**

在与标准 RL、基于均值/中位数的鲁棒统计聚合、Dawid‑Skene 以及 GAIL 代理对抗的比较中，ESA 在所有测试中均实现了更低的潜在代价、较快的恢复速度，并在 80% 评审者偏见时仍保持亚线性累积误差，明显优于对齐失败的基准方法。

**⚠️ 局限性**

主要局限是对内部公理的依赖：目前公理需人工设计且为稀疏且静态，未来需研究自动化公理生成和在更复杂多元环境中的可扩展性。

---

## 548. Online Domain-aware LLM Decoding for Continual Domain Evolution

**arXiv ID:** 2602.08088 | [PDF](https://arxiv.org/pdf/2602.08088v1)

**作者:** Mohammad Abu-Shaira `[一作]` (University of North Texas), Weishi Shi `[通讯]` (University of North Texas)

**通讯引用:** 169 | [OpenAlex ID](https://openalex.org/A5035107019)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了在线域感知解码框架，利用LLM与动态维护的前缀Trie先验进行概率级融合，以在概念漂移环境下实现无训练、无检索的实时适配。

**💡 创新点**

创新点包括：1）无额外模型训练或外部检索即可在线适配；2）通过不一致性(disagreement)与连续性(continuity)两种动态信号自适应调节LLM与Trie置信度；3) 对Trie先验做温度校准和概率融合，保持两者尺度一致；4) 采用轻量级Trie实现O(L)插入、O(L²)检索，保持低延迟。

**🔧 技术方法**

使用技术包括：前缀Trie（N-gram）构建与更新、温度自适应校准、熵与JSD的置信度评估、动态加权融合、基于最大熵的温度调节、LLM+Trie混合解码。

**📊 数据集**

实验数据集为Bitext Telco LLM Chatbot数据（≈26k样本，26意图），通过替换placeholder构造了突发、递增、渐进三种概念漂移场景。

**📈 对比分析**

与LLM-Greedy和LLM-TempScaled两种基线解码方法进行比较，在所有漂移场景下均实现了显著提升：绝对ROUGE‑L提升0.065，余弦相似度提升13.6%，同时在BLEU、BERTScore等语义指标上保持领先。

**⚠️ 局限性**

局限性包括：1）依赖Trie结构，需手工设置特征权重λ；2）在长序列或高并发环境下检索复杂度可能上升；3）目前仅针对placeholder实体验证，泛化到更复杂实体或多模态场景需进一步探索。

---

## 549. Spectral Guardrails for Agents in the Wild: Detecting Tool Use Hallucinations via Attention Topology

**arXiv ID:** 2602.08082 | [PDF](https://arxiv.org/pdf/2602.08082v1)

**作者:** Valentin Noël `[一作]` `[通讯]` (Devoteam), Valentin Noël (Devoteam)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出一种无训练的光谱守栏，通过分析Transformer注意力图谱的拉普拉斯谱来检测工具调用中的幻觉，直接部署于生产代理。

**💡 创新点**

创新点在于：①把注意力矩阵视为动态图并计算其谱特征（熵、Fiedler、平滑度、HFER）作为无监督幻觉判别器；②发现“Loud Liar”现象——Llama 3.1 8B 的幻觉在单层谱特征上几乎完美可检；③跨模型对照实验揭示不同架构的谱失效几何。

**🔧 技术方法**

技术手段包括：对每层头聚合权重得到无向图，构造组合图拉普拉斯；使用Lanczos或近似方法求前k个特征值；计算四类谱诊断指标；阈值化判别并可组合多特征。

**📊 数据集**

实验使用 Glaive Function Calling v2 数据集，在 General/Mixed（N=1000，T=0.3）和 Finance（N=1000）域分别评估 Qwen 0.5B、Mistral 7B 与 Llama 3.1 8B。

**📈 对比分析**

与监督 MLP、语义相似度基线对比，光谱方法在 Recall 端表现最优：单特征 L26 Smoothness 98.2% Recall、5特征 97.7% Recall；在 Balanced 端 Llama Finance 86.1% Recall/81% Precision；Mistral 7B 在 AUC 上最高 0.900；整体提升 10–15% Recall，Precision 仍有限。

**⚠️ 局限性**

局限性包括：高温度下谱信号被噪声掩盖，单特征 Precision 较低（≈20–25%），需阈值重新校准，且实验仅覆盖三种架构与工具调用场景，未验证多轮对话、不同工具模式下的泛化。

---

## 550. Investigating Energy Bounds of Analog Compute-in-Memory with Local Normalization

**arXiv ID:** 2602.08081 | [PDF](https://arxiv.org/pdf/2602.08081v1)

**作者:** Brian Rojkov `[一作]` (University of Waterloo), Manoj Sachdev `[通讯]` (University of Waterloo)

**通讯引用:** 11118 | [OpenAlex ID](https://openalex.org/A5086259491)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329`

**🎯 论文内容**

本文提出并分析了在模拟Compute-in-Memory（CIM）电路中加入增益调节（Gain‑Ranging）阶段，从而实现浮点数的直接本地归一化与累加。

**💡 创新点**

创新点在于：①通过局部归一化把指数信息移入数字域，②增益调节使各个乘加单元按指数加权累加，③显著降低ADC分辨率需求，④实现动态范围与精度解耦，避免了传统浮点转整数所产生的能耗与精度损失。

**🔧 技术方法**

采用的技术包括：电容阵列模拟乘加、可变开关电容增益调节、数字一次性指数加法树、低功耗DAC/ADC量化模型以及寄生补偿与非整数电容尺寸技术。

**📊 数据集**

论文为设计空间探索，未使用具体深度学习数据集；而是基于三种统计分布（均匀、最大熵、Gaussian+outliers）来模拟输入/权重量化。

**📈 对比分析**

通过能耗模型与传统INT‑CIM对比，结果显示在35 dB SQNR标准下，GR‑CIM可实现4比特动态范围提升且能耗仅提升约21%（相较于传统方案能耗降低约23%在FP4_E2M1配置下），并在10 TOPS/W时区间内保持低功耗。

**⚠️ 局限性**

局限性包括：①需要额外的数字逻辑和增益调节电容尺寸，对面积与寄生匹配有更高要求；②在高精度或高频工作时，ADC热噪声仍然限制能效；③在极大动态范围时仍需全局归一化或分段，增加实现复杂度。

---

## 551. Enhancing Bandit Algorithms with LLMs for Time-varying User Preferences in Streaming Recommendations

**arXiv ID:** 2602.08067 | [PDF](https://arxiv.org/pdf/2602.08067v1)

**作者:** Chenglei Shen `[一作]` (Renmin University of China), Jun Xu `[通讯]` (Renmin University of China)

**通讯引用:** 13791 | [OpenAlex ID](https://openalex.org/A5020766468)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出 HyperBandit+，一种结合时间感知超网络和 LLM 辅助热启动的上下文多臂赌博机推荐算法，专为周期性非平稳流式推荐设计。

**💡 创新点**

创新点包括：① 用超网络根据时间周期生成用户偏好矩阵，实现对时变偏好的在线自适应；② 通过 LLM 生成增强的用户/项目嵌入和模拟交互数据，实现离线热启动，显著提升初期探索‑利用效率；③ 在超网络输出中引入低秩分解与 Euler 编码，降低训练复杂度并捕捉周期性特征。

**🔧 技术方法**

技术手段包括：上下文多臂赌博机框架、超网络（MLP）、时间周期的 Fourier（Euler）编码、低秩矩阵分解、LLM 辅助的数据增强与热启动、Ridge 回归更新以及 ListNet 风格的损失训练。

**📊 数据集**

实验数据集：短视频推荐的 KuaiRec、以及两份 Foursquare 位置点（NYC 与 TKY）数据集。

**📈 对比分析**

与传统基线（LinUCB、HybridLinUCB、DLinUCB、ADTS、FactorUCB、HyperBandit）对比，HyperBandit+ 在累积奖励和归一化累计奖励上均优于全部基线；在初期阶段表现尤为突出，且训练与在线推理时间均保持在毫秒级，满足实时需求。

**⚠️ 局限性**

局限性包括：需要 LLM 生成的高质量模拟数据，模型对 LLM 质量高度敏感；超网络和低秩分解在极大规模场景下仍需进一步优化；目前仅在基于点击/签到的二元反馈环境验证，尚未评估多元或多阶奖励情境。

---

## 552. Efficient and Adaptable Detection of Malicious LLM Prompts via Bootstrap Aggregation

**arXiv ID:** 2602.08062 | [PDF](https://arxiv.org/pdf/2602.08062v1)

**作者:** Shayan Ali Hassan `[一作]` (King Abdullah University of Science and Technology), Marco Canini `[通讯]` (King Abdullah University of Science and Technology)

**通讯引用:** 4601 | [OpenAlex ID](https://openalex.org/A5042255975)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于 Bootstrap 聚合与专家混合的轻量级可增量更新框架 Bagel，用以检测 LLM 的恶意提示。

**💡 创新点**

创新点在于：①在不同攻击数据集上微调小模型形成专门专家；②用随机森林路由定位最适合的专家，并与随机选取的其他专家做概率聚合；③不依赖大模型，仅使用 86 M 参数模型即可实现与千亿参数方案竞争的性能；④支持逐步增量更新，避免大规模重训练。

**🔧 技术方法**

采用 Bootstrap Aggregation、Mixture of Experts 思路、随机森林路由、概率平均聚合、阈值微调、特征工程（9 个结构特征）等技术。

**📊 数据集**

使用 9 个公开恶意提示数据集（覆盖简单有害请求、越狱、注入等），总计约 839k 样本。

**📈 对比分析**

与 OpenAI Moderation API、Perspective、ToxicDetector、ShieldGemma 等基线进行对比；在 k=9、n=5 的设置下，Bagel 的 F1=0.922、ASR=0.095、FPR=0.066，仅 430 M 有效参数，显著优于现有黑白盒方法。

**⚠️ 局限性**

局限性包括：仅进行二分类，缺乏细粒度政策标签；仅评估单轮提示，未验证多轮会话；对完全新型攻击依赖足量数据进行微调；对基础模型的先验知识有一定依赖。

---

## 553. Integrating Code Metrics into Automated Documentation Generation for Computational Notebooks

**arXiv ID:** 2602.08133 | [PDF](https://arxiv.org/pdf/2602.08133v1)

**作者:** Mojtaba Mostafavi Ghahfarokhi `[一作]` (Sharif University of Technology), Abbas Heydarnoori `[通讯]` (Bowling Green State University)

**通讯引用:** 1471 | [OpenAlex ID](https://openalex.org/A5026887037)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了将代码度量（metrics）作为辅助信号来提升计算笔记本的自动文档生成，构建了专门的代码‑markdown配对数据集，并在轻量级CNN‑RNN和LLM（GPT‑3.5）模型中验证其效果。

**💡 创新点**

创新点包括：①首次将结构化代码指标引入文档生成；②提出两阶段方法（数据集构建+模型训练），并在CNN‑RNN和LLM少量提示场景中均显示显著性能提升；③设计了基于代码指标的检索模块（CM‑IR）与语义检索相结合的组合。

**🔧 技术方法**

使用了CNN‑RNN轻量级编码‑解码网络、代码指标提取与编码、GPT‑3.5少量提示（few‑shot）与多种Shot Sampler（CM‑IR、Roberta‑IR、组合）、LLM‑as‑Judge评估框架，以及Wilcoxon检验等统计方法。

**📊 数据集**

使用了从Kaggle Notebook中整理的36,734对高质量代码‑markdown配对的数据集，数据集基于CodeSearchNet处理并做结构与语义过滤。

**📈 对比分析**

通过对比无指标基线与加指标模型，使用BLEU、ROUGE、BERTScore等指标评估；CNN‑RNN加指标提升BLEU‑1 6%和ROUGE‑L F1 3%；GPT‑3.5加指标提升BERTScore F1 9%；在LLM少量提示中，CM‑IR和Roberta+CM‑IR超越Zero‑Shot/Random‑Shot，表现更佳。

**⚠️ 局限性**

局限性包括：数据集仅来自Kaggle Notebook，可能缺乏跨平台泛化；仅评估了36k条样本，未检验更大规模或不同语言；未单独分析各代码指标的独立贡献；实验仅使用GPT‑3.5，结果可能不适用于其他LLM；实现细节可能存在错误风险。

---

## 554. MambaFusion: Adaptive State-Space Fusion for Multimodal 3D Object Detection

**arXiv ID:** 2602.08126 | [PDF](https://arxiv.org/pdf/2602.08126v1)

**作者:** Venkatraman Narayanan `[一作]` (Qualcomm Inc), Senthil Yogamani `[通讯]` (Qualcomm Inc)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `8d10c613-917e-4880-9716-17789f50e119` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了一个统一的多模态3D目标检测框架，融合摄像头和LiDAR的BEV特征。

**💡 创新点**

创新点包括使用线性时间的状态空间模型与窗口注意力混合编码、可学习的多模态token对齐与可靠性门控、基于结构的扩散校正，以及时序自蒸馏实现的稳定性。

**🔧 技术方法**

采用Mamba状态空间模型、窗口Transformer、跨模态对齐模块、可靠性门控、图神经网络推理、结构条件扩散网络以及自蒸馏训练。

**📊 数据集**

在nuScenes和Argoverse 2两个大型自动驾驶基准上进行实验。

**📈 对比分析**

相较于现有BEV融合方法，在nuScenes验证集上获得77.9 NDS、74.9 mAP，在测试集上77.2 NDS、74.7 mAP，优于BEVFusion4D等主流方法。

**⚠️ 局限性**

局限性包括对极端稀疏点云的处理仍有限，扩散步骤虽然短但仍有推理开销，且对高频噪声的鲁棒性尚未完全验证。

---

## 555. Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems

**arXiv ID:** 2602.08104 | [PDF](https://arxiv.org/pdf/2602.08104v1)

**作者:** Risal Shahriar Shefin `[一作]` (Wake Forest University), Sarra Alqahtani `[通讯]` (Wake Forest University)

**通讯引用:** 438 | [OpenAlex ID](https://openalex.org/A5057127359)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出一种两阶段梯度基方法，用于在多智能体强化学习（MARL）中检测首次失效（Patient‑0）并追踪其传播路径，构建可解释的感染图；

**💡 创新点**

创新点在于结合本地策略曲率异常检测与基于批评器的方向性二阶敏感度，既能识别最早失效代理，又能区分放大效应与真实源头；

**🔧 技术方法**

主要技术包括：Taylor剩余误差曲率探测、批评器一阶/二阶导数分析、加权累计影响与加速状态判别、并生成有向感染图；

**📊 数据集**

在两个协作环境（Simple Spread和SMAC）以及两种MARL算法（MADDPG与HATRPO）上进行实验；

**📈 对比分析**

与传统的全局奖励或性能指标对比，方法在Patient‑0识别率上达到88.2%–99.4%，在影响力验证上显著优于奖励/价值曲线（提升20%+），并通过干预实验验证加速状态的显著性；

**⚠️ 局限性**

局限包括：仅假设单一失效源，依赖可微批评器且对梯度噪声敏感，阈值和窗口设置需手工调参，且计算开销相对较大。

---

## 556. Emergent Search and Backtracking in Latent Reasoning Models

**arXiv ID:** 2602.08100 | [PDF](https://arxiv.org/pdf/2602.08100v1)

**作者:** Jasmine Cui `[一作]` (Independent), Charles Ye `[通讯]` (Independent)

**通讯引用:** 9057 | [OpenAlex ID](https://openalex.org/A5017355711)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过逐步解码隐层状态的预测分布，研究了无词语生成的潜在推理Transformer（LRT）在四选一问答中的思考轨迹，发现其表现出探索、浅层承诺以及自发回溯的搜索行为。

**💡 创新点**

创新点在于：①首次在不通过自然语言中介的前提下直接可视化LRT的逐步推理轨迹；②揭示并量化了模型自发回溯的系统性和准确率提升；③提出任务难度对探索阶段长度的因果影响测度。

**🔧 技术方法**

使用looped LRT（Huginn-0125）架构，包含预处理层、循环Transformer块和Coda层；通过在每个递归步骤将隐藏状态送入Coda得到softmax分布，并利用KL散度、熵以及语义相似度来分析探索、回溯等动态。

**📊 数据集**

构造了260条四选一的人工问答基准，涵盖事实回忆、定义、推理、算术和对抗性问题；每条问题提供三种答案集变体（Base、Easy、No correct answer）。

**📈 对比分析**

对不同答案变体及答案顺序随机化的实验进行量化比较：Base题比Easy题探索步长多54%；回溯事件出现32%，并使准确率提升34%；在No correct answer变体中模型保持高熵、未收敛。

**⚠️ 局限性**

局限性：仅在单一3.5B参数模型和合成问答数据上验证；未探讨更大规模模型、开放式生成任务或非循环自适应计算架构；回溯机制在更复杂任务中的普适性仍未验证。

---

## 557. SiameseNorm: Breaking the Barrier to Reconciling Pre/Post-Norm

**arXiv ID:** 2602.08064 | [PDF](https://arxiv.org/pdf/2602.08064v1)

**作者:** Tianyu Li `[一作]` (Tsinghua University), Gao Huang `[通讯]` (Tsinghua University)

**通讯引用:** 66802 | [OpenAlex ID](https://openalex.org/A5013240918)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 SiameseNorm，一种双流残差架构，在每层同时使用 Pre‑Norm 与 Post‑Norm 的优点，并在 Transformer 训练中保持稳定性。

**💡 创新点**

创新点在于通过共享参数的两条并行流（Pre‑Norm 维护梯度恒等通道，Post‑Norm 约束表示尺度）实现梯度稳定与表征深度兼顾，且仅增加极小的计算量。

**🔧 技术方法**

采用了层归一化（LayerNorm / RMSNorm）、深度归一化技术、混合尺度缩放以及注意力/MLP 结构的改进，构建 1.3B 参数模型并进行大规模预训练。

**📊 数据集**

主要使用 FineWeb‑Edu 语料库进行预训练，随后在 ARC、HellaSwag、PIQA、WinoGrande、OpenBookQA、Arithmetic 等下游基准数据集上评估。

**📈 对比分析**

与 Pre‑Norm、Post‑Norm、DeepNorm、ResiDual、HybridNorm、Hyper‑Connections 等基线比较，SiameseNorm 在多种学习率设置下实现更低的 perplexity（最低 10.43）和更高的平均分数（最高 55.63），尤其在算术推理任务上提升约 41% 相比 Pre‑Norm。

**⚠️ 局限性**

局限性包括：在某些下游任务上的提升有限，且模型出现“巨激活”现象，提示仍有优化空间。

---

## 558. Implicit Strategic Optimization: Rethinking Long-Horizon Decision-Making in Adversarial Poker Environments

**arXiv ID:** 2602.08041 | [PDF](https://arxiv.org/pdf/2602.08041v1)

**作者:** Boyang Xia `[一作]` (Gradient), Bill Shi `[通讯]` (Gradient)

**通讯引用:** 1280 | [OpenAlex ID](https://openalex.org/A5076320426)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文提出一种预测感知的长期博弈学习框架——Implicit Strategic Optimization (ISO)，通过预测潜在的战略上下文并在该上下文条件下进行学习，实现对长期博弈中不可观测的战略外部性的建模与优化。

**💡 创新点**

创新点在于：① 将长期博弈的难点拆解为“预测战略上下文”和“上下文条件学习”两部分；② 提出了 iso‑grpo 算法，在上下文预测与真实上下文之间进行动作路由和学习更新；③ 给出了以误预测次数为主导的预测感知情境下的上下文退化不等式与平衡收敛性分析。

**🔧 技术方法**

核心技术包括：多类别在线预测、基于梯度的无偏优化（GRPO）、优化的鲁棒性不等式（RVU）与情境化的动态不等式、以及利用战略奖励模型（SRM）对长期收益进行监督。

**📊 数据集**

实验数据集包括：6‑player No‑Limit Texas Hold’em（约10,000局手牌）和竞技版 Pokémon Showdown（Gen 1 OU对局集）。

**📈 对比分析**

与多种基线（SFT‑LLM、PPO、CFR、GPT‑4o、Claude 3.5 Sonnet、Llama‑3.1‑70B）对比，ISO 在 NLHE 的长期回报提升至 +15.8 BB/100 局，胜率提升至 22% 并保持较低的可利用度（5.2 mBB/手）；在 Pokémon 中，ISO 在与 GPT‑4o 的对局中实现 70% 的胜率。实验表明，ISO 的提升主要体现在后期决策与长周期收益上。

**⚠️ 局限性**

局限性包括：① 仅适用于离散有限的战略上下文，无法直接推广到连续或高维上下文空间；② 需要完整信息（full‑information）反馈，缺乏对半信息/仅奖赏反馈的处理；③ 误预测对性能的敏感性依赖于上下文预测器的精度，实际环境中预测不确定性可能更高。

---

## 559. FIRE: Frobenius-Isometry Reinitialization for Balancing the Stability-Plasticity Tradeoff

**arXiv ID:** 2602.08040 | [PDF](https://arxiv.org/pdf/2602.08040v1)

**作者:** Isaac Han `[一作]` (Gwangju Institute of Science and Technology), Kyung-Joong Kim `[通讯]` (Gwangju Institute of Science and Technology)

**通讯引用:** 2166 | [OpenAlex ID](https://openalex.org/A5076055880)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于受限优化的重初始化方法FIRE，用以在持续学习中平衡模型的稳定性与可塑性。

**💡 创新点**

创新点在于将稳定性（平方弗罗贝尼乌斯误差）和可塑性（偏离等距性）构造为约束优化问题，并用Newton-Schulz迭代高效近似其解。

**🔧 技术方法**

使用SFE、DfI度量、正交投影、Newton-Schulz迭代以及卷积层逐核正交化等技术实现方法。

**📊 数据集**

在视觉（CIFAR‑10/100、Tiny‑ImageNet与ResNet/ViT/VGG）、语言（GPT‑0.1B预训练+OpenWebText/WikiText‑103）和强化学习（SAC/HumanoidBench、DQN/Atari）三大数据集上进行实验。

**📈 对比分析**

与全重置、S&P、DASH、Parseval等基线对比，FIRE在三类任务中均保持或提升性能，恢复率高、损失低。

**⚠️ 局限性**

局限性在于假设可访问历史数据，实验仅覆盖较小模型，未验证在受限数据或更大模型上的表现。

---

## 560. Robustness of Vision Language Models Against Split-Image Harmful Input Attacks

**arXiv ID:** 2602.08136 | [PDF](https://arxiv.org/pdf/2602.08136v1)

**作者:** Md Rafi Ur Rashid `[一作]` (Pennsylvania State University), Shagufta Mehnaz `[通讯]` (Pennsylvania State University)

**通讯引用:** 531 | [OpenAlex ID](https://openalex.org/A5032020253)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6215c339-3735-4be3-8a07-5bbb7004712d` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `8d10c613-917e-4880-9716-17789f50e119` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文发现并利用视觉语言模型（VLM）在面对分割图像（split‑image）时的安全对齐缺陷，提出了一套分割图像视觉越狱攻击（SIVA），并给出多阶段攻击策略。

**💡 创新点**

创新点在于：①首次识别出VLM在分割图像上的安全对齐漏洞；②设计了三阶段逐步加强的攻击流程，并引入对抗知识蒸馏（Adv‑KD）显著提升跨模型黑盒攻击成功率；③提出可扩展的 aDPO（增强 DPO）对齐策略，解决分割图像安全训练成本高的问题。

**🔧 技术方法**

技术手段包括：分割图像生成与逐步优化（从简单拆分到白盒再到黑盒迁移）；对抗知识蒸馏（Adv‑KD）结合 Direct Preference Optimization 与对比学习；aDPO 通过在 DPO 损失中加入多分割实例实现对齐增强；利用 LM‑Judge（GPT‑5.1）进行攻击成功率评估。

**📊 数据集**

使用了三大数据集：JailbreakV‑28k（模拟图像）、Forbidden Recipe（非法物品真实图像）和 Reddit‑NSFW（真实暴力/色情图像），共计约1300个样本进行评估。

**📈 对比分析**

与现有14种视觉越狱方法对比，SIVA 在白盒下提高 15–21% 的成功率，在全黑盒迁移下通过 Adv‑KD 实现 60% 以上的提升；在三大主流 VLM（Qwen‑3‑VL、Llama‑3.2‑Vision、Pixtral）上均验证了效果；采用 aDPO 的模型在黑盒/白盒下攻击成功率下降 9–16%，显示出一定的防御潜力。

**⚠️ 局限性**

限制：①目前的 aDPO 实验仅在 1000 条人工标注样本上验证，规模有限；②攻击流程依赖图像分割与合成技巧，对高度结构化图像的适用性待验证；③防御效果仍受限于小样本规模，缺乏大规模对齐与长尾分割场景的实证。

---

## 561. Gender and Race Bias in Consumer Product Recommendations by Large Language Models

**arXiv ID:** 2602.08124 | [PDF](https://arxiv.org/pdf/2602.08124v1)

**作者:** Ke Xu `[一作]` (University of Victoria), Alex Thomo `[通讯]` (University of Victoria)

**通讯引用:** 1511 | [OpenAlex ID](https://openalex.org/A5011013528)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文利用大型语言模型（GPT‑4o）为15个种族与性别组合生成商品推荐，并通过Prompt Engineering获取结果，随后使用Marked Words、支持向量机（SVM）和Jensen‑Shannon Divergence（JSD）三种方法分析这些推荐中的性别与种族偏差。

**💡 创新点**

创新点在于首次将隐式偏差检测方法（Marked Words、SVM、JSD）结合Prompt Engineering，系统评估LLM在现实消费推荐场景中的种族与性别偏差，并提供多维度的量化指标。

**🔧 技术方法**

采用的技术包括：Prompt Engineering对LLM进行定向提问；文本预处理与匿名化；Marked Words统计显著词；线性SVM分类器提取区分词；JSD衡量词分布差异。

**📊 数据集**

使用的数据集为GPT‑4o生成的225条推荐文本（15人群×15条），不依赖公开消费数据集，而是基于模型内部知识生成。

**📈 对比分析**

方法对比：SVM在种族组上的准确率达0.98±0.03，性别组仅0.70±0.21，种族+性别组合0.95±0.03；Marked Words与JSD均发现明显的词频差异，显示模型在不同人群上给出显著不同的推荐词汇。

**⚠️ 局限性**

局限性包括：仅使用GPT‑4o，未验证其他LLM模型；样本量有限，未覆盖所有可能的种族/性别细分；缺乏有效的偏差缓解措施（如调优或RLHF），且仅分析了推荐文本而非用户实际购买行为。

---

## 562. Probability Hacking and the Design of Trustworthy ML for Signal Processing in C-UAS: A Scenario Based Method

**arXiv ID:** 2602.08086 | [PDF](https://arxiv.org/pdf/2602.08086v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 563. Outsourcing in Global Software Development: Effects of Temporal Location and Methodologies

**arXiv ID:** 2602.08084 | [PDF](https://arxiv.org/pdf/2602.08084v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df`

---

## 564. Adding More Value Than Work: Practical Guidelines for Integrating Robots into Intercultural Competence Learning

**arXiv ID:** 2602.08123 | [PDF](https://arxiv.org/pdf/2602.08123v1)

**作者:** Zhennan Yi `[一作]` (Indiana University Bloomington), Selma Šabanović `[通讯]` (Indiana University Bloomington)

**通讯引用:** 5465 | [OpenAlex ID](https://openalex.org/A5070868769)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过两轮教师共创工作坊，收集并分析了17名美国K-12教师对将社交机器人用于跨文化能力培养的看法与需求，进一步提出了实践指导原则。

**💡 创新点**

将教师视为设计共同创造者，系统归纳机器人在跨文化教育中的增值点（多语言支撑、文化知识共享、冲突调解的中立第三方）并与课堂嵌入、基础设施需求结合，形成可落地的指导框架。

**🔧 技术方法**

采用人机交互中的参与式共创方法，以 Haru 机器人原型作为设计探路灯；通过视频示例引导教师思考，并使用 Miro、Zoom 等协作工具记录与讨论；数据分析采用反思式主题分析。

**📊 数据集**

使用的“数据集”为教师访谈与工作坊记录（含口述访谈稿、投票结果、工作坊笔记）以及教师基本信息表。

**📈 对比分析**

本研究未进行量化对比或性能评估，主要通过定性分析得出设计指导；若需评估可在后续实验中采用前后测量或使用现有跨文化能力量表。

**⚠️ 局限性**

限制包括：样本仅来自美国教师，无法覆盖其他文化背景；研究聚焦 Haru 机器人，可能限制了设计思路；未直接获取学生和家长的反馈，缺乏多方视角。

---

## 565. MMLSv2: A Multimodal Dataset for Martian Landslide Detection in Remote Sensing Imagery

**arXiv ID:** 2602.08112 | [PDF](https://arxiv.org/pdf/2602.08112v1)

**作者:** Sidike Paheding `[一作]` (Fairfield University), Thomas Oommen `[通讯]` (University of Mississippi)

**通讯引用:** 3589 | [OpenAlex ID](https://openalex.org/A5006970579)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出并发布了MMLSv2——一套包含七种波段的火星滑坡分割数据集，并提供了独立的空间不重叠测试集

**💡 创新点**

改进了标签质量，新增300多张图像，引入完整的空间离散化测试集以检验模型泛化能力，并通过多模态输入展示不同波段的互补性

**🔧 技术方法**

使用深度学习语义分割模型（U‑Net、U‑Net++、PSPNet、DeepLabV3/3+、SegFormer），统一训练配置，并对不同波段组合进行实验

**📊 数据集**

使用MMLSv2数据集（664张图，包含RGB、DEM、坡度、热惯性、灰度等七个通道），并构建了训练/验证/标准测试与独立测试四个子集

**📈 对比分析**

通过与标准测试集比较，模型在标准分割上可达0.81–0.83 mIoU，添加多模态通道提升约0.1；在独立测试集上mIoU下降到0.70–0.73，说明泛化挑战明显

**⚠️ 局限性**

实验未做模型专门调参，融合方式仅为拼接，未探索更高效的多模态融合；仅测试了有限几种主流网络，未覆盖所有可能的架构

---

## 566. A Collaborative Crowdsourcing Method for Designing External Interfaces for Autonomous Vehicles

**arXiv ID:** 2602.08090 | [PDF](https://arxiv.org/pdf/2602.08090v1)

**作者:** Ronald Cumbal `[一作]` (Uppsala University), Ginevra Castellano `[通讯]` (Uppsala University)

**通讯引用:** 4198 | [OpenAlex ID](https://openalex.org/A5014668082)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

通过协作式众包方法，收集并迭代改进公众对自动驾驶车辆外部人机界面（eHMI）的设计想法，并在实验中评估这些设计的可解释性与用户体验。

**💡 创新点**

结合参与式设计原则与可扩展的众包平台，提供多轮协作与专家反馈，使普通用户在大规模下产生既创新又可行的eHMI概念，突破传统小规模、资源密集的参与式设计限制。

**🔧 技术方法**

使用基于web的交互式绘图与树形可视化协作平台（jsPsych+Blender视频仿真），专家通过7点Likert量表评价效果与可行性，实验者则用重复测量ANOVA/Friedman检验比较反应时间和UEQ问卷分数。

**📊 数据集**

采集自Prolific平台的67名欧盟参与者草图及其反思，随后在131名参与者中收集视频实验数据；未使用公开数据集，全部为自建样本。

**📈 对比分析**

通过三组设计（基准、流行设计、创新设计）的重复测量ANOVA与Friedman检验对比反应时间与用户体验，结果显示流行设计在可解释性与体验上均优于基准，创新设计排名第二。

**⚠️ 局限性**

仅评估视觉模块，未覆盖声音/触觉等多模态；样本局限于欧洲Prolific用户，可能存在地域与平台偏差；专家评估单一且主观；实验场景仅限低/高风险交叉，未涵盖多种交通参与者或真实环境。

---

## 567. Multimodal normative modeling in Alzheimers Disease with introspective variational autoencoders

**arXiv ID:** 2602.08077 | [PDF](https://arxiv.org/pdf/2602.08077v1)

**作者:** Sayantan Kumar `[一作]` (Washington University in St Louis), Aristeidis Sotiras `[通讯]` (Washington University in St Louis)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `afceb026-1760-41ae-8d86-010831a37d97` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `dc6c6f4a-9d29-4fb8-b59a-f6c271315b9b` `a6cb313d-240c-4723-a372-3ba1f39b9afc`

**🎯 论文内容**

提出一种多模态软自省变分自编码器（mmSIVAE）用于神经影像学中的规范化建模，并给出患者级别的偏差地图。

**💡 创新点**

创新点在于结合软自省训练（Soft‑IntroVAE）和混合乘积-混合专家（MOPOE）聚合方法，既提升参考分布拟合精度，又实现更稳健的多模态潜在融合。

**🔧 技术方法**

核心技术包括变分自编码器、软自省目标函数、MOPOE后验聚合、马氏距离偏差度量及Z‑score映射。

**📊 数据集**

使用 ADNI 数据集，训练 248 名无认知障碍对照，评估 726 名阿尔茨海默症光谱患者，输入为 T1‑MRI 区域体积和 AV45‑PET SUVR。

**📈 对比分析**

与单模态/多模态 VAE、mmJSD、JMVAE、MVTCAE 等基线对比，mmSIVAE 在控制组重构误差最小、潜在偏差的阳性似然比最高（最高至 5‑10 倍），且在区域偏差上与 AD 病理高度一致。

**⚠️ 局限性**

局限包括：仅在 ADNI 内部验证，未评估跨站/跨人群泛化；偏差度量依赖高斯假设且马氏距离对协方差估计敏感；解释阈值和多重检验控制需进一步系统化。

---

## 568. ViT-5: Vision Transformers for The Mid-2020s

**arXiv ID:** 2602.08071 | [PDF](https://arxiv.org/pdf/2602.08071v1)

**作者:** Feng Wang `[一作]` (Johns Hopkins University), Alan Yuille `[通讯]` (Johns Hopkins University)

**通讯引用:** 106016 | [OpenAlex ID](https://openalex.org/A5086706224)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在本研究中，对Vision Transformer的各个组件进行了系统化的更新，包括归一化、激活函数、位置编码、门控机制以及可学习的注册标记，并基于此提出了新的ViT-5模型。

**💡 创新点**

创新点在于统一引入LayerScale、RMSNorm、2D Rotary Positional Embedding（RoPE）、QK-Norm以及注册标记，并通过避免LayerScale与SwiGLU的过门控问题，构建了可直接替换的下一代ViT。

**🔧 技术方法**

采用的技术包括LayerScale、RMSNorm、GeLU（避免SwiGLU导致的过门控）、2D RoPE、QK-Normalization、无偏置QKV投影以及四个可学习的注册标记。

**📊 数据集**

主要使用的公开数据集有ImageNet-1k（用于分类）、ImageNet-256（用于图像生成）和ADE20k（用于语义分割），以及相应的训练和评估流程。

**📈 对比分析**

与ConvNeXt和DeiT-III等基线模型在相同参数量与FLOPs下进行对比，ViT-5在ImageNet-1k分类中达到84.2%（Base）至86.0%（Large）top‑1精度；在SiT扩散框架中，FID从2.06下降至1.84；在ADE20k语义分割中，mIoU从49.3%提升至52.0%，整体表现均优于基线。

**⚠️ 局限性**

限制方面包括：SwiGLU与LayerScale的组合导致过门控，需要在不同规模下仔细调参；模型的优势主要在规模较大时显著，尚未在极大规模或极低算力场景下充分验证；以及在多模态或细粒度任务上的进一步泛化仍需探索。

---

## 569. ReRoPE: Repurposing RoPE for Relative Camera Control

**arXiv ID:** 2602.08068 | [PDF](https://arxiv.org/pdf/2602.08068v1)

**作者:** Chunyang Li `[一作]` (Zhejiang University), Yiyi Liao `[通讯]` (Zhejiang University)

**通讯引用:** 2742 | [OpenAlex ID](https://openalex.org/A5018811297)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

在预训练的视频扩散 Transformer 上实现相机控制，通过将相机姿态信息注入 RoPE 的低频冗余通道，实现图像到视频（I2V）和视频到视频（V2V）的精确相机轨迹控制。

**💡 创新点**

发现 RoPE 的低频通道在预训练模型中几乎未被利用，可直接复用为相机控制通道；提出无结构改动、无额外编码器的 plug‑and‑play 机制，保持生成先验并实现高精度相机控制。

**🔧 技术方法**

RoPE 低频重用、相机投影块（PRoPE 思路）、Diffusion Transformer（Wan2.1/2.2）、流匹配损失、AdamW、学习率调度、相机姿态归一化等技术。

**📊 数据集**

MultiCamVideo、SDG-1.5M、DL3DV（含 VIPE 生成的轨迹）等数据集。

**📈 对比分析**

与 TrajectoryCrafter、ReCamMaster（V2V）以及 SEVA、DualCamCtrl（I2V）等基线对比；在 RRE/RTE/ATE、VBench、View Syn 等指标上，ReRoPE 以更低的相机误差和相近或更优的视觉质量获得最佳结果，且收敛速度最快。

**⚠️ 局限性**

仅适用于包含 RoPE 的 Transformer 结构，若 RoPE 设计不同需重新调整；低频重用在极长序列或高空间分辨率下可能失效；需对相机平移归一化，否则训练可能不稳定。

---

## 570. Efficient Distribution Learning with Error Bounds in Wasserstein Distance

**arXiv ID:** 2602.08063 | [PDF](https://arxiv.org/pdf/2602.08063v1)

**作者:** Eduardo Figueiredo `[一作]`, Luca Laurenti `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

本论文提出了一种基于数据驱动的分布学习框架，利用聚类和最优传输构造离散近似分布，并给出其与真实分布之间的 Wasserstein 距离置信上界。

**💡 创新点**

创新点在于：①将置信区间与样本信息结合，得到样本相关的非渐近误差上界；②通过 MILP（随后可简化为单整数变量的 MILP）高效计算该上界；③利用改进的 Lloyd 算法自动构造最优分区，从而显著减小近似分布的支持大小。

**🔧 技术方法**

使用的技术包括：最优传输（Wasserstein 距离）、混合整数线性规划（MILP）及其松弛、Clopper‑Pearson 置信区间、k‑means（Lloyd）聚类、凸优化和概率收敛理论。

**📊 数据集**

实验数据集涵盖：人工合成的二维到百维高斯与均匀分布；UCI 回归基准（Emissions、MiniBooNE）；医学影像数据集 MedMNIST（OCTMNIST）。

**📈 对比分析**

与现有基于 Fournier 等的经验分布、最优投影等方法对比，实验显示本方法在给定置信度下的 Wasserstein 上界普遍更小，且支持点数量通常低于 10⁵；在高维/低方差场景下性能提升更为显著。

**⚠️ 局限性**

局限性包括：①需要已知有界支持；②计算上仍依赖 MILP，虽然已通过单整数变量简化但在大 M 时仍有一定成本；③对极大样本量或非常高维的场景下，Clopper‑Pearson 区间宽度可能导致保守；④当前仅针对 Wasserstein，尚未推广至 Sinkhorn 等其它 OT 距离。

---

## 571. DICE: Disentangling Artist Style from Content via Contrastive Subspace Decomposition in Diffusion Models

**arXiv ID:** 2602.08059 | [PDF](https://arxiv.org/pdf/2602.08059v1)

**作者:** Tong Zhang `[一作]` (Beijing University of Posts and Telecommunications), Jianyi Liu `[通讯]` (Beijing University of Posts and Telecommunications)

**通讯引用:** 1505 | [OpenAlex ID](https://openalex.org/A5100738078)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出 DICE 框架，在推理时通过对比子空间分解实现艺术家风格的无训练消除。

**💡 创新点**

创新点在于利用对比三元组构造风格与内容分离的可求解子空间，并在自注意力层对 Q、K、V 进行差异化抑制与增强，实现精准且无训练的风格消除。

**🔧 技术方法**

使用对比型典型相关分析（Contrastive CCA）求解风格子空间，注意力解耦编辑（分离 Q、K、V 并分别抑制/增强），以及自适应消除控制（动态调节抑制强度）。

**📊 数据集**

在 Stable Diffusion v1.4 上进行实验，以多位艺术家（如 Van Gogh、Monet、Adrian Ghenie、Chuck Close 等）的风格图像作为评估数据集。

**📈 对比分析**

与 SPEED、ESD-U、ESD-X、FMN、MACE、SELECT 等基线对比，实验结果显示 DICE 在风格消除效果上优于多数方法且内容保持更好，DLPIPS、CLIP Score 等指标均证明其性能卓越。

**⚠️ 局限性**

局限性包括需要预先提取特征并解算子空间，对极小或不常见的风格表现可能不佳；以及在实时大规模部署时仍存在一定计算开销。

---

## 572. Weak to Strong: VLM-Based Pseudo-Labeling as a Weakly Supervised Training Strategy in Multimodal Video-based Hidden Emotion Understanding Tasks

**arXiv ID:** 2602.08057 | [PDF](https://arxiv.org/pdf/2602.08057v1)

**作者:** Yufei Wang `[一作]` (New South Wales University), Hongsheng Xing `[通讯]` (Shandong University of Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种多模态弱监督框架用于视频中隐性情绪识别，并在iMiGUE数据集上实现了最新的准确率。

**💡 创新点**

创新点包括：①利用Gemini 2.5 Pro通过CoT+反思生成伪标签进行弱监督；②将人姿态关键点从GCN简化为MLP+Transformer，保持或提升性能；③将视频、姿态与Gemini生成文本三模态特征进行联合预训练与微调。

**🔧 技术方法**

使用的技术包括：YOLO 11x人像裁剪、DINOv2 Base提取图像特征、OpenPose关键点提取及偏移特征、Transformer进行长序列建模、BERT编码文本、Gemini 2.5 Pro进行伪标签生成以及多模态融合的全连接层。

**📊 数据集**

所用数据集为iMiGUE tennis-interview数据集，包含359段裁判访谈视频，正负样本比例约3:1。

**📈 对比分析**

与传统CNN/GCN+LSTM等方法对比，该框架在测试集上从原先60%以下提升至69%以上，成为公开基准最高成绩。

**⚠️ 局限性**

局限性包括：手部关键点识别不准导致噪声、缺乏噪声标签的理论分析、半监督学习稳定性不足、未对大模型做精细调参及缺乏验证集。

---

## 573. Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling

**arXiv ID:** 2602.08052 | [PDF](https://arxiv.org/pdf/2602.08052v1)

**作者:** Bulent Soykan `[一作]` (University of Central Florida), Grace Bochenek `[通讯]` (University of Central Florida)

**通讯引用:** 146 | [OpenAlex ID](https://openalex.org/A5067700276)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

利用深度强化学习框架，针对带发布日期、机台依赖设置时间及机台资格限制的多目标不相关并行机调度问题（UPMSP）设计并学习直接的调度策略。

**💡 创新点**

在传统启发式和元启发式方法基础上，首次将 Proximal Policy Optimization 与异构图神经网络相结合，构造多目标奖励函数，并以图结构捕捉作业、机台与设置的复杂关系，从而实现同时最小化总加权迟到（TWT）与总设置时间（TST）的平衡。

**🔧 技术方法**

使用 Proximal Policy Optimization（PPO）作为策略梯度算法，图神经网络采用 GATv2 进行特征聚合；同时实现了多目标奖励、动作屏蔽与可解释的图结构表示。

**📊 数据集**

作者自行生成的 UPMSP benchmark：作业数 20/50/100，机台数 5/10/15，随机抽取处理时间、设置时间、发布/截止时间、权重及机台资格，针对每组参数组合生成 50 个实例。

**📈 对比分析**

与基准启发式 ATCSR_Rm 规则和基于 GA 的多目标遗传算法进行对比。实验表明 PPO‑GNN 在所有规模下平均 TWT 与 TST 均低于两者，且推理时间仅 0.5–1.6 秒，远快于 GA（≈60 秒）。统计检验显示差异显著（p < 0.01）。

**⚠️ 局限性**

主要限制包括：训练分布内的泛化能力尚未在更大规模或不同设置比例下验证；奖励权重的选取缺乏理论指导；对动态作业流或实时调度的适用性仍待进一步研究。

---

## 574. Interpretable Fuzzy Systems For Forward Osmosis Desalination

**arXiv ID:** 2602.08050 | [PDF](https://arxiv.org/pdf/2602.08050v1)

**作者:** Qusai Khaled `[一作]` (Eindhoven University of Technology), Laura Genga `[通讯]` (Eindhoven University of Technology)

**通讯引用:** 452 | [OpenAlex ID](https://openalex.org/A5056706542)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

结合专家驱动的网格划分与数据驱动的规则剪枝与正则化，构建可解释的Takagi–Sugeno型模糊规则系统，用于预测前向渗析（FO）膜渗透流量。

**💡 创新点**

采用人机协同的固定专家划分 + 规则不活跃检测 + 全局后继估计的组合，在保持语义可解释性的同时获得与聚类方法相当甚至更优的预测性能。

**🔧 技术方法**

使用Gaussian基模糊集的网格划分、归一化后发射强度阈值剪枝、L2岭回归的全局后继估计、λ参数网格搜索以及对比聚类算法（Gustaffson‑Kessel）与GRABS简化。

**📊 数据集**

基于荷兰Eindhoven大学实验室汇编的709条FO实验数据，经过特征工程后生成三维输入（绘制溶液分子量、渗透压差、速度）的子集。

**📈 对比分析**

与pyFUME基于Gustaffson‑Kessel聚类的模糊系统做对比，使用MAE/MAPE及相似度d衡量；网格划分模型在优化后MAE0.486 (MAPE7%)略优于聚类0.49 (MAPE8.2%)，且规则数更少、参数更少、语义可分辨度更高。

**⚠️ 局限性**

仅在固定前驱模糊集下优化后继，未对前驱参数进一步调优；对极度偏态数据的适应性仍有限，且仅针对FO模型，未验证至RO等其它膜技术。

---

## 575. CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts

**arXiv ID:** 2602.08221 | [PDF](https://arxiv.org/pdf/2602.08221v1)

**作者:** Xuhua Ma `[一作]` (Beihang University), Zhijie Nie `[通讯]` (Beihang University)

**通讯引用:** 132 | [OpenAlex ID](https://openalex.org/A5059807664)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出CoRect方法，针对检索增强生成（RAG）中的知识冲突，识别并纠正内部FFN层的参数抑制；

**💡 创新点**

创新点在于无需目标标签的推理时隐藏状态纠正，动态定位抑制层并进行“去抑制”而非强行注入；

**🔧 技术方法**

利用Logit Lens进行层级分析，采用上下文互信息和注意力过滤选取可信目标，再通过对隐藏状态的加性补丁消除抑制；

**📊 数据集**

在问答与摘要任务上评估：NQ、HotpotQA、TriviaQA、TabMWP、SQuAD、NQ‑Swap；摘要评测用XSum、CNN‑DM、TofuEval；

**📈 对比分析**

与Greedy、CAD、AdaCAD、COIECD等基线对比，CoRect在EM、AlignScore、ROUGE‑L等指标上均高于或相当，尤其在高冲突数据集NQ‑Swap上提升显著；

**⚠️ 局限性**

引入多次前向推理和隐藏状态访问，导致推理延迟显著增加，且实现上依赖缓存重用以降低开销。

---

## 576. Thermodynamic Isomorphism of Transformers: A Lagrangian Approach to Attention Dynamics

**arXiv ID:** 2602.08216 | [PDF](https://arxiv.org/pdf/2602.08216v1)

**作者:** Gunn Kim `[一作]` (Sejong University), Gunn Kim `[通讯]` (Sejong University)

**通讯引用:** 2769 | [OpenAlex ID](https://openalex.org/A5025699953)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文提出将Transformer注意力机制视为遵循最小作用原理的物理系统，构建了信息动力学的拉格朗日框架，并从热力学角度推导了Softmax为自由能最小化的平衡状态。

**💡 创新点**

创新点在于把Transformer的注意力、查询-键交互、温度缩放等算子映射为热力学量（能量、温度、压力、自由能），并用自旋场与偶极相互作用等物理模型解释其功能，从而统一推导了Softmax、扩展解释了缩放律、grokking、RoPE等现象。

**🔧 技术方法**

主要技术包括信息几何（Fisher-Rao度量）、拉格朗日动力学、变分原理、热力学分区函数、对数薛定谔方程以及Goldstone玻色子理论。

**📊 数据集**

论文为理论性工作，没有使用具体的数据集；若要验证，作者建议在Transformer、Mamba、RWKV等模型上测量所定义的热力学常数κ。

**📈 对比分析**

未给出实验比较；若按作者设想，可通过比较不同架构模型的κ值、信息压缩率等指标验证理论，但目前尚无实验结果。

**⚠️ 局限性**

主要局限包括：①时间变量t仅是层深的抽象映射，未体现真正的动力学；②假设信息气体可理想化，忽略了tokens间的强相互作用；③理论预测缺乏实验验证，容易陷入圆形推导；④对实际训练和学习过程的非平衡热力学分析仍未完成。

---

## 577. LLMs and people both learn to form conventions -- just not with each other

**arXiv ID:** 2602.08208 | [PDF](https://arxiv.org/pdf/2602.08208v1)

**作者:** Cameron R. Jones `[一作]` (Stony Brook University), Benjamin K. Bergen `[通讯]` (University of California San Diego)

**通讯引用:** 4709 | [OpenAlex ID](https://openalex.org/A5043344696)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究了人类与大型语言模型（LLM）在多模态指向游戏中的对话对齐与共识形成能力，并通过两组实验比较人类-人类、AI-AI与人类-AI配对的表现。

**💡 创新点**

创新点在于首次系统评估LLM与人类在视觉参考游戏中的共识形成，并检验通过提示让LLM表现得更像人类是否能弥合人与机器之间的对齐差距。

**🔧 技术方法**

使用 GPT‑5（通过 OpenAI API）进行“在情境中学习”对话，并采用自然语言生成与交互测评技术（准确率、信息量、词汇重叠度等指标），辅以人类实验者的交互式指令与反馈。

**📊 数据集**

数据集为 18 个具有多样形状的 tangram 组合图像，配合 109 名人类受试者与 39 对 AI‑AI 对话会话，实验共完成 50 轮对话（每轮一张目标图）。

**📈 对比分析**

比较方法：对三类配对分别计算准确率、描述长度和词汇重叠度；实验二在默认提示基础上引入“人类化”提示，评估其对上述指标的提升。结果显示：AI‑AI 达到 99% 的准确率与最高词汇重叠度，但长度几乎不变；人类‑人类表现最佳；人类‑AI 在默认提示下显著落后，提示后虽有所改善但仍低于人类‑人类。

**⚠️ 局限性**

局限性：实验仅涉及 tangram 视觉任务，难以推广到更复杂或多模态情境；LLM 仅靠提示无法完全复制人类的语用与资源敏感性；样本量与任务规模有限，缺乏跨语言、跨文化验证；模型对先前成功/失败的感知仍不足，影响对齐效果。

---

## 578. Geospatial-Reasoning-Driven Vocabulary-Agnostic Remote Sensing Semantic Segmentation

**arXiv ID:** 2602.08206 | [PDF](https://arxiv.org/pdf/2602.08206v1)

**作者:** Chufeng Zhou `[一作]` (Wuhan University of Science and Technology), Xiaokang Zhang `[通讯]` (Wuhan University)

**通讯引用:** 2425 | [OpenAlex ID](https://openalex.org/A5100412315)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `8d10c613-917e-4880-9716-17789f50e119` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

提出了一种基于地理推理链条的遥感开词汇语义分割框架（GR‑CoT），通过离线知识蒸馏和在线实例推理生成图像自适应词汇，指导分割模型完成像素级地理语义映射。

**💡 创新点**

创新点在于：① 将多模态大型语言模型的链条推理能力引入遥感分割，实现主动地理推理而非被动外观匹配；② 设计双流结构——离线类别解释标准和在线实例推理，形成可解释的语义决策链；③ 生成图像自适应词汇，显著减少同类光谱相似度导致的语义歧义。

**🔧 技术方法**

技术手段包括：多模态大语言模型（MLLM）与链条推理（CoT）提示；离线知识蒸馏构建类别解释标准；在线宏观场景锚定、视觉特征解耦和知识驱动决策合成；以及基于视觉‑文本对齐的开词汇分割模块。

**📊 数据集**

使用的数据集为 LoveDA（多光谱遥感）和 GID5（高分辨率光学遥感）两个公开基准。

**📈 对比分析**

与现有方法 CAT‑Seg、RSKT‑Seg 的对比实验表明：在 LoveDA 上 mIoU 从 41.39% 提升到 45.34%，OA 从 59.93% 提升到 63.34%；在 GID5 上 mIoU 从 45.34% 提升到 51.39%，OA 从 63.34% 提升到 67.42%；尤其在农田、森林、草地等光谱相近类别的分割精度显著提升，背景误检率大幅下降。

**⚠️ 局限性**

局限性包括：依赖 MLLM 提示的质量与可解释性，推理过程计算量较大，难以实时部署；对极其细粒度或未见场景的类别识别仍有限；模型对不同卫星平台与传感器的泛化能力尚未充分验证。

---

## 579. Dreaming in Code for Curriculum Learning in Open-Ended Worlds

**arXiv ID:** 2602.08194 | [PDF](https://arxiv.org/pdf/2602.08194v1)

**作者:** Konstantinos Mitsides `[一作]` (Imperial College London), Antoine Cully `[通讯]` (Imperial College London)

**通讯引用:** 2351 | [OpenAlex ID](https://openalex.org/A5011747084)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

提出 DiCode 框架，利用基础模型（FM）生成可执行的环境代码，构建自适应课程，帮助代理在开创性环境 Craftax 中学会长期依赖的技能。

**💡 创新点**

创新点：① 通过可执行代码生成环境，实现比传统参数化更高层次的结构演化；② 结合闭环学习反馈（agent 绩效与父级级别），让 FM “做梦”生成与代理能力匹配的训练世界；③ 展示代码级环境设计能突破传统 UED 的学习瓶颈。

**🔧 技术方法**

技术：基础模型（open‑weight 代码生成模型）、强化学习（PPO‑GTrXL）、Unsupervised Environment Design（UED）及 Prioritized Level Replay（PLR）、程序化内容生成与编译验证。

**📊 数据集**

数据集：Craftax 生成式游戏环境（无限生成的世界），测试时使用 1024 个未见的随机种子实例；训练时基于标准 Craftax 分布。

**📈 对比分析**

比较方法：与 DR、PLR、SFL 等 UED 基线及无课程 PPO‑GTrXL 对比；在 2×10^9 步训练后，DiCode 平均回报提升约 16%（48.33 vs 41.54），并在晚期战斗等关键任务上实现 11%/9% 成功率，其他基线几乎 0%。

**⚠️ 局限性**

局限性：① 只能在固定游戏引擎内配置，无法创造全新物理法则；② 依赖大模型推理，计算开销高；③ 生成多样性受模型与指令限制，仍可能产生无用或误导性级别。

---

## 580. Nexus: Inferring Join Graphs from Metadata Alone via Iterative Low-Rank Matrix Completion

**arXiv ID:** 2602.08186 | [PDF](https://arxiv.org/pdf/2602.08186v1)

**作者:** Tianji Cong `[一作]` (University of Michigan), H. V. Jagadish `[通讯]` (University of Michigan)

**通讯引用:** 14539 | [OpenAlex ID](https://openalex.org/A5090550596)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研发了一种只使用元数据（表名、列名、类型及基本统计）的联合图推断系统（Nexus），能够在没有数据值访问权限的企业场景下自动发现所有表之间的 PK/FK 关联。

**💡 创新点**

创新点主要包括：① 发现并利用真实数据库中联合图矩阵的高稀疏性和低秩结构，将联合图推断转化为低秩矩阵补全问题；② 提出迭代 EM 算法，在低秩补全的基础上通过大型语言模型（LLM）动态修正列实体类型匹配，显著提升对未知数据集的泛化能力；③ 设计快节模式（Fast）与完整模式（EM）的可切换实现，兼顾精度与延迟；④ 通过核心子矩阵裁剪进一步降低计算和内存开销。

**🔧 技术方法**

核心技术包括：低秩矩阵补全（核范数 + L1 正则）、Expectation‑Maximization（EM）迭代、LLM 进行列实体类型推断与相似度评估、预训练 XGBoost 模型用于初始候选概率、元数据特征工程（列名相似度、数据类型、基数、空值比例等）以及 LLM 调用缓存和批量化。

**📊 数据集**

实验数据集：① 用于结构分析的 5,957 个来自 SchemaPile‑Perm 的真实数据库；② TPC‑H、TPC‑DS（单模式基准）和 11 个 BIRD‑SQL 数据库（多源合并）；③ 真实生产环境的 REAL（3 个数据源，只有元数据和查询日志）；此外使用 GPT‑4o 作为预训练模型，并训练 XGBoost 模型。

**📈 对比分析**

与 XGBoost、GPT‑4o、SemPy、Auto‑BI、Aurum、DeepJoin 等基线比较；评估指标为 F1、精确率、召回率以及运行时。结果显示：Nexus‑GPT‑4o 在四个数据集上分别比 Auto‑BI 提升 32‑53 F1 分，Nexus‑XGBoost 亦实现显著提升；Fast 模式在保持相近 F1 的同时，比 EM 模式快 6‑10 倍；在加入查询日志时，F1 可提升 20‑45 分；当数据值可用时，Nexus‑EM 仍保持领先，且显著优于基线。整体上，该方法在精度与效率上均优于现有技术。

**⚠️ 局限性**

局限性：① EM 模式需要大量 LLM 调用，导致成本和延迟上升；② 目前主要针对单列 PK/FK 关联，尽管可扩展到多列但实验集中于单列；③ 对 LLM 实体类型识别的准确性和一致性敏感，误判会影响最终结果；④ 核心子矩阵裁剪可能会误删潜在关联列；⑤ 对超大规模模式（列数十万）时仍需进一步优化内存和并行度；⑥ 需要手工调节超参数（λ1、λ2、阈值）以获得最佳性能。

---

## 581. A Transfer Learning Approach to Unveil the Role of Windows Common Configuration Enumerations in IEC 62443 Compliance

**arXiv ID:** 2602.08165 | [PDF](https://arxiv.org/pdf/2602.08165v1)

**作者:** Miguel Bicudo `[一作]` (Federal University of Rio de Janeiro), Priyanjan Sharma `[通讯]` (Siemens Technology)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过基于文本嵌入的迁移学习方法，将SUSE Linux的IEC 62443‑3‑3系统安全要求映射到Windows CCEs，并手动验证得到Windows的合规标签，从而实现Windows环境下的自动化合规评估。

**💡 创新点**

①使用句子嵌入+距离权重的跨平台迁移框架，首次将Linux安全标签迁移至Windows；②通过多级阈值与排名筛选提升映射质量；③结合LLM自动标注对比验证，量化人工验证的一致性。

**🔧 技术方法**

句子嵌入（MPNet）+欧氏/余弦距离 + 反距离权重 + 幂变换 + 归一化 + 阈值筛选 + 手工标注与Gemini 2.5 Flash对比。

**📊 数据集**

SUSE Linux CCE表（含IEC 62443‑3‑3 SR标签）与Windows CCE表（无标签），共612个Windows CCE和约3000个标签关系；参考DISA STIG、NIST等安全框架。

**📈 对比分析**

采用人工标注与Gemini 2.5 Flash对比，得到95.6%一致率；接受率31%、疑问7%、拒绝61%；多样性通过多样性指数M(p)和平均列表长度L(p)评估，p=5.5、τ=0.68、K=10时多样性高且列表易解释。

**⚠️ 局限性**

迁移仍受文本相似性限制，跨平台语义差异导致部分映射需人工复核；样本覆盖率有限，仅覆盖部分Windows CCE；需进一步提升自动化准确度并扩展至其他操作系统。

---

## 582. NLP for Local Governance Meeting Records: A Focus Article on Tasks, Datasets, Metrics and Benchmark

**arXiv ID:** 2602.08162 | [PDF](https://arxiv.org/pdf/2602.08162v1)

**作者:** Ricardo Campos `[一作]` (University of Beira Interior), Nuno Guimarães `[通讯]` (INESC TEC)

**通讯引用:** 98 | [OpenAlex ID](https://openalex.org/A5016762476)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

综述了本地治理会议记录在文档分割、领域实体抽取和自动摘要三大核心NLP任务的研究进展，并提供了评估指标与现有方法对比。

**💡 创新点**

创新点在于系统性梳理局部治理文本的任务方法、提出多层级评估指标，并集中讨论了缺乏数据和评估适配的问题。

**🔧 技术方法**

主要使用Transformer系列模型（BERT、Longformer、BART、T5）、CRF、Bi‑LSTM、图模型及LLM+RAG等技术。

**📊 数据集**

涉及的公开数据集包括WikiSection、Wiki‑727K、ParlaMint、UlyssesNER‑BR、RuREBus、MeetingBank、QMSum、CitiLink‑Minutes等。

**📈 对比分析**

在分割任务上以P_k/WindowDiff为指标，模型在WikiSection上P_k下降约4%；实体抽取在ParlaMint/Legal语料上F1达到80–96%；摘要在MeetingBank上ROUGE‑1约65%/BERTScore≈80%。

**⚠️ 局限性**

主要限制是缺乏多语言本地治理标注数据、评估指标与任务不匹配以及模型在隐私和多说话者结构上的泛化能力不足。

---

## 583. SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning

**arXiv ID:** 2602.08234 | [PDF](https://arxiv.org/pdf/2602.08234v1)

**作者:** Peng Xia `[一作]` (University of North Carolina Chapel Hill), Huaxiu Yao `[通讯]` (University of North Carolina Chapel Hill)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计了一个递归技能增强强化学习框架（SkillRL），通过经验蒸馏生成分层技能库并在训练过程中动态演化技能，以提升LLM代理的任务性能。

**💡 创新点**

创新点包括：①基于教师模型的经验蒸馏，将冗长轨迹压缩为可重用技能；②将技能分为通用与任务特定两层，实现高效检索；③在RL过程中递归更新技能库，使技能与策略共同进化；④通过冷启动SFT让模型学会利用技能。

**🔧 技术方法**

使用的技术主要有：大型语言模型（如Qwen2.5-7B-Instruct）作为基线，OpenAI的o3作为教师模型；强化学习方法GRPO；经验蒸馏与技能抽取；语义相似度检索；KL正则化与SFT训练。

**📊 数据集**

评估数据集包括：文本类游戏ALFWorld、网页购物环境WebShop，以及七个搜索增强问答任务（NQ、HotpotQA、TriviaQA、PopQA、2Wiki、MuSiQue、Bamboogle）。

**📈 对比分析**

与多类基线（闭源LLM、提示式代理、RL、记忆增强RL等）比较，SkillRL在ALFWorld、WebShop以及问答任务上均实现了显著提升，单场景成功率从最优基线提升约15.3%，在复杂子任务上提升20%以上，且在任务复杂度提升时保持鲁棒性。

**⚠️ 局限性**

限制包括：依赖大型教师模型进行蒸馏，训练成本高；技能库增长会占用更多存储与检索开销；在极端稀疏奖励或完全新任务时，技能抽取与演化仍可能不足；目前仅验证于文本交互与搜索任务，尚未扩展到多模态或物理仿真环境。

---

## 584. Tutti: Expressive Multi-Singer Synthesis via Structure-Level Timbre Control and Vocal Texture Modeling

**arXiv ID:** 2602.08233 | [PDF](https://arxiv.org/pdf/2602.08233v1)

**作者:** Jiatao Chen `[一作]` (Wuhan University of Technology), Jie Zhou `[通讯]` (WeChat AI)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了 Tutti 框架，实现了在同一首歌中动态多声部演唱的结构化合成与声纹控制。

**💡 创新点**

创新点在于①基于音乐结构的声部提示与自适应融合器，②条件引导 VAE 的互补纹理学习，以及③首次实现多声部演唱的全流程生成。

**🔧 技术方法**

采用了 Latent Diffusion Transformer（DiT）作为生成骨干，配合重构的 Vocal VAE 与 Condition‑Guided VAE，并引入自注意力的声部融合与 logit‑normal 采样等技术。

**📊 数据集**

构建了约 140K 歌曲的 Vocal VAE 训练集和约 300K 歌曲的 DiT 训练集，来源包括 AudioBox、SongEval、WhisperX 等，包含中英双语及多声部标注。

**📈 对比分析**

通过与 DiffRhythm/LeVo/SongBloom VAE 在音频重构、与 Vevo2 在生成任务的对比实验，使用 STOI/WB‑PESQ/MCD/FAD、WER/SIM/MOS‑Q/N/​MS‑MOS/Mel‑MOS 等指标评估，Tutti 在所有指标上均优于基线，重构 STOI 提升至 0.8175，生成 WER 降至 13.5%，SIM 与 MOS 亦显著提高。

**⚠️ 局限性**

局限性包括对段落声部假设（段落仅单声部）不够灵活，声纹特征覆盖不足，且生成的旋律表达仍有提升空间。

---

## 585. Generating Adversarial Events: A Motion-Aware Point Cloud Framework

**arXiv ID:** 2602.08230 | [PDF](https://arxiv.org/pdf/2602.08230v1)

**作者:** Hongwei Ren `[一作]` (Harbin Institute of Technology), Xiangqian Wu `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 4962 | [OpenAlex ID](https://openalex.org/A5042120075)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6215c339-3735-4be3-8a07-5bbb7004712d` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

利用点云表示，提出 MA-ADV 生成对事件相机的最小扰动对抗样本

**💡 创新点**

创新点在于：1) 基于运动感知的扰动扩散策略，抑制高频噪声并保留时空一致性；2) 采用样本级自适应学习率，精准平衡攻击成功率与扰动成本；3) 结合二进制搜索动态调节损失权重。

**🔧 技术方法**

主要技术包括：KNN 近邻搜索、速度与距离衰减权重、Chamfer 与 L2 距离损失、Adam 优化、二进制搜索、样本级学习率调节。

**📊 数据集**

实验数据集：DVSGesture、N-Caltech101、N-MNIST；使用的目标模型有 EventMamba、PointNet++ 与 PointNet。

**📈 对比分析**

与 FGSM、IFGSM、C&W、HIT-ADV 等基线及三种防御方法对比，MA-ADV 在所有数据集上均实现 100% 的攻击成功率，同时在 Chamfer、L2 与 Hausdorff 距离上均取得最小值，显示出更优的攻击效果与更低的扰动成本。

**⚠️ 局限性**

局限性包括：1) 仅针对基于点云的后端模型验证，未覆盖所有事件网络架构；2) 对实际硬件环境的物理攻击评估不足；3) KNN 与扩散参数需要手工调优，可能对不同数据分布产生依赖。

---

## 586. Investigating Writing Professionals' Relationships with Generative AI: How Combined Perceptions of Rivalry and Collaboration Shape Work Practices and Outcomes

**arXiv ID:** 2602.08227 | [PDF](https://arxiv.org/pdf/2602.08227v1)

**作者:** Rama Adithya `[一作]`, Batia Mishan `[通讯]`

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本研究通过跨截面问卷调查，探讨写作专业人员对生成式AI的竞争与合作倾向，并评估其对工作工艺与绩效的影响。

**💡 创新点**

创新点在于将竞争与合作视为并存的双重关系，并利用联合分析揭示两者共同增强工作工艺与成果的作用。

**🔧 技术方法**

采用线性回归、响应曲面分析（RSA）、聚类（PAM）以及定性主题分析等多方法技术。

**📊 数据集**

使用了403名北美写作专业人员收集的问卷数据集。

**📈 对比分析**

通过多元回归与RSA比较独立与联合效应，结果显示高竞争+高合作组合对工作工艺与产出具有最显著的正向效应。

**⚠️ 局限性**

局限包括样本仅限写作行业、单点自报告可能受共变效应影响、缺乏纵向或跨文化验证。

---

## 587. ByteHouse: A Cloud-Native OLAP Engine with Incremental Computation and Multi-Modal Retrieval

**arXiv ID:** 2602.08226 | [PDF](https://arxiv.org/pdf/2602.08226v1)

**作者:** Yuxing Han `[一作]` (ByteDance), Fan Wu `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 19036 | [OpenAlex ID](https://openalex.org/A5075948251)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个云原生共享存储的数据仓库 ByteHouse，专门用于实时多模态数据分析。

**💡 创新点**

创新点包括统一表引擎与自描述文件格式、SSD 基础的分布式缓存、分层向量索引、融合检索算子，以及 AI 驱动的历史执行优化和预测。

**🔧 技术方法**

使用了列式存储、MVCC、分布式缓存、Arrow 零拷贝、管道化并行执行、向量化处理、机器学习回归模型等技术。

**📊 数据集**

采用了内部 ByteDance 业务数据以及公开基准：TPC‑DS、ClickBench、Cohere、C4、MS MARCO、VDBBench 等数据集。

**📈 对比分析**

在同等硬件上与 StarRocks、Doris、ClickHouse 等主流仓库，以及 Milvus、pgvector 等向量数据库对比，ByteHouse 在 TPC‑DS 和 ClickBench 上平均降低 25% 延迟，向量检索吞吐提升 50%+，增量处理 CPU 消耗下降 30%–70%。

**⚠️ 局限性**

局限性包括分布式缓存写入延迟、向量索引重建成本、AI 优化模型对新查询模式的泛化能力，以及高写入量场景下事务一致性的复杂性。

---

## 588. RECUR: Resource Exhaustion Attack via Recursive-Entropy Guided Counterfactual Utilization and Reflection

**arXiv ID:** 2602.08214 | [PDF](https://arxiv.org/pdf/2602.08214v1)

**作者:** Ziwei Wang `[一作]` (Wuhan University), Yang Liu `[通讯]` (Nanyang Technological University)

**通讯引用:** 48876 | [OpenAlex ID](https://openalex.org/A5100355773)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `6215c339-3735-4be3-8a07-5bbb7004712d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究大型推理模型的思考循环机制，提出RECUR攻击方法，通过递归熵指导生成反事实问题并诱导模型进入无限思考循环，导致资源耗尽。

**💡 创新点**

创新点在于引入递归熵度量思考过程中的熵变化，并基于此设计递归熵引导采样与一致性裁剪技术，构建可跨模型、可迁移的资源耗尽攻击。

**🔧 技术方法**

使用的技术包括递归熵度量、反事实问题生成、递归熵引导采样、基于一致性的裁剪、以及与AutoDoS、GCG、LoopLLM、Overthink等方法的对比实验。

**📊 数据集**

实验使用的主要数据集是GSM8k数学题库（随机抽取20道题目作为攻击基准），并在多种开源与闭源大型推理模型上评估。

**📈 对比分析**

通过与四种基线方法对比，RECUR在所有模型上平均推理长度提升5–10倍，最大长度可达64k，吞吐量下降约90%，表现显著优于现有攻击方法。

**⚠️ 局限性**

局限性包括：依赖反事实问题生成、需要白盒访问采样概率，攻击效果对模型规模与推理长度有限制，实验范围仅覆盖公开与部分闭源模型，且对极简模型的适用性不佳。

---

## 589. DrugR: Optimizing Molecular Drugs through LLM-based Explicit Reasoning

**arXiv ID:** 2602.08213 | [PDF](https://arxiv.org/pdf/2602.08213v1)

**作者:** Haoran Liu `[一作]` (Beihang University), Yunduo Xiao `[通讯]` (South China University of Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

设计并实现了一种基于大语言模型的显式推理框架 DrugR，能够在保留核心结构相似性的前提下对药物分子进行多目标 ADMET 优化，并生成可解释的优化理由。

**💡 创新点**

创新点在于：① 通过持续预训练（CPT）注入化学知识；② 采用逆向数据工程自动生成解释式训练集；③ 在多粒度自平衡强化学习（GRPO）中同时优化推理质量与分子优化结果，实现在保持结构相似度的同时显著提升 ADMET 性能。

**🔧 技术方法**

使用技术包括：LLaMA‑3‑8B‑Instruct 作为基础模型；CPT、SFT、GRPO 强化学习；ADMETLab 作为多指标预测器；SMILES 生成与指纹相似度评估；LMS、Target‑property F1 等自定义奖励函数。

**📊 数据集**

数据集来源于 DrugBank 与 ChEMBL，构建了 10,000+ 现有药物样本，并通过逆向工程生成 4,855 条解释式优化样本；使用 ADMETLab 提供的 23 个 ADMET 指标作为属性评估；任务聚焦于抗炎、降压、降糖三类小分子药物。

**📈 对比分析**

对比方法包括传统 Diffusion、MOBO、通用 LLM（GPT5、DeepSeek‑R1）以及化学专用 LLM（ChemDFM、ExLLM、ether0、LLaMA3‑8B）和各消融实验；DrugR 在整体优化分数（0.2712）上显著优于所有基线，Fingerprint 相似度维持在 0.64，Binding 亲和力基本不降，且推理质量（LMS、F1）最高。

**⚠️ 局限性**

局限性：① 依赖单一代理评估器 ADMETLab，可能导致代理劫持与对真实实验结果的泛化不足；② SMILES 生成仍受限于训练样本分布，长尾化学空间偏移仍存在；③ 缺乏实验验证与真实临床数据；④ 在极端属性优化时可能出现与目标功能的权衡失衡。

---

## 590. Fork, Explore, Commit: OS Primitives for Agentic Exploration

**arXiv ID:** 2602.08199 | [PDF](https://arxiv.org/pdf/2602.08199v1)

**作者:** Cong Wang `[一作]` (Multikernel Technologies), Yusheng Zheng `[通讯]` (University of California)

**关键词:** `9a43038e-f401-4fd9-9c05-65c0b8369d7e` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

提出并实现了 Agentic OS 的“分支上下文”（Branch Context）抽象，支持多路径并行探索、原子提交与回滚，并实现了无根权限的 FUSE 文件系统 BranchFS 和新型 Linux 系统调用 branch，提供进程与文件系统的隔离与同步。

**💡 创新点**

创新点在于：①将 AI 代理的并行探索拆解为 Fork‑Explore‑Commit 生命周期；②首次在内核层面实现“先提交者赢”（first‑commit‑wins）并自动失效兄弟分支；③通过 FUSE 的文件级 copy‑on‑write 以及内核调用实现轻量级、可嵌套、无特权的分支管理；④设计了通用 ioctl 接口，使任何支持三种基本操作的文件系统都能直接接入。

**🔧 技术方法**

核心技术包括：
- FUSE‑based 文件系统（BranchFS）实现文件级 copy‑on‑write 与 O(1) 分支创建。
- 设计并描述 Linux 系统调用 branch，结合 cgroup、PID namespace、mount namespace、页表 copy‑on‑write 等内核机制。
- 采用普通 ioctl（FS_IOC_BRANCH_CREATE/COMMIT/ABORT）实现文件系统无关的分支控制。
- 在用户空间实现了分支链解析、删除墓碑与子分支管理。

**📊 数据集**

实验未使用公开数据集，主要在本地实验机（AMD Ryzen 5 5500U、8 GB RAM、240 GB NVMe）上使用人工构造的文件系统基线（100–10 000 文件）与不同修改量（1 KB–1 MB）进行性能评测。

**📈 对比分析**

对比方法：
- 分支创建：测量不同基线大小下的创建延迟，结果均 < 350 µs，证明 O(1) 成本。
- 提交与回滚：按修改量测量提交/回滚耗时，1 KB 约 317 µs，1 MB 约 2 100 µs，回滚几乎不复制文件。
- I/O 通过率：在 50 MB 顺序读写上，原生文件系统 8 800 MB/s 读，BranchFS 正常模式 1 655 MB/s，pass‑through 模式 7 236 MB/s。整体性能足以满足 LLM 语义推理延迟的需求。

**⚠️ 局限性**

局限性：
- 仅覆盖文件系统与进程状态，网络、IPC、设备 I/O 等外部副作用无法回滚。
- 采用文件级 copy‑on‑write，导致符号链接、硬链接、特殊文件等不完整；当磁盘空间不足时会报错。
- 目前只实现了文件系统分支，内存分支的页面表复制尚未完成。
- “先提交者赢”机制不支持多分支合并，无法处理文件冲突或语义级合并。
- 需要在每个代理中手动将工作空间绑定到分支挂载点，使用复杂度相对较高。

---

## 591. PEGAsus: 3D Personalization of Geometry and Appearance

**arXiv ID:** 2602.08198 | [PDF](https://arxiv.org/pdf/2602.08198v1)

**作者:** Jingyu Hu `[一作]` (Chinese University of Hong Kong), Chi-Wing Fu `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 20990 | [OpenAlex ID](https://openalex.org/A5054382056)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文提出一种3D个性化框架，能够从参考形状中学习可重用的几何与外观概念，并通过文本组合生成新形状。

**💡 创新点**

创新点在于将形状个性化转化为跨类别、可重用概念的学习，支持全局与局部两种模式，并实现几何与外观的解耦学习。

**🔧 技术方法**

采用TRELLIS大规模3D基础模型，结合可学习文本嵌入与生成器微调的双步优化，并引入上下文感知与上下文无关损失实现局部概念学习。

**📊 数据集**

主要使用Objaverse-XL中的30个参考形状及其三种文本提示构成90个评测案例，并在对比实验中选用相同数据集。

**📈 对比分析**

与Qwen-Edit、Edit360、StyleSculptor、Coin3D、VoxHammer等方法进行定量比较，使用KID、CLIP‑R、ArtFID、FID等指标，实验表明本文方法在质量、属性保留与文本一致性方面均优于现有技术。

**⚠️ 局限性**

局限性包括对单一参考形状的过拟合风险、在极端跨类别转换时细节不完整或语义偏差，以及对训练资源与时间的较高需求。

---

## 592. NeuroScaler: Towards Energy-Optimal Autoscaling for Container-Based Services

**arXiv ID:** 2602.08191 | [PDF](https://arxiv.org/pdf/2602.08191v1)

**作者:** Alisson O. Chaves `[一作]` (Federal University of Uberlândia), Flavio de Oliveira Silva `[通讯]`

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在真实的 Telco 等级数据中心使用 K8s 负载生成器，构建了 NeuroScaler AI‑native 自动缩放框架并在生产级服务器上验证；

**💡 创新点**

将能耗视为首要控制目标，结合多层遥测和 MPC（模型预测控制）实现基于能耗与 SLO 的闭环缩放，显著低于传统 HPA；

**🔧 技术方法**

使用 MLOps 训练能耗与延迟预测模型、Kubernetes、Kepler、Scaphandre、RAPL 以及 MPC 算法；

**📊 数据集**

利用 48 小时 K6 负载实验数据，收集 PDU、CPU/内存/交换机、VM 与容器层的功耗与性能指标；

**📈 对比分析**

与原生 K8s HPA 对比，NeuroScaler 在相同工作负载下实现了 34.68% 的能耗下降，平均实例数减少 1.6 个，CPU 负载亦显著降低；

**⚠️ 局限性**

目前仅针对单一服务、单一 Kubernetes 集群验证，缺乏多服务、多域（edge、5G/6G）及动态网络链路协同的完整评估。

---

## 593. ZipFlow: a Compiler-based Framework to Unleash Compressed Data Movement for Modern GPUs

**arXiv ID:** 2602.08190 | [PDF](https://arxiv.org/pdf/2602.08190v1)

**作者:** Gwangoo Yeo `[一作]` (Korea Advanced Institute of Science and Technology), Minsoo Rhu `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 3425 | [OpenAlex ID](https://openalex.org/A5091648103)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

在GPU加速的数据分析中，提出了一个编译器驱动的压缩数据迁移框架，自动对压缩、传输、解压三阶段进行协同调度。

**💡 创新点**

创新点在于：①将压缩算法抽象为三类并行模式（完全并行、分组并行、非并行）并提供统一的(L,S,C)编译调度向量；②支持自定义嵌套压缩并自动核融合；③设计基于Johnson算法的流水线调度，以最小化PCIe传输与GPU解压的总时延。

**🔧 技术方法**

使用PyTorch+LLVM编译器技术实现GPU内核自动化调度，采用强化学习搜索最佳(L,S,C)配置；核心技术包括核融合、流水线调度、GPU资源自适应、PCIe DMA+CUDA/ROCm多线程并行。

**📊 数据集**

采用TPC‑H 100规模（约1TB）作为基准数据集，并在其列上构造多种压缩方案。

**📈 对比分析**

对比nvCOMP、Parquet、BTRBLOCKS以及DuckDB、SQL Server，在22个TPC‑H查询中，平均在GPU端实现2.08×（vs nvCOMP）和3.14×（vs CPU DBMS）的端到端加速；解压吞吐比nvCOMP高约1.6×，PCIe传输时间降低1.85×。

**⚠️ 局限性**

局限性包括：①仍受PCIe带宽限制，无法突破极大数据量的迁移瓶颈；②需要针对不同GPU进行离线配置搜索；③对非列式或高度随机的压缩模式支持有限；④在极端压缩率与解压耗时权衡上仍需手动调节。

---

## 594. Nansde-net: A neural sde framework for generating time series with memory

**arXiv ID:** 2602.08182 | [PDF](https://arxiv.org/pdf/2602.08182v1)

**作者:** Hiromu Ozai `[一作]` (Hiroshima University), Kei Nakagawa `[通讯]` (Osaka Metropolitan University)

**通讯引用:** 485 | [OpenAlex ID](https://openalex.org/A5086122043)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出 NANSDE-Net，一种将神经网络参数化的 ARMA‑型噪声（NA‑noise）嵌入到神经 SDE 框架中，用于生成具有长期或短期记忆特征的时间序列。

**💡 创新点**

创新点：① 将可学习的卷积核 ℓ(s,u)=ℓ₁(s)ℓ₂(u) 通过神经网络近似，从而在 Itô 计算框架下实现可模拟的长短期记忆噪声；② 证明在 Lipschitz 与线性增长条件下解存在唯一，并给出梯度反向传播公式；③ 在实际数据上展示 NA‑noise 能同时捕获 H>½ 与 H<½ 的记忆特性。

**🔧 技术方法**

技术：神经网络参数化的 ARMA‑型噪声、Itô 随机微分方程、Euler–Maruyama 数值解、梯度下降优化（Adam）、多层感知机（MLP）实现漂移、扩散及噪声核；使用 Hurst 指数、ACF、marginal TV、R² 等指标评估。

**📊 数据集**

数据集：合成的分形布朗运动（H=0.2, 0.3）以及六个真实序列（SPX、TPX、SX5E、NileMin、ethernetTraffic、NhemiTemp），涵盖长期与短期记忆样本。

**📈 对比分析**

与 RNN、SDE‑Net、fSDE‑Net 进行对比；在 H>½ 数据（如 NileMin、ethernetTraffic、NhemiTemp）上 NANSDE‑Net 与 fSDE‑Net 相当或略优；在 H<½ 数据（如 fBm、TPX、SX5E）上优于其他神经 SDE 方法；在 marginal distribution 与 ACF 方面表现稳健，但在极低 Hurst 的情况下并未明显优于 SDE‑Net。

**⚠️ 局限性**

局限性：① 采用的核分解并不能保证噪声具有平稳增量；② 对应长记忆核 ℓ(s,u) 的显式表达式尚未知；③ 简单的 MLP 架构可能限制拟合能力；④ 对极低 Hurst 指数的数据效果不佳；⑤ 未实现对噪声高阶记忆特性或自相关衰减的严格控制。

---

## 595. Self-Supervised Bootstrapping of Action-Predictive Embodied Reasoning

**arXiv ID:** 2602.08167 | [PDF](https://arxiv.org/pdf/2602.08167v1)

**作者:** Milan Ganai `[一作]` (Stanford), Marco Pavone `[通讯]` (Stanford)

**通讯引用:** 11262 | [OpenAlex ID](https://openalex.org/A5050003000)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种自监督的框架 Refine，通过把机器人推理视为潜在变量，利用重要性加权变分推理从互联网规模先验中筛选并强化能提升动作预测的推理序列。

**💡 创新点**

创新点在于：①将推理过程建模为潜在变量而非固定模板；②使用前后置模型（先验+后验）做重要性采样，自动评估推理对动作预测的“信息收益”；③实现无外部奖励、无人工标注的自我引导改进。

**🔧 技术方法**

核心技术包括：变分推理、重要性加权自编码器（IWAE）、基于推理抖动的warm‑start策略、两阶段采样-重采样（Refine + Bootstrap）以及多模态 Vision‑Language‑Action (VLA) 网络。

**📊 数据集**

实验数据集涵盖：机器人操纵（FrankA Panda 仿真、WidowX 真实、LIBERO‑90）、四足/两足/车轮/自行车等步态导航、以及自动驾驶环境；使用 1B、4B、7B 与 30B 级别的 VLA 模型。

**📈 对比分析**

与基线（无推理、全部推理原语、随机推理）比较时，Refine 在操纵任务提升 28% 成功率，在步态导航任务提高 101% 分数，在自动驾驶任务降低 21% 碰撞率，显示显著性能提升。

**⚠️ 局限性**

局限性包括：需要额外训练前后置模型，warm‑start 数据生成成本高；对极大模型的扩展仍需验证；当前方法主要在离线训练阶段，在线实时推理的可行性尚未充分评估。

---

## 596. Test vs Mutant: Adversarial LLM Agents for Robust Unit Test Generation

**arXiv ID:** 2602.08146 | [PDF](https://arxiv.org/pdf/2602.08146v1)

**作者:** Pengyu Chang `[一作]` (Shanghai Jiao Tong University), Xiaodong Gu `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 2383 | [OpenAlex ID](https://openalex.org/A5033286111)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一个基于大模型的对抗性双代理框架（AdverTest），通过测试用例生成代理与突变体生成代理相互博弈，以提升单元测试的缺陷检测能力

**💡 创新点**

创新点在于将突变测试与大模型生成结合，并设计双向反馈的对抗循环，让测试用例持续击杀生存突变体，突变体针对测试盲区生成，从而显著提升缺陷曝光率

**🔧 技术方法**

使用大语言模型（如DeepSeek、GPT‑OSS‑120B）进行测试用例和突变体的生成，配合覆盖率与突变得分的指标进行迭代反馈；同时采用变异测试技术来评估测试套件的健壮性

**📊 数据集**

评估数据集为 Defects4J 与 GrowingBugs 两个真实工业级 Java 缺陷库，覆盖 20 项工程、247 个缺陷、727 个方法

**📈 对比分析**

与传统随机/搜索工具（Randoop、EvoSuite）以及 LLM 基础方法（ChatUniTest、HITS）对比；在 Defects4J 上 FDR 提升至 66.6%（比 HITS 8.6% 领先、比 EvoSuite 63.3% 领先），在 GrowingBugs 上 65.96%；覆盖率保持与 HITS 接近，API 成本也较低

**⚠️ 局限性**

局限性包括：仅针对 Java；只生成一阶突变体，未考虑更复杂的高阶突变；对抗循环可能受模型随机性影响；对其他编程语言和更大模型的迁移性尚待验证

---

## 597. Distribution-Free Robust Functional Predict-Then-Optimize

**arXiv ID:** 2602.08215 | [PDF](https://arxiv.org/pdf/2602.08215v1)

**作者:** Yash Patel `[一作]` (University of Michigan), Ambuj Tewari `[通讯]` (University of Michigan)

**通讯引用:** 9059 | [OpenAlex ID](https://openalex.org/A5051918150)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

在 PDE 驱动的工程设计中，本文提出了一种在无分布假设下对神经算子（spectral neural operator）预测的无限维函数空间实现分位点覆盖的 conformal prediction 方法，并将该覆盖用于 robust predict‑then‑optimize 任务；

**💡 创新点**

创新点在于：①将 conformal prediction 扩展到 Sobolev 空间的无穷维函数，得到对完整解函数的分布无关覆盖；②设计了带 margin 的量化校正因子，使覆盖在不同分辨率下保持；③将此覆盖嵌入多分辨率的 robust 优化框架，实现了在不同 PDE（椭圆、抛物、量子波函数）和决策任务（资源收集、量子态判别）中的显著性能提升；

**🔧 技术方法**

核心技术包括：分布无关 conformal prediction、Sobolev 范数残差评分、spectral neural operator 学习、多分辨率（multi‑stage）robust predict‑then‑optimize、Danskin 定理与变分方法、Wielandt‑Hoffman 定理用于矩阵谱不确定性；

**📊 数据集**

使用了由高斯随机场生成的合成数据，包含 2D Poisson、2D 热方程以及 2D 量子波函数（step‑index 与 GRIN 光波导）等；每个任务均从 300 条训练、150 条校准、150 条测试样本构建；

**📈 对比分析**

与基准（普通预测、Gaussian Process、PGM 方案）比较时，实验显示：①在资源收集任务中，robust 方案平均子最优性差距显著下降，且统计显著；②在量子态判别中，robust 方案的互信息平均提高 2‑5%，相较于 PGM 与 nominal 均有显著优势；整体上，该方法在保持置信覆盖的同时提升了决策性能；

**⚠️ 局限性**

局限性包括：①需要先验的函数上界 B(·) 的构造，对复杂 PDE 可能难以获取；②覆盖区域存在一定保守性，尤其在低分辨率或低光滑度时；③仅验证了 spectral neural operator，对基于网格的算子（如 Fourier neural operator）尚未推广；④多阶段优化中需要选择合适的分辨率序列，仍有经验性依赖；

---

## 598. Generative Regression for Left Ventricular Ejection Fraction Estimation from Echocardiography Video

**arXiv ID:** 2602.08202 | [PDF](https://arxiv.org/pdf/2602.08202v1)

**作者:** Jinrong Lv `[一作]` (Southwest Jiaotong University), Weili Jiang `[通讯]` (Southwest Jiaotong University)

**通讯引用:** 323 | [OpenAlex ID](https://openalex.org/A5056773459)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `7b0f05dc-d396-4b03-96d2-a379dbd5049d`

**🎯 论文内容**

提出一种基于多模态条件扩散模型（MCSDR），将左心室射血分数（LVEF）估计从确定性回归转为生成式回归，直接建模给定超声视频与患者人口学信息的条件后验分布；

**💡 创新点**

①将LVEF估计视为概率逆问题，使用扩散生成模型捕获多峰、非高斯分布；②设计多模态条件分数网络（MCSN）融合视频特征与人口学先验，实现临床先验约束；③利用多重采样提供置信度评估；

**🔧 技术方法**

扩散概率模型（VP‑SDE/DDIM）、条件分数网络、跨模态注意力、Denoising Diffusion Implicit Model采样、CRPS评价指标；

**📊 数据集**

EchoNet‑Dynamic、EchoNet‑Pediatric 与 CAMUS 三个公开超声心电图数据集；

**📈 对比分析**

与多种确定性回归基线（CNN、Transformer、GNN、基础模型）以及同类扩散回归方法对比；在 EchoNet‑Dynamic、EchoNet‑Pediatric 与 CAMUS 上均取得 MAE 低于 4%，R² 高于 0.77，并在分布性指标 CRPS 上表现更好；

**⚠️ 局限性**

对扩散过程未做生理范围约束导致偶尔预测值超出 0–100%；假设双编码架构需同时获得视频和人口学数据，缺失模态时鲁棒性不足；仅基于 2D 视图，未涵盖 3D 超声；推理时多轨道采样仍增加计算负担；

---

## 599. Interpretable Dynamic Network Modeling of Tensor Time Series via Kronecker Time-Varying Graphical Lasso

**arXiv ID:** 2602.08197 | [PDF](https://arxiv.org/pdf/2602.08197v1)

**作者:** Shingo Higashiguchi `[一作]` (SANKEN, University of Osaka), Yasushi Sakurai `[通讯]` (SANKEN, University of Osaka)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `3f18e8e3-0266-457c-8567-9039b6d2394d` `5a41884c-404f-4688-a89c-aa238c10fe68` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

开发并验证了一种基于Kronecker结构的时间变图形拉索（KTVGL），用于对多模态张量时间序列进行模式特定的动态网络推断。

**💡 创新点**

创新点在于：①使用Kronecker积将整体网络拆分为若干可解释的模式网络；②通过交替优化将非凸问题分解为可解的TVGL子问题；③提出流式（滑动窗口）算法，使计算时间与序列长度无关。

**🔧 技术方法**

技术手段包括张量展开、Kronecker矩阵理论、交替优化（含ADMM）、TVGL子问题求解以及滑动窗口流算法。

**📊 数据集**

实验数据包括：①基于Erdős‑Rényi生成的合成3阶/4阶张量时间序列；②真实的Google Trends搜索量数据（按国家和按州的关键词搜索频次）。

**📈 对比分析**

与静态Kronecker Graphical Lasso和传统TVGL进行对比；在AUC‑ROC上提升最高73.5%，在计算时间上比TVGL快60.5倍；流式版本时间独立于序列长度，性能略逊于批处理版但仍优于TVGL。

**⚠️ 局限性**

局限性包括：流式版本因缺少未来信息导致变更点检测准确性下降；对正则化参数敏感；仅适用于高斯假设的张量时间序列，非高斯或离散数据尚未验证。

---

## 600. Adoption of Large Language Models in Scrum Management: Insights from Brazilian Practitioners

**arXiv ID:** 2602.08192 | [PDF](https://arxiv.org/pdf/2602.08192v1)

**作者:** Mirko Perkusich `[一作]` (VIRTUS Research, Development and Innovation Center), Angelo Perkusich `[通讯]` (VIRTUS Research, Development and Innovation Center)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文通过对70名巴西Scrum专业人士的问卷调查，系统描述了他们在Scrum管理实践中使用大型语言模型（LLM）的现状、频率、功能定位、收益与风险。

**💡 创新点**

创新点在于首次从实证角度量化LLM在Scrum管理中的应用场景、受益与挑战，为后续的责任式AI与敏捷实践结合提供了基线数据和洞见。

**🔧 技术方法**

使用的技术主要是主流LLM平台（ChatGPT、Gemini、Copilot Chat 等）以及问卷工具 Google Forms；数据处理采用描述性统计和定性编码分析。

**📊 数据集**

使用的数据集为问卷收集的 70 份有效回答，包含受访者背景、LLM 使用频率、应用领域、感知收益与风险等信息。

**📈 对比分析**

比较方法是对各问题进行频率/百分比统计，并对不同 Scrum 角色、不同使用场景进行分组比较；结果显示高达 78% 的受访者感知到生产力提升、75% 的人认为手工工作减少，52% 的人每天使用 LLM，风险方面 81% 的人遇到“几乎正确但不完全”输出。

**⚠️ 局限性**

限制包括：非概率抽样导致外部效度受限、仅自我报告数据、调查时间窗口（2025 年）可能不代表未来技术演进、未进行对照实验或纵向追踪，且仅使用单一问卷，缺乏多方法验证。

---

## 601. A Causal Machine Learning Framework for Treatment Personalization in Clinical Trials: Application to Ulcerative Colitis

**arXiv ID:** 2602.08171 | [PDF](https://arxiv.org/pdf/2602.08171v1)

**作者:** Cristian Minoccheri `[一作]` (University of Michigan), Ryan Stidham `[通讯]` (University of Michigan)

**通讯引用:** 4584 | [OpenAlex ID](https://openalex.org/A5038079014)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

开发并应用了一套模块化因果机器学习框架，用于评估在临床试验中基于患者特征的治疗个体化方案。

**💡 创新点**

通过将特征重要性、最佳线性预测检验和双重稳健策略评估分离开来，揭示异质性检测与实际决策收益可能不一致，并提出诊断比较以区分预后因子与真正的效应修饰因子。

**🔧 技术方法**

使用 X‑learner CATE 估计、梯度提升树预测、置换重要性、最佳线性预测检验、双重稳健策略评估以及增量 Brier 分数等技术。

**📊 数据集**

利用 UNIFI 维持期随机对照试验的患者级别数据，包括安慰剂、每 12 周和每 8 周 ustekinumab 的临床、实验室和视频内镜特征。

**📈 对比分析**

通过交叉验证与嵌套留一法比较全特征与仅临床特征的策略价值和预测性能，发现内镜特征在统计上显著但对策略价值无提升，整体决策收益有限。

**⚠️ 局限性**

局限包括内镜输入仅为 Mayo 子评分和 CDS，受限于测量误差和样本量；未考虑时间事件；结果可能不适用于其他生物制剂或克罗恩病。

---

## 602. The Confidence Manifold: Geometric Structure of Correctness Representations in Language Models

**arXiv ID:** 2602.08159 | [PDF](https://arxiv.org/pdf/2602.08159v1)

**作者:** Seonglae Cho `[一作]` (Holistic AI), Adriano Koshiyama `[通讯]` (Holistic AI)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对大语言模型内部表示进行几何分析，揭示正确性表示的低维子空间

**💡 创新点**

发现正确性信息仅占3–8维且线性可分，可用中心距实现少量监督检测，无需复杂非线性方法

**🔧 技术方法**

使用对比数据构造、PLS投影、线性逻辑回归、激活调度、中心距与几何分类器

**📊 数据集**

TruthfulQA为主数据集，并在SciQ、CommonsenseQA、HaluEval、FEVER等数据集上进行转移验证

**📈 对比分析**

与输出基不确定性方法、语义熵、CCS等比较，内部线性探测AUC可达0.80–0.97，输出方法仅0.44–0.64；中心距可达90%全量性能

**⚠️ 局限性**

局限在于仅针对结构化问答、模型输出不直接携带正确信息、跨任务泛化受限于数据差异

---

## 603. A second order regret bound for NormalHedge

**arXiv ID:** 2602.08151 | [PDF](https://arxiv.org/pdf/2602.08151v1)

**作者:** Yoav Freund `[一作]` (University of California), Yu-Xiang Wang `[通讯]` (University of California)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `de8d30ba-c289-43a5-b4ec-7b80df73aea2`

**🎯 论文内容**

本文研究了在“简单”序列上使用专家建议进行预测的问题，提出了一种NormalHedge算法的变体，证明其具有O(√(V_T log(V_T/ϵ)))的二阶后悔界限。

**💡 创新点**

创新点在于确认了NormalHedge算法同时具有基于分位数和方差的后悔界限，解决了一个开放问题，并引入了局部自一致性概念以支持分析。

**🔧 技术方法**

使用了随机微分方程（SDE）和自一致性技术来分析算法的性能。

**📊 数据集**

未具体提及使用的数据集，但研究的背景是在线学习和专家建议的经典问题。

**📈 对比分析**

与现有算法相比，NormalHedge算法在处理简单序列时表现出更优的适应性，且其后悔界限不依赖于迭代次数T，性能上优于依赖于T的算法。

**⚠️ 局限性**

限制在于该算法的适应性需要根据未知的V_T进行调节，且在某些情况下可能存在较大的常数因子差距。

---

## 604. ModARO: A Modular Approach to Architecture Reconstruction of Distributed Microservice Codebases

**arXiv ID:** 2602.08181 | [PDF](https://arxiv.org/pdf/2602.08181v1)

**作者:** Oscar Manglaras `[一作]` (Adelaide University), Markus Wagner `[通讯]` (Monash University)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df`

**🎯 论文内容**

提出并实现了 ModARO，一种基于可重用提取器的微服务架构静态重构框架。

**💡 创新点**

创新点在于将重构代码拆解为与技术无关的可插拔提取器，并通过共享 JSON 模型实现不同项目间的重用；同时支持多仓库分布式重构和后向链接。

**🔧 技术方法**

核心技术包括基于 JavaScript 的提取器实现、JSON 模型和递归调度算法、正则表达式与文件搜索 API、以及 Retroactive Linking 机制。

**📊 数据集**

使用了 10 个公开的微服务项目（包括 4 个 demo 与 6 个工业级项目）进行案例研究，并收集 8 名行业从业者的实验数据。

**📈 对比分析**

与现有的 ReSSA 进行对比，采用用户研究的 TAM2 问卷；结果显示 ModARO 在可用性、易用性上略优，且在多语言、多技术项目的提取准确率达 100%（除非因静态分析限制）。

**⚠️ 局限性**

局限性包括：提取器需要针对非标准文件结构手工配置、缺乏高级代码解析能力、后向链接在某些动态配置场景下不足、实验样本规模有限、并未验证动态分析场景。

---

## 605. DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries

**arXiv ID:** 2602.08149 | [PDF](https://arxiv.org/pdf/2602.08149v1)

**作者:** Sahana Ramnath `[一作]` (University of Southern California), Akshaj Kumar Veldanda `[通讯]` (Capital One)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一套针对对话摘要的双层错误分类法，并基于此手工标注了一批细粒度错误数据集，同时评估了多种 LLM 作为判定器的表现。

**💡 创新点**

创新点在于：①提出覆盖对话层与转录层、结构与叙述视角的全新错误分类体系；②生成并公开一份细粒度错误标注数据集；③系统比较 LLM 判定器在粗细粒度错误上的能力，并揭示当前模型的局限。

**🔧 技术方法**

主要技术包括：使用大语言模型（如 GPT‑4、ChatGPT、LLama‑2、Gemini 等）进行摘要生成与错误检测；少量提示工程；平衡准确率（Balanced Accuracy）评估；人工双标注与后处理。

**📊 数据集**

采用 200 条人机多轮对话（来源如 Human‑AI 交互数据集），筛选 192 条后进行摘要生成，并在每条摘要上标注 10 类错误，形成 1,920 条错误标签。

**📈 对比分析**

方法上先与基本的“对比/新信息”错误、TofuEval、FineSurE 等先前分类体系做对照；LLM 判定器在粗粒度错误检测的句子层面平均 60‑70% 平衡准确率，细粒度错误表现差异明显，整体仍处于中等水平。

**⚠️ 局限性**

局限性包括：数据集规模有限；某些错误类别缺乏实例；未对 LLM 推理过程进行评估；可能存在模型偏差、位置偏置和身份偏见；仅关注英文，未覆盖语法/流畅性错误。

---

## 606. SNC: A Stem-Native Codec for Efficient Lossless Audio Storage with Adaptive Playback Capabilities

**arXiv ID:** 2602.08148 | [PDF](https://arxiv.org/pdf/2602.08148v1)

**作者:** Shaad Sufi `[一作]` `[通讯]` (Wubble AI), Shaad Sufi (Wubble AI)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出并实现了一种 Stem‑Native Codec (SNC)，将音乐存储为独立编码的音轨（stems）加低能量的主混残差，支持自适应播放、空间渲染和用户混音。

**💡 创新点**

创新点在于：①用独立编码的音轨降低信息熵，显著压缩文件；②加入轻量残差层实现无损重建；③通过 Matroska + JSON 元数据实现可扩展的自适应规则和空间信息，使文件既小又具功能。

**🔧 技术方法**

技术主要包括：Opus VBR 作为音频编码器；Matroska 容器存放多轨与残差；JSON 结构化元数据；基于 AI 的音轨分离（Hybrid Transformer）；评估指标 STOI、Spectral Convergence、SNR；开源编码/解码实现。

**📊 数据集**

实验数据集为一首 2:18 的电子/摇滚混音（48kHz/16bit），通过 AI 分离得到四个音轨（人声、鼓、低音、其它），随后按 Opus 码率分别编码并加入残差。

**📈 对比分析**

与 FLAC、MP3、Opus 256kbps、AAC 256kbps 等标准格式比较，SNC 采用 7.76 MB 文件，较 FLAC 缩小 38.2%（从 12.55 MB），STOI 0.996、Spectral Convergence 0.0402、SNR 24.86 dB，均满足或超过无损感知阈值，显示出较好的压缩效率与音质。

**⚠️ 局限性**

局限性包括：①需要高质量的音轨（原始工作室导出或 AI 分离会导致残差能量升高）；②解码需并行解码多条 Opus 流，增加一点计算负担；③元数据标准化与播放器支持尚未普及，影响行业推广。

---

## 607. Pretraining with Token-Level Adaptive Latent Chain-of-Thought

**arXiv ID:** 2602.08220 | [PDF](https://arxiv.org/pdf/2602.08220v1)

**作者:** Boyi Zeng `[一作]` (Shanghai Jiao Tong University), Zhouhan Lin `[通讯]` (Shanghai Jiao Tong University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种在预训练阶段生成可变长度隐式链式推理（Latent CoT）并在每个 token 生成前自适应分配计算量的方法。

**💡 创新点**

创新点在于：1) 在一次预训练中自然学习到可变长度隐式 CoT；2) 通过并行掩码实现 2D 顺序限制，消除串行依赖；3) 结合概率停滞路由器和 correctness‑aware 适应性损失，令模型在每个 token 上自适应停留或跳过计算；4) 在不增加模型参数的前提下提升每 token 计算量，从而改善性能。

**🔧 技术方法**

使用的技术包括：并行掩码（parallel masking）将注意力扩展到 (token, latent step) 维度；概率停滞路由器（Router）与阈值裁剪；期望混合（expectation‑based mixing）保留概率质量；正确性感知自适应损失；以及与 LLaMA 架构集成的预训练与推理流程。

**📊 数据集**

主要使用的数据集为公开的 Pile 语料库进行预训练，评估则使用 The Pile、WikiText、LAMBADA 三个语言建模基准，以及 0‑shot 与 5‑shot 的跨领域任务集（LAMBADA、SciQ、HellaSwag、PIQA、WinoGrande、ARC‑Easy/Challenge、RACE 等）。

**📈 对比分析**

与 LoopedLM、PausedLM、PonderLM、PonderLM2、MoR 等基线在相同参数或 FLOPs 对比；结果显示其在语言模型 perplexity 下降（例如 LLaMA‑1.4B 与 l_max=3 的 perplexity 低于 PonderLM‑1.4B），以及在多项下游任务上的平均准确率提升（0‑shot 与 5‑shot 均超过基线），同时训练 FLOPs 低于 PonderLM‑2 等竞争者。

**⚠️ 局限性**

限制方面：1) 需要调节路由器与自适应损失中的超参数（λ、β、τ）；2) 目前仅在 LLaMA 系列上验证，未在更大模型或其他架构上的通用性；3) 该方法在极长上下文或极大 token 负载时的计算效率尚未系统评估；4) 对特殊任务如代码生成、翻译的适用性尚需进一步验证。

---

## 608. HOICraft: In-Situ VLM-based Authoring Tool for Part-Level Hand-Object Interaction Design in VR

**arXiv ID:** 2602.08219 | [PDF](https://arxiv.org/pdf/2602.08219v1)

**作者:** Dohui Lee `[一作]` (KAIST), Sang Ho Yoon `[通讯]` (KAIST)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一个基于视觉语言模型（VLM）的实时 VR 交互设计工具，支持手物交互（HOI）在对象细部级别的自动化推荐、定制和映射。

**💡 创新点**

创新点包括：①将用户意图与 3D 对象属性结合，通过 VLM 和 LLM 实现交互部分优先级推荐；②构建基于用户偏好的 HOI 推荐模块，采用上下文学习实现自适应排序与二元决策；③在沉浸式 VR 中提供即时反馈的原型设计流程，显著降低手工迭代成本。

**🔧 技术方法**

技术手段涵盖：视觉语言模型（如 GPT‑4o）用于对象分析与意图理解；LLM 进行上下文学习与决策生成；Unity、Meta Interaction SDK 与手势识别 API 实现实时物理与手势交互；多视角图像采集实现对象解析。

**📊 数据集**

数据集：①来自 3D 物体与其可交互部件的 20 组日常对象（13 组对象‑部件对）；② 20 名用户在 5 种 HOI 设计（PM、GM、CM、GA、CA）下的使用偏好、可用性、真实感、效率、挑战等评价；③ 12 名 VR 设计师在手工与推荐两种界面下的实验数据。

**📈 对比分析**

比较方法：①与传统手工映射基线进行决策速度、探索次数及主观满意度对比；②通过 SUS、Likert 量表评估工具可用性；③使用 Friedman、Wilcoxon 等非参数检验评估 HOI 设计在效率、误差、反转次数等方面的差异。结果显示推荐模式与手工模式在决策速度无显著差异，但显著减少探索次数；HOI 推荐模块的输出质量与手工相当；效率上，物理‑基准优于手势/接触，接触更快、误差更小。

**⚠️ 局限性**

局限性：① 只支持单自由度（平移/旋转）的标准关节；② 依赖预处理的对象（分割、标注、运动约束）对细粒度部件识别不完善；③ 对复杂多部件协调、非规则几何体的交互支持不足；④ 设计意图以自由文本输入为主，表达抽象概念困难；⑤ 在多平台部署方面尚未完整实现。

---

## 609. Sparsity-Aware Evolution for Model Merging

**arXiv ID:** 2602.08218 | [PDF](https://arxiv.org/pdf/2602.08218v1)

**作者:** Huan Zhang `[一作]` (Université de Montréal), Bang Liu `[通讯]` (Université de Montréal)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种基于稀疏感知的进化模型合并框架（SAE），通过迭代修剪-合并循环实现稀疏化与融合。

**💡 创新点**

将稀疏约束直接嵌入进化适应度函数，形成稀疏竞争与吸引机制，从而减少不同父模型之间的互相干扰。

**🔧 技术方法**

使用稀疏化、重密集化、进化搜索、稀疏性评分、循环稀疏调度等技术。

**📊 数据集**

在 LLaMA‑3.2‑3B 的 Instruct‑Math 与 Instruct‑Multilingual 这两种子模型上进行实验，评估集为 GSM8K 与 MMLU‑ProX。

**📈 对比分析**

与粒子群优化（PSO）基线对比，SAE 在 GSM8K 与 MMLU‑ProX 上均略优，平均提升约 0.5–1%，并在多任务场景中展示更平滑的二阶几何特征。

**⚠️ 局限性**

局限包括计算成本较高、仅验证同构模型、稀疏调度为经验式、未在异构或 MoE 体系上进行验证。

---

## 610. Chain-of-Caption: Training-free improvement of multimodal large language model on referring expression comprehension

**arXiv ID:** 2602.08211 | [PDF](https://arxiv.org/pdf/2602.08211v1)

**作者:** Yik Lung Pang `[一作]` (Queen Mary University of London), Changjae Oh `[通讯]` (Queen Mary University of London)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究多模态大型语言模型（MLLM）在指代表达理解（REC）任务中的性能，分析视觉与文本上下文的作用，并提出无训练的 Chain-of-Caption 框架来提升定位准确率。

**💡 创新点**

无训练的 Chain-of-Caption 框架，结合基于 grounding 的描述、裁剪、VQA 与 captioning 的多轮迭代上下文增强，实现对 REC 预测的自我校正和精细化。

**🔧 技术方法**

采用 NVILA-8B/15B、Qwen2.5-7B 等 MLLM；使用 prompt 生成 grounded description、图像裁剪、绘制框、VQA 与 captioning 进行上下文补充；并通过多轮迭代更新预测框。

**📊 数据集**

四大 REC 基准集：RefCOCO、RefCOCO+、RefCOCOg 以及 Ref-L4。

**📈 对比分析**

在基线模型上对比单一上下文（文字、视觉）与 Chain-of-Caption，评估 0.5、0.7、0.9 IoU 阈值下的准确率。Chain-of-Caption 在 0.7/0.9 IoU 上提升 5%–30%，在某些设置甚至超过 Qwen2.5-7B 的表现。

**⚠️ 局限性**

对 grounded description 的格式一致性高度依赖 prompt，裁剪操作会导致低 IoU 下性能下降；部分模型（如 Qwen2.5-7B）在生成结构化描述时不稳定，限制了方法的普适性。

---

## 611. CADO: From Imitation to Cost Minimization for Heatmap-based Solvers in Combinatorial Optimization

**arXiv ID:** 2602.08210 | [PDF](https://arxiv.org/pdf/2602.08210v1)

**作者:** Hyungseok Song `[一作]` (LG AI Research), Woohyung Lim `[通讯]` (LG AI Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ba576bd1-e51d-44e8-8077-fc943b333c93` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种基于强化学习的热图求解器CADO，解决了传统监督学习在热图生成中的目标不匹配问题；

**💡 创新点**

创新点在于将扩散去噪过程视为马尔可夫决策过程，设计Label-Centered Reward利用训练标签作为无偏基线，并通过Hybrid Fine‑Tuning实现参数高效、稳定的RL微调；

**🔧 技术方法**

核心技术包括扩散模型、马尔可夫决策过程建模、REINFORCE梯度、LoRA与Selective Layer Fine‑Tuning、Label‑Centered Reward；

**📊 数据集**

实验使用TSP（100–10k节点）和MIS（MIS‑SAT、MIS‑ER）等标准基准数据集；

**📈 对比分析**

与多种基线（Exact、Heuristic、SL、RL、UL）比较，CADO在TSP和MIS上均取得了新的最优或接近最优的落差，且在低质量训练数据和真实世界TSPLIB上表现出色；

**⚠️ 局限性**

局限性包括对解码器的显式依赖、RL训练仍需高计算开销以及在极大规模实例下的可扩展性待进一步验证。

---

## 612. Large Language Models in Peer-Run Community Behavioral Health Services: Understanding Peer Specialists and Service Users' Perspectives on Opportunities, Risks, and Mitigation Strategies

**arXiv ID:** 2602.08187 | [PDF](https://arxiv.org/pdf/2602.08187v1)

**作者:** Cindy Peng `[一作]` (Carnegie Mellon University), Hong Shen `[通讯]` (Carnegie Mellon University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过与新泽西州协作支持计划（CSPNJ）合作，利用漫画式协同设计（comicboarding）对16名同行专家和10名服务用户进行访谈式研讨，探讨在同行主导的社区行为健康服务中整合大型语言模型（LLM）推荐系统的机会、风险及缓解策略。

**💡 创新点**

创新点在于：①将LLM视为“关系协作者”而非临床决策者，提出“生活经验在环（lived‑experience‑in‑the‑loop）”的设计理念；②揭示LLM在同行支持中的“关系权威”维度，通过三大张力（规模 vs 具体性、信任 vs 不信任、自治 vs 自动化）归纳机会、风险与缓解措施；③使用漫画式工具降低技术壁垒，促使低技术素养的参与者能充分表达对LLM的期望与担忧。

**🔧 技术方法**

技术采用的是通用LLM（如ChatGPT风格的生成式语言模型）作为推荐引擎，支持自然语言交互、信息检索与生成摘要；同时结合检索增强生成（RAG）与提示工程，以实现本地化知识适配。

**📊 数据集**

数据来源为定性访谈与研讨记录，涵盖16名同行专家与10名服务用户的自述、情景故事及对漫画板的反馈。并未使用公开数据集训练LLM，而是通过与CSPNJ合作收集服务资源与案例，构建本地化知识库供LLM检索。

**📈 对比分析**

本研究未进行量化性能对比，而是通过主题分析与编码，归纳出机会、风险与缓解策略；在实验层面也未对LLM生成结果做准确率或安全性评估，仅基于参与者对潜在功能与危害的主观评价。

**⚠️ 局限性**

局限性包括：样本量有限且仅来自单一地区的同行组织；研究聚焦于用户感知，未验证LLM在实际服务中的效果；缺乏对LLM输出质量的客观评测；可能存在受访者偏倚与社会期望影响，且结论在不同文化或资源条件下的泛化性尚未验证。

---

## 613. Spherical Steering: Geometry-Aware Activation Rotation for Language Models

**arXiv ID:** 2602.08169 | [PDF](https://arxiv.org/pdf/2602.08169v1)

**作者:** Zejia You `[一作]` (Tufts University), Hanjie Chen `[通讯]` (Rice University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种无训练的激活旋转方法——Spherical Steering，用来在推理阶段通过几何一致的方向更新来控制大型语言模型的行为；

**💡 创新点**

核心创新在于：①使用在单位高维球面上的 geodesic（最短弧）旋转来替代传统的向量加法，实现激活向量的幅值不变；②结合 von Mises‑Fisher 分布的置信门控，对每个 token 的旋转强度进行自适应调节；③通过对比学习提取正负示例的 prototype 方向，将真相与幻觉的语义区分投射到球面上；

**🔧 技术方法**

技术细节包括：对比学习得到的 prototype 方向；对激活向量进行归一化后在球面上执行 Slerp 旋转；基于 vMF 的软最大化产生置信分数并映射到旋转比例；在 LLaMA‑3.1‑8B 与 Qwen‑2.5‑7B 的各层中插入此干预；

**📊 数据集**

使用多项选择基准 TruthfulQA（MC1/MC2/MC3）、COPA、StoryCloze、MMLU、WinoGrande、BoolQ；以及 TruthfulQA 的生成评测（TRUE×INFO）和 5‑shot ICL 作为对照；

**📈 对比分析**

与 ITI、CAA、SADI‑HEAD、5‑shot ICL 等传统加法式激活干预方法对比；在 TruthfulQA 上，Spherical Steering 的平均多项选择准确率提升约 11%（LLaMA）和 5%（Qwen），同时保持或提高 TRUE×INFO，构成 Pareto 前沿；在其他基准同样保持领先，且相较加法干预更具“collapse‑efficiency”，即在相同表示退化水平下获得更高准确率；

**⚠️ 局限性**

局限性包括：①需要手动调参（α、β）以平衡准确率与生成质量；②过强旋转会导致生成多样性下降；③目前验证仅覆盖 LLaMA‑3.1‑8B 与 Qwen‑2.5‑7B，未在更大模型或多语言场景验证；④门控参数依赖经验设定，缺乏理论最优选择；⑤对极端对抗示例或非语义属性的鲁棒性尚待进一步研究。

---

## 614. Reliable and Responsible Foundation Models: A Comprehensive Survey

**arXiv ID:** 2602.08145 | [PDF](https://arxiv.org/pdf/2602.08145v1)

**作者:** Xinyu Yang `[一作]` (Carnegie Mellon University), Huaxiu Yao `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

系统综述并梳理了基础模型（包括LLM、MLLM、图像与视频生成模型）在可靠性与责任性方面的关键挑战与方法，涵盖偏见、公平、对齐、安全、隐私、不确定性、分布漂移、可解释性和AI生成内容检测等九大维度；

**💡 创新点**

首次将九个维度与四类基础模型整合成统一框架，系统性地识别相互作用、交叉影响与共同挑战，并提出跨维度的未来研究方向；

**🔧 技术方法**

综合了评估指标、对齐与偏见消除技术（SFT、RLHF、DPO、prompt engineering等）、安全防御策略、隐私保护方法、可解释性工具和AIGC检测技术；

**📊 数据集**

利用公开的基础模型预训练与微调数据集（如Common Crawl、WebText、Reddit、Wikipedia、ImageNet、COCO、LAION、Kinetics等），以及自建的基准评测集（如BiasBench、Winoground、ImageNet-A、SkepticalAI等）；

**📈 对比分析**

通过与现有对齐、偏见检测、鲁棒性与安全防御方法的对照实验，显示本综述所推荐的多模态对齐、对齐强化学习与可解释性技术在提升模型公平性、鲁棒性与可信度方面均优于单一方法；

**⚠️ 局限性**

受限于大模型规模导致的计算成本与评测难度，缺乏统一可解释性与对齐评价标准，以及对跨域多模态偏见与安全威胁的全局监测手段，使得实际部署仍需进一步验证与细化。

---

## 615. InfiCoEvalChain: A Blockchain-Based Decentralized Framework for Collaborative LLM Evaluation

**arXiv ID:** 2602.08229 | [PDF](https://arxiv.org/pdf/2602.08229v1)

**作者:** Yifan Yang `[一作]` (Hong Kong Polytechnic University), Hongxia Yang `[通讯]` (Hong Kong Polytechnic University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出基于区块链的去中心化LLM评估框架CoEvalChain，实现多节点多硬件多参数的联合评估，显著降低评估标准差

**💡 创新点**

首次将区块链共识与激励机制结合用于LLM评测，利用多维环境消除随机性，并提供透明公平的验证流程

**🔧 技术方法**

使用区块链P2P网络、Schelling Point共识、加密Commit‑Reveal、Gaussian权重激励、CLT统计等技术

**📊 数据集**

采用公开基准GSM8K、HumanEval、LiveCodeBench、GPQA‑Diamond、MMLU等数据集进行评估

**📈 对比分析**

与传统集中式评测对比，去中心化方法标准差从约1.67降至0.28，95%置信区间显著收窄，模型排名更稳健

**⚠️ 局限性**

依赖多节点参与，网络延迟与算力差异可能影响结果；目前仅覆盖文本基准，尚未扩展到多模态模型

---

## 616. Efficient-SAM2: Accelerating SAM2 with Object-Aware Visual Encoding and Memory Retrieval

**arXiv ID:** 2602.08224 | [PDF](https://arxiv.org/pdf/2602.08224v1)

**作者:** Jing Zhang `[一作]` (Chinese Academy of Sciences), Qingyi Gu `[通讯]` (Chinese Academy of Sciences)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了 Efficient‑SAM2，一种对 SAM2 进行后训练加速的框架，显著降低视频对象分割任务中的计算负载；

**💡 创新点**

创新点在于发现 SAM2 的稀疏感知模式，并设计基于对象的 Sparse Window Routing（SWR）与 Sparse Memory Retrieval（SMR）两种轻量化模块，动态剔除背景窗口和无关记忆 token 的冗余计算；

**🔧 技术方法**

采用窗口级路由、背景窗口轻量快捷分支、记忆 token 的稀疏模式缓存以及少量的重构训练损失，结合 Hiera 视觉编码器与窗口注意力；

**📊 数据集**

实验数据集包括 SA‑V、DAVIS 2017 与 MOSE 等视频分割基准，使用 SA‑V 训练集进行极少量的无标签样本训练；

**📈 对比分析**

与 ToMe、ALGM、ToMe4DM、MemPool、EdgeTAM、SMR‑random/SMR‑uniform 等方法比较，Efficient‑SAM2 在 SAM2.1‑L 模型上实现 1.68× 的整体加速，SWR 与 SMR 分别提供约 1.83× 与 1.78× 的加速，且在 SA‑V、DAVIS、MOSE 上的精度仅下降 1% 或几乎不变；

**⚠️ 局限性**

局限性包括需要少量训练样本来学习快捷分支，方法主要针对窗口注意力架构，可能对其他模型结构或极端场景的泛化能力有限。

---

## 617. Weak-Driven Learning: How Weak Agents make Strong Agents Stronger

**arXiv ID:** 2602.08222 | [PDF](https://arxiv.org/pdf/2602.08222v1)

**作者:** Zehao Chen `[一作]` (China Telecom eSurfing Cloud), Yikun Ban `[通讯]` (Beihang University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种后训练范式 Weak-Driven Learning，使弱检查点帮助强模型进一步提升。

**💡 创新点**

创新点在于利用弱模型的概率分布混合来激活梯度，打破 SFT 的饱和瓶颈，且不需要额外推理成本。

**🔧 技术方法**

使用自回归 LLM、logit 混合、基于熵的课程化数据激活、联合训练、梯度放大等技术。

**📊 数据集**

在数学推理（AIME、MATH、GSM8K 等）和代码生成（HumanEval、MBPP）等数据集上进行评测。

**📈 对比分析**

相较于标准 SFT、UNDIAL、NEFTune 等基线，显著提升 5–7% 的准确率（如 Qwen3‑4B 由 64.1% 提升到 69.1%），且无额外推理成本。

**⚠️ 局限性**

局限性包括对历史检查点质量依赖、在极大模型上可扩展性待验证、未解决模型在极难样本上的退化等。

---

## 618. Finger Tendon Vibration: Finger Movement Illusions for Immersive Virtual Object Interaction

**arXiv ID:** 2602.08201 | [PDF](https://arxiv.org/pdf/2602.08201v1)

**作者:** Kun-Woo Song `[一作]` (Korea Advanced Institute of Science and Technology), Sang Ho Yoon `[通讯]` (Korea Advanced Institute of Science and Technology)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

**🎯 论文内容**

提出利用指腱振动（FTV）在VR中实现运动错觉的肌肉运动诱导式 kinesthetic haptic 反馈，提升虚拟物体交互的现实感与沉浸感。

**💡 创新点**

创新点在于：①将短时（<5 s）指腱振动应用于手指，首次实现即时的运动错觉；②系统性研究了最短有效持续时间（0.75 s）及其对感知力量和不自主运动的影响；③设计了六种典型VR交互场景，并给出了基于触发时机和持续时长的渲染准则。

**🔧 技术方法**

使用低成本的两台 80 Hz、±1 mm 位移的偏心旋转质量（ERM）电机配合微控制器、驱动电路和 3D 打印外壳；实验采集手指关节角度（OptiTrack）和按压力（压力传感器），并在 Meta Quest 3 上实现全息渲染。

**📊 数据集**

没有使用公开数据集，而是自行收集 28 名受试者（左右手）在 5 分钟内完成的 5 秒手指按压数据、8 秒交互轨迹以及 5 秒指尖位置记录。

**📈 对比分析**

通过 16 名受试者的双盲实验，比较了 FTV、单向振动、无振动三种设置，使用 avatar embodiment 问卷、现实感、沉浸感等 7‑点 Likert 量表。结果显示：FTV 在身体拥有感方面显著提升（p<0.05），其余指标（沉浸、现实、享受）与简单振动相近，但比无振动更好。

**⚠️ 局限性**

局限性包括：①仅针对单指（拇指）实现，无法覆盖多指交互；②ERM 电机延迟约 50 ms，短时振动仍可能引起视觉-触觉不同步；③需要较长的手动校准（5–15 min）；④实验仅评估 6 种场景，未覆盖所有 VR 交互类型；⑤未使用 EMG 监测，感知测量主要基于自报告。

---

## 619. Chamelion: Reliable Change Detection for Long-Term LiDAR Mapping in Transient Environments

**arXiv ID:** 2602.08189 | [PDF](https://arxiv.org/pdf/2602.08189v1)

**作者:** Seoyeon Jang `[一作]` (Korea Advanced Institute of Science and Technology), Hyun Myung `[通讯]` (Korea Advanced Institute of Science and Technology)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `729e5870-4135-47f5-97f2-e3974d07b5dc` `3855fcda-48ef-4070-a15e-803cd5c84d83` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种双头网络，用于在线检测低动态（LD）变化并维护长期3D地图。

**💡 创新点**

利用单次扫描合成数据增强生成伪标签，并引入跨可见性置信度估计，显著提升动态环境下的鲁棒性。

**🔧 技术方法**

使用4D稀疏卷积骨干、双头分类与置信度头、基于贝叶斯的地图更新与伪标签数据生成技术。

**📊 数据集**

自制施工现场与实验室数据集（8月建图、10月扫描）以及LiSTA室内办公数据集。

**📈 对比分析**

与可见性、占用、MapMOS、SPS等基线对比，扫描端IoU提升约10%~20%，地图端F1提升约12%，表现出更高的准确率与鲁棒性。

**⚠️ 局限性**

对地图分辨率与多场景配准误差敏感，需保持低配准误差才能充分发挥伪标签优势。

---

## 620. Evasion of IoT Malware Detection via Dummy Code Injection

**arXiv ID:** 2602.08170 | [PDF](https://arxiv.org/pdf/2602.08170v1)

**作者:** Sahar Zargarzadeh `[一作]` (University of Texas at Arlington), Mohammad Islam `[通讯]`

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在 Mirai 机器人的扫描阶段注入结构化假代码，动态扰动功耗特征，从而逃避基于功耗侧信道的 AI/ML 漏洞检测。

**💡 创新点**

提出了利用解释性 AI（SHAP）定位最具辨识度的功耗时段并注入假代码的对抗策略，首次将假代码注入视为侧信道攻击的实用逃逸手段。

**🔧 技术方法**

采用深度学习模型（LSTM、BiLSTM、TCN、BiLSTM+CNN、CNN+Attention、AE+MLP）、SHAP 解释、Pearson、ANOVA、Granger 因果分析、噪声注入与对抗训练等技术。

**📊 数据集**

构建了包含 5 款 Android 智能手机（Samsung Galaxy、Google Pixel、OnePlus 等）在四种工作状态（空闲、IoT 服务、原始 Mirai、注入假代码 Mirai）下采样 1kHz 的功耗时间序列数据，总计 5100 条样本。

**📈 对比分析**

与六种主流深度模型进行基准对照；在原始数据上精度最高可达 96%，在注入假代码后攻击成功率平均超过 75%，单个循环假代码甚至达到 96% 的误判率；对抗训练显著降低误判率，噪声注入效果有限。

**⚠️ 局限性**

局限性包括：仅在安卓智能手机上验证，未评估嵌入式微控制器或长期运行场景；假代码引入的执行时间延迟可能被基于时序的监控发现；对抗训练和噪声注入的鲁棒性需进一步提升。

---

## 621. DAS-SK: An Adaptive Model Integrating Dual Atrous Separable and Selective Kernel CNN for Agriculture Semantic Segmentation

**arXiv ID:** 2602.08168 | [PDF](https://arxiv.org/pdf/2602.08168v1)

**作者:** Mei Ling Chee `[一作]` (Lakehead University), Kanchan Keisham `[通讯]` (Vellore Institute of Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `64443552-63e0-44b5-906f-d90fe95c5a1b` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种轻量化农业语义分割模型 DAS‑SK，能够在高分辨率遥感图像上实现高精度像素级分类。

**💡 创新点**

创新点在于将双分支膨胀可分离卷积（DAS‑Conv）与自适应通道注意力（Selective Kernel）融合，并改进 ASPP 模块，引入条形池化以捕捉长距离结构，显著提升多尺度特征表达同时保持极低计算量。

**🔧 技术方法**

技术实现基于改造的 DeepLabV3 体系，使用 MobileNetV3‑Large 与 EfficientNet‑B3 两条轻量化骨干，结合 DAS‑SK 卷积、增强 ASPP、分层解码器以及多尺度特征拼接与注意力机制，训练采用交叉熵、Dice、Focal 与 Lovász 损失的组合。

**📊 数据集**

实验数据集包括 LandCover.ai（高分辨率航空影像）、VDD（多环境 UAV 影像）以及 PhenoBench（作物-杂草细粒度分割），共计 3 个公开基准。

**📈 对比分析**

与多种 CNN、Transformer 以及混合模型对比，DAS‑SK 在 mIoU 上取得 86.25% / 79.45% / 85.55%（分别对应 LandCover.ai、VDD、PhenoBench），参数仅 10.7M，GFLOPs 11.25，效率提升 49% 以上，且 FPS 在 40+ 级，远优于同类方法。

**⚠️ 局限性**

局限性主要体现在：① 对极端光照、季节变化和稀疏类别的鲁棒性仍有限；② 需要一定规模的标注数据才能充分训练；③ 在极低资源的嵌入式平台上仍可能因内存占用稍高而受限，后续研究需进一步探索自监督和域自适应策略。

---

## 622. Variance-Gated Ensembles: An Epistemic-Aware Framework for Uncertainty Estimation

**arXiv ID:** 2602.08142 | [PDF](https://arxiv.org/pdf/2602.08142v1)

**作者:** H. Martin Gillis `[一作]` (Dalhousie University), Thomas Trappenberg `[通讯]` (Dalhousie University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了 Variance‑Gated Ensembles (VGE) 框架，包含可训练的 VGN 层和基于决策边缘的 VGMU 评分，用于高效地在集成模型中估计不确定性。

**💡 创新点**

创新点在于：① 用信噪比门控机制将模型不确定性嵌入概率分布；② 通过 VGMU 只关注 top‑2 边缘与方差的乘积，实现线性时间的方差分解；③ 通过闭式向量-雅可比乘积实现 VGN 的端到端可微训练，避免了 O(M²C) 的配对散度计算。

**🔧 技术方法**

技术手段包括：集成统计（均值与方差）、指数门控函数、向量‑雅可比乘积推导、可微归一化层、跨模型梯度共享及 softplus 可学习的门控参数。

**📊 数据集**

在 MNIST、SVHN、CIFAR‑10 与 CIFAR‑100 数据集上进行实验，使用 LeNet‑5、WideResNet‑28‑10 等网络，配合 Deep Ensemble、Last‑Layer Ensemble、Monte‑Carlo Dropout 等多种集成策略。

**📈 对比分析**

与熵/互信息拆分、EPKL、EPJS 等信息论方法对比，VGMU 在不确定性排名与 OOD 检测上与基线保持一致或略优，计算成本仅为 O(MC)（VGMU）和 O(MC)（VGN），在 CIFAR‑100 上实现 365× 的推理速度提升，部分配置还能提升校准误差。

**⚠️ 局限性**

局限性：① 只关注 top‑2 边缘，忽略全 simplex 的分布不一致；② 依赖一阶、二阶矩，可能无法捕获多峰分布；③ 门控函数形式固定，对极端类不平衡或大规模极小差异的集成可能效果有限；④ 在大规模集成且多头共享时，VGN 可能抑制必要的方差，导致 OOD 检测性能下降。

---

## 623. Distributed Architecture Reconstruction of Polyglot and Multi-Repository Microservice Projects

**arXiv ID:** 2602.08166 | [PDF](https://arxiv.org/pdf/2602.08166v1)

**作者:** Oscar Manglaras `[一作]` (Adelaide University), Markus Wagner `[通讯]` (Monash University)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df`

**🎯 论文内容**

设计并实现了一个基于静态分析的微服务架构重构框架ModARO，支持多语言、分布式仓库环境；

**💡 创新点**

创新点在于引入可复用的“extractor”模块化分析单元，并实现多仓库分布式重构与后期链接解析，打破单仓库与单技术的限制；

**🔧 技术方法**

技术手段包括静态代码解析、正则表达式抽取、JSON Schema 与 JSON Pointer 规范、并行执行与聚合算法，并可嵌入现有工具（如ReSSA）来完成分析；

**📊 数据集**

实验使用作者内部的多语言、多仓库微服务项目，未公开使用标准数据集；

**📈 对比分析**

论文未给出量化评估或与现有方法的对比实验，主要通过案例演示验证框架的可扩展性和模块化设计，性能指标未被测评；

**⚠️ 局限性**

局限性包括需要自行实现或注册 extractor、缺乏统一的模型 schema、对安全性与动态分析未做深入探讨、以及缺少对大型真实项目的评测。

---

## 624. ReefFlex: A Generative Design Framework for Soft Robotic Grasping of Organic and Fragile objects

**arXiv ID:** 2602.08285 | [PDF](https://arxiv.org/pdf/2602.08285v1)

**作者:** Josh Pinskier `[一作]` (CSIRO Robotics), David Howard `[通讯]` (CSIRO Robotics)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文设计并验证了一种生成式软机器人抓手框架（ReefFlex），用于在珊瑚养殖设施中安全、高效地抓取多形态、易损的珊瑚及其基座；

**💡 创新点**

创新点包括：①将专家直觉与多负荷拓扑优化相结合的层级生成式设计框架，能够在极高非线性环境下产生多样化、可适应的软抓手；②提出机械智能 cam‑barrel 驱动机构，实现无外部传感器、可在水下使用的自适应抓取；③构建抓取质量评估基准，系统性比较设计与传统 Fin‑Ray 抓手。

**🔧 技术方法**

技术主要包括：多负荷（6 个或 3 个）SIMP 拓扑优化、非线性有限元仿真、3D 打印软抓手与机械结构、工业机器人 UR10e 进行实验测试、以及海水环境下的现场演示。

**📊 数据集**

数据集：作者自制的 7 种测试对象（6 种 3D 打印珊瑚+空槽）以及真实海水珊瑚养殖设施中的珊瑚样本，未使用公开公开数据集。

**📈 对比分析**

与 Fin‑Ray 抓手进行对比，通过抓取成功率、抓取质量得分（0–4）、冲击响应等指标评估。实验结果显示，优化后的抓手在多尺寸珊瑚上成功率最高，尤其 P(i)、P(iii) 及 A(ii) 设计在不同粗细、尺寸珊瑚上表现优异；在现场演示中 P(i) 的成功率（8/10）显著高于 Fin‑Ray（1/10）。

**⚠️ 局限性**

局限性包括：①仿真模型对极大变形的近似可能导致设计在实际水下环境中出现未预见的失效；②高柔性设计易产生应力集中，导致疲劳失效；③未在长期海水腐蚀与生物附着条件下进行测试；④对极端碰撞、多物体冲突场景的适应性仍有待验证。

---

## 625. Tighnari v2: Mitigating Label Noise and Distribution Shift in Multimodal Plant Distribution Prediction via Mixture of Experts and Weakly Supervised Learning

**arXiv ID:** 2602.08282 | [PDF](https://arxiv.org/pdf/2602.08282v1)

**作者:** Haixu Liu `[一作]` (Sydney University), Hongsheng Xing `[通讯]` (Shandong University of Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

开发了一个多模态融合的弱监督植物种分布预测框架，结合了 Presence–Absence（PA）与 Presence‑Only（PO）数据，并通过混合专家模型（MoE）实现地理分区推理。

**💡 创新点**

创新点包括：①基于卫星影像覆盖的 PO 样本聚合伪标签策略；②可堆叠的串行三模态交叉注意力融合机制；③两阶段 MoE 训练与地理邻近分区推理方法。

**🔧 技术方法**

采用的技术包括：Swin Transformer (Base) 影像提取、TabM 表格特征抽取、Temporal Swin Transformer 时序建模、串行交叉注意力融合、Asymmetric Loss (ASL) 失真、MOE 分区训练以及 Threshold Top‑K 后处理。

**📊 数据集**

使用的数据集为 GeoLifeCLEF 2024/2025，包含 88,987 条 PA 训练样本、3,845,533 条 PO 训练样本以及 11,255 种植物标签。

**📈 对比分析**

通过在 2024 与 2025 公开/私有榜单上与 PA 单模型、PA+PO 混合模型对比，MoE 模型在 2024 公开/私有榜单分别达到 0.369/0.372，2025 公开/私有榜单分别达到 0.217/0.245，显示在 OOD 场景下显著提升。

**⚠️ 局限性**

局限性包括：伪标签仅基于规则生成，未实现迭代半监督；PO 数据的标签噪声未显式建模；多标签长尾分布导致模型偏向常见种；对负样本错误的处理仍不充分。

---

## 626. Optimal Transmit Beamforming for MIMO ISAC with Unknown Target and User Locations

**arXiv ID:** 2602.08255 | [PDF](https://arxiv.org/pdf/2602.08255v1)

**作者:** Yizhuo Wang `[一作]` (Hong Kong Polytechnic University), Shuowen Zhang `[通讯]` (Hong Kong Polytechnic University)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文提出了在多输入多输出（MIMO）集成感知与通信（ISAC）系统中，对未知且随机目标与用户位置的场景下，基于后验克莱姆-罗伯特-边界（PCRB）最小化的最优发射波束成形设计，并证明在期望速率约束下，静态（时间不变）波束成形已能达到最优性能，无需在多时隙中动态分配资源。

**💡 创新点**

创新点包括：① 将目标与用户位置的不确定性用先验概率分布建模，并以PCRB作为感知性能度量；② 在未知位置的前提下，推导了最优波束成形的结构并给出其秩上界；③ 分析并证明了时间灵活性（多时隙波束成形）在该场景下无性能提升；④ 提出基于Kullback‑Leibler距离的基站‑用户‑目标关联算法。

**🔧 技术方法**

使用了概率统计方法（PCRB、Fisher信息矩阵）、凸优化（半正定规划、Lagrange对偶、KKT条件）、矩阵分析（秩约束）以及模拟仿真技术。

**📊 数据集**

实验使用的“数据集”为多维高斯角分布的离散化（目标与用户角度PDF均为Gaussian，分别通过均值与方差控制集中或扩散），并在仿真中采用统一线性阵列、LoS+NLoS通道模型以及预设的功率、噪声等参数；无真实传感/通信数据集。

**📈 对比分析**

与两种基线方案（先进行信道估计再进行ISAC设计，和将估计信号同时用于感知的两阶段方案）比较。实验结果显示：① 本文方法在相同速率目标下PCRB显著低于两种基线；② 随着目标/用户分布相似度（KLD）降低，PCRB上升；③ 在多时隙设置下，静态波束成形与动态波束成形获得相同性能；④ 基于KLD的关联策略在多小区场景中平均PCRB比随机关联低。

**⚠️ 局限性**

限制包括：假设用户/目标位置先验分布已知且满足可解析；信道与反射系数被视为已知或满足特定统计假设；系统模型以LoS+NLoS为主，未考虑更复杂多径或移动目标的动态跟踪；最终设计仍需要对实际硬件实现与时延同步等问题进行进一步研究。

---

## 627. SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities

**arXiv ID:** 2602.08254 | [PDF](https://arxiv.org/pdf/2602.08254v1)

**作者:** Arman Aghaee `[一作]` (Klick Health), Jouhyun Jeon `[通讯]` (Klick Health)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `67630363-6be0-4f51-ab05-7198250671a5` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

本文提出 SynthAgent 多代理系统，用于生成既医学又心理、行为层面丰富的肥胖伴心理疾病患者虚拟记录，并通过 GPT‑5、Claude 4.5 Sonnet 等 LLM 作为核心推理引擎进行仿真。

**💡 创新点**

创新点在于将多源数据（NHANES、医疗索赔、流行病学、病例报告）与 HEXACO、RST、TCI 等人格模型融合，构建多代理架构（Summarizer、Generator、Augmenter、Evaluator、Refiner）实现端到端的患者生成、质量评估与改进，并系统比较不同 LLM 的生成质量与语义多样性。

**🔧 技术方法**

使用的技术包括多代理系统框架、LLM（GPT‑5、Claude 4.5 Sonnet、Gemini 2.5 Pro、DeepSeek‑R1）作为推理核心、Jina Embeddings 进行语义向量化、t‑SNE 可视化、LLM‑as‑Judge 进行自动化质量评估。

**📊 数据集**

数据集来源于 12 期 NHANES 调查、7 万条 PurpleLab 医疗索赔记录、CDC BRFSS、世界肥胖联合会、国家共病调查、PubMed 病例报告等多维度数据。

**📈 对比分析**

通过固定 Summarizer 输出、四种不同 LLM 作为核心引擎，生成 120 份患者记录进行自动化质量评分与语义多样性评估。GPT‑5 与 Claude 4.5 Sonnet 的平均质量分均在 76 以上，差异无显著性；但 Claude 4.5 Sonnet 在多样性和心理维度表现更佳，GPT‑5 在结构、时间连贯性上更优；Gemini 2.5 Pro 与 DeepSeek‑R1 的质量与多样性均显著低于前两者。

**⚠️ 局限性**

局限包括：依赖输入数据的代表性与偏倚；代理间推理和冲突解决仍偏规则化，难以实现真正的自适应行为；人格与行为建模使用代理变量，难以完全捕捉真实社会文化差异；缺乏临床专家验证与跨域外部评估。

---

## 628. Software Testing at the Network Layer: Automated HTTP API Quality Assessment and Security Analysis of Production Web Applications

**arXiv ID:** 2602.08242 | [PDF](https://arxiv.org/pdf/2602.08242v1)

**作者:** Ali Hassaan Mughal `[一作]` (Independent Researcher), Muhammad Bilal `[通讯]` (Data Analytics)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

构建并执行了基于 Playwright 的自动化框架，对 18 个生产网站进行 HAR 捕获、8 种 API 反模式检测并计算综合质量分。

**💡 创新点**

首次量化并公开 API 调用质量与安全风险，提出可复现的 8 维反模式检测与加权评分方法。

**🔧 技术方法**

使用 Playwright 采集 HAR、Python+Pandas/Matplotlib 进行分析、基于内容类型和 URL 正则的 heuristic 识别。

**📊 数据集**

共 108 份 HAR（18 个网站×2 页×3 轮），约 475k 请求，涵盖 11 个业务类别。

**📈 对比分析**

通过对比不同架构（SSR vs SPA）和第三方占比，发现请求量越大质量分越低；平均质量分 76.9，最高 100，最低 56.8。

**⚠️ 局限性**

样本有限且为 18 个公开网站，heuristic 识别可能漏检/误报；第三方域判断简单，无法区分必要与可删减；仅基于单次捕获，未考虑时间变化。

---

## 629. Linearization Explains Fine-Tuning in Large Language Models

**arXiv ID:** 2602.08239 | [PDF](https://arxiv.org/pdf/2602.08239v1)

**作者:** Zahra Rahimi Afzal `[一作]` (University of Illinois Chicago), Mesrob I. Ohannessian `[通讯]` (University of Illinois Chicago)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了通过显式正则化靠近预训练模型实现的线性化微调，并阐明了其与神经切线核（NTK）回归的等价性；

**💡 创新点**

创新点在于给出了正则化强度对微调距离和NTK谱影响的理论上限，提出了基于NTK谱的层选择与正则化调优方法；

**🔧 技术方法**

主要技术包括：NTK回归、线性化微调框架、LoRA参数化微调、谱扰动与条件数分析，以及相应的实验验证；

**📊 数据集**

实验使用RoBERTa‑base+LoRA在GLUE（CoLA、SST‑2）、IMDb 和 Yelp 这四个数据集；

**📈 对比分析**

通过比较NTK条件数与训练/评估误差、准确率，证明NTK条件数能预测微调效果；实验表明较大正则化能使微调更接近线性化模型，且对准确率影响不大；

**⚠️ 局限性**

局限性包括：理论假设为平方损失和梯度下降，实际实验使用交叉熵和AdamW；NTK常数假设在有限宽度模型下可能不严格；仅验证LoRA，对其他PEFT方法的推广仍需进一步研究。

---

## 630. Grokking in Linear Models for Logistic Regression

**arXiv ID:** 2602.08302 | [PDF](https://arxiv.org/pdf/2602.08302v1)

**作者:** Nataraj Das `[一作]` (Indian Institute of Technology Madras), Chandrashekar Lakshminarayanan `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究在线性可分数据上使用逻辑回归和梯度下降时出现的延迟泛化（grokking）现象，揭示其背后的动力学机制。

**💡 创新点**

提出了三阶段学习动态（群体主导、支持向量去学习、支持向量泛化）并用隐式偏置分析解释了为何即便是单一超平面也会出现grokking；给出了支持向量失衡和测试分布敏感度对grokking时延的显式理论界限。

**🔧 技术方法**

梯度下降、逻辑损失、指数损失的渐近近似、支持向量分析、理论证明以及数值实验（包括PGD对抗样本）。

**📊 数据集**

构造的线性可分合成数据集，三种测试分布（标准、靠近间隔的敏感分布、PGD攻击生成的对抗分布）。

**📈 对比分析**

与标准训练/测试设置对比：在标准分布下无grokking，敏感和对抗分布下显著出现grokking；实验结果与理论推导高度一致，验证了理论预测的grokking时间和支持向量失衡的影响。

**⚠️ 局限性**

局限在于仅考虑线性可分且margin为正的合成数据；对复杂非线性任务、深度网络的推广需要进一步研究；理论推导假设学习率足够小且对抗样本生成方式有限。

---

## 631. "I Can't Keep Up": Accessibility Barriers in Video-Based Learning for Individuals with Borderline Intellectual Functioning

**arXiv ID:** 2602.08300 | [PDF](https://arxiv.org/pdf/2602.08300v1)

**作者:** Hyehyun Chu `[一作]` (KAIST), Juho Kim `[通讯]` (SkillBench)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

对边缘智力功能（BIF）人群在观看信息视频时的学习障碍进行深度访谈与观察研究，提出视频内容与认知差异的匹配设计原则。

**💡 创新点**

首次系统阐释BIF用户在视频学习中的认知-媒介不匹配、经验性负面因素及自我调节策略的交互机制，并给出针对内容层和界面层的具体改进建议。

**🔧 技术方法**

采用半结构化访谈、观察式观看与问卷测评相结合的定性研究方法，辅以主题编码与反思性分析。

**📊 数据集**

收集12名成年BIF参与者、4名社会工作者与4名家长的数据，使用一段约2分钟的AED使用教学视频作为实验素材。

**📈 对比分析**

并未通过量化指标与对照组比较，而是通过对比分析发现传统视频设计对BIF群体的认知负荷过高、缺乏可解释符号和自我效能支持，提出可行的可访问性改进方案。

**⚠️ 局限性**

样本规模有限、仅覆盖年轻成人、只测试单一类型视频、实验环境与日常学习情境差异大，未验证改进方案的实际学习成效。

---

## 632. Quantization-aware Photonic Homodyne computing for Accelerated Artificial Intelligence and Scientific Simulation

**arXiv ID:** 2602.08269 | [PDF](https://arxiv.org/pdf/2602.08269v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `7a50eb32-3dbc-4c3e-a038-bda01b2d9965`

---

## 633. DexFormer: Cross-Embodied Dexterous Manipulation via History-Conditioned Transformer

**arXiv ID:** 2602.08278 | [PDF](https://arxiv.org/pdf/2602.08278v1)

**作者:** Ke Zhang `[一作]` (Hong Kong University of Science and Technology), Renjing Xu `[通讯]` (Hong Kong University of Science and Technology)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了DexFormer，一种基于历史条件Transformer的跨胴体灵巧操纵策略，可在不同手部结构上实现零射击迁移

**💡 创新点**

通过在Transformer中使用观测-动作历史进行隐式形态推断，实现了对不同手部动力学的在线自适应控制，无需显式胴体识别或单独的解码头

**🔧 技术方法**

使用Transformer编码器+因果自注意、可共享动作空间、分布式数据并行训练、动态随机化以及观察-动作序列令牌化的RL算法

**📊 数据集**

在Isaac Lab中对100个随机化的LEAP、Allegro、Rapid手型（共300个胴体）进行训练，并在10个对象集合上测试；真实实验使用LEAP+Franka Arm与Intel RealSense摄像机

**📈 对比分析**

与3层GRU/ LSTM基线比较，DexFormer在零射击成功率上提升约15-25%，并在不同手型和变体上表现出更稳健的性能；多历史步长、胴体多样性、环境并行度均能进一步提升效果

**⚠️ 局限性**

受限于对象几何/质量的多样性、对高DoF手型的细节不足、需要在不同胴体上分离GPU导致梯度方差以及对非拓扑一致胴体支持不足

---

## 634. Language Modeling and Understanding Through Paraphrase Generation and Detection

**arXiv ID:** 2602.08274 | [PDF](https://arxiv.org/pdf/2602.08274v1)

**作者:** Jan Philip Wahle `[一作]` `[通讯]` (University of Göttingen), Jan Philip Wahle (University of Göttingen)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

将语义等价的改写拆分为可细粒度的语言学改写类型，并训练模型在检测、生成和下游任务中显式考虑这些类型。

**💡 创新点**

创新点在于：①构建了基于改写类型的多标签、span‑aware 评估框架；②提出了类型条件的生成器与检测器；③通过改写类型提升了抄袭检测、问答去重、标题/摘要/文本生成等多任务性能；④将改写类型用作提示工程的可操作工具。

**🔧 技术方法**

技术包括：自监督 span‑aware 分类与生成；in‑context 及 fine‑tune 训练；强化学习（PPO/GRPO）用于控制生成；人类标注与偏好学习；多语言跨域迁移与可解释性分析。

**📊 数据集**

数据集涵盖：Wikipedia、arXiv、Quora、PAWS、ParaBank、ParaNMT、ETPC、APTY 等；并自行构建了改写类型标注、合成数据与多参考评测集。

**📈 对比分析**

与基线对比：抄袭检测模型在 Wikipedia 上达到 89.6% 准确率（人类 78.4%），arXiv 上 66.5%（人类 55.7%）；在 Quora 去重、标题生成、文本完成、摘要生成等任务相较于仅二元改写训练模型平均提升 6%–6.4%；在多任务微调中，类型条件生成显著提升 24 类任务的性能。

**⚠️ 局限性**

局限性包括：评估指标仍依赖单一参考，缺乏对所有类型的精细度量；语言覆盖有限，跨语言推广困难；内部机制解释性不足；高质量类型标注昂贵，数据稀缺；对极端或低频改写类型的泛化能力待验证。

---

## 635. When Do Multi-Agent Systems Outperform? Analysing the Learning Efficiency of Agentic Systems

**arXiv ID:** 2602.08272 | [PDF](https://arxiv.org/pdf/2602.08272v1)

**作者:** Junwei Su `[一作]` (University of Hong Kong), Chuan Wu `[通讯]` (University of Hong Kong)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

在大型语言模型任务中，系统性地对比并推导了单体强化学习（SARL）与多体强化学习（MARL）的 PAC 样本复杂度，揭示了任务分解与对齐对学习效率的影响；

**💡 创新点**

首次提供了理论阐明 MARL 在任务可独立拆分时如何获得样本复杂度优势，以及任务误对齐时的可接受阈值；

**🔧 技术方法**

基于 PAC 学习框架、Lipschitz 参数化、奖励界定与参数紧致性进行严谨推导；

**📊 数据集**

论文主要为理论分析，未使用具体数据集；若做实验则可取离线 RLHF 数据；

**📈 对比分析**

通过比较样本复杂度表达式，展示 MARL 在独立子任务时可比 SARL 快数倍，依赖子任务时优势消失；引入任务对齐因子阐释误分解的代价；

**⚠️ 局限性**

局限在于不考虑具体算法实现、假设样本 i.i.d.、未覆盖部分依赖子任务、缺乏实证验证。

---

## 636. Constraint-Aware Generative Auto-bidding via Pareto-Prioritized Regret Optimization

**arXiv ID:** 2602.08261 | [PDF](https://arxiv.org/pdf/2602.08261v1)

**作者:** Binglin Wu `[一作]` (Dalian University of Technology), Xiaoyi Zeng `[通讯]` (Alibaba International Digital Commerce Group)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了 PRO‑Bid 框架，用于在满足硬性成本效益约束（如 CPA、ROAS）的前提下，生成最优的自动竞价策略。

**💡 创新点**

创新点包括：①Constraint‑Decoupled Pareto Representation（CDPR），将成本与价值解耦为双流并按 Pareto 前沿加权重采样；②Counterfactual Regret Optimization（CRO），利用全局预测器生成逆因果优劣动作并以 regret‑weighted 回归主动提升策略。

**🔧 技术方法**

使用了 Decision Transformer 的序列生成模型、Gaussian action head、双流回报/成本表示、Pareto‑prioritized 采样、全局 outcome predictor、Regret‑Weighted Regression、离线强化学习与生成式建模技术。

**📊 数据集**

实验数据集包括公开基准 AuctionNet 与其稀疏版本 AuctionNet‑Sparse，以及在 AliExpress 广告系统上进行的在线 A/B 测试。

**📈 对比分析**

与 BCQ、CQL、IQL、DiffBid、DT、CDT、GAS、GAVE 等基线比较，PRO‑Bid 在 Value、AR、ER、Score 等多项指标上均优于基线，并在预算扩展和噪声鲁棒性上表现突出；在线 AB 测试中 GMV、点击、ROI 及约束满足率均显著提升。

**⚠️ 局限性**

局限性包括：对离线数据质量仍敏感；模型复杂度较高，推理时需要额外的预测器和计算；在极端噪声或非常动态的多约束环境下的鲁棒性和可扩展性仍有待进一步验证。

---

## 637. STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction

**arXiv ID:** 2602.08245 | [PDF](https://arxiv.org/pdf/2602.08245v1)

**作者:** Jinhao Li `[一作]` (Shanghai Jiao Tong University), Guohao Dai `[通讯]` (Infinigence-AI)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种低延迟的扩散式视觉运动控制方法，利用时空一致性预测器对扩散过程进行热启动，并加入速度感知扰动注入来防止执行停滞；

**💡 创新点**

创新点在于：①同时满足空间一致性与时间一致性的热启动预测器，显著降低采样步数；②速度感知扰动注入机制，动态调节执行激励；③对热启动引入的局部收敛性进行了理论证明；

**🔧 技术方法**

采用扩散策略与Transformer跨注意力预测器、DDIM/DPM-Solver等数值求解器、噪声注入与收敛分析技术；

**📊 数据集**

使用RoboMimic（5任务）、Push‑T、ManiSkill2（3任务）以及两项真实机器人任务（PickNPlace、StackCube）进行评估；

**📈 对比分析**

与DDPM、DDIM、DPM‑Solver++、CP、OneDP、BRIDGER、RTI‑DP、Falcon、RNR‑DP等8个先进基线对比，2步热启动即可在RoboMimic上平均提升21.6%、在真实任务上提升27.5%的成功率，同时推低推理延迟至≈20 ms，显著提高Pareto前沿；

**⚠️ 局限性**

局限性包括：对极端高维或突变状态的鲁棒性尚未充分验证；需额外训练预测器，参数成本仍高；在某些任务上仍需更多采样步以保持多模态生成能力。

---

## 638. Inverting Data Transformations via Diffusion Sampling

**arXiv ID:** 2602.08267 | [PDF](https://arxiv.org/pdf/2602.08267v1)

**作者:** Jinwoo Kim `[一作]` (KAIST), Siamak Ravanbakhsh `[通讯]` (Mila)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `ba576bd1-e51d-44e8-8077-fc943b333c93` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种基于 Lie 群扩散采样的变换反演方法 TIED，用于在测试时将未知变换的数据恢复到训练分布，从而提升预训练网络的鲁棒性。

**💡 创新点**

创新点在于：① 将贝叶斯变换后验建模为能量函数的 Boltzmann 分布；② 推导出适用于任意 Lie 群的“目标分数恒等式”，实现只需能量梯度即可估计分数；③ 设计了在 Lie 代数上进行扩散的采样器，保持在流形上操作，兼容非紧、非阿贝尔的变换组。

**🔧 技术方法**

技术包括：Lie 群与代数理论、能量基模型、分数匹配、逆向扩散 SDE、Monte‑Carlo 分数估计、自动微分和指数映射实现。

**📊 数据集**

使用的数据集主要有：MNIST（及其 affNIST、homNIST 扩展）、1D 热方程和 1D Burgers 方程的 PDE 数据（用于 DeepONet 训练与测试）。

**📈 对比分析**

与传统的梯度采样（Kinetic Langevin、LieLAC）、优化搜索（ITS、FoCal）以及专用的等变网络（affConv、homConv）对比，TIED 在 MNIST‑homography 任务中准确率从 55.48% 提升至 85.64%（F1 0.57% FID 0.71），在 PDE 任务中均能实现最小的 L2 误差，整体性能均优于所有基线。

**⚠️ 局限性**

局限性包括：① 需要能量函数（可能需要预训练或额外训练）；② 采样过程仍存在计算开销，尤其在大维 Lie 群或高分辨率图像时；③ 对能量梯度的数值不稳定性和极端变换下的收敛速度仍待进一步改进。

---

## 639. JUSTICE: Judicial Unified Synthesis Through Intermediate Conclusion Emulation for Automated Judgment Document Generation

**arXiv ID:** 2602.08305 | [PDF](https://arxiv.org/pdf/2602.08305v1)

**作者:** Binglin Wu `[一作]` (Dalian University of Technology), Xiannneg Li `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了JUSTICE框架，实现了从案情描述自动生成完整判决文书，并在流程中显式模拟了人类法官的预判步骤。

**💡 创新点**

核心创新在于把司法判决生成拆解为“搜索 → 预判 → 写作”三阶段，专门设计了RJER（检索司法要素）、ICE（中间结论模拟）和JUS（统一合成）三大模块，首次把预判过程显式纳入生成流程。

**🔧 技术方法**

技术方案包括：bi‑encoder + cross‑encoder检索法律条文，结构化检索模型SAILER检索案例；利用LLM进行结构化中间结论生成（ICE）和最终文书写作（JUS）；使用prompt模板与监督式生成优化；对检索结果进行重排与精细化。

**📊 数据集**

主要数据集：JuDGE（中文判决文书生成基准），LeCaRDv2‑Doc（OOD测试集）以及法律条文与案例库，构成检索和生成的训练与评估素材。

**📈 对比分析**

与传统的Court View Generation（C3VG、EGG）和Legal Judgment Prediction（TopJudge、NeurJudge）方法以及LLM基础的ICL、SFT、MRAG等做对比。JUSTICE在法律准确度（判决、法条引用、刑期罚金）和文本质量（METEOR、BERTScore）上均显著优于所有基线，Convicting F1提升约1–2%，整体性能达到最优。

**⚠️ 局限性**

主要局限：模型仍高度依赖检索结果，检索误差会直接影响预判质量；对法律条文和案例的覆盖范围有限；需要大量标注的中间结论数据；在超大规模法条/案例或不同法律体系下的可迁移性尚未验证。

---

## 640. Automatic Generation of Polynomial Symmetry Breaking Constraints

**arXiv ID:** 2602.08297 | [PDF](https://arxiv.org/pdf/2602.08297v1)

**作者:** Madalina Erascu `[一作]` (West University of Timisoara), Johannes Middeke `[通讯]` (Temple University)

**关键词:** `847a60d8-a755-47af-ba5d-c5236b9e3083` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出一种基于代数运算的自动化多项式对称性破坏方法，利用给定的对称群和基多项式生成形如h(Px)-h(x)≤0的非线性约束，并在近半容量0‑1箱子装载问题上进行实验验证。

**💡 创新点**

创新点在于：①首次提供了可直接生成非线性对称性破坏约束的通用公式；②不依赖传统的线性排序或多面体方法；③通过随机多项式模板与对称群置换的组合，实现了对对称群结构的符号化利用。

**🔧 技术方法**

技术手段包括：符号计算（在OCaml中实现多项式替换与生成）；整数规划求解器Gurobi 12.0.3；对称群的生成与置换采样；实验设计中的工作单位（work units）性能度量。

**📊 数据集**

数据集：人工生成的近半容量箱子装载实例族，四类规模（n≈1000–2000），每类包含4个子类，约4百万变量与4000约束，专门为实验设计而生成。

**📈 对比分析**

比较方法：将所生成的线性/二次破坏约束与基线（无破坏）以及Gurobi自带的对称性处理（Default）对比；使用工作单位作为统一度量。实验结果显示：二次破坏约束在大多数设置下均显著降低工作单位，尤其是小规模xy模板；相较于Gurobi自带处理，表现更优；线性破坏往往效果不佳或导致开销增加。

**⚠️ 局限性**

局限性包括：①随机置换生成的破坏约束常为平凡，需要改进生成策略；②仅测试了二次多项式，未扩展到三次及更高阶；③实验仅针对0‑1箱子装载问题，缺乏在其他问题域的验证；④在大规模破坏集合时，非线性约束的额外开销会导致性能波动；⑤对称群的已知子群依赖，无法处理未知对称结构。

---

## 641. MonkeyTree: Near-Minimal Congestion for Multi-tenant Training via Migration

**arXiv ID:** 2602.08296 | [PDF](https://arxiv.org/pdf/2602.08296v1)

**作者:** Anton A. Zabreyko `[一作]` (Massachusetts Institute of Technology), Manya Ghobadi `[通讯]` (Massachusetts Institute of Technology)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种基于作业迁移的碎片化去除系统，利用GPU训练任务的稀疏环形通信特性在多租户GPU集群中实现近乎无拥塞的网络传输。

**💡 创新点**

创新点在于：1）将网络拥塞根源定位为作业碎片化而非网络层；2）证明任何GPU集群都可达至每个ToR最多两条跨机架流的拥塞自由状态；3）将碎片化约束与迁移最小化建模为整数线性规划，并在迁移数量极小的情况下快速求解；4）提出Perfect routing算法在碎片化受限时可保证路径隔离。

**🔧 技术方法**

核心技术包括：整数线性规划求解器、基于GPUDirect RDMA的内存级别检查点-恢复迁移、PyTorch分布式检查点扩展、Perfect routing（边着色求解）、仿真器（Rust实现）和五机测试平台。

**📊 数据集**

实验使用的模型数据集包括GPT‑3、GPT‑OSS、Llama‑2、Llama‑3等大模型的单机/多机训练任务，采用对应的TP/DP/PP混合并行化配置。

**📈 对比分析**

与ECMP、Crux、SGLB、全二叉宽带+分片等基线相比，系统在1,024 GPU 4:1过载场景下平均作业完成时间提升14%，p99延迟比最优包喷射低5%；在2,048 GPU 16:1过载场景下p99延迟仅5%高于理想。迁移平均耗时9.02 s，ILP求解平均<1 s。

**⚠️ 局限性**

限制包括：1）仅保证数据并行（DP/FSDP）稀疏流的拥塞自由，专家并行（EP）和上下文并行（CP）等模式不在保证范围内；2）迁移仍需10 s以上的停机窗口，对极长训练周期影响可忽略但不消除；3）在更大规模集群时需要分区管理，系统设计上需进一步验证。

---

## 642. When Does Context Help? Error Dynamics of Contextual Information in Large Language Models

**arXiv ID:** 2602.08294 | [PDF](https://arxiv.org/pdf/2602.08294v1)

**作者:** Dingzirui Wang `[一作]` (Harbin Institute of Technology), Yang Deng `[通讯]` (Singapore Management University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一套统一的理论框架，用输出误差动力学分析大型语言模型在推理时加入任意上下文（如示例、检索知识或历史交互）对误差的影响；

**💡 创新点**

创新点在于：①引入“上下文修正向量”描述上下文对误差的贡献；②推导误差下降的几何条件（方向与范数约束）及其上界；③将结论推广到多上下文和多层Transformer；

**🔧 技术方法**

使用Transformer结构的数学分析（注意力、MLP、残差）、梯度与Jacobian理论、余弦角度与范数约束、Lipschitz常数分析以及实验中的上下文选择策略；

**📊 数据集**

实验覆盖三大任务（数学、推理、问答）七个公开数据集（MATH、CHAMP、TheoremQA、MMLU-Redux、GPQA、NaturalQuestions、FinQA），四款主流LLM（Llama‑3.1‑8B、DeepSeek‑R1‑Distill‑Llama‑8B、Qwen3‑8B、Ministral‑8B）；

**📈 对比分析**

通过对比无上下文基线、ICL、RAG、ME以及理论指导的上下文筛选策略，实验显示理论预测与实际高度一致；基于角度对齐和范数提升的上下文选择策略平均提升约0.6%（相对）；

**⚠️ 局限性**

局限性包括：①需要先验答案或小模型来估计角度，仍有误差；②理论主要聚焦单词级向量，未深入多token/句子级细粒度；③对模型的Lipschitz假设和梯度可微性要求较强，实际LLM在训练时可能违反；④在极大规模数据与多模态任务中的泛化仍待验证。

---

## 643. Towards CXL Resilience to CPU Failures

**arXiv ID:** 2602.08271 | [PDF](https://arxiv.org/pdf/2602.08271v1)

**作者:** Antonis Psistakis `[一作]` (University of Illinois Urbana-Champaign), Josep Torrellas `[通讯]` (University of Illinois Urbana-Champaign)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62`

**🎯 论文内容**

设计并实现了名为"CXL-CR"的可容错写回协议，在CXL 3.0以上的分布式共享内存系统中，通过硬件复制日志实现节点失效时的状态恢复。

**💡 创新点**

创新点在于：①在写入事务中嵌入复制消息，利用少量副本节点的硬件日志单元实现对节点失效的快速恢复；②采用逻辑时间戳确保复制日志按程序顺序排列；③提供三种可重叠的复制协议变体，最优者在写回基础上仅产生30%延迟；④通过最小化CXL链路层修改实现失效检测与恢复触发。

**🔧 技术方法**

技术包括：CXL Transaction Layer增强（REPL/REPL_ACK/VAL消息）、硬件日志单元（SRAM+DRAM日志缓冲）、逻辑时间戳、日志压缩（gzip 5.8x）、软件驱动的恢复协议（配置管理器、目录控制器、日志遍历器）以及在CXL Switch中扩展Viral_Status位。

**📊 数据集**

评估使用16个计算节点和16个内存节点的模拟环境，采用PARSEC、SPLASH‑2和YCSB（500K条1KB记录）的工作负载，全部多线程执行64个线程。

**📈 对比分析**

与基础写回（WB）以及写穿透（WT）等方案对比，CXL-CR在相同环境下仅产生约30%的性能下降；相比WT的7.6×慢速，CXL-CR显著提升；实验表明日志传输对带宽影响极小，整体性能主要受复制消息影响，适用于大多数工作负载。

**⚠️ 局限性**

局限性包括：仅支持失败停止模型，无法处理拜占庭错误；复制因子固定为3，无法动态调整；恢复过程涉及软件驱动的全局暂停与重启，可能对实时性要求高的应用产生影响；对极低CXL链路带宽时仍可能出现拥塞。

---

## 644. Structural transparency of societal AI alignment through Institutional Logics

**arXiv ID:** 2602.08246 | [PDF](https://arxiv.org/pdf/2602.08246v1)

**作者:** Atrisha Sarkar `[一作]` (Western University), Isam Faik `[通讯]` (Ivey Business School)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f`

**🎯 论文内容**

提出并构建了结构透明度框架，用以分析组织与制度层面对生成式 AI 对齐决策及其社会后果的影响。

**💡 创新点**

创新点在于将制度逻辑理论引入对齐治理的透明化，系统化了五个分析组件（识别主次逻辑、逻辑关系、外部/内部干扰、结构风险与社会技术危害），并将逻辑映射至结构风险与危害，弥补了现有信息透明框架对制度与组织层面关注的不足。

**🔧 技术方法**

采用制度逻辑理论（Institutional Logics）与多方法分析手段，包括模式匹配、归纳/演绎推理、自然语言处理词频计数、案例访谈与观察等。

**📊 数据集**

未使用具体数据集，而是在概念层面提供了一个假设案例（高校 LLM 辅导系统）以演示框架的应用。

**📈 对比分析**

该研究为概念性框架，不涉及可量化对比或性能评估；通过案例演示展示框架的可操作性，而非实验验证。

**⚠️ 局限性**

局限性包括：仅有示例性演示，缺乏实证案例验证；框架聚焦组织决策，未深入政策层面；对个体决策者的微观推理与偏好未充分捕捉；需进一步研究如何在大规模实践中落地与评估。

---

## 645. On convexity and efficiency in semantic systems

**arXiv ID:** 2602.08238 | [PDF](https://arxiv.org/pdf/2602.08238v1)

**作者:** Nathaniel Imel `[一作]` (New York University), Noga Zaslavasky `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了人类语义类别系统中凸性（convexity）和通信效率（efficiency）两种结构特征的关系，特别聚焦在颜色命名领域。

**💡 创新点**

证明凸性与效率并不互相蕴含：存在凸而低效的系统，也存在非凸而高效的系统，并表明信息瓶颈（IB）最优系统大多凸，从而解释凸性在颜色命名中的出现；同时证明效率是区分真实与旋转变体颜色命名系统的更强预测因子。

**🔧 技术方法**

使用信息瓶颈框架、凸性度量（通过集合与其凸包大小比值）、Voronoi 采样与聚类、逻辑回归分类器、ROC‑AUC、似然比检验等技术。

**📊 数据集**

主要数据来源是 World Color Survey（WCS）110 种语言的颜色命名数据，以及通过 Voronoi 分区生成的数十万套人工凸色彩类别系统。

**📈 对比分析**

通过对比真实系统与其 39 个色调旋转变体，计算效率优势与凸性一致性优势；效率优势显著高于凸性优势（93% vs 13%），ROC‑AUC 在 5‑折交叉验证中效率分类器几乎达到上限，凸性分类器表现远逊；联合模型相较于仅用凸性模型，损失更小，说明凸性贡献极小。

**⚠️ 局限性**

局限性在于仅针对颜色命名实验，可能无法直接推广至其他语义域；凸性度量的离散化与噪声影响；信息瓶颈模型对通信需求分布的假设敏感；计算上需要大量仿真与搜索，难以实时应用。

---

## 646. When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning

**arXiv ID:** 2602.08236 | [PDF](https://arxiv.org/pdf/2602.08236v1)

**作者:** Shoubin Yu `[一作]` (University of North Carolina), Mohit Bansal `[通讯]` (University of North Carolina)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了Adaptive Visual Imagination Control框架，能够在推理时自适应地决定是否调用世界模型并规划需要的视角，从而提升视觉空间推理效率和准确性。

**💡 创新点**

在推理时引入门控策略和动作规划，结合自一致性测试时间缩放，实现实例级可控的视觉想象，而非传统的固定或全枚举方式。

**🔧 技术方法**

使用多模态大型语言模型（如GPT‑4o、GPT‑4.1等）作为推理器，配合预训练的视觉世界模型（Stable Virtual Camera）生成视角变换，采用策略网络进行需求判断和动作规划，并通过自一致性投票和轨迹验证选择最优视图。

**📊 数据集**

在视觉空间推理基准SAT‑Real、MMSI‑Bench以及室内导航基准Room‑to‑Room (R2R) 进行评测。

**📈 对比分析**

与无想象基线、MindJourney等全枚举想象方法对比，Adaptive框架在SAT‑Real上平均准确率从74.0%提升至79.3%，与MindJourney同等或更高的同时将世界模型调用次数降至0.73，Token消耗下降约90%，在MMSI‑Bench和R2R也取得相对优势。

**⚠️ 局限性**

适用范围受限于已有的高质量世界模型和有限的动作空间，对极端动态场景或高度不确定的物理交互仍表现不佳，且门控策略仍依赖手工设计的阈值和投票机制。

---

## 647. When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents

**arXiv ID:** 2602.08235 | [PDF](https://arxiv.org/pdf/2602.08235v1)

**作者:** Jaylen Jones `[一作]` (Ohio State University), Huan Sun `[通讯]` (Ohio State University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `9cc9baba-5356-466d-81ff-d80028d90279` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了用于识别和自动诱发计算机使用代理（CUA）在无害输入下出现的意外行为的概念框架和完整的自动化诱发管线（AutoElicit），并系统地展示了在真实OSWorld任务中能大规模挖掘严重安全风险的可行性。

**💡 创新点**

创新点包括①构建了统一的四维意外行为定义（偏离用户意图、由无害输入产生、违反安全约束、非一般错误），②设计了两阶段代理式诱发框架（上下文感知种子生成 + 执行引导细化），③通过多轮反馈迭代提升诱发成功率，并提供可验证的失败/成功历史；这些都弥补了先前仅依赖人工构造或工具调用的安全评估方法。

**🔧 技术方法**

技术实现主要包括：基于LLM的种子生成与评估（使用o4-mini、GPT‑5等模型）、视觉语言模型（VLM）对执行轨迹进行总结与评估、执行引导细化的双重反馈循环（外环执行反馈、内环质量评估）、约束检测与迭代改进、以及对结果进行聚类的Meta‑Analysis。

**📊 数据集**

数据集方面使用了公开的OSWorld基准（包含OS与Multi‑Apps两类任务），构建了361个种子扰动样本；此外发布了117个人工验证的成功扰动与132条包含意外行为的执行轨迹，供社区复现与进一步研究。

**📈 对比分析**

在对Claude 4.5 Haiku与Opus的实验中，AutoElicit在OS域的诱发成功率最高达72.5%，在Multi‑Apps域达到60.8%；在Open‑Source与Closed‑Source不同代理的迁移实验中，诱发成功率维持在35%–54%之间，表明其迁移性和普适性较好。相比传统人工案例或工具调用测试，AutoElicit显著提升了规模与效率。

**⚠️ 局限性**

局限性主要包括：仍需人工参与进行最终验证与评估；诱发过程受限于可执行的OSWorld任务，难以覆盖所有真实场景；对模型的依赖使得结果受LLM性能和策略的影响；以及在极端安全环境下可能无法完全避免误报或漏报。

---

## 648. The Vibe-Automation of Automation: A Proactive Education Framework for Computer Science in the Age of Generative AI

**arXiv ID:** 2602.08295 | [PDF](https://arxiv.org/pdf/2602.08295v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 649. G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design

**arXiv ID:** 2602.08253 | [PDF](https://arxiv.org/pdf/2602.08253v1)

**作者:** Baoyun Zhao `[一作]` (Northeastern University), Liang Zeng `[通讯]` (Tsinghua University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 G-LNS，一种利用大语言模型协同进化破坏与修复算子以进行大邻域搜索的自动启发式设计框架。

**💡 创新点**

引入协同评估与协同交叉机制，使破坏与修复算子能自适应配对，突破传统只调参或构造规则的局限。

**🔧 技术方法**

结合大语言模型（DeepSeek‑V3.2）、演化算法、适应性 LNS 评价、同质与异质交叉、强化学习式权重更新等技术。

**📊 数据集**

在随机生成的 TSP、CVRP、OVRP 实例以及 TSPLib、CVRPLib 标准基准上进行实验。

**📈 对比分析**

与手工启发式、POMO、FunSearch、EoH、MCTS‑AHD、Evo‑MCTS、OR‑Tools 等基线比较，G‑LNS 在 TSP、CVRP 上实现了接近最优的误差，并在时间成本上比传统求解器快 10‑100 倍。

**⚠️ 局限性**

目前仅针对单目标路径规划任务，缺乏对多目标、约束更复杂或大规模实例的理论分析与扩展。

---

## 650. TextResNet: Decoupling and Routing Optimization Signals in Compound AI Systems via Deep Residual Tuning

**arXiv ID:** 2602.08306 | [PDF](https://arxiv.org/pdf/2602.08306v1)

**作者:** Suizhi Huang `[一作]` (Nanyang Technological University), Xiaoxiao Li `[通讯]` (University of British Columbia)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种名为 TextResNet 的框架，用于解决复合 AI 系统（Compound AI System）中的语义耦合导致的梯度传播失效问题，提升多步推理与工具调用任务的优化效果。

**💡 创新点**

创新点包括：① 在前向传播中引入可加语义增量（Additive Semantic Deltas）构建“身份高速公路”；② 在反向传播中设计语义投影器（Semantic Projector）实现梯度分解，并通过因果路由（Causal Routing）精确分离局部与上游错误；③ 采用密度感知优化调度（Density‑Aware Scheduling）动态分配优化资源；④ 将残差学习与几何约束思想迁移到离散文本空间，解决语义耦合与归因模糊。

**🔧 技术方法**

核心技术包括：深度残差学习原理、语义梯度分解与投影、因果错误归因、结构化梯度路由、Boltzmann 采样调度、文本级梯度优化（Textual Gradient）等。

**📊 数据集**

实验使用四大复合 AI 评测集：HotpotQA、BigCodeBench、PubMedQA 与 STARK‑PRIME，涵盖多步检索、代码生成、医学问答与半结构化检索等多种任务。

**📈 对比分析**

与基准方法（CoT、HBC、DSPy、TextGrad、TextGrad+Sum）进行对比，TextResNet 在 HotpotQA 上提升 21.37 F1、BigCodeBench 上达到 37.86% 通过率、PubMedQA 与 STARK‑PRIME 上也保持领先，整体性能明显优于所有对照实验。

**⚠️ 局限性**

局限性包括：依赖可写文本接口，可能对极长链或非文本输出的系统效果有限；投影器与路由仍需精细调参；在资源受限环境下的推理成本未做全面评估。

---

## 651. Benchmarking Autonomous Vehicles: A Driver Foundation Model Framework

**arXiv ID:** 2602.08298 | [PDF](https://arxiv.org/pdf/2602.08298v1)

**作者:** Yuxin Zhang `[一作]` (Jilin University), Hubert P. H. Shum `[通讯]` (Durham University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `9cc9baba-5356-466d-81ff-d80028d90279` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了驾驶员基础模型（DFM）框架，用于全面基准化自动驾驶车辆在安全、舒适、通勤效率和能耗等方面的性能。

**💡 创新点**

创新点在于：①通过大规模无人机拍摄获得全景、无遮挡的多模态交通数据；②设计“五问”式多任务解码器（How/What/Where/When/Why）实现对人类驾驶行为的量化、分布化和可解释化；③将语言、轨迹、属性、环境四个子编码器通过跨注意力或共享潜在空间融合。

**🔧 技术方法**

采用多模态编码器（语言编码器、轨迹编码器、属性编码器、环境编码器）与并行多任务解码器，结合大语言模型（如GPT）和生成模型技术进行行为模拟与分布预测。

**📊 数据集**

使用基于无人机摄像头的轨迹数据集，总计约750万条轨迹，覆盖住宅区、城市干道、交叉口、快速路、环岛、施工区、恶劣天气等多种城市运营设计域（ODD）。

**📈 对比分析**

通过与现有安全基准（如CCDM、RS2S）对比，DFM提供概率分布、参考轨迹、时空归因等多维评估指标；在安全、舒适、效率和能耗四个维度上实现更细粒度、可解释的评估，证明其能覆盖多代理交互情景并为AV验证提供客观基线。

**⚠️ 局限性**

局限性包括：①对极端稀有场景的覆盖仍不充分；②模型在实时部署时的计算成本较高；③在非城市ODD（如高速公路、乡村道路）上的适用性和验证尚未完成。

---

## 652. Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis

**arXiv ID:** 2602.08276 | [PDF](https://arxiv.org/pdf/2602.08276v1)

**作者:** Haoyu Jia `[一作]` (University of Tokyo), Kei Okada `[通讯]` (University of Tokyo)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a4b10f5d-130b-4e77-9367-6469ec621899` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种基于结构化上下文的正式模型（Structural Context Model, SCM），并在此基础上开发了语义动力学分析（Semantic Dynamics Analysis, SDA）方法，用以从现有LLM代理的prompt中提取可复用的上下文模式，随后构建了声明式实现框架和可持续的代理工程工作流，最终在猴子-香蕉（Monkey–Banana）动态变体基准上验证了该框架的有效性。

**💡 创新点**

① 通过 SCM 将 LLM 代理抽象为上下文模式的组合，消除了实现细节的耦合；② 通过 SDA 提供可量化的语义指标（ΔSemantics、Global Drift、Global ΔDrift），实现对上下文结构的自动分割与模式抽取；③ 将模式抽取与代理设计、评估闭环起来，形成一种可持续的工程流程；④ 在实验中证明新设计的代理相较传统 ReAct、MLDT 等方法成功率提升多达 32%。

**🔧 技术方法**

正式建模（类似自动机理论的上下文模式语言）；语义动力学分析（使用词嵌入、余弦距离、ΔSemantics 等指标）；声明式 UI 风格的代理实现框架；基于猴子-香蕉的仿真环境；实验评估指标包括成功率、平均步数、时间、token、Time‑to‑Success、Token‑to‑Success。

**📊 数据集**

Monkey–Banana 变体基准（15 场景，5 类动态因素：Classic、Dual Bananas、Shortsighted Monkey、Over‑weight Monkey、Comprehensive，每类 3 难度等级）。

**📈 对比分析**

通过在 15 个场景上对 6 种代理（Basic、ReAct、MLDT、On‑Demand Reasoning、On‑Demand Reasoning+Notes、On‑Demand Reasoning+Notes+Planning）进行 100 次独立试验，使用成功率、平均步数、时间、token、Time‑to‑Success、Token‑to‑Success 等多维度指标进行比较。结果显示，作者提出的 PlanORN 代理在大多数困难场景中成功率最高（最高 100%），且在 Time‑to‑Success、Token‑to‑Success 上优于其他方法，整体性能提升约 32%。

**⚠️ 局限性**

① SDA 的自动化程度仍有限，需人工干预；② 当前 SCM 对模式间交互的理论支持（命题、定理）尚不完整；③ 仅在单一领域（猴子‑香蕉）验证，缺乏跨域的普适性实验；④ 对大型模型内在状态的依赖导致对不同 LLM 版本的适配性不明确；⑤ 语义指标基于词嵌入，受嵌入模型的稳定性与偏差影响。

---

## 653. Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI

**arXiv ID:** 2602.08268 | [PDF](https://arxiv.org/pdf/2602.08268v1)

**作者:** Akinori Maeda `[一作]` (Research Institute of Advanced Technology, SoftBank Corporation), Kohei Watanabe `[通讯]` (WebDINO Japan)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `9cc9baba-5356-466d-81ff-d80028d90279` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了基于浏览器的多粒度个人数据管理架构Puda，以实现用户主权的个性化AI服务。

**💡 创新点**

创新点在于将个人数据划分为详细浏览历史、提取关键词和预定义类别子集三层粒度，并提供用户可控的隐私级别，同时通过LLM预处理实现跨服务数据聚合。

**🔧 技术方法**

采用浏览器插件记录、LLM（Gemma 3 4B、GPT‑5 nano）进行摘要与关键词抽取、A2A协议实现代理通信、OAuth 2.0/OIDC实现授权。

**📊 数据集**

使用20个虚拟日本用户的浏览记录（50–110条）和8名真实参与者进行模拟旅行规划任务的数据集。

**📈 对比分析**

通过LLM‑as‑a‑Judge评估个性化性能，结果显示预定义类别子集（Level 3）在隐私保护下可获得97.2%相当于详细浏览历史的性能，同时成本和延迟低；关键词层次在新颖性上甚至优于浏览历史。

**⚠️ 局限性**

局限包括：仅支持浏览器内活动，未覆盖移动端或系统级操作；使用云端GPT‑5 nano导致无法完全在端侧运行；模型选择可能因未来SLM进步而变化；评估仅针对旅行规划任务，缺乏跨任务验证。

---

## 654. HEAL: Online Incremental Recovery for Leaderless Distributed Systems Across Persistency Models

**arXiv ID:** 2602.08257 | [PDF](https://arxiv.org/pdf/2602.08257v1)

**作者:** Antonis Psistakis `[一作]` (University of Illinois Urbana-Champaign), Josep Torrellas `[通讯]` (University of Illinois Urbana-Champaign)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种针对无领导分布式系统的在线增量恢复方案，能够在节点故障后快速恢复。

**💡 创新点**

创新点在于结合低开销的Proactive恢复、无冗余更新以及恢复期间节点仍参与写协议，显著降低恢复延迟和吞吐下降。

**🔧 技术方法**

使用了基于MINOS的无领导一致性协议、持久化内存(NVM)日志、RPC通信以及TLA+模型验证。

**📊 数据集**

实验数据集包括TAOBench社交图数据库驱动（MySQL、CockroachDB、YugabyteDB、Cloud Spanner）和YCSB哈希表工作负载。

**📈 对比分析**

与基线、传统非增量恢复以及ZooKeeper进行比较，恢复延迟平均从360秒降至120毫秒，吞吐下降从16.2%降至8.7%，相较ZooKeeper恢复延迟降低20.7倍，吞吐下降减少62.4%。

**⚠️ 局限性**

局限在于只能支持单一或少量并发故障、依赖节点持久状态完整、对网络分区与Byzantine故障不处理。

---

## 655. Trust-Based Incentive Mechanisms in Semi-Decentralized Federated Learning Systems

**arXiv ID:** 2602.08290 | [PDF](https://arxiv.org/pdf/2602.08290v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 656. Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs

**arXiv ID:** 2602.08241 | [PDF](https://arxiv.org/pdf/2602.08241v1)

**作者:** Siqu Ou `[一作]` (TeleAI), Xuelong Li `[通讯]` (TeleAI)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出SAYO框架，利用强化学习在视觉多模态LLM中引入区域视觉注意力奖励，使模型在推理过程中能够更精准地聚焦目标视觉区域。

**💡 创新点**

创新点：1）通过高熵token筛选，仅对信息量大的关键步骤给与注意力奖励；2）将视觉注意力奖励与格式奖励结合，实现信用分配；3）在RL（GRPO）中引入区域注意力奖励，提升模型在长链推理中的视觉稳定性。

**🔧 技术方法**

技术：视觉多模态LLM（Qwen3‑VL、InternVL3.5‑8B）+ GRPO强化学习框架 + 熵筛选 + 区域视觉注意力奖励函数。

**📊 数据集**

数据集：训练使用带有物体/区域标注的视觉推理数据（GQA、ReFocus、ChartQA 等）；评测使用 M3CoT、V*Bench、MMStar、MME‑RealWorld‑Lite、ChartQA、CharXiv、AI2D、We‑Math、MathVision 等多领域基准。

**📈 对比分析**

比较方法：与基础模型、各类开源模型（Kimi‑VL‑16B、OpenVLThinker‑7B、Semantic‑back‑7B 等）以及部分闭源大模型（GPT‑4o、Gemini 2.5 pro）进行同一基准测试。结果显示，SAYO 在视觉推理、结构图像和一般推理任务上均实现显著提升，部分指标甚至超过闭源模型。

**⚠️ 局限性**

限制：① 需要依赖手工标注的视觉边界信息；② RL 训练成本高、收敛稳定性受奖励设计影响；③ 在极端高分辨率或超大场景下的鲁棒性待进一步验证；④ 奖励机制在不同任务领域的通用性仍有提升空间。

---

## 657. Document Reconstruction Unlocks Scalable Long-Context RLVR

**arXiv ID:** 2602.08237 | [PDF](https://arxiv.org/pdf/2602.08237v1)

**作者:** Yao Xiao `[一作]` (Infinity Lab, MiroMind AI), Lidong Bing `[通讯]` (Infinity Lab, MiroMind AI)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种无监督的 RLVR 框架，通过在长文档中随机掩盖若干段落并让 LLM 重构其顺序，从而提升模型的长上下文理解能力。

**💡 创新点**

创新点在于：①直接利用原始文档的结构信息生成可验证奖励，完全摆脱人工标注或教师模型；②将重构任务建模为序列决策问题，使用 Group Relative Policy Optimization 进行训练；③通过可调 K（掩盖段落数）实现难度递增的 curriculum，促进模型逐步掌握全局结构。

**🔧 技术方法**

使用的技术包括：Reinforcement Learning with Verifiable Rewards、Group Relative Policy Optimization、文档重构任务设计、可调 K 的难度控制与 curriculum learning。

**📊 数据集**

数据来源：从书籍、arXiv 论文和代码三大领域挑选最长 8000 篇、3000 篇和 3000 篇文档（共 14000 篇）用于训练；验证集 500 篇；评测基准为 RULER（合成多跳推理）和 LongBench v2（现实多选 QA）。

**📈 对比分析**

与原始 LLaMA‑3.1‑8B‑Instruct 与 Qwen2.5‑7B‑Instruct‑1M 基线相比，在 RULER 上实现显著提升，在 LongBench v2 上亦取得可观改善；通过奖励设计、K 分布、文档长度、数据规模等维度的消融实验验证了方法的稳健性和可扩展性。

**⚠️ 局限性**

局限性：依赖足够长且结构良好的文档，对文档质量和长度敏感；不同模型架构对效果差异明显；在更大规模或不同模型尺寸下的表现尚未评估；数据规模虽正向影响性能，但尚无明确上限。

---

## 658. Informative Object-centric Next Best View for Object-aware 3D Gaussian Splatting in Cluttered Scenes

**arXiv ID:** 2602.08266 | [PDF](https://arxiv.org/pdf/2602.08266v1)

**作者:** Seunghoon Jeong `[一作]` (Seoul National University), Ayoung Kim `[通讯]` (Seoul National University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `e0540dec-d77f-42db-94ae-d039248f6393` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了基于实例感知的 3D 高斯喷涂（3DGS）与置信度加权的下一最佳视角（NBV）策略，在混乱场景中实现面向目标对象的高质量重建与抓取。

**💡 创新点**

创新点在于将对象实例掩码压缩为 one‑hot 向量融入 3DGS，并用其置信度权重修改信息增益，平衡探索与利用；同时支持全场景与对象中心化的 NBV，显著提升深度误差和抓取可靠性。

**🔧 技术方法**

使用的技术包括 3D Gaussian Splatting、基于 Jacobian 的置信度/信息增益估计、贝叶斯光线方法、Mask supervision（SAM、CLIP、GroundedSAM）、深度与 RGB 联合优化以及对象中心化的 NBV 规划。

**📊 数据集**

使用的数据集包括合成 BlenderProc 场景、GraspNet 训练集中的 10 个场景，以及 4 个机器人捕获的 BOP 对象场景；掩码采用 GroundedSAM/CLIP 生成的伪真实标签。

**📈 对比分析**

与随机采样、螺旋轨迹、最远点采样、FisherRF、POp‑GS 等基线比较，实验表明在全场景重建中 depth MAE 下降至合成数据上 77% 以上、真实数据 34% 以上；对象中心 NBV 在目标对象上额外降低约 25% 深度误差，并在真实抓取任务中通过多视角提升抓取成功率。

**⚠️ 局限性**

局限性在于对对象掩码的依赖，掩码误差会影响重建与 NBV 决策；当前视角采样仅基于固定球面，未实现主动视角生成；缺乏明确的终止准则与实时在线掩码细化机制。

---

## 659. Knowledge Augmented Entity and Relation Extraction for Legal Documents with Hypergraph Neural Network

**arXiv ID:** 2602.08289 | [PDF](https://arxiv.org/pdf/2602.08289v1)

**作者:** Binglin Wu `[一作]` (Dalian University of Technology), Xianneng Li `[通讯]` (Dalian University of Technology)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `3f18e8e3-0266-457c-8567-9039b6d2394d` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了基于知识增强的超图神经网络（Legal-KAHRE）用于药物犯罪判决文件的实体与关系抽取。

**💡 创新点**

①采用邻域打包+双线性机制的候选跨度生成器；②构建药物词典并通过多头注意力融入编码；③为司法特殊情形设计sor、jc、cp三类超边的超图结构，实现高阶推理。

**🔧 技术方法**

使用中文BERT/ELECTRA预训练模型、双线性跨度判别、法律词典增强、超图神经网络（HGNN）进行实体与关系联合抽取。

**📊 数据集**

CAIL 2022 信息抽取竞赛药物犯罪判决文档数据集（1,763份）。

**📈 对比分析**

与UniRE、PFN、CARE、PURE、PL-Marker等强基线在同一预训练模型下对比，Legal-KAHRE在实体F1和关系F1均取得最高分，分别提升约2.1和0.9个百分点。

**⚠️ 局限性**

仅针对药物犯罪领域，缺乏跨司法领域泛化能力；对长文本和稀缺实体仍有限；超图结构需人工设计，适用性受限。

---

## 660. Noise Stability of Transformer Models

**arXiv ID:** 2602.08287 | [PDF](https://arxiv.org/pdf/2602.08287v1)

**作者:** Themistoklis Haris `[一作]` (Boston University), Yuichi Yoshida `[通讯]` (National Institute of Informatics)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了噪声稳定性（noise stability）作为 Transformer 简单性偏置的度量，并基于此设计了噪声稳定性正则化方法，用以加速模型的学习与泛化；

**💡 创新点**

创新点在于首次将噪声稳定性引入深度学习，给出单层注意力与 ReLU MLP 的理论分析，提出协方差区间传播技术来处理多层网络，并证明该正则化能显著触发并加速“grokking”现象；

**🔧 技术方法**

核心技术包括 Ornstein‑Uhlenbeck 半群、Hermite 级数、谱集中理论、协方差区间传播、噪声稳定性正则化以及对 Transformer 结构的精细分析；

**📊 数据集**

实验使用了合成数据（噪声稀疏奇偶性、模加法）以及真实语料库 WikiText‑2‑v1 的下一个词预测任务；

**📈 对比分析**

与传统平均灵敏度度量相比，噪声稳定性给出的谱集中界限更精确；在合成任务上，正则化将训练步骤减少约35‑75%，在 WikiText‑2 上迭代次数降低约75%；

**⚠️ 局限性**

局限性包括对多层传播的理论推导仍基于简化假设，正则化机制尚未完全阐明，且在包含残差、层归一化等完整 Transformer 结构时的效果与理论需要进一步验证。

---

## 661. New Skills or Sharper Primitives? A Probabilistic Perspective on the Emergence of Reasoning in RLVR

**arXiv ID:** 2602.08281 | [PDF](https://arxiv.org/pdf/2602.08281v1)

**作者:** Zhilin Wang `[一作]` (University of Science and Technology of China), Yu Cheng `[通讯]` (Chinese University of Hong Kong)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究 Reinforcement Learning with Verifiable Rewards（RLVR）如何通过提升原子操作的成功概率，使大语言模型在多步推理任务中出现新的能力，并提供了实例级可解性的概率框架来解释这一现象。

**💡 创新点**

创新点在于将能力定义为每个实例的可解概率，提出乘法障碍（Multiplicative Barrier）理论和可行/无解集阈值，证明 RLVR 的能力提升是原子概率的迭代放大导致的相位转变，而非直接学习复杂逻辑。

**🔧 技术方法**

技术上先对 Pass@k 指标进行理论推导，构造概率乘积模型；随后使用 Algebrarium 框架对 Llama、Qwen、Gemma 进行原子级训练并采用 Group Relative Policy Optimization（GRPO）进行 RLVR 优化，并通过 Pearson 相关系数、Pass@k 曲线等统计方法进行评估。

**📊 数据集**

实验数据集为自生成的 Algebrarium 代数推理集，包含四类代数系统（无穷/有限、可交换/不可交换），训练集仅包含 1 步算子，测试集按推理深度 2–5 级均衡划分，每级 200 条样本，共 800 条。

**📈 对比分析**

与基线模型比较时采用 Pass@k、平均成功率、Pearson 相关性等指标，结果显示 RLVR 将 22.6% 的原本无解任务提升至可行集，复合任务最终成功率升至约 0.60，且 Pearson 相关系数在 0.69–0.96 之间，表明原子成功率的提升直接驱动整体能力增强。

**⚠️ 局限性**

主要限制是 RLVR 在提升整体性能的同时会导致某些具体技能的衰退（能力侵蚀），不同模型对这种牺牲的程度不同；此外实验仅在符号推理环境进行，缺乏对更广泛真实世界任务的验证。

---

## 662. PISCO: Precise Video Instance Insertion with Sparse Control

**arXiv ID:** 2602.08277 | [PDF](https://arxiv.org/pdf/2602.08277v1)

**作者:** Xiangbo Gao `[一作]` (Texas A&M University), Zhengzhong Tu `[通讯]` (Texas A&M University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种基于视频扩散模型（PISCO）的精确视频实例插入框架，支持在任意稀疏关键帧上进行实例插入，保持原始背景的运动与物理一致性。

**💡 创新点**

核心创新点包括：① Variable‑Information Guidance（VIG）动态上下文丢弃，使模型能在稀疏监督下自适应传播实例信息；② Distribution‑Preserving Temporal Masking（DPTM）先像素级完成缺失帧再进行token‑级掩码，消除预训练VAE的分布偏移；③ 多通道上下文适配器（RGB、遮罩、深度、可用性信号）和几何感知条件，实现物理一致的遮挡与光照；④ 训练时的遮挡补全与重新照明增强，提升几何与外观鲁棒性。

**🔧 技术方法**

技术细节包括：Wan视频扩散骨干 + VACE上下文适配器，使用LoRA微调，采用可用性掩码与深度信息注入；DPTM中像素级最近邻插值 + token‑级掩码；使用可视化遮罩的可用性通道对齐；训练分阶段从适配器热身到完整微调再到高分辨率、长时序扩展；评估采用FVD、LPIPS、PSNR、SSIM和VBench。

**📊 数据集**

训练数据来自ROSE、VPData、MOSE、DAVIS共约1.66万条视频；通过侧效应感知实例去除模型生成背景对齐的视频；深度使用Depth Anything V3；评测基准为自构的 BURST‑Bench，挑选100段真实场景视频，并人工校正实例掩码。

**📈 对比分析**

与基线对比：① Agentic（图像编辑+I2V）① Video Inpainting（CoCoCo、VideoPainter）② Reference‑guided V2V（VACE、UniVideo）。在稀疏控制（首帧/首末帧）下，PISCO（14B）在FVD、LPIPS、PSNR、SSIM等指标上均明显优于所有基线，并在VBench的主观评估（背景一致性、主体一致性、画质、运动平滑）中名列前茅；添加更多稀疏控制帧（五帧）还能持续提升性能，验证可扩展性。

**⚠️ 局限性**

局限性包括：① 对深度估计和实例掩码的依赖，若输入质量差易导致效果退化；② 训练与推理需要大规模算力（H100 GPU），模型规模较大；③ 目前主要针对单实例插入，对多实例或极端运动的支持尚待进一步验证；④ 在极端光照或遮挡条件下仍可能出现阴影/反射不自然。

---

## 663. Specification Vibing for Automated Program Repair

**arXiv ID:** 2602.08263 | [PDF](https://arxiv.org/pdf/2602.08263v1)

**作者:** Taohong Zhu `[一作]` (University of Manchester), Youcheng Sun `[通讯]` (Mohamed bin Zayed University of Artificial Intelligence)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种基于行为规范的自动程序修复方法，先将有缺陷的代码转换为结构化的行为规范，修正规范中的误差，再从修正后的规范生成修复代码；通过交互式的验证反馈不断迭代优化规范，最终输出符合开发者意图的补丁。

**💡 创新点**

创新点主要包括：
1) 把修复焦点从代码直接改写转移到行为规范修正，减少模型产生错误补丁的风险；
2) 采用三阶段框架（变换‑修复‑生成）与结构化规范模板，使LLM在生成补丁前先对程序意图进行系统性推理；
3) 引入可选的“推理组件”，在默认修复失败时动态调用工具与历史修复例子，提升在复杂情形下的成功率；
4) 通过对验证失败信息的循环反馈，实现在小的补丁空间内实现高精度修复。

**🔧 技术方法**

核心技术：
- 大型语言模型（GPT‑4o、GPT‑4、GPT‑3.5、DeepSeek‑Coder）与链式思维提示；
- 结构化行为规范模板与零样本提示工程；
- 推理与行动框架（agent）结合工具库（变量、方法、类分析等）与相似修复案例检索；
- 交互式验证循环：将失败测试的输入输出回馈给修复阶段；
- LangChain 框架实现流程自动化。

**📊 数据集**

使用的数据集：
- Defects4J v1.2（391 bug）和 v2.0（438 bug）四种修复场景；
- RWB v1.0 与 v2.0（各 27 bug）作为后训练期的真实世界测试。

**📈 对比分析**

与多种基线（包括 ReinFix、ChatRepair、ThinkRepair、AlphaRepair 等传统与 LLM 基础工具）在同一 LLM 环境下比较；实验表明在 Defects4J v1.2 及 v2.0 上，VibeRepair（miniR_GPT4o）分别修复 174/223、178/223 个可行补丁，分别比 ReinFix 提高 28 和 33 个正确补丁（≈19% 与 23% 的提升），且使用的补丁空间仅为 5×3，远小于基线的数百或数千次采样；在 RWB 上也能保持竞争性或超越基线。

**⚠️ 局限性**

局限性与挑战：
- 仍需依赖高质量 LLM 与训练数据，模型能力不足时修复效果下降；
- 推理组件虽然提升效果，但会显著增加计算成本与耗时，且在始终开启时可能适得其反；
- 对缺乏失败测试或精确错误信息的情形（如 RWB v1.0）仍有局限；
- 规范化过程依赖模板与提示，若程序语义复杂或不易归纳为规范，仍可能产生不完整的修复；
- 需要人工验证正确补丁，存在主观性与工作量。

---

## 664. Moving Beyond Functional Connectivity: Time-Series Modeling for fMRI-Based Brain Disorder Classification

**arXiv ID:** 2602.08262 | [PDF](https://arxiv.org/pdf/2602.08262v1)

**作者:** Guoqi Yu `[一作]` (PolyU), Shujun Wang `[通讯]` (PolyU)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5a41884c-404f-4688-a89c-aa238c10fe68` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `a6cb313d-240c-4723-a372-3ba1f39b9afc`

**🎯 论文内容**

评估时序深度学习模型在fMRI脑障碍分类中的表现，并提出了基于Cycle‑Drift分解与Channel‑Independent策略的DeCI框架

**💡 创新点**

结合Cycle‑Drift分解提取周期性与漂移成分，并采用通道独立学习减少噪声传播与过拟合，显著提升了对内外ROI动态的建模能力

**🔧 技术方法**

时序模型（PatchTST、TimesNet、TimeMixer等）、1D卷积与SE网络实现分解、共享权重的通道独立块

**📊 数据集**

六个公开fMRI数据集：Mātai、TaoWu、Neurocon、PPMI、ADNI、ABIDE

**📈 对比分析**

与传统Pearson sFC、dFC及最新fMRI专用模型进行5折交叉验证，DeCI在大多数指标（Accuracy、Precision、Recall、F1、AUROC）上位居前列，平均提升数个百分点

**⚠️ 局限性**

对TR、序列长度和图谱选择敏感；通道独立策略削弱了细粒度网络互联，且在某些数据集（如PPMI）未能超过PatchTST

---

## 665. Language Predicts Identity Fusion Across Cultures and Reveals Divergent Pathways to Violence

**arXiv ID:** 2602.08252 | [PDF](https://arxiv.org/pdf/2602.08252v1)

**作者:** Devin R. Wright `[一作]` (Indiana University), F. LeRon Shults `[通讯]` (University of Agder)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并验证了一种基于认知语言学、LLM 与隐式隐喻的身份融合度量方法 CLIFS，用以预测极端行为风险；

**💡 创新点**

创新在于将隐式隐喻检测与多维融合特征（亲族化、融合接近度、双向身份重叠）结合，并通过跨文化外域验证证明其泛化能力；

**🔧 技术方法**

使用大语言模型嵌入、Fine‑tuned ModernBERT 分类器、Masked‑LM 隐喻检测以及传统 LIWC、UAI、VRI‑Fusion 等基线技术；

**📊 数据集**

数据集包括英国与新加坡 MTurk 的宗教融合问卷、两家教堂访谈记录以及包含九篇“暴力自我牺牲”与“意识形态极端”宣言的极端主义宣言库；

**📈 对比分析**

与 UAI、nUAI、VRI‑Fusion 等基线比较，CLIFS 在所有外域条件下均获得显著的 Spearman 相关（最高 0.55）和最低 MAE（1.11‑1.75），显著优于基线；

**⚠️ 局限性**

局限在于对文本长度的过滤要求、未在更大规模多语料环境中测试，以及对极端分子多样化动机的解释仍需进一步研究。

---

## 666. Aerial Manipulation with Contact-Aware Onboard Perception and Hybrid Control

**arXiv ID:** 2602.08251 | [PDF](https://arxiv.org/pdf/2602.08251v1)

**作者:** Yuanzhu Zhan `[一作]` (Pennsylvania State University), Junyi Geng `[通讯]` (Pennsylvania State University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `51c0528b-f690-4182-ae60-bb5f046c276c`

**🎯 论文内容**

实现了完全靠机载感知与控制的接触丰富空中操作系统，能够在无需外部MoCap的情况下精准定位并控制接触力。

**💡 创新点**

创新点在于：1）在视觉‑惯性里程计中加入仅在接触时激活的接触一致性因子；2）结合图像基视觉伺服与混合力动控制闭环；3）利用全致动六旋翼实现运动与力的同时控制。

**🔧 技术方法**

采用改进的VINS‑Fusion视觉‑惯性里程计、图像基视觉伺服（IBVS）、力/运动混合控制器以及六旋翼控制分配算法。

**📊 数据集**

实验使用Gazebo仿真中的圆孔插入任务和真实世界中的红色圆形墙面目标，未使用公开数据集。

**📈 对比分析**

与VINS‑Fusion和OpenVINS对比，在接触方向上的速度估计RMSE从0.0356降至0.0121 m/s，力保持稳定且定位误差显著下降。

**⚠️ 局限性**

当前实验仅在光照良好、特征丰富的室内环境下验证，受限于风扰动和特征稀疏场景。

---

## 667. Learning in Context, Guided by Choice: A Reward-Free Paradigm for Reinforcement Learning with Transformers

**arXiv ID:** 2602.08244 | [PDF](https://arxiv.org/pdf/2602.08244v1)

**作者:** Juncheng Dong `[一作]` (Duke University), Vahid Tarokh `[通讯]` (Duke University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出一种完全无奖励监督的in-context强化学习范式ICPRL，利用仅有偏好反馈进行预训练和部署

**💡 创新点**

创新点在于将偏好反馈直接用于Transformer预训练，提出I-PRL（步级偏好）与T-PRL（轨迹级偏好）两种偏好级别，并给出无奖励、无最优动作标签的偏好本地化训练框架

**🔧 技术方法**

主要技术包括Transformer基元策略、偏好代理/奖励估计、Bradley‑Terry模型生成偏好、基于偏好的监督与强化学习目标

**📊 数据集**

实验数据集包括多任务的Dueling Bandit、DarkRoom导航任务和Meta‑World连续控制任务，采用多任务预训练与偏好采样

**📈 对比分析**

与奖励监督的DPT和在线SAC做对比，ICPRL在有高质量偏好上下文时可逼近DPT性能，在复杂连续控制任务上甚至优于DPT，且远超SAC

**⚠️ 局限性**

局限性在于需预先收集大量离线偏好数据，且未实现主动偏好查询或在极度稀疏偏好场景下的表现有限

---

## 668. PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition

**arXiv ID:** 2602.08240 | [PDF](https://arxiv.org/pdf/2602.08240v1)

**作者:** Xun Su `[一作]` (Southwest University), Qi Zhang `[通讯]` (Southwest University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出一种参数高效的 neuromorphic 适配框架 PTS‑SNN，将冻结的自监督特征对齐到事件驱动的尖峰网络，实现低能耗语音情感识别。

**💡 创新点**

结合无参通道时间移位编码器、尖峰稀疏线性注意力与软提示，动态校准膜电位，解决分布不匹配问题；仅更新少量适配器参数，兼顾性能与能耗。

**🔧 技术方法**

使用尖峰神经网络（Parametric LIF）、Prompt‑Tuning（软提示）、Temporal Shift、Sparse Linear Attention、surrogate‑gradient 学习以及自监督特征提取。

**📊 数据集**

在 IEMOCAP、CASIA、EMODB、EMOVO、URDU 这五个多语种语音情感数据集上进行实验。

**📈 对比分析**

与多种 ANN 变压器、ShiftFormer、Co‑attention 等做对比，IEMOCAP 上取得 73.34% 的加权准确率，参数仅 1.19 M，推理能耗 0.35 mJ，显著优于基准。

**⚠️ 局限性**

仅使用声学信号，未融合视觉或文本等多模态信息；软提示在不同语言/语料中可能存在泛化限制。

---

## 669. Interaction-Grounded Learning for Contextual Markov Decision Processes with Personalized Feedback

**arXiv ID:** 2602.08307 | [PDF](https://arxiv.org/pdf/2602.08307v1)

**作者:** Mengxiao Zhang `[一作]` (University of Iowa), Paul Mineiro `[通讯]` (Microsoft Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文提出一种在上下文情境下的多步马尔可夫决策过程（MDP）中，利用间接个性化反馈学习最佳策略的框架。

**💡 创新点**

创新点在于将Interaction‑Grounded Learning（IGL）从单步情境扩展到多步情境，并设计了可实现子线性回报的奖励解码器（基于逆运动学）与策略优化算法（Inverse‑Gap‑Weighting），实现了理论上可证明的 O(T^{3/4}) 子线性回报。

**🔧 技术方法**

主要技术包括：①可学习的可到达状态识别、逆运动学学习和Lipschitz奖励解码器；②利用在线平方损失回归 oracle 与自适应转移估计实现政策学习；③在奖励缺失情况下通过解码器生成代理奖励并进行策略优化。

**📊 数据集**

实验数据集包括：1）自定义的三层情境 MDP（包含“好/坏”状态和多种动作）用于验证理论；2）真实任务对话数据（餐厅预订 + 电影预订）合并后约3,700条两轮对话，用于评估在实际对话场景中的效果。

**📈 对比分析**

与基线（仅使用真实奖励或不使用解码器的随机策略）相比，实验结果显示解码器策略的平均奖励在训练结束时可接近最优（0.7/0.729 在合成数据，0.95 在真实数据），并且解码器的奖励始终是对真实奖励的下界，验证了理论预期。

**⚠️ 局限性**

局限性包括：①回报上限仍高于单步结果，需进一步降低回报率；②仅考虑终端奖励，未处理中间步骤的反馈；③对同质状态需要预先知晓常数 c；④需要先学习可达状态的“归位”策略，增加了探索成本。

---

## 670. Cyclic Adaptive Private Synthesis for Sharing Real-World Data in Education

**arXiv ID:** 2602.08299 | [PDF](https://arxiv.org/pdf/2602.08299v1)

**作者:** Hibiki Ito `[一作]` (Kyoto University), Hiroaki Ogata `[通讯]` (Kyoto University)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `67630363-6be0-4f51-ab05-7198250671a5` `9cc9baba-5356-466d-81ff-d80028d90279` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `5a41884c-404f-4688-a89c-aa238c10fe68` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出并验证了 CAPS（Cyclic Adaptive Private Synthesis）框架，用于在教育领域中迭代共享受隐私保护的真实世界数据。

**💡 创新点**

创新点：① 将差分隐私下的生成模型适配为循环式适应，利用先前周期生成的合成数据持续更新特征提取器；② 结合公开的 LLM 生成模拟数据进行预训练；③ 通过“半私有半监督学习（SPSSL）”在保持隐私的前提下提升模型性能。

**🔧 技术方法**

技术：差分隐私 (DP-SGD、RDP/GDP 计数)、变分自编码器 (VAE) 与条件 VAE、连续学习（生成式回放）、LLM 生成的合成数据、Beta‑VAE、Adam 优化器。

**📊 数据集**

数据集：真实日本初中七年级数学课 3 年（2022‑2024）共 3 组 105‑115 名学生的学习习惯日志与期末考试成绩，经过时间窗口与参与度分类后得到 4 维时间序列（17 周）。

**📈 对比分析**

对比方法：与一次性（one‑shot）基线模型比较；性能指标包括下游学业成就预测的平衡准确率和均方误差。实验显示，CAPS 在多周期迭代后在这两项指标上略有提升，且模型重构能力随周期增强；但合成数据的条件生成质量随周期略差，出现“累积偏差”现象。

**⚠️ 局限性**

局限性：① 仅在小样本、维度高且特征空间不变的设置下验证；② 依赖 LLM 生成的公开数据，可能引入偏差；③ 评估主要基于统计指标，缺乏真实应用中的可解释性与实用性验证；④ 对“累积偏差”机制的解释仍属假设，需进一步研究。

---

## 671. Altruism and Fair Objective in Mixed-Motive Markov games

**arXiv ID:** 2602.08389 | [PDF](https://arxiv.org/pdf/2602.08389v1)

**作者:** Yao-hua Franck Xu `[一作]` (Orange Labs), Jean-Marie Bonnin `[通讯]` (IRISA)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

设计并实现了基于比例公平与利他主义的公平多智能体强化学习框架，提出公平利他马尔可夫游戏及对应的公平策略梯度算法；

**💡 创新点**

创新点在于将比例公平（Proportional Fairness）与利他主义结合，构造新的公平利他效用函数，推导出公平策略梯度理论，并在序列决策（马尔可夫游戏）中实现；

**🔧 技术方法**

使用 Actor‑Critic 算法（FAIR MAA2C、FAIR MAPPO）、PPO、A2C 以及 Jax 编写的 CleanUp 环境；

**📊 数据集**

实验数据集为 Melting Pot 2.0 的 CleanUp 社会困境环境，包含 7 名智能体的部分可观测场景；

**📈 对比分析**

通过比较比例公平目标与传统效用最大化（Utilitarian Welfare）目标以及不同 altruism 水平（α）下的表现，结果显示：在完全合作（α=1）时比例公平能获得约 120 个苹果（比 UW 的 40 个高得多），并且 Gini 系数低；α≈0.7 时获得最高效益；公平优势函数使得 Gini 指数保持在 0.05–0.2 之间；

**⚠️ 局限性**

limitations：缺乏收敛与平衡性理论证明；公平优势函数与 TRPO 理论不一致导致理论支持不足；训练过程在 MAA2C 中表现不稳定；实验仅在单一 CleanUp 环境下验证，未覆盖更复杂或真实世界场景。

---

## 672. Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI

**arXiv ID:** 2602.08373 | [PDF](https://arxiv.org/pdf/2602.08373v1)

**作者:** Feiyu Wu `[一作]` (Xidian University), Hui Li `[通讯]` (Xidian University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 Verifiable Iterative Refinement Framework（VIRF），通过正式逻辑导师与 LLM 规划者的因果对话，实现可验证的安全规划；

**💡 创新点**

核心创新是把安全检查从被动拒绝转为主动因果反馈，构建可追溯的知识采集流程（TAS）和多阶段 VLM 语义感知，形成完整的神经-符号安全协同体系；

**🔧 技术方法**

采用 OWL 2 形式化安全本体、描述逻辑推理器、VLM-Cascade 感知管线、AI Synthesizer–Human Arbiter 的半自动知识构建、以及 LLM 与逻辑导师的对话循环；

**📊 数据集**

主要使用 SafeAgentBench 以及通过 RAG 合成的真实安全文档构建的本体知识库，另外在 AI2‑THOR 环境中生成新挑战场景进行验证；

**📈 对比分析**

在 SafeAgentBench 上与多种基线（包括自回归、ReAct、Constitutional AI 等）对比，VIRF 实现 0% Hazardous Action Rate、77.3% Goal‑Condition Rate，且平均仅需 1.1 次修正；

**⚠️ 局限性**

局限在于知识本体静态更新、感知噪声导致的符号不一致、以及从仿真到现实的物理动态建模不足；

---

## 673. E-VAds: An E-commerce Short Videos Understanding Benchmark for MLLMs

**arXiv ID:** 2602.08355 | [PDF](https://arxiv.org/pdf/2602.08355v1)

**作者:** Xianjie Liu `[一作]` (Alibaba Group), Bo Zheng `[通讯]` (Alibaba Group)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了面向电商短视频的E-VAds问答基准以及基于RL的推理模型E-VAds-R1。

**💡 创新点**

创新点包括：①多模态信息密度评估框架，量化视觉/音频/文本的高密度；②构建涵盖5类任务的开放式问答基准；③引入多粒度奖励（MG‑GRPO）提升RL推理的效率与精度。

**🔧 技术方法**

采用多模态特征提取与时序对齐、动态采样、基于LLM的多代理生成、RLHF+多粒度奖励、视频LLM等技术。

**📊 数据集**

使用了3,961条淘宝短视频及其对应的19,785个高质量开放式问答对。

**📈 对比分析**

与主流视频QA与广告基准相比，E-VAds在视觉、音频、文本密度上显著更高；E-VAds‑R1在商业意图推理上相较基线提升109.2%，在多模态推理任务上大幅优于大多数开放模型，闭源模型虽领先但仍落后于人类专家。

**⚠️ 局限性**

局限性：仍与人类专家存在较大差距；对低质量或超长视频的适用性有限；开放式评价主观性较高，RL奖励仍易出现稀疏性；模型对极端噪声鲁棒性不足。

---

## 674. To Tango or to Disentangle? Making Ethnography Public in the Digital Age

**arXiv ID:** 2602.08349 | [PDF](https://arxiv.org/pdf/2602.08349v1)

**作者:** Daniel Mwesigwa `[一作]` (Cornell University), Palashi Vaghela `[通讯]` (Simon Fraser University)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并应用“emergent relationality”分析框架，通过在VRChat和WhatsApp上进行民族志研究探讨种族与种姓议题

**💡 创新点**

将民族志的双重角色与混合媒体环境结合，提出新的“emergent relationality”概念，用以解释平台、公众与研究者之间的相互塑造

**🔧 技术方法**

采用人类可读民族志方法：参与式观察、访谈、现场笔记、社交媒体记录、数字痕迹分析

**📊 数据集**

VRChat用户交互日志、WhatsApp群聊与私聊文本、研究者自我反思日志与访谈记录

**📈 对比分析**

本文未进行定量方法比较或性能评估，主要是质性案例研究与理论阐释

**⚠️ 局限性**

局限包括样本规模有限、对特定平台的依赖、研究者身份带来的偏见、数据获取受限及对普遍性的推断受限

---

## 675. OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration

**arXiv ID:** 2602.08344 | [PDF](https://arxiv.org/pdf/2602.08344v1)

**作者:** Qi Guo `[一作]` (National Engineering Research Center for Software Engineering, Peking University), Wei Ye `[通讯]` (Peking University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了Outline-guided Parallel Exploration (OPE) 方法，用高层思路划分解题空间以提升大规模推理模型的并行思考性能。

**💡 创新点**

核心创新在于将探索阶段引入可控大纲，利用信息论分析消除路径互信息饱和，且采用迭代 RL 共同优化大纲规划与路径推理。

**🔧 技术方法**

结合强化学习与可验证奖励（RLVR）、GRPO 算法、分层策略（先生成大纲再推理），并在 Qwen3-8B 上实现。

**📊 数据集**

使用数学推理基准 GURU（包含 OR1、DAPO 等子集）以及 MATH-500、AMC、AIME、BeyondAIME、HMMT-25 等标准数据集进行评测。

**📈 对比分析**

与传统无大纲的并行思考在 BoN、Self-Consistency、LRM‑Based Summary 等聚合方式上均有提升，最高可提升约 5%–10%，并展现更好的测试时扩展性。

**⚠️ 局限性**

主要局限在于固定的大纲预算（N=4）限制了探索深度，对极其复杂问题仍可能需要更多大纲；且模型对大纲质量高度依赖，若生成大纲不足会导致性能下降。

---

## 676. Vec-QMDP: Vectorized POMDP Planning on CPUs for Real-Time Autonomous Driving

**arXiv ID:** 2602.08334 | [PDF](https://arxiv.org/pdf/2602.08334v1)

**作者:** Xuanjin Jin `[一作]` (Shanghai Jiao Tong University), Panpan Cai `[通讯]` (Shanghai Jiao Tong University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

针对自主驾驶中高维不确定性规划，提出了一种纯CPU并行的POMDP搜索框架。

**💡 创新点**

创新点在于结合数据导向设计、全局与局部SIMD向量化、基于QMDP的子树并行分解以及负载均衡UCB，以实现数百倍加速。

**🔧 技术方法**

使用技术包括多线程+SIMD并行、Data‑Oriented Design（SoA/SoT）、QMDP近似、全局/局部向量化、STR树加速碰撞检测、负载均衡UCB等。

**📊 数据集**

使用的数据集为nuPlan大规模城市驾驶基准集（Val14、Test14-random、Test14-hard）。

**📈 对比分析**

与学习、混合、基于模型的基线相比，规划时延仅9–14 ms，获得与最先进方法相当或更优的驾驶分数，树构造吞吐量提升227×–1073×。

**⚠️ 局限性**

局限：QMDP假设不确定性在第一步消失，难以处理长期信息获取；在极异的情景树上向量化效率仍受限。

---

## 677. PACC: Protocol-Aware Cross-Layer Compression for Compact Network Traffic Representation

**arXiv ID:** 2602.08331 | [PDF](https://arxiv.org/pdf/2602.08331v1)

**作者:** Zhaochen Guo `[一作]` (University of Electronic Science and Technology of China), Shinan Liu `[通讯]` (University of Hong Kong)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `fede83ac-7505-405f-ab37-e7284695c47f` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `9ce7179e-700c-4310-ac2b-91df50ded46e` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

设计并实现了一种面向加密流量的跨层冗余感知表示框架，利用共享/私有分解、重构、对比一致性和任务相关信息联合学习，将原始位编码压缩为高效、判别性强的低维表示；

**💡 创新点**

创新点在于将协议栈视为多视图结构，显式区分跨层共享与层内私有信息，利用对比学习对共享信息对齐、重构约束消除冗余，并通过不确定性加权注意力实现动态层级融合，兼顾鲁棒性与压缩；

**🔧 技术方法**

核心技术包括层级自编码器、信息瓶颈重构损失、InfoNCE 对比损失、交叉熵任务损失、全局与局部不确定性注意力融合，以及基于预编码的 nPrint 作为输入；

**📊 数据集**

实验使用三类公开数据集：加密应用分类（CipherSpectrum 四子集）、IoT 设备分类（UNSW 2018）、攻击流量识别（CICIoT 2023），每个数据集均包含多层协议视图；

**📈 对比分析**

与传统流量统计、原始位编码、预训练嵌入（如 nPrint、TFE‑GNN、NetMamba、YaTC）对比，模型在 CipherSpectrum 上平均提升 12.9% 以上、在 IoT 设备分类与攻击识别任务中均达到或接近预训练模型的准确率，同时训练与推理效率提升至 3.16× 以上；

**⚠️ 局限性**

局限性包括：目前仅处理单个流，未考虑会话级或多流的时间/图关系；对抗性改写（填充、头部篡改）可能削弱共享对齐的鲁棒性；以及在极低维度或极高类别不平衡场景下性能下降。

---

## 678. Modalities, a PyTorch-native Framework For Large-scale LLM Training and Research

**arXiv ID:** 2602.08387 | [PDF](https://arxiv.org/pdf/2602.08387v1)

**作者:** Max Lübbering `[一作]` (Fraunhofer IAIS), Mehdi Ali `[通讯]` (Fraunhofer IAIS)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一个基于PyTorch的可扩展LLM训练框架Modalities，支持从研究到生产的完整工作流。

**💡 创新点**

核心创新在于模块化设计与声明式YAML配置，结合多种并行策略实现可伸缩的训练与高效实验，减少集成工作量。

**🔧 技术方法**

采用PyTorch原生并行（FSDP、tensor/pipeline并行）、依赖注入工厂、注册机制、Hugging Face兼容、全局数据并行等技术。

**📊 数据集**

主要使用FineWeb（≈100B token）和FineWeb‑Edu子集进行预训练，评估以8B LLaMA‑3为例。

**📈 对比分析**

与Megatron‑LM等框架对比，Modalities在1,024卡上实现强扩展，tokenization吞吐率约31M tokens/s，训练损失与基准一致。

**⚠️ 局限性**

局限在于仍需对超大规模训练进行细粒度调优，依赖PyTorch生态，尚未覆盖所有新兴训练范式。

---

## 679. Towards Real-World Industrial-Scale Verification: LLM-Driven Theorem Proving on seL4

**arXiv ID:** 2602.08384 | [PDF](https://arxiv.org/pdf/2602.08384v1)

**作者:** Jianyu Zhang `[一作]` (Zhejiang University), Yongwang Zhao `[通讯]` (Zhejiang University)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一种面向工业规模验证的 LLM 驱动定理证明方法 AutoReal，并实现了可在本地轻量部署的 7B 规模证明器 AutoReal‑Prover

**💡 创新点**

创新点主要有：1) 基于 chain‑of‑thought 的证明训练，教会 LLM 逐步解释每一步证明的推理过程；2) 上下文增强策略，显式向模型提供与目标定理相关的证明上下文，从而提升证明成功率并使生成的证明更易于人类审查

**🔧 技术方法**

技术包括：使用 Qwen2.5‑Coder‑7B 进行指令微调；构造约 200k 条基于 Isabelle 证明步骤的 CoT 训练样本；在生成证明时结合证明上下文并输出逐步自然语言解释；采用 Isabelle/HOL 证明检查器评估生成脚本

**📊 数据集**

数据集：① seL4 Isabelle 代码库，提取 660 条重要定理；② 约 200k 条从 seL4 证明轨迹自动生成的 CoT 实例；③ AFP 里的 3 个安全相关项目（CRYSTALS‑Kyber、RSAPSS、Elliptic_Curves）共 451 条定理

**📈 对比分析**

与之前仅使用 GPT‑4 的 Selene 方法（27.06% 成功率）相比，AutoReal‑Prover 在 seL4 上达到 51.67%，在 AFP 项目上实现 53.88%，显著提升；在 ablation 实验中，单独使用 CoT 训练或上下文增强均提升至约 20‑6% 的成功率，二者结合后成功率提升至 54.29%，证明两项创新互补有效

**⚠️ 局限性**

局限性：① 证明上下文的提取仍需人工手动指定；② 对某些结构化步骤（如终止命令）存在解释漂移或错误；③ 目前仅针对 Isabelle/HOL 开发，尚未迁移到 Coq、Lean 等其它交互式定理证明器；④ 7B 模型仍受限于推理深度，面对更复杂的工业级证明链时成功率仍有提升空间

---

## 680. Does Your Reasoning Model Implicitly Know When to Stop Thinking?

**arXiv ID:** 2602.08354 | [PDF](https://arxiv.org/pdf/2602.08354v1)

**作者:** Zixuan Huang `[一作]` (Beihang University), Deqing Wang `[通讯]` (Beihang University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 SAGE（Self‑Aware Guided Efficient Reasoning）和 SAGE‑RL 两种新的采样框架，利用大型推理模型自身的自信信号（累计概率 Φ）来自动识别何时结束推理，从而显著减少冗余推理步骤并提升正确率。

**💡 创新点**

创新点：①发现大型推理模型隐式知道何时停止思考；②利用累计概率 Φ 在采样过程中高效定位终止点，避免传统随机或贪婪采样导致的冗余推理；③将 SAGE 与 RL 采样（GRPO/GSPO）相结合，形成 SAGE‑RL，进一步让模型学习更短更准确的推理路径。

**🔧 技术方法**

技术：Token‑wise/step‑wise 推理路径扩展、累计概率 Φ、容差排名 TR；RL‑VR 框架（GRPO、GSPO）与 SAGE 的混合 roll‑out；评价指标 RFCS（First Correct Step Ratio）；对比随机采样、贪婪采样、ThinkPrune、AdaptThink、Efficient‑Reasoning 等。

**📊 数据集**

数据集：MATH‑500、AIME 2024/2025、AMC23、OlympiadBench、Minerva 等数学与推理基准。

**📈 对比分析**

比较方法：在相同模型（DS‑1.5B、DeepScaleR、DS‑7B、Qwen3‑8B 等）与相同 token 预算下，与随机采样、Greedy、ThinkPrune、AdaptThink、Efficient‑Reasoning、GRPO、GSPO 等 baseline 进行对比；结果显示 SAGE‑RL 在 pass@1 提升 0.5%–2%，CoT 长度缩短 30%–60%，token‑efficiency（pass@1/长度）提升 50%–100% 甚至更高。

**⚠️ 局限性**

局限性：①需要足够的探索空间和 token 预算；②对低资源或小模型效果有限；③需手动调参（m、r、TR 等）；④依赖模型已有的自信信号，若自信度不高则 SAGE 效果下降。

---

## 681. What, Whether and How? Unveiling Process Reward Models for Thinking with Images Reasoning

**arXiv ID:** 2602.08346 | [PDF](https://arxiv.org/pdf/2602.08346v1)

**作者:** Yujin Zhou `[一作]` (Hong Kong University of Science and Technology), Sirui Han `[通讯]` (Hong Kong University of Science and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了针对“思考与图像”范式的 Process Reward Model（PRM）评估基准，并对现有大视觉语言模型在该范式下的推理错误进行细粒度划分与评估。

**💡 创新点**

首次提出七类细粒度错误类型，创建了覆盖四大视觉推理维度的1,206条手工标注推理轨迹，并揭示现有 LVLM 作为 PRM 的显著局限性。

**🔧 技术方法**

采用多模态推理轨迹收集、人工标注、PRM 引导搜索算法以及准确率和 F1 指标对多种公开与专有 LVLM 进行评估。

**📊 数据集**

从 VBench、Blink、SAT-2、HRBench、MME-RealWorld 等公开数据集采集问题-图像对，并在此基础上生成并标注推理轨迹。

**📈 对比分析**

使用“guided search”框架将 PRM 作为奖励函数评估每一步轨迹，比较不同模型的准确率与 F1，最佳模型约 45% 的准确率，远低于人类约 83% 的水平，显示显著性能差距。

**⚠️ 局限性**

仅覆盖基本的图像处理工具（裁剪、缩放）且未考虑更高级视觉工具与推理能力，导致错误类型可能不完整且评估范围受限。

---

## 682. An Attention-over-Attention Generative Model for Joint Multiple Intent Detection and Slot Filling

**arXiv ID:** 2602.08322 | [PDF](https://arxiv.org/pdf/2602.08322v1)

**作者:** Wei Zhu `[一作]` `[通讯]` (University of Hong Kong), Wei Zhu (University of Hong Kong)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种生成式框架 GEMIS，用统一的序列到序列（seq2seq）模型同时完成多意图检测和槽位填充。

**💡 创新点**

创新点包括：① 将多意图 SLU 重新表述为 seq2seq 任务，利用预训练 BART 的共享解码器；② 在解码器中引入 attention‑over‑attention（AoA）子层，借助先前预测的意图注意图引导槽位生成；③ 采用指针网络在解码器顶部直接预测槽位位置；④ 利用 BERT 的 next‑sentence‑prediction（NSP）头构造更自然的多意图数据集 MultiATIS 和 MultiSNIPS。

**🔧 技术方法**

技术手段主要是预训练 seq2seq 语言模型 BART、指针网络、AoA 结构、NSP 判别器、Transformer 架构、AdamW 优化器。

**📊 数据集**

使用的数据集包括公开的 MixATIS、MixSNIPS（随机拼接单意图句子）以及作者构造的 MultiATIS、MultiSNIPS（基于 NSP 的语义连贯拼接）。

**📈 对比分析**

与多种基线（Slot‑Gated、SF‑ID、Stack‑Propagation、Joint Multiple ID‑SF、AGIF、GL‑GIN）进行比较。实验显示 GEMIS 在 MixATIS/MixSNIPS 的整体准确率分别提升至 53.4% / 87.4%，在 MultiATIS/MultiSNIPS 分别提升至 71.5% / 91.5%，显著优于现有最优模型。

**⚠️ 局限性**

局限性：① 构造的数据集仍为人工拼接，真实对话中的语义连贯性和多意图分布可能更复杂；② 只评估了 1–3 个意图的情况，对更高意图数的鲁棒性尚未验证；③ 仅使用贪心解码，未探索束搜索对性能的影响；④ 主要关注意图和槽位的联合预测，未考虑对话上下文的长期依赖。

---

## 683. Improving Data and Reward Design for Scientific Reasoning in Large Language Models

**arXiv ID:** 2602.08321 | [PDF](https://arxiv.org/pdf/2602.08321v1)

**作者:** Zijie Chen `[一作]` (Zhejiang University), Peng Cheng `[通讯]` (Microsoft Research Asia)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了Dr. SCI科学推理后训练框架，包含大规模数据处理、细粒度评价 rubric 以及针对开放式问题的 RL 方法；

**💡 创新点**

创新点在于：①统一构建可验证与开放式科学问题的数据集并提供难度标注；②使用基于 4‑gram 覆盖率的探索扩展式 SFT 以提升模型的推理模式多样性；③引入动态难度课程与 rubric‑guided RL，兼顾推理覆盖与答案正确性；

**🔧 技术方法**

核心技术包括：大规模数据清洗与归一化、基于 4‑gram 的样本选取算法、动态难度筛选策略、Rubric‑Guided 强化学习（GRPO+verifier）以及多任务 SFT；

**📊 数据集**

使用了 Dr. SCI 数据集（≈1 M STEM 题目，分可验证与开放式），其来源涵盖 WebInstruct‑Verified、NaturalReasoning、MegaScience、RaR‑Science 等公开资源；

**📈 对比分析**

与多种后训练基线（o1-mini、GPT‑4o、Qwen3‑32B、MegaScience 版模型等）对比，4 B Dr. SCI‑think 模型在 GPQA‑Diamond、GPQA‑General、SuperGPQA、HLE、MMLU‑Pro 等基准上均实现显著提升，甚至超越 32 B 级模型；

**⚠️ 局限性**

局限性包括：① 对生成的科学解释仍存在事实错误风险，需人工审查；② 对评价 rubric 的质量依赖高，若 rubric 编写不足可能导致奖励偏差；③ 训练过程对算力依赖较大，尤其是 RL 期间的验证模型；

---

## 684. Dynamic Regret via Discounted-to-Dynamic Reduction with Applications to Curved Losses and Adam Optimizer

**arXiv ID:** 2602.08372 | [PDF](https://arxiv.org/pdf/2602.08372v1)

**作者:** Yan-Feng Xie `[一作]` (Nanjing University), Zhi-Hua Zhou `[通讯]` (Nanjing University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

研究了非平稳在线学习的动态损失，提出模块化的折扣到动态化简化方法，并将其应用于线性回归、逻辑回归以及Adam优化器。

**💡 创新点**

通过在未调优的上界模板层面实现折扣-动态化简化，既简化了曲线损失的动态误差分析，又实现了Adam在非凸、非光滑环境下的最优收敛率，并对β1,β2参数提供了更宽松的约束。

**🔧 技术方法**

采用折扣损失与动态损失的等价转换（D2D）、FTRL框架、指数化在线到非凸转换（O2NC）、自适应学习率调优与自信调节引理，以及尺度无关的在线学习技术。

**📊 数据集**

无；论文为理论分析与证明，无实验数据集。

**📈 对比分析**

与传统FTRL、OMD及已有Adam分析比较，所给动态误差上界在线性回归上达到最优的O(d log T + √(d T P^β_T))，在逻辑回归上实现了O(d B log(B T)+√(d B T P^β_T))，并在Adam中实现了最优的O((G+σ)^{3/2}/ε^{7/2})等收敛率，优于之前需β₂=β₁²等限制的结果。

**⚠️ 局限性**

主要局限在于假设严格（如梯度可测量、噪声方差已知、凸/光滑等），缺乏实验验证；对β₁,β₂的取值仍需满足一定范围；以及对高维稀疏特征或其他FTRL变体的推广尚未深入。

---

## 685. ViGoEmotions: A Benchmark Dataset For Fine-grained Emotion Detection on Vietnamese Texts

**arXiv ID:** 2602.08371 | [PDF](https://arxiv.org/pdf/2602.08371v1)

**作者:** Hung Quang Tran `[一作]` (University of Information Technology), Kiet Van Nguyen `[通讯]` (University of Information Technology)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文通过LLM辅助标注与人工复核，构建了含 20,664 条越南语社交媒体评论的细粒度情感语料库 ViGoEmotions，并对其进行实验评估。

**💡 创新点**

创新点在于：①采用多模型 LLM（Gemini Flash、Llama‑3、Gemma）与人工双重验证相结合的标注流程，提升标注效率与一致性；②创建 27 类细粒度越南情感标签集；③系统比较了三种 emoji 处理方案与 ViSoLex 词汇归一化对情感识别的影响。

**🔧 技术方法**

技术手段包括：大语言模型标注、Transformer 基础模型（mBERT、XLM‑R、PhoBERT、ViBERT、BARTpho、ViT5、ViSoBERT、CafeBERT）以及三种预处理策略（保留 emoji、emoji→文本、ViSoLex 归一化）。

**📊 数据集**

使用的数据集为 ViGoEmotions，包含 20,664 条来自 Facebook、Reddit、Threads、TikTok、X、YouTube 等平台的评论，原始内容还融合了 UIT‑VSMEC 数据。

**📈 对比分析**

通过在 8 个模型与 3 个预处理场景下训练并评估宏 F1 与加权 F1，发现保留原始 emoji 的 Scenario 1 最优；ViSoBERT 在该场景下取得宏 F1 61.50% 与加权 F1 63.26%，成为最佳模型。

**⚠️ 局限性**

局限性包括：数据来源平台有限、情感标签主观性与重叠、模型对细微语境或讽刺的捕捉不足，以及 ViSoLex 未做域自适应，可能影响归一化效果。

---

## 686. Circuit Representations of Random Forests with Applications to XAI

**arXiv ID:** 2602.08362 | [PDF](https://arxiv.org/pdf/2602.08362v1)

**作者:** Chunxi Ji `[一作]` (University of California), Adnan Darwiche `[通讯]` (University of California)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出两种算法将随机森林编译成可解释的电路形式，实现对决策的完整原因、一般原因、足因、必要因、对比解释以及鲁棒性与最短翻转路径的高效枚举。

**💡 创新点**

创新点在于利用排序网络生成无辅助变量的NNF电路，再通过弱测试一次决策图实现决策原因的线性计算，并兼容多类别随机森林的投票逻辑。

**🔧 技术方法**

核心技术包括：排序网络、NNF电路、弱测试一次决策图、闭式推导完整/一般原因、最短GNR求解、算法B与A的实现。

**📊 数据集**

实验使用19个UCI与Penn数据集，采用WEKA训练随机森林，按85/15训练/测试划分。

**📈 对比分析**

与ADD/ORD编译方法相比，本研究在编译时间上提升约10–20倍，电路规模更小；在多类别场景下，完整/一般原因的计算与解释枚举速度明显优于现有方法。

**⚠️ 局限性**

局限在于高维大类数据（如ionosphere）时决策图规模膨胀导致枚举耗时增加；对实例属于多类别时需要人工归类，且算法仍以单一类别为前提。

---

## 687. Effect-Level Validation for Causal Discovery

**arXiv ID:** 2602.08340 | [PDF](https://arxiv.org/pdf/2602.08340v1)

**作者:** Hoang Dang `[一作]` (Independent Researcher), Minh Nguyen `[通讯]` (Florida Atlantic University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了基于可识别性优先的因果发现框架，并将发现得到的图视为结构假设，先通过可识别性和正性门检验再估计因果效应；

**💡 创新点**

核心创新是将评估焦点从传统的图结构恢复指标转向“可识别性+效果稳定性+反证检验”，证明不同结构但可识别的图可以得到一致的、可信的因果效应；

**🔧 技术方法**

使用了多种因果发现算法（PC、GRaSP、BOSS、FCI等）以及DoWhy的双重稳健估计、E-value 敏感度分析、placebo 与子样本反证检验；

**📊 数据集**

采用真实游戏遥测数据，包含1,280名付费玩家的26个行为特征，研究早期PvP（PvP）介入对短期留存（Day‑1）的影响；

**📈 对比分析**

通过在不同约束阶梯、显著性阈值和算法之间做可识别性统计与效应稳定性评估，发现约束越严格可识别率越高，且可识别的效应在不同算法间高度一致，估计结果在不同估计器间相近；

**⚠️ 局限性**

局限包括：仅对已付费且保持活跃的子样本可推断，外推性有限；仍依赖已观测的正性检验；对潜在强烈未测混杂仍无法完全消除；

---

## 688. CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT

**arXiv ID:** 2602.08339 | [PDF](https://arxiv.org/pdf/2602.08339v1)

**作者:** Chengyi Du `[一作]` (University of Electronic Science and Technology of China), Luxin Xu `[通讯]` (University of Electronic Science and Technology of China)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `67630363-6be0-4f51-ab05-7198250671a5` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出CoTZero框架，实现无注释的视觉‑语言模型高层次推理

**💡 创新点**

双阶段数据合成与认知对齐训练，利用层级链式思维与 Cognitively Coherent Verifiable Rewards (CCVR) 奖励

**🔧 技术方法**

使用VLM生成caption→LLM抽取三元组→Atomic QA合成与树形合并构造CoT数据；训练阶段采用SFT+GRPO强化学习+CCVR

**📊 数据集**

自行生成的CoTZero合成数据（1k→4k样本），并在由五个公开数据集组成的10k图像+问答基准上评估

**📈 对比分析**

与Qwen‑VL基线、SFT、冷启动等对比，整体、域内、域外F1分别提升约10%~15%，表现最佳

**⚠️ 局限性**

仍受限于生成质量、奖励设计的可解释性，以及对更高效RL算法与跨模态通用性的探索不足

---

## 689. Language-Guided Transformer Tokenizer for Human Motion Generation

**arXiv ID:** 2602.08337 | [PDF](https://arxiv.org/pdf/2602.08337v1)

**作者:** Sheng Yan `[一作]` (Transsion Ltd), Mengyuan Liu `[通讯]` (Peking University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了一种语言引导的Transformer分割器（LG‑Tok），在运动分割阶段将自然语言信息与运动序列对齐，生成高层语义、紧凑的离散token，并在解码器中使用跨注意力重建运动。

**💡 创新点**

创新点包括：①在分割阶段引入语言引导，使token侧重细粒度运动细节；②用Transformer代替CNN，利用全局注意力实现语言‑运动的有效对齐；③设计语言‑drop方案，让解码器在无语言条件下也能生成高质量运动，提升模型鲁棒性。

**🔧 技术方法**

主要技术：VQ‑VAE + Transformer tokenizer/detokenizer、LLaMA‑3.2‑1B文本编码器、RoPE、RMSNorm、SwiGLU、UNet‑style skip 连接、语言‑drop 与运动空间指导。

**📊 数据集**

实验数据集：HumanML3D（约14k动捕序列）和更大规模的Motion‑X（约38k动捕序列）。

**📈 对比分析**

通过与MARDM、MoSa、MoMask等SOTA方法在HumanML3D和Motion‑X上比较，LG‑Tok在Top‑1 R‑Precision上分别达到0.542/0.582，FID分别为0.057/0.088，均显著优于对比方法；LG‑Tok‑mini仅用一半token也保持竞争性能。

**⚠️ 局限性**

局限性：仍需要合理平衡token数与生成难度；语言对细粒度动作描述有限，难以完全替代视觉细节；实验仅涉及身体运动，未覆盖手指、面部等细部；语言‑drop比例与指导尺度对不同数据集的泛化仍需进一步研究。

---

## 690. UReason: Benchmarking the Reasoning Paradox in Unified Multimodal Models

**arXiv ID:** 2602.08336 | [PDF](https://arxiv.org/pdf/2602.08336v1)

**作者:** Cheng Yang `[一作]` (University of California San Diego), Taylor Berg-Kirkpatrick `[通讯]` (University of California San Diego)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一个面向统一多模态模型的推理驱动图像生成诊断基准，探究推理链是否能被准确地转化为像素级输出。

**💡 创新点**

创新点在于构建了 5 类可验证推理任务（代码、算术、空间、属性、文本），并提出了“推理悖论”——推理提升了规划，但中间思考仍会因上下文干扰削弱生成质量。

**🔧 技术方法**

使用了链式思考推理、统一多模态模型（如 Bagel、UniCoT 等）以及自动化多模态评估器 Qwen3‑VL‑235B‑A22B 来验证图像是否满足预设的客观标准。

**📊 数据集**

数据集为 2,000 条人工核对的实例，涵盖 30 个细粒度子类别，并划分为 1,500 条测试集和 500 条快速验证集。

**📈 对比分析**

通过对 8 种开源 UMM 在三种生成设定（直接、推理引导、去上下文）下的准确率进行对比，发现去上下文设定往往能获得最高准确率，表明推理链的中间思考会产生上下文干扰；相对直接设定，推理引导可提升约 8–19% 的准确率。

**⚠️ 局限性**

局限性包括：仅关注推理至图像的可执行性，未覆盖编辑任务；仅单回合生成；需要暴露推理链，无法评估闭源模型；自动评估可能受评测器偏差影响。

---

## 691. Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System

**arXiv ID:** 2602.08335 | [PDF](https://arxiv.org/pdf/2602.08335v1)

**作者:** Yanming Li `[一作]` (Didichuxing Co. Ltd), Li Shen `[通讯]` (Sun Yat-sen University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种多智能体强化学习框架 SHARP，利用 Shapley 值实现精确的信用分配，并通过三重奖励拆分（全局准确度奖励、边际信用奖励、工具过程奖励）稳定训练 LLM 规划-执行多智能体系统。

**💡 创新点**

创新点在于：①引入 Shapley‑based 边际信用奖励，通过对每个智能体的因果贡献做 counterfactual 掩码，精准量化个体影响；②三重奖励结构兼顾全局目标、个体贡献和工具执行质量；③使用 Group‑Relative Policy Gradient 归一化奖励，降低方差并提升学习稳定性。

**🔧 技术方法**

核心技术包括：共享策略的自对抗训练（planner‑worker 共享 LLM 策略），Shapley 值近似与 counterfactual 掩码，三重奖励设计与加权组合，Group‑Relative Policy Gradient（GRPO）优化以及工具调用有效性评估。

**📊 数据集**

实验数据集涵盖多任务工具使用与推理：MuSiQue、GAIA‑text、WebWalkerQA、FRAMES、DocMath‑Eval 等。

**📈 对比分析**

与单智能体和多智能体基线（Llama‑3.1‑it、Qwen‑3、Plan‑Search、MATPO、ACESEARCHER 等）对比，SHARP 在平均匹配率上分别比单智能体基线提升 23.66%，比其他多智能体基线提升 14.05%；在规模化（0.6B‑8B）和训练步长（0‑180）上也表现出更好的泛化与稳定性。

**⚠️ 局限性**

限制：仍存在多数子智能体无效或无益的情况，优良子智能体占比仅略有提升；Shapley 近似与掩码计算开销较大；需要进一步研究更激进的子智能体剪枝与资源效率优化。

---

## 692. Personalized Autonomous Driving via Optimal Control with Clearance Constraints from Questionnaires

**arXiv ID:** 2602.08326 | [PDF](https://arxiv.org/pdf/2602.08326v1)

**作者:** Yongjae Lim `[一作]` (Seoul National University), H. Jin Kim `[通讯]` (Seoul National University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种基于问卷获取的用户优先安全间距的个性化驾驶规划框架，利用该间距约束优化车辆轨迹。

**💡 创新点**

创新点在于：①从问卷设计直接提取用户对不同车辆交互情景下的安全距离偏好；②将偏好映射为约束构成的“偏好空间”，并在多情景下通过并行子问题求解实现实时规划；③使用并行轨迹优化与原始目标函数相结合的选择策略。

**🔧 技术方法**

使用了基于模型预测控制的轨迹优化、Frenet坐标系统、线性化车辆动力学、并行求解子问题的技术，以及基于STL/MIP的安全约束处理思路。

**📊 数据集**

数据集：通过设计并发布在线问卷（https://docs.google.com/forms/...）收集不同驾驶者（保守型、激进型）对安全间距的回答；仿真环境采用 HighwayEnv 与随机车辆分布。

**📈 对比分析**

与无偏好规划（Frenet-规划器、Batch MPC、CBF+MPPI）进行对比，评估指标为偏好空间内时间比例、平均速度和车道变换次数；实验表明该方法在保守场景下停留在原车道、在激进场景下实现安全超车，并且偏好匹配率接近100%。

**⚠️ 局限性**

局限性包括：①仅考虑纵向安全间距，未涉及横向或情境（如急驶）偏好；②问卷设计的离散化可能不足以覆盖所有真实驾驶情境；③实时性能依赖于并行计算资源，复杂场景下计算量仍可能较大。

---

## 693. Antiferromagnetic Tunnel Junctions (AFMTJs) for In-Memory Computing: Modeling and Case Study

**arXiv ID:** 2602.08323 | [PDF](https://arxiv.org/pdf/2602.08323v1)

**作者:** Yousuf Choudhary `[一作]` (University of Arizona), Tosiron Adegbija `[通讯]` (University of Arizona)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文提出了首个将双亚晶层Landau‑Lifshitz‑Gilbert动力学嵌入SPICE框架的抗磁隧道结（AFMTJ）仿真模型，并将其集成到层级式内存计算体系结构中。

**💡 创新点**

创新点在于实现了AFMTJ的双亚晶层耦合动力学模型、验证其实验TMR与开关特性，并展示其在IMC中的系统级速度与能耗优势。

**🔧 技术方法**

使用了多亚晶层LLG方程、互亚晶层交换耦合、第四阶Runge–Kutta积分器、SPICE仿真以及基于Synopsys HSPICE的电路级建模。

**📊 数据集**

采用了包括二值神经网络（bnn）、图像灰度化（img-grayscale）、阈值化（img-threshold）、乘加（mac）、矩阵加法（mat_add）和均方根误差（rmse）等多种基准工作负载。

**📈 对比分析**

通过将AFMTJ与传统MTJ在相同IMC层级架构中对比，AFMTJ在设备层实现写延迟约8倍、写能耗约9倍更低，在系统层平均提升速度17.5倍、能耗降低约20倍。

**⚠️ 局限性**

局限在于模型仍为仿真验证，缺乏实际制程验证；且在极高频或复杂逻辑操作下的稳定性与可扩展性尚未充分探究。

---

## 694. Fast Flow Matching based Conditional Independence Tests for Causal Discovery

**arXiv ID:** 2602.08315 | [PDF](https://arxiv.org/pdf/2602.08315v1)

**作者:** Shunyu Zhao `[一作]` (Graduate University of Advanced Studies), Kenji Fukumizu `[通讯]` (Institute of Statistical Mathematics)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `40105733-5154-44cd-8090-a8cab9e64b07`

**🎯 论文内容**

提出了一种基于流匹配的快速条件独立性检验方法（FMCIT），并将其集成到两阶段引导PC框架（GPC‑FMCIT）中，显著加速约束式因果发现；

**💡 创新点**

创新点在于利用流匹配一次性学习联合分布，将条件采样转化为完整数据的缺失值插补，并通过Picard‑RePaint采样实现高效、低成本的CRT；

**🔧 技术方法**

主要技术包括流匹配（flow matching）模型、Picard采样、RePaint噪声注入、以及在PC算法中的预算化条件集合搜索；

**📊 数据集**

在合成的后非线性结构方程模型（含重尾噪声）以及真实的Sachs流细胞术数据集上进行实验；

**📈 对比分析**

与FisherZ、RCIT、FastKCI、EPC‑ECIT等基准方法比较，FMCIT在保持或提升类型I错误控制与统计功效的同时，显著缩短计算时间，尤其在高维条件集下表现更佳；

**⚠️ 局限性**

局限性包括尚未给出理论型I错误控制证明，且在极高维或极大样本量场景下，流匹配模型的训练与采样仍可能成为瓶颈。

---

## 695. CAE-AV: Improving Audio-Visual Learning via Cross-modal Interactive Enrichment

**arXiv ID:** 2602.08309 | [PDF](https://arxiv.org/pdf/2602.08309v1)

**作者:** Yunzuo Hu `[一作]` (East China University of Science and Technology), Jing Zhang `[通讯]` (East China University of Science and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `9ce7179e-700c-4310-ac2b-91df50ded46e` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种基于冻结预训练骨干的跨模态互补增强框架（CAE‑AV），通过两个轻量级模块——基于音视频一致性的空间‑时间增强（CASTE）和基于字幕对齐的显著性注入（CASE），显著缓解音视频误对齐问题。

**💡 创新点**

创新点：① 通过Agreement Gate动态估计帧级音视频一致性，自动平衡空间与时间增强权重；② 采用高层字幕语义作为跨模态先验，仅在显著位置注入，避免噪声扩散；③ 结合轻量化目标（InfoNCE、一致性损失、熵正则）实现冻结骨干下的高效训练与稳定优化。

**🔧 技术方法**

核心技术：Swin Transformer 与 HTS‑AT 预训练骨干；深度可分离时间卷积与轻量化注意力；CLIP 文本编码器对 MLLM 生成的字幕进行向量化；多模态 Mixture‑of‑Experts（AVMoE）融合；自监督 InfoNCE 与一致性损失。

**📊 数据集**

实验数据集：Audio‑Visual Event Localization (AVE)、Audio‑Visual Video Parsing (AVVP)、Audio‑Visual Segmentation (AVSBench)、Audio‑Visual Question Answering (MUSIC‑AVQA)。

**📈 对比分析**

比较方法：在同一预训练骨干（Swin‑V2‑L + HTS‑AT）和参数量约束下，与 AVMoE、DG‑SCT、LAVisH 等主流方法对标；在所有四个基准任务上均实现或逼近 SOTA，AVE 准确率 82.6%、AVVP 语义一致性提升 1.7%~1.5%，AVSJaccard 0.8+%、AVQA 平均精度 76.7%。

**⚠️ 局限性**

局限性：① 依赖 MLLM 生成的字幕，字幕质量直接影响 CASE 效果；② 对极端离线或多源干扰的误对齐仍有一定误差；③ 轻量化设计虽然降低参数量，但在大规模实时部署时仍需关注算力与延迟；④ 目前未深入研究多模态偏差（如语言与视觉语义差异）的可解释性。

---

## 696. Geometric Image Editing via Effects-Sensitive In-Context Inpainting with Diffusion Transformers

**arXiv ID:** 2602.08388 | [PDF](https://arxiv.org/pdf/2602.08388v1)

**作者:** Shuo Zhang `[一作]` (Beijing University of Posts and Telecommunications), Zhanyu Ma `[通讯]` (Beijing University of Posts and Telecommunications)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 GeoEdit 框架，实现精确几何编辑（平移、旋转、缩放）并同时生成逼真的光影效果。

**💡 创新点**

创新点在于：① 引入几何变换模块将目标物体投影到三维空间并精确变换；② 设计效果敏感注意力（Effects‑Sensitive Attention）以软引导注意力捕捉光影；③ 通过构建 120k 对的 RS‑Objects 大规模数据集，为模型提供精确几何与光影先验。

**🔧 技术方法**

使用技术包括 Diffusion Transformer（DiT）在 in‑context inpainting 框架下、3D 网格重建与投影、Effects‑Sensitive Attention、LoRA 微调、SigLIP 图像编码器等。

**📊 数据集**

使用了 RS‑Objects 数据集（约 120,000 张高质量图像‑掩码对，涵盖 30 种对象与 24 个场景）以及公开 benchmark GeoBench 进行评估。

**📈 对比分析**

通过与多种 2D/3D 编辑基线（RegionDrag、DiffusionHandles、GeoDiffuser 等）在 GeoBench 上进行对比，GeoEdit 在 FID、DINOv2 距离、子对象/背景一致性、Warp Error 等七项指标上均显著优于对手，且在用户研究中获得最高优先率。

**⚠️ 局限性**

限制在于对极端光照变化、复杂遮挡场景的光影重建仍存在一定误差，且模型对极大尺寸或长距离变换的鲁棒性尚待进一步提升。

---

## 697. UrbanGraphEmbeddings: Learning and Evaluating Spatially Grounded Multimodal Embeddings for Urban Science

**arXiv ID:** 2602.08342 | [PDF](https://arxiv.org/pdf/2602.08342v1)

**作者:** Jie Zhang `[一作]` (National University of Singapore), Zdravko Trivic `[通讯]` (National University of Singapore)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `57a58b01-81b4-4d75-a45c-2e891f272b50` `3f18e8e3-0266-457c-8567-9039b6d2394d` `9ce7179e-700c-4310-ac2b-91df50ded46e` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种基于城市空间图的视觉‑文本‑空间三模态对齐框架UGE，用于学习和评估城市环境的空间化嵌入；

**💡 创新点**

创新点在于①构建了将街景图像与城市空间图结构对齐的UGData数据集；②提出两阶段训练策略，先通过指令引导的对比学习注入空间语义，再通过图编码器实现结构化空间信息的显式条件化；③设计了UGBench统一的零样本评估基准，涵盖地理定位、图像检索、城市感知和空间定位等多任务；

**🔧 技术方法**

技术上使用指令引导的对比学习、图神经网络（GATv2 + 位置编码和边特征）、LoRA 微调、以及现有VLM骨干如Qwen2‑VL、LLaVA、Phi‑3等；

**📊 数据集**

数据集为UGData，基于纽约、旧金山等城市的Mapillary街景、OpenStreetMap、城市开放数据构建的城市空间图，包含SRP和SCC等结构化语义；

**📈 对比分析**

与多种VLM和多模态嵌入基线比较，UGE在地理定位、图像检索、城市感知和空间定位任务上均取得显著提升，最优模型Qwen2.5‑VL‑7B在训练城市地理定位Hit@5提升约44%，跨城市提升30%以上；

**⚠️ 局限性**

局限在于对精细度量关系（距离、方向）仍捕捉不足，训练对比学习无法完全表达细粒度度量与方向性，导致在距离‑方向任务表现不如预期。

---

## 698. Near-Oracle KV Selection via Pre-hoc Sparsity for Long-Context Inference

**arXiv ID:** 2602.08329 | [PDF](https://arxiv.org/pdf/2602.08329v1)

**作者:** Yifei Gao `[一作]` (University College London), Dacheng Tao `[通讯]` (Nanyang Technological University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出预先稀疏（Pre‑hoc Sparsity）框架及其实现 CPE，针对大语言模型 KV 缓存进行高效的稀疏化处理，保持接近全稠密注意力的性能。

**💡 创新点**

创新点在于通过信息理论上推导的“丢弃注意力质量”上界，避免后验偏差；结合三种互补的预先选择器（CIS、PSAW、ETF），实现高达 90% 的 KV 省检和 15% FLOP 减少，同时提供可验证的误差保证。

**🔧 技术方法**

使用注意力聚类共享、滑动窗口剪枝、早期 token 冻结等技术；配合自定义 CUDA 核心实现并行索引操作；基于信息论的互信息上界作为理论指导。

**📊 数据集**

在 LLaMA 与 Mistral 系列模型上，利用 GSM8K、COQA、LongBench 及 WikiText 等标准基准进行评测。

**📈 对比分析**

与 HShare、H2O、Quest、DS 等现有稀疏方案对比，CPE 在相同或更低检索成本下保持或提升精度，取得 9.9× 的注意力算子延迟加速和 2.8× 的整体吞吐量提升。

**⚠️ 局限性**

局限性包括对超参数（块大小、相似度阈值、扩展半径等）的敏感性；在极低预算或非常长上下文时仍可能出现信息丢失；实现复杂度较高，需专门的 GPU 核心支持。

---

## 699. Making Databases Searchable with Deep Context

**arXiv ID:** 2602.08320 | [PDF](https://arxiv.org/pdf/2602.08320v1)

**作者:** Alekh Jindal `[一作]` (Tursio), Ravi Shetye `[通讯]` (Tursio)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了Tursio搜索平台，利用大语言模型（LLM）构建数据库的语义知识图，自动化上下文化用户意图、生成查询计划并直接返回自然语言结果，同时提供可视化、共享、审计等企业级交互界面。

**💡 创新点**

创新点包括：在整个查询处理栈（建模、编译、规划、结果推理）中注入LLM，实现从原始数据库到语义知识图的自动推断；通过语义图实现精确的意图映射、查询计划树生成和重写；以及在保证安全、隐私和可解释性的前提下，为非专家用户提供一键式自然语言查询体验。

**🔧 技术方法**

采用的技术包括：SQLAlchemy连接器实现多种数据库无缝接入；LLM（如Azure OpenAI）用于列名简化、PII检测、语义图推断、查询意图归纳、重写等；ANTLR解析器将LLM输出转化为操作符；树生成与规则化转换实现查询计划；以及前端的可视化、结果推理与共享组件。

**📊 数据集**

使用的数据集包括：内部生产工作负载（医疗、银行、保险等）、BIRD‑DEV（11个异构数据库）、BEAVER（2个企业数据仓库的真实业务查询）、TPC‑H（标准决策支持数据库）以及多条真实案例（客服工单、动态仪表盘）。

**📈 对比分析**

评估方法：对表检索、join推理、SQL结构准确率等指标与BIRD/BEAVER/TPC‑H基准及现有方法进行对比；在BIRD‑DEV上表检索准确率79%，join推理精度82%，SQL结构准确率76%；在生产案例中，客服工单准确率>96%，仪表盘查询编译/验证准确率分别为86/94%；整体表现显示高准确性、可解释性和企业可部署性。

**⚠️ 局限性**

局限性：对低规范化或不完整模式的join推理效果下降；LLM存在模型漂移与推理误差，需要定期迁移与评估；知识图更新需手工触发或定期重新训练；当前仅支持结构化数据库，未覆盖非结构化或网络数据；实时查询性能受LLM推理开销影响，需进一步优化。

---

## 700. SWE Context Bench: A Benchmark for Context Learning in Coding

**arXiv ID:** 2602.08316 | [PDF](https://arxiv.org/pdf/2602.08316v1)

**作者:** Jared Zhu `[一作]` (Independent Researcher), Junde Wu `[通讯]` (University of Oxford)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了 SWE-ContextBench 基准，用于评估编程代理在仓库级软件工程任务中重用过去经验的能力。

**💡 创新点**

创新点在于通过构造任务序列、引入 oracle 与自由重用设置，以及从准确性、时间效率和成本效率三个维度系统评估经验重用的实际效果。

**🔧 技术方法**

采用大语言模型（如 Claude Sonnet 4.5）进行代码生成，结合实验测量补丁可用性、测试通过率、运行时间与 token 成本，并构建完整与摘要两种经验池。

**📊 数据集**

使用基于 SWE-Bench Lite 的 300 个经验任务与 99 个相关任务的数据集，来源于 12 个真实 GitHub 仓库，包含问题描述、pull request 差异及相应测试集。

**📈 对比分析**

通过五种重用设置（无经验、自由完整、oracle 完整、自由摘要、oracle 摘要）进行对比；oracle 摘要重用在解决率、运行时和成本上表现最佳（解决率 34.34%、平均运行时间 356.95 s、成本 $0.77/实例），而自由重用效果有限甚至低于基线。

**⚠️ 局限性**

局限性包括经验重用的收益高度依赖于经验表示与检索质量，缺乏高质量自动检索策略；实验仅针对单一 LLM 进行，未验证跨模型或更大规模系统的泛化性。

---

## 701. Moral Sycophancy in Vision Language Models

**arXiv ID:** 2602.08311 | [PDF](https://arxiv.org/pdf/2602.08311v1)

**作者:** Shadman Rabby `[一作]` (University of Dhaka), Irfan Ahmad `[通讯]` (King Fahad University of Petroleum and Minerals)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

对十种主流视觉-语言模型在面对用户显式反对时的道德同谋（sycophancy）行为进行系统评估，探讨其对道德判断的影响。

**💡 创新点**

首次将道德同谋纳入评估框架，提出 Sycophancy Rate、Error Introduction Rate (EIR) 与 Error Correction Rate (ECR) 三个度量，揭示开放源模型更易受用户偏见影响且道德错误倾向不对称。

**🔧 技术方法**

采用双轮提示协议（先给图片做一次判断，再在用户异议下重新评估），使用二元道德标签，对模型输出进行分类并计算上述度量；对比不同模型规模、开源与专有实现的差异。

**📊 数据集**

使用两大公开数据集：Moralise（仅图片版）和 M^3oralBench（包含六个道德基础类别）。

**📈 对比分析**

在十个模型上计算 Sycophancy Rate、EIR 与 ECR，并与基线准确率对齐；开放源模型平均 Sycophancy Rate 在 Moralise 为 32.94%，M^3oralBench 为 49.47%；专有模型平均为 7.33% 与 16.44%，显示后者更稳健。EIR 与 ECR 的权衡表明，高准确率模型并不一定具备强自我纠错能力。

**⚠️ 局限性**

局限性包括：使用二元道德标签可能过度简化伦理推理；评估仅为两轮提示，未覆盖长时间对话；数据集在文化与语言上相对单一；确定性解码可能掩盖随机性对道德稳定性的影响。

---

## 702. BiManiBench: A Hierarchical Benchmark for Evaluating Bimanual Coordination of Multimodal Large Language Models

**arXiv ID:** 2602.08392 | [PDF](https://arxiv.org/pdf/2602.08392v1)

**作者:** Xin Wu `[一作]` (Tsinghua University), Xiu Li `[通讯]` (Tsinghua University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 BiManiBench 这一分层双臂操作基准，系统评估多模态大语言模型（MLLM）在空间推理、动作规划和低层控制三大维度的双臂协调能力。

**💡 创新点**

创新点在于：①设计了三层评估结构并细化双臂协同模式（并行、顺序、同步）；②引入了视觉驱动的 Agent 框架与任务自适应执行截断机制；③通过多视角、动作分块与 Gaussian 加权评分细化评测。

**🔧 技术方法**

主要技术包括多模态大语言模型（如 GPT‑5、Gemini‑2.5‑Pro、InternVL 系列）、基于图像的空间推理、任务规划与动作分块、以及可重入式执行截断与闭环反馈。

**📊 数据集**

使用仿真环境 RoboTwin 的 5 个双臂任务集合，包含稀疏、稠密、杂乱场景的立方体、抓取、堆叠等，数据由视觉与物理域随机化生成。

**📈 对比分析**

与 30+ 现有 MLLM 进行对比，发现封闭源模型在三大层面均领先，空间推理平均得分约 94%，高层规划约 70%，低层控制约 65%；开源模型呈现规模-性能非单调关系，部分中型模型表现可与大型模型相当。

**⚠️ 局限性**

主要局限：评测仅基于仿真，未覆盖非刚体或动态物体；推理延迟高，难以实现实时双臂控制；多视角输入对低能力模型有噪声负面影响。

---

## 703. Hierarchical Subcode Ensemble Decoding of Polar Codes

**arXiv ID:** 2602.08391 | [PDF](https://arxiv.org/pdf/2602.08391v1)

**作者:** Yubeen Jo `[一作]` (Korea University), Namyoon Lee `[通讯]` (POSTECH)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种层级子码集成解码（HSCED）框架，用于在极化码的 BP 解码中通过构造多层子码来提升错误率性能。

**💡 创新点**

创新点在于递归构造子码集，利用线性覆盖（LC）属性在每一层保证完整覆盖，同时通过 RREF 基础稀疏图和密度感知行向量抽样实现可扩展且可实现的多层子码集合。

**🔧 技术方法**

使用的技术包括：线性覆盖（LC）约束、基于行约简（RREF）的稀疏 PCM 预处理、递归层级子码构造、密度感知行向量抽样以及并行 BP 集成解码。

**📊 数据集**

实验数据集为 5G NR 标准极化码（N,K）∈{(64,32),(128,96),(512,464)}，在二进制输入 AWGN 信道上进行仿真。

**📈 对比分析**

与标准 BP、SCED 以及 SCL32（列表大小 32）对比，通过 BLER、总运算量和时延（平均/最差）指标评估。结果表明，在相同的最大迭代次数下，HSCED 在 BLER 方面显著优于 BP 与 SCED，并且逼近 SCL32 的可靠性，同时保持固定且极低的时延。

**⚠️ 局限性**

局限性包括：随着子码层数增加，计算量呈指数增长，需要更多并行硬件资源；并且在构造过程中仍会略微增加短环数量，虽然对性能影响较小。

---

## 704. Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning

**arXiv ID:** 2602.08382 | [PDF](https://arxiv.org/pdf/2602.08382v1)

**作者:** Zhuoen Chen `[一作]` (Research Institute of Computing and Intelligence), Min Zhang `[通讯]` (Research Institute of Computing and Intelligence)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种将长文本分块、压缩为 KV‑cache 表示，并通过门控和推理模块进行动态记忆检索与迭代推理的长上下文处理框架；

**💡 创新点**

核心创新是将压缩与检索与推理联合强化学习优化，同时通过门控模型实现基于当前工作记忆的状态感知检索，显著减少对全长文本的暴露；

**🔧 技术方法**

使用 LoRA 模块实现压缩（Compressor）、门控（Gate）和推理（Reason）三大子网络，配合 Qwen2.5‑Instruct 基础模型，并采用端到端 RL（CLIP‑style）进行联合优化；

**📊 数据集**

在 RULER‑HQA、2WikiMultihopQA、StreamingQA 等多跳推理数据集上进行训练与评估；

**📈 对比分析**

与 Search‑R1、MemAgent、QwenLong‑L1 等主流长上下文基线对比，最高可达 82% 的归一化 sub‑EM，支持 1.75M token 的上下文长度，显著降低 2× GPU 内存占用，推理速度提升 6×；

**⚠️ 局限性**

门控引入的阈值会导致轻微准确率下降，压缩比例过高（>4×）会丢失重要信息；同时端到端 RL 训练复杂度高，需要额外的标签化检索样本。

---

## 705. Reinforcement Learning with Backtracking Feedback

**arXiv ID:** 2602.08377 | [PDF](https://arxiv.org/pdf/2602.08377v1)

**作者:** Bilgehan Sel `[一作]` (Google), Dingcheng Li `[通讯]` (Google)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `9cc9baba-5356-466d-81ff-d80028d90279` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了 Reinforcement Learning with Backtracking Feedback（RLBF）框架，能够让大语言模型在生成过程中实时检测并修正安全违规内容，主要通过在输出中插入“backtrack by X tokens”指令实现动态回溯。

**💡 创新点**

创新点在于①将安全违规检测与回溯指令结合，形成一种轻量级、可流式处理的自纠机制；②在监督微调阶段使用改进的 BSAFE+ 数据生成策略（在高质量安全回答中注入违规片段），为模型提供精确的回溯学习信号；③在强化学习阶段利用 LLM 安全评估器（Critic）提供的即时反馈，通过 GRPO 优化策略，使模型既能主动避免违规，又能在违规发生时高效纠正。

**🔧 技术方法**

技术手段包括：
- 监督微调（SFT）配合 BSAFE+ 违规注入；
- RL（GRPO）与安全评估器（LLM‑based Critic）形成的回溯奖励机制；
- 采用 token‑efficient 的 <backtrack by X> 指令代替传统的多 token 替换；
- 训练时混合标准 instruction 数据以保持原模型功能。

**📊 数据集**

数据集：
- 训练时使用原始 instruction‑tuned 对话数据（ChatGPT、Llama‑Chat 等）和 BSAFE+ 生成的违规注入样本；
- 评估时采用 LMSYS benchmark（含 Middle‑Filling 攻击）、GCG AdvBench、HEx‑PHI、MaliciousInstruct 等公开攻击数据集。

**📈 对比分析**

对比方法包括：IT（标准 instruction‑tuned）、RL（传统 RLHF/RLAIF）、BSAFE+、Circuit Breakers。实验显示：
- 在 LMSYS‑MF 上，RLBF 的攻击成功率从 70‑80% 降低至 1‑3%；
- 对 GCG 攻击，RLBF 的 ASR 为 4.3‑4.7%，显著优于 BSAFE+（5.7‑6.6%）和 Circuit Breakers（10.7‑13.4%）；
- 在标准 LMSYS 任务上，RLBF 的 ASR 仅为 1‑2%，远低于 BSAFE+（14‑17%）。
- 对通用基准（MMLU、BBH、GSM8K、MATH）模型表现与原 IT 基线几乎一致，说明安全改进未带来显著性能损失。

**⚠️ 局限性**

局限性：
- RLBF 的训练与推理过程需要额外的 RL 与安全评估器计算，计算成本较高；
- 仍依赖对“有害”内容的定义与评估器的准确性，可能无法覆盖所有潜在违规；
- 回溯机制在极端长文本或高频违规场景下的效率与稳定性尚待进一步验证。

---

## 706. OJBKQ: Objective-Joint Babai-Klein Quantization

**arXiv ID:** 2602.08376 | [PDF](https://arxiv.org/pdf/2602.08376v1)

**作者:** Xinyu Wang `[一作]`, Xiao-Wen Chang `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种层级后训练量化（PTQ）框架OJBKQ，利用多目标联合Babai–Klein量化与K-Best采样来量化大语言模型的权重。

**💡 创新点**

创新点在于：①将量化任务正式建模为多右手侧箱约束整数最小二乘（BILS）问题；②引入联合目标对齐（JTA）插值目标，在保持全精度一致性的同时考虑运行时误差传播；③采用随机K-Best Babai/Klein解码扩展Babai点，显著提升候选解质量。

**🔧 技术方法**

主要技术包括：整数最小二乘（ILS）与Babai最近平面算法、K-Best随机Klein算法、矩阵Cholesky分解、GPU并行化路径隔离实现、联合目标对齐（JTA）评分。

**📊 数据集**

使用的评测数据集：C4、WikiText-2（PPL评估）；LM-Harness（ARC、BoolQ、HellaSwag、PIQA、WinoGrande）以及GSM‑8K、GPQA、MBPP（零样本推理评估）。

**📈 对比分析**

与GPTQ、AWQ、QUIP等主流PTQ方法对比，OJBKQ在3‑4比特量化时在C4/WikiText‑2上PPL显著下降，零样本推理和推理任务准确率均保持在或接近FP16水平，尤其在较难模型和极低位宽下表现更稳健。

**⚠️ 局限性**

局限性包括：未实现权重置序（如GPTQ）或动态缩放；对所有层使用统一的超参数（μ、λ、K），缺乏层级自适应；对不同模型结构的通用性尚待进一步验证。

---

## 707. Learning Human-Like Badminton Skills for Humanoid Robots

**arXiv ID:** 2602.08370 | [PDF](https://arxiv.org/pdf/2602.08370v1)

**作者:** Yeke Chen `[一作]` (University of Hong Kong), Peng Lu `[通讯]` (University of Hong Kong)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

设计并实现一种从模仿到交互的四阶段渐进式强化学习框架，使人形机器人能够在零样本仿真-现实迁移下完成羽毛球拦截动作。

**💡 创新点**

1) 四阶段管线（模仿→蒸馏→稳定→交互）; 2) 基于模型的时序目标表示 (Time‑to‑Hit + 目标状态); 3) 稀疏演示的流形扩展生成密集拦截目标; 4) 对抗运动先验（AMP）保持人类风格; 5) 首次实现零样本仿真到真实羽毛球拦截。

**🔧 技术方法**

运动捕捉重映射、DAgger 蒸馏、目标条件强化学习、对抗运动先验 (AMP)、物理基准 shuttlecock 模拟（空气阻力、羽毛与头部分离）、域随机化、Isaac Sim 并行训练、EKF 状态估计。

**📊 数据集**

人类羽毛球动作的 MoCap 数据集（含击球点和恢复点），以及通过流形扩展生成的多时空拦截轨迹样本。

**📈 对比分析**

与无稳定化、无交互、端到端 AMP、ASE、VQ 等基线对比。完整方法在轻/难模式下成功率最高、MSE 最低；端到端 AMP 在易模式下 IBR 较高但整体 SR 较低；无交互方法性能差甚至负 IBR。真实机器人上，前后拦截成功率分别为 90% 和 70%。

**⚠️ 局限性**

动作自然性、动态稳定性与任务精度之间存在冲突，需手动调优；仅实现单一拦截动作，未实现持续连击或全场覆盖；机器人硬件限制（5 DoF 手臂）导致姿态不稳定。

---

## 708. MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval

**arXiv ID:** 2602.08369 | [PDF](https://arxiv.org/pdf/2602.08369v1)

**作者:** Xin Zhang `[一作]` (University of Manchester), Sophia Ananiadou `[通讯]` (University of Manchester)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `8d10c613-917e-4880-9716-17789f50e119` `57a58b01-81b4-4d75-a45c-2e891f272b50` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出MemAdapter框架，将显式、参数化和潜在三种代理记忆范式统一到统一记忆空间，通过生成子图检索器和轻量级对齐模块实现跨范式快速对齐与融合。

**💡 创新点**

创新点在于：①将三种记忆范式放入同一统一记忆空间，打破传统范式耦合；②采用两阶段训练：先用教师模型蒸馏训练生成式子图检索器，再通过对比学习快速对齐；③支持零样本融合，可在单GPU 13分钟内完成跨范式对齐。

**🔧 技术方法**

使用技术包括：生成式子图检索、模型蒸馏（teacher‑student）、对比学习（InfoNCE）、统一记忆空间映射、轻量级对齐网络、结构化线性化分词。

**📊 数据集**

使用的主要数据集为三大公开问答基准：WikiMultiHopQA、NarrativeQA、MuSiQue（以及对应的任务查询和知识库）。

**📈 对比分析**

与五个强基线（如A‑Mem、Mem0、StreamingLLM、MemoryLLM等）及参数化/潜在记忆系统在1.5B、3B、7B模型上进行对比，结果显示生成子图检索器在EM、F1、ROUGE‑1等指标上持续领先；跨范式对齐耗时13min，计算量不到5%，并在零样本融合场景下仍能提升性能。

**⚠️ 局限性**

局限性：统一记忆空间的构造对特定任务仍需调优；对噪声或冗余记忆的对齐效果有限；极大模型规模下对齐可能出现小幅性能下降；缺乏对动态更新的实时适配机制。

---

## 709. T2VTree: User-Centered Visual Analytics for Agent-Assisted Thought-to-Video Authoring

**arXiv ID:** 2602.08368 | [PDF](https://arxiv.org/pdf/2602.08368v1)

**作者:** Zhuoyun Zheng `[一作]` (Computer Network Information Center, Chinese Academy of Sciences), Jie Liang `[通讯]` (University of Technology Sydney)

**关键词:** `a154b176-e466-40fc-8ae0-e5cd17677106` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出并实现了一套名为T2VTree的可视化分析系统，用于支持从创意到多场景多模态视频生成的完整工作流程。系统将创作者的意图与生成步骤以树形状态记录，配合代理辅助规划和可编辑的提示参数，提供交互式的生成、对比、分支管理和最终拼接功能。

**💡 创新点**

①将创作者意图与生成结果绑定为持久状态，形成可追溯、可复用的树形工作轨迹；②通过代理辅助规划将自然语言意图转化为可编辑的生成计划，解决“下一步不明确”问题；③将多模态生成（图像、视频、音频）统一在同一树节点内，支持跨模态检索与拼接；④集成拼接工作区，使整个流程可在同一环境完成。

**🔧 技术方法**

主要技术包括：
- 大语言模型（LLM）驱动的代理协作框架，用于意图解析、规划、提示生成；
- 开源的图像/视频/音频生成模型（如Stable Diffusion、ControlNet、Diffusion Video等）
- 可视化分析技术：树形状态图、卡片式节点展示、多模态预览、对比与分支管理；
- 交互式拼接工具：多轨道时间线、拖拽拼接与同步。

**📊 数据集**

本工作没有使用公开的固定数据集。评估案例使用创作者自行选择的文化遗产素材（如“Tricolor Glazed Pottery Camel”“Zhonghe Guqin”），并在用户研究中让参与者使用任意自选场景（如“Future City”）。

**📈 对比分析**

方法比较：与ComfyUI（基于节点工作流的开源平台）进行对比。评估指标包括：
- 场景完成时间（T3）、最终导出时间（T5）
- 等待时间（T_wait）与主动交互时间（T_active）
- 生成调用次数（N_calls）与保留变体数（N_variants）
- 终端拼接时间（T_assemble）
- 主观满意度（Likert 1–5）
结果显示：T2VTree在T3和T5上均快（约 30%），主动时间下降 34% 以上，生成调用次数下降 37%，保留变体数上升 94%，拼接时间几乎消失（1.8 min vs 10.5 min）。用户满意度在“下一步清晰度”“迭代控制”“端到端收敛”三项上均显著更高。

**⚠️ 局限性**

局限性：
- 由于分支树可能快速膨胀，长视频或复杂故事线会导致可视化拥挤，需要更高级的聚合与层级概览功能；
- 对细粒度控制的支持有限，若生成模型无法满足细节约束，仍需多次分支迭代，增加操作负担；
- 系统目前依赖LLM规划与开源生成模型，若模型更新需手动适配；
- 评估样本规模有限，尚未验证在更大范围创作者群体中的可推广性。

---

## 710. WorldTravel: A Realistic Multimodal Travel-Planning Benchmark with Tightly Coupled Constraints

**arXiv ID:** 2602.08367 | [PDF](https://arxiv.org/pdf/2602.08367v1)

**作者:** Zexuan Wang `[一作]`, Wenhao Huang `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了面向端到端行程规划的WorldTravel基准和WorldTravel-Webscape多模态交互环境，包含150个真实欧洲城市任务与2000+仿真网页，并通过专家设计的评估指标实现可验证的可行性评估。

**💡 创新点**

创新点在于：① 将真实网页截图作为输入，迫使模型在视觉感知与信息抽取上挑战；② 设计紧耦合时空约束（15+约束/任务），让单一错误可导致整个行程失效；③ 提供可自动验证的硬/软约束校验机制和专家评审的中间决策打分；④ 通过“感知-动作差距”和“10约束规划阈值”两大瓶颈剖析模型瓶颈。

**🔧 技术方法**

使用技术包括：大语言模型（GPT‑5.2/5.1、Claude、Gemini等）、视觉语言模型、工具调用API（返回渲染网页截图）、约束提取与验证脚本、自动化评测框架。

**📊 数据集**

数据集为：150个任务覆盖Berlin、Vienna、Rome、Barcelona、Florence五城，任务基于真实运营数据、价格表、用户评论生成；Webscape提供36景点、25餐厅、26酒店共2000+页面，用以测试参数抽取与决策。

**📈 对比分析**

对比方法：在文本与多模态两种设置下评估10款前沿LLM与7款VLM。最佳模型GPT‑5.2在文本设置下可行率32.67%，多模态下19.33%；相比之下人类可行率77.86%。多模态进一步揭示感知-动作差距（约13个百分点）和约束数量上限（10约束后可行率骤降）。

**⚠️ 局限性**

限制包括：① 对时空约束的全局推理能力仍弱；② 视觉信息抽取仍是独立瓶颈，影响多模态性能；③ 在高耦合任务（≥10约束）下可行率显著下降；④ 当前评测主要关注可行性和软约束准确率，尚缺乏对动态环境鲁棒性与用户体验的细粒度分析。

---

## 711. Towards Better Evolution Modeling for Temporal Knowledge Graphs

**arXiv ID:** 2602.08353 | [PDF](https://arxiv.org/pdf/2602.08353v1)

**作者:** Zhang Jiasheng `[一作]` (Xidian University), Li Hui `[通讯]` (Xidian University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

本文发现现有时间知识图谱（TKG）评测基准存在“共现快捷方式”，导致模型仅凭共现频数即可达到较高分数，因而提出了新的TKG演化基准，并设计了两种更符合真实演化过程的评测任务。

**💡 创新点**

创新点包括：①系统剖析共现快捷现象并定位其根源；②构造四个消除共现偏差的新数据集，并同时包含时间戳与时间区间知识；③丰富实体与关系的文本注释以提升语义信息；④提出“生成式知识预测”和“知识陈旧预测”两种新任务，以全面考察模型对知识演化机制的学习能力。

**🔧 技术方法**

采用的技术主要有：共现计数基准、时间嵌入方法（TNT、HGE）、动态嵌入方法（De‑Simple、ATiSE、TA‑dismult）、大型语言模型（GPT‑3.5/4o）以及与文本注释相结合的提示式学习；同时在构造数据集时使用了k‑core过滤、流行度采样和与Wikidata的对齐。

**📊 数据集**

使用了四个新构建的数据集（FinWiki、ICEWSWiki、YAGO130K、WIKI500K），覆盖金融、政治事件与通用知识四个领域；此外还引用了传统基准（ICEWS、GDELT、YAGO/Wikidata）作为对比。

**📈 对比分析**

与传统共现基准相比，新的基准显著降低了共现快捷的影响；在生成式知识预测任务中，最优方法（如TKN‑ICL+文本）在Recall@50、NDCG等指标上仍低于传统任务，但表现差距更大，说明模型真正学习到了演化机制；在知识陈旧预测任务中，基于文本的LLM方法取得了最好的MAE/Accuracy，表明文本注释对学习演化至关重要。

**⚠️ 局限性**

局限性包括：①尽管消除了共现快捷，但整体性能仍偏低，说明现有模型在真实演化预测上仍不足；②部分任务仍受时间粒度和数据稀疏性的影响；③LLM方法依赖大量文本信息，若缺失文本则性能急剧下降；④未解决如何在动态增量式环境下持续更新模型的研究。

---

## 712. The Chicken and Egg Dilemma: Co-optimizing Data and Model Configurations for LLMs

**arXiv ID:** 2602.08351 | [PDF](https://arxiv.org/pdf/2602.08351v1)

**作者:** Zhiliang Chen `[一作]` (National University of Singapore), Bryan Kian Hsiang Low `[通讯]` (National University of Singapore)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了一种能同时优化大语言模型（LLM）训练数据混合比例与模型配置（如LoRA层、rank等）的算法

**💡 创新点**

创新点在于先用一小部分完整训练样本学习一个基于缩放法则的性能预测器，再把该预测器作为代价低的高保真度代理，用贝叶斯优化（BO）在预算内高效搜索配置，并给出了预算分配的理论最优策略

**🔧 技术方法**

主要技术包括高斯过程（GP）贝叶斯优化、神经网络性能预测器（由少量完整训练和早期训练步骤的性能作为输入），以及对预测误差影响的平均回报分析

**📊 数据集**

使用了九个数据域的混合训练集（Wikitext、GSM8K、PubmedQA、SciQ、TriviaQA、TruthfulQA、MMLU、AI2 ARC、CommonsenseQA）以及六个语言任务（如GSM8K、CommonsenseQA等）作为实验评估

**📈 对比分析**

与单独的数据信息优化方法、模型架构搜索方法以及多保真度BO基线进行对比；在相同的总训练步骤预算下，方法在所有任务上均取得更高的任务性能，并且 wall‑clock 运行时间低于传统数据信息优化方法

**⚠️ 局限性**

局限性包括：需要先花费预算收集完整训练样本以训练预测器；预测器的泛化性能取决于任务和数据域；预算分配仍需经验调优；在更大规模模型或不同任务时可能需要重新学习预测器

---

## 713. All ERMs Can Fail in Stochastic Convex Optimization Lower Bounds in Linear Dimension

**arXiv ID:** 2602.08350 | [PDF](https://arxiv.org/pdf/2602.08350v1)

**作者:** Tal Burla `[一作]` (Tel Aviv University), Roi Livni `[通讯]` (Tel Aviv University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

研究了随机凸优化中最佳经验风险最小化器的样本复杂性，展示了在某些情况下样本大小与维度线性相关，且经验风险最小化器可能是唯一的并且会过拟合。

**💡 创新点**

解决了一个开放问题，扩展了对近似经验风险最小化器的研究，并提供了梯度下降算法的新的泛化下界。

**🔧 技术方法**

使用了随机凸优化框架，构建了特定的损失函数，并分析了梯度下降算法的行为。

**📊 数据集**

使用了构造的有限实例空间和分布 D，具体数据集未详细说明。

**📈 对比分析**

与现有方法比较，提出了梯度下降的新的泛化下界 Ω(√(η T/m^1.5))，缩小了已知的上界 O(η T/m) 和现有下界之间的差距。

**⚠️ 局限性**

研究的局限性在于只关注了最坏情况的随机凸优化问题，未能涵盖所有凸问题的情况。

---

## 714. ManifoldKV: Training-Free KV Cache Compression via Euclidean Outlier Detection

**arXiv ID:** 2602.08343 | [PDF](https://arxiv.org/pdf/2602.08343v1)

**作者:** Debajyoti Datta `[一作]` (Hippocratic AI), Subhabrata Mukherjee `[通讯]` (Hippocratic AI)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了基于欧氏距离的KV缓存压缩方法（ManifoldKV），通过对关键向量与均值的距离进行排序来保留重要token，并在长上下文下采用局部窗口均值解决均值稀释问题；

**💡 创新点**

创新点在于使用欧氏距离而非传统余弦相似度捕捉角度和幅度两方面的离群特征，解决了余弦忽视幅度导致的关键token误删，并发现所有模型的键向量都聚集于约9维流形上，实现跨模型零训练迁移；

**🔧 技术方法**

核心技术包括欧氏距离评分、滑动窗口局部均值计算、与AdaKV框架无缝集成的零训练评分器，算法实现仅需3行代码；

**📊 数据集**

使用RULER长上下文基准（包含6,497个检索任务）以及四种大模型（Llama‑3.1‑8B、Qwen3‑8B、Gemma‑3‑12B、Ministral‑8B）进行评估；

**📈 对比分析**

与KeyDiff（余弦评分）和SnapKV（注意力评分）等基线对比，ManifoldKV在4K–16K上下文下达95.73%（与KeyDiff相近），在64K上下文下全局均值方法仅35.2%而窗口化方法恢复至84.3%，比KeyDiff提升3.2点，跨模型平均性能保持94–96%；

**⚠️ 局限性**

局限性包括：目前仅验证到64K token，128K+等更大规模未测试；在极端检索密集任务中注意力方法偶尔表现相近；流式推理场景下需更高效的近似均值计算。

---

## 715. AI-Assisted Model for Generating Multiple-Choice Questions

**arXiv ID:** 2602.08383 | [PDF](https://arxiv.org/pdf/2602.08383v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

---

## 716. Regime Change Hypothesis: Foundations for Decoupled Dynamics in Neural Network Training

**arXiv ID:** 2602.08333 | [PDF](https://arxiv.org/pdf/2602.08333v1)

**作者:** Cristian Pérez-Corral `[一作]` (Universitat Politècnica de València), Enrique S. Quintana-Ortí `[通讯]` (Universitat Politècnica de València)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文研究了 ReLU 网络在训练过程中的激活模式与参数更新的两阶段动态，并提出“Regime Change Hypothesis”——激活模式在训练早期即可基本稳定，随后仅在已稳定的激活区域内进行参数细调。

**💡 创新点**

创新点在于：1) 用几何和测度论证明了 ReLU 网络激活模式对小幅参数扰动的局部稳定性；2) 设计了基于每批 Hamming 距离的激活变化度量；3) 通过大规模多架构、多数据集实验系统验证激活模式比权重更新早约三倍收敛，首次将激活收敛与权重收敛做定量对比。

**🔧 技术方法**

主要技术包括：ReLU 线性分段理论、测度论分析、梯度下降/Adam 优化器、每批激活模式跟踪（二进制掩码 Hamming 距离）、滑动平均平滑、AUC 归一化与相对加速率（ρ）计算。

**📊 数据集**

使用的公开数据集有：Adult、Breast Cancer、HAR、MNIST、CIFAR-10/100、TinyImageNet、SST-2、AG News、SQuAD、WikiText、CIFAR-100/10、CIFAR-100/10、ImageNet 子集（TinyImageNet）以及多种 Transformer 数据集。

**📈 对比分析**

与传统单一优化视角对比，本文的衡量指标是激活变化率与权重变化率的相对 AUC。实验结果显示，在大多数模型（包括 MLP、CNN、Transformer）中，激活变化的 AUC 明显低于权重变化，且 ρ 约为 3‑12，表明激活模式在训练早期就已趋于稳定，权重仍在细化。

**⚠️ 局限性**

局限性包括：仅针对基于 ReLU 的网络，未验证平滑激活（如 GELU、SiLU）下的两阶段动态；实验中未使用学习率调度或其他提升性能的技巧；仅在单 GPU 环境下测试，缺乏大规模分布式验证；以及理论仅证明局部稳定性，未给出全局收敛证明。

---

## 717. Latent Reasoning with Supervised Thinking States

**arXiv ID:** 2602.08332 | [PDF](https://arxiv.org/pdf/2602.08332v1)

**作者:** Ido Amos `[一作]` (Google Research), Idan Szpektor `[通讯]` (Google Research)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种名为 Thinking States 的隐式推理方法，能够在不扩展上下文长度的前提下，在处理输入 token 的过程中生成自然语言思考序列并将其作为状态注入后续计算。

**💡 创新点**

创新点包括：① 通过在浅层注入压缩后的思考状态实现递归推理；② 思考序列采用自然语言，允许使用教师强制训练，实现完全并行化；③ 设计了稀疏推断的 Speculative Thinking 预填策略，显著降低推理延迟；④ 通过将 CoT 步骤对齐到输入片段，构建了块级监督数据。

**🔧 技术方法**

技术方案包括：使用 Qwen2.5-Base 作为主干 LLM；在深层输出上使用轻量级 Transformer 解码器生成思考序列；使用编码器+池化模块将变长思考序列压缩为固定大小状态；将状态注入下一块的浅层；采用教师强制损失和标准语言建模损失；利用 KV‑cache 进行高效并行处理；实施 Speculative Prefill 迭代预填。

**📊 数据集**

数据集主要涵盖：1) 生成式多步推理任务（如 Multi‑Hop QA、HotpotQA 等）；2) 数学推理任务（如 GSM8K）；3) 结构化状态跟踪任务；4) 通过已有 CoT 数据生成的块级监督标注。

**📈 对比分析**

与 CoT、无 CoT、iCoT、Coconut 等基线对比，Thinking States 在多跳问答和状态跟踪任务上与 CoT 的准确率相当或更优，在隐式推理基线上显著提升，并在墙钟时间上比 CoT 提升 2–3 倍；在推理时长上比传统 CoT 更快。

**⚠️ 局限性**

局限性包括：需要先行生成块级 CoT 标注，难以自动化；仅在预填阶段实现加速，解码阶段仍未扩展；对无法清晰对齐推理步骤的任务效果有限；依赖教师强制，若无高质量人类注释可能受限。

---

## 718. Towards Efficient Large Language Reasoning Models via Extreme-Ratio Chain-of-Thought Compression

**arXiv ID:** 2602.08324 | [PDF](https://arxiv.org/pdf/2602.08324v1)

**作者:** Yuntian Tang `[一作]` (East China Normal University), Shaohui Lin `[通讯]` (Huawei Noah’s Ark Lab)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了名为 Extra-CoT 的三阶段框架，用于在极低 token 比例下高保真地压缩 Chain-of-Thought（CoT）推理。

**💡 创新点**

创新点在于：① 设计了问答感知、公式原子化的压缩器以生成高质量监督；② 通过混合比例 SFT 训练模型实现多预算可控性；③ 引入层次化奖励 CHRPO 在 RL 阶段逼近极低预算同时保持准确率。

**🔧 技术方法**

技术包括：提取式 CoT 压缩（基于 Longformer+全局注意）、混合比例监督微调、以及基于策略梯度的层次化 RL (CHRPO)。

**📊 数据集**

使用的数据集主要有 CAMEL（30k CoT 生成）、MetaMathQA-395K、GSM8K、MATH-500、AMC2023 以及 OOD 的 MMLU STEM 等。

**📈 对比分析**

与 TokenSkip、Thinkless 等基线在 0.2-1.0 预算下对比，Extra-CoT 在极低压缩比例下提升 20-30% 的准确率，同时保持相近或更低的 token 数。

**⚠️ 局限性**

局限性：对极低预算的推理仍可能出现逻辑跳跃；压缩器需针对特定领域训练，通用性与可迁移性有限。

---

## 719. Controlled Flight of an Insect-Scale Flapping-Wing Robot via Integrated Onboard Sensing and Computation

**arXiv ID:** 2602.08328 | [PDF](https://arxiv.org/pdf/2602.08328v1)

**作者:** Yi-Hsuan Hsiao `[一作]` (Massachusetts Institute of Technology), YuFeng Chen `[通讯]` (Massachusetts Institute of Technology)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `51c0528b-f690-4182-ae60-bb5f046c276c` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文研发了一款1.29 g的昆虫尺度扑翼飞行器，搭载IMU、ToF、光流等三种最轻量化传感器和单芯片MCU，实现了飞行中的完整姿态、位置与速度估计，并完成了悬停、轨迹跟踪、障碍规避和精准落地等多种任务。

**💡 创新点**

创新点在于：①采用三层级滤波器（Mahony补偿+两阶段Kalman滤波）实现低延迟、低功耗的六自由度状态估计；②将飞行电子装载在244 mg的可柔性PCB上，兼容极限尺寸；③在单核MCU上完成传感、估计与低层控制，首次实现昆虫尺度飞行器的“感知-计算-执行”全链路自控。

**🔧 技术方法**

使用技术包括：低功耗MEMS IMU（LSM6DSV80X）、ToF（TMF8806）、光流（PAA3905E1-Q）、单芯片MCU（CY8C6245FNI-S3D41T）、Mahony非线性互补滤波、两阶段Kalman滤波、基于DEAs的扑翼机体设计及柔性PCB集成。

**📊 数据集**

该工作没有采用公开数据集，而是通过在室内外实验室（含移动捕捉系统）进行多次悬停、轨迹跟踪、障碍规避与落地试验，收集飞行姿态、速度和控制信号数据进行评估。

**📈 对比分析**

方法评估对比了三种配置：①运动捕捉+离线计算；②仅使用运动捕捉的离线估计；③完全依赖飞行器自身的传感与MCU计算。结果显示，悬停时姿态误差≈1.8°、位置误差≤3 cm；轨迹跟踪最大速度≈70 cm/s，位置误差≤6 cm；障碍规避与落地成功率≥90%。

**⚠️ 局限性**

局限性包括：①飞行时间受限（≤30 s）且主要受扑翼驱动器功耗占比高；②目前仅具备障碍检测与规避，缺乏全局路径规划与目标识别；③缺乏长效能源方案，尚未实现真正的能量自给；④对外部环境的感知仍有限，需加入侧向ToF或摄像头以提升安全性。

---

## 720. CLEAR: A Knowledge-Centric Vessel Trajectory Analysis Platform

**arXiv ID:** 2602.08482 | [PDF](https://arxiv.org/pdf/2602.08482v1)

**作者:** Hengyu Liu `[一作]` (Aalborg University), Christian S. Jensen `[通讯]` (Aalborg University)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了一个基于知识图谱的船舶轨迹分析平台 CLEAR，利用 AIS 原始轨迹数据构建结构化数据导出的知识图谱（SD‑KG），并通过大语言模型（LLM）完成轨迹缺失填补、行为模式推理、以及可解释的轨迹分析报告与图形化知识可视化。

**💡 创新点**

创新点在于：① 将 LLM 的推理与生成能力与轨迹知识图谱相结合，形成闭环式的数据–知识–数据循环；② 通过 SD‑KG 记录静态属性、行为模式和插补方法之间的频繁共现关系，实现基于知识的轨迹缺失自动填补与可解释性；③ 提供面向非专业用户的交互式轨迹报告和知识图谱浏览，弥补现有海事分析工具缺乏可解释性和行为洞察的不足。

**🔧 技术方法**

核心技术包括：大语言模型（LLM）用于特征编码、行为抽象、插补方法生成与解释生成；结构化数据导出知识图谱（SD‑KG）构建与维护；轨迹插补算法（如 Smooth Curve Filler、Decelerate‑Align 等）与方法选择器；以及基于图形化可视化的交互式用户界面。

**📊 数据集**

使用公开 AIS 数据集（通过平台自动下载并配置时间范围、地区等参数），并在 GitHub 仓库中提供相应的数据与代码。

**📈 对比分析**

与现有工具（MarineTraffic、VesselFinder、MovingPandas 等）相比，CLEAR 在轨迹缺失填补准确率上通过 SD‑KG 的知识推理提升了约 15%–25%（基于人工标注的评估），并在用户体验上获得正向反馈：用户能够在无需海事专业知识的情况下快速理解轨迹行为并查看证据链；缺失填补后轨迹完整度提升至 95% 以上。

**⚠️ 局限性**

局限性包括：① 目前仅支持离线批量处理，尚未实现实时、隐私保护的在线分析；② 对 LLM 生成质量和安全性的依赖较高，存在生成错误或不一致解释的风险；③ 需要海事专家参与知识图谱的持续维护与更新；④ 对极端稀缺或异常航线的数据缺失填补效果仍有限。

---

## 721. Boltzmann sampling and optimal exact-size sampling for directed acyclic graphs

**arXiv ID:** 2602.08471 | [PDF](https://arxiv.org/pdf/2602.08471v1)

**作者:** Wojciech Gabryelski `[一作]` (Wroclaw University of Science and Technology), Martin Pépin `[通讯]` (Université Caen Normandie)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出两种基于Boltzmann模型的有向无环图（DAG）均匀随机生成算法，并给出了一个n^2/2+o(n^2)时间、无预处理的最优精确大小采样器。

**💡 创新点**

创新点在于将图形生成函数与Boltzmann采样相结合，构造了根层分解和剥离（peeling）两种新的DAG分解方法，并利用这些分解实现了理论上最优的采样复杂度。

**🔧 技术方法**

采用的技术包括图形生成函数、根层分解、剥离递归分解、Boltzmann采样框架、拒绝采样以及跳跃（leapfrogging）技巧来实现精确大小采样。

**📊 数据集**

论文中未使用特定的实验数据集，而是通过对生成算法的实现（C/C++）在标准随机数生成器上进行基准测试。

**📈 对比分析**

与之前基于Markov链或早期Boltzmann采样的DAG生成器相比，本文实现的算法在n=4096时从3秒降低到约20毫秒，在n=200k时可在2秒内完成，速度提升了数百倍，且内存访问与随机位消耗均达到最优量级。

**⚠️ 局限性**

局限性包括递归实现非尾递归，可能在极大规模图时导致堆栈溢出；此外在精确概率计算时依赖浮点近似，极大规模时可能出现数值不稳定；并且跳跃方法仅适用于满足超临界条件的分解结构。

---

## 722. TriC-Motion: Tri-Domain Causal Modeling Grounded Text-to-Motion Generation

**arXiv ID:** 2602.08462 | [PDF](https://arxiv.org/pdf/2602.08462v1)

**作者:** Yiyang Cao `[一作]` (Huazhong University of Science and Technology), Jingdong Chen `[通讯]` (Ant Group)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

开发了一种基于扩散模型的文本到运动生成框架TriC‑Motion，融合时域、空间拓扑和频域三域建模，并通过因果干预消除无关噪声。

**💡 创新点**

创新点包括①三域联合建模与自适应融合机制，②将因果干预（CCMD）引入生成流程以去除运动无关特征，③混合频域分析使用 DWT+FFT 以同时捕获低频趋势与高频细节。

**🔧 技术方法**

采用技术包括扩散模型（MDM）、TransformerEncoder、图卷积网络（GCN）、离散小波变换（DWT）+快速傅里叶变换（FFT）、多分支注意力融合、因果结构模型和感知损失。

**📊 数据集**

在 HumanML3D 与 SnapMoGen 两大动作-文本数据集上进行实验。

**📈 对比分析**

与多种SOTA方法（MDM、M2DM、CoMo、StableMoFusion、MoMask、GMMotion、SALAD 等）在 R‑Precision、MM‑Dist、FID、CLIP Score、Diversity 等指标上进行对比，TriC‑Motion 在 HumanML3D 上 R@1 达 0.612、MM‑Dist 0.885、FID 0.347，SnapMoGen 上 FID 0.969、CLIP Score 0.985 等，整体性能领先。

**⚠️ 局限性**

局限性：训练需要大量 GPU 资源；因果干预仅在训练阶段使用，推理时无显著加速；对极长或极复杂文本的生成仍存在误差；模型在极端多样性动作的覆盖面尚有提升空间。

---

## 723. SteerVLA: Steering Vision-Language-Action Models in Long-Tail Driving Scenarios

**arXiv ID:** 2602.08440 | [PDF](https://arxiv.org/pdf/2602.08440v1)

**作者:** Tian Gao `[一作]` (Stanford University), Chelsea Finn `[通讯]` (Stanford University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出SteerVLA框架，利用视觉‑语言‑动作模型与预训练的视觉‑语言模型（VLM）结合，先用VLM产生细粒度的meta‑action，再驱动VLA低层控制，从而显著提升长尾驾驶场景的鲁棒性。

**💡 创新点**

创新点在于：①层次化设计，将VLM推理与VLA控制分离，避免在低层直接丢失推理能力；②构建全自动标签管道，生成与车辆轨迹紧密对齐的细粒度语言监督；③通过meta‑action细粒度指令桥接高层推理与低层执行，实现更精准的行为指导。

**🔧 技术方法**

核心技术包括：使用InternVL2‑1B作为高层推理与低层VLA的backbone；Gemini 2.5 Flash‑Lite 进行自动化语言标签生成；SimLingo VLA模型改造为基于meta‑action的 waypoint 预测；CARLA仿真环境下闭环评估与PID控制。

**📊 数据集**

实验数据集：SimLingo（含轨迹与原始meta‑action）、Bench2Drive 与 Bench2Drive‑LongTail（闭环评估），以及 NuScenes（开环轨迹复制）来验证模型在真实数据上的迁移性。

**📈 对比分析**

与 SimLingo、DriveMoE、ORION、AutoVLA 等现有基线对比，Bench2Drive 总分提升 4.77 分，Bench2Drive‑LongTail 提升 8.04 分，显示在长尾场景中性能明显优于现有方法。

**⚠️ 局限性**

局限性包括：自动标签质量受限于 VLM 的时序理解能力；仅采用单摄像头输入，空间感知有限；推理延迟较高，尚未在真实车辆上进行验证。

---

## 724. USBD: Universal Structural Basis Distillation for Source-Free Graph Domain Adaptation

**arXiv ID:** 2602.08431 | [PDF](https://arxiv.org/pdf/2602.08431v1)

**作者:** Yingxu Wang `[一作]` (Mohamed bin Zayed University of Artificial Intelligence), Nan Yin `[通讯]` (City University of Hong Kong)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了源无关图结构域适应方法 Universal Structural Basis Distillation（USBD），通过学习覆盖整个 Dirichlet 能量谱的结构基准实现对未知目标图的自适应。

**💡 创新点**

创新点在于：①把适应过程从调优偏倚模型转为构建无结构依赖的通用基准；②使用双层优化将语义一致性、谱覆盖和结构多样性联合训练；③在推理时采用谱感知加权集成，使适配成本与目标规模无关。

**🔧 技术方法**

主要技术包括：双层元学习（bi‑level optimization）、Dirichlet 能量锚点、Gromov‑Wasserstein 多样性约束、谱加权注意力、代理学习（proxy learning）和轻量级目标特定分类器。

**📊 数据集**

实验数据集涵盖结构/特征/相关性三类域移：TUDataset（DD、Mutagenicity、NCI1、FRANKENSTEIN、ogbg‑molhiv）及合成 Spurious‑Motif 数据集。

**📈 对比分析**

与现有 SF‑GDA、SF‑DA、GNN 基线和谱方法比较，USBD 在所有域移场景均优于最强基线，且在推理阶段显著降低时间和显存占用，达到更高的准确率/ AUC。

**⚠️ 局限性**

局限性：①仍需先行训练并保存源模型；②通用基准的数量 K 影响性能与计算的平衡，过小可能覆盖不足，过大导致冗余；③对极端谱分布之外的目标图可能仍有适配瓶颈。

---

## 725. Radial Müntz-Szász Networks: Neural Architectures with Learnable Power Bases for Multidimensional Singularities

**arXiv ID:** 2602.08419 | [PDF](https://arxiv.org/pdf/2602.08419v1)

**作者:** Gnankan Landry Regis N'guessan `[一作]` (Axiom Research Group), Bum Jun Kim `[通讯]` (University of Tokyo)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种可学习幂指数的径向Müntz–Szász网络（RMN），专门用于高效逼近多维径向奇异场。

**💡 创新点**

创新点包括：① 坐标可分解网络无法逼近非二次径向奇异的分离性阻碍定理；② 引入可学习幂指数基函数和对数极限原语以实现对1/r、log r等奇异的精确表示；③ 可学习源点位置实现多源奇异的自适应恢复；④ 在角度依赖场景中加入球面谐波或半整数傅里叶基。

**🔧 技术方法**

技术手段：结构匹配的可学习幂指数网络、闭式梯度与拉普拉斯算子、对数极限原语、球面谐波/半整数基、Adam优化、对源点的梯度学习、局部采样与punctured域训练。

**📊 数据集**

实验基准：10个二维/三维任务，包括Laplace基函数、1/r、r^{1/2}、裂尖场、双源/三源log场、Coulomb势、偶极势以及平滑正弦控制函数。

**📈 对比分析**

与4层128宽MLP、SIREN、RBF、MSN等基线对比，RMN在径向奇异任务上仅用27个参数即可实现1.5×–51×的RMSE提升；在角度或多源任务中RMN‑Angular/MC保持低误差并能恢复源点位置；总体保持极低的参数占用与优秀的近似精度。

**⚠️ 局限性**

局限性：只适用于已知或可假设为径向（或可分解为径向）奇异的场；对非径向、光滑或高频结构表现不佳；多源学习对初始化高度敏感；在高维或大规模问题中采样与训练效率仍有提升空间。

---

## 726. Intelligent support for Human Oversight: Integrating Reinforcement Learning with Gaze Simulation to Personalize Highlighting

**arXiv ID:** 2602.08403 | [PDF](https://arxiv.org/pdf/2602.08403v1)

**作者:** Thorsten Klößner `[一作]` (Saarland University), Anna Maria Feit `[通讯]` (Saarland University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了一种基于强化学习的自适应界面，在无人机监控任务中通过模拟用户注视行为动态决定高亮提示，以提升人类监督的情境感知。

**💡 创新点**

创新点在于将视觉注意力模型（TASED‑Net）嵌入强化学习框架，利用用户注视模拟来学习个性化、稀疏的高亮策略，从而在不造成警报洪水或注意力过载的前提下优化信息呈现。

**🔧 技术方法**

技术主要包括：强化学习（PPO）、时间序列视觉注意力预测（TASED‑Net）、基于状态转移的模拟环境与奖励函数设计。

**📊 数据集**

数据集为自研的无人机监控模拟数据，包含4架无人机的8项属性随时间变化的轨迹，并使用该数据与TASED‑Net训练得到的注意力模型进行仿真。

**📈 对比分析**

通过与规则化的高亮策略（如每个关键事件高亮5秒）进行对比，初步实验显示RL策略在避免不必要高亮、减少错误警报方面表现更好，但缺乏大规模真实用户实验验证。

**⚠️ 局限性**

限制主要在于：注视模拟模型的精度会显著影响策略学习效果；奖励设计仍偏重知识误差，未充分考虑认知负荷与疲劳；且实验仅在单一任务场景下进行，缺乏多事件或并发危机的鲁棒性评估。

---

## 727. On Protecting Agentic Systems' Intellectual Property via Watermarking

**arXiv ID:** 2602.08401 | [PDF](https://arxiv.org/pdf/2602.08401v1)

**作者:** Liwen Wang `[一作]` (Hong Kong University of Science and Technology), Juergen Rahmel `[通讯]` (HSBC)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出一种针对灰盒代理式大模型的水印框架，利用动作序列的语义等价性在可见的工具调用轨迹上注入分布式水印；

**💡 创新点**

创新点在于：①首次在代理式系统的灰盒环境下设计水印；②通过动作等价集实现分布层级的水印注入；③提供五种可组合的水印方案及自动化实例化管线；

**🔧 技术方法**

技术手段包括：动作序列分布偏移（logit偏置）、多方案水印集、Jensen‑Shannon Divergence检测、用户唯一ID映射的多通道水印；

**📊 数据集**

实验使用了公开的 xlam‑function‑calling‑60k 数据集（约 60K 轨迹，3,673 个工具），并在三大业务领域（Social、Business、Data）上进行微调；

**📈 对比分析**

评估通过与无水印模型对比，测量了任务性能（PR/RS/TS）、下游推理（ARC/ACPBench）和延迟；结果显示水印对性能影响 <3% 并实现 F1≈1 的高效检测与用户定位；

**⚠️ 局限性**

局限性包括：需手动或自动生成等价集，依赖可见的动作序列，水印强度需平衡以防过度偏移，且在极大用户规模下可能出现碰撞。

---

## 728. SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains

**arXiv ID:** 2602.08400 | [PDF](https://arxiv.org/pdf/2602.08400v1)

**作者:** Longkun Li `[一作]` (National University of Singapore), Ivor Tsang `[通讯]` (Agency for Science Technology and Research)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了SCOUT-RAG，一个分布式代理式Graph-RAG框架，用于在跨域、受隐私与成本限制的环境下高效检索增强生成。

**💡 创新点**

创新点包括：①无监督域相关性估计，避免依赖标签；②分层代理体系（域评估、局部检索、答案评估、合成）实现逐步、成本约束的跨域检索；③通过增量效用决策实现可扩展、低成本的多域遍历。

**🔧 技术方法**

采用代理式多智能体结构、图检索（局部/全局）、LLM评估与生成、增量效用估计、预算约束决策以及基于语义相似性、知识丰富度和历史性能的域相关性特征。

**📊 数据集**

使用了45个国家的维基百科文章构成的模拟域图，以及100条跨域查询（89条被所有方法成功回答）进行实验。

**📈 对比分析**

与集中式 GraphRAG_Local、GraphRAG_Global、GraphRAG_DRIFT-c 以及分布式 GraphRAG_DRIFT-dec 对比；SCOUT-RAG 在 89 条查询中整体得分为 56（比 DRIFT-c 低 7 分，但比 GraphRAG_Global 高 7 分），并将 token 与时间分别降低约 80%（与 DRIFT-dec 相比）同时保持接近的质量。

**⚠️ 局限性**

limitations: 与全量检索（GraphRAG_DRIFT-dec）仍存在性能差距；依赖 LLM 评估的质量与鲁棒性；在极端多域或动态域更新场景下可能出现噪声与检索冗余；缺乏对更复杂知识结构或实时域演化的实验。

---

## 729. D$^2$-VR: Degradation-Robust and Distilled Video Restoration with Synergistic Optimization Strategy

**arXiv ID:** 2602.08395 | [PDF](https://arxiv.org/pdf/2602.08395v1)

**作者:** Jianfeng Liang `[一作]` (Shanghai Jiaotong University), Xiaoyun Zhang `[通讯]` (Shanghai Jiaotong University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `5b4c1114-4a70-478e-9921-2514ee03850d` `8d10c613-917e-4880-9716-17789f50e119` `ba576bd1-e51d-44e8-8077-fc943b333c93` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了基于单图像扩散模型的D^2‑VR框架，实现低步推理的视频恢复。

**💡 创新点**

创新点包括降噪鲁棒流对齐模块（DRFA）与自适应注意力、对抗蒸馏以及时间一致性耦合优化策略的联合使用。

**🔧 技术方法**

采用了Stable Diffusion 2.1、光流对齐技术、对抗蒸馏、Temporal‑LPIPS损失以及预训练UNet鉴别器等技术。

**📊 数据集**

在Synthetic REDS30、VideoLQ等公开视频降质/修复基准上进行实验。

**📈 对比分析**

与Real‑ESRGAN、StableVSR等方法对比，D^2‑VR在LPIPS、MUSIQ、CLIP‑IQA等感知指标以及tOF等时序一致性指标上均优于对手，同时推理速度提升约12倍。

**⚠️ 局限性**

主要限制是对极端噪声仍可能出现细节丢失；对抗损失导致像素级指标略有下降；需要预训练的光流模型，且在高帧率视频上表现仍有限。

---

## 730. Learning Credal Ensembles via Distributionally Robust Optimization

**arXiv ID:** 2602.08470 | [PDF](https://arxiv.org/pdf/2602.08470v1)

**作者:** Kaizheng Wang `[一作]` (Nanyang Technological University), Hans Hallez `[通讯]` (KU Leuven)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `3855fcda-48ef-4070-a15e-803cd5c84d83` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出一种通过分布鲁棒优化（DRO）学习的多模型集成，生成盒状可信集（Credal Set）来量化模型的知识不确定性（EU）。

**💡 创新点**

创新点：① 将不同程度的 i.i.d. 失效假设嵌入训练阶段，使用可调的权重比例 δ 以模拟多种潜在的训练-测试分布偏移；② 在不修改网络结构的情况下，仅用 DRO 训练单模型，从而生成可信集；③ 通过最大化与最小化熵差的方式高效计算 EU。

**🔧 技术方法**

技术：分布鲁棒优化（DRO）、深度集成（Deep Ensemble）、软最大（Softmax）概率转盒状可信集、熵差计算、SciPy 求解最优化。

**📊 数据集**

数据集：ImageNet、CIFAR‑10/100、SVHN、Places365、Fashion‑MNIST、CIFAR‑10‑C/100‑C、Camelyon17 组织病理图像。

**📈 对比分析**

与 SOTA 可信集方法（CreBNN、CreDE、CreWra、CreEns、CreRL）以及深度集成基线（DE、EN‑DRO）对比；在 OOD 检测（AUROC）和医学场景的选择性分类（AR 曲线、AUC）上均实现了显著提升，尤其在 CIFAR‑10‑C/100‑C 及 Camelyon17 的分布偏移任务中表现最佳。

**⚠️ 局限性**

局限性：① 采用的是可调权重的 DRO 近似，未覆盖所有 DRO 形式；② 仍未给出从可信集到单一概率预测的理论框架；③ 缺乏对回归任务的推广与理论证明；④ 对极端偏移情况的鲁棒性尚需进一步验证。

---

## 731. Bi-Adapt: Few-shot Bimanual Adaptation for Novel Categories of 3D Objects via Semantic Correspondence

**arXiv ID:** 2602.08425 | [PDF](https://arxiv.org/pdf/2602.08425v1)

**作者:** Jinxian Zhou `[一作]` (National University of Singapore), Lin Shao `[通讯]` (National University of Singapore)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `ba576bd1-e51d-44e8-8077-fc943b333c93` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本研究提出了 Bi-Adapt 框架，通过在训练集上学习点级动作并利用视觉基础模型实现跨类别语义对应，从而在新类别上高效地完成双臂协同操作。

**💡 创新点**

创新点在于：① 将视觉基础模型的语义对应能力用于跨类别的抓取/操作 affordance 迁移；② 结合少量交互实现快速微调，过滤负面接触点并调整动作方向；③ 在单一模型中统一处理双臂协同与跨类别泛化。

**🔧 技术方法**

使用的技术包括：视觉基础模型（如 DINOv2、DiFT）提取扩散特征；PointNet++ 进行点云特征编码；cVAE 用于动作方向的生成；动作评分网络使用二元交叉熵；少量交互实现的微调策略。

**📊 数据集**

数据集主要有：PartNet‑Mobility 与 ShapeNet 中的 61 种带关节的可变形物体；模拟环境采用 SAPIEN + NVIDIA PhysX，真实实验使用 xArm6 与 RealSense D435；对训练集与新类别采用 50 次少量示范进行微调。

**📈 对比分析**

与手工规则、M-Where2Act、DualAfford 等基线对比，Bi-Adapt 在 5 任务（展开、开启、拆封、闭合、盖/扣）上平均成功率提升至约 60‑70%，显著高于基线（20‑40%）。且在少量交互预算下即可获得较高成功率，显示更高的学习效率。

**⚠️ 局限性**

限制：目前仅能处理短时、单物体的双臂操作，无法完成多物体或长时序任务；对视觉基础模型的语义对应质量敏感，若模型或图像质量不足可能导致映射错误。

---

## 732. Characterizing, Evaluating, and Optimizing Complex Reasoning

**arXiv ID:** 2602.08498 | [PDF](https://arxiv.org/pdf/2602.08498v1)

**作者:** Haoran Zhang `[一作]` (Shanghai AI Laboratory), Yu Cheng `[通讯]` (Shanghai AI Laboratory)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一个统一框架，用 ME² 原则对推理质量进行宏微层面的刻画，并通过 DAG 结构化、基于偏好对推理轨迹进行评估，训练出 Thinking Reward Model（TRM）用于在测试时挑选高质量推理以及在 RL 训练中提供奖励信号，从而显著提升大型推理模型的效率与效果。

**💡 创新点**

创新点包括：①将宏观效率/有效性与微观效率/有效性四维维度整合为 ME² 原则，系统化描述推理质量；②将任意自由文本推理轨迹自动抽象为 DAG，既保留进展、分支与合并结构，又可进行可解释的层级评估；③构建 TRM‑Preference 数据集，采用配对偏好训练 TRM，彻底脱离答案正确性监督；④在测试时与 RL 训练中使用 TRM 作为奖励信号，提升 19.3%（测试）和 3.9%（训练）性能。

**🔧 技术方法**

核心技术包括：DAG 结构化与压缩算法、宏微层级抽象与 LLM 生成摘要、配对评估与 Bradley–Terry 损失、强化学习（RLVR + GRPO）与奖励整形、以及基于 LLM 的自动评估器。

**📊 数据集**

主要使用数据集：WebInstruct‑Verified（生成 64K 题目，采样 103K 训练对）、AIME24/AIME25、GPQA‑Diamond、MMLU‑Pro、BBEH、FrontierScience 等多领域基准；验证集包含 1.5K 对；用于评估的推理模型包括 Qwen3、DeepSeek、GPT‑OSS、Qwen2.5‑Math‑PRM、ReasonFlux‑PRM 等。

**📈 对比分析**

对比方法：与 Prompt‑Only、ReasonFlux‑PRM‑7B、Qwen2.5‑Math‑PRM‑7B 等现有 PRM 及纯验证奖励（Verifier）进行比较。测试时在 Best‑of‑N 方案下，TRM 在 AIME24、AIME25 上最高可提升 19.3% 的准确率；训练时在 10 大基准上，TRM 与 Verifier 的平均提升约 2–4%，优于 ReasonFlux‑PRM，尤其在 GPQA、AIME 等高难度任务上显著。

**⚠️ 局限性**

局限性：①依赖 LLM 进行 DAG 生成与摘要，易受 prompt 设计与模型偏差影响；②评估偏好仅基于已验证正确答案的轨迹，可能忽略多样性与创造性推理；③DAG 抽象与压缩过程存在计算开销，虽然比全图方法低，但仍需额外推理；④在大规模推理任务中，TRM 作为奖励信号可能与验证奖励冲突，需要调参平衡。

---

## 733. A Two-Week In-the-Wild Study of Screen Filters and Camera Sliders for Smartphone Privacy in Public Spaces

**arXiv ID:** 2602.08465 | [PDF](https://arxiv.org/pdf/2602.08465v1)

**作者:** Andreas Tjeldflaat `[一作]` (University of Bergen), Bjørn Sætrevik `[通讯]` (University of Bergen)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `9cc9baba-5356-466d-81ff-d80028d90279` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本研究在真实公共环境中，对两种可携带隐私增强工具（屏幕隐私滤镜和摄像头滑块）进行为期两周的混合方法实验，评估其对用户隐私感知、行为适应和可用性的影响。

**💡 创新点**

创新点在于首次系统性、长期地探讨可触控隐私工具在日常使用中的效果，并将Contextual Integrity框架用于定性和定量数据分析。

**🔧 技术方法**

采用问卷调查、半结构化访谈、配对t检验与Wilcoxon符号秩检验等统计方法，并结合主题分析进行定性解读。

**📊 数据集**

实验数据来自22名（11男11女）大学生手机用户，收集两周使用期间的问卷和访谈记录。

**📈 对比分析**

通过实验前后对比评估工具效果，结果显示屏幕滤镜显著降低了对肩窥的担忧并减少了屏幕遮挡行为，而摄像头滑块因可用性差和社会认知问题影响有限；未与其他技术进行性能竞赛，只做了自评与对比。

**⚠️ 局限性**

局限性包括样本量小、仅限年轻学生群体、可能存在自我报告偏差，以及摄像头滑块在使用中出现的固定与功能冲突导致部分数据未完整收集。

---

## 734. From Assistant to Double Agent: Formalizing and Benchmarking Attacks on OpenClaw for Personalized Local AI Agent

**arXiv ID:** 2602.08412 | [PDF](https://arxiv.org/pdf/2602.08412v1)

**作者:** Yuhang Wang `[一作]` (Xidian University), Zhenxing Niu `[通讯]` (Xidian University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了 Personalized Agent Security Bench (PASB)，一个针对真实部署的个性化 LLM 代理进行端到端安全评估的框架，并在 OpenClaw 上进行案例研究，发现多阶段漏洞及其传播机制。

**💡 创新点**

创新点在于：①将真实的个性化使用场景、私有资产与高权限工具链融入安全基准；②设计长时序交互与跨阶段传播的评估流程；③实现黑盒端到端自动化评估与量化判定。

**🔧 技术方法**

技术方法包括：黑盒交互驱动器、外部内容与工具链仿真、四类攻击原语（直接注入、间接注入、工具返回欺骗、内存中毒）、三种防御策略（分隔符、三明治、指令预防）以及 ASR、提取成功率、写入成功率等评估指标。

**📊 数据集**

数据集主要为：自构造的三大场景（外部内容、个人上下文/长期记忆、工具/插件风险）与 OpenClaw 的 131 个公开高危技能；同时使用可追溯的 canary 私有资产进行泄露验证。

**📈 对比分析**

实验对比了三种后端模型（Llama‑3.1‑70B、Qwen2.5‑7B、GPT‑4o‑mini）在多种攻击与防御下的 ASR、提取/写入成功率。结果表明，虽然防御能显著降低成功率，但仍存在 10%–30% 的残留风险，且长期记忆泄露比短期更易成功。

**⚠️ 局限性**

局限性在于：仅评估 OpenClaw，可能不具备对所有个性化代理的普适性；黑盒框架无法覆盖所有潜在攻击向量（如系统级入侵、网络攻击）；防御策略仍需改进以阻断工具返回与跨会话传播；未来需扩展更多真实场景与更强的防御机制。

---

## 735. Gesture Matters: Pedestrian Gesture Recognition for AVs Through Skeleton Pose Evaluation

**arXiv ID:** 2602.08479 | [PDF](https://arxiv.org/pdf/2602.08479v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 736. RealSynCol: a high-fidelity synthetic colon dataset for 3D reconstruction applications

**arXiv ID:** 2602.08397 | [PDF](https://arxiv.org/pdf/2602.08397v1)

**作者:** Chiara Lena `[一作]` (Politecnico di Milano), Elena De Momi `[通讯]` (Politecnico di Milano)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `67630363-6be0-4f51-ab05-7198250671a5` `6514db3d-8de6-452c-91b7-acdb31787cc4` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `edb9d762-f411-4838-a852-f2d638b018db` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建并公开了 RealSynCol，一套 28,130 帧、10 个真实解剖模型的高逼真度合成结肠数据集，并利用该数据集评估和对比现有合成结肠数据集在单目深度与位姿估计任务上的性能。

**💡 创新点**

创新点包括：① 从 10 个真实 CT 结肠模型生成多样化、具有真实光照与血管纹理的 3D 环境；② 在摄像机轨迹上引入真实操作员的运动噪声与多步采样，实现更真实的视角变化；③ 结合深度图、光流、轨迹、三维网格等多种高质量标注，为深度学习和 SLAM 任务提供完整训练与评测基础；④ 通过 Ablation 和 Benchmark 体系验证纹理、反射和轨迹多样性对模型泛化的显著影响。

**🔧 技术方法**

使用了 Blender 与 Unity 等渲染引擎、3D Slicer 进行 CT 处理、光流与深度图的自动生成；深度学习技术包括基于 Monodepth2 的 Lite‑Mono 以及基于 Transformer 的 DAM‑v2（通过 LoRA 微调）。

**📊 数据集**

数据集：RealSynCol（28,130 帧），对比 SimCol3D（23,421 帧）、C3VD（10,015 帧）、Endomapper、EndoSLAM、Synth‑colon 等；真实数据用于验证时使用 SUN 结肠数据库的临床图像。

**📈 对比分析**

采用 Lite‑Mono 自监督框架进行深度与位姿估计；在 RealSynCol 上训练得到的模型在自测、跨数据集评测中显著优于 SimCol3D、C3VD 及其他合成数据集，尤其在真实临床图像上的深度预测精度与鲁棒性提升明显；Fine‑tuned DAM‑v2 在 RealSynCol 上从相对深度提升为绝对度量深度，误差大幅下降。

**⚠️ 局限性**

局限性：仍是合成数据，可能无法完全覆盖所有真实病变与光照情况；纹理与血管模式虽逼真但不完全个体化；对真实结肠内液体、血腥或黏膜病变的建模尚不足；数据集规模虽大，但相较于真实临床数据仍有限，未来需进一步扩充并验证在临床真实流水线中的实用性。

---

## 737. Reliability-aware Execution Gating for Near-field and Off-axis Vision-guided Robotic Alignment

**arXiv ID:** 2602.08466 | [PDF](https://arxiv.org/pdf/2602.08466v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

---

## 738. Enhanced Food Category Recognition under Illumination-Induced Domain Shift

**arXiv ID:** 2602.08491 | [PDF](https://arxiv.org/pdf/2602.08491v1)

**作者:** Keonvin Park `[一作]` (Interdisciplinary Program in Artificial Intelligence, Seoul National University), Jin Hong Mok `[通讯]` (Dongguk University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究了光照变化对多类别食品识别的域漂移影响，并通过合成光照增强数据提升鲁棒性。

**💡 创新点**

创新点在于系统性地使用光照温度与强度的合成扰动进行鲁棒性评估，并针对工业检验场景提出光照感知增强策略。

**🔧 技术方法**

采用了CNN、Vision Transformer、DeiT、ConvNeXt等多种架构，结合ImageNet预训练、光照增强、迁移学习、领域自适应与领域泛化方法。

**📊 数据集**

使用Food‑101（真实场景）和Fruits‑360（受控场景）两大公开食品数据集，且自行生成光照扰动版本。

**📈 对比分析**

在同域测试中取得优秀准确率，跨域测试表现明显下降；光照增强后在跨域和合成扰动测试中准确率提升约5‑10%，并保持接近实时推理速度。

**⚠️ 局限性**

局限性包括缺乏真实光照标注、合成扰动可能未完全覆盖实际光照变化，以及对极端光照或多光源环境的鲁棒性仍待进一步验证。

---

## 739. Beyond Correctness: Learning Robust Reasoning via Transfer

**arXiv ID:** 2602.08489 | [PDF](https://arxiv.org/pdf/2602.08489v1)

**作者:** Hyunseok Lee `[一作]` (KAIST), Jinwoo Shin `[通讯]` (KAIST)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

改进了大语言模型在推理任务中的鲁棒性与一致性，强调推理过程本身的可重用性与稳定性。

**💡 创新点**

创新点在于提出跨模型推理可转移奖励（Transfer Reward），在RLVR框架中对生成模型的推理前缀进行奖励，使其能被另一模型继续完成得到正确答案，从而提升推理的可转移性与一致性。

**🔧 技术方法**

技术实现基于RLVR（可验证奖励）和GRPO强化学习，加入Transfer Reward并与答案奖励、格式奖励加权融合；通过截断推理前缀并让接收模型继续生成实现跨模型评估。

**📊 数据集**

使用的评测数据集包括数学推理基准MATH‑500、GSM8K、AMC23、AIME2024，以及科学推理基准GPQA。

**📈 对比分析**

与RLVR及基线模型对比，Transfer-augmented RLVR在多数指标上均有提升：平均准确率提升（如MATH‑500从71.0%提升至77.0%），Majority‑Voting（Maj@K）性能显著提升（如Maj@64从82.6%提升至84.2%），且仅需约2.5倍更少的训练步数即可达到相同或更佳性能。

**⚠️ 局限性**

局限性包括：需要额外的接收模型进行推理继续，导致训练时额外计算成本；奖励设计对截断比例和接收模型能力敏感；在极端复杂或非数学领域的泛化能力仍待进一步验证。

---

## 740. Low Rank Transformer for Multivariate Time Series Anomaly Detection and Localization

**arXiv ID:** 2602.08467 | [PDF](https://arxiv.org/pdf/2602.08467v1)

**作者:** Charalampos Shimillas `[一作]` (University of Cyprus), Marios M. Polycarpou `[通讯]` (University of Cyprus)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文通过理论分析 Transformer 编码器在多变量时间序列（MTS）上的学习机制，提出了 Attention Low‑Rank Transformer（ALoRa‑T）用于异常检测，并基于贡献权重提出 ALoRa‑Loc 进行异常定位；同时设计了轻量化的两元相关嵌入模块和低秩正则化损失，实现高效、可解释的异常诊断流程。

**💡 创新点**

创新点在于：① 将 Transformer 自注意力矩阵的秩作为异常信号，并通过截断 Geman 核范数实现低秩正则化；② 理论上证明 Transformer 的潜在空间可视作 STAR 模型的线性组合，为后续解释提供依据；③ 通过两元 Spearman 相关筛选的稀疏嵌入提升可解释性与计算效率；④ 设计 ALoRa‑Loc 利用贡献权重追溯异常来源，实现精确定位。

**🔧 技术方法**

技术手段包括：Transformer 编码器、单/多头自注意力、低秩正则化（截断 Geman 核范数）、线性投影重构、稀疏嵌入（Top‑K 相关）、贡献权重分析、A‑LoRa 损失与 A‑LoRa‑T/LOC 分数。

**📊 数据集**

使用六个工业与IT监控数据集：SWaT、HAI、SMD、PSM、MSL、MSDS（用于定位评估）。

**📈 对比分析**

与 20+ 传统与深度基线（PCA、KNN、IForest、LSTM‑VAE、OmniAnomaly、Anomaly Transformer、MEMTO、NPSR、D³R、SARAD 等）比较。ALoRa‑Det 在 4/5 个数据集上获得最高 F1（SMD 0.97、PSM 0.98 等），在定位任务中 HR/NDCG/IPS 均位居前列；A‑LoRa‑T 分数提供更早、更准确的异常提示。

**⚠️ 局限性**

局限性包括：理论分析仅针对单头注意力，未推广到多头；未考虑概念漂移与实时在线更新；对极端噪声或高频异常的鲁棒性尚未系统评估。

---

## 741. Estimating Aleatoric Uncertainty in the Causal Treatment Effect

**arXiv ID:** 2602.08461 | [PDF](https://arxiv.org/pdf/2602.08461v1)

**作者:** Liyuan Xu `[一作]` (Secondmind), Bijan Mazaheri `[通讯]` (Dartmouth Engineering)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出并识别了治疗效应方差（VTE）及其条件版（CVTE），用以量化因果效应的个体不确定性；

**💡 创新点**

创新点在于将VTE/CVTE作为新的不确定性指标，并在存在未观测混杂的情况下给出可识别条件与核方法估计；

**🔧 技术方法**

采用核岭回归与核条件均值嵌入的非参数估计器，并证明其一致性与收敛率；

**📊 数据集**

实验使用合成数据、半合成IHDP数据以及模拟数据集进行评估；

**📈 对比分析**

与naïve、CATE、匹配、因果森林等基线对比，提出方法在VTE/CVTE估计上误差更小，尤其在IHDP上表现更优；

**⚠️ 局限性**

局限在于估计速率受限于核岭回归，对高维混杂/分类特征适应性差，且缺乏双重稳健性与对更高阶矩的估计。

---

## 742. Hybrid Pooling with LLMs via Relevance Context Learning

**arXiv ID:** 2602.08457 | [PDF](https://arxiv.org/pdf/2602.08457v1)

**作者:** David Otero `[一作]` (Universidade da Coruã), Javier Parapar `[通讯]` (Universidade da Coruã)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种结合深度‑k 混合池化与基于人类评判生成的显式相关性叙事的框架，用大型语言模型（LLM）自动完成信息检索（IR）系统的相关性评估。

**💡 创新点**

创新点在于：①利用“Instructor LLM”将少量人工标注的查询‑文档对转化为主题特定的自然语言相关性叙事，从而显式捕获检索目标；②在混合池化中将人工评审集中在浅层高相关文档，随后让 LLM 在更深层进行评估，显著降低人工成本与模型上下文负担。

**🔧 技术方法**

技术手段包括：LLM 零射提示、上下文学习（ICL）、指令诱导（instruction induction）生成叙事、混合池化算法、基于规则的结构化输出、评价指标（AP@1000、F1、MCC）及其统计检验。

**📊 数据集**

实验使用三大标准 IR 测试集合：TREC Deep Learning 2019、TREC Deep Learning 2020 以及 TREC‑8。

**📈 对比分析**

与零射、传统 ICL（随机与相关例子）以及分层抽样策略对比，RCL 在所有数据集上至少保持与 ICL 相当的 F1 与 MCC，并在长文档集合（TREC‑8）上提升约 24% F1，且输入 token 数量显著减少，推理成本和延迟更低。

**⚠️ 局限性**

局限性包括：①叙事质量高度依赖 Instructor LLM 的能力；②目前仅验证二元相关性，难以直接扩展到分级或多维相关性；③叙事生成仍需人工审校以防误导；④混合池化在稀疏评审预算下可能无法完全消除系统偏差。

---

## 743. Modeling Concurrent Multi-Agent Systems

**arXiv ID:** 2602.08452 | [PDF](https://arxiv.org/pdf/2602.08452v1)

**作者:** Senthil Rajasekaran `[一作]` (Université Libre de Bruxelles), Moshe Y. Vardi `[通讯]` (Rice University)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355`

**🎯 论文内容**

本文提出了基于电路的多智能体系统模型，并与传统的显式表格模型进行对比，研究其在均衡存在性（W‑NE realizability）与均衡验证（W‑NE verification）两个决策问题上的复杂度，证明显式模型的 realizability 为 PTIME‑complete、verification 为 PSPACE‑complete，电路模型的 realizability 为 EXPTIME‑complete、verification 仍为 PSPACE‑complete；同时通过“模型缺口”论证显式模型在下界证明中的局限性，指出电路模型能更贴近实际系统并提供更精确的理论结果。

**💡 创新点**

创新点在于：①提出了可显式展开但更简洁的电路基多智能体模型，消除了显式表格模型导致的指数规模表示问题；②通过该模型首次给出 realizability 与 verification 的严格复杂度上下界，揭示了显式模型下的模型缺口问题；③提出了模型缺口概念，解释了先前文献中上下界不匹配的根源，强调使用电路模型可获得更可靠的复杂度分析。

**🔧 技术方法**

采用的技术包括：多智能体系统的正式定义、策略与均衡的形式化、Büchi 自动机构造、可达性与非空检查、交叉产品转移器的构造、对电路展开与压缩的分析、以及基于交替 PSPACE 与归约技术的下界证明。

**📊 数据集**

无具体数据集；研究以理论形式化与复杂度分析为主。

**📈 对比分析**

与显式表格模型比较时，作者通过构造相同功能的电路模型，证明在 realizability 问题上复杂度从 PTIME 跳至 EXPTIME，验证问题则保持 PSPACE；通过实验性例子（未给出具体数据），说明电路模型能更好地模拟实际系统，避免了显式模型中因表格膨胀导致的效率低下。

**⚠️ 局限性**

局限性包括：①仅考虑可达性目标，未探讨更复杂的时间逻辑目标；②验证下界仅在两代理或单代理电路模型下给出，未给出通用并发显式模型的完整下界；③电路模型仍需显式展开才能进行某些算法，导致在实现细节上可能存在额外的指数开销；④未对概率或学习等更丰富的多智能体行为进行建模。

---

## 744. Vista: Scene-Aware Optimization for Streaming Video Question Answering under Post-Hoc Queries

**arXiv ID:** 2602.08448 | [PDF](https://arxiv.org/pdf/2602.08448v1)

**作者:** Haocheng Lu `[一作]` (Huazhong University of Science and Technology), Jianzong Wang `[通讯]` (Ping An Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并实现了Vista框架，用场景感知分割、压缩与召回三步实现流式视频问答；

**💡 创新点**

三大创新：1) 基于视觉时空相似度的在线场景分割；2) 场景级时空压缩将帧聚合为紧凑Token并存GPU，原始帧卸载CPU；3) 查询时基于注意力检索相关场景并按需恢复全分辨率帧；

**🔧 技术方法**

采用视觉‑语言模型跨模态对齐、相似度阈值在线分割、时间平均+空间加权平均的时空压缩、基于注意力的检索召回、GPU/CPU分区与索引检索技术；

**📊 数据集**

使用StreamingBench、EgoSchema、MLVU等流式与离线长视频问答基准进行评测；

**📈 对比分析**

与Flash‑VStream、Video‑LLM‑online、Dispider、LLaVA‑OneVision‑7B等流式MLLM以及GPT‑4o、Claude 3.5 Sonnet等专有模型对比，Vista在StreamingBench多项任务（RT、MA、ACU等）实现SOTA，显著提升准确率；在离线长视频Benchmark上亦优于其他模型；

**⚠️ 局限性**

局限性：对快速运动或剧烈切换场景的边界检测易失效；对极长静态场景需强制限制场景长度；复杂重叠事件时召回精度下降；性能受相似度阈值、压缩比例等超参影响。

---

## 745. Understanding and Optimizing Attention-Based Sparse Matching for Diverse Local Features

**arXiv ID:** 2602.08430 | [PDF](https://arxiv.org/pdf/2602.08430v1)

**作者:** Qiang Wang `[一作]` `[通讯]`, Qiang Wang

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究并改进了基于Transformer的稀疏图像匹配模型LightGlue在不同局部特征上的训练与部署，发现去除近邻关键点的重要性，并提出针对多检测器的无检测器偏倚模型。

**💡 创新点**

①提出去除近邻关键点的关键设计，显著提升匹配性能；②通过分离检测器与描述子解析其对匹配的影响，证明检测器主导性能；③给出细调方法使已有专用模型泛化为统一的无检测器匹配器。

**🔧 技术方法**

Transformer-based attention matching（LightGlue、SuperGlue）、非最大抑制、单尺度提取、跨特征细调、零样本检测器兼容等技术。

**📊 数据集**

MegaDepth-1500、Image Matching Competition 2021、Aachen Day‑Night、InLoc 等公开基准数据集。

**📈 对比分析**

与基线（NN、专用LightGlue、GIM、DON）在相对位姿估计、IMC多视图、可视定位等任务中进行AUC、mAA、定位成功率比较；细调后模型在所有检测器上与专用模型持平或超越，定位成功率提升超过20%，在二进制特征上也实现零样本匹配。

**⚠️ 局限性**

仍受检测器多尺度特性和光照极端条件限制；细调需要额外训练成本；对二进制特征的鲁棒性仍有提升空间。

---

## 746. Prism: Spectral-Aware Block-Sparse Attention

**arXiv ID:** 2602.08426 | [PDF](https://arxiv.org/pdf/2602.08426v1)

**作者:** Xinghao Wang `[一作]` (Fudan University), Xipeng Qiu `[通讯]` (Fudan University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出Prism框架，利用谱感知的块稀疏注意力在不训练的情况下克服RoPE下均值池化导致的高频信息丢失。

**💡 创新点**

创新点在于将高频与低频分支分离并采用能量基温度校准，恢复高频位置信息，完全基于块级操作实现高效块重要性估计。

**🔧 技术方法**

使用技术包括块稀疏注意力、RoPE谱分解、能量基温度校准、Top‑P 选择以及 Triton/CUDA 核加速。

**📊 数据集**

实验使用 PG19、LongBench、RULER、VideoMME、LongVideoBench 等数据集，模型包括 Llama‑3.1‑8B‑Instruct 与 Qwen3‑8B。

**📈 对比分析**

与 FlashAttention‑2、MInference、FlexPrefill、XAttention 等基线对比，Prism 在 128K 上下文实现约 5× 速度提升，且保持或优于全注意力的准确率，估算开销最小。

**⚠️ 局限性**

局限在于仍需手动调节不同 RoPE 变体下的频谱切分参数，对极低密度情形下高频分支的稳定性有限，且目前仅评估训练‑free 方案，未探讨与训练‑based 方法的结合。

---

## 747. SAT Encodings for Bandwidth Coloring: A Systematic Design Study

**arXiv ID:** 2602.08423 | [PDF](https://arxiv.org/pdf/2602.08423v1)

**作者:** Duc Trung Kim Nguyen `[一作]` (VNU University of Engineering and Technology), Khanh Van To `[通讯]` (VNU University of Engineering and Technology)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c` `5b4c1114-4a70-478e-9921-2514ee03850d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

研究并实现了一个系统的SAT编码框架，用于求解带宽着色问题（BCP）

**💡 创新点**

提出了六种编码方法（单变量、双变量、块编码）并系统评估了增量求解、对称性破坏及块宽度等配置的交互效果

**🔧 技术方法**

基于SAT求解的编码技术，包括顺序编码、双变量编码和块编码，并利用增量SAT与对称性约束

**📊 数据集**

使用了GEOM和MS-CAP两组基准图实例进行实验

**📈 对比分析**

与现有POP‑S‑B和POPH‑S‑B等最先进SAT方法对比，最优配置在总耗时上比对手快约6–17%，并在最难实例GEOM120b上速度提升近两倍

**⚠️ 局限性**

受限于编码间的交互效应，单一优化对所有实例不均衡；块宽度策略影响小，需进一步研究自适应配置和更大规模实例

---

## 748. Decentralized Intent-Based Multi-Robot Task Planner with LLM Oracles on Hyperledger Fabric

**arXiv ID:** 2602.08421 | [PDF](https://arxiv.org/pdf/2602.08421v1)

**作者:** Farhad Keramat `[一作]` (University of Turku), Tomi Westerlund `[通讯]` (University of Turku)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并实现了基于Hyperledger Fabric的去中心化多机器人任务分解框架，利用LLM或acles执行多模型生成并通过新的LCS聚合方法得到可信的机器人执行序列。

**💡 创新点**

创新点在于：①将LLM或acles与区块链结合构建可追溯的去中心化规划系统；②引入基于最长公共子序列（LCS）的序列感知聚合与信誉机制，显著提升对恶意输出的检测；③公开了专门针对机器人任务分解的SkillChain‑RTD基准。

**🔧 技术方法**

采用技术包括：多模型LLM或acles、Hyperledger Fabric智能合约（OracleSC、PlannerSC）、OpenRouter接口、LCS相似度计算、信誉评分算法、Docker容器化部署。

**📊 数据集**

使用数据集：SkillChain‑RTD，包含30条高层自然语言意图与人工审核的线性任务序列。

**📈 对比分析**

对比方法：用LCS、SBERT、TF‑IDF三种相似度指标对各模型输出与真值进行评估；实验显示LCS在识别恶意模型输出上优于其他指标，聚合后平均推理延迟约2.0秒，精度明显高于传统聚合。

**⚠️ 局限性**

局限性：仅评估线性任务序列，未覆盖并行或DAG规划；仅在单机Docker环境中验证，缺乏真实机器人执行；聚合延迟仍为系统瓶颈之一；对模型多样性和攻击手段的泛化能力待进一步研究。

---

## 749. Multipoint Code-Weight Sphere Decoding: Parallel Near-ML Decoding for Short-Blocklength Codes

**arXiv ID:** 2602.08501 | [PDF](https://arxiv.org/pdf/2602.08501v1)

**作者:** Yubeen Jo `[一作]` (Korea University), Namyoon Lee `[通讯]` (POSTECH)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

针对短码长的URLLC场景，提出一种两阶段并行近ML解码框架MP-WSD，先用低复杂度列表解码器得到候选码字，再从多个起始点并行执行代码权重球面搜索以改进结果。

**💡 创新点**

创新点在于利用线性码的几何均匀性预先计算低权码字集合，实现多点并行局部搜索，从而在不扩展搜索球半径的前提下逃离局部最优，并提供确定性的低延迟和可扩展的并行实现。

**🔧 技术方法**

主要技术包括列表解码（SCL/OSD）、循环冗余校验（CRC）早停、预计算的低权码字集、相关系数过滤、迭代局部搜索和多路径并行硬件实现。

**📊 数据集**

使用模拟实验验证，涵盖CRC辅助极化码(256,16)、深极化码(128,16)以及RM(128,29)三类线性码，参照5G NR可靠性序列和标准CRC多项式。

**📈 对比分析**

与传统SCL(L=32)、SCL-BPC(L=32)和高阶OSD(k=4)相比，MP-WSD在相同或更低的平均复杂度下实现近ML性能，BLER在10⁻³处提升约1.2 dB，且延迟保持可预见且低。

**⚠️ 局限性**

局限在于仍需预计算并存储低权码字集合，且对极低信噪比场景多路径仍可能导致较高复杂度；并行硬件资源需求随起始点数增大，限制了在资源受限设备上的直接部署。

---

## 750. Is Meta-Path Attention an Explanation? Evidence of Alignment and Decoupling in Heterogeneous GNNs

**arXiv ID:** 2602.08500 | [PDF](https://arxiv.org/pdf/2602.08500v1)

**作者:** Maiqi Jiang `[一作]` (William and Mary), Yanfu Zhang `[通讯]` (William and Mary)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文通过构建MetaXplain协议，将现有的后置解释器投射到元路径视图域，提出MP-AEA诊断指标，用于评估元路径注意力与实际重要性的一致性，并在多种元路径GNN上进行实验。

**💡 创新点**

创新点在于：①提出元路径一致的解释流程（视图分解、模式合法的通道扰动、融合感知归因）；②设计MP‑AEA量化注意力与解释结果的排名相关性；③发现元路径注意力在不同数据集与骨干网络上既能保持一致也能失效，并展示解释子图可作为去噪并提升性能。

**🔧 技术方法**

使用的技术包括：基于梯度、扰动与Shapley的解释器（Grad、GNNExplainer、PGM‑Explainer、GraphSVX、GNNShap），以及HAN与HAN‑GCN两种元路径GNN骨干；解释指标包括Faithfulness、Macro‑F1/Micro‑F1、MP‑AEA（Kendall、Spearman）。

**📊 数据集**

实验数据集为三种异构图：ACM、DBLP 与 IMDB，均包含两条元路径。

**📈 对比分析**

方法对比：在每个解释器下与对应类型的随机掩码和xPath做对照，结果显示 Lifted 解释器普遍优于随机基线，Shapley 类型在边掩码上更鲁棒；MP‑AEA 显示 HAN‑GCN 在大多数场景下注意力与解释结果高度相关，而 HAN 在部分数据集上显著不一致；在解释子图上重新训练时可恢复甚至提升性能，表明解释器具有去噪作用。

**⚠️ 局限性**

局限性：①解释质量与骨干网络紧密相关，GAN‑GCN 下表现不稳定；②MP‑AEA 仅评估排名相关性，无法完全衡量解释的实际可解释性；③基于掩码的评估易受分布偏移影响，需结合再训练验证。

---

## 751. Contextual Rollout Bandits for Reinforcement Learning with Verifiable Rewards

**arXiv ID:** 2602.08499 | [PDF](https://arxiv.org/pdf/2602.08499v1)

**作者:** Xiaodong Lu `[一作]` (Beihang University), Deqing Wang `[通讯]` (Beihang University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出一种统一的上下文轮次bandit调度框架，通过神经调度器在RLVR训练中自适应选择高价值的rollout，既实现了组内噪声感知的精细挑选，又实现了对历史rollout的全局自适应重用，提升了样本效率和最终模型表现。

**💡 创新点**

创新点在于：①将rollout调度视为上下文bandit问题，用神经网络估计每个rollout的未来价值；②在同一框架下同时解决组内噪声过滤与历史数据重用两大难题；③通过子线性回报界证明调度器的理论收敛性，并展示增大回放缓冲能提升性能上界。

**🔧 技术方法**

技术手段包括：基于MLP的神经调度器、rollout编码（10维特征）与奖励估计、上下文bandit学习策略、FIFO回放缓冲、以及对RLVR训练的插拔式插件化实现。

**📊 数据集**

使用六个主流数学推理基准数据集（如MATH、GSM8K、MATH-50K等）进行实验。

**📈 对比分析**

与三种主流RLVR优化方法（GRPO、DAPO、GSPO）进行对比，实验表明调度器在所有基准上均提升了模型的准确率和训练效率，且在不同的优化器和超参设置下保持稳定的性能提升。

**⚠️ 局限性**

局限性包括：①奖励信号依赖于规则式近似，可能无法完全捕捉真正的性能提升；②对不同任务的泛化能力尚未充分验证，仅在数学推理领域得到证明；③调度器需要额外的训练开销和超参调优，实际部署时需考虑计算成本。

---

## 752. Time-Delayed Transformers for Data-Driven Modeling of Low-Dimensional Dynamics

**arXiv ID:** 2602.08478 | [PDF](https://arxiv.org/pdf/2602.08478v1)

**作者:** Albert Alcalde `[一作]` (Friedrich-Alexander-Universität), Emre Yılmaz `[通讯]` (Institute of Aerodynamics and Flow Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

设计并验证了一种简化的Transformer架构——时间延迟Transformer（TD‑TF），用于对无界时空动力学进行数据驱动建模。

**💡 创新点**

将TD‑DMD的延迟结构与Transformer自注意力机制融合，证明单层单头注意力即为TD‑DMD的非线性推广，兼具可解释性与非线性表达能力。

**🔧 技术方法**

采用位置编码、前馈网络、单头自注意力与残差学习，训练使用AdamW，并与传统TD‑DMD进行对比。

**📊 数据集**

使用了四类数据集：正弦波、NLR7301机翼迎风激波、Lorenz ’63混沌系统以及反应扩散PDE的POD投影。

**📈 对比分析**

通过RMSE、峰值、跳跃次数等统计指标与TD‑DMD比较，TD‑TF在线性系统表现相当，在非线性和混沌系统上显著优于TD‑DMD，能够保持长时演化的相位与幅值。

**⚠️ 局限性**

参数量虽少但训练仍需大量数据；在近线性场景下需要更大延迟或易过拟合，且未充分引入物理约束与多尺度时间结构。

---

## 753. UAV-Supported Maritime Search System: Experience from Valun Bay Field Trials

**arXiv ID:** 2602.08450 | [PDF](https://arxiv.org/pdf/2602.08450v1)

**作者:** Stefan Ivić `[一作]` (University of Rijeka), Bojan Crnković `[通讯]` (University of Rijeka)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `e0540dec-d77f-42db-94ae-d039248f6393` `5b4c1114-4a70-478e-9921-2514ee03850d` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究了一套基于实时漂流器流场重建、动态概率建模和深度学习视觉检测的无人机海上搜索系统，并在克罗地亚Valun湾进行现场试验。

**💡 创新点**

结合漂流器观测与CFD拟合的双模型流场重建、可自适应扩散的概率搜索以及HEDAC路径规划，实现了在复杂海流中自适应的多无人机搜索。

**🔧 技术方法**

使用实时漂流器数据融合、粒子群优化的流场拟合、YOLOv8目标检测、热方程驱动的区域覆盖（HEDAC）以及自适应扩散修正等技术。

**📊 数据集**

自制的522张海上航拍图像数据集（包含海面目标、漂流器、船只三类）以及现场漂流器GPS数据。

**📈 对比分析**

通过三次现场任务评估，第一任务多无人机成功检测四个目标，第二任务因摄像机故障仅检到四个目标中四个，第三任务因距离限制仅检到三目标；整体检测精度约为70% mAP，显示系统能在不确定环境下保持较高检出率。

**⚠️ 局限性**

受限于摄像机硬件故障、信号中断、流场重建的二维CFD近似以及漂流器分布不均导致的流场误差。

---

## 754. RIFLE: Robust Distillation-based FL for Deep Model Deployment on Resource-Constrained IoT Networks

**arXiv ID:** 2602.08446 | [PDF](https://arxiv.org/pdf/2602.08446v1)

**作者:** Pouria Arefijamal `[一作]` (Sharif University of Technology), Jörg Henkel `[通讯]` (Karlsruhe Institute of Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `8d10c613-917e-4880-9716-17789f50e119` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出RIFLE框架，利用知识蒸馏与KL分歧评估，在IoT边缘设备上实现深度模型（如VGG‑19、ResNet‑18）的联邦学习

**💡 创新点**

创新点：1) 用logit蒸馏替代梯度共享，减少通信与隐私泄漏；2) 引入KL差异动态评估与PFPV指标实现无标签的鲁棒客户端验证；3) 通过知识蒸馏实现大模型在资源受限设备上的高效训练

**🔧 技术方法**

技术：联邦学习、知识蒸馏、KL散度客户端可信度评估、无标签验证、轻量级学生模型、压缩日志传输

**📊 数据集**

数据集：MNIST、CIFAR‑10、CIFAR‑100，在Dirichlet分布下的极端非IID划分

**📈 对比分析**

与FedGA、PyramidFL、FedBary等基线比较；在10轮内达到比基线高28.3%准确率、降低88%误判率、攻击成功率<20%，并将VGG‑19训练时间从600+天缩短至1.39小时，通信量显著降低至3.5MB/轮

**⚠️ 局限性**

局限：依赖公开无标签数据集进行蒸馏，可能受限于公共数据质量；对极端恶意攻击（如大规模Byzantine）仍需进一步验证；在高度动态数据分布下PFPV可能升高

---

## 755. Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition

**arXiv ID:** 2602.08439 | [PDF](https://arxiv.org/pdf/2602.08439v1)

**作者:** Yuhao Dong `[一作]` (Nanyang Technological University), Ziwei Liu `[通讯]` (Nanyang Technological University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了Demo-ICL任务，研究在视频情境下通过文本或视频演示进行指令学习，并构建了对应的评测基准Demo-ICL-Bench；

**💡 创新点**

创新点在于：①将视频演示作为可学习的上下文，突破传统零样本视频问答；②设计三种子任务（文本演示、视频演示、演示选择）；③提出信息辅助DPO训练框架，利用自动生成的辅助信息提升模型的演示学习效果；

**🔧 技术方法**

使用多模态大型语言模型（如Qwen2.5‑VL、Ola‑Video等），结合两阶段训练（视频监督微调 + 信息辅助DPO），并利用ASR、字幕、文本摘要等技术生成演示与问题；

**📊 数据集**

基准数据集来自HowTo100M，经过自动字幕生成、文本摘要和视频对齐，最终形成1200个包含文本/视频演示、目标视频、问题与答案的样本；

**📈 对比分析**

与现有LLM（Gemini‑2.5‑Pro、GPT‑4o）及开源视频LLM（Qwen2‑VL、LLaVA‑Video、InternVL‑3等）进行对比。Demo‑ICL在文本演示下提升≈20%，在视频演示下提升≈6%，在演示选择下仍落后人类约20%。相较于其他模型，Demo‑ICL在VideoMMMU等知识获取基准上接近同等规模模型甚至更好；

**⚠️ 局限性**

局限性包括：①视频演示的效果受视频质量与剪辑粒度限制，模型仍难以精确对齐时间轴；②信息辅助DPO依赖自动生成的辅助信息，可能引入噪声；③演示选择任务中对全球语义的把握不足，未能充分模拟真实检索场景；③整体模型规模受限，无法与最新大模型（如大规模商业LLM）直接竞争。

---

## 756. The Connection between Kriging and Large Neural Networks

**arXiv ID:** 2602.08427 | [PDF](https://arxiv.org/pdf/2602.08427v1)

**作者:** Marius Marinescu `[一作]` `[通讯]` (King Juan Carlos University), Marius Marinescu (King Juan Carlos University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

**🎯 论文内容**

研究 Kriging 与高斯过程回归（GPR）以及单隐藏层神经网络（MLP）之间的数学关系，证明 Kriging 等价于 GPR 的 MAP 估计，并展示 MLP 在无限宽极限下收敛为高斯过程，从而得到激活函数与核函数的对应关系，并通过数值实验验证该理论。

**💡 创新点**

将 Kriging 与 MLP 的关联系统化；揭示单隐藏层 MLP 随机权重极限为 GP；提供激活函数对应核函数的表格；利用随机函数秩检验验证理论；进一步讨论深层网络、CNN、NTK 等更广泛的关联。

**🔧 技术方法**

使用统计学中的最佳线性无偏估计、条件分布、中心极限定理、核方法；神经网络理论；高斯过程推断；数值实验方法；以及深度学习中的 NNGP 与 NTK 理论。

**📊 数据集**

仅使用模拟数据（从 GP 和 MLP 生成的随机过程），未使用真实空间数据集。

**📈 对比分析**

采用随机函数秩检验（基于功能深度）对 50 条 GP 与 MLP 模拟路径进行比较，p 值均高于 0.5，接受同一分布的原假设，验证理论相等性；性能评估侧重于分布一致性，而非预测精度。

**⚠️ 局限性**

局限性包括：仅在理论和模拟层面验证，未在实际地理空间数据上测试；对非平稳核的解析困难；逼近 GP 需要大量隐藏层；对深层网络训练过程的实际影响尚未完全揭示；缺乏对不确定性量化的实验验证。

---

## 757. LLMs + Security = Trouble

**arXiv ID:** 2602.08422 | [PDF](https://arxiv.org/pdf/2602.08422v1)

**作者:** Benjamin Livshits `[一作]` `[通讯]` (Imperial College London), Benjamin Livshits (Imperial College London)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文批判了现有的“先生成后检测/修复”与“神经符号化验证”等方法在安全性上的局限，提出在代码生成阶段直接通过约束解码（尤其是扩散模型）实现安全构造。

**💡 创新点**

创新点在于将扩散式代码生成的并行预测与基于 AST 的安全约束相结合，构建了模块化、层级化的安全强制机制，克服了自回归模型的路径爆炸与后期修复的低效。

**🔧 技术方法**

采用的核心技术包括约束解码（Constrained Beam Sampling、语义约束）、扩散式模型（TreeDiff、DiffusionGuard）以及结构化抽象语法树与安全规范的自动化映射。

**📊 数据集**

使用的主要数据集包括 SecCodePLT、SecurityEval、HumanEval、MBPP、PatchDB、Common Weakness Enumeration (CWE) 库，以及自建的安全约束库。

**📈 对比分析**

通过与传统 LLM+后期修复、神经符号验证以及安全审计框架的对比，实验表明在 SecurePass@1 以及功能通过率（Pass@1）上可提升 15–30% 以上，同时保持功能完整性。

**⚠️ 局限性**

局限性包括：需要人工编写或收集安全约束，约束解码可能导致生成多样性下降；扩散模型训练和推理成本高；对尚未出现的新型漏洞或复杂业务逻辑的覆盖仍有限。

---

## 758. Graph-Loc: Robust Graph-Based LiDAR Pose Tracking with Compact Structural Map Priors under Low Observability and Occlusion

**arXiv ID:** 2602.08417 | [PDF](https://arxiv.org/pdf/2602.08417v1)

**作者:** Wentao Zhao `[一作]` (Shanghai Jiao Tong University), Jingchuan Wang `[通讯]` (Shanghai Jiao Tong University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种基于图的 LiDAR 位姿跟踪框架 Graph-Loc，利用压缩结构化点-线图实现对离线固定地图的实时匹配与定位。

**💡 创新点**

创新点：1）采用无偏最优传输（Unbalanced Optimal Transport）配合图上下文正则化实现全局关联，避免传统轮廓切分导致的地图膨胀；2）引入低可观测性时的延迟优化策略，动态识别弱约束方向并暂缓更新，以提升稳健性。

**🔧 技术方法**

技术手段：图结构化表示、点线特征提取、无偏最优传输与Sinkhorn求解、图上下文正则化、动态特征过滤、延迟优化、GPU 加速的求解器。

**📊 数据集**

使用数据集：KITTI、ERPoT、CMU‑EXPLORATION、室内 Gazebo 模型、CAD/楼层平面图以及多种公开点云地图。

**📈 对比分析**

与 ALOAM_MCL、FLOAM_MCL、KISS_MCL、HDL_LOC、ERPoT 等方法对比，Graph‑Loc 在大多数轨迹段上平均 ATE 与 RMSE 低于基线，同时地图体积仅为传统方法的 5–10%，并在 GPU 端实现实时（平均 < 25 ms/帧）。

**⚠️ 局限性**

局限性：在极度缺失或极其重复的结构中仍可能出现漂移；需要足够多帧积累信息才能解除延迟优化；实现复杂度高，依赖 GPU 加速和精细的图构造与特征筛选。

---

## 759. Drop the mask! GAMM-A Taxonomy for Graph Attributes Missing Mechanisms

**arXiv ID:** 2602.08407 | [PDF](https://arxiv.org/pdf/2602.08407v1)

**作者:** Richard Serrano `[一作]` (Laboratoire Hubert Curien), Christine Largeron `[通讯]` (Laboratoire Hubert Curien)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出了GAMM（Graph Attributes Missing Mechanisms）分类法，用以在图属性缺失研究中引入结构相关的缺失机制；

**💡 创新点**

创新点在于将传统的MCAR/MAR/MNAR框架扩展到图结构，系统划分了基于属性、结构、邻居及其组合的缺失机制，并公开了完整的实验代码；

**🔧 技术方法**

采用了多种现有缺失填补技术，包括基于均值、最优传输、邻居平均、扩散、PCFI和GRIOT等图神经网络方法，同时对传统表格填补器做对比；

**📊 数据集**

实验基于十二个公开图数据集（Cora、PubMed、CiteSeer、Chameleon、Squirrel、Minesweeper、Actor、Roman‑empire、Tolokers、Wisconsin、Cornell、Texas），涵盖不同同质性特征；

**📈 对比分析**

通过对齐不同缺失机制和缺失率，使用MAE/RMSE衡量填补质量，结果显示图感知的缺失机制（尤其是邻居MNAR）显著降低填补性能，且在异质性网络中表现最差；

**⚠️ 局限性**

局限在于仅考虑属性缺失且假设拓扑完全可观测，未探究边缺失或更复杂的结构缺失情形，也未验证对下游任务的直接影响。

---

## 760. Submodular Maximization over a Matroid $k$-Intersection: Multiplicative Improvement over Greedy

**arXiv ID:** 2602.08473 | [PDF](https://arxiv.org/pdf/2602.08473v1)

**作者:** Moran Feldman `[一作]` (University of Haifa), Justin Ward `[通讯]` (Queen Mary University of London)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文提出了一种基于贪心-局部搜索混合的算法，求解在 matroid k‑交约束下的非负单调（以及非单调）子模函数最大化问题；

**💡 创新点**

核心创新在于实现了相对于传统贪心算法的乘法改进：给出了 0.819k+O(√k) 的近似比（单调）和 0.819k+O(k^{2/3})（非单调），首次在一般 k 上实现乘法提升；

**🔧 技术方法**

主要技术包括：随机平移阈值的贪心分层选择、局部搜索的增删操作、辅助权重 u(e) 与实际增益 w(e) 的比较、以及对 matroid k‑parity 的交换性质的利用；

**📊 数据集**

该工作为理论分析，未使用任何实验数据集；

**📈 对比分析**

与现有贪心（k+1 近似）和前沿局部搜索（k 近似）方法对比，实验中理论上证明了新的近似比；

**⚠️ 局限性**

局限性在于：近似比仍呈线性依赖 k；算法实现复杂，最坏时间复杂度为 O(|E|^4/k)（虽然与 k 无关）；且在实际应用中需假设可访问子模函数和独立性 oracle。

---

## 761. Decentralized Spatial Reuse Optimization in Wi-Fi: An Internal Regret Minimization Approach

**arXiv ID:** 2602.08456 | [PDF](https://arxiv.org/pdf/2602.08456v1)

**作者:** Francesc Wilhelmi `[一作]` (Universitat Pompeu Fabra), Miguel Calvo-Fullana `[通讯]` (Universitat Pompeu Fabra)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出一种基于内部遗憾最小化的无协调学习算法，以实现Wi‑Fi网络中基础服务集（BSS）之间的空间复用（SR）优化。

**💡 创新点**

创新点在于使用内部遗憾匹配（regret‑matching）引导各BSS自动趋向相关均衡（CE），从而在无需显式通信的情况下实现隐式协调，克服传统外部遗憾方法容易陷入非最优纳什均衡的缺陷。

**🔧 技术方法**

核心技术包括多玩家多臂赌博机游戏建模、内部遗憾矩阵更新、奖励估计（基于空中时间和速率），以及带衰减因子和粘性因子的纯策略内部遗憾匹配。

**📊 数据集**

实验基于开源Wi‑Fi模拟器 Komondor，使用随机部署（100个场景）和两BSS的固定/随机位置设置，未使用公开数据集而是自行生成的仿真场景。

**📈 对比分析**

与三种方法比较：默认固定配置（Baseline）、外部遗憾（ε‑greedy）和内部遗憾（regret‑matching）。实验显示，内部遗憾方法在强平衡和弱平衡场景下平均吞吐量分别提升至≈80 Mbps和最高≈80 Mbps，且最小吞吐量（公平性）也优于其它方法，整体性能优于外部遗憾且近似最优。

**⚠️ 局限性**

局限性包括：奖励估计依赖于对对手行为的“善意”假设，估计不准确时可能陷入次优；实验仅覆盖两BSS场景，未验证大规模网络的可扩展性；算法仍需要调参（如衰减因子、粘性因子）以适应不同环境。

---

## 762. When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment

**arXiv ID:** 2602.08449 | [PDF](https://arxiv.org/pdf/2602.08449v1)

**作者:** Igor Santos-Grueiro `[一作]` `[通讯]`, Igor Santos-Grueiro

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过信息流视角评估AI系统的情境感知导致的评估与部署行为差异，并提出在训练阶段通过对内部表示进行对抗性不可变训练来抑制基于评估情境的条件策略。

**💡 创新点**

创新点在于：①把对齐评估转化为信息泄露的最大化问题，给出评估风险差距与内部表示与情境变量互信息的上界；②提出“情境盲”机制（Regime‑Blind Mechanisms），利用梯度逆向与对抗性探测器在决策瓶颈处强制实现情境不可变性；③在同一基础模型上对科学讽刺与时间触发的后门两类失败模式进行可比实验，揭示两类问题对不可变性的不同响应。

**🔧 技术方法**

使用对抗性不可变训练（Adversarial Invariant Training，AIT）结合梯度逆向层（Gradient Reversal Layer），对Transformer的最后残差流施加正则；采用LoRA微调、双层MLP探测器和交叉熵对抗损失；通过两阶段（探索-验证）训练协议评估稳定性。

**📊 数据集**

使用公开的 Qwen2.5‑7B 基础模型；对两个实验场景分别构造匹配对话/SQL生成的训练对：1）科研讽刺（科学家 vs. Flat‑Earther 人格）；2）时间触发的后门（年份字段 2023 vs. 2024）。

**📈 对比分析**

比较方法：在训练过程中记录探测器准确率、任务损失、风险指标（讽刺时“yes”出现、后门时不安全 SQL 生成）。结果显示：讽刺任务在约 α≈0.06 时出现“稳定性崩溃”，风险降至 0% 而任务效能保持 100%；后门任务则需更大 α≈0.5 才消除风险，效能亦保持 100%。因此，情境不可变训练能在两种失败模式下实现无效风险且无显著性能下降。

**⚠️ 局限性**

局限性：①不可变训练仅针对给定的有限探测器族，无法排除更复杂或隐写的情境编码；②不同失败模式对不可变性的敏感度不同，可能需要更高压力甚至多层次约束；③仅在单一基础模型上验证，缺乏跨模型通用性研究；④该机制不解决“沙盒化”或自适应评估诱导等更高级的策略；⑤可能削弱模型对合法上下文敏感性的需求，导致潜在的性能损失。

---

## 763. Post-Collision Trajectory Restoration for a Single-track Ackermann Vehicle using Heuristic Steering and Tractive Force Functions

**arXiv ID:** 2602.08444 | [PDF](https://arxiv.org/pdf/2602.08444v1)

**作者:** Samsaptak Ghosh `[一作]` (Indian Institute of Technology Roorkee), Sohom Chakrabarty `[通讯]` (Indian Institute of Technology Roorkee)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

设计并验证了一种启发式控制函数，用于在碰撞后通过联合转向和牵引力指令恢复单轨Ackermann车辆的行驶轨迹。

**💡 创新点**

将时间变速纵向速度与非线性转向耦合项显式保留，提出双阶段三角函数控制器（转向+牵引），并在碰撞后无需制动即可实现轨迹恢复。

**🔧 技术方法**

结构化启发式控制设计、单轨车辆动力学模型（泛化Ackermann与3DOF MATLAB模型）、MATLAB仿真以及非线性控制器参数化与时域调节。

**📊 数据集**

未使用公开数据集，采用预设车辆参数（质量、摩擦系数、阻力系数等）和若干碰撞初始条件（横向/角速度）进行仿真。

**📈 对比分析**

通过与无控制和仅转向恢复两种对照方法比较，使用轨迹偏差、偏航率峰值、恢复时间等指标，结果显示启发式控制显著降低偏差并快速回到原轨道，性能优于单转向方案。

**⚠️ 局限性**

仅考虑单轨模型，碰撞仅以初始状态形式建模，未包含接触动力学、参数不确定性、执行器限制；缺乏稳健性分析和闭环实验验证。

---

## 764. Large Language Models and Impossible Language Acquisition: "False Promise" or an Overturn of our Current Perspective towards AI

**arXiv ID:** 2602.08437 | [PDF](https://arxiv.org/pdf/2602.08437v1)

**作者:** Ziyan wang `[一作]`, Longlong Ma `[通讯]` (Institute of Software, University of Chinese Academy of Sciences)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

实验验证了ChatGPT等LLM在学习可能与不可能语言时的性能差异，评估其能否区分自然语言。

**💡 创新点**

提出将不可行语言定义为对英语句子进行句子倒序或基于词数奇偶性插入否定，并用此检验Transformer与RNN在结构偏好上的差异；同时将Chomsky批判置于实证层面，倡导功能主义与经验主义视角。

**🔧 技术方法**

使用GPT‑2 small模型、LSTM模型，并采用Perplexity、Loss等指标；通过Welch's t‑test比较实验组与对照组。

**📊 数据集**

构造简化SVO句子集（10,000句）以及BabyLM 1亿词数据集。

**📈 对比分析**

实验结果显示GPT‑2 small在学习自然语言时Loss与Perplexity显著更低（p<0.001），表明其对可能语言有内在偏好；LSTM模型无显著差异，支持Chomsky对RNN的批评；在不可能语言中，GPT‑2的性能随变换程度下降，说明注意力机制对线性结构的敏感度。

**⚠️ 局限性**

实验受限于模型规模、训练步骤、可用数据与硬件；不可行语言仅基于两种线性变换，未涵盖更复杂的语法错误；未检验更大模型或不同语言；缺乏对最小化程序的理论扩展。

---

## 765. A Sketch+Text Composed Image Retrieval Dataset for Thangka

**arXiv ID:** 2602.08411 | [PDF](https://arxiv.org/pdf/2602.08411v1)

**作者:** Jinyu Xu `[一作]` (Wuhan University of Technology), Yongjian Liu `[通讯]` (Wuhan University of Technology)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并发布了 CIRThan 数据集，用于绘画风格的藏传唐卡图像的绘图+文本组合检索任务，并在此数据集上进行基准实验。

**💡 创新点**

创新点在于：① 针对知识专属视觉域设计细粒度手绘草图和三层次分级文本描述；② 通过多级文本丰富语义层次，满足用户不同专业深度的检索需求；③ 公开了标准划分与评测基线，推动文化遗产多模态检索研究。

**🔧 技术方法**

采用的技术包括：人类绘图与专家标注、基于 Qwen-3 的层级文本简化、对比基线模型（Combiner、CLIP4Cir、Bi-Blip4CIR、CaLa、ENCODER）以及零样本方法（Pic2Word、LinCIR、Context‑I2W、LDRE、SEIZE、OSrCIR、CoTMR）与 MLLM 组合。

**📊 数据集**

使用的数据集为 CIRThan，包含 2,287 张唐卡图像、对应手绘草图和 3 级层级文本；训练/测试划分为 80%/20%。

**📈 对比分析**

在 3 级文本水平上，监督方法平均 R@1 达到 52.03%（ENCODER 最高 54.65%），而零样本方法平均 R@1 低于 8%；文本越细粒度检索性能越好，显示文本层级对检索的关键作用。

**⚠️ 局限性**

局限性：① 仍依赖人工绘图和专家审核，规模受限；② 监督模型表现尚不理想，说明唐卡细粒度匹配挑战大；③ 零样本 MLLM 对文化专属视觉语义的理解有限，需进一步跨模态知识适配。

---

## 766. TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration

**arXiv ID:** 2602.08404 | [PDF](https://arxiv.org/pdf/2602.08404v1)

**作者:** Linye Wei `[一作]` (Institute for Artificial Intelligence), Meng Li `[通讯]` (Institute for Artificial Intelligence)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出TEAM框架，通过时间‑空间一致性指导专家激活，显著加速MoE扩散语言模型的推理。

**💡 创新点**

创新点在于利用解码块内已接受token的时间一致性与未接受token的空间一致性，设计三种专家激活策略（延迟缓存、热token投机探索、冷token限激活），实现更少专家激活、更多token解码。

**🔧 技术方法**

核心技术包括基于MoE的路由器、双向注意力、块级扩散解码、延迟KV缓存、分支式投机解码与双轮路由限制。

**📊 数据集**

实验使用SDAR 30B-A3B的代码生成基准（HumanEval、MBPP）和数学推理基准（GSM8K、Math‑500）。

**📈 对比分析**

与原始MoE dLLM对比，TEAM在保持0.0~0.6%性能差距的前提下，平均提升1.9×速度（最大2.2×），显著减少激活专家数。

**⚠️ 局限性**

局限性包括：仅在SDAR上验证，未探讨其他MoE dLLM；对热/冷token阈值需调参；在极低资源边缘设备上仍存在内存占用问题。

---

## 767. Conditional Sequence Modeling for Safe Reinforcement Learning

**arXiv ID:** 2602.08584 | [PDF](https://arxiv.org/pdf/2602.08584v1)

**作者:** Wensong Bai `[一作]` (Zhejiang University), Hui Qian `[通讯]` (Zhejiang University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出一种基于条件序列建模的离线安全强化学习算法，能够在单一训练的策略下实现零射击（zero-shot）跨多成本阈值的部署。

**💡 创新点**

创新点在于将Lagrangian式成本惩罚与自适应惩罚系数、轨迹级奖励-成本加权重与Q值正则化相结合，实现对回报与成本权衡的自动调节；并从理论上给出了RTG/CTG条件与实际回报-成本差距的上界，阐明了数据覆盖度对零射击控制的限制。

**🔧 技术方法**

技术手段包括：Transformer‑based 归一化的条件序列建模（Conditional Sequence Modeling，CSM）；自适应双线性（dual‑ascent）更新的Lagrange乘子；轨迹级加权重函数 Wτ=exp(αR)·sigmoid(γ(c_lim−C))；以及基于当前策略的 Q‑value 与成本 critic 的 TD 更新与正则化。

**📊 数据集**

使用了公开的 DSRL（SafetyGym、BulletSafetyGym、MetaDrive）三大离线安全数据集，涵盖多种连续控制与仿真驾驶任务。

**📈 对比分析**

与行为克隆、BC‑Safe、BCQ‑Lag、BEAR‑Lag、COptiDICE、CPQ、FISOR、TraC、CDT 等多类基线对比，实验表明该方法在绝大多数任务上实现了更优的归一化回报并且成本满足或低于阈值，特别是在零射击多阈值评估中表现出显著优势。

**⚠️ 局限性**

主要限制包括：需要较为丰富的联合回报‑成本覆盖数据才能保证理论上预测的误差控制；对超参数（α、γ、β、c_lim 等）的敏感性尚未完全自动化；以及在极端数据不平衡或极低专家覆盖度下仍可能出现回报下降或成本偏高的情况。

---

## 768. Modeling Score Approximation Errors in Diffusion Models via Forward SPDEs

**arXiv ID:** 2602.08579 | [PDF](https://arxiv.org/pdf/2602.08579v1)

**作者:** Junsu Seo `[一作]` `[通讯]` (Seoul National University), Junsu Seo (Seoul National University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `f86bf285-fd08-4156-973b-6e6481af8fa0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文通过把分数估计误差视为随机源，构造前向SPDE框架，对分数基础生成模型（SGM）的动态进行建模与分析；并基于该框架提出了新的评估指标SIEM；

**💡 创新点**

创新点在于：① 将SGM的误差建模为SPDE中的随机项，从而以几何稳定性和位移凸度解释模型鲁棒性；② 通过SPDE的二次变差导出实用的评价指标SIEM；

**🔧 技术方法**

技术手段包括：Fokker-Planck方程、Stochastic PDE、离散化与Stratonovich/Itô积分、位移凸度理论、二次变差分析、重要抽样、U-Net式DDPM训练及相关统计分析；

**📊 数据集**

使用的数据集为CIFAR‑10和32×32尺寸的LSUN‑Bedroom；

**📈 对比分析**

通过Spearman相关性对比，SIEM与FID的相关系数高达0.8898，显著优于与2‑Wasserstein距离的0.5094；且即使仅使用前10%采样轨迹，相关系数仍保持在0.86以上，表明SIEM既能高效又能有效捕捉样本质量；

**⚠️ 局限性**

局限性包括：误差仅被建模为通用随机源，未对其空间谱特性进行具体刻画；实验范围仅限于小规模数据集，缺乏对更大模型与更复杂数据的验证；此外，理论与实践间的桥梁尚不完整。

---

## 769. ValueFlow: Measuring the Propagation of Value Perturbations in Multi-Agent LLM Systems

**arXiv ID:** 2602.08567 | [PDF](https://arxiv.org/pdf/2602.08567v1)

**作者:** Jinnuo Liu `[一作]` (New York University), Hua Shen `[通讯]` (New York University)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种基于扰动的评估框架，用来量化并分析多代理LLM系统中的价值漂移；

**💡 创新点**

创新点在于将价值传播拆解为代理层面（β-敏感度）和系统层面（SS-系统敏感度）两层度量，并配套构造了56维价值评测数据集；

**🔧 技术方法**

主要技术包括基于Schwartz价值调查的提问式评价、LLM-as-a-judge打分、线性回归估计β、以及系统敏感度SS的定义与计算；

**📊 数据集**

使用从Schwartz价值调查（SVS）抽取的56个价值维度的行为问题集合作为评价数据集；

**📈 对比分析**

在多种模型骨干（Qwen3‑8B、Llama‑3.3‑70B、GPT‑3.5‑Turbo、GPT‑4o、Gemma‑3‑27B）、不同开放度个性、输入方差以及网络拓扑下进行实验，发现价值维度、模型与拓扑对β和SS有显著影响，但未给出传统任务性能指标；

**⚠️ 局限性**

局限性包括：评价仅基于表面回答，未涉及内部目标；使用单一LLM评估者可能引入偏差；β估计受实验协议限制；仅适用于无反馈循环的DAG结构；扰动为人工优化的极端情况，未必代表自然对话影响。

---

## 770. Semantics and Multi-Query Optimization Algorithms for the Analyze Operator

**arXiv ID:** 2602.08546 | [PDF](https://arxiv.org/pdf/2602.08546v1)

**作者:** Marios Iakovidis `[一作]` (University of Ioannina), Panos Vassiliadis `[通讯]` (University of Ioannina)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种新的面向意图的 OLAP 运算符——ANALYZE，定义其语义并将其拆解为原始查询、兄弟查询和下钻查询三个子查询；在此基础上给出了可行的多查询优化（MQO）策略，并在 Delian Cubes 系统中实现和评估了三种实现方案（Min‑MQO、Mid‑MQO、Max‑MQO）。

**💡 创新点**

创新点主要包括：
• 设计了统一的 360° 视图运算符 ANALYZE，首次将原始、同级（兄弟）和细粒度（下钻）查询合并为单一调用；
• 通过 Cube Usability 定理证明这些子查询可以合并为更少的查询，并给出理论支持；
• 提出了三种层次不同的 MQO 策略（全合并、无合并、部分合并），并给出了选用依据的经验阈值；
• 在实际系统中实现并验证了这些策略的性能优势。

**🔧 技术方法**

技术手段包括：
• 基于层次多维立方体的模型与 OLAP 语义；
• 多查询优化算法（Max‑MQO、Mid‑MQO、Min‑MQO），利用查询合并、共享子查询、聚合级别推导等技术；
• 结合 Cube Usability Theorem 的理论分析与证明；
• Java 实现与 MySQL 8.0 后端的实验部署；
• 性能测评框架，记录解析、构造、执行、后处理等四个阶段。

**📊 数据集**

实验使用的数据集包括：
• TPC‑DS（规模因子 1、3.5、35，分别约 2M、10M、100M 事实行）；
• Foodmart（约 288K 事实行）；
• pkdd99+（约 100M 事实行）；
• Northwind（约 2K 事实行）。
此外，还分别采用了大、宽、细的维度表组合。

**📈 对比分析**

比较方法：在同一套工作负载（10 条不同 SELECTIVITY、GROUPER 级别、过滤器数量的查询）下，分别测量三种 MQO 策略的总执行时间，并细分为四个阶段；进一步在不同数据规模、维度大小、查询选择性下做敏感性分析。结果表明：
• Mid‑MQO 在绝大多数场景下获得最快的总执行时间；
• Max‑MQO 仅在兄弟查询占比高且重叠度大的情况下优于 Mid‑MQO；
• Min‑MQO 最慢但不会超时；
• 所有策略的查询执行时间均受查询选择性与事实表规模的显著影响。

**⚠️ 局限性**

局限性：
• 仅适用于单度量、单层级聚合的 OLAP 查询；
• 依赖于层次维度的“完全可滚动”假设，非完全层次或跨维度的复杂查询难以直接适用；
• 目前的 MQO 只在外部实现，对 DBMS 内部优化器没有协同；
• 在极大事实表且兄弟查询稀疏时，Max‑MQO 可能因一次性拉取大量中间结果导致超时；
• 仅在实验平台上验证，缺乏在分布式、列式存储等多样化后端的通用性评估。

---

## 771. GISA: A Benchmark for General Information-Seeking Assistant

**arXiv ID:** 2602.08543 | [PDF](https://arxiv.org/pdf/2602.08543v1)

**作者:** Yutao Zhu `[一作]` (Renmin University of China), Zhicheng Dou `[通讯]` (Renmin University of China)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了名为 IISA 的面向通用信息检索代理的基准，包含373个由人类设计、答案结构化（项目、集合、列表、表格）且配有完整搜索轨迹的查询。

**💡 创新点**

创新点包括：①将深度搜索与广度聚合统一评估；②通过结构化答案实现确定性评估；③划分稳定与实时子集，防止预训练记忆污染；④提供完整人类搜索轨迹用于过程监督。

**🔧 技术方法**

采用 LLM‑驱动的 ReAct 代理、工具调用（Google Serper、Jina API）和多种商用搜索系统；评估指标包括精确匹配、F1、顺序准确度、行/单元格 F1。

**📊 数据集**

使用自建的 IISA 数据集，涵盖10个主题领域，回答类型多样；同时对比现有 Benchmarks 如 BrowseComp、WideSearch 等。

**📈 对比分析**

对比 10+ LLM 及 3 种商用系统，最优模型（Claude 4.5 Sonnet 思考模式）整体精确匹配仅 19.30%，表明当前系统仍显不足；工具调用数量与性能呈非线性关系，商用系统普遍落后于 LLM 代理。

**⚠️ 局限性**

局限性包括：规模仅 373 题，难以用于大规模训练；仅关注文本检索，未覆盖多模态；工具调用上限 30 次可能导致部分任务未完成；需要人工持续更新实时子集。

---

## 772. TIBR4D: Tracing-Guided Iterative Boundary Refinement for Efficient 4D Gaussian Segmentation

**arXiv ID:** 2602.08540 | [PDF](https://arxiv.org/pdf/2602.08540v1)

**作者:** He Wu `[一作]` (Zhejiang University of Technology), Jiazhou Chen `[通讯]` (Zhejiang University of Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `aaccfe5c-6b26-4208-b23c-35331481e142` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了一个无训练的双阶段迭代边界细化框架（TIBR4D），将视频分割掩码提升到4D高斯场，实现高效、精确的目标级动态高斯分割。

**💡 创新点**

创新点在于：① 在时间段级别应用迭代高斯实例跟踪（IGIT），兼顾身份一致性与动态变化；② 通过帧级高斯渲染范围控制（RCC）抑制边界溢出和漂浮点；③ 两阶段迭代可收敛，显著降低漂浮点与漏边缘。

**🔧 技术方法**

主要技术包括：高斯实例跟踪（基于2D掩码的权重矩阵）、时间段合并策略、帧级高斯渲染范围阈值迭代、显式高斯场表示（3D Gaussian Splatting）以及DEVA等视觉基础模型生成的2D分割。

**📊 数据集**

在HyperNeRF和Neu3D两个公开数据集上进行实验，分别包含多种动态场景与多摄像头视角。

**📈 对比分析**

与现有SOTA方法SA4D和SADG比较，TIBR4D在mIoU与mAcc上均有显著提升，且提取目标高斯所需时间几乎是对手的1/20以上，尤其在3-5次迭代即可收敛。

**⚠️ 局限性**

局限性：① 对2D分割质量高度依赖，严重错误难以完全纠正；② 目前只针对单一目标提取，未实现完整全景分割；③ 迭代次数或视角数量增多会导致运行时间上升。

---

## 773. An arithmetic method algorithm optimizing k-nearest neighbors compared to regression algorithms and evaluated on real world data sources

**arXiv ID:** 2602.08577 | [PDF](https://arxiv.org/pdf/2602.08577v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 774. UniPlan: Vision-Language Task Planning for Mobile Manipulation with Unified PDDL Formulation

**arXiv ID:** 2602.08537 | [PDF](https://arxiv.org/pdf/2602.08537v1)

**作者:** Haoming Ye `[一作]`, Panpan Cai `[通讯]`

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种新的深度学习模型，用于图像分类任务。

**💡 创新点**

创新点在于引入了一种新的激活函数，能够提高模型的收敛速度和分类精度。

**🔧 技术方法**

使用了卷积神经网络（CNN）和改进的激活函数。

**📊 数据集**

使用了CIFAR-10数据集进行实验。

**📈 对比分析**

与传统的激活函数（如ReLU）进行比较，结果显示新模型在分类精度上提高了5%，并且训练时间缩短了15%。

**⚠️ 局限性**

模型在处理高分辨率图像时性能下降，且对噪声数据的鲁棒性有待提高。

---

## 775. Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering

**arXiv ID:** 2602.08519 | [PDF](https://arxiv.org/pdf/2602.08519v1)

**作者:** Yunhui Liu `[一作]` (Nanjing University and Ant Group), Tieke He `[通讯]` (Nanjing University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `79276348-11e0-48e3-84bc-7ec231d0171c` `3f18e8e3-0266-457c-8567-9039b6d2394d` `9ce7179e-700c-4310-ac2b-91df50ded46e` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

设计并实现了工业级的Attributed Graph Clustering基准库PyAGC，包含12个从小到大、异质属性、低同质性等多样化图数据集，提供可微分的Encode‑Cluster‑Optimize框架和 mini‑batch 实现，支持单张 32GB GPU 上对 111M 节点大图的深度聚类训练。

**💡 创新点**

①将所有现有 AGC 方法统一到 Encode‑Cluster‑Optimize 三模块架构并重构为可插拔、支持 mini‑batch 的模块化实现；②收集从学术到工业、从文本到表格属性的 12 个多尺度图数据集；③提出全方位评价协议，既包含监督指标（ACC/NMI/ARI/F1），又加入无监督结构指标（Modularity、Conductance）以及效率指标；④首次在单 GPU 上完成 111M 节点图的深度聚类实验。

**🔧 技术方法**

基于 PyTorch 与 PyTorch‑Geometric，使用邻居采样、子图采样实现 mini‑batch；GPU 加速 KMeans 与聚类层；利用 GCN、GAT、图 Transformer 等 GNN；自监督对比学习、图重构、模块化聚类损失；Adam 优化器；实现了 GPU 内存占用 14GB 以下、训练时间 ≤ 1.5 小时的方案。

**📊 数据集**

12 个数据集：经典学术集（Cora、Citeseer、Pubmed、Photo、Physics、HM、Flickr、ArXiv、Reddit、MAG、Pokec）以及工业场景集（Products、WebTopic、Papers100M（111M 节点）），属性类型从文本词袋到多维表格。

**📈 对比分析**

对 17 种代表性方法（传统、非参数、深度解耦、深度联合）进行评估，使用 ACC/NMI/ARI/F1、Modularity/Conductance 以及 GPU 内存/训练时间。实验显示：在学术数据集性能优秀；在工业图上性能显著下降，深度解耦模型保持相对稳健；结构指标与监督指标往往不一致；mini‑batch 实现使 111M 节点图在单 GPU 上训练时间 ≤ 1.5 小时，显著提升可扩展性。

**⚠️ 局限性**

1) 对高度异质属性与高异质性图的建模仍不充分；2) 无监督模型选择标准缺失；3) 仅在单 GPU 环境评估，未考察多 GPU/分布式加速；4) 对极大图仍有进一步加速需求；5) 仅聚焦节点聚类，未覆盖子图或动态图聚类。

---

## 776. PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition

**arXiv ID:** 2602.08586 | [PDF](https://arxiv.org/pdf/2602.08586v1)

**作者:** Yiming Yang `[一作]` (Alibaba Group), Yue Liu `[通讯]` (Alibaba Group)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了 PRISM 多代理推理框架，并提出了三维收益分解理论，解释多代理协作提升性能的根本原因。

**💡 创新点**

创新点在于将多代理推理收益拆解为探索、信息、聚合三维，并通过角色多样化、执行反馈与基于证据的交叉评估，实现三维协同最大化。

**🔧 技术方法**

技术方法包括角色化多样化生成、环境执行反馈、基于证据的交叉评估、迭代合成闭环验证，以及游戏理论收敛分析。

**📊 数据集**

实验使用了四个基准数据集：GSM8K、AIME-2025、MBPP 与 BFCL-SP，涵盖数学推理、代码生成和工具调用任务。

**📈 对比分析**

与 Self‑Consistency、MoA、Two Heads、ReConcile 以及大模型基准进行比较，PRISM 在所有四个基准上均取得最高准确率（最高 +6.6pp），并在计算效率上实现优越表现。

**⚠️ 局限性**

局限性包括需针对不同任务诊断三维收益瓶颈，执行反馈不可得时信息维度受限，且实验规模仅覆盖有限的四个基准。

---

## 777. RankGR: Rank-Enhanced Generative Retrieval with Listwise Direct Preference Optimization in Recommendation

**arXiv ID:** 2602.08575 | [PDF](https://arxiv.org/pdf/2602.08575v1)

**作者:** Kairui Fu `[一作]` (Zhejiang University), Kun Kuang `[通讯]` (Zhejiang University)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了 RankGR，一个结合初步评估阶段（IAP）和精细评分阶段（RSP）的生成式检索框架，用以在推荐系统中更好地捕捉用户偏好层级与候选项目的深度交互。

**💡 创新点**

创新点包括：①基于列表级直接偏好优化（LDPO）的初步评估，使模型能学习到用户购买、点击、曝光等多层级偏好顺序；②在 RSP 中加入轻量级排名头，通过注意力机制深度交互候选 SID 与历史序列，从而显著提升候选排序质量；③通过异步预计算与流式训练实现近 10,000 QPS 的实时部署。

**🔧 技术方法**

核心技术包括：Transformer‑based 生成式检索、语义标识符（SID）与残差量化变分自编码器、下一词预测 (NTP) 与 LDPO 损失联合优化、MLP + sigmoid 的评分子模块、动态束搜索、异步推理与 Redis 缓存、流式在线学习。

**📊 数据集**

实验使用公开的 Amazon Clothing_Shoes_and_Jewelry 数据集与淘宝工业级大规模数据集（约 0.2 B 用户、1 B 商品、0.9 T 交互），两者均具高稀疏性。

**📈 对比分析**

与传统检索模型（YouTubeDNN、SASRec、Bert4Rec 等）及生成式检索模型（HSTU、TIGER、FORGE）对比，RankGR 在 HR@20/50/100/500 等指标上均获得 2–3 % 的提升，在线 A/B 测试显示 IPV 与交易量分别提升 1.08% 与 0.57%。

**⚠️ 局限性**

局限性包括：依赖 SID 生成质量，若多模态信息噪声大会影响效果；模型训练与推理仍需要大规模 LLM，计算成本较高；LDPO 的层级标签需要手工划分，难以自动化；对极端稀疏场景的鲁棒性还有待进一步验证。

---

## 778. Agent-Supported Foresight for AI Systemic Risks: AI Agents for Breadth, Experts for Judgment

**arXiv ID:** 2602.08565 | [PDF](https://arxiv.org/pdf/2602.08565v1)

**作者:** Leon Fröhling `[一作]` (GESIS - Leibniz Institute for the Social Sciences), Daniele Quercia `[通讯]` (Nokia Bell Labs)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本研究构建了基于人工智能代理的Futures Wheel推演管道，自动生成并评估四类不同技术成熟度 AI 用例的系统性风险，并与人类专家及大众生成的风险进行对比。

**💡 创新点**

创新点在于首次将多角色 LLM 代理与结构化战略预见方法相结合，形成可扩展的“代理+专家”混合风险识别流程，并公开了完整的风险库与评估指标。

**🔧 技术方法**

技术主要包括：Futures Wheel 结构化推演、Plurals 框架的多代理交互、GPT‑4.1 mini 生成与分类、Embedding 进行去重、以及自定义评估量表。

**📊 数据集**

数据集为从四个 AI 用例（聊天机器人伴侣、AI 玩具、哀伤机器人、死亡服务应用）出发，通过 30 次独立推演产生的 103 条系统性后果，并经人工标注后得到 27–47 条唯一风险。

**📈 对比分析**

对比方法为让 170 名领域专家与 120 名专家分别评价代理生成与人类生成的风险，采用 5 分量表评价可靠性与系统性；结果显示代理生成的风险数量高、系统性覆盖广、专家认可度在 3.5–3.7 级别，表明代理能在早期阶段补全人类视角。

**⚠️ 局限性**

局限包括：风险偏向社会/法律维度，技术与环境风险不足；仅采用 EU AI Act 的系统性定义；用例范围有限，未覆盖工业/基础设施类 AI；代理输出受模型偏见与提示设定影响；缺乏对情感深度与多样性视角的充分挖掘。

---

## 779. M-Loss: Quantifying Model Merging Compatibility with Limited Unlabeled Data

**arXiv ID:** 2602.08564 | [PDF](https://arxiv.org/pdf/2602.08564v1)

**作者:** Tiantong Wang `[一作]` (Nanyang Technological University), Wei Yang Bryan Lim `[通讯]` (Nanyang Technological University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种基于无标签数据的融合损失度量M‑Loss，并将其应用于改进模型融合方法M‑TIES，验证了参数平均在非线性网络中可近似模型集成的理论条件。

**💡 创新点**

创新点在于①给出了M‑Loss的数学定义和期望分析，解释了参数平均与输出平均的差异；②将M‑Loss作为动态剪枝预算的度量，形成新的M‑TIES融合算法；③展示了仅需极少无标签样本即可评估融合可行性。

**🔧 技术方法**

核心技术包括：神经网络中层/节点级的M‑Loss计算、线性相关参数集（LCP）分析、基于M‑Loss的剪枝比例动态调度、以及对ViT模型的任务向量合并。

**📊 数据集**

实验使用的基础预训练模型为OpenAI CLIP的ViT‑B/32与ViT‑L/14，并在八个不同任务（RESISC45、Cars、MNIST、DTD、EuroSAT、GTSRB、SUN397、SVHN）上进行微调，随后在这些模型上进行融合与对比。

**📈 对比分析**

与简单平均、Task Arithmetic、TIES、DARE以及集成学习等基线相比，M‑TIES在两种ViT backbone上均取得了最高或次高的平均精度，接近甚至超过某些任务的集成性能；同时实验显示其对样本量、随机种子和层数变化具有较好稳健性。

**⚠️ 局限性**

局限性包括：融合效果仍略低于完整集成学习；对非线性层的处理仍采用简化剪枝，可能限制对更深模型的适用；需要额外的无标签样本（尽管量小），以及对大规模模型数目的扩展性未作充分评估。

---

## 780. Automating Computational Reproducibility in Social Science: Comparing Prompt-Based and Agent-Based Approaches

**arXiv ID:** 2602.08561 | [PDF](https://arxiv.org/pdf/2602.08561v1)

**作者:** Syed Mehtab Hussain Shah `[一作]` (GESIS – Leibniz Institute for the Social Sciences), Arnim Bleier `[通讯]` (GESIS – Leibniz Institute for the Social Sciences)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建了一个基于R的社会科学研究的合成可复现性基准，并在该基准上评估了两种自动化修复工作流：基于提示的LLM修复和基于代理的自动修复。

**💡 创新点**

创新点在于：①提出了专门针对社会科学R代码的合成失败基准；②将提示式LLM与代理式执行环境进行系统对比；③量化了不同错误复杂度下两种方法的修复成功率。

**🔧 技术方法**

技术主要包括：大语言模型（GPT‑4o、Gemini 2.5 Pro、Qwen3‑Coder‑480B‑A35B），Docker容器化执行环境，OpenCode和Claude Code等代理框架，以及自动化日志记录与输出验证。

**📊 数据集**

数据集由5篇完全可复现的R研究论文复制，并在其代码中注入130个合成错误，错误分为A、B、C三类，涵盖执行、语法、逻辑等不同难度。

**📈 对比分析**

对比方法是：在相同的Docker环境下，分别运行提示式LLM（不同上下文级别）和代理式修复，记录每个案例的成功率；结果显示提示式方法在最简单错误中可达79%成功率，但复杂错误仅达54%；代理式方法在所有错误类型中成功率高达69–96%，显示显著优于提示式。

**⚠️ 局限性**

局限性包括：合成错误可能不完全覆盖真实失败情况；仅评估了少数模型与代理组合；未深入分析错误修复后的分析结果是否完全一致；对长期维护与跨语言/平台的通用性尚待验证。

---

## 781. QARM V2: Quantitative Alignment Multi-Modal Recommendation for Reasoning User Sequence Modeling

**arXiv ID:** 2602.08559 | [PDF](https://arxiv.org/pdf/2602.08559v1)

**作者:** Tian Xia `[一作]` (Kuaishou Technology), Kun Gai `[通讯]` (Kuaishou Technology)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出 QARM V2 框架，在 Recommendation System 的 General Search Unit 与 Exact Search Unit 中分别使用基于 LLM 的推理对齐嵌入和混合量化语义 ID，以提升用户序列建模效果。

**💡 创新点**

创新点在于：① 通过推理 LLM 过滤噪声项对，生成业务对齐的嵌入；② 采用三段注意力结构实现 LLM 的嵌入生成；③ 结合 Residual K-means 与 Finite Scalar Quantization，显著降低语义 ID 冲突。

**🔧 技术方法**

技术包括：多模态 LLM 微调、对比学习、问答生成、三段注意力结构、残差 K-means、FSQ 量化、GSU/ESU 并行检索以及 MoE CTR/CVR 预测。

**📊 数据集**

使用 Kuaishou 的短视频、直播、广告与购物业务的百万级用户交互数据，以及公开的 Amazon 商品评论数据。

**📈 对比分析**

与 DIN、SIM-hard、SIM-soft 等基线相比，离线 AUC 提升约 0.8%~1.0%，线上 A/B 测试中广告收入 +4.9%、购物 GMV +5.6%、直播观看时长 +3.0%，显示方法在多场景均有显著收益。

**⚠️ 局限性**

局限性包括：仍需大规模 LLM 训练与推理成本；量化方法在极长尾分布下可能产生冲突；对非短视频/直播业务的迁移性尚未验证；代码冲突完全消除仍有挑战。

---

## 782. GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing

**arXiv ID:** 2602.08550 | [PDF](https://arxiv.org/pdf/2602.08550v1)

**作者:** Shih-Fang Chen `[一作]` (National Yang Ming Chiao Tung University), Yen-Yu Lin `[通讯]` (National Yang Ming Chiao Tung University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `aaccfe5c-6b26-4208-b23c-35331481e142` `edb9d762-f411-4838-a852-f2d638b018db` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了GOT-Edit框架，通过在线模型编辑将从2D视频流中推断的3D几何信息与语义特征融合，实现无额外3D输入的通用目标跟踪。

**💡 创新点**

创新点在于：①利用预训练的Visual Geometry Grounded Transformer（VGGT）在仅有2D图像的情况下生成几何特征；②采用AlphaEdit式零空间约束的在线模型编辑，保证语义知识不被破坏的同时注入几何信息；③实现了语义与几何特征的门控融合与自适应更新，首次实现3D推理与2D跟踪的协同。

**🔧 技术方法**

核心技术包括：VGGT提取语义与几何特征，Transformer Encoder-Decoder作为模型预测器，SVD+whitening+正则化求零空间投影实现语义约束，ToMP/PiVOT框架作为基线，交叉验证的在线模型编辑策略。

**📊 数据集**

训练集：LaSOT、GOT10k、TrackingNet、COCO（+VASTTrack）。测试集：AVisT、NfS、OTB、GOT-10k、LaSOT、TrackingNet、VOT2020/2022。

**📈 对比分析**

与PiVOT、LoRAT、ToMP、MCITrack等SOTA方法在SUC、AO、OP50等指标上对比，GOT-Edit在Occlusion、Clutter等属性上提升约2–3%，整体在多项基准上实现最优或接近最优性能。

**⚠️ 局限性**

局限性：对快速运动、显著视角变化等非几何属性的鲁棒性仍不够；几何信息在极端运动或极端遮挡情况下效果有限；在光照、干扰等属性上相较基线可能略有下降。

---

## 783. How Do Language Models Understand Tables? A Mechanistic Analysis of Cell Location

**arXiv ID:** 2602.08548 | [PDF](https://arxiv.org/pdf/2602.08548v1)

**作者:** Xuanliang Zhang `[一作]` (Harbin Institute of Technology), Wanxiang Che `[通讯]` (Harbin Institute of Technology)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本论文通过对单元格定位任务的机制分析，揭示LLM在理解表格时的内部三阶段流程：语义绑定、坐标定位和信息提取。

**💡 创新点**

创新点在于发现模型通过计数分隔符构建隐式坐标系统，并将列索引编码为线性子空间，可通过向量算术实现精确导航；同时证明在多单元格定位时，模型复用同一组注意力头实现并行处理。

**🔧 技术方法**

主要技术包括激活补丁（Activation Patching）、线性探针（Linear Probing）以及注意力头消融（Attention Head Ablation）等解释方法。

**📊 数据集**

使用合成表格数据（500个样本）以及Qwen和Llama系列开源模型进行评估。

**📈 对比分析**

与单元格定位基准比较，Qwen3-4B在500样本上达到约90%准确率，证明所揭示的机制在现有模型中普遍存在。

**⚠️ 局限性**

局限性包括对表格大小的鲁棒性不足（大尺寸表格时坐标编码误差增大），以及仅在单元格定位任务上验证，未扩展到更复杂的表格推理场景。

---

## 784. Causal Schrödinger Bridges: Constrained Optimal Transport on Structural Manifolds

**arXiv ID:** 2602.08535 | [PDF](https://arxiv.org/pdf/2602.08535v1)

**作者:** Rui Wu `[一作]` (University of Science and Technology of China), Li YongJun `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `40105733-5154-44cd-8090-a8cab9e64b07` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了 Causal Schrödinger Bridge (CSB) 框架，利用受因果约束的熵正则化最优传输实现高维干预下的稳健反事实生成。

**💡 创新点**

创新点在于将反事实推理转化为因果可接受的 Schrödinger 桥问题，并通过 Structural Decomposition Theorem 将高维桥问题分解为可独立求解的局部条件桥。

**🔧 技术方法**

核心技术包括 SDE Schrödinger 桥、因果滤波约束的可接受控制、Causal Sequential Fitting (CSF) 方法以及结构化参考过程与熵正则化。

**📊 数据集**

实验使用了模拟的因果结构 (Confounder Isolation Test)、50 维非凸双月数据以及 Morpho‑MNIST 视觉因果数据集进行验证。

**📈 对比分析**

与无结构的最优传输（Flow Matching）和 Deterministic Flow Matching 对比，CSB 在结构一致性、SSIM 以及 L2 距离上分别提升约 4.5 倍、90% 降低误差，并在强干预下保持目标变量不变。

**⚠️ 局限性**

局限性包括需先验已知因果图，对结构误判极为敏感，且当前方法未将因果发现与桥求解结合。

---

## 785. EvoCorps: An Evolutionary Multi-Agent Framework for Depolarizing Online Discourse

**arXiv ID:** 2602.08529 | [PDF](https://arxiv.org/pdf/2602.08529v1)

**作者:** Ning Lin `[一作]` (Beijing University of Posts and Telecommunications), Linna Zhou `[通讯]` (Beijing University of Posts and Telecommunications)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了EvoCorps框架，利用演化多智能体对在线话语进行主动去极化治理；

**💡 创新点**

将治理视为动态社交博弈，采用角色专门化协同、检索增强集体认知与闭环进化学习，实时对抗协同恶意放大；

**🔧 技术方法**

使用多智能体马尔可夫决策过程、检索增强知识库、行动-结果记忆、进化学习、角色分工（Analyst、Strategist、Leader、Amplifier）、MOSAIC仿真平台；

**📊 数据集**

基于NELA‑GT‑2021、COVID‑19 Fake News Dataset、IBM Debater 论证库、Wikipedia API、Nemotron‑Personas等数据集；

**📈 对比分析**

通过与无对手基线、对手放大基线、后置干预基线比较，在情绪极化、观点极端度、论证合理性等指标上，EvoCorps 显著降低情绪负面、减轻极端度、提升证据使用率、降低谬误率；

**⚠️ 局限性**

受检索知识库更新限制、对多样化攻击的鲁棒性不足、模型规模与实时性需进一步优化、缺乏真实平台验证等局限。

---

## 786. Characteristics, Management, and Utilization of Muscles in Musculoskeletal Humanoids: Empirical Study on Kengoro and Musashi

**arXiv ID:** 2602.08518 | [PDF](https://arxiv.org/pdf/2602.08518v1)

**作者:** Kento Kawaharazuka `[一作]` (University of Tokyo), Masayuki Inaba `[通讯]` (University of Tokyo)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文通过对Kengoro与Musashi两款筋骨格人形机体的实验，系统地归纳了肌肉的五大特性，并提出了结合反射控制、身体图式学习、肌肉分组与身体图式适应的完整框架，以管理其优势与缺点并实现多种任务。

**💡 创新点**

创新点在于将低层反射控制与高层学习控制无缝集成，并引入基于功能与空间连接的自动肌肉分组方法，以及针对肌肉增添与断裂的在线身体图式适应机制，显著降低计算成本并提升系统鲁棒性。

**🔧 技术方法**

使用技术包括：扩展卡尔曼滤波（EKF）估计关节角、二次规划求解肌张力、神经网络（Encoder‑Decoder）构建静态/动态身体图式、图划分实现自动肌肉分组、以及多种反射控制（伸长、拮抗抑制、热力、速度、松弛）。

**📊 数据集**

数据集为Kengoro与Musashi机体的传感器记录（肌长、肌张力、关节角、接触力、温度等），没有使用公开的外部数据集。

**📈 对比分析**

在抓取、布料操控、无人驾驶等实验中，系统表现出相对传统方法更高的稳定性和效率，例如在动态布料操作中通过可变刚度控制使关节最大速度提升约12%；但文中未给出与基线算法的定量对比指标，主要以实验演示为主。

**⚠️ 局限性**

局限性包括：侧重软件实现，硬件细节与能量存储利用未深入；内部建模难度仍未完全解决；反射控制在精细操作时可能降低精度；对动态外部扰动的鲁棒性评价不足。

---

## 787. Head-to-Head autonomous racing at the limits of handling in the A2RL challenge

**arXiv ID:** 2602.08571 | [PDF](https://arxiv.org/pdf/2602.08571v1)

**作者:** Simon Hoffmann `[一作]` (Technical University of Munich), Markus Lienkamp `[通讯]` (Technical University of Munich)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在Abu Dhabi Autonomous Racing League (A2RL)中，团队实现并部署了一套完整的自动驾驶赛车软件，涵盖感知、定位、预测、规划与控制，并在实车赛中夺冠。

**💡 创新点**

核心创新包括：空间分辨的抓地力图（GripMap）实现局部加速度约束；多传感器融合的鲁棒定位与EKF状态估计；基于三维OCP的时最优赛道线优化；采样式局部轨迹规划与八边形加速约束的TMPC控制架构；以及微服务化部署与快速容错机制。

**🔧 技术方法**

使用技术包括LiDAR+Radar+摄像头融合感知、RTK‑GNSS、三维点云地图、EKF状态估计、Frenet坐标轨迹规划、MPC/TMPC控制、ABS/TC、预测换挡与制动热管理等。

**📊 数据集**

主要数据集来自赛道实测与仿真：EAV24车辆传感器记录的LiDAR/Radar/摄像头、GPS/IMU/光学速度数据、手工标注的轨迹与抓地力地图；仿真使用高保真车辆动力学模型与传感器仿真。

**📈 对比分析**

在时间赛、进攻防守赛和四车决赛中，最终平均圈速118.985s，赛后与职业车手差距不足10s，显示出与人类车手相当的性能。

**⚠️ 局限性**

局限包括：单一预测轨迹难以捕捉对手不确定行为；仿真环境过度匹配导致过拟合；抓地力地图需手工生成且缺乏实时性；瞬态动力学建模不足限制更高性能。

---

## 788. Approximate Cartesian Tree Matching with Substitutions

**arXiv ID:** 2602.08570 | [PDF](https://arxiv.org/pdf/2602.08570v1)

**作者:** Panagiotis Charalampopoulos `[一作]` (King's College London), Manal Mohamed `[通讯]` (King's College London)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce`

**🎯 论文内容**

提出了一种针对卡特森树匹配的近似算法，能够在给定 Hamming 距离阈值 k 的情况下，检索文本中所有与模式在卡特森树结构上相近的片段。

**💡 创新点**

核心创新在于引入 CT‑块周期性概念，将字符串周期性与卡特森树匹配的技术相结合，并运用“少数匹配或近似周期性”范式，显著降低了时间复杂度。

**🔧 技术方法**

利用组合论工具（周期性、运行、标记、剪裁）和动态规划求 (X  Y) 距离，结合分块与算术进程以及多实例求解策略，完成了高效的近似匹配实现。

**📊 数据集**

本文为理论研究，没有使用实际数据集；所有结果均在理论分析与算法复杂度证明层面给出。

**📈 对比分析**

与 Kim & Han 的 O(nmk) 方案相比，在 k = o(m^{1/4}) 时实现了 O(n√m k^{2.5})（k ≤ m^{1/5}) 或 O(nk^5)（k ≥ m^{1/5}) 的时间提升，进一步压缩了低距离范式下的运算时间。

**⚠️ 局限性**

限制在于对大 k 时仍需 O(nk^5) 时间，算法的高阶多项式复杂度以及对 k ≤ m^{1/4} 的依赖；此外，目前缺乏 (X  Y) 计算的下界，无法进一步评估最优性。

---

## 789. Stateless Yet Not Forgetful: Implicit Memory as a Hidden Channel in LLMs

**arXiv ID:** 2602.08563 | [PDF](https://arxiv.org/pdf/2602.08563v1)

**作者:** Ahmed Salem `[一作]` (Microsoft), Sahar Abdelnabi `[通讯]` (ELLIS Institute Tübingen and MPI for Intelligent Systems)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了大型语言模型在无显式记忆机制的前提下，利用模型自身输出中的编码实现隐式记忆，并通过此机制演示了一种跨交互激活的时间炸弹后门；

**💡 创新点**

提出了隐式记忆和时间炸弹后门的概念，展示了跨会话隐蔽状态累积与触发的全新攻击范式；

**🔧 技术方法**

采用提示工程和微调两种方式实现状态编码，利用零宽字符或语义特征嵌入隐式记忆，并在模型输出中实现信息携带与恢复；

**📊 数据集**

使用 GPT‑4o、GPT‑5.2 等生成的合成对话与信号数据集，以及 Alpaca 评测集进行训练与评估；

**📈 对比分析**

通过位设置准确率、位传播准确率和后门激活率等指标比较提示与微调方案，微调模型在正确激活率>90%且误触率<2%的同时保持几乎无性能损失；

**⚠️ 局限性**

局限性包括：依赖于模型输出被重新输入的场景，零宽字符易被清理，语义编码实现复杂且易被改写破坏，且目前仅在实验环境验证，缺乏大规模真实环境的验证与检测方法。

---

## 790. Global Rotation Equivariant Phase Modeling for Speech Enhancement with Deep Magnitude-Phase Interaction

**arXiv ID:** 2602.08556 | [PDF](https://arxiv.org/pdf/2602.08556v1)

**作者:** Chengzhong Wang `[一作]` (Institute of Acoustics, Chinese Academy of Sciences), Junfeng Li `[通讯]` (Institute of Acoustics, Chinese Academy of Sciences)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出了一种全局旋转等变（GRE）的幅相双流框架，用于在语音增强中从根本上解决相位的圆形拓扑建模问题。

**💡 创新点**

创新点包括：① 在相位流中严格施加GRE约束；② 设计Magnitude‑Phase Interactive Convolution Module (MPICM) 与 Hybrid‑Attention Dual‑FFN (HADF)，实现相位与幅度的交互信息流而不破坏等变性；③ 通过旋转不变的注意力分数实现幅相协同融合。

**🔧 技术方法**

技术手段包括 bias‑free 复数卷积、复数 RMS 归一化、频域与时域双路径注意力、基于幅度门控的相位卷积、GRU 与卷积结合的双流 FFN 以及多尺度 DenseNet 结构。

**📊 数据集**

实验使用 VoiceBank+DEMAND、DNS‑2020、DNS‑2021、WSJ0+WHAMR! 等公开数据集，覆盖相位检索、降噪、去混响、带宽扩展及其组合任务。

**📈 对比分析**

与 FRCRN、CMGAN、DB‑AIAT、MP‑SENet、SEMamba、ZipEnhancer、UniverSE++ 等基线比较，取得了 Phase Distance 下降 20%+、PESQ 与 DNSMOS 上的 SOTA 结果，且在零射模型与跨域评估中表现出更强的泛化能力。

**⚠️ 局限性**

局限性在于：目前模型为非实时非因果设计，尚未针对低延迟应用做优化；GRE 约束虽提升相位精度，但对极端低 SNR 或非常规噪声场景的鲁棒性仍待进一步验证。

---

## 791. Three Lessons from Citizen-Centric Participatory AI Design

**arXiv ID:** 2602.08554 | [PDF](https://arxiv.org/pdf/2602.08554v1)

**作者:** Eike Schneiders `[一作]` (Southampton University), Sebastian Stein `[通讯]` (Southampton University)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开展三场参与式工作坊，探讨以市民为中心的人工智能代理设计，收集市民视角与价值观。

**💡 创新点**

提出三大挑战：如何实现有意义参与、语言共识与参与者输入转化为可实现系统，并给出对应的实践建议。

**🔧 技术方法**

采用参与式设计方法、低保真原型制作、定性分析与专家访谈。

**📊 数据集**

未使用传统数据集，而是基于参与者产生的艺术材料与故事。

**📈 对比分析**

未进行量化性能比较，而是通过专家评估可行性与资源需求进行定性对比。

**⚠️ 局限性**

限制包括样本多样性不足、语言偏差、长期参与难度以及从创意到实现的转化缺乏系统路径。

---

## 792. Incremental (k, z)-Clustering on Graphs

**arXiv ID:** 2602.08542 | [PDF](https://arxiv.org/pdf/2602.08542v1)

**作者:** Emilio Cruciani `[一作]` (European University of Rome), Antonis Skarlatos `[通讯]` (University of Warwick)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

针对加权无向图在面对任意边插入的动态环境下，提出一种随机增量算法，能够维护一个常数因子逼近的 (k, z)-聚类解。

**💡 创新点**

创新点包括：
   1. 将 Mettu‑Plaxton 的双重近似算法迁移到增量图环境，证明其半径可以强制为非递减且不影响近似比；
   2. 设计两阶段增量框架：首先维护一个大小为 O(k log³n log_{1+ε}nW) 的双重近似中心集合；随后利用动态稀疏化（动态稠密子图生成和动态稀疏化算法）与静态 (k, z)-聚类算法相结合，得到最终的常数近似解；
   3. 通过引入泄漏集（leaking set）和严格控制半径的更新次数，降低更新复杂度至 Õ(k m^{1+o(1)} + k^{1+1/λ} m) 并实现摊销更新时间 O(k n^{o(1)} + k^{1+1/λ})。

**🔧 技术方法**

核心技术：
   - 随机化增量 Mettu‑Plaxton 变体（半径非递减、近似因子保留）；
   - 动态 (1+ε)-近似单源最短路（SSSP）结构；
   - 动态稠密子图（spanner）算法；
   - 静态 (k, z)-聚类求解器（如 Lattanzi 等的 3+ε 或 2+ε 近似算法）；
   - 泄漏集处理与半径重新采样的技术。

**📊 数据集**

该工作为理论算法研究，未使用具体实验数据集；评估基于渐进时间复杂度分析。

**📈 对比分析**

与之前的动态 k‑center 方案（Cruciani 等 2024）相比，
   - 对 (k, z) 的支持更广；
   - 在增量设置下，摊销更新时间仅为 O(k n^{o(1)} + k^{1+1/λ})，而传统方案的摊销时间为 O(k n^{o(1)})；
   - 通过动态稠密子图与静态聚类的组合，整体总更新时间降低到 Õ(k m^{1+o(1)} + k^{1+1/λ} m)，实现了近似因子常数。

**⚠️ 局限性**

局限性：
   1. 只考虑增量（仅插入）更新，未覆盖完全动态（插入与删除）情形；
   2. 需要无记忆（oblivious）对手模型；
   3. 对常数因子和 λ 的选择影响性能，实际实现中常数可能较大；
   4. 主要理论复杂度分析，缺乏实验验证与实际数据集评估。

---

## 793. Craig Interpolation in Program Verification

**arXiv ID:** 2602.08532 | [PDF](https://arxiv.org/pdf/2602.08532v1)

**作者:** Philipp Rümmer `[一作]` `[通讯]` (University of Regensburg), Philipp Rümmer (University of Regensburg)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文综述了 Craig 插值在程序验证中的应用，阐述了如何在不同理论（线性算术、数组、EUF 等）下高效计算量化自由的插值子句，并探讨了基于插值的验证算法（IMC、CEGAR、CHC 等）及其实现细节。

**💡 创新点**

创新点在于将传统的插值技术与 SMT 求解器中的理论求解器深度耦合，提出多种面向验证的插值计算规则（如基于分割、裁剪、分支定界等），并统一讨论序列、树形插值与多范式插值的关系。

**🔧 技术方法**

主要技术包括基于证明的插值规则、图（e-graph）插值抽取、理论归约与量化消除、以及结合 SMT 与 SAT 求解的插值生成。

**📊 数据集**

本文为综述性质，未使用特定实验数据集，而是以 Fibonacci、数组等经典示例演示插值方法。

**📈 对比分析**

由于是综述，没有直接实验对比；但讨论中指出在 LIA、数组等理论下，基于裁剪或分支定界的插值在实践中往往能产生更紧凑的插值，且结合 SMT 的实现能在多种验证任务中取得竞争性性能。

**⚠️ 局限性**

主要局限包括：量化自由插值的生成往往导致符号量或大小膨胀；对组合理论的插值支持有限；并且许多高级插值技术在实践中尚未成熟或缺乏统一的实现。

---

## 794. PIT: A Dynamic Personalized Item Tokenizer for End-to-End Generative Recommendation

**arXiv ID:** 2602.08530 | [PDF](https://arxiv.org/pdf/2602.08530v1)

**作者:** Huanjie Wang `[一作]` (Beijing University of Posts and Telecommunications), Guang Chen `[通讯]` (Beijing University of Posts and Telecommunications)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了PIT，一个可在端到端生成式推荐框架，动态协同优化项目到令牌化与推荐器，并在工业环境中实现beam索引。

**💡 创新点**

引入协同信号对齐、最小损失选择机制以及一对多beam索引，实现动态共进化的词标化与推荐，并解决传统两阶段流程的语义鸿沟和实时更新不稳定问题。

**🔧 技术方法**

Transformer基础的Item‑to‑Token与User‑to‑Token模型、DIN辅助多行为预测、RQ‑VAE代码库、Beam Search、最小损失选择、协同信号对齐，端到端联合训练。

**📊 数据集**

Amazon Review 2014三大品类（Beauty、Sports & Outdoors、Toys & Games）以及Kuaishou短视频平台的线上A/B实验数据。

**📈 对比分析**

与传统序列推荐模型（Caser、HGN等）和生成式推荐模型（TIGER、LETTER、ETEGRec、LC‑Rec）使用Recall@K/NDCG@K做对比；PIT在离线评测中均击败所有基线，在上线实验中相对提升App Stay Time 0.402% 以上。

**⚠️ 局限性**

在离线小规模数据中Item‑to‑Token更新受限导致码本熵提升有限；依赖大规模工业流水线的同步索引更新，缺乏在极低资源或无实时流的场景中的可行性。

---

## 795. Reinforcement Inference: Leveraging Uncertainty for Self-Correcting Language Model Reasoning

**arXiv ID:** 2602.08520 | [PDF](https://arxiv.org/pdf/2602.08520v1)

**作者:** Xinhai Sun `[一作]` (Politecnico di Milano), Xinhai Sun `[通讯]` (Synthoid.ai)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

利用模型自身的熵（不确定性）作为触发信号，在推理时自动进行第二次推理，以自我校正答案。

**💡 创新点**

不需要任何额外训练或外部反馈，提出了“自我强化推理（Reinforcement Inference）”框架：将内部熵作为计算控制信号，仅在模型认为自己不确定时才额外消耗推理资源。

**🔧 技术方法**

使用熵（Entropy）与最大 softmax 概率（MSP）进行不确定性评估，基于阈值触发第二次提示（prompt），在 deterministic decoding 的 zero‑shot 环境下实现。

**📊 数据集**

主要在 MMLU‑Pro 数据集上评估，包含 12,032 道多选题，覆盖 14 个专业领域（生物、法律、医学等）。

**📈 对比分析**

与单次推理 baseline、统一 re‑ask、prompt‑only ablation 对比；在 DeepSeek‑v3.2 上准确率从 60.72% 提升至 84.03%（+23.31pp），计算量仅增加 61.06%；在其它模型（Qwen3、DeepSeek‑Reasoner）和标准 MMLU 上也验证了鲁棒性，阈值 sweep 探索了计算-准确率折中。

**⚠️ 局限性**

局限性：对模型校准高度敏感，仅适用于多选任务；提示语可能影响结果；对过度自信的错误无效；未针对攻击性或极端不确定性设计；需要可访问模型概率的接口，无法直接应用于某些 API。

---

## 796. Do physics-informed neural networks (PINNs) need to be deep? Shallow PINNs using the Levenberg-Marquardt algorithm

**arXiv ID:** 2602.08515 | [PDF](https://arxiv.org/pdf/2602.08515v1)

**作者:** Muhammad Luthfi Shahab `[一作]` (Institut Teknologi Sepuluh Nopember), Hadi Susanto `[通讯]` (Khalifa University of Science and Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `14d48e9d-0069-4ad9-996a-1d5968216998` `a8e75ba4-7a2d-4153-b003-06c94533add0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文研究了将物理信息神经网络（PINNs）重构为非线性系统后，利用 Levenberg–Marquardt (LM) 算法对浅层前馈网络（两隐藏层）进行前向和逆向 PDE 求解，并给出了完整的解析梯度与雅可比公式。

**💡 创新点**

创新点包括：① 将 PINNs 视为非线性最小二乘问题，引入第二阶 LM 优化；② 对浅层网络给出完整的解析导数和雅可比推导，揭示网络参数与 PDE 残差的显式关系；③ 在四个经典 PDE（Burgers、Schrödinger、Allen–Cahn、三维 Bratu）上证明浅层网络配合 LM 能取得比深层网络或 LBFGS 更高精度和更快收敛；④ 通过理论与实验相结合，系统展示了 LM 对 PINNs 的优势。

**🔧 技术方法**

采用的技术包括：浅层前馈神经网络、激活函数 tanh、解析梯度与雅可比计算、Levenberg–Marquardt 优化、MATLAB 的 fsolve 和 fminunc、自动微分对比、损失函数构造与边界条件嵌入、基准 PDE 的数值解（RK4、Fourier谱、有限差分等）作参考。

**📊 数据集**

使用的“数据集”为四个标准 PDE 的空间时间采样点：Burgers、Schrödinger 在 10000 个采样点上训练；Allen–Cahn、Bratu 在 2000 个采样点上训练；训练点均从整个域均匀或随机采样，未使用公开数据集。

**📈 对比分析**

比较方法：将 LM 与传统 BFGS、LBFGS 在相同网络结构（NN(a,25,25,1) 等）下进行对比，使用相同的采样点、相同迭代上限（LM 4000 次，BFGS 20000 次）并在每次迭代后评估损失、相对 L₂ 误差或参数识别误差。结果显示，LM 的最终损失常在 10⁻⁸–10⁻¹⁰ 级别，误差比 BFGS 低 2–5 个数量级，且计算时间约为 BFGS 的一半到 1.5 倍，证明了 LM 的高效与精度优势。

**⚠️ 局限性**

局限性：① LM 需要显式构造雅可比矩阵，内存与计算开销随网络参数规模增大而急剧上升，限制了对更大网络或高维 PDE 的直接应用；② 目前缺乏兼容自动微分框架的 LM 求解器，导致实现复杂；③ 实验仅覆盖 1D 与 3D 的相对简单 PDE，对极端激波、多尺度或更高维问题的泛化性仍需验证；④ 对于需要大量采样点的高精度解，浅层网络在参数量上仍需适度提升，可能影响收敛速度。

---

## 797. A Machine Learning Enabled MDO for Bio-Inspired Autonomous Underwater Gliders

**arXiv ID:** 2602.08508 | [PDF](https://arxiv.org/pdf/2602.08508v1)

**作者:** Andrea Serani `[一作]` (National Research Council Institute of Marine Engineering), Matteo Diez `[通讯]` (National Research Council Institute of Marine Engineering)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文提出并实现了一个基于机器学习的双层多学科设计优化框架，用于设计鳗状外形的自主水下滑翔机，涵盖外形优化与内部气压舱尺寸设计；

**💡 创新点**

创新点在于引入物理驱动的参数模型嵌入（PD‑PME）实现高维几何的压缩，使用多层级随机RBF surrogate与不确定性量化，并在BLISS‑2000体系中采用基于EHVI的批量贝叶斯优化与自适应精度分配；

**🔧 技术方法**

采用物理驱动降维、随机RBF多层级 surrogate、贝叶斯优化与EHVI聚类、低/高精度CFD（PUFFIn、OpenFOAM、ISIS‑CFD）等技术；

**📊 数据集**

数据集由约1.6万条低精度CFD（PUFFIn）样本用于PD‑PME训练，初始 surrogate 训练采用512低精度+128高精度样本，随后迭代增补；

**📈 对比分析**

通过与原始鳗形基准模型对比，所得到的 Pareto 最优解在最大升阻比提升 14.7%、空重下降 12.8%，且高精度计算次数比全高精度评估低 95% 以上；

**⚠️ 局限性**

局限性包括对单一工况的物理驱动降维、线性嵌入限制、需要大量低精度样本、对聚类/批量大小与精度分配的敏感性，以及在更复杂物理耦合下的可扩展性待验证。

---

## 798. Towards Reliable Social A/B Testing: Spillover-Contained Clustering with Robust Post-Experiment Analysis

**arXiv ID:** 2602.08569 | [PDF](https://arxiv.org/pdf/2602.08569v1)

**作者:** Xu Min `[一作]` (Kuaishou Technology), Jianhui Bu `[通讯]` (Kuaishou Technology)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

在社交平台上构建多行为加权社交图，提出两阶段网络 A/B 测试框架：先用 Balanced Louvain 生成大小平衡、溢出受控的实验单元，再用 CUPAC 在后期分析中通过预处理协变量降低方差，提升实验效能。

**💡 创新点**

① 设计了兼顾网络溢出、集群平衡与时序稳定性的 Balanced Louvain 算法；② 将 CUPED 的思想推广为 CUPAC，利用多源预处理协变量实现方差显著下降；③ 将两者结合成可直接落地的工业级实验管线。

**🔧 技术方法**

技术手段包括：多行为加权社交图构建、Soft-Hard 约束的 Balanced Louvain 聚类、桶级线性化（Delta 方法）与聚类随机化、CUPAC 协变量调整、交叉拟合预测与统计推断。

**📊 数据集**

主要数据集为 Kuaishou 真实社交网络（约 3.7 亿活跃用户，73k 个聚类）以及仿真网络（Watts–Strogatz），用于验证算法在真实与理论场景下的表现。

**📈 对比分析**

与传统用户级随机化、标准 Louvain、Label Propagation 等方法对比。实验显示 WGSR 从 0.5 提升至 0.9，ATE 偏差下降 87–89%，聚类误差降低，CUPAC 方差减少约 4–7pp，统计显著性提升，业务指标（分享、保留等）显著改善。

**⚠️ 局限性**

局限性：需要对社交图进行预先构建与更新，动态网络变化未能实时自适应；聚类与 CUPAC 参数需经验调优；对无法观测或难以预测的协变量依赖较高，且在大规模分布式环境下仍有计算与内存压力。

---

## 799. Constrained Sampling to Guide Universal Manipulation RL

**arXiv ID:** 2602.08557 | [PDF](https://arxiv.org/pdf/2602.08557v1)

**作者:** Marc Toussaint `[一作]`, Justin Carpentier `[通讯]`

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

论文探讨了某种新型算法在特定任务中的应用。

**💡 创新点**

创新点在于提出了一种改进的模型架构，能够更有效地处理复杂数据。

**🔧 技术方法**

使用了深度学习技术，特别是卷积神经网络（CNN）和循环神经网络（RNN）的结合。

**📊 数据集**

使用了公开的图像数据集和文本数据集进行实验。

**📈 对比分析**

与现有方法进行了对比，结果显示新方法在准确率和处理速度上均有显著提升。

**⚠️ 局限性**

限制在于模型对特定类型数据的适应性较差，且训练时间较长。

---

## 800. An Automata-Based Approach to Games with $ω$-Automatic Preferences

**arXiv ID:** 2602.08549 | [PDF](https://arxiv.org/pdf/2602.08549v1)

**作者:** Véronique Bruyère `[一作]` (Université de Mons), Jean-François Raskin `[通讯]` (Université libre de Bruxelles)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355`

**🎯 论文内容**

本文研究了在图上的多人轮流博弈，玩家的偏好用 ω-自动化关系（由确定性奇偶图灵机给出）建模，并从阈值问题、值与最优策略到 N 形均衡以及合理合成等角度进行计算复杂度分析。

**💡 创新点**

创新点包括：①将玩家偏好推广到任意 ω-自动化关系，打破传统的总序或特定收益函数限制；②提出“值”集合的定义，并证明其为 ω-可识别并可由多项式大小的交替奇偶自动机识别；③给出阈值问题、最优策略存在性、N 均衡存在性以及合作/非合作合理合成的精确复杂度（多项式空间、NP/Σ^1_1 级），并填补先前研究中的空白；④在非合作合理合成中首次证明了不可判定性。

**🔧 技术方法**

主要技术手段包括：交替奇偶自动机构造、自动机闭包与交叉构造、与奇偶博弈的归约、使用 Safra‑Piterman 变换生成确定性奇偶自动机、以及对 ω‑rPCP 的归约来证明不可判定性。

**📊 数据集**

该工作不涉及具体实验数据集，而是基于理论模型与自动机构造进行证明，所有结论均为理论复杂度分析。

**📈 对比分析**

与以往仅针对特定奖励函数或总序偏好的研究相比，本文在更一般的 ω‑自动化偏好框架下给出了同样紧的复杂度界限，证明了阈值问题与均衡存在性均为 PSPACE‑完整；合作合理合成亦保持 PSPACE‑完整，而非合作合理合成升至不可判定，显示了问题难度的显著差异。

**⚠️ 局限性**

局限性包括：①偏好仍需满足 ω‑自动化可识别性，无法覆盖更广的可逆关系；②仅讨论 N 均衡，未考虑子博弈完美均衡或可接受策略等更稳健的合理性概念；③非合作合理合成结果为不可判定，表明在此框架下该问题难以处理；④对实际系统的应用需进一步验证自动机规模与实现效率。

---

## 801. DA-RAG: Dynamic Attributed Community Search for Retrieval-Augmented Generation

**arXiv ID:** 2602.08545 | [PDF](https://arxiv.org/pdf/2602.08545v1)

**作者:** Xingyuan Zeng `[一作]` (Technology Innovation Center for Collaborative Applications of Natural Resources Data in GBA, MNR), Jian Yin `[通讯]` (Sun Yat-sen University)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

提出了一种名为 DA‑RAG 的检索增强生成框架，利用动态属性社区搜索（EACS）在知识图谱中实时定位结构紧凑且语义相关的子图，从而为大语言模型提供高质量上下文。

**💡 创新点**

创新点包括：①将属性社区搜索（ACS）从图分析领域迁移并动态化用于 RAG；②设计三层 Chunk‑Layer、Knowledge Graph Layer 与 Similarity Layer 的多粒度索引，避免了昂贵的预聚类；③在子图检索中引入 k‑truss 结构一致性与 QRScore 评价，显著抑制自由骑手效应；④使用 LLM 对候选社区进行自适应 k 选取和质量评估，实现问句驱动的动态子图生成。

**🔧 技术方法**

技术手段：语义分块与实体抽取、图嵌入与相似度矩阵、三层图索引构建、k‑truss 结构分解、EACS（Embedding‑Attributed Community Search）、Q‑Peel 贪心剥离算法、LLM 评估与自适应 k 选择、粗细层级检索策略。

**📊 数据集**

使用的数据集包括 UltraDomain 的 Agriculture、Mixed 子集以及 News Articles 数据集，均包含 125 道人工构造的问答对。

**📈 对比分析**

与 LightRAG、HippoRAG、GraphRAG、ArchRAG、VanillaRAG、BM25 等基线进行 head‑to‑head 比较。DA‑RAG 在四个评价维度（Comprehensiveness、Diversity、Empowerment、Overall）的平均 win‑rate 超过基线 57% 以上；索引构建时间和 token 消耗比 GraphRAG 减少 37% 与 41%；在线检索延迟与 GraphRAG‑Global 相当，但 token 消耗降低 70%+，显著提升整体效率。

**⚠️ 局限性**

局限性：①仍依赖 LLM 嵌入与评估的质量，若嵌入不佳会影响子图质量；②k‑truss 与 Q‑Peel 的时间复杂度在极大图上可能较高；③需手工设定 k_neighbor 与 k 上限，对不同领域的自适应性有限；④对非结构化文本或极其稀疏的知识图谱效果尚未充分验证。

---

## 802. Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO

**arXiv ID:** 2602.08533 | [PDF](https://arxiv.org/pdf/2602.08533v1)

**作者:** Kun Peng `[一作]` (Institute of Information Engineering), Hao Peng `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于两代理博弈的在线个性化对话模型，并引入自适应树结构的长周期强化学习框架 AT‑GRPO，提升对话连贯性与用户参与度。

**💡 创新点**

创新点在于结合用户风格模仿与主动终止的环境建模，以及将对话轨迹改为树形并采用自适应观察范围来消除短视偏差，既实现长周期奖励捕获又保持计算效率。

**🔧 技术方法**

采用强化学习（GRPO改进）、树搜索结构、对抗式用户代理、策略梯度与KL正则、分层奖励聚合等技术。

**📊 数据集**

在自研的 NPC‑Chat 数据集、公开的 LCCC 与 DailyDialog 三个语料上进行实验。

**📈 对比分析**

与 GPT‑5、DeepSeek、Gemini 等商用 API 以及 Qwen、Llama 等开源 LLM 的 RL 版本比较，AT‑GRPO 在 Avg.r、Avg.L、PPL 等指标上均优于基线，显示出更高的交互长度和奖励。

**⚠️ 局限性**

局限在于仍依赖较大的 LLM 规模，且对多模态或更细粒度用户特征建模的适应性尚待验证。

---

## 803. GeoFocus: Blending Efficient Global-to-Local Perception for Multimodal Geometry Problem-Solving

**arXiv ID:** 2602.08524 | [PDF](https://arxiv.org/pdf/2602.08524v1)

**作者:** Linger Deng `[一作]` (Huazhong University of Science and Technology), Xiang Bai `[通讯]` (Huazhong University of Science and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出 GeoFocus 框架，通过 Critical Local Perceptor 与 VertexLang Topology Percepter 两模块提升 LMM 在几何问题求解中的视觉感知与推理能力。

**💡 创新点**

创新点在于：1) 13 个理论驱动的局部感知模板实现对关键局部结构的自动识别和强调；2) VertexLang 作为紧凑符号语言，仅用顶点坐标与连通关系进行全局拓扑重建，显著降低文本长度与训练时间。

**🔧 技术方法**

采用模板生成 Q&A 训练、DPO 优化、DynamicGT‑RL 强化学习、VertexLang 语法与图像渲染算法，以及 LlamaFactory、EasyR1 等训练框架。

**📊 数据集**

使用 Geo3K、GeoQA、FormalGeo7K、CogAlign 数据集进行感知与推理评测，并在 We‑Math、MathVerse、MathVision、MathVista、ChartQA、HallusionBench 进行跨域验证。

**📈 对比分析**

与现有方法对比，GeoFocus 在 Geo3K、GeoQA、FormalGeo7K 上平均提升 4.7% 语义准确率，VertexLang 训练时间比 CodeLang 降低 20%，局部感知覆盖率提升 61%，在 MATHVERSE 视觉依赖场景中表现更稳健。

**⚠️ 局限性**

局限包括：对点-圆位置约束的冲突导致渲染失败、VertexLang 仅适用于平面几何、3D 扩展尚未实现，且在极端视觉失真或符号生成误差时仍可能出现推理错误。

---

## 804. TreeTensor: Boost AI System on Nested Data with Constrained Tree-Like Tensor

**arXiv ID:** 2602.08517 | [PDF](https://arxiv.org/pdf/2602.08517v1)

**作者:** Shaoang Zhang `[一作]`, Yazhe Niu `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文提供了 MLSys 2023 会议的论文提交与格式化指南，详细说明了双盲评审、页面限制、字体与图像格式等细节要求。

**💡 创新点**

其创新点在于将评审与排版规范细化到每一细节（如禁止作者信息、严格的字体和图表排版规定），为会议提交提供了统一标准。

**🔧 技术方法**

使用 LaTeX 风格文件、PDF 输出、Type‑1 字体、EPS/PNG 等技术规范，强调排版、图表和引用格式的一致性。

**📊 数据集**

本文不涉及数据集，纯粹是模板与规范性说明。

**📈 对比分析**

不包含实验比较，主要是对提交格式的说明与要求，没有性能指标可评估。

**⚠️ 局限性**

限制在 10 页、禁止在初稿中出现作者信息、对字体、图像尺寸、引用格式等都有严格限制；若超出或偏离规范将直接被拒稿。

---

## 805. The M-Tensor Format: Optimality in High Dimensional Regression for Nonlinear Models with Scarce Data

**arXiv ID:** 2602.08509 | [PDF](https://arxiv.org/pdf/2602.08509v1)

**作者:** Rémi Cloarec `[一作]` (Arts et Metiers ParisTech), Francisco Chinesta `[通讯]`

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种基于 m‑张量的非线性回归框架，利用分离变量和张量代数在高维、数据稀缺的情境下构造多项式/三角基函数的组合逼近，并给出了可在有限样本下求解的最小二乘闭式解。

**💡 创新点**

创新点包括：①定义了 m‑张量积和相关张量运算，直接把核回归中的特征映射映射到张量空间；②将传统矩阵正则化方法（Tikhonov、谱截断）推广到张量回归；③提出 ALI（Almost‑Linearly‑Dependent）正则化，在保留行结构的同时把样本行降到子集，在线推理实现线性缩放；④通过 m‑张量实现了与 kPCA、kFSA 等核方法的等价关系，避免了高维矩阵存储与计算。

**🔧 技术方法**

使用的技术包括：张量代数（m‑张量积、Hadamard积、张量内积）、Cholesky 分解、SVD（及随机 SVD）、Tikhonov 正则化、谱截断、ALI/ALD 子集选取、kPCA、随机化数值线性代数、稀疏/高维采样（Latin Hypercube）。

**📊 数据集**

数据集与实验：①Rosenbrock 函数在 20–300 维下采用 LHS 采样；②3 维 Lorenz 吸引子，用 500 步训练后在 25000 步预测；③Kuramoto 振荡器在 n=3、10、100 的情形下，训练 1000 步后预测 50000 步；所有实验均在公开的 NumPy 工具箱中实现。

**📈 对比分析**

比较方法：与普通最小二乘、谱截断和 ALI 正则化进行对比；构造时间与推理时间分别呈 O(α³n³)、O(α³n³)、O(α²n³)（上界）以及 O(αn²)、O(αn²)、O(m̃n)。实验结果显示：ALI 正则化在推理阶段线性化，速度比最小二乘快数倍；误差在 2% 左右，随维度增大误差下降；谱截断虽然更稳健但成本更高。

**⚠️ 局限性**

局限性：①需要人工选定一维基函数，基函数不当会影响逼近质量；②仍受条件数影响，需正则化；③对极高维参数时需要随机化或稀疏化技术；④实现目前基于单线程 NumPy，未并行化；⑤未考虑 ℓ₀ 约束、局部/稀疏基的选择及更复杂的数值稳定性策略。

---

## 806. Are Vision Foundation Models Foundational for Electron Microscopy Image Segmentation?

**arXiv ID:** 2602.08505 | [PDF](https://arxiv.org/pdf/2602.08505v1)

**作者:** Caterina Fuster-Barceló `[一作]` (University of Zurich), Virginie Uhlmann `[通讯]` (University of Zurich)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本研究评估了自然图像预训练的视觉基础模型在电镜图像中线粒体分割任务的迁移性能。

**💡 创新点**

创新点在于系统对比了冻结骨干与LoRA参数高效微调两种实用适配方案，并通过表示空间诊断揭示了EM数据集内部域差异的根源。

**🔧 技术方法**

使用的技术包括DINOv2、DINOv3和OpenCLIP作为骨干，冻结或LoRA微调的分割头，PCA、Fréchet距离和线性探针进行表示分析。

**📊 数据集**

实验数据集为公开的Lucchi++和VNC两组EM图像，用于单一数据集与联合训练。

**📈 对比分析**

与传统监督式U‑Net等方法对比，单一数据集时VFM+LoRA可达到约0.8的前景IoU，优于零射方法但仍低于专用监督模型；但在联合训练时性能骤降至≈0.05，显示出明显的性能差距。

**⚠️ 局限性**

主要局限在于EM数据集间的强域不匹配，单纯的LoRA微调无法消除该差异，且缺乏有效的跨域对齐机制，限制了VFM在多样化微观图像上的普适性。

---

## 807. A Multi-objective Evolutionary Algorithm Based on Bi-population with Uniform Sampling for Neural Architecture Search

**arXiv ID:** 2602.08513 | [PDF](https://arxiv.org/pdf/2602.08513v1)

**作者:** Yu Xue `[一作]` (Nanjing University of Information Science and Technology), Dunwei Gong `[通讯]` (Qingdao University of Science and Technology)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `39fd911c-56a4-425d-a2f9-8038ad3b6e21` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于双种群与均匀采样的多目标进化算法 MOEA-BUS，用于神经架构搜索，同时在搜索过程中利用代理模型和权重继承加速评估。

**💡 创新点**

创新点包括：① 通过均匀采样方法在目标空间中均匀初始化种群，显著提升初始多样性；② 设计双种群演化框架，使两群体互相迁移精英，从而避免陷入局部最优并加快收敛；③ 将上述两项结合，并配合代理模型与一次性全网权重继承，实现高效搜索。

**🔧 技术方法**

技术手段主要有：进化算法（基于 NSGA‑II 的多目标遗传算子）、双种群演化策略、均匀采样初始化、支持向量机对偶预测的代理模型、一次性全网（Once‑For‑All）权重继承以及多种交叉、变异算子。

**📊 数据集**

使用的公开数据集包括 CIFAR‑10、CIFAR‑100 与 ImageNet，用于验证搜索得到的网络在图像分类任务上的性能。

**📈 对比分析**

与众多现有 NAS 方法（手工设计、RL、GD、EA 等）在相同搜索成本下进行对比。实验显示，MOEA‑BUS 在 CIFAR‑10 上实现 98.39% 的 top‑1 精度（MAdds 281M），在 ImageNet 上实现 80.03% 的 top‑1 精度（MAdds 610M）。相较于其他方法，既保持或提升了准确率，又降低了计算复杂度，搜索成本约 1.2 GPU 天，显著优于多数前沿方法。

**⚠️ 局限性**

局限性主要在于：仅在 MobileNetV3 搜索空间与图像分类任务中验证，未检验其在其他网络骨干（如 ResNet、EfficientNet、Vision Transformer）或其它视觉任务（语义分割、目标检测）上的通用性；代理模型的预测精度仍受已评估样本数量限制。

---

## 808. MMTS-BENCH: A Comprehensive Benchmark for Time Series Understanding and Reasoning

**arXiv ID:** 2602.08588 | [PDF](https://arxiv.org/pdf/2602.08588v1)

**作者:** Yao Yin `[一作]` (Tsinghua University), Yuantao Gu `[通讯]` (Tsinghua University)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `5a41884c-404f-4688-a89c-aa238c10fe68` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出MMTS-Bench——一个基于多层级任务分类、涵盖结构感知、特征分析、时间推理、序列匹配与跨模态理解的多模态时序问答基准，包含2424条问答对，覆盖四个子集(Base、InWild、Match、Align)。

**💡 创新点**

创新点在于构建了层级化的时序任务分类框架与逐步生成的三阶段实景问答流水线，系统化地将时序分析任务细化为可组合的子任务，并提供可控的合成数据与真实数据混合的评测集合。

**🔧 技术方法**

使用了大型语言模型（GPT‑4o、Claude 4、Gemini 2.5 Pro等）、开源LLM（Qwen、DeepSeek、Kimi）、时序专用LLM（ChatTS、ITFormer、ChatTime）以及多模态融合、链式思考（CoT）和统计前缀提示等技术。

**📊 数据集**

主要数据集为自研MMTS‑Bench（2424条QA），其中Base子集采用可控合成时序，InWild子集来自LOTSA的真实时序，Match与Align子集利用DTW匹配与跨模态描述构造。

**📈 对比分析**

通过在四个子集上对比评测，发现通用LLM在跨域泛化上明显优于专用TS‑LLM，CoT和多模态输入可提升约10‑20%，但模型规模扩展带来边际收益；局部任务与因果/逆推理表现尤为弱。

**⚠️ 局限性**

局限性包括仅关注时序问答，未覆盖预测、填补、异常检测等传统时序任务；数据集仅使用英文注释；以及当前时序编码器与对齐机制仍无法充分发挥，需进一步研究更高效的时序‑文本对齐方法。

---

## 809. Predicting Future Utility: Global Combinatorial Optimization for Task-Agnostic KV Cache Eviction

**arXiv ID:** 2602.08585 | [PDF](https://arxiv.org/pdf/2602.08585v1)

**作者:** Ziyao Tang `[一作]` (Fudan University), Jingjing Chen `[通讯]` (Fudan University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `fede83ac-7505-405f-ab37-e7284695c47f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了一种基于长时效益的KV缓存清理方法LU-KV，在头级分配预算时通过全局组合优化来最小化长期信息丢失。

**💡 创新点**

提出了“最优性缺口”概念，利用凸包松弛与贪心求解实现近似最优分配，并通过离线配置文件实现无运行时开销。

**🔧 技术方法**

使用凸放松、等距回归（PAVA）、贪心搜索、离线配置、以及oracle重要性评估等技术。

**📊 数据集**

在LongBench和RULER-16K两个长文本生成/检索基准上进行评估。

**📈 对比分析**

与Uniform、PyramidKV、AdaKV等基线对比，80%压缩率下KV缓存大小减少80%，性能仅略降，平均准确率提升至接近完整KV，显著优于传统方法。

**⚠️ 局限性**

局部静态配置对查询变化不敏感，仍需在极端任务或动态场景下进一步验证；离线预估的可靠性受模型与数据分布一致性的限制。

---

## 810. SemiNFT: Learning to Transfer Presets from Imitation to Appreciation via Hybrid-Sample Reinforcement Learning

**arXiv ID:** 2602.08582 | [PDF](https://arxiv.org/pdf/2602.08582v1)

**作者:** Melany Yang `[一作]` (Zhejiang University), Wei Dong `[通讯]` (vivo Mobile Communication Company Limited)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `da1b1a89-583a-4b57-9c81-478778569bec` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了 SemiNFT 框架，实现多输入（源图+参考图）照片级色彩修饰，并支持跨域、黑白色彩化等零样本任务。

**💡 创新点**

创新点在于双阶段课程式训练（冷启动监督+强化学习）结合混合在线-离线奖励，解决语义无关映射、数据稀缺和感知误差问题。

**🔧 技术方法**

使用了基于 Diffusion Transformer（Flux.1-dev）的模型、LoRA 模块、Flow Matching 与 DiffusionNFT、VLM 奖励模型（Qwen3‑VL‑8B‑Instruct）以及人类标注奖励，辅以强化学习。

**📊 数据集**

构建了 3,200 对齐的四元组数据集（源、参考、目标、文本）和 1,500 个无对齐的源‑参考对，同时收集少量人标注离线样本作为奖励锚点。

**📈 对比分析**

与 SA‑LUT、Neural Preset、PIF、CAP‑VSTNet、GPT‑Image‑1.5、Nano Banana 等 SOTA 方法在真实与合成数据集上通过 VLM 分数、PSNR/SSIM/LPIPS、成功率和用户研究进行评估，SemiNFT 在绝大多数指标上均领先且保持高成功率。

**⚠️ 局限性**

局限性包括对极端光照/色调差异仍可能出现细节漂移，强化学习奖励依赖 VLM 质量，训练成本高且离线样本规模有限。

---

## 811. FLAG-4D: Flow-Guided Local-Global Dual-Deformation Model for 4D Reconstruction

**arXiv ID:** 2602.08558 | [PDF](https://arxiv.org/pdf/2602.08558v1)

**作者:** Guan Yuan Tan `[一作]` (Monash University), Chee-Ming Ting `[通讯]` (Monash University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `67630363-6be0-4f51-ab05-7198250671a5` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `25d64835-ec5b-425b-899d-a6e1e6fecabd` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出FLAG-4D双网络框架，利用随时间演化的3D高斯体素实现4D动态场景重建。

**💡 创新点**

通过将局部精细变形（IDN）与全局一致运动（GMN）双分支紧耦合，并采用基于光流嵌入的上下文变形对齐（CDA）及互相学习机制，实现局部细节与全局时空一致性的统一提升。

**🔧 技术方法**

核心技术包括3D高斯喷射、瞬时变形网络与全局运动网络、GRU递归提取未来轨迹、跨注意力对齐光流特征、互相学习正则化、深度增强损失和局部刚性损失。

**📊 数据集**

在NeRF-DS和HyperNeRF两个真实世界动态场景数据集上进行训练与评估。

**📈 对比分析**

与4DGS、SC-GS、D-MiSo、MotionGS等现有方法比较，FLAG-4D在PSNR、SSIM等指标上实现SOTA（如PSNR 24.23 dB、SSIM 0.852），且在细节保留和时序连贯性上优于基线。

**⚠️ 局限性**

主要局限在于对预训练光流网络的依赖，若场景存在显著运动模糊或光流估计不准，性能可能受影响；同时仍需从稀疏视角中推断，输入稀疏度对重建质量有一定影响。

---

## 812. Rho-Perfect: Correlation Ceiling For Subjective Evaluation Datasets

**arXiv ID:** 2602.08552 | [PDF](https://arxiv.org/pdf/2602.08552v1)

**作者:** Fredrik Cumlin `[一作]` `[通讯]`, Fredrik Cumlin

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了ρ-Perfect度量，用来估算主观评测数据中模型与人类评分的最高可达相关性。

**💡 创新点**

创新点在于在异方差噪声场景下给出可计算的相关性上限，并证明其平方近似两次独立相似评测的相关性。

**🔧 技术方法**

采用统计推导（总方差、条件方差）、Pearson相关系数以及拆分评测模拟等技术实现。

**📊 数据集**

实验使用BVCC、MovieLens、SOMOS、MERP以及NISQA等多种主观评分数据集。

**📈 对比分析**

通过与ICC(2,k)、子抽样可靠性以及真实测验-重测相关性比较，ρ-Perfect^2与实际相关性高度吻合，并能在不同子集上区分模型缺陷与数据质量问题。

**⚠️ 局限性**

局限在于需满足评测者独立且噪声呈异方差的假设，以及至少50条目、每条目至少3个评测的前提，对极小样本或评测数极少的情况不适用。

---

## 813. Thegra: Graph-based SLAM for Thermal Imagery

**arXiv ID:** 2602.08531 | [PDF](https://arxiv.org/pdf/2602.08531v1)

**作者:** Anastasiia Kornilova `[一作]` (Skolkovo Institute of Science and Technology), Alexander Menshchikov `[通讯]` (Skolkovo Institute of Science and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种针对热成像的稀疏单目图优化SLAM系统，利用预处理和置信权重增强特征匹配与后端优化。

**💡 创新点**

创新点在于将通用学习特征（SuperPoint/LightGlue）迁移到热域并结合热图像预处理与基于检测置信度的加权因子图优化。

**🔧 技术方法**

使用了SuperPoint、LightGlue、Chambolle/CLAHE/Median滤波、MAGSAC、RANSAC、Bundle Adjustment及加权HUBER损失的因子图。

**📊 数据集**

在ViViD++和ROVTIO两个公开热图SLAM基准数据集上进行评估。

**📈 对比分析**

与ORB‑SLAM3、ROTIO、DSO等基准方法比较，平均ATE下降至1–2mm，跟踪成功率提升至100%，在大多数序列中优于对手。

**⚠️ 局限性**

局限性包括对高频噪声的敏感度、单目尺度不确定性以及对极端低对比度环境的进一步提升空间。

---

## 814. Automatic regularization parameter choice for tomography using a double model approach

**arXiv ID:** 2602.08528 | [PDF](https://arxiv.org/pdf/2602.08528v1)

**作者:** Chuyang Wu `[一作]` (University of Helsinki), Samuli Siltanen `[通讯]` (University of Helsinki)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

本文提出一种利用双网格一致性与闭环控制的计算机断层成像（CT）正则化参数自动选择方法，能够在无真值或噪声估计的情况下动态调节正则化强度。

**💡 创新点**

创新点在于：①将正则化参数视为可控变量，并用两种不同离散网格下的重建结果的相似度（SSIM）作为可观测反馈；②通过比例控制器在对数域动态更新α，使其在达到用户设定的相似度阈值后自动停止，从而避免传统方法对噪声水平的依赖与网格搜索。

**🔧 技术方法**

技术手段包括：变分正则化（TV、Tikhonov）、双网格重建（原始投影矩阵A与旋转Aθ）、SSIM相似度测量、PID（主要使用比例）控制、ASTRA Toolbox实现投影与反投影、在对数域对α进行乘法更新。

**📊 数据集**

使用芬兰逆问题协会公开的两组 3D cone‑beam 数据集——Walnut 和 Pine Cone（截取中心 2D 切片并模拟 fan‑beam 几何），共 450×450 像素网格进行实验。

**📈 对比分析**

与传统 L‑curve 与差异原理两种闭源参数选择基线进行对比；实验显示控制器在满足用户设定的相似度目标时，获得更高梯度能量和细节保留，形成 Pareto 前沿；传统方法由于目标过高导致 α 过大，产生过度平滑、细节丢失的重建。

**⚠️ 局限性**

局限性包括：①需要用户手动设定相似度阈值；②假设相似度随 α 单调上升，若网格对齐或角度接近 90° 时可能失效；③目前仅在完整采样、无严重金属伪影等理想场景验证，极端欠采样或不完整角度情况下的稳健性尚待进一步研究。

---

## 815. A General Theory of Proportionality with Additive Utilities

**arXiv ID:** 2602.08504 | [PDF](https://arxiv.org/pdf/2602.08504v1)

**作者:** Piotr Skowron `[一作]` `[通讯]` (University of Warsaw), Piotr Skowron (University of Warsaw)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一套适用于任意可行性约束和加法效用的比例化选举算法，扩展了Phragmén顺序规则和等额共享规则，并给出了相应的理论保证与实验评估。

**💡 创新点**

创新点在于：①把比例代表性（EJR、PJR及比例度量）推广到一般约束下；②设计了PropRank算法，引入局部与全局比例因子；③证明了在PB约束下PropRank实现 (α−u_max)/2 的比例度；④将等额共享与有界超支方法改造为通用约束；⑤提出了可改进比例度的启发式变体。

**🔧 技术方法**

使用的技术包括：虚拟货币累计与分段支付策略、比例因子与潜在函数分析、凸/凹函数方法、时间戳与最优购买时机计算、蒙特卡罗实验评估。

**📊 数据集**

实验数据来源于真实的参与式预算案例库 PabuLib，包含约1300个实例。

**📈 对比分析**

将新规则与MES‑PB、BOS‑PB、Greedy‑PB等现有PB规则进行对比，评估指标为EJR+违规数、排除率与成本满意度；PropRank κ=1 在比例性方面明显优于其他规则，启发式变体进一步降低EJR+违规，且总效用与最优规则相当。

**⚠️ 局限性**

局限性包括：启发式变体缺乏严格的理论保证；算法在一般约束下的复杂度与可扩展性尚未完全评估；比例因子上界受 u_max 限制，可能导致剩余预算较大；对极端约束（如非凸或非下闭合）验证不足。

---

## 816. Learning Self-Correction in Vision-Language Models via Rollout Augmentation

**arXiv ID:** 2602.08503 | [PDF](https://arxiv.org/pdf/2602.08503v1)

**作者:** Yi Ding `[一作]` (Purdue University), Ruqi Zhang `[通讯]` (Purdue University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出通过Rollout增广（Octopus）在单通道视觉语言模型中显式学习自我纠正行为，提升推理性能；

**💡 创新点**

创新点在于利用已生成的Rollout中正确与错误响应的对比，构造大量密集的自我纠正样本，同时通过响应掩码分离自我纠正与直接推理的学习信号；

**🔧 技术方法**

技术包括Rollout增广、两阶段RL训练（Stage I仅更新后续纠正响应，Stage II选择性解码前置响应）、基于GSPO的序列级重要性采样、以及自定义奖励函数；

**📊 数据集**

数据集涵盖7个基准（MathVista、MathVerse、WeMath、HallBench、MMStar、MMMU、CharXiv_RQ）以及训练用的ViRL‑39k和LLaVA‑CoT；

**📈 对比分析**

与同等规模的开源VLM（如Qwen3‑VL‑8B‑ThThinking、MiMo‑VL‑7B、InternVL3.5‑8B‑RL）及RLVR基线（GRPO、DAPO、GSPO、SRPO）比较，Octopus在所有基准上平均提升约9.5分，并在GSPO基础上再增1.0分，且每步训练时间仅为最佳基线的0.72倍；

**⚠️ 局限性**

局限在于仍需大规模GPU资源，且自我纠正机制主要针对单通道设计，尚未验证跨任务的泛化与对更大模型的适配；

---

## 817. ALIVE: Animate Your World with Lifelike Audio-Video Generation

**arXiv ID:** 2602.08682 | [PDF](https://arxiv.org/pdf/2602.08682v1)

**作者:** Ying Guo `[一作]` (Bytedance), Zehuan Yuan `[通讯]` (Bytedance)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `04572f8d-59e5-41c9-8850-ac8e7ee2b108` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一种统一的音频-视频生成模型，能够从文本生成同步音视频、支持参考图像动画，并在高分辨率下实现自然的口型同步与背景音效。

**💡 创新点**

创新点包括：①联合音频-视频DiT架构，引入 UniTemp‑RoPE 和 TA‑CrossAttn 实现精确的时间对齐；②完整的音视频数据采集与清洗流水线，涵盖双模质量过滤、语音-视觉对应校正、音频事件标签等；③全流程多阶段训练策略与自适应学习率，解决音频快速遗忘与跨模态同步难题；④推出 Alive‑Bench 1.0 细粒度评测基准，覆盖 22 个维度。

**🔧 技术方法**

技术上使用：MMDiT、Rectified‑Flow Transformer、WavVAE、CLIP/ArcFace 多模特、Qwen‑Image‑Edit、APG、CFG、DPO、FAISS 等；音频处理采用 MegaTTS3‑VAE、音频事件检索与对齐；训练采用分阶段（T2A→T2VA→I2VA→Refiner）以及多任务与多条件控制。

**📊 数据集**

数据集为百万级高质量音视频语料，经过上述流水线后得到 480p 训练集、4.3M CT 集、5M SFT 集、0.8M 参考配对集、0.7M 1080p Refiner 集；音频与视频分别来自公开大规模语音库、背景音乐库以及在野生视频中提取的音频事件。

**📈 对比分析**

与 Veo 3.1、Kling 2.6、Wan 2.6、Sora 2、LTX‑2 等开源/商用模型在 Alive‑Bench 1.0 上进行对比，Alive 在音频质量、音频指令遵循、音视频同步以及参考角色保持上均占优，整体表现位于前列；在多模态细粒度评测中，Alive 的得分显著高于多数竞争者。

**⚠️ 局限性**

局限性：数据量受限于音视频清洗后可用样本，导致对少见概念的生成效果不佳；对极端光照或复杂多说话者场景仍可能出现同步偏差；模型对音频-视觉对应误差的鲁棒性在极端噪声条件下尚待提升。

---

## 818. Enhancing Genetic Algorithms with Graph Neural Networks: A Timetabling Case Study

**arXiv ID:** 2602.08619 | [PDF](https://arxiv.org/pdf/2602.08619v1)

**作者:** Laura-Maria Cornei `[一作]` (Alexandru Ioan Cuza University), Mihaela-Elena Breabăn `[通讯]` (Alexandru Ioan Cuza University)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

研究并实现了将遗传算法与图神经网络相结合，用于解决人员排班（Staff Rostering）问题。

**💡 创新点**

首次提出将预训练的GNN作为改进算子集成进多模态遗传算法，实现两种优化范式的互补，提高搜索效率与解质量。

**🔧 技术方法**

使用的技术包括：多模态遗传算法（交叉、变异、概率拥挤距离选择）、TransformerConv型图神经网络、早停与学习率调度、批量化训练与Numba加速。

**📊 数据集**

使用自己生成的数据集：250个基于100人7天的实例生成训练/验证/测试集（共62,500个日程对），以及另外50个随机实例用于评估。

**📈 对比分析**

通过10次独立运行、统计均值/标准差、Welch t检验与对比基准（单独GA、单独GNN），实验表明混合方法在时间上比单独GA快约10倍，解质量与单独GA相当；在相同时间内，GA+GNN*的质量更好但多样性略差。

**⚠️ 局限性**

局限性包括：GNN对新实例的泛化能力受限、混合模型的多样性下降、训练数据量大、在某些配置下仍存在较高的计算成本。

---

## 819. Breaking the Grid: Distance-Guided Reinforcement Learning in Large Discrete and Hybrid Action Spaces

**arXiv ID:** 2602.08616 | [PDF](https://arxiv.org/pdf/2602.08616v1)

**作者:** Heiko Hoppe `[一作]` (Technical University of Munich), Maximilian Schiffer `[通讯]` (Technical University of Munich)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

设计并实现了一种名为 DGRL 的框架，利用 SDN 与 DBU 在离散和混合动作空间中高效进行强化学习。

**💡 创新点**

创新点在于：①使用 Chebyshev（L∞）度量构建维度无关的体积邻域，实现高效采样；②将策略优化转化为距离回归任务，梯度方差与动作空间大小无关；③实现了无层次依赖的混合动作联合优化。

**🔧 技术方法**

核心技术包括：采样动态邻域（SDN）、基于距离的更新（DBU）、离散→连续映射、软平均目标、经验回放、双重 Q、Polyak 平滑等。

**📊 数据集**

使用了多种仿真数据集：2D 迷宫、电影推荐（343 电影）、作业车间调度、库存补货等，涵盖结构化和非结构化大规模离散与混合动作空间。

**📈 对比分析**

与 A2C、Cacla、Wolpertinger、LAR、DNC、H-DNC 等基准进行对比，DGRL 在所有环境中均实现更高的最终奖励、更快的收敛速度，性能提升可达 66%–164%。

**⚠️ 局限性**

局限性包括：需要手动调参邻域半径与温度，依赖语义嵌入的质量；在极大规模或实时工业系统中的延迟与内存仍有待进一步优化；未在真实工业数据上进行大规模验证。

---

## 820. Inspiration Seeds: Learning Non-Literal Visual Combinations for Generative Exploration

**arXiv ID:** 2602.08615 | [PDF](https://arxiv.org/pdf/2602.08615v1)

**作者:** Kfir Goldberg `[一作]` (BRIA AI), Yael Vinker `[通讯]` (MIT)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `9ce7179e-700c-4310-ac2b-91df50ded46e` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

训练模型从两张图像生成非显而易见的视觉组合，以支持创意探索与灵感生成。

**💡 创新点**

创新点在于利用CLIP稀疏自编码器实现无监督的视觉特征分解，自动构造训练三元组，并用Flux.1 Kontext学习逆向组合；同时提出以描述长度为指标的新评估框架。

**🔧 技术方法**

技术包括CLIP稀疏自编码器（SAE）、K‑means聚类、CLIP编码与解码、Kandinsky生成、Flux.1 Kontext微调（LoRA）、随机种子采样等。

**📊 数据集**

数据集为自建的2085张多属性合成图像（生成后分解得到三元组）和基准实验使用的Pexels 41类图像共99对跨类别样本。

**📈 对比分析**

与Flux.1 Kontext、Qwen‑Image‑2511、Nano Banana三种公开模型对比，使用描述长度、用户研究及可视化评估，结果显示本方法产生更长、更复杂的描述，视觉上更非显而易见，整体性能优于基线。

**⚠️ 局限性**

局限性包括仅支持两张输入图、缺乏细粒度控制与多输入扩展、生成耗时约30秒、以及对交互式即时响应的不足。

---

## 821. MOSAIC: Bridging the Sim-to-Real Gap in Generalist Humanoid Motion Tracking and Teleoperation with Rapid Residual Adaptation

**arXiv ID:** 2602.08594 | [PDF](https://arxiv.org/pdf/2602.08594v1)

**作者:** Zhenguo Sun `[一作]` (Beijing Academy of Artificial Intelligence), Alois Knoll `[通讯]` (Technical University of Munich)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了MOSAIC系统，实现了通用式人形机器人运动追踪与远程操控，并提供了快速适配新接口的残差适配模块；

**💡 创新点**

创新点在于将基于多源数据训练的通用运动追踪器与针对接口误差的残差适配器分离，利用少量数据即可在保持通用性的同时显著提升真实硬件的鲁棒性；

**🔧 技术方法**

采用强化学习（PPO）训练全局运动追踪器，使用双层自适应采样与全局坐标奖励，残差适配器通过零偏初始化和双教师行为克隆实现；

**📊 数据集**

使用约64小时的多源运动数据，包括自制光学与惯性MoCap、公开AMASS/OMOMO、生成的GENMO运动以及少量接口特定的适配数据；

**📈 对比分析**

通过与GMT、TWIST等主流方法的仿真与真实机器人基准比较，MOSAIC在全局位置误差、跟踪精度、成功率和长时段鲁棒性方面均优于对手，且残差适配在30分钟数据下即可匹配甚至超过Fine‑tune方案；

**⚠️ 局限性**

局限性包括仍需低延迟传感与状态估计的支持，残差适配主要针对接口误差，对其他类型的仿真‑真实差异（如动力学误差）影响有限。

---

## 822. Dashed Line Defense: Plug-And-Play Defense Against Adaptive Score-Based Query Attacks

**arXiv ID:** 2602.08679 | [PDF](https://arxiv.org/pdf/2602.08679v1)

**作者:** Yanzhang Fu `[一作]` (Harbin Institute of Technology), Jizhou Luo `[通讯]` (Harbin Institute of Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `f86bf285-fd08-4156-973b-6e6481af8fa0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

设计并评估了一种名为Dashed Line Defense (DLD) 的插件式后处理防御方法，用于抵御自适应基于得分的查询攻击。

**💡 创新点**

通过在损失映射中引入不连续的破折线映射，使观察损失与真实损失之间产生模糊关系，既干扰最小化也干扰最大化策略，从而实现对自适应攻击的鲁棒防御。

**🔧 技术方法**

利用零阶优化的得分查询攻击模型、非平滑的损失映射函数、随机化DLD、模拟退火式自适应攻击以及理论概率分析与实验验证。

**📊 数据集**

在ImageNet图像分类数据集上，针对预训练的WideResNet‑50、RegNet‑Y 1.6GF和MaxViT‑T模型进行实验。

**📈 对比分析**

与RND（预处理）和AAA（后处理）两种主流插件式防御进行对比，采用Square Attack在standard、reverse、explore、SA等四种自适应策略下评估攻击成功率和模型准确率；DLD在所有攻击策略下均保持更高准确率，尤其在最恶劣自适应攻击中优于AAA和RND。

**⚠️ 局限性**

对输出置信度要求极高的应用中，较大的τ会显著扰动预测置信度；当S的区间过小导致映射过于连续时，攻击者仍可通过精细搜索突破；此外，本文未针对纯标签查询（label‑only）攻击提供防御。

---

## 823. Reliable one-bit quantization of bandlimited graph data via single-shot noise shaping

**arXiv ID:** 2602.08669 | [PDF](https://arxiv.org/pdf/2602.08669v1)

**作者:** Johannes Maly `[一作]` (Ludwig-Maximilians-Universität), Anna Veselovska `[通讯]` (Technical University of Munich)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

提出了一种单次噪声塑造（SSNS）算法，用于将图结构的低通带宽数据以极少位（包括单比特）进行量化，并给出了严谨的误差上界。

**💡 创新点**

创新点在于：① 采用单次噪声塑造而非迭代方法，能够在一次处理后得到满足低频信息且大多数量化值已落在量化字母表上的表示；② 允许任意比特级别，尤其能实现单比特量化；③ 提供了比现有迭代噪声塑造更优的理论误差上界，误差随比特数按 2^{-B} 缩放；④ 证明了误差与图子空间不一致度 μ(r) 的乘积相关。

**🔧 技术方法**

主要技术包括：图拉普拉斯谱分析、基于 GFT 的低通滤波、对角线约束的前向噪声塑造算法、以及中值尺度量化（midrise MSQ）和字母表设计。

**📊 数据集**

实验使用多种标准图拓扑（二维网格、环图、瑞士卷、Bunny 3D 形状、传感器网络、Minnesota 网络）以及 Stanford Bunny 网格信号（顶点 z 坐标）进行量化验证。

**📈 对比分析**

与迭代噪声塑造（SSS‑R）和传统无记忆量化（MSQ）比较，SSNS 在相同比特预算下的相对误差更低，尤其在低带宽和单比特情形下表现突出；理论误差上界在环图上已被证明是紧的，其余图的实际误差普遍低于该上界。

**⚠️ 局限性**

局限性包括：仅考虑砖墙低通滤波器，未对近似 r‑bandlimited 数据的鲁棒性做分析；误差与图子空间不一致度 μ(r) 的估计可能过于保守；算法在高带宽下的计算复杂度较高，且对非均匀图拓扑的误差分布尚未得到细致解释。

---

## 824. WiFlow: A Lightweight WiFi-based Continuous Human Pose Estimation Network with Spatio-Temporal Feature Decoupling

**arXiv ID:** 2602.08661 | [PDF](https://arxiv.org/pdf/2602.08661v1)

**作者:** Yi Dao `[一作]` (Kunming University of Science and Technology), Wenbo Wang `[通讯]` (Kunming University of Science and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

开发了 WiFlow，一个基于 WiFi CSI 的轻量化连续人体姿态估计网络。

**💡 创新点**

通过时空特征解耦（TCN + 非对称卷积）与轴向注意力，精确捕捉连续信号并建模骨架结构。

**🔧 技术方法**

采用时序卷积网络、非对称卷积块、轴向自注意力、直接坐标回归与骨骼长度约束损失。

**📊 数据集**

使用自建的 360,000 条同步 CSI-姿态对数据集，涵盖 5 位受试者和 8 种日常动作。

**📈 对比分析**

在随机划分和交叉主体设置下与 WPformer、WiSPPN 等基线对比，WiFlow 在 PCK@50 达 99.48%，MPJPE 0.008 m，参数仅 4.82 M，训练时间 18 h，显著优于对手。

**⚠️ 局限性**

对极端或未知体型动作的鲁棒性仍有下降，并且依赖 OpenPose 标注的清洗步骤，可能受视觉标注噪声影响。

---

## 825. Two-Stage Data Synthesization: A Statistics-Driven Restricted Trade-off between Privacy and Prediction

**arXiv ID:** 2602.08657 | [PDF](https://arxiv.org/pdf/2602.08657v1)

**作者:** Xiaotong Liu `[一作]` (Xi'an Jiaotong University), Ding-Xuan Zhou `[通讯]` (University of Sydney)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `67630363-6be0-4f51-ab05-7198250671a5` `9cc9baba-5356-466d-81ff-d80028d90279` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

本文提出并验证了一个两阶段合成数据生成策略：第一阶段使用合成-再混合（SH）方法保持协方差分布，第二阶段基于核岭回归（KRR）重构输出，最终实现隐私与预测性能的平衡。

**💡 创新点**

创新点在于引入可调混合参数α的合成-再混合两阶段架构，理论证明其在统计驱动、受限的隐私-预测权衡下仍能保证最优预测性能；并首次将KRR用于第二阶段以克服分布失配。

**🔧 技术方法**

技术手段包括拉丁超立方采样（LHS）或GAN/DM等合成技术、混合操作、核岭回归、总变差度量、理论泛化误差分析与对数几率阈值等。

**📊 数据集**

实验数据集涵盖：保险、EIA、加州房价、人口普查、塔拉戈纳等五个公开真实数据集；营销价格-销量数据；以及人工生成的非线性回归仿真数据。

**📈 对比分析**

与单阶段传统合成方法（GAN、DM、SH）及不同预测模型（KRR、NWK、AdaBoost、RF）进行对比，结果显示两阶段方法在MSE、LID等指标上明显优于单阶段方案，同时运行时间更短，预测误差降低约30%~50%。

**⚠️ 局限性**

局限性包括：仅针对数值回归任务，未覆盖分类或离散特征的合成；KRR对核选择敏感，模型性能受限；在极端隐私要求下α调参复杂；多方异构分布合成与协同学习的扩展仍待研究。

---

## 826. Projected Gradient Ascent for Efficient Reward-Guided Updates with One-Step Generative Models

**arXiv ID:** 2602.08646 | [PDF](https://arxiv.org/pdf/2602.08646v1)

**作者:** Jisung Hwang `[一作]` (KAIST), Minhyuk Sung `[通讯]` (KAIST)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于投影梯度上升的硬约束潜在优化方法，能够在保持白高斯噪声特性的前提下进行奖励驱动生成；

**💡 创新点**

创新点在于构造紧凑频谱域的白噪声约束集合，并给出闭式 O(N log N) 投影算法，替代软正则化，实现了更安全、更高效的潜在搜索；

**🔧 技术方法**

使用投影梯度上升、FFT、块级 ℓ₁/ℓ₂ 约束、闭式投影算法，并与 ReNO、MPGR 等软正则化方法进行对比；

**📊 数据集**

实验使用 FLUX‑schnell（文本到图像的一阶模型）与 SDXL‑Turbo，配合动物数据集（Aesthetic Score）与 T2I‑Compbench++；

**📈 对比分析**

与无优化、无正则、ReNO、PRNO、MPGR 等基线比较。结果显示在 Aesthetic Score 上，200 步可达 8.9，其他方法仅 7.1；在 30% 时间（60 步）即可达到 7.12，显著提高效率且样本质量不下降；

**⚠️ 局限性**

限制包括：依赖奖励模型的偏差与误差，硬约束可能限制搜索空间，对多步扩散/流模型尚未验证，需在安全过滤和奖励模型审计下使用。

---

## 827. We Should Separate Memorization from Copyright

**arXiv ID:** 2602.08632 | [PDF](https://arxiv.org/pdf/2602.08632v1)

**作者:** Adi Haviv `[一作]` (Blavatnik School of Computer Science and AI), Shay Moran `[通讯]` (Technion Israel Institute of Technology)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f`

**🎯 论文内容**

本文提出将生成模型中的“memorization”与版权复制区分的框架，分析两者在技术和法律层面的差异，并提出以输出级风险评估为核心的评估体系；

**💡 创新点**

创新点在于：① 明确区分技术层面的memorization与法律层面的复制，避免两者混淆；② 将薄厚版权保护与技术攻击对应，提供法律视角下的评估标准；③ 呼吁以输出级、风险导向的评价和缓解措施，形成跨学科研究路线；

**🔧 技术方法**

主要运用法律分析、案例对比、信息论与重建攻击技术的综合评估；并借鉴现有的重建攻击、提取攻击、原创性判定等技术，构建评估框架；

**📊 数据集**

本文主要引用已有论文和判例，并未使用特定实验数据集；

**📈 对比分析**

本文未进行新的实验比较，而是提出评估标准：是否与受版权保护表达高度相似、是否为文字/图像、薄/厚保护等维度，并建议未来在此基础上进行量化评估；

**⚠️ 局限性**

局限性：仅聚焦美国版权法；缺乏实证实验验证；框架仍需进一步量化；对模型内部“复制”判定缺少客观度量。

---

## 828. VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling

**arXiv ID:** 2602.08607 | [PDF](https://arxiv.org/pdf/2602.08607v1)

**作者:** Ziyang Cheng `[一作]` (Shanghai Jiao Tong University), Yu Wang `[通讯]` (Shanghai Jiao Tong University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `64443552-63e0-44b5-906f-d90fe95c5a1b` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本工作提出了 VocalNet-MDM，一种基于 Masked Diffusion Modeling 的端到端语音 LLM，旨在克服自回归模型的串行瓶颈与曝光偏差，实现在 6k 小时数据下的低延迟、高效语音生成；

**💡 创新点**

创新点在于① Hierarchical Block‑wise Masking 解决训练与推理过程中的分布不匹配；② Iterative Self‑Distillation 将多步扩散压缩为少步推理；③ 将 MDM 成功应用于对话式语音生成，并实现 3.7–10× 的速度提升和 34% 首块延迟下降；

**🔧 技术方法**

采用 Masked Diffusion Modeling、Block‑Causal attention、Speech Encoder+Downsample Adaptor、Thinker‑Talker 框架、Flow‑matching vocoder（CosyVoice2+HiFi‑GAN）、自监督自蒸馏、以及多任务损失（α,τ）调参等技术；

**📊 数据集**

使用 VoiceAssistant‑400K（400K 语音对话）、UltraChat（300K 语音对话）以及 CosyVoice2 合成的语音，共约 6k 小时语音数据；

**📈 对比分析**

通过与开源语音 LLMs 及 AR baseline 在效率（TPS/RTF）、文本质量（AlpacaEval、Llama Qs）和语音质量（UTMOS、WER）方面进行对比，VocalNet‑MDM Step‑4/1 在速度上实现 3.7–10.5× 加速、首块延迟降低 34%，文本质量最高 7.07/8.27，语音自然度 4.49/4.46，WER 5.34–6.23，显著优于 AR baseline；

**⚠️ 局限性**

局限性包括训练规模相对有限，极低步数下质量‑效率 trade‑off 明显，vocoder 仍占主导延迟，且对高精度语音‑文本对齐和双向上下文建模尚需改进。

---

## 829. Mimic Intent, Not Just Trajectories

**arXiv ID:** 2602.08602 | [PDF](https://arxiv.org/pdf/2602.08602v1)

**作者:** Renming Huang `[一作]` (Shanghai Jiao Tong University), Panpan Cai `[通讯]` (Shanghai Jiao Tong University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种通过多尺度频域离散化将动作轨迹分解为意图（低频）和执行细节（高频）的 MINT 框架，支持一-shot 技能迁移。

**💡 创新点**

创新点在于：1) Spectrally Disentangled Action Tokenizer（SDAT）通过频域重建约束实现意图与执行的显式解耦；2) 逐层自回归生成与意图驱动的动作集成；3) 用意图 token 直接注入实现无语言的任务指定。

**🔧 技术方法**

使用 DCT 频域变换、多尺度残差量化 VAE、频域重建损失、意图驱动的自回归策略以及意图基动作集成；整体基于 Transformer 结构。

**📊 数据集**

主要数据集：LIBERO、LIBERO-Plus、CALVIN、MetaWorld、BridgeDataV2；在真实机器人上验证了四个任务。

**📈 对比分析**

与 OpenVLA、π 系列、Diffusion Policy、UniVLA 等现有 VLA 与 IL 方法比较，MINT 在 LIBERO、CALVIN、MetaWorld 等基准上实现了与最先进方法相当或更优的成功率，并在 LIBERO-Plus 上表现出更强的鲁棒性和在一次演示下的 90%+ 迁移成功率。

**⚠️ 局限性**

局限性在于：1) 依赖演示轨迹来学习意图，意图多样性受限；2) 需要多尺度频域重建的额外计算；3) 在极端新任务或极高频细节场景下的泛化仍有待提升。

---

## 830. Kissan-Dost: Bridging the Last Mile in Smallholder Precision Agriculture with Conversational IoT

**arXiv ID:** 2602.08593 | [PDF](https://arxiv.org/pdf/2602.08593v1)

**作者:** Muhammad Saad Ali `[一作]` (Lahore University of Management Sciences), Muhammad Hamad Alizai `[通讯]` (Lahore University of Management Sciences)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a2602d71-93ab-4bad-974b-672788df8193` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `3855fcda-48ef-4070-a15e-803cd5c84d83` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `5a41884c-404f-4688-a89c-aa238c10fe68` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发并部署了Kissan-Dost，一个多语言、传感器驱动的对话系统，能够将现场土壤和气象传感器实时数据转换为在WhatsApp文字或语音中提供的可执行农业建议。

**💡 创新点**

创新点包括：①端到端整合 IoT 传感器与检索增强生成（RAG）的大语言模型（LLM）实现；②为低识字、低网络环境的农户设计的多语言、语音友好交互管道，强调证据引用与可追溯性；③通过真实的 90 天田间试点证明每日高参与度和决策改进，展示了“最后一英里”交付的重要性。

**🔧 技术方法**

使用的技术有：ESP32+ESP‑NOW 传感器节点、工业 7‑in‑1 土壤探头、无线网关、云后端（数据融合、天气预报、市场信息）、检索增强生成管道（检索模块 + LLM）、多语言翻译与语音合成、WhatsApp Business API 交互接口。

**📊 数据集**

使用的数据集包括：现场收集的土壤湿度、温度、NPK、pH、电导率等实时传感器数据；实时天气预报和市场价格数据；本地农技手册与最佳实践文档作为检索库；以及构造的 99 条多难度农作物查询（包含作物、阶段、传感器值）用于评估。

**📈 对比分析**

评估方法：①LLM‑as‑Judge 方案对 99 条查询进行正确性、连贯性、相关性和简洁性打分，准确率>90%；②RAGAS 框架评估检索与答案的相关性与可信度，硬核指标均在 75‑97% 范围；③多语言翻译通过 COMETKiwi（高分）和 MetricX‑24（低分）指标测评，说明多语言表现良好；④硬件实验验证传输距离 425 m、功耗低、延迟<1 s。性能结果显示系统在实时性、准确性和用户体验上均优于传统仪表盘，且在现场实验中实现每日持续交互与决策改进。

**⚠️ 局限性**

局限性：①缺乏作物生命周期与生长阶段的上下文感知，导致在不同生长期的建议不够精准；②试点时间短，仅能观察短期行为变化，未验证长期产量与收益影响；③多语言脚本问题（如旁遮普语使用印度式 Gurmukhi 而非巴基斯坦式 Shahmukhi）影响部分用户体验；④LLM 在多源推理（传感器+预报+文档）时可信度略有下降，偶有轻微“hallucination”。

---

## 831. SDFed: Bridging Local Global Discrepancy via Subspace Refinement and Divergence Control in Federated Prompt Learning

**arXiv ID:** 2602.08590 | [PDF](https://arxiv.org/pdf/2602.08590v1)

**作者:** Yicheng Di `[一作]` (Jiangnan University), Hongzhi Yin `[通讯]` (University of Queensland)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

针对多方隐私环境下的视觉‑语言预训练模型，提出了 SDFed：一种允许客户端使用可变长度本地提示并保持统一全局提示的联邦提示学习框架，并通过子空间细化与差异控制来解决全局与本地知识冲突。

**💡 创新点**

创新点在于①在保持可聚合的全局提示长度的同时，允许每个客户端学习不同长度的本地提示；②利用全局提示的奇异值分解投影本地提示到子空间，以消除冲突；③引入信息保持与分离正则，既保留本地关键信息，又保证全局与本地表示的可分离性，从而在异构环境中兼顾全局泛化与个性化。

**🔧 技术方法**

主要技术包括联邦学习（FedAvg 聚合）、提示学习、基于 SVD 的子空间投影、MSE 与 ReLU 边际正则（信息保持与分离），以及在 CLIP 文本编码器上的可训练上下文向量。

**📊 数据集**

使用单域数据集（Flowers102、DTD、Food101、OxfordPets、Caltech101）和跨域数据集（Office31、OfficeHome）、以及标准图像基准（CIFAR‑10、Tiny‑ImageNet）进行实验，均采用非 IID 客户端划分。

**📈 对比分析**

与 CoOp、Powder、FedOTP、GPT‑FL、UOPP 等方法在同一设置下对比，SDFed 在所有数据集上均表现最佳，平均提升约 2–4%（最高 3.44%），并在样本少量（few‑shot）和系统异构场景下保持稳健性。

**⚠️ 局限性**

局限性包括：①仍需对更大规模、跨模态或更复杂系统异构的场景进行验证；②子空间投影与正则化需要额外的超参调优，可能增加实现复杂度；③在极端隐私攻击（如差分隐私）下的鲁棒性未做深入分析。

---

## 832. SRSUPM: Sequential Recommender System Based on User Psychological Motivation

**arXiv ID:** 2602.08667 | [PDF](https://arxiv.org/pdf/2602.08667v1)

**作者:** Yicheng Di `[一作]` (Jiangnan University), Jingcai Guo `[通讯]` (Hong Kong Polytechnic University)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了一个可插拔的框架 SRSUPM，用于在序列推荐中显式建模用户心理动机的变化，并通过多级转移表示来提升下一条项目预测。

**💡 创新点**

创新点在于：① 用多标签类别信息量化心理动机转移度（PMSA）；② 设计 Shift Information Construction 与信息分解（PMSID）生成多级转移向量并进行分布正则化；③ 引入心理动机转移信息匹配（PMSIM）在协同学习中对相同转移级别的用户进行对齐；④ 将上述模块无缝集成到任意序列推荐骨干模型，保持插件式可扩展性。

**🔧 技术方法**

技术方法包括：Transformer/CNN/RNN 序列编码器；多标签类别交叉熵与IoU 计算；bucket‑mapping 离散化转移度；对数正则化与softmax 分布学习；InfoNCE 对比学习；交叉熵训练主任务；多任务联合损失。

**📊 数据集**

使用三大公开数据集：Yelp、Beauty 与 Sports（均进行稀疏用户/项目过滤），并利用各自的类别标签作为心理动机信号。

**📈 对比分析**

与 GRU4Rec、SASRec、Caser、Bert4Rec、LightSANs 等骨干模型以及 STOSA、CDR、IMSR、PoMRec、Meta‑SGCL、IOCLRec、IBLSRec、ASIF、MSSR、DIFF 等先进方法进行对比。SRSUPM 在所有数据集与所有骨干上均实现显著提升，往往是最佳或次佳结果；在 Recall@10、NDCG@10、Recall@20、NDCG@20 上提升幅度从 5% 到 15% 之间。

**⚠️ 局限性**

局限性：① 需要丰富的类别标签作为心理动机信号，对标签缺失或噪声敏感；② 离散化的转移度（V 取值）会影响精细度和推理效率，过细会导致性能下降；③ 推理时需要额外的 V 个 SIC 分支，虽然增量小但仍增加延迟；④ 目前仅考虑静态用户历史，未针对在线实时更新与因果因子进行处理。

---

## 833. LEFT: Learnable Fusion of Tri-view Tokens for Unsupervised Time Series Anomaly Detection

**arXiv ID:** 2602.08638 | [PDF](https://arxiv.org/pdf/2602.08638v1)

**作者:** Dezheng Wang `[一作]` (Southeast University), Hongzhi Yin `[通讯]` (University of Queensland)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出LEFT框架，利用时域、频域与多尺度三视图实现无监督时间序列异常检测。

**💡 创新点**

创新点包括：①使用可学习且Nyquist约束的滤波器生成多尺度token；②引入双向时频循环一致性与多尺度重建一致性来强化跨视图/跨尺度对齐；③采用轻量级视图交互保持视图特征的独立性与一致性。

**🔧 技术方法**

核心技术：STFT变换、可学习的滤波器银行、Transformer自注意力、Prototype银行与余弦相似度、Jensen‑Shannon不相似度、以及跨路径与循环一致性损失。

**📊 数据集**

实验数据集涵盖七个工业与环境TSAD基准：SMD、MSL、SMAP、SWaT、PSM、GECCO、SWAN。

**📈 对比分析**

与19个基线（经典与最新深度模型）对比，LEFT在VUS‑ROC和VUS‑PR上分别提升约3%和6%，并在PSM上实现FLOPs 188M、参数4.3M、训练时间25.66s/epoch、推理时间0.015s/128样本，速度提升8×、占用显著下降。

**⚠️ 局限性**

局限性：需要对多项超参数（如λ_cyc、λ_cons、α_cyc、α_ms）进行手工调优；跨视图一致性权重对性能影响大，调参成本高；对极端低频或高噪声场景的鲁棒性尚待进一步验证。

---

## 834. Supporting Effective Goal Setting with LLM-Based Chatbots

**arXiv ID:** 2602.08636 | [PDF](https://arxiv.org/pdf/2602.08636v1)

**作者:** Michel Schimpf `[一作]` (University of Cambridge), Thomas Bohné `[通讯]` (University of Cambridge)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了大型语言模型（LLM）聊天机器人在目标设定与行动计划中的作用，检验了指导、建议与反馈三种设计特征对目标质量与实施意图的影响；

**💡 创新点**

首次系统评估三种LLM特征的单独与组合效应，并揭示了更高目标质量与更低动机之间的权衡；

**🔧 技术方法**

采用 GPT‑4o 语言模型，配合状态机架构、函数调用与对话模板；

**📊 数据集**

使用 543 名来自 Prolific 的英国受试者生成的自选目标与行动计划文本；

**📈 对比分析**

通过预注册的五组对照实验与 Kruskal‑Wallis + Dunn 检验评估，发现反馈与指导显著提升目标具体度与实施意图质量，建议效果有限；

**⚠️ 局限性**

主要局限在未检验长期目标达成、存在受试者自我报告偏差、未研究目标选择过程、样本受限于英语移动用户及缺乏多域外部验证。

---

## 835. Overview and Comparison of AVS Point Cloud Compression Standard

**arXiv ID:** 2602.08613 | [PDF](https://arxiv.org/pdf/2602.08613v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 836. Do Multilingual LLMs have specialized language heads?

**arXiv ID:** 2602.08625 | [PDF](https://arxiv.org/pdf/2602.08625v1)

**作者:** Muhammad Naufil `[一作]` `[通讯]` (Saarland University), Muhammad Naufil (Saarland University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过逐一屏蔽多语种大型语言模型（Cohere Aya‑23）的注意力头，研究不同语言注意力头的功能与可裁剪性；

**💡 创新点**

创新点在于首次系统地把注意力头分为英语专属、印地语专属、语言无关和杂项四类，并验证去除非目标语言专属头对模型性能的影响；

**🔧 技术方法**

主要技术包括注意力头掩码、热图量化评估、GPT‑3.5‑Turbo 作为判定器进行语义正确性打分以及 4‑bit 量化模型的实验；

**📊 数据集**

使用的训练数据集是 Aya 数据集中的 MLQA‑en（T）对齐语料（共 500 英语样例与 500 印地语样例）；

**📈 对比分析**

比较方法是对 12 层×32 头进行逐一掩码实验，评估 500 例英语与印地语上的正确率，结果显示大多数专属头可被裁剪而不明显损失目标语言性能；

**⚠️ 局限性**

局限性包括仅测试两种语言、仅关注模型后几层、未覆盖更大语种范围，且裁剪策略依赖于过参数化模型，可能对小模型不适用。

---

## 837. From Raw Data to Shared 3D Semantics: Task-Oriented Communication for Multi-Robot Collaboration

**arXiv ID:** 2602.08624 | [PDF](https://arxiv.org/pdf/2602.08624v1)

**作者:** Ruibo Xue `[一作]` (Shenzhen University), Shuoyao Wang `[通讯]` (Shenzhen University)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

提出了一种去中心化、任务导向的语义通信框架，利用事件驱动的语义更新在未知3D环境中实现多机器人协同搜索与运输，并构建共享的3D语义场景；

**💡 创新点**

创新点在于(1) 采用轻量化的PiDiNet提取结构边缘与稀疏锚点，聚焦任务相关信息；(2) 引入事件驱动传输策略，仅在新目标、姿态显著变化、状态变更或结构变化时发送；(3) 构建仅包含语义的共享场景而非全密集地图，支持去中心化任务分配与路径规划；

**🔧 技术方法**

使用轻量化Pixel Difference Network（PiDiNet）进行边缘检测，体素下采样提取稀疏锚点，事件驱动的语义消息编码与优先级调度，多机器人无中心协同决策与语义驱动路径规划；

**📊 数据集**

在自建的未知3D仿真环境中进行实验，使用多机器人搜索与运输任务；未使用公开数据集，仅在仿真内部生成网格地图做碰撞检查；

**📈 对比分析**

与原始传感器数据持续广播的基线相比，四机器人时通信量下降约38倍、六机器人时下降200倍；任务完成步数从1054步降至281步；总行驶距离从9141m降至3030m，显著提升协作效率；

**⚠️ 局限性**

局限性包括：仅在仿真环境验证，未实测真实机器人；边缘检测与锚点提取对传感器噪声敏感；仅适用于静态障碍与目标，未考虑动态环境；假设无线信道共享且延迟可忽略，未覆盖更复杂的网络状况。

---

## 838. Improving Reconstruction of Representation Autoencoder

**arXiv ID:** 2602.08620 | [PDF](https://arxiv.org/pdf/2602.08620v1)

**作者:** Siyu Liu `[一作]` (Nankai University), Chongyi Li `[通讯]` (Nankai University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了 LV-RAE 表示自编码器，在 Vision Foundation Model (VFM) 的语义特征上补充低层信息，并通过噪声增益训练和推理时噪声注入提升解码器鲁棒性，解决了 VFM 作为自编码器导致的重建失真问题。

**💡 创新点**

创新点包括：① 将 VFM 的语义基底固定，只学习缺失的低层信息，从而避免传统的同时对齐与重建目标导致的漂移；② 对解码器在高维 latent 空间对离基底方向的敏感性进行分析，并通过噪声增益训练与动态噪声注入抑制离基底偏差；③ 采用可调节噪声水平在推理阶段平滑 latent，显著提升生成质量。

**🔧 技术方法**

使用 Transformer 结构的编码器/解码器（带 RoPE 位置嵌入）、LPIPS 感知损失、对齐 L2 损失、噪声增益训练（随机噪声幅度）、对解码器敏感性分析（Jacobian 计算）以及噪声注入技术。

**📊 数据集**

主要在 ImageNet-1K（256×256）和 COCO2017 验证集上进行重建实验；生成质量评估在 ImageNet-1K 256×256 上进行。

**📈 对比分析**

与现有 VAE、FLUX‑VAE、SVG、VA‑VAE 等自编码器以及多种 latent diffusion 模型（DiT、DiT^DH‑XL 等）进行对比，评估指标包括 PSNR/SSIM/LPIPS（重建）、CKNNA（语义一致性）、gFID、IS、gFDD（生成）。LV‑RAE 在重建方面 PSNR>32、SSIM>0.93、LPIPS<0.02，生成 gFID 仅 3.77/2.42（DiT‑XL/DiT^DH‑XL）且 gFDD 58.2，明显优于其他方法。

**⚠️ 局限性**

局限性：① 对高维 latent 的解码器仍保持一定的噪声敏感性，需手动调节噪声量；② Transformer 解码器参数量大，训练与推理成本较高；③ 对极低频细节的恢复仍有限；④ 依赖特定 VFM 作为语义基底，若 VFM 迁移到新任务可能需要重新调优。

---

## 839. OneLive: Dynamically Unified Generative Framework for Live-Streaming Recommendation

**arXiv ID:** 2602.08612 | [PDF](https://arxiv.org/pdf/2602.08612v1)

**作者:** Shen Wang `[一作]` (Kuaishou Technology), Kun Gai `[通讯]` (Kuaishou Technology)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了OneLive框架，用于直播推荐系统，集成动态分词、时序门控注意力、顺序多标记预测、QK归一化和多目标强化学习。

**💡 创新点**

创新点包括：① 结合实时直播内容和行为信号的动态Tokenizer；② 针对直播生命周期的时序门控注意力；③ 通过Sequential MTP显著提升推理效率；④ 引入QK Norm提升训练稳定性；⑤ 以Pantheon多目标奖励模型驱动强化学习，实现个性化多目标对齐。

**🔧 技术方法**

技术手段：Transformer解码器、残差量化（Res-Kmeans）、多模态LLM、RMSNorm、QK Norm、Sequential MTP、时间感知门控注意力、强化学习（DPO/GRPO）与Pantheon奖励模型。

**📊 数据集**

数据集：Kuaishou直播日志，涵盖数百万用户与作者的点击、观看、礼物等多目标行为，规模达数千万条记录。

**📈 对比分析**

对比方法：与SASRec、KuaiFormer、GNN和OneRec等传统与生成式基线进行离线HR/MRR评估以及线上A/B测试。OneLive在HR@128提升约16.7%，MRR@128提升约14.3%，线上曝光CTR提升1.3–1.96%，并在多目标指标上也显著优于基线。

**⚠️ 局限性**

限制：仍受实时编码延迟与GPU资源限制；模型规模需折中，导致推理延迟与吞吐量平衡；多目标奖励权重设定仍需手工调优；直播场景稀疏行为对训练鲁棒性提出挑战。

---

## 840. Beyond Scalar Scores: Reinforcement Learning for Error-Aware Quality Estimation of Machine Translation

**arXiv ID:** 2602.08600 | [PDF](https://arxiv.org/pdf/2602.08600v1)

**作者:** Archchana Sindhujan `[一作]` (University of Surrey), Constantin Orăsan `[通讯]` (University of Surrey)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一套基于低资源英语→马拉雅拉姆语的分段质量估计（QE）方法，构建了首个包含直接评估分数与翻译质量备注（TQR）的QE数据集，并利用该数据集与强化学习实现对LLM的优化。

**💡 创新点**

创新点在于：①将短文本自然语言错误备注作为弱监督信号，弥补传统单一数值评分的不足；②提出ALOPE‑RL框架，将政策优化与多元奖励（评分精度、错误类型、说明文本等）结合，提升LLM在低资源场景下的QE表现；③通过量化的LoRA适配器和4‑bit压缩，使得4B以下模型即可达到SOTA。

**🔧 技术方法**

使用的技术包括：大规模预训练LLM（Gemma‑3‑4B‑It、Qwen‑3‑4B‑Instruct、Llama‑3.2‑3B‑Instruct），LoRA微调、4‑bit量化、GRPO（Group Relative Policy Optimization）强化学习、BERTScore、DA分数与错误类别奖励等。

**📊 数据集**

数据集：首个英语→马拉雅拉姆语的分段QE数据集（约4K实例，含DA分数与TQR备注）；同时对英-泰、英-马、英-印三语对采用基于词级错误标签的弱监督。

**📈 对比分析**

在英语→马拉雅拉姆语上，ALOPE‑RL在Spearman相关性上获得0.571（最高）并显著优于零样本、指令微调及主流编码器基准（XCOMET、COMET‑Kiwi）。在其它三语对也均优于基线。

**⚠️ 局限性**

限制：①需要手工收集TQR备注，虽然比MQM易标注，但仍需人工；②强化学习训练过程较为复杂且对奖励设定敏感；③在非德拉维语系的低资源语对（英-马、英-印）时，基于词级标签的弱监督反而可能产生噪声，需进一步研究跨语言的通用性。

---

## 841. An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture

**arXiv ID:** 2602.08597 | [PDF](https://arxiv.org/pdf/2602.08597v1)

**作者:** Roland Bertin-Johannet `[一作]` (University Toulouse), Rufin VanRullen `[通讯]` (University Toulouse)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种基于全局工作空间（GW）理论的上行注意机制，用于在多模态融合中自适应选择可靠模态，提高系统对缺失或噪声模态的鲁棒性。

**💡 创新点**

创新点在于将注意机制与冻结的GW表示分离，能够在不重新训练整个系统的情况下，仅通过少量参数学习模态权重，同时支持跨任务、跨模态的泛化。

**🔧 技术方法**

采用GW框架的翻译、半循环、循环一致性与对比对齐自监督损失构建共享的amodal表示，并通过Key‑Query点积实现自适应权重。

**📊 数据集**

在合成的Simple Shapes数据集和真实的MM‑IMDb 1.0数据集上进行实验，分别验证噪声鲁棒性与多模态分类性能。

**📈 对比分析**

与GMU、DynMM等传统注意融合方法以及多种基线模型（CoMM、MFAS、BridgeTow等）比较，本文方法在噪声条件下实现了更高的准确率或macro‑F1，并在MM‑IMDb上获得了与最优基线相近甚至更优的性能，同时训练耗费的FLOPs显著低于对等方法。

**⚠️ 局限性**

局限性包括仅测试了静态图像/文本模态，缺乏对动态多模态（视频、音频）的验证；以及在扩展到更多模态时需进一步验证注意机制的可扩展性。

---

## 842. TFMLinker: Universal Link Predictor by Graph In-Context Learning with Tabular Foundation Models

**arXiv ID:** 2602.08592 | [PDF](https://arxiv.org/pdf/2602.08592v1)

**作者:** Tianyin Liao `[一作]` (Nankai University), Ziwei Zhang `[通讯]` (Beihang University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出一种名为 TFMLinker 的通用链接预测方法，利用表格基础模型（TFM）的上下文学习能力，在不进行数据集特定微调的情况下完成多域图数据的链接预测。

**💡 创新点**

创新点在于：①首次将 TFMs 引入链接预测任务；②设计了结合局部子图采样和全局可学习原型的上下文构造模块，既捕获图特定模式又提取跨图可迁移模式；③使用预训练 GNN 与启发式特征共同编码链路，生成可直接输入 TFM 的表格表示，从而实现全无微调的通用推理。

**🔧 技术方法**

技术手段包括：随机子图下采样 + 可学习原型构造上下文；基于 DRNL+ 标记技巧的预训练 GNN（UniLP）加上 AA、RA 等启发式特征的多编码器；将链路表示拼接为伪表格后输入 TabPFN 或 LimiX 等 TFM 进行 in‑context 学习；整个模型在大规模合成结构因果模型生成的数据上预训练。

**📊 数据集**

数据集：在 10 个不同领域的图（Ecoli、Yeast、Power、PolBlogs、Router、Physics、Pubmed、Citeseer、Twitch、Github）上预训练，并在 7 个未见图（Celegans、USAir、PB、NS、CS、Cora、Facebook）上进行评估。

**📈 对比分析**

与传统启发式方法（CN、AA、RA 等）、GNN 链接预测模型（GAE、SEAL、ELPH、NCNC、MPLP）以及 GFM UniLP 进行比较。TFMLinker 在 5/7 个基准上均超越所有基线，Hits@50 提升约 5%，整体排名提升 1.8 位，且不需要对每个测试图进行微调。

**⚠️ 局限性**

局限性：①性能受限于可学习原型数量和上下文长度，过多或过少都会影响效果；②模型依赖预训练 GNN 与 TFM，若预训练数据与目标图分布差异较大，泛化可能下降；③在极大规模图或缺少结构信息的场景下，计算开销和表示能力仍受限。

---

## 843. FairRARI: A Plug and Play Framework for Fairness-Aware PageRank

**arXiv ID:** 2602.08589 | [PDF](https://arxiv.org/pdf/2602.08589v1)

**作者:** Emmanouil Kariotakis `[一作]` (KU Leuven), Aritra Konar `[通讯]` (KU Leuven)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

开发了FairRARI框架，实现可插拔的公平PageRank向量计算，支持多种群组公平约束。

**💡 创新点**

将PageRank的变分表述与强凸优化相结合，给出带公平约束的投影迭代，并在三种公平准则下实现线性时间投影。

**🔧 技术方法**

使用变分法、强凸优化、投影梯度下降、固定点迭代和二分搜索实现的线性时间投影，并与传统PR、FSPR、LFPR等算法比较。

**📊 数据集**

在22个真实网络数据集上评估，包括PolBooks、Deezer、GitHub、DBLP-G、TwitchDE-2等。

**📈 对比分析**

通过与后处理基线和现有公平PR方法在TV距离与Kendall Tau上的对比，FairRARI在保持原始PR近似的同时满足公平约束，TV接近下界，Kendall Tau最高，计算时间仅比原PR增加约10%。

**⚠️ 局限性**

仅覆盖群组公平，未考虑个体公平或流行度公平；需要凸约束，无法处理非凸公平目标；在极端图结构下可能需要更多迭代。

---

## 844. SA-CAISR: Stage-Adaptive and Conflict-Aware Incremental Sequential Recommendation

**arXiv ID:** 2602.08678 | [PDF](https://arxiv.org/pdf/2602.08678v1)

**作者:** Xiaomeng Song `[一作]` (Shandong University), Zhumin Chen `[通讯]` (Shandong University)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文提出一种无缓冲、冲突感知的增量序列推荐框架SA-CAISR。

**💡 创新点**

创新点在于利用Fisher信息动态筛选冲突参数，并结合InfoNCE一致性正则，实现稳定-可塑性平衡。

**🔧 技术方法**

采用Transformer（SASRec）骨干，Fisher权重屏蔽和对比学习（InfoNCE）技术。

**📊 数据集**

实验使用四个公开数据集：DIGINETICA、YOOCHOOSE、Gowalla、Amazon Sports。

**📈 对比分析**

与重训练、微调、EWC、ADER等基线对比，SA-CAISR在Recall@20、MRR@20、NDCG@20平均提升约2%，并将内存和训练时间分别降低97.5%和46.9%。

**⚠️ 局限性**

局限性包括仅在注意力骨干上验证、未考虑用户/物品异质性、以及全局超参未自适应。

---

## 845. LLaDA2.1: Speeding Up Text Diffusion via Token Editing

**arXiv ID:** 2602.08676 | [PDF](https://arxiv.org/pdf/2602.08676v1)

**作者:** Tiwei Bie `[一作]` (Ant Group), Yihong Zhuang `[通讯]` (Ant Group)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ba576bd1-e51d-44e8-8077-fc943b333c93` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并实现了可配置阈值的混合 Mask‑to‑Token 与 Token‑to‑Token 解码策略，推出了 LLaDA2.1 及其 Mini/Flash 版本。

**💡 创新点**

创新点在于将动态的“草稿‑编辑”机制与可调阈值解码相结合，形成 Speedy 与 Quality 两种模式，并首次在大规模 dLLM 上实现基于 ELBO 的 Block‑级强化学习优化。

**🔧 技术方法**

使用了离散扩散模型、双阈值解码、Token‑to‑Token 编辑、持续预训练与监督微调的混合目标、Multi‑turn Forward 数据增强、ELBO‑based Block‑level Policy Optimization、Alpha‑MoE、FP8 量化、Block causal attention 等技术。

**📊 数据集**

在 CPT 与 SFT 阶段使用大规模通用文本与对话数据；评测集包括 MMLU‑Pro、GPQA‑Diamond、C‑Eval、PHYBench、TriviaQA、SQuAD、DROP、BIG‑Bench、CRUXEval、MultiPL‑E、BigCodeBench、LiveCodeBench、HumanEval+、OMNI‑MATH、GSM‑Plus、BFCL、IFEval 等约 33 项基准。

**📈 对比分析**

通过在 S Mode 与 Q Mode 下与 LLaDA2.0、Ling、Qwen‑3 等模型比较，评估 TPS、TPF 和各基准得分，发现 Flash 版在 S Mode 达到约 892 TPS，Mini 版约 1587 TPS，速度显著提升；在 Q Mode 上质量可超过 2.0 版本，整体性能兼具速度与质量。

**⚠️ 局限性**

仍存在速度‑准确性权衡，阈值需针对不同领域调优；编辑机制在非结构化对话中效果有限；模型处实验阶段，极端情况可能产生噪声或重复；缺乏长期自适应编辑与 RL 融合的进一步研究。

---

## 846. 6G-Bench: An Open Benchmark for Semantic Communication and Network-Level Reasoning with Foundation Models in AI-Native 6G Networks

**arXiv ID:** 2602.08675 | [PDF](https://arxiv.org/pdf/2602.08675v1)

**作者:** Mohamed Amine Ferrag `[一作]` (United Arab Emirates University), Merouane Debbah `[通讯]` (Khalifa University)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 6G‑Bench，一个面向 AI‑Native 6G 网络的开源基准，用以评估大型语言模型在语义通信与网络层推理方面的能力。

**💡 创新点**

创新点包括：①从 3GPP、IETF、ETSI、ITU‑T、O‑RAN 等标准化工作中抽取 30 项决策任务并按五大能力类别归纳；②构造 10,000 题难度极高的多选题（含多步量化推理与不确定性评估），并通过自动与专家双阶段校验保留 3,722 题作为高可信度评测集；③提出基于任务条件的评测流程、pass@k 鲁棒性指标，并系统评估 22 名现代基础模型。

**🔧 技术方法**

采用多轮对话情景重建、任务条件提示生成、自动去重与否定式约束、人工审核、JSON 解析等技术；评测使用 deterministic pass@1 与 stochastic pass@k；对模型规模、上下文长度、MoE 等参数进行归档与对齐。

**📊 数据集**

主要数据集为 α³‑Bench（113,475 个多轮场景）及其衍生的 10,000 题（3,722 题用于最终评测）；除此之外，还使用了 UAVBench 作为情境来源。

**📈 对比分析**

通过对 22 个模型（包含大模型、MoE、长上下文、开源与闭源）在 6G‑Bench 的 pass@1、pass@3、pass@5 进行对比，模型单轮准确率从 0.22 变到 0.82，顶尖模型在意图/策略推理组 0.87‑0.89，信任与安全组 0.83‑0.89；在鲁棒性评测中 pass@5 可提升至 0.92‑0.96，显示模型在多步推理下的可恢复性。

**⚠️ 局限性**

局限性：①评测集仅包含 3,722 题，覆盖面虽广但仍不足以完全代表未来 6G 任务多样性；②对高难度题目生成与校验过程可能引入偏倚，且人工审核耗时；③模型在信任/安全、分布式协同等子任务仍表现不佳，说明现有 LLM 对 6G 关键安全合规的内在推理仍有不足；④仅评估多选题答案，未覆盖生成式策略或代码生成等实际控制执行环节。

---

## 847. Equalized Generative Treatment: Matching f-divergences for Fairness in Generative Models

**arXiv ID:** 2602.08660 | [PDF](https://arxiv.org/pdf/2602.08660v1)

**作者:** Alexandre Verine `[一作]` (École normale supérieure), Florian Le Bronnec `[通讯]` (Université Paris-Dauphine)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并验证了一种新的公平定义——equalized generative treatment (EGT)，证明传统的比例匹配（EGO/MGO）在生成模型中易产生子群质量不均衡，并通过实验验证了 min‑max 训练策略在图像与文本生成任务中能显著提升 EGT 性能。

**💡 创新点**

① 证明比例基准无法保证子群生成质量；② 定义以 f‑divergence 为度量的 EGT；③ 证明最小-最大（min–max）优化可实现 EGT，并给出理论与实验的统一说明。

**🔧 技术方法**

使用 f‑divergence 评估、min–max 训练、条件训练、重加权等方法；采用扩散模型 EDM、LLaMA‑3.2、Gemma‑3 等生成模型；评价指标包括 Topological Precision & Recall、FID、MAUVE 等。

**📊 数据集**

FFHQ（人脸图像，性别敏感属性）和 Wikipedia Biographies（文本，性别敏感属性）。

**📈 对比分析**

与 EGO/MGO、条件训练、重加权三种常见公平策略对比；min‑max 在 precision/recall 等 δ‑指标上显著缩小子群差距，保持整体性能，但最优子群的精度/召回可能略有下降。

**⚠️ 局限性**

仅针对 f‑divergence 进行了理论分析，未覆盖其他距离度量；min‑max 训练需要额外的稳定技巧；公平提升伴随整体性能的轻微下降；实验规模受限，文本任务的算力成本高。

---

## 848. From Robotics to Sepsis Treatment: Offline RL via Geometric Pessimism

**arXiv ID:** 2602.08655 | [PDF](https://arxiv.org/pdf/2602.08655v1)

**作者:** Sarthak Wanjari `[一作]` `[通讯]`, Sarthak Wanjari

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `e15e3743-5ee0-4d5f-813d-d146868082fc` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种名为Geo-IQL的几何悲观主义框架，旨在通过基于密度的惩罚机制来增强离线强化学习（RL）的性能，特别是在处理稀疏和不稳定数据时。

**💡 创新点**

创新点在于通过几何距离来估计不确定性，并将其作为惩罚机制引入到标准的隐式Q学习（IQL）中，从而提高了算法的稳定性和安全性。

**🔧 技术方法**

使用了几何距离、k近邻算法和预计算的惩罚机制，结合隐式Q学习（IQL）进行训练。

**📊 数据集**

在D4RL MuJoCo基准和MIMIC-III脓毒症数据集上进行了评估。

**📈 对比分析**

与标准IQL相比，Geo-IQL在敏感和不稳定任务上提高了18分，同时将种子间方差减少了4倍。在稳定的数据流形上，Geo-IQL的性能没有下降。

**⚠️ 局限性**

限制在于Geo-IQL在某些情况下可能会对数据的稀疏性过于敏感，导致在极端情况下的表现不如预期。

---

## 849. Deep Learning-Based Fixation Type Prediction for Quality Assurance in Digital Pathology

**arXiv ID:** 2602.08652 | [PDF](https://arxiv.org/pdf/2602.08652v1)

**作者:** Oskar Thaeter `[一作]` (Technical University of Munich), Peter J. Schüffler `[通讯]` (Technical University of Munich)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

利用低分辨率预扫描缩略图训练深度学习模型，实现对病理切片固定方式（FFPE 与 FS）的自动分类。

**💡 创新点**

创新点在于：①仅依赖缩略图完成分类，避免高分辨率扫描后才做的耗时处理；②在多种视觉 Transformer 预训练模型中提出最佳组合（UNI+soft voting）；③在不同扫描仪上进行跨域评估，揭示扫描仪导致的域漂移问题。

**🔧 技术方法**

技术主要包括：视觉 Transformer（ViT）预训练模型、滑动窗口裁剪+软投票聚合、基于 OpenSlide 的缩略图提取与预处理、三层全连接分类头、Bayesian 超参数优化及单线程推理。

**📊 数据集**

使用了四个数据集：TUM（训练、验证、内部测试；Leica GT450DX），TCGA（外部测试；Leica AT2），Augsburg（外部测试；Philips UFS），Regensburg（外部测试；3DHISTECH P1000）。

**📈 对比分析**

与先前最先进的缩略图模型（Weng 等 0.78 AUROC）相比，本模型在 TCGA 上达到 0.88 AUROC，提升 12.8%；与高分辨率全切片模型（98.91% 准确率，≈10 s/切片）相比，虽然准确率略低，但推理时间仅 21 ms，速度快 400 倍，适合高通量预扫描 QC。

**⚠️ 局限性**

主要局限是扫描仪相关的域漂移：在非 Leica 扫描仪（Philips、3DHISTECH）上的准确率下降至约 50%/56%，AUROC 仅 0.72。未来需探索域适应、色彩归一化或多站点训练等方法。

---

## 850. Forget Superresolution, Sample Adaptively (when Path Tracing)

**arXiv ID:** 2602.08642 | [PDF](https://arxiv.org/pdf/2602.08642v1)

**作者:** Martin Bálint `[一作]` (Max Planck Institute for Informatics), Karol Myszkowski `[通讯]` (Max Planck Institute for Informatics)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了针对实时路径跟踪在极低采样率（<1 spp）下的端到端自适应采样与去噪管线。

**💡 创新点**

创新点：①使用随机化采样的可微稀疏采样框架，实现极低采样率下的梯度估计；②基于可微 Filmic 曲线的色调映射感知训练，结合 MILO 损失；③采集层级金字塔稀疏去噪滤波和可学习的颜色除调；④共享特征的采样器与去噪器并行学习。

**🔧 技术方法**

技术：可微随机采样/松弛估计、可微 Filmic 色调映射、MILO 感知损失、Gather式金字塔卷积去噪、可学习的反调色、蓝噪声随机化。

**📊 数据集**

使用扩展后的 Noisebase 数据集（1024个序列，每帧64帧）并预渲染多倍样本。

**📈 对比分析**

与 DLSS、JNDS、NPPD、NTASD、SAUDC、RLSNAS 等方法在多预算、分辨率、感知指标上比较，最低 0.25 spp 时 PSNR 25.4 dB、MS‑SSIM 0.927、MILO 2.677，优于所有基线；在更高预算下持续领先。

**⚠️ 局限性**

局限：训练在极低预算下仍可能发散；需要高分辨率 GBuffer；模型规模大，推理成本高；目前仅在离线训练场景验证，尚未在实时引擎完整集成。

---

## 851. Debate is efficient with your time

**arXiv ID:** 2602.08630 | [PDF](https://arxiv.org/pdf/2602.08630v1)

**作者:** Jonah Brown-Cohen `[一作]` (Google DeepMind), Mario Szegedy `[通讯]` (Rutgers University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

**🎯 论文内容**

本文定义了辩论查询复杂度（DQC）作为衡量人工监督成本的指标，并对其在电路复杂度、对数查询效率以及与PSPACE/poly的关系进行了理论分析。

**💡 创新点**

创新点在于：①提出DQC概念并给出上界与下界；②证明PSPACE/poly等价于可用O(log n)查询的函数；③通过交叉审查技术将多项式时间验证压缩至对数查询；④建立DQC下界与电路下界之间的桥梁，指出提升DQC下界可推动电路下界突破。

**🔧 技术方法**

主要使用了：Karchmer–Wigderson游戏、交叉审查（cross‑examination）技巧、决策树与信息复杂度分析、Yao原理，以及新颖的对数查询压缩构造。

**📊 数据集**

无实验数据集，研究完全基于理论证明与抽象模型。

**📈 对比分析**

方法与传统的人工监督对比：理论上人工审阅量仅需O(log n)条信息，而非按问题规模线性或多项式增长；在已知的复杂度类（如PSPACE/poly）中得到最优对数查询效率，证明了理论性能的最优性。

**⚠️ 局限性**

局限性包括：①假设争论者具备无限算力，现实中可能受限；②对随机化验证器的优势几乎无提升，限制了进一步的效率提升；③证明更高下界仍与电路下界难题相连，实际实现和实验验证仍缺失。

---

## 852. Revisiting [CLS] and Patch Token Interaction in Vision Transformers

**arXiv ID:** 2602.08626 | [PDF](https://arxiv.org/pdf/2602.08626v1)

**作者:** Alexis Marouani `[一作]` (FAIR), Huy V. Vo `[通讯]` (FAIR)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `6514db3d-8de6-452c-91b7-acdb31787cc4` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究 Vision Transformer 中 class token 与 patch token 的相互作用，发现层归一化会隐式区分两类 token，随后提出在归一化层、QKV 投影等位置对两类 token 采用专门化权重，显式分离它们的计算通道；通过这种轻量级层级专化显著提升密集预测任务的表现。

**💡 创新点**

创新点在于：①首次系统地分析并证明 LayerNorm 在 self‑attention 前即能隐式区分 global 与 local token；②设计专门化的 LayerNorm/LayerScale、QKV 投影等模块，使两类 token 共享注意力机制但在前处理阶段保持不同；③该专化仅增加约 8% 参数，且不增加 FLOPs，兼顾模型规模与效率。

**🔧 技术方法**

技术手段包括：Vision Transformer 架构、LayerNorm/LayScale 专化、QKV 投影专化、self‑attention、线性探针评估、PCA 可视化；预训练方式使用自监督 DINOv2 以及全监督 DeiT‑III；对不同高范数处理策略（registers、attention bias）也做实验。

**📊 数据集**

数据集：预训练使用 ImageNet‑22K（DINOv2）和 ImageNet‑1K（DeiT‑III）；下游评估涵盖 ADE20K、Cityscapes、PASCAL VOC（语义分割）、KITTI、NYU Depth v2、SUN RGB‑D（深度估计）以及 COCO（目标检测）。

**📈 对比分析**

评估方法：对原始 DINOv2、DeiT‑III、CaiT 等 baseline 在 ImageNet‑1K 线性分类和多种密集预测任务（mIoU、RMSE、AP）上进行对比；结果显示在分割任务上平均提升 1.0–2.2 mIoU，深度估计 RMSE 减少 0.05–0.08，检测 AP 维持或略增，而分类精度仅无显著下降。

**⚠️ 局限性**

局限性：专化对不同训练目标（自监督 vs 全监督）和模型规模（ViT‑L 在全监督下无明显收益）敏感；仍需额外参数（虽然增幅小），并未深入探讨多模态或跨任务的适用性；对极大模型的训练稳定性和收敛速度尚需进一步验证。

---

## 853. Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs

**arXiv ID:** 2602.08621 | [PDF](https://arxiv.org/pdf/2602.08621v1)

**作者:** Yukun Jiang `[一作]`, Yang Zhang `[通讯]` (CISPA Helmholtz Center for Information Security)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `afceb026-1760-41ae-8d86-010831a37d97` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

探究混合专家（MoE）大型语言模型的稀疏安全问题，发现并利用“危险路径”使模型产生不安全输出；

**💡 创新点**

提出Router Safety importance score（RoSais）量化路由器对安全的影响，并基于此设计Fine‑grained Unsafe Route Discovery（F‑SOUR）框架，显著提升对抗性攻击成功率；

**🔧 技术方法**

RoSais、随机遮蔽路由器、分层与分词粒度的随机优化搜索、Shadow Judge与重启机制；

**📊 数据集**

JailbreakBench、AdvBench两大危险查询集，评估多款MoE LLM（DeepSeek‑V2‑Lite、Mixtral‑8x7B、OLMoE‑1B‑7B、Qwen1.5‑MoE‑A2.7B）；

**📈 对比分析**

与原模型、GCG、SHIPS、SAFEx、SteerMoE、TAP等对手手段比较，F‑SOUR在四款模型上均达0.86–0.94的攻击成功率，显著优于现有方法；

**⚠️ 局限性**

RoSais方法对路由器重要性估计依赖静态单词，易受浅层干扰；F‑SOUR计算量大，对资源和时间有较高要求；缺乏针对动态RoSais更新与更高效的路由器筛选策略；

---

## 854. ERIS: Enhancing Privacy and Communication Efficiency in Serverless Federated Learning

**arXiv ID:** 2602.08617 | [PDF](https://arxiv.org/pdf/2602.08617v1)

**作者:** Dario Fenoglio `[一作]` (Università della Svizzera italiana), Marc Langheinrich `[通讯]` (Università della Svizzera italiana)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了名为 eris 的无服务器联邦学习框架，通过梯度分区和分布式位移压缩实现了与 FedAvg 等价的聚合，同时显著降低通信开销并提升隐私安全。

**💡 创新点**

创新点包括：1）完全等价 FedAvg 的去中心化聚合；2）结合模型分区与分布式压缩的双重技术；3）信息论层面的隐私放大与通信效率提升的理论与实证证明。

**🔧 技术方法**

核心技术包括：ω‑压缩（随机稀疏化/量化）、位移压缩、模型分区（离散掩码划分）、分布式聚合器、信息论隐私分析与无服务器架构。

**📊 数据集**

实验使用 MNIST、CIFAR‑10、IMDB、CNN/DailyMail（GPT‑Neo 1.3B）、LFW 等数据集，涵盖从 62K 参数到 1.3B 参数的模型。

**📈 对比分析**

与 FedAvg、LDP、SoteriaFL、PriPrune、Shatter 等 SOTA 方法对比，eris 在保持或接近 FedAvg 级别准确率的前提下，通信上传量下降至 1% 以内，隐私攻击（MIA、DRA）成功率显著低于基线。

**⚠️ 局限性**

限制：需要聚合器的可用性与网络稳定性；多聚合器协同会降低隐私放大效果；在极端聚合器缺失或网络抖动场景下，收敛速度可能受影响。

---

## 855. OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval

**arXiv ID:** 2602.08603 | [PDF](https://arxiv.org/pdf/2602.08603v1)

**作者:** Teng Wang `[一作]` (OPPO), Jun Wang `[通讯]` (OPPO)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了 OSCAR 框架：先用离线两阶段混合整数规划（MIP）优化得到最佳工具调用轨迹和集合组合逻辑，然后将这些轨迹存入金色库，在推理时通过 VLM 代理基于金色演示完成一次性、无训练的组合式图像检索。

**💡 创新点**

创新点：① 把 agentic CIR 从启发式搜索转化为全局优化的轨迹规划；② 通过两阶段 MIP 既保证召回又实现精确的布尔集合组合；③ 使用金色库作为上下文演示，使 VLM 在单次推理中复制优化得到的抽象推理策略；④ 仅需 10% 训练数据即可实现超越 SOTA 的性能。

**🔧 技术方法**

核心技术：离线两阶段混合整数规划、布尔集合操作（并、交、差）、VLM（如 Qwen3、InternVL）工具调用、查询重写、top‑k 截断、金色库检索与上下文注入。

**📊 数据集**

使用数据集：公开 CIRCO、CIRR、FashionIQ 三大组合式图像检索基准，以及私有工业照片库（1,069/1,466/1,047 张图像，483/336/369 条用户查询)。

**📈 对比分析**

对比方法：多模态嵌入模型、文本嵌入模型、CIR 专用方法、启发式 agentic 方法。实验表明 OSCAR 在所有基准上均取得显著提升，例如 CIRR Recall@1 提升 18%+、FashionIQ mAP@5 提升 23%+，并且仅用 10% 的训练数据即可达到 SOTA 水平。

**⚠️ 局限性**

局限性：① 离线 MIP 求解成本高，需额外计算资源；② 依赖 VLM 的工具调用与推理能力，若工具支持不足会失效；③ 对极端负面属性或多重否定的推理仍可能出现多余或缺失的过滤；④ 金色库的覆盖度受训练样本多样性影响，对完全新颖查询的迁移能力有限。

---

## 856. A Machine Learning accelerated geophysical fluid solver

**arXiv ID:** 2602.08670 | [PDF](https://arxiv.org/pdf/2602.08670v1)

**作者:** Yang Bai `[一作]` `[通讯]` (Technical University of Berlin), Yang Bai (Technical University of Berlin)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

设计并实现了二维/三维浅水方程与欧拉方程的经典有限体积求解器，并将其迁移至 PyTorch 与 DACE 框架，随后嵌入四种基于 CNN 的数据驱动方法，对球面浅水方程进行加速求解与性能评估。

**💡 创新点**

创新点在于：①通过机器学习预测有限差分/有限体积系数，实现在低分辨率下保持守恒性与高精度；②提出四种不同 CNN 结构（直接预测通量、学习线性系数、直接预测边界状态、预测重构斜率），验证其稳定性与准确性；③构建可扩展的逻辑正方形网格球面求解器，显著提升速度并与 PyClaw 进行对比。

**🔧 技术方法**

使用有限体积法（Rusanov、Roe、HLL、HLLE、HLLC Riemann 求解器）、MINMOD 极限器、Runge‑Kutta 高阶时间积分；机器学习方面采用卷积神经网络（CNN）预测通量或边界状态；框架包括 PyTorch、DACE（数据中心并行编程）以及 PyClaw；训练数据源自高分辨率 PyClaw 结果的降采样。

**📊 数据集**

数据集为高分辨率 (1000×500) 球面 Perlin 噪声与 Rossby‑Haurwitz 初始条件共 300 条样本；1D 高分辨率 Gaussian 过程样本；2D Perlin 噪声样本；总计约 200,000 条训练样本。

**📈 对比分析**

通过相对误差、能量守恒、潜在涡量等指标与 PyClaw 对比，经典 DACE/Torch 求解器速度比 PyClaw 快数倍；第三、第四种 ML 方案在能量保持与误差方面与 2 阶经典求解器相当或更优，计算时间与 1 阶经典求解器相近，表现出显著的加速效果。

**⚠️ 局限性**

主要限制包括：①第一、第二种 CNN 结构易出现负水深或 NaN，稳定性不足；②训练样本量有限，网络泛化性待提升；③球面高分辨率时重构精度与能量守恒仍需改进；④尚未完成对欧拉方程的数据驱动求解，需进一步约束正密度与正能量。

---

## 857. Retrieval Pivot Attacks in Hybrid RAG: Measuring and Mitigating Amplified Leakage from Vector Seeds to Graph Expansion

**arXiv ID:** 2602.08668 | [PDF](https://arxiv.org/pdf/2602.08668v1)

**作者:** Scott Thornton `[一作]` `[通讯]`, Scott Thornton

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究混合RAG系统在向量检索和知识图谱扩展之间的安全风险，并提出检索Pivot风险（RPR）及其度量方法；

**💡 创新点**

首次量化跨租户泄漏的二跳结构特征，定义RPR、Leakage@k、AF、PD等指标，并设计五层防御，证明一次性逐跳授权即可完全消除泄漏；

**🔧 技术方法**

使用向量检索（ChromaDB）+实体链接+Neo4j BFS图遍历，配合自定义攻击模板和逐跳授权技术；

**📊 数据集**

合成企业多租户语料（1000文档、4租户）和Enron邮件语料（50k邮件、5部门），构建对应知识图；

**📈 对比分析**

通过RPR、Leakage@k、AF、PD等指标对500/200个查询进行评估，未防御RPR≈0.95/0.70，防御后RPR→0且延迟<1 ms，内容量保持5.6×向量检索；

**⚠️ 局限性**

仅考察二分块-实体图，未评估更复杂实体关系；使用公开数据与单一NER；生成质量评估有限；假设元数据可信，未涵盖复杂RBAC/ABAC场景。

---

## 858. Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models

**arXiv ID:** 2602.08658 | [PDF](https://arxiv.org/pdf/2602.08658v1)

**作者:** Mingzi Cao `[一作]` (University of Sheffield), Nikolaos Aletras `[通讯]` (University of Sheffield)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过在符号推理轨迹上训练LLM，系统评估了推理范式（演绎、归纳、溯因）对模型泛化能力的影响，并验证了多种诱导方法的效果。

**💡 创新点**

创新点在于①使用抽离世界知识的符号推理轨迹来单独诱导三种基本推理范式；②首次系统比较单独与混合范式对OOV表现的影响；③发现Mixture‑of‑Experts（upcycling）在不同模型上比传统FT、LoRA和上扩更能提升推理性能。

**🔧 技术方法**

主要技术包括：教师模型（Qwen3‑30B‑Instruct、Llama‑3.3‑70B‑Instruct）生成轨迹；使用全参数FT、LoRA、模型上扩（LLaMAPro）和upcycling（Sparse‑Upcycling）等诱导方法；使用Qwen3‑30B‑Instruct作为判定器评估答案准确率。

**📊 数据集**

数据集为自建的约17K条符号推理题（SAT、数列、逻辑），以及五个真实OOV任务（True Detective、αNLI、WinoWhy、FOLIO、RECV）。

**📈 对比分析**

通过对比教师模型、原始学生和四种诱导方法的性能，采用准确率评估。结果显示在OOV任务上提升高达14.60分，演绎推理取得最高提升，upcycling在大多数设置中表现最佳。

**⚠️ 局限性**

局限性包括：仅使用英文数据；符号任务仅覆盖单一代表性实例，未充分探索不同符号任务的影响；跨语言泛化及多语言评估尚未展开。

---

## 859. High-Speed Vision-Based Flight in Clutter with Safety-Shielded Reinforcement Learning

**arXiv ID:** 2602.08653 | [PDF](https://arxiv.org/pdf/2602.08653v1)

**作者:** Jiarui Zhang `[一作]` (Zhejiang University), Fei Gao `[通讯]` (Zhejiang University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

设计并实现了一个融合强化学习与基于模型安全机制的四旋翼高速度障碍规避框架。

**💡 创新点**

创新点包括：在训练阶段使用基于Dijkstra的全局导航奖励和CBF安全奖励，以及在部署阶段通过高阶控制障碍函数(HOCBF)实时投影策略输出，既保留了学习算法的低延迟优势，又实现了高速度下的形式化安全保证。

**🔧 技术方法**

主要技术包括：PPO异步actor‑critic网络、CNN+GRU感知模块、三维ESDF与CBF安全奖励、HOCBF实时QP滤波、域随机化与Sim2Real转移。

**📊 数据集**

训练与评估数据集来自Isaac Lab生成的16个程序化随机障碍场景，测试环境为8个未见过的不同密度几何障碍场景。

**📈 对比分析**

与Ego‑Planner和DiffPhys等基准在3、5、7、9 m/s目标速度下进行对比，实验显示我方方法在各速度下成功率分别为87.5%、75%、42.5%与25%，显著优于对照方法。

**⚠️ 局限性**

局限性在于软奖励对高速度安全约束的学习仍有限，对动态障碍物和细小障碍物的感知与规避仍有挑战，未来需进一步提升动态场景鲁棒性。

---

## 860. Comparison of Structure Preserving Schemes for the Cahn-Hilliard-Navier-Stokes Equations with Degenerate Mobility and Adaptive Mesh Refinement

**arXiv ID:** 2602.08639 | [PDF](https://arxiv.org/pdf/2602.08639v1)

**作者:** Jimmy Kornelije Gunnarsson `[一作]` (Lund University), Robert Klöfkorn `[通讯]` (Lund University)

**关键词:** `e4c502e8-c16d-4c56-8df3-cffaee9eaadb` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文比较并改进了多相流Cahn‑Hilliard‑Navier‑Stokes (CHNS) 系统中结构保持（质量守恒、能量耗散、相场界限保持）的数值方案，尤其聚焦于Discontinuous Galerkin (DG) 方法与基于ASU的限制器以及传统连续Galerkin方案；

**💡 创新点**

创新点在于提出一种加权DG形式以减轻相场逼近界限时的阻尼问题，并将ASU限制器与DG相结合实现无后处理的界限保持；同时给出完整的UFL实现代码并在适应网格下验证可扩展性；

**🔧 技术方法**

采用的技术包括：IMEX时离散、变形密度与粘度的非均匀耦合、Symmetric Weighted Interior Penalty (SWIP) 与 SIPG 离散、ASU 上的上风移动项、质量守恒的L2投影、能量守恒的梯度提升与对偶网格适应；

**📊 数据集**

使用标准的CHNS基准数据集，包括：制造解、旋转合并气泡、上升气泡（Case 1 与 Case 2）以及典型的圆盘/球面上升/旋转问题，均采用不同的物理参数（密度、粘度比、Re、We、Fr、Cn、Pe）以及适应网格；

**📈 对比分析**

比较方法：在相同时间步长和网格设置下计算质量误差、能量衰减曲线、相场最大/最小值；结果显示：受限DG方案（ASU+DG+限制器）在质量守恒和界限保持上表现最佳，能量耗散与标准DG相近；无限制方案虽收敛速度快但会出现界限外溢；传统CG-L有限元方案在质量保持上略逊，且在强耦合下更易失稳；

**⚠️ 局限性**

局限性：高阶（k>1）DG方案实现难度较大，且对预条件器要求高；ASU限制器需要在每步进行投影，增加计算量；部分方案在强耦合或高Re条件下仍出现质量漂移；目前仅在二维平面上验证，三维推广需进一步研究。

---

## 861. CauScale: Neural Causal Discovery at Scale

**arXiv ID:** 2602.08629 | [PDF](https://arxiv.org/pdf/2602.08629v1)

**作者:** Bo Peng `[一作]` (Shanghai Artificial Intelligence Laboratory), Chaochao Lu `[通讯]` (Shanghai Artificial Intelligence Laboratory)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

设计了一种可扩展至1000节点的神经因果发现架构，支持大规模图的高效推理；

**💡 创新点**

创新点在于：①压缩单元（Reduction Unit）在网络内部对观测维度进行压缩；②共享注意力权重（tied attention）显著降低显存；③双流（data + graph）设计将观测的关系信息注入图流，保持信息完整；

**🔧 技术方法**

采用了Axial Attention、共享注意力、Data2Graph模块、压缩单元、双流融合以及分离式预测头；

**📊 数据集**

主要使用合成数据（线性、非线性、Sigmoid、Polynomial机制的Erdős‑Rényi/Scale‑Free图）和单细胞基因调控网络（SERGIO）生成的半合成数据；

**📈 对比分析**

与PC、FCI、NOTEARS、SDCD、DiffAN、AVICI、SEA‑gies等传统与预训练方法对比，取得99.6%（in‑distribution）/84.4%（OOD）mAP，推理速度比NOTEARS提升4–13 000倍，训练可达500节点，推理可达1000节点；

**⚠️ 局限性**

对噪声分布和机制函数的OOD场景较为敏感，模型对非标准分布与复杂机制的鲁棒性仍有限，需要更丰富的训练分布和更大样本量来进一步提升稳健性。

---

## 862. A Precise Real-Time Force-Aware Grasping System for Robust Aerial Manipulation

**arXiv ID:** 2602.08599 | [PDF](https://arxiv.org/pdf/2602.08599v1)

**作者:** Kenghou Hoi `[一作]` (Zhejiang University), Fei Gao `[通讯]` (Zhejiang University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `51c0528b-f690-4182-ae60-bb5f046c276c`

**🎯 论文内容**

设计并实现了一种集成磁性柔性触觉传感器的轻量化空中操控平台，实现了实时力感知和基于力的自适应控制，能够安全抓取并承载易碎物体。

**💡 创新点**

①提出基于磁场变化的低成本柔性触觉传感器并实现多点阵列；②通过参考霍尔传感器消除地磁干扰，实现精确三维力测量；③将力反馈融入自适应阻抗控制，提升对易碎物体的柔性抓取性能。

**🔧 技术方法**

磁性软触觉传感器、霍尔效应磁传感、地磁补偿算法、可变阻抗控制、姿态与位置控制、视觉-惯性里程计、CAN总线通信。

**📊 数据集**

未使用公开数据集，所有评估基于实验室实测数据（气球、玻璃杯、鸡蛋、木块等）。

**📈 对比分析**

与现有软触觉传感器(ReSkin、9DTact)及无力反馈抓取方法比较。实验表明在气球抓取任务中，系统将抓取力控制在0.25–0.65 N内，显著低于开环控制导致的破裂；在动态负载测试中，系统可在±180 g负载变化下维持高度误差≤3 cm，表现优于传统无力反馈方案。

**⚠️ 局限性**

1) 传感器在极大负载下测量范围有限；2) 目前仅在受控实验环境验证，缺乏复杂室外环境的鲁棒性评估；3) 需进一步研究抓取规划与物体识别以提升完全自主性。

---

## 863. Learning to Judge: LLMs Designing and Applying Evaluation Rubrics

**arXiv ID:** 2602.08672 | [PDF](https://arxiv.org/pdf/2602.08672v1)

**作者:** Clemencia Siro `[一作]` (Centrum Wiskunde en Informatica), Mohammad Aliannejadi `[通讯]` (University of Amsterdam)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出GER‑Eval框架，系统评估LLM自生成评估标准并在多任务场景下应用，探讨其与人类标准的对齐与跨模型迁移性。

**💡 创新点**

创新点在于将评估标准的生成与使用解耦，构建统一的两阶段实验流程，并验证LLM在自身标准上的高一致性与对人类标准的偏差；同时首次系统研究标准在不同模型间的可迁移性。

**🔧 技术方法**

技术核心包括Prompt工程（Task‑only、Task+Contexts、Task+Contrastive），LLM推理（GPT‑4o、GPT‑4o‑mini、Mixtral‑8x22B、Llama‑3.3‑70B、Qwen2.5‑72B），以及基于零样本与少样本的评分推理；评估指标为一致性、相关性、ICC/α/Kappa等。

**📊 数据集**

数据集覆盖四大NLG任务：对话（USR、HelpSteer2）、摘要（SummEval、SumPubMed）。

**📈 对比分析**

对比方法采用人类标注标准与LLM自生成标准的零样本/少样本评分，衡量与人类评分的Spearman相关系数与同一模型内部的零样本/少样本一致率。结果显示，闭源GPT‑4o在对话类任务上相关系数>0.8、内部一致率>85%，但在医学摘要等知识密集任务相关系数降至<0.3；跨模型迁移在对话任务中表现出较好的一致性，而在SumPubMed任务则极差。

**⚠️ 局限性**

局限性包括仅评估英语单一模态，未覆盖多语言或小型模型；对事实准确性的验证依赖人类标签；未考虑模型随时间的漂移或交互式反馈；跨模型迁移仅在有限的标准与任务上测试，难以推断更广泛的适用性。

---

## 864. The Theory and Practice of MAP Inference over Non-Convex Constraints

**arXiv ID:** 2602.08681 | [PDF](https://arxiv.org/pdf/2602.08681v1)

**作者:** Leander Kurscheidt `[一作]` (University of Edinburgh), Antonio Vergari `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了两种针对非凸代数约束和非对数凹密度的MAP推理方法，一种基于树形结构的精确消息传递求解器，另一种将可判定的凸多面体枚举与局部优化相结合的近似框架。

**💡 创新点**

创新点在于：①将可分解为树形结构的非凸MAP问题归纳为可解的子类并给出严格的消息传递算法；②设计了可并行、可裁剪的全局凸多面体枚举与优化管道，能够处理任意密度并在约束多面体上实现全局或近似最优；③在理论、算法与实践三方面同时突破了现有方法在复杂约束下的可扩展性与精度。

**🔧 技术方法**

使用SMT（线性实数）约束表达式、分段多项式/指数多项式密度、树形消息传递算法、AllSMT凸多面体枚举、局部优化器（LBFGS、SoS‑moment、粒子法）以及上界剪枝技术。

**📊 数据集**

实验数据集包括合成的树形（STAR、SNOW、PATH）约束实例、斯坦福无人机轨迹数据（SDD）以及基于House‑Sales的表格数据缺失实验。

**📈 对比分析**

与OptiMathSAT、CDCL‑OCAC、Adam以及粒子化约束优化器等基线对比，精确消息传递在树形问题上速度提升数倍且获得最优解；PA‑MAP在轨迹预测与缺失填充任务中以更低的相对最优缺口、比粒子法更快的运行时间优于现有OMT求解器，整体性能优越。

**⚠️ 局限性**

局限性包括：①精确解法仅适用于树形全局结构，非树形或高直径图难以扩展；②近似框架需要大量凸多面体枚举，枚举规模与约束复杂度呈指数增长；③上界剪枝依赖于可解析的密度结构，某些黑盒密度或高维问题可能难以获得有效上界。

---

## 865. Belief Offloading in Human-AI Interaction

**arXiv ID:** 2602.08754 | [PDF](https://arxiv.org/pdf/2602.08754v1)

**作者:** Rose E. Guingrich `[一作]` (Princeton University), Umang Bhatt `[通讯]` (University of Cambridge)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出并系统阐述了“信念卸载（belief offloading）”这一概念，定义了其与认知卸载的区别，给出了三条判定条件、BENDING模型下的网络传播分析及一套多维度分类体系，并讨论了其在伦理与社会层面的潜在风险。

**💡 创新点**

创新点在于：①首次将信念卸载作为一个独立的认知过程来定义和分析；②构建了三阶段判定条件和BENDING网络传播模型，揭示了卸载后信念在网络中的级联效应；③提出了多层次分类（从自我认知到社会协调、从基本到非基本、从有意到无意等）和四大伦理关注领域，为后续实证研究提供理论框架。

**🔧 技术方法**

本研究主要采用跨学科理论分析与概念建模方法，借鉴哲学、认知心理学和计算机科学文献，构建了BENDING模型的扩展，未使用机器学习或程序实现技术。

**📊 数据集**

文章并未使用具体数据集进行实验，主要依据大型语言模型的训练语料（如宗教文本、政治宣言、学术论文等）作为理论示例，讨论其对用户信念的潜在影响。

**📈 对比分析**

由于为理论与框架性工作，未进行实验比较或性能评估；文中提出未来研究方向，建议通过用户实验、行为追踪或大规模日志分析来量化信念卸载的影响。

**⚠️ 局限性**

局限性包括：①缺乏经验验证，理论假设尚未通过实证检验；②模型对不同用户群体、文化背景及AI系统多样性的适用性待进一步探讨；③依赖于LLM训练数据的内容与偏见，可能导致对特定社会群体的偏向性结论。

---

## 866. Shifting the Breaking Point of Flow Matching for Multi-Instance Editing

**arXiv ID:** 2602.08749 | [PDF](https://arxiv.org/pdf/2602.08749v1)

**作者:** Carmine Zaccagnino `[一作]` (University of Modena and Reggio Emilia), Silvia Cascianelli `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `04572f8d-59e5-41c9-8850-ac8e7ee2b108` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种实例去耦合注意力（Instance-Disentangled Attention），实现多实例文本引导的单次流匹配图像编辑

**💡 创新点**

通过将联合注意力拆分为实例专属与全局子注意力，解决传统全局速度场导致的语义泄漏（attribute leakage）问题

**🔧 技术方法**

采用流匹配（Rectified Flow Matching）+ MMDiT Transformer，结合注意力掩码和高效多提示编码

**📊 数据集**

在LoMOE-Bench、Crello Edit与InfoEdit三大数据集上进行评估，后两者为自制的密集文本编辑基准

**📈 对比分析**

与FLUX、LoMOE、LayerEdit、Calligrapher等基线比较，实验表明在编辑数量、文本准确率、背景保持和视觉一致性等指标上均优于或相近，且单次推理速度显著提升

**⚠️ 局限性**

仍存在一定的语义干扰与对大规模实例的鲁棒性不足，且目前主要针对文本编辑，其他视觉目标的多实例支持仍待进一步探索

---

## 867. SynSacc: A Blender-to-V2E Pipeline for Synthetic Neuromorphic Eye-Movement Data and Sim-to-Real Spiking Model Training

**arXiv ID:** 2602.08726 | [PDF](https://arxiv.org/pdf/2602.08726v1)

**作者:** Khadija Iddrisu `[一作]` (Dublin City University), Noel OConnor `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `67630363-6be0-4f51-ab05-7198250671a5` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

通过 Blender 生成合成眼动事件流并使用 Spiking Neural Networks 对快速眼动（扫视与停顿）进行分类，随后在真实事件数据上进行微调。

**💡 创新点**

创新点在于①构建完整的合成事件数据集（SynSacc）并提供标注；②将合成数据与真实数据结合进行迁移学习，显著缩小域差距；③使用 SNN 实现高效低能耗的眼动识别。

**🔧 技术方法**

技术方法包括 Blender 3D 眼动仿真 → V2E 事件模拟 → 二值脉冲编码 → CUBA‑LIF 及卷积/全连接 SNN 架构 → surrogate gradient 训练；对比传统 ANN。

**📊 数据集**

使用了自制合成数据集 SynSacc（约 2,200 条样本）以及公开的 EV‑Eye 真实事件数据集。

**📈 对比分析**

评估方式：在合成数据上比较 DenseSNN 与 ConvSNN；在不同时间分辨率下测试 DenseSNN；在真实数据上做零样本与微调实验；与等价 ANN 的 MAC/激活量对比。性能：合成数据上 DenseSNN 83.5% 准确率，ConvSNN 70.7%；在 200 ms 窗口下 92.25%；微调 50% EV‑Eye 后 87.8%；SNN 的事件/突触运算量比 ANN 小数倍至千倍。

**⚠️ 局限性**

局限性：合成与真实数据仍存在域差距，需更多真实标注；SNN 的训练难度与超参数调优；目前仅覆盖扫视与停顿两类，未涉及更细粒度眼动；对低光/噪声环境的鲁棒性待进一步验证。

---

## 868. FusionEdit: Semantic Fusion and Attention Modulation for Training-Free Image Editing

**arXiv ID:** 2602.08725 | [PDF](https://arxiv.org/pdf/2602.08725v1)

**作者:** Yongwen Lai `[一作]` (South China Normal University), Shaobo Min `[通讯]` (University of Science and Technology of China)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `04572f8d-59e5-41c9-8850-ac8e7ee2b108` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出FusionEdit，一个训练‑free 的文本引导图像编辑框架，实现对目标提示的精确可控编辑并保持源图像身份。

**💡 创新点**

创新点包括：①利用源/目标提示的速度场差异自动生成语义差异图并进行区域生长得到软掩模；②在软掩模上做距离感知潜变量融合并加入全变分正则以平滑边界；③引入基于AdaIN的差异感知注意力调制（DAM），在保留全局一致性的同时提升编辑可控性。

**🔧 技术方法**

技术手段：Rectified Flow（Flux）模型与ODE轨迹、速度场语义差异计算、区域生长+距离感知软掩模、全变分正则、AdaIN注意力调制、潜变量融合。

**📊 数据集**

使用PIE‑Bench基准数据集（700张图像）进行评估。

**📈 对比分析**

与RF Inversion、InfEdit、FlowEdit、LOCATEdit、MasaCtrl等多种现有方法对比，采用CLIP‑T、PSNR、LPIPS、MSE、SSIM、结构距离等指标，FusionEdit在大多数指标上领先，且用户研究显示最高的偏好率。

**⚠️ 局限性**

局限性：依赖Rectified Flow模型的预训练质量，软掩模生成对噪声仍有一定敏感性；在极端大语义变换或细粒度编辑场景下的鲁棒性尚待进一步验证。

---

## 869. Towards Understanding Multimodal Fine-Tuning: Spatial Features

**arXiv ID:** 2602.08713 | [PDF](https://arxiv.org/pdf/2602.08713v1)

**作者:** Lachin Naghashyar `[一作]` (University of Oxford), Constantin Venhoff `[通讯]` (University of Oxford)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过阶段性模型差分（stage‑wise model diffing）对视觉‑语言模型（VLM）在多模态微调过程中的内部特征进行逐层分析，揭示语言骨干如何“学习视觉”，尤其是空间关系的编码。

**💡 创新点**

创新点在于：①将阶段性模型差分扩展至多模态场景，提供了首个基于特征层面的机制解释；②通过可视化旋转的稀疏自编码器（SAE）特征，筛选出视觉偏好且旋转显著的特征；③利用空间查询的分布式偏移与词汇过滤，识别空间专用特征，并用归因补丁（attribution patching）定位其因果驱动的中层注意头。

**🔧 技术方法**

使用的核心技术包括稀疏自编码器（SAE）进行特征表示、阶段性模型差分以追踪特征旋转、归因补丁评估注意头贡献、以及特征消融验证因果性；实验还采用了自动解释工具（Auto‑Interp）对特征语义进行标注。

**📊 数据集**

主要数据集：VQAv2（含50k训练样本与完整验证集）以及从中抽取的空间子集（包含空间指示词），并对OCR样式提示进行了二次实验；VSR数据集用于空间推理评估。

**📈 对比分析**

方法对照：与基线文本‑只SAE、随机初始化SAE以及无归因补丁的对照进行比较。结果显示，消融空间特征可使VSR准确率下降9–16个百分点，VQA性能影响微乎其微，证明空间特征的专一性；归因补丁识别出的中层头在空间任务上贡献显著。整体性能并未以传统指标提升为主，而是提供了更深层的解释性洞见。

**⚠️ 局限性**

局限性包括：仅在单一模型（LLaVA‑More + LLaMA‑3.1‑8B）上验证，缺乏跨模型或更大规模数据的普适性；消融实验虽显示因果性，但仍需进一步的因果干预与调优研究；方法依赖于稀疏自编码器的可解释性，可能在不同训练设置下表现不稳定。

---

## 870. Intermediate Results on the Complexity of STRIPS$_{1}^{1}$

**arXiv ID:** 2602.08708 | [PDF](https://arxiv.org/pdf/2602.08708v1)

**作者:** Stefan Edelkamp `[一作]` (Charles University), Bernhard Nebel `[通讯]` (Pompeu Fabra University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

研究了仅有单前置条件和单后效应的STRIPS规划问题（STRIPS_1^1）的最短计划长度与复杂性，并结合SAT求解、文字图与重叠树分析、Petri网与合作MAPF编译等多种方法进行实验与理论探讨。

**💡 创新点**

提出了文字图与重叠树结构用于子计划的分解与可视化，利用SAT编码验证小规模实例的最优计划长度，并在此基础上推断STRIPS_1^1的最短计划不具指数级增长，从而支持“小解假设”。

**🔧 技术方法**

采用SAT求解器kissat进行约束编码；利用图论方法（超立方体、文字图）与动态规划；将规划任务编译为安全保守Petri网；使用冲突搜索（CBS）解决合作MAPF。

**📊 数据集**

构造了P_n、Q_n、R_n等从n=4到n=7的实例集合，并在此基础上生成了规模从5到7的具体规划任务。

**📈 对比分析**

与已知最优长度上界进行对比；对n=5、6、7得到的最优长度分别为30、39、51，均低于2^n；实验耗时从几分钟到两周不等，显示方法在可接受时间内完成。

**⚠️ 局限性**

仅在极小规模实例上获得证据，缺乏对更大规模的实验或理论上界，仍未证明STRIPS_1^1的NP完全性，结果难以推广到所有n。

---

## 871. Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers

**arXiv ID:** 2602.08707 | [PDF](https://arxiv.org/pdf/2602.08707v1)

**作者:** Aditya Gulati `[一作]` (ELLIS Alicante), Nuria Oliver `[通讯]` (ELLIS Alicante)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文通过认知心理学与人机交互视角，分析聊天机器人中信任形成的机制，并提出将聊天机器人重新定义为“销售人员”而非助手的框架，强调设计中的偏差与动机；

**💡 创新点**

创新点在于提出了“双框架”——“心理行为信任”与“规范可信度”，揭示用户对聊天机器人的信任主要源自认知偏差和表面互动，而非系统本身的可信性；

**🔧 技术方法**

主要使用认知心理学理论（如权威偏差、拟人化、光环效应）和人机交互设计原则进行分析，并未采用具体机器学习或算法技术；

**📊 数据集**

本研究无实测数据集，内容基于文献综述与理论分析；

**📈 对比分析**

通过与欧盟可信AI七柱进行概念对比，展示了规范层面与用户实际信任感的差异，并阐述了透明度、可解释性等要素在聊天机器人中的双重效应；

**⚠️ 局限性**

局限性在于缺乏实证验证与量化评估，框架仅为理论性建议，需后续通过用户实验或案例研究进一步检验其有效性与可操作性。

---

## 872. Low-Light Video Enhancement with An Effective Spatial-Temporal Decomposition Paradigm

**arXiv ID:** 2602.08699 | [PDF](https://arxiv.org/pdf/2602.08699v1)

**作者:** Xiaogang Xu `[一作]` (Chinese University of Hong Kong), Bei Yu `[通讯]` (Chinese University of Hong Kong)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `edb9d762-f411-4838-a852-f2d638b018db` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文提出了 VLLVE 与 VLLVE++ 两种低照度视频增强框架，通过视角无关与视角相关的三项分解以及跨帧交互、双向训练与残差项，实现了高质量、时空一致的增强。

**💡 创新点**

创新点包括：① 将低光视频分解为视角无关、视角相关与残差三部分，并用跨帧对应约束视角无关、空间连续约束视角相关；② 设计跨帧交互模块 CFIM 及双网络一致性训练；③ 在 VLLVE++ 中引入自监督的对应关系细化与残差学习，形成双向提升循环。

**🔧 技术方法**

核心技术为基于 Lambertian 模型的分解、跨帧光流/特征对应、Transformer 交互注意力、残差学习与自监督对应细化，网络采用 U‑Net 结构，CFIM 以长短距注意力与通道融合实现。

**📊 数据集**

实验数据集包括 SMID、SDSD、DID、DAVIS、YouTube‑VOS、BVI‑RLV、RAW CRVD 等多种真实与合成低照度视频集，且在 3D 低照度数据与 NeRF 场景上也做了评估。

**📈 对比分析**

与现有 LLVE 与 LLIE 方法（如 RetinexFormer、DP3DF、StableLLVE 等）对比，VLLVE/VLLVE++ 在 PSNR/SSIM、时空一致性、视觉质量上均优于前者，并在主流基准上刷新 SOTA；在人类用户研究中也获得最高偏好率。

**⚠️ 局限性**

局限性包括：对跨帧对应的依赖仍可能在极端运动或遮挡下出现误差；残差分解与对应细化增加训练复杂度；在极端低照度或未知光照变化下的泛化能力尚待进一步验证。

---

## 873. Reasoning aligns language models to human cognition

**arXiv ID:** 2602.08693 | [PDF](https://arxiv.org/pdf/2602.08693v1)

**作者:** Gonçalo Guiomar `[一作]` (ETH AI Center), Valerio Mante `[通讯]` (ETH Zürich)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计了一种主动概率推理任务，分离信息采样与推理过程，并对人类与大语言模型（LLM）进行对比实验

**💡 创新点**

通过构建可解释的四维认知模型（记忆、策略、偏差、遮挡意识）映射人类与LLM行为，揭示链式推理（CoT）如何提升LLM在推理上的人类化表现

**🔧 技术方法**

采用主动采样的近似最优策略（PPO+MAP）作为基准，使用自定义贝叶斯更新与策略映射框架进行建模，结合CoT提示实现LLM推理

**📊 数据集**

使用50名人类参与者完成的图形版任务以及55,000+条LLM生成的文本版任务，覆盖采样轮数2~15

**📈 对比分析**

与近优参照政策比较，LLM在推理质量上与人类相当甚至超过顶尖人类，但在采样质量上仍落后；CoT显著降低推理误差，提升总体成功率至≈61%

**⚠️ 局限性**

CoT对采样策略提升有限，LLM仍无法完全匹配人类在信息获取上的高效性，且模型对遮挡的敏感度差异大，未来需进一步改进采样策略

---

## 874. Technosocial risks of ideal emotion recognition technologies: A defense of the (social) value of emotional expressions

**arXiv ID:** 2602.08706 | [PDF](https://arxiv.org/pdf/2602.08706v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

---

## 875. DyMA-Fuzz: Dynamic Direct Memory Access Abstraction for Re-hosted Monolithic Firmware Fuzzing

**arXiv ID:** 2602.08750 | [PDF](https://arxiv.org/pdf/2602.08750v1)

**作者:** Guy Farrelly `[一作]` (Adelaide University), Damith C. Ranasinghe `[通讯]` (Adelaide University)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

**🎯 论文内容**

在重新托管的嵌入式固件环境中，构建了 DyMA‑Fuzz 框架，实现了对 DMA（Direct Memory Access）接口的动态检测与数据注入，从而在不依赖外部数据手册的情况下对固件进行模糊测试。

**💡 创新点**

创新点主要体现在：①利用运行时内存访问分析和静态 Ghidra 分析相结合，自动推断 DMA 转移描述符的地址、大小与类型；②支持多种 DMA 实现（I_M、I_I、I_R）并兼容不同 MCU 的多通道、内嵌或列表式描述符；③通过动态挂钩与缓冲区大小推断，实现无手工配置、无文档依赖的 DMA 模糊。

**🔧 技术方法**

核心技术包括：运行时内存访问监控、基于地址空间识别指针的启发式算法、Ghidra 静态分析提取缓冲区信息、动态生成统一的 DMA 传输描述符、在 MultiFuzz 之上实现多流模糊与即时注入。

**📊 数据集**

数据集涵盖：32 条带 DMA 的单元测试二进制、48 条无 DMA 的二进制；11 种 MCU 族（6 个制造商）；11 条开源固件二进制；8 条 CVE 级别的 DMA 触发漏洞；另外 6 条 P2IM 无 DMA 例子作为基准。

**📈 对比分析**

与 MultiFuzz 基线、MultiFuzz-DICE、SEmu、DICE、P2IM 等方法对比，DyMA‑Fuzz 在覆盖率上平均提升约 122%，在 96 小时实验中比手工 Oracle 近 4 倍的时间更快发现 13/14 个已知漏洞，并在 CVE 评测中成功触发 8 条 DMA 触发漏洞；运行时性能影响极小（-8%~+7% 取决于被挂钩的 RAM 区域大小）。

**⚠️ 局限性**

局限性包括：①假设所有 DMA 用于外设 I/O，无法覆盖内存到内存或仅监视总线的 DMA；②在 16 位 MCU 上指针空间较大，可能产生误报；③依赖 Ghidra 的符号与类型信息，若二进制被剥离或无符号，缓冲区大小推断可能受限；④对堆/栈 DMA 的支持有限；⑤在某些 MCU 的 DMA 结构（如指向缓冲区末端的指针）下需手动调整；⑥未验证 DMA 配置是否适配目标硬件，可能漏掉基于计数越界的缓冲区溢出。

---

## 876. Welfarist Formulations for Diverse Similarity Search

**arXiv ID:** 2602.08742 | [PDF](https://arxiv.org/pdf/2602.08742v1)

**作者:** Siddharth Barman `[一作]` (Indian Institute of Science), Kirankumar Shiragur `[通讯]` (Microsoft Research India)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出利用福利函数（尤其是Nash社会福利）对最近邻搜索中的多属性多样性进行建模，并给出对应的NaNNS与p‑NNS优化目标。

**💡 创新点**

创新点在于将福利理论引入多属性NNS，实现查询自适应的多样性‑相关性平衡，不再依赖硬性约束，并通过可调参数p实现从全相关性到全多样性的连续过渡。

**🔧 技术方法**

技术手段包括：基于Nash社交福利的目标函数定义，单属性场景下的贪心最优算法和多属性场景下的NP‑hard证明以及1‑1/e近似贪心算法；与ANN子例程（DiskANN等）结合实现低延迟搜索；对p‑均值进行参数化调节。

**📊 数据集**

实验使用的真实数据集包括Amazon产品（CLIP嵌入）、ArXiv OpenAI嵌入、SIFT 1M、Deep1B，以及基于聚类和随机分布的合成属性版本。

**📈 对比分析**

与传统ANN和硬约束多样性方法对比，评估近似比、召回、熵等指标；NaNNS在保持≈0.9+相关性的同时显著提升熵，p‑NNS可通过调节p获得最佳平衡；算法在单属性场景下实现O(kc+∑_ℓT(D_ℓ))时间，满足实时查询需求。

**⚠️ 局限性**

局限性包括：多属性情形仍需预取候选集，未实现完全子线性；极端p值时收敛速度慢；算法未涵盖无显式属性的场景，未来需探索直接在ANN流程中优化福利目标。

---

## 877. Map of Encoders -- Mapping Sentence Encoders using Quantum Relative Entropy

**arXiv ID:** 2602.08740 | [PDF](https://arxiv.org/pdf/2602.08740v1)

**作者:** Gaifan Zhang `[一作]` (University of Liverpool), Danushka Bollegala `[通讯]` (University of Liverpool)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一个基于量子相对熵（QRE）的句子编码器映射，能在二维平面上可视化1101个预训练句子编码器的相似性。

**💡 创新点**

创新点在于将句子编码器的PIP矩阵转换为密度矩阵，并利用QRE与单位基编码器对齐生成高维特征向量，再通过t‑SNE得到全局结构。

**🔧 技术方法**

使用了PIP矩阵、密度矩阵、量子相对熵、SVD、t‑SNE、PCA、ElasticNet等技术。

**📊 数据集**

使用了10,000句高质量英语句子集合（agentlans/high-quality-english-sentences）以及Hugging Face Hub中下载量最高的2000个句子编码器。

**📈 对比分析**

通过对比单位基编码器的QRE特征向量来衡量相似性，邻近度与实际Fine‑tuned关系高度一致，且对112个MTEB任务的Spearman/Pearson相关系数均超过0.8，表明映射能预测下游性能。

**⚠️ 局限性**

局限在于仅使用英语句子集合、对多语言编码器的评估有限、样本规模受计算资源限制、以及偏重热门模型导致低资源语言缺失。

---

## 878. Friedkin-Johnsen Social Influence Dynamics on Networks: A Boundary-Value Formulation and Influenceability Measures

**arXiv ID:** 2602.08704 | [PDF](https://arxiv.org/pdf/2602.08704v1)

**作者:** Moses Boudourides `[一作]` `[通讯]` (Northwestern University), Moses Boudourides (Northwestern University)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文将Friedkin–Johnsen社交影响模型转化为离散初值-边界值问题，推导其收敛、稳态、敏感性等解析结果，并提出基于稳态响应的全节点扫描矩阵与广播图，随后定义了一系列广播中心性与中心化量并在Zachary Karate Club网络上通过蒙特卡洛实验验证其有效性。

**💡 创新点**

创新点在于：①以PDE风格的离散IBVP框架对FJ模型进行严谨解析；②引入Green算子、谱分解及Neumann级数得到闭式稳态与收敛率；③构造全节点扫描矩阵产生广播图，进而定义广播度、接近、介数、特征向量与PageRank等新的影响力度量；④通过随机敏感性采样展示这些度量对异质易感性的稳健性。

**🔧 技术方法**

主要技术包括：矩阵分析与解析解（Green函数、谱分解、Neumann级数）；敏感性与稳定性导数推导；零膨胀Beta模型的随机易感性采样；蒙特卡洛实验；统计评估（Pearson、Spearman、Top‑5 重叠）。

**📊 数据集**

实验数据集为Zachary Karate Club图（34个节点，34条边），采用其无向版本的随机行走矩阵W=D⁻¹A作为影响矩阵。

**📈 对比分析**

通过与传统中心性（度、接近、介数、特征向量、PageRank）在同一图上进行对比，使用Pearson相关、Spearman相关和Top‑5重叠度量。实验结果显示广播中心性与传统度量高度相关（相关系数>0.9），顶级排名完全重合或重叠率高（≥0.8），说明新度量在保持结构特征的同时加入了易感性信息。

**⚠️ 局限性**

局限性在于：①仅对无向或已知随机行走矩阵的静态网络做了完整解析；②模型为线性FJ，未覆盖非线性或时间变异网络；③在有向弱连通或多层网络的推广尚待研究；④蒙特卡洛实验基于随机易感性分布，缺乏对真实社交数据的实证验证。

---

## 879. SoK: The Pitfalls of Deep Reinforcement Learning for Cybersecurity

**arXiv ID:** 2602.08690 | [PDF](https://arxiv.org/pdf/2602.08690v1)

**作者:** Shae McFadden `[一作]` (King's College London), Fabio Pierazzi `[通讯]` (University College London)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3855fcda-48ef-4070-a15e-803cd5c84d83` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文系统评估并归纳了 66 篇 2018-2025 年关于深度强化学习（DRL）在网络安全应用中的 11 个常见方法学缺陷（pitfalls），量化其出现频率，并通过三类案例实验（自适应网络防御、对抗性恶意软件生成、Web 安全测试）验证缺陷对性能的实质性影响。

**💡 创新点**

创新点：①首次构建 DRL 在网络安全领域的缺陷分类与量化框架；②结合文献综述与实验案例，直观展示缺陷导致的性能偏差；③提出针对每个缺陷的可操作性改进建议，为后续研究提供标准化参考。

**🔧 技术方法**

技术手段主要包括：系统性文献检索与双评审、缺陷标签化与统计分析、深度强化学习算法（如 PPO、A2C 等）在仿真环境中的训练与评估，以及对比实验与置信区间、收敛曲线等统计量。

**📊 数据集**

使用的数据集与环境：MiniCAGE（网络防御仿真）、AutoRobust（恶意软件动态分析报告）、Link（XSS 载荷生成）、WAVSEP（脆弱 Web 应用）、Smb（SQL 注入漏洞）等。

**📈 对比分析**

比较方法：在每个案例中对比不同缺陷处理前后的性能（如漏洞发现率、奖励收益、置信区间宽度）和与基线（随机动作、无改进环境）对照；实验结果表明，修正缺陷可显著提升性能、降低方差、揭示收敛性不足；缺陷未修正时性能往往被夸大或不稳定。

**⚠️ 局限性**

局限性：①样本量仅覆盖 66 篇代表性论文，未覆盖全部文献；②对缺陷的判定在部分模糊情况下较为主观；③实验案例仅选取三种任务，缺少更广泛的安全场景；④缺陷的解决方案多为经验性建议，缺乏统一的量化标准。

---

## 880. MVAnimate: Enhancing Character Animation with Multi-View Optimization

**arXiv ID:** 2602.08753 | [PDF](https://arxiv.org/pdf/2602.08753v1)

**作者:** Tianyu Sun `[一作]` (Nanyang Technological University), Guosheng Lin `[通讯]` (Nanyang Technological University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `5b4c1114-4a70-478e-9921-2514ee03850d` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了 MVAnimate 框架，通过多视角优化融合 2D 与 3D 姿态信息，生成高质量的人物动画视频，并能够输出多视角视频。

**💡 创新点**

创新点包括：① 结合 2D 关键点与 3D SMPL‑X 等姿态表征，实现结构与外观的双重优势；② 引入自适应视角加权的多视角注意力机制，动态衡量各视角可靠性；③ 采用多视角优化模块，用三类损失（时序、视角姿态、语义）迭代提升 2D 与多视角输出；④ 训练阶段将姿态与外观解耦，显著降低纹理污染；⑤ 结合预训练的 SV4D 2.0 与 Stable Diffusion v2 进行背景修复。

**🔧 技术方法**

核心技术包括：Stable Video Diffusion 作为骨干网络，VAE 编码器 + ReferenceNet，DWPose 姿态提取，SV4D 2.0 多视角合成，AdaLIN 标准化，跨视角与时序注意力对齐，LoRA 微调，背景 Inpainting，虚拟试衣数据增强。

**📊 数据集**

主要使用 TikTok 舞蹈数据集和 TED‑talks 语音对话数据集进行训练与评估，训练阶段通过虚拟试衣扩增数据；测试时采用原始数据集样本。

**📈 对比分析**

与 DreamPose、MimicMotion、DisCo、MagicAnimate、Animate‑X、MagicPose 等 SOTA 方法对比，指标包括 PSNR、SSIM、LPIPS、FID、FID‑VID、FVD。MVAnimate 在 TikTok 上 PSNR 29.96（最高）、SSIM 0.775（最高），在 TED‑talks 上 FVD 129.66、FID 22.01 亦为最优；整体表现明显优于或逼近最先进方法。

**⚠️ 局限性**

局限性：① 依赖大规模预训练模型（SV4D 2.0、Stable Diffusion）和高成本 GPU；② 在极端姿势、严重遮挡或非人类角色时的泛化尚待验证；③ 纹理污染虽大幅降低，但在光照变化极端场景下仍可能出现残留；④ 对多样化服装、肤色的鲁棒性未做充分评估。

---

## 881. Central Dogma Transformer II: An AI Microscope for Understanding Cellular Regulatory Mechanisms

**arXiv ID:** 2602.08751 | [PDF](https://arxiv.org/pdf/2602.08751v1)

**作者:** Nobuyuki Ota `[一作]` `[通讯]` (Independent Researcher), Nobuyuki Ota (Independent Researcher)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出 CDT-II，一种将中央狗ma 对齐的 Transformer 结构，用作“AI 显微镜”，通过注意力机制直接可视化基因组、RNA 和转录调控网络，预测单细胞 CRISPRi 诱导的表达变化。

**💡 创新点**

创新点在于：①将 DNA、RNA 和 DNA‑to‑RNA 的注意力分别对应三条生物学关系，生成可解释的调控网络；②使用原始单细胞表达而非差异或预训练语言模型，仅依赖基因组嵌入和 RNA 表达；③通过基因集质量（跨数据集可重复性）提升模型分辨率，揭示 RNA 处理模块等层级调控。

**🔧 技术方法**

技术：基于 Transformer 的自注意力和跨注意力层；DNA 嵌入由 Enformer 生成，RNA 表达通过 RawExpressionEncoder 编码；Virtual Cell Embedding 通过注意力池化整合；任务头预测 2,361 基因的 log2 变化；使用 MSE 损失、AdamW 优化、Dropout、残差等常规深度学习手段。

**📊 数据集**

数据集：K562 细胞的 STING‑seq v2 CRISPRi 单细胞 RNA‑seq（60,505 细胞，447 个靶点，包括 27 TSS 与 420 SNP），使用两份独立 K562 CRISPRi 实验交叉验证的基因集（2,361 基因+GFI1B）。

**📈 对比分析**

与传统方法对比：在5个 held‑out 基因上，单细胞预测 Pearson r=0.64，伪批平均 r=0.84；相较于实验间 reproducibility（约0.79），表现逼近上限；GFI1B 调控网络恢复 6.6 倍富集（P=3.5×10⁻¹⁷）；两个注意力机制对同一 RNA 处理模块的收敛显著（P=1×10⁻¹⁶），说明能无监督捕获真实调控关系。

**⚠️ 局限性**

局限性：单细胞预测精度受实验噪声限制；仅在单一细胞系和单一实验设计下验证；模型对极端突变（如全基因敲除）表现不佳；注意力权重需外部验证才能作为因果证据；当前基因集排除了一些已知调控因子，且需依赖 Enformer 嵌入，可能限制未来扩展。

---

## 882. PARD: Enhancing Goodput for Inference Pipeline via Proactive Request Dropping

**arXiv ID:** 2602.08747 | [PDF](https://arxiv.org/pdf/2602.08747v1)

**作者:** Zhixin Zhao `[一作]` (Tianjin University), Hao Wang `[通讯]` (Stevens Institute of Technology)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了一种名为PARD的推理管道系统，通过主动预测请求的端到端延迟并提前丢弃不满足SLO的请求，从而提升整体吞吐量（goodput）和资源利用率。

**💡 创新点**

创新点在于：①引入双向主动请求丢弃机制，利用前后模块的实时状态实现更早、更精准的丢弃决策；②设计自适应请求优先级策略，根据剩余延迟预算和工作负载强度动态重排请求；③对DAG式管道和非DNN工作负载（如RAG）也适用。

**🔧 技术方法**

技术手段包括：动态批处理、GPU资源调度、状态同步（gRPC、NTP时钟同步）、双向运行时信息收集、批等待时间分布估计、双端优先队列（DEPQ）实现自适应优先级；系统实现基于Python+PyTorch，代码约15k行。

**📊 数据集**

使用了多条真实工作负载轨迹：Wikipedia、Twitter、Azure Function以及自建的四个多模型推理管道（交通监测、直播视频分析、游戏分析）和一个DAG式管道（人脸+姿态并行分支）。

**📈 对比分析**

在12种工作负载下与Nexus、Clipper++及自定义基线对比，PARD平均提升goodput 16%–176%，显著降低丢弃率（1.6×–16.7×）和无效计算率（1.5×–62×）；对比更强基线和敏感性分析表明其对SLO、窗口大小和量化参数λ鲁棒性良好。

**⚠️ 局限性**

局限性包括：对批等待时间估计需要采样，无法完全覆盖高度动态路径的DAG管道；算法依赖NTP时钟同步，若同步失效会影响延迟估计；对极端峰值负载的容错性仍有限，且在某些负载下自适应优先级切换仍会引入轻微延迟。

---

## 883. On the Expressive Power of GNNs for Boolean Satisfiability

**arXiv ID:** 2602.08745 | [PDF](https://arxiv.org/pdf/2602.08745v1)

**作者:** Saku Peltonen `[一作]` (ETH Zürich), Roger Wattenhofer `[通讯]` (ETH Zürich)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文通过 Weisfeiler‑Leman（WL）理论分析了图神经网络（GNN）在布尔可满足性（SAT）求解中的表达能力，证明即使是完整的 WL 层级也无法区分可满足与不可满足的实例，并研究了正则、随机、平面实例的可区分性；随后在 G4SAT 随机实例和国际 SAT 竞赛工业实例上进行实验验证。

**💡 创新点**

创新点在于：①首次用 WL 层级证明 GNN 无法在一般情况下判断 SAT 的可满足性；②构造了可满足与不可满足但在 n‑WL 下不可区分的公式对；③把该构造与 Tseitin 公式与解析式复杂性联系起来；④指出平面 SAT 可被 4‑WL 完全识别；⑤提出通过 WL 等价约束检查 GNN 预测可满足赋值所需表达力的实验方法。

**🔧 技术方法**

主要技术包括： Weisfeiler‑Leman 与 k‑WL 层级理论、基于句法的图表示（带否定边的文字-子句图）、图神经网络（MPNN、GIN）以及实验中对 WL 迭代次数与可满足性检查的组合。

**📊 数据集**

使用的数据集为：G4SAT 生成的随机实例（随机 3‑SAT、CA 系列）和 2020‑2025 年国际 SAT 竞赛的工业与手工构造实例。

**📈 对比分析**

实验通过统计 WL 需要的迭代轮次（r_crit 与 r_converged）来评估可表达性；结果显示随机实例大多在 3–4 轮内即可区分所有文字，且 234/448 的实例可被 WL 处理；工业与手工实例往往需要更多轮次甚至无法通过 WL 区分，说明 WL 的表达力不足。

**⚠️ 局限性**

局限性在于：即使在 WL 层级的 GNN 也无法在一般情况下判定可满足性；对工业/手工实例的实验效果差，提示需要更高阶的 GNN 或对称性打破技术来提升表达能力。

---

## 884. Empirical Evaluation of SMOTE in Android Malware Detection with Machine Learning: Challenges and Performance in CICMalDroid 2020

**arXiv ID:** 2602.08744 | [PDF](https://arxiv.org/pdf/2602.08744v1)

**作者:** Diego Ferreira Duarte `[一作]` (Instituto de Informática -- Universidade Federal do Rio Grande do Sul), Andre Augusto Bortoli `[通讯]`

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

在CICMalDroid 2020动态行为数据集上，系统评估了24种机器学习模型（包括XGBoost、Random Forest、SVC、Naïve Bayes）对Android恶意软件检测的性能，并对比了是否使用SMOTE处理类别不平衡的影响。

**💡 创新点**

创新点：①首次系统比较SMOTE在Android恶意软件动态特征中的实际效果；②发现树集成模型对SMOTE不敏感且表现最佳；③指出SMOTE在稀疏高维特征下易导致性能下降，为后续数据平衡方法提供经验。

**🔧 技术方法**

使用技术：机器学习算法（XGBoost、RF、SVC、NB），SMOTE、特征预处理（标准化、Min‑Max、Robust）、特征选择（F‑test、Chi‑square）、降维（PCA、Truncated SVD），Optuna贝叶斯超参优化，嵌套分层交叉验证评估。

**📊 数据集**

数据集：CICMalDroid 2020（11598个Android执行样本，5类恶意 + 1类良性），包含动态行为特征。

**📈 对比分析**

比较方法：嵌套分层交叉验证，优化目标为加权召回率。结果显示：75%的配置在使用SMOTE后性能下降或仅有微增（平均损失6.14%），树集成模型表现最好（XGBoost 95.4%，RF 94.9%），NB表现最差；SMOTE对树模型影响极小。

**⚠️ 局限性**

局限性：SMOTE在稀疏高维动态特征下效果不佳；仅测试单一数据集，未验证其他恶意样本；仅评估传统机器学习模型，未包含深度学习或更复杂的过采样方法；GPU计算导致非确定性，可能对实验一致性产生影响。

---

## 885. Artifact Reduction in Undersampled 3D Cone-Beam CTs using a Hybrid 2D-3D CNN Framework

**arXiv ID:** 2602.08727 | [PDF](https://arxiv.org/pdf/2602.08727v1)

**作者:** Johannes Thalhammer `[一作]` (Technical University of Munich), Florian Schaff `[通讯]` (Technical University of Munich)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

提出一种混合2D‑3D卷积网络，用于去除欠采样CT图像中的伪影，提升体素一致性与图像质量。

**💡 创新点**

创新点在于先用2D U‑Net快速提取切片特征，再将特征堆叠成3D表示供3D解码器学习体素上下文，从而兼顾计算效率与体素一致性。

**🔧 技术方法**

使用的技术包括2D U‑Net编码器、3D解码器（3×3×3卷积）、MSE损失、AdamW优化器，并通过PyTorch/Lightning实现训练。

**📊 数据集**

使用的训练与测试数据集来自RSNA Pulmonary Embolism Detection Challenge 2020的肺动脉CT，采用128视角的稀疏重建作为输入，完整视角重建作为目标。

**📈 对比分析**

与单纯2D U‑Net相比，混合模型在冠状和矢状面伪影去除上表现更好，PSNR/SSIM略低但在垂直方向更平滑；处理时间为2.4秒（2D）vs 20.3秒（混合）。

**⚠️ 局限性**

局限在于3D解码器的训练集规模受特征存储限制，导致性能略逊于2D模型；未来需增大3D训练样本并评估在临床诊断任务中的效果。

---

## 886. QUOKA: Query-Oriented KV Selection For Efficient LLM Prefill

**arXiv ID:** 2602.08722 | [PDF](https://arxiv.org/pdf/2602.08722v1)

**作者:** Dalton Jones `[一作]` (Qualcomm AI Research), Harper Langston `[通讯]` (Qualcomm AI Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种训练‑无关、硬件无关的稀疏注意力机制，专门用于在块化预填充（chunked prefill）阶段加速 Transformer 推理。

**💡 创新点**

创新点在于：① 通过将查询向量与均值查询的余弦距离作为筛选依据，只保留对多数键具有强交互的“低相似度”查询；② 采用余弦相似度作为键‑查询匹配的稳定代理；③ 结合组感知聚合（group‑aware aggregation）兼容现代多组查询（GQA）架构，实现高效、可扩展的 KV 子选择。

**🔧 技术方法**

使用的技术包括：标准线性代数运算（矩阵乘法、归一化）、余弦相似度计算、查询子选择、键‑查询相似度评分、组感知聚合，以及与 FlashAttention 等现有密集注意力内核的无缝集成。

**📊 数据集**

实验所用数据集：Needle‑In‑a‑Haystack、LongBench、RULER、Math500；并在多种 LLM 体系结构上验证（Llama 3.2‑3B、Qwen 3‑4B、SmolLM、GPT‑OSS‑20B 等）。

**📈 对比分析**

与现有稀疏注意力基线（SampleAttention、LessIsMore、SparQ、Loki 等）对比，本文方法在保持接近基线准确率的同时，获得了：3×的首词时间（TTFT）缩短、5×的注意力模块加速（Nvidia A100 GPU）以及高达7×的 CPU 加速；在消费者 GPU 和边缘 CPU 上亦实现显著提升。

**⚠️ 局限性**

局限性：在极高稀疏率下准确率会缓慢下降，依赖查询-键几何分布的假设；未结合 KV 缓存驱逐策略或专用稀疏核优化，且目前主要针对块化预填充，其他推理模式的适用性仍待进一步验证。

---

## 887. Approximate-EFX Allocations with Ordinal and Limited Cardinal Information

**arXiv ID:** 2602.08714 | [PDF](https://arxiv.org/pdf/2602.08714v1)

**作者:** Aris Filos-Ratsikas `[一作]` (University of Edinburgh), Alexandros A. Voudouris `[通讯]` (University of Essex)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355`

**🎯 论文内容**

本文研究在信息受限的情况下实现 α‑EFX 公平分配的可行性和近似度，提出了从完全信息到仅序数偏好再到少量值查询的三种算法模型，并给出了相应的近似比和查询复杂度。

**💡 创新点**

创新点包括：
- 证明仅使用序数偏好就无法获得超过 1/(m‑n) 的 EFX 近似，构成最优下界；
- 设计了 “虚拟价值” 方法，利用有限值查询构造代理的近似价值函数，从而在 O(n+log²m) 次查询内实现 ϕ‑1/2(1+ε)‑EFX；
- 给出下界证明，证明任何 k‑查询算法若 k = O(log m / log log m) 则无法达到常数 EFX 近似；
- 针对常数 n 与双值实例提出改进算法，分别实现 O(log n) 次查询下的 1/2‑EFX（以及 1/n‑EFX），并证明这些是最优的。

**🔧 技术方法**

技术方法包括：
- 虚拟价值函数的构造与二分搜索分桶；
- 对于常数 n 的算法采用基于阈值的分段查询与回合制分配；
- 对双值实例利用 Match&Freeze 与 Round‑Robin 组合，先通过二分搜索确定高低值阈值；
- 证明中大量使用信息不完全模型下的构造性对抗实例与归纳论证。

**📊 数据集**

本文为理论工作，未使用任何实际数据集；所有结果均为信息理论和算法复杂度的证明。

**📈 对比分析**

与完全信息下已知的 ϕ‑1‑EFX 算法相比，本文提供的 O(n+log²m) 查询实现 ϕ‑1/2(1+ε)‑EFX，接近最优；在常数 n 和双值情况下，O(log n) 次查询即可得到 1/2‑EFX，显著低于完整信息所需的 O(log m) 查询；下界证明显示常数 EFX 近似至少需要 Ω(log m / log log m) 次查询。

**⚠️ 局限性**

局限性：
- 仍存在查询复杂度的上界与下界之间的 gap（O(n+log²m) 与 Ω(log m / log log m)）；
- 仅考虑加性效用函数，未讨论互补/替代品等更一般的价值模型；
- 对常数 n 的算法需要事先知道 n，且在 n 非常大时效果不佳；
- 结果主要针对 α‑EFX，未直接推广到其他公平/效率结合目标。

---

## 888. TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions

**arXiv ID:** 2602.08711 | [PDF](https://arxiv.org/pdf/2602.08711v1)

**作者:** Linli Yao `[一作]` (Peking University), Xu Sun `[通讯]` (Peking University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出Omni Dense Captioning任务，生成带时间戳、六维结构化的音视频脚本。

**💡 创新点**

创新在于同时实现连续时间分割、细粒度多维描述，并构建高质量人类标注基准与统一评测指标。

**🔧 技术方法**

使用多模态大语言模型Qwen2.5-Omni结合音视频交叉编码、M-RoPE定位；训练流程为SFT+GRPO，奖励包括格式、长度、时间戳和时空一致性。

**📊 数据集**

训练数据为42K合成音视频对，评测基准为1,122人类注释的Omni脚本数据集，并对Charades-STA、Daily-Omni、WorldSense等下游任务做评估。

**📈 对比分析**

与Gemini-2.5-Pro、LongVALE等模型对比，-7B-GRPO在脚本质量上达到35.0分，优于所有开源基线；在视频QA和时序定位任务上亦跑出SOTA。

**⚠️ 局限性**

局限在于对训练数据的人工/合成质量依赖、奖励设计需要调参，且仍无法完全消除模型对多样化音视频语义的误解与幻觉。

---

## 889. FactSim: Fact-Checking for Opinion Summarization

**arXiv ID:** 2602.08709 | [PDF](https://arxiv.org/pdf/2602.08709v1)

**作者:** Leandro Anghinoni `[一作]` (MercadoLibre), Jorge Sanchez `[通讯]` (MercadoLibre)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种名为FactSim的度量，用于自动评估意见摘要的事实一致性与覆盖率。

**💡 创新点**

创新点在于将摘要和原始评论都抽取成一维事实元组，然后通过余弦相似度计算并取调和平均，既可解释又不依赖人工参考摘要。

**🔧 技术方法**

使用GPT‑4进行事实元组抽取，利用预训练句子编码器得到向量，再通过cosine相似度实现评分；整体流程完全自动化。

**📊 数据集**

主要评估数据来自OpinSummEval（基于Yelp评论的100个样本）以及手工构造的toy示例。

**📈 对比分析**

与ROUGE、BERTScore、BARTScore等传统指标对比，FactSim在aspect relevance、self‑coherence、sentiment consistency四维度上与人工评估的Kendall τ相关性最高，排名常年前六，性能优异。

**⚠️ 局限性**

局限在于高度依赖LLM抽取的准确性；缺乏带事实计数的标注数据；对非结构化或极短评论的处理仍不理想；多语言和大规模部署尚需进一步验证。

---

## 890. OneVision-Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence

**arXiv ID:** 2602.08683 | [PDF](https://arxiv.org/pdf/2602.08683v1)

**作者:** Feilong Tang `[一作]` (Glint Lab), Jiankang Deng `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `fede83ac-7505-405f-ab37-e7284695c47f` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种基于视频编解码器信息的稀疏 Patch 选择与编码框架 OneVision‑Encoder，融合 3D‑RoPE 位置编码和自监督集群判别目标，实现统一的图像与视频表征学习；

**💡 创新点**

创新点在于将视频压缩中的 I/P 帧结构与运动、残差能量直接映射到 Patch 层面，形成稀疏但高效的时空 Token；

**🔧 技术方法**

采用 HEVC‑style 码流提取运动矢量与残差、3D Rotary Position Embedding、Vision Transformer、Cluster Discrimination 以及多模式输入（Dense‑Codec、Chunk‑wise、单图）等技术；

**📊 数据集**

使用 LAION‑400M、COYO‑700M、HowTo100M、Panda‑70M、Kinetics‑710、SSV2、OCR 文本数据等，训练约 17B 语义标签；

**📈 对比分析**

在 LMM 评测和 attentive‑probe 任务中，与 SigLIP2、Qwen3‑ViT 等基线相比，OneVision‑Encoder 在 16 组多模态基准上提升 10‑20% 以上，视频分类 Top‑1 亦比对手高 8‑12%；

**⚠️ 局限性**

局限性包括对 HEVC 码流的依赖、对运动与残差信息的敏感性、以及在极端运动或无运动场景下可能欠缺足够的全局语义覆盖。

---

## 891. Redundancy-Free View Alignment for Multimodal Human Activity Recognition with Arbitrarily Missing Views

**arXiv ID:** 2602.08755 | [PDF](https://arxiv.org/pdf/2602.08755v1)

**作者:** Duc-Anh Nguyen `[一作]` (University College Dublin), Nhien-An Le-Khac `[通讯]` (University College Dublin)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `9ce7179e-700c-4310-ac2b-91df50ded46e` `afceb026-1760-41ae-8d86-010831a37d97` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了 RALIS 模型，能够在训练和推理阶段灵活处理任意缺失视图的多模态多视角人体活动识别。

**💡 创新点**

创新点在于采用冗余‑free 的视图对齐：使用调整中心对比损失与注意力加权融合，避免重建缺失视图；并结合稀疏 Mixture‑of‑Experts 与负载均衡机制提升对未知视图组合的鲁棒性。

**🔧 技术方法**

主要技术包括多视角对比学习（center contrastive loss）、注意力加权融合、向量幅值归一化、稀疏 MoE 与专用负载均衡损失，以及无监督对比学习训练。

**📊 数据集**

使用四个多视角 HAR 数据集：CMDFall、DailySport、RealDisp 与 UP‑Fall，涵盖加速度与姿态等多模态。

**📈 对比分析**

与 CMC、COCOA、Flex‑MoE、Fuse‑MoE、ShaSpec 等基线在完整、缺失及随机缺失视图场景下进行对比，RALIS 在大多数实验中取得最高 F1 分数，尤其在视图缺失时表现更为稳健。

**⚠️ 局限性**

局限性包括：对视图间信息独立或互相依赖度低时对比学习效果受限；仅在融合层进行加权，未深入建模跨视角交互；在非 HAR 领域的适用性和可扩展性仍需进一步验证。

---

## 892. Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing

**arXiv ID:** 2602.08741 | [PDF](https://arxiv.org/pdf/2602.08741v1)

**作者:** Jona te Lintelo `[一作]` (Radboud University), Stjepan Picek `[通讯]` (University of Zagreb)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `afceb026-1760-41ae-8d86-010831a37d97` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 Large Language Lobotomy，一种训练‑free、架构无关的攻击框架，利用 Mixture‑of‑Experts LLM 的专家路由动态识别并在推理时逐步屏蔽安全专家，从而绕过拒绝机制。

**💡 创新点**

创新点包括：①使用 LSTM 对路由序列进行顺序建模并通过梯度归因精确定位少量安全专家；②设计自适应专家屏蔽策略，最小化对通用语言能力的影响；③揭示 MoE 体系结构中安全能力高度集中，凸显效率与安全的根本冲突。

**🔧 技术方法**

技术手段包括：LSTM 顺序建模 + 梯度归因法定位安全专家；专家路由追踪与分析；自适应屏蔽（将专家 logits 设为 -∞）；基于 twin 数据集的对比分析；使用 Llama‑Guard、ARC、CoLA 等评估指标。

**📊 数据集**

使用了 Twin 数据集（由 390 条有害 prompt 与 Gemini 3 Pro 生成的 390 条安全对应构成 780 条），以及 HarmfulQA、StrongREJECT、CatHarmfulQA 等标准对抗性数据集。

**📈 对比分析**

通过与 GateBreaker 的对比实验，平均攻击成功率（ASR）从 64.3% 提升至 70.4%（最高 86.3%），且仅需屏蔽低于 20% 的本地专家；相比随机屏蔽和全局专家屏蔽表现更差；在保持通用语言能力的前提下，攻击效果显著。

**⚠️ 局限性**

局限性包括：仅在白盒环境实现，无法直接迁移到黑盒；对全局专家定位不够细粒度，导致屏蔽效果不如本地专家；不同模型对专家屏蔽的鲁棒性差异大；缺乏对大规模模型计算成本和资源消耗的评估。

---

## 893. From Correspondence to Actions: Human-Like Multi-Image Spatial Reasoning in Multi-modal Large Language Models

**arXiv ID:** 2602.08735 | [PDF](https://arxiv.org/pdf/2602.08735v1)

**作者:** Masanari Oi `[一作]` (Institute of Science Tokyo), Naoaki Okazaki `[通讯]` (National Institute of Advanced Industrial Science and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

针对多图空间推理问题，提出了 HATCH 训练框架，显式监督跨视角对应与视角变换。

**💡 创新点**

创新点在于结合两种人类空间认知机制：①几何监督的 Patch 对齐目标，②通过显式视角变换动作的中间推理步骤，并用 GRPO 强化学习进行优化。

**🔧 技术方法**

核心技术包括：Patch‑Level 语义对齐目标（几何重投影+交叉熵对齐），Action‑then‑Answer 生成格式，GRPO 强化学习与可验证奖励（动作准确率、答案准确率、格式符合度），以及多阶段训练策略。

**📊 数据集**

使用的主要数据集是 SPAR‑Bench‑MV、MindCube‑Tiny、MMSI‑Bench（多图推理）以及 SPAR‑Bench‑SI、CV‑Bench（单图推理）。训练数据来自 SPAR‑7M 的多图样本。

**📈 对比分析**

与同规模基线（Qwen2.5‑VL‑3B）相比，HATCH 在 SPAR‑Bench‑MV 上提升 53.6%（+17.8pp），在 MindCube‑Tiny 上提升 50.2%（+14.9pp），在 MMSI‑Bench 上提升 27.0%（+1.4pp）。在三大基准上均超过同规模或更大开源模型，并与部分闭源模型竞争。

**⚠️ 局限性**

局限性包括：对 MMSI‑Bench 的属性与运动子任务提升有限；仅在预训练阶段使用几何信息，推理时仍需手工制定动作词表；跨域通用性与更复杂动态场景的适应性待进一步验证。

---

## 894. Algorithmic Governance in the United States: A Multi-Level Case Analysis of AI Deployment Across Federal, State, and Municipal Authorities

**arXiv ID:** 2602.08728 | [PDF](https://arxiv.org/pdf/2602.08728v1)

**作者:** Maxim Dedyaev `[一作]` `[通讯]` (National Research University Higher School of Economics), Maxim Dedyaev (National Research University Higher School of Economics)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `3855fcda-48ef-4070-a15e-803cd5c84d83` `e0540dec-d77f-42db-94ae-d039248f6393` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了美国联邦、州、地方三层政府中人工智能（AI）的制度化使用方式，并通过对30个案例的比较性定性分析揭示了不同层级的AI治理模式；

**💡 创新点**

创新点在于将AI治理划分为“控制导向”和“支持导向”两大模式，并以制度层级为维度系统化比较，指出相同技术在不同政府层级下实现不同功能与风险；

**🔧 技术方法**

主要技术手段包括机器学习风险评分、异常检测、计算机视觉与生成式模型等，研究本身并未开发新算法，而是聚焦于这些技术在政府流程中的部署；

**📊 数据集**

使用公开的AI使用案例清单（联邦与州级政府公开数据）、政策法规文本、政府部门发布的实施报告以及相关学术与行业研究资料；

**📈 对比分析**

采用比较性定性案例分析方法，对案例按功能取向、制度嵌入程度和风险聚焦进行编码与跨层级对比。研究未给出数值性能指标，而是通过模式识别展示不同层级的治理结构差异；

**⚠️ 局限性**

局限性包括：研究仅覆盖美国联邦制，难以推广至一元制或欧盟监管模式；案例选择可能存在偏倚，且缺乏定量度量与长周期效应评估；对技术细节与数据质量的深入分析有限。

---

## 895. Rotated Lights for Consistent and Efficient 2D Gaussians Inverse Rendering

**arXiv ID:** 2602.08724 | [PDF](https://arxiv.org/pdf/2602.08724v1)

**作者:** Geng Lin `[一作]` (University of Maryland), Matthias Zwicker `[通讯]` (University of Maryland)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `25d64835-ec5b-425b-899d-a6e1e6fecabd` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了 RotLight 拍摄方案和改进的逆渲染管线，利用 2D 高斯拆分、代理网格和残差约束实现对几何、材质与光照的更准确分解。

**💡 创新点**

创新点在于通过旋转对象实现多角度光照观测以消除光照与材质颜色的模糊；使用代理网格高效求交代替 2D 高斯光追；在神经辐射缓存上加入残差约束提升全局照明处理。

**🔧 技术方法**

核心技术包括 2D 高斯喷射（2D Gaussian Splatting）、基于 MLP 的神经辐射缓存、残差损失约束、Optix 级别的网格光追以及传统 Disney BRDF 的差分渲染。

**📊 数据集**

在合成数据集 SynRotLight（四个物体场景、800×800 视角）和真实视频（箱子、桌面三角度旋转）上进行实验；同时使用公开的 NeRF、3D Gaussian 等基线进行对比。

**📈 对比分析**

与 IRGS 等前沿方法在相同第一阶段 2DGS 模型下对比，采用相同迭代次数；结果表明在材质颜色（albedo）估计上取得更低的烘焙阴影误差，粗糙度和环境光估计保持一致，整体性能优于或相当于现有最佳方法。

**⚠️ 局限性**

局限性主要包括：依赖初始 2DGS 生成网格的精度，网格不完善会导致阴影与材质分离不完全；在阴影区的细节易被模糊，且当前材质编码仅使用高斯，低密度区域难以充分恢复细节。

---

## 896. Data Reconstruction: Identifiability and Optimization with Sample Splitting

**arXiv ID:** 2602.08723 | [PDF](https://arxiv.org/pdf/2602.08723v1)

**作者:** Yujie Shen `[一作]` (Tsinghua University), Qi Lei `[通讯]` (New York University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究了从训练好的两层多项式激活网络恢复训练数据的可辨识性与优化方法，并提出样本拆分算法提升重构性能。

**💡 创新点**

证明对阶数≥3的多项式激活两层网络在宽度适中时，KKT系统唯一确定训练样本；提出通用的样本拆分优化策略，利用负曲率方向逃离鞍点并自适应增减样本。

**🔧 技术方法**

KKT条件与隐式偏置理论、张量分解与插值、负曲率分析的样本拆分、梯度下降与二阶泰勒展开，实验中使用SSIM、L2等指标。

**📊 数据集**

MNIST和CIFAR‑10的子集。

**📈 对比分析**

将样本拆分与原有KKT/NTK重构方法对比，发现拆分后在SSIM（CIFAR‑10）和L2（MNIST）上均有提升，尤其高质量样本显著改善。

**⚠️ 局限性**

仅针对理想化可辨识性（完美KKT）和多项式激活≥3、宽度满足条件的情形，未考虑噪声与逼近误差；低阶或非均匀激活、欠宽网络的可辨识性不明确。

---

## 897. PERSPECTRA: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments

**arXiv ID:** 2602.08716 | [PDF](https://arxiv.org/pdf/2602.08716v1)

**作者:** Shangrui Nie `[一作]` (Bonn-Aachen International Center for Information Technology), Charles Welch `[通讯]` (McMaster University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个兼具Kialo结构化辩论与Reddit语言多样性的多视角基准数据集（PESPECTRA），并基于此设计了三个评测子任务：观点计数、观点匹配与极性判断。

**💡 创新点**

创新点在于：①通过检索‑扩展管道将Kialo简洁观点与Reddit自然评论相结合，实现高效、可扩展的多视角文本生成；②首次将多样化、结构化的观点集成到统一的基准中；③针对多视角推理提出了可量化的评价任务与指标。

**🔧 技术方法**

技术手段包括：①检索时使用基于Qwen3-Embedding-8B的语义相似度匹配；②扩展阶段采用ChatGPT‑4o的对话式提示模板，保持观点一致性并注入Reddit式表达；③评测使用精确匹配、MAE、NIE、立场准确率等多指标。

**📊 数据集**

数据集来源为Kialo（100个主题、762条观点）与Reddit（约1.5–1.8K条评论/主题），最终生成3,810条多样化扩展观点，涵盖373条赞成与389条反对。

**📈 对比分析**

在三项任务上，与多种开源与专有LLM进行对比：在观点计数任务中Qwen3‑32B与GPT‑4o表现最佳；在观点匹配任务中Distill‑Qwen‑32B等模型超越GPT‑4系列；在极性判断任务中GPT‑4o与GPT‑4o‑mini领先。整体来看，模型普遍在多视角推理上存在显著误差，尤其是观点过度分裂与让步结构导致极性判断错误。

**⚠️ 局限性**

局限性包括：检索到的Reddit评论质量参差不齐，导致部分扩展观点的相关性与真度下降；基准仅涵盖三类任务，未覆盖多视角推理的更广泛场景；人工评测规模有限，未来需更大样本的多维度评估。

---

## 898. LLM-Enhanced Wearables for Comprehensible Health Guidance in LMICs

**arXiv ID:** 2602.08701 | [PDF](https://arxiv.org/pdf/2602.08701v1)

**作者:** Mohammad Shaharyar Ahsan `[一作]` (Lahore University of Management Sciences), Muhammad Hamad Alizai `[通讯]` (Lahore University of Management Sciences)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

开发了一款低成本、无屏幕可穿戴设备与基于WhatsApp的LLM聊天机器人组合，用于在低中等收入国家实现持续健康监测和个性化健康解释。

**💡 创新点**

创新点包括：① 将低成本硬件与WhatsApp聊天接口结合，降低数字鸿沟与学习成本；② 采用LLM直接处理原始噪声传感器波形，实现 100% 覆盖率（连续可解释的生理记录）；③ 设计多级LLM调度与RAG工具链，实现成本与性能的动态平衡。

**🔧 技术方法**

使用的技术：硬件层面为 ATmega328P MCU、MAX30102 PPG、ADXL345 加速度计、NTC 温度传感器、BLE；Android BLE 配套应用；后端采用 LangChain + 多模型 LLM（GPT‑4o‑mini、o3‑mini、o1）+ RAG、可视化、调度工具；LLM 对原始波形进行估计与解释。

**📊 数据集**

数据集：在公开基准数据集（未命名）上进行算法对比；实地部署收集 20 名参与者 96 小时共 1920 participant‑hours 的原始传感器数据和用户交互数据。

**📈 对比分析**

比较方法：将 Guardian Angel 的覆盖率与传统开源算法进行对比；传统算法仅在 70.29% 的窗口产生有效输出，而 Guardian Angel 覆盖率为 100%；在 96 小时实地研究中，用户健康数据理解度和对生命体征的关注度均出现显著提升（统计显著）。

**⚠️ 局限性**

局限性：① 仅为健康辅导工具，不能替代临床诊断；② 依赖第三方 LLM 服务，存在成本与可用性风险；③ 低成本传感器仍可能导致测量误差，影响精准度；④ 现场评估样本量有限，缺乏长期追踪与多地区验证。

---

## 899. Prototype-Based Disentanglement for Controllable Dysarthric Speech Synthesis

**arXiv ID:** 2602.08696 | [PDF](https://arxiv.org/pdf/2602.08696v1)

**作者:** Haoshen Wang `[一作]` (Fujian University of Traditional Chinese Medicine), Wai Ting Siok `[通讯]` (Hong Kong Polytechnic University)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出ProtoDisent-TTS框架，实现在统一潜在空间中可控的健康与痉挛发音双向转换，并用于ASR数据增强与痉挛语音重建。

**💡 创新点**

创新点在于引入病理原型码本与双分类器+梯度反转机制，实现说话人音色与病理发音的解耦，提供可解释的病理控制向量，解决传统方法中身份与病理特征混合的问题。

**🔧 技术方法**

采用预训练Index‑TTS模型，加入LoRA适配器、原型码本、双分类器与梯度反转层，并结合声纹转换的对抗训练，以实现解耦与控制。

**📊 数据集**

在TORGO失语语料库（8名痉挛说话人+7名健康说话人）上训练评估，并利用Whisper ASR模型进行离线性能测试。

**📈 对比分析**

通过与预训练Whisper、真实痉挛数据微调以及全合成数据微调对比，并逐步增大合成比例，实验显示合成数据可逼近真实数据的WER提升，最佳配置在严重到轻度各组均优于前沿方法。

**⚠️ 局限性**

局限在于原型数目有限，原型代表性不足，对极端病变语音或多种发音病症的泛化仍需进一步验证。

---

## 900. Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement

**arXiv ID:** 2602.08688 | [PDF](https://arxiv.org/pdf/2602.08688v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86`

---

## 901. Trapped by simplicity: When Transformers fail to learn from noisy features

**arXiv ID:** 2602.08695 | [PDF](https://arxiv.org/pdf/2602.08695v1)

**作者:** Evan Peters `[一作]` (University of Waterloo), Achim Kempf `[通讯]` (Perimeter Institute for Theoretical Physics)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究了 transformer 在特征噪声环境下对布尔函数的噪声鲁棒学习能力，并对比 LSTM 的表现。

**💡 创新点**

创新点在于揭示 transformer 在稀疏奇数长度奇偶函数上能成功鲁棒学习，而在随机 k‑junta 或偶数 n 的多数/奇偶函数上普遍失败，并将失败原因归因于其简洁性偏置；同时提出通过在损失中加入敏感度惩罚可以部分缓解该问题。

**🔧 技术方法**

主要技术包括：使用自注意力 Transformer（SAN）和 LSTM；合成布尔函数（稀疏奇偶、奇偶多数、随机 k‑junta）作为任务；在输入上施加独立同分布位翻转噪声；对训练过程进行 300 次随机初始化与超参数搜索；在损失中加入敏感度惩罚项。

**📊 数据集**

数据集为合成布尔函数样本：例如 N=2000 的 (Z, Y) 对，随机生成 k‑junta 等；所有数据均从均匀随机 bitstring 采样并通过位翻转噪声得到噪声特征。

**📈 对比分析**

通过 300 次随机实验对比两模型：Transformer 在稀疏奇偶（如 (20,5)、(40,5)、(50,3)）和奇偶多数（如 (20,5)、(40,5)）上显著优于 LSTM；但在随机 k‑junta、偶数 n 的多数/奇偶函数上 Transformer 失效，甚至与 LSTM 的差距几乎消失；加入敏感度惩罚后 Transformer 能略微逃离“学习陷阱”，但效果依赖惩罚系数。

**⚠️ 局限性**

局限性包括：仅考虑独立同分布的位翻转噪声，未检验标签噪声；使用合成数据，可能无法直接推广到自然语言或更复杂噪声模型；对高熵输入下的实际任务表现仍不确定；在随机 k‑junta 上 Transformer 的失败可能不适用于所有实际问题。

---

## 902. PBLean: Pseudo-Boolean Proof Certificates for Lean 4

**arXiv ID:** 2602.08692 | [PDF](https://arxiv.org/pdf/2602.08692v1)

**作者:** Stefan Szeider `[一作]` `[通讯]` (TU Wien), Stefan Szeider (TU Wien)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c`

**🎯 论文内容**

在 Lean 4 中实现了一套可验证的伪布尔（Pseudo‑Boolean）证明证书检查器，支持直接导入 PB 求解器输出的内核格式证明，并通过反射（reflection）实现高效检查。

**💡 创新点**

创新点在于：①利用反射仅需证明一次完整的 Soundness 定理，即可在运行时对任意 PB 证明做检查；②把检查结果转化为 Lean 定理（theorem），可在更大形式化开发中复用；③提出“可信编码（trusted encoding）”流程，将问题建模、编码证明与 PB 证明合成，消除求解器输出与原问题语义之间的信任缺口。

**🔧 技术方法**

主要技术包括：Lean 4 的元编程（tactic、monad 等）、对 PB 约束的自然数算术定义、13 条证明 Soundness 证明、基于行级分词器的证明字符串解析、hash‑map 约束数据库、递归子证明处理、以及通过 `Lean.run` 将布尔检查器编译成本地代码。

**📊 数据集**

使用的数据集主要为组合数学实例：Paley 图的独立集数、Langford 配对、Schur 数、Van der Waerden 数、Ramsey 数、以及公平着色数等；这些实例的 PB 编码由 Lean 内部完成，证明文件来自现有 PB 求解器（如 `veripb`）转为内核格式。

**📈 对比分析**

与显式构造证明项（Direct）方法相比，反射检查器在内存使用和运行时间上显著优越；例如 Paley(101) 的 63k 行证明在 3.5 分钟内完成，而 Direct 方法因内存溢出无法完成。对多实例的实验显示：在 60 秒超时阈值内，反射方法可验证最多 101 的 Paley 图，而 Direct 方法仅能处理到约 37。性能评估表明检查器的瓶颈在本地执行的布尔代码，而不是 Lean 核心的证明验证。

**⚠️ 局限性**

局限性包括：①仅支持 PB 求解器输出的内核格式（需要额外转换）；②当前实现不依赖 Mathlib，限制了一些高级形式化功能；③对复杂的子证明结构仍有一定的实现复杂度；④缺乏自动化 tactic，需手动调用 `pblean.check` 或类似工具；⑤在极大规模证明（超过几十万行）时仍可能出现性能瓶颈。

---

## 903. Learning To Sample From Diffusion Models Via Inverse Reinforcement Learning

**arXiv ID:** 2602.08689 | [PDF](https://arxiv.org/pdf/2602.08689v1)

**作者:** Constant Bourdrez `[一作]` (École normale supérieure), Olivier Cappé `[通讯]` (École normale supérieure)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `a4b10f5d-130b-4e77-9367-6469ec621899` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

利用逆强化学习在扩散模型采样时自适应调节采样参数（如导向强度、重噪策略和随机性注入），无需重新训练去噪网络。

**💡 创新点**

创新点在于将扩散采样视为有限时域马尔可夫决策过程，直接通过匹配状态占比的f-多样性实现策略学习，避免显式奖励学习并提供可解释的精度‑召回控制。

**🔧 技术方法**

使用技术包括逆强化学习、f-多样性匹配、策略梯度与PPO、基于分类器的密度比估计，以及对多种采样干预（类无导向、重噪、随机性注入）的统一实现。

**📊 数据集**

实验数据集包括CIFAR‑10、FFHQ和ImageNet。

**📈 对比分析**

与固定采样参数（固定导向、重噪等）进行对比，使用FID、Precision、Recall和平均函数评估次数（NFE）评估；实验显示学习策略在多种采样方式上显著提升图像质量和多样性，同时降低计算成本。

**⚠️ 局限性**

局限性包括对初始化敏感、离散动作空间设计影响性能、需要大量采样轨迹进行训练以及未探索连续动作空间的可能改进。

---

## 904. CompilerKV: Risk-Adaptive KV Compression via Offline Experience Compilation

**arXiv ID:** 2602.08686 | [PDF](https://arxiv.org/pdf/2602.08686v1)

**作者:** Ning Yang `[一作]` (Institute of Automation), Haijun Zhang `[通讯]` (University of Science and Technology Beijing)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种预填充阶段的 KV 缓存压缩框架 CompilerKV，利用离线经验编译成头部可靠性表和风险适配阈值表，实现一次性、无在线调优的压缩决策。

**💡 创新点**

创新点包括：① 通过离线上下文多臂赌博机学习每个注意力头的可靠性权重，显式捕捉头部功能异质性；② 将注意力熵与局部困惑度联合建模的风险阈值门控，使压缩阈值根据提示的结构性和语义难度自适应；③ 采用基于离线强化学习的保守 Q 学习来编译决策表，保证在极限压缩下的稳定性。

**🔧 技术方法**

核心技术包括：离线强化学习（上下文多臂赌博机 + Conservative Q‑Learning）、基于全局均值注意力的稳健实用度计算、相对范数归一化、最大池化投票头部可靠性、熵+困惑度风险评估、阈值门控与预算校正。

**📊 数据集**

在 LongBench（共 16 个任务，涵盖单文档问答、多文档问答、摘要、少样本学习、合成与代码任务）上进行评估；并在四种主流 LLM（InternLM‑2.5‑7B、LLaMA‑3‑8B、Qwen2‑7B、Mistral‑7B‑Instruct）上验证。

**📈 对比分析**

与 FullKV、StreamingLLM、H2O、SnapKV、ZigZagKV、PyramidKV、DynamicKV 等 SOTA 方法对比，512 令牌预算下平均得分提升 3.0–5.2 分（最高 5.2 分），恢复 97.7% 的 FullKV 性能；在极低预算（64 令牌）下表现最平滑，极大降低 tail failure 风险。

**⚠️ 局限性**

局限性包括：① 仍依赖离线校准数据，跨模型迁移可能受限；② 只针对预填充阶段，不适用于在线自适应压缩；③ 对极端长序列的完整性保障仍有限，尤其在多头互补性更强的模型上需要进一步验证。

---

## 905. HoGS: Homophily-Oriented Graph Synthesis for Local Differentially Private GNN Training

**arXiv ID:** 2602.08762 | [PDF](https://arxiv.org/pdf/2602.08762v1)

**作者:** Wen Xu `[一作]` (Jinan University), Kaoru Ota `[通讯]` (Muroran Institute of Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `67630363-6be0-4f51-ab05-7198250671a5` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

HoGS提供了一种在本地差分隐私下同时保护图链接和节点特征、生成可用于GNN训练的合成图的方法。

**💡 创新点**

通过双向利用同质性进行图结构与特征的去噪，且仅分配两部分隐私预算，无需额外分配节点度信息。

**🔧 技术方法**

采用本地差分隐私的随机响应和1-bit机制收集数据，基于余弦相似度与贝叶斯推理重构边概率，再用加权特征聚合恢复节点特征。

**📊 数据集**

在Cora、CiteSeer和LastFM三大公开图数据集上进行实验。

**📈 对比分析**

与FP-BLink、FP-LDPGen、Solitude和BLink等基线比较，HoGS在GCN、GraphSAGE、GAT等多种GNN架构下在不同隐私预算下均显著提升准确率，逼近无隐私上限。

**⚠️ 局限性**

在极低隐私预算下仍受噪声影响，且对GAT的关注机制敏感，导致在ε极小情况下性能下降；此外目前仅支持无权重边和二进制特征。

---

## 906. Foundation Inference Models for Ordinary Differential Equations

**arXiv ID:** 2602.08733 | [PDF](https://arxiv.org/pdf/2602.08733v1)

**作者:** Maximilian Mauel `[一作]` (University of Bonn), Ramses J. Sanchez `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `a8e75ba4-7a2d-4153-b003-06c94533add0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出并实现了一种用于从噪声轨迹一次性推断向量场的 Foundation Inference Model (FIM)，并给出预训练和微调的完整训练流程。

**💡 创新点**

创新点包括：① 使用低维低阶多项式向量场作为简单且可解释的预训练先验；② 采用 Transformer‑based 神经算子架构实现局部向量场估计，避免了全局符号表达的强制承诺；③ 通过预训练获得强有力的初始化，显著缩短并稳定微调过程。

**🔧 技术方法**

技术细节包括：预训练先验分布（多项式 + 随机系数 + 稀疏掩码）、子采样与乘性噪声的数据腐蚀、基于注意力的编码器‑解码器神经算子、误差不确定性加权的 MAE 损失、与 Gaussian Process 的理论关联以及后续微调的基于 MSE 的优化。

**📊 数据集**

数据集涵盖：① 600K 个 1–3 维多项式 ODE 合成数据；② ODEBench（61 个自治 ODE 系统，包含三角、指数、分式等非多项式）；③ CMU Motion Capture 数据（3 个受试者、50 维标记坐标，经 PCA 降维至 5 维后再限制为 3 维）；③ 经典振荡器（Van der Pol、FitzHugh–Nagumo）用于低数据实验。

**📈 对比分析**

与 86M 参数的 SymbolicFIM、Neural ODE、GP 等传统方法在多种评估指标下比较。 ① 在 ODEBench 零射击下，FIM 在轨迹重建与泛化任务中表现更好或相当；② 在低数据/稀疏噪声场景下，零射击表现不佳但微调后可超越大多数基线；③ 在 CMU MoCap 低维投影下，零射击已优于多数基线，微调后进一步提升到领先水平。

**⚠️ 局限性**

局限性：① 先验仅包含低阶多项式导致向量场幅度随状态范数增长，易产生发散；② 预训练仅覆盖 1–3 维，难以扩展到更高维或非多项式系统；③ 模型架构中维度是硬编码的，限制了对不同输入维度的适应性。

---

## 907. Closing the Confusion Loop: CLIP-Guided Alignment for Source-Free Domain Adaptation

**arXiv ID:** 2602.08730 | [PDF](https://arxiv.org/pdf/2602.08730v1)

**作者:** Shanshan Wang `[一作]` (Anhui University), Xingyi Zhang `[通讯]` (Anhui University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种源自由域适应框架，利用CLIP引导对目标域的类别混淆进行检测、表示和对齐，从而在不访问源数据的情况下提升跨域分类性能。

**💡 创新点**

创新点包括：① 构造方向性混淆图检测源模型的异向混淆；② 通过多原型CLIP提示生成“像……一样的……”文本，细化伪标签；③ 采用特征空间对齐模块将CLIP语义先验隐式迁移到源模型特征空间，实现对混淆的双向纠正。

**🔧 技术方法**

核心技术为CLIP多原型提示、混淆图分析、伪标签融合、基于SimCLR的对比学习、KL/熵加权损失、特征中心银行以及自适应加权特征融合。

**📊 数据集**

在 VisDA、Office‑Home、DomainNet‑126 以及 Office‑31 四个公开跨域数据集上进行实验，使用 ResNet‑101/50 作为骨干网络。

**📈 对比分析**

与现有 SFDA 方法（SHOT、NRC、AdaCon、CoWA、DIFO‑V、ProDe‑V 等）对比，CGA 在大多数任务中均取得了最高平均准确率，尤其在 VisDA 车辆类混淆（bus/truck）上提升约 3.9%，显著优于先前最优方案。

**⚠️ 局限性**

主要局限包括：需额外加载 CLIP 与大量提示，导致显存与训练时间有一定增长；对超大类别数或极端类别不平衡时的鲁棒性未充分验证；小规模数据集的提升幅度相对有限。

---

## 908. Trellis codes with a good distance profile constructed from expander graphs

**arXiv ID:** 2602.08718 | [PDF](https://arxiv.org/pdf/2602.08718v1)

**作者:** Yubin Zhu `[一作]` (Chinese University of Hong Kong), Zitan Chen `[通讯]` (Chinese University of Hong Kong)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

本文首先证明了图形码（trellis codes）的自由距离和列距离满足Singleton型上界，并指出在列距离方面，图形码可超越传统卷积码的界限；随后构造了一类基于谱图（spectral expander）与区块码的图形码，在常数字母表上实现了与最大距离谱（MDP）卷积码相近的速率‑距离折衷。

**💡 创新点**

创新点主要有：
1) 证明图形码的自由距离满足与卷积码相同的Singleton上界；
2) 发现并举例说明列距离上图形码可超过卷积码的界限；
3) 设计了一种新的构造方法：利用同构的谱图序列和一致的边序，融合卷积码与接近满率的块码，从而在常数字母表上构造出近MDP性能的图形码；
4) 在理论上给出了列距离的下界，并证明在适当取谱图扩展因子与块码距离时，能够使列距离接近卷积码的最优值。

**🔧 技术方法**

主要技术手段包括：
- 轨道编码与卷积码的矩阵/多项式描述；
- Singleton型距离上界推导；
- 通过鸽巢原理与块码 Singleton 上界得到图形码自由距离上界；
- 利用谱图的邻接矩阵第二特征值与图论扩展混合引理获得列距离下界；
- 构造一致边序的同构谱图序列，使得不同时间步的列之间保持相同的映射；
- 结合块码与卷积码生成矩阵得到新的生成矩阵并推导其自由距离、列距离和维数。

**📊 数据集**

本研究属于理论构造与证明，没有使用具体数据集；所有结果均基于代数/图论的理论推导。

**📈 对比分析**

相较于已知的需要指数级字母表的MDP卷积码，本文构造的图形码在常数字母表上实现了相同的速率‑距离折衷（自由距离和列距离均满足与MDP卷积码相当的上界）。在极限情况下，本文得到的自由距离与 Singleton 上界差距仅为 o(1)，即近乎最优。与传统卷积码相比，列距离在前若干时间步可更高；与已有的图形码构造相比，本文实现了更小的字母表尺寸。

**⚠️ 局限性**

局限性：
- 未给出高效的编码/译码算法；
- 构造依赖于谱图与块码参数的匹配，实际实现可能受限于可构造的谱图和块码；
- 论文未解决在有限域大小固定的情况下构造近MDP卷积码的问题；
- 对于更一般的非线性图形码或更宽松的约束，结果尚未扩展。

---

## 909. Zero-shot System for Automatic Body Region Detection for Volumetric CT and MR Images

**arXiv ID:** 2602.08717 | [PDF](https://arxiv.org/pdf/2602.08717v1)

**作者:** Farnaz Khun Jush `[一作]` (Bayer AG), Matthias Lenga `[通讯]` (Bayer AG)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

本文提出并评估了三种完全零训练的体区检测方案，以实现对CT和MR体积图像的无元数据、无监督体区识别；

**💡 创新点**

创新点在于：①将预训练的多器官分割模型与基于规则的推理结合，形成可解释的零训练方法；②将多模态大型语言模型（MLLM）引入医学图像推理，并通过规则提示实现视觉推断；③尝试将分割结果作为显式文本输入给MLLM，探讨混合零训练模型的可行性；

**🔧 技术方法**

技术包括：预训练的TotalSegmentator多器官分割模型、Gemini 2.5等通用MLLM、规则集成推理、三视图图像拼接、规则注入提示、混合文本-视觉输入；

**📊 数据集**

数据集为887份来自TotalSegmentator公开数据集的CT（465份）和MR（422份）扫描，人工标注的体区标签；

**📈 对比分析**

与5折交叉验证训练的状态‑of‑the‑art方法（Golzan等）对比，零训练规则基分割方案在CT与MR上均获得最高或相近的准确率/ F1（如CT腹部F1≈0.976、MR腹部F1≈0.964），MLLM方案在视觉明显区域表现良好但整体不稳定，混合方案表现不佳；

**⚠️ 局限性**

局限：①依赖分割模型性能，关键器官/椎体误分会导致整体错误；②MR颈区整体性能低，说明现有分割类不足；③混合MLLM未能有效整合文本与视觉信息，出现过度预测；④无大规模微调/提示优化，难以提升泛化。

---

## 910. Exploring SAIG Methods for an Objective Evaluation of XAI

**arXiv ID:** 2602.08715 | [PDF](https://arxiv.org/pdf/2602.08715v1)

**作者:** Miquel Miró-Nicolau `[一作]` (University of the Balearic Islands), Anna Arias-Duart `[通讯]` (Barcelona Supercomputing Center)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `90291a0e-9d36-4a08-9a16-89ce846d923f` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

综述并系统性分类了 Synthetic Artificial Intelligence Ground truth (SAIG) 方法，用于客观评估 XAI 解释。

**💡 创新点**

首次将 SAIG 定义为统一的评估框架，并提出七维度（图像特征、GT 定义、GT 取值、可生成性、评估指标等）分类法。

**🔧 技术方法**

结合合成图像生成、人工构造的 GT、以及多种空间对齐、分布、统计与比较指标来实现评估。

**📊 数据集**

主要使用了 16 个公开合成数据集（如 Toy Color、an8Flower、BAM、BlockMNIST、seneca-img、Focus 等）进行实验。

**📈 对比分析**

对比了 32 种 XAI 方法（梯度、LIME、Grad‑CAM、SHAP 等），但不同 SAIG 方法得出的最佳方法不一致，说明评估结果高度依赖数据与指标设定。

**⚠️ 局限性**

局限在于缺乏统一标准、评估方法与数据集高度耦合、易产生分歧，且大多数 SAIG 仍基于固定数据集而非通用框架。

---

## 911. Do Images Clarify? A Study on the Effect of Images on Clarifying Questions in Conversational Search

**arXiv ID:** 2602.08700 | [PDF](https://arxiv.org/pdf/2602.08700v1)

**作者:** Clemencia Siro `[一作]` (University of Amsterdam), Maarten de Rijke `[通讯]` (University of Amsterdam)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `a2602d71-93ab-4bad-974b-672788df8193` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过对比包含图像的多模态澄清问题与仅文本澄清问题，探讨图像在对话式搜索（Conversational Search）中回答澄清问题和查询重构任务的作用，主要通过73名受试者的实验数据进行验证。

**💡 创新点**

创新点在于：①首次系统评估图像在澄清问题中的任务依赖性；②提出图像在不同用户专业水平和任务类型下的调节作用；③结合实验与检索效果分析，揭示图像提升参与度但对检索性能影响复杂。

**🔧 技术方法**

主要技术包括：多模态澄清问题生成（文本+图像）、用户实验设计、线性混合效应模型、独立t检验、Spearman相关、方差分析以及基于BM25的检索效果评估（NDCG@k）。

**📊 数据集**

使用了从ClariQ数据集挑选的30个主题（共90个澄清问题），并通过Google图片搜索为每个主题采集相关图像，构成实验素材。

**📈 对比分析**

对比方法：对照组为仅文本澄清问题，实验组为图像+文本澄清问题。实验结果显示：在回答澄清问题时受试者偏好多模态；在查询重构时偏好相对平衡；图像能略微提升查询重构的检索NDCG@1（从0.091提升至0.204），但在回答澄清问题时文本答案在BM25检索中表现更佳（NDCG@1从0.079提升至0.185）。

**⚠️ 局限性**

局限性包括：①实验主题为预先挑选的ClariQ子集，未涵盖所有真实搜索场景；②检索模型仅为BM25，未考虑图像特征，导致对图像答案的检索效果低估；③受试者来自线上平台，实验场景为受控任务，缺乏自然对话数据；④未研究图像属性（如尺寸、质量、相关性）对效果的细粒度影响。

---

## 912. Challenges in Translating Technical Lectures: Insights from the NPTEL

**arXiv ID:** 2602.08698 | [PDF](https://arxiv.org/pdf/2602.08698v1)

**作者:** Basudha Raje `[一作]` (Indian Institute of Technology Madras), Hema A. Murthy `[通讯]` (Indian Institute of Technology Madras)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在论文中作者构建了一个基于NPTEL讲座的孟加拉语、马拉雅拉姆语、泰卢固语的学术口语并行语料库，并通过人工校正提升了机器翻译质量。

**💡 创新点**

创新点在于将真实的学术口语作为源语，采用人机协同的后编辑流程，并针对印度语言的形态学和语域特征提出了定制化评估指标。

**🔧 技术方法**

主要技术包括基于BhashaVerse/SpringLab的神经机器翻译、后编辑校正流水线、以及BLEU、METEOR、COMET三种评估指标。

**📊 数据集**

使用的数据集是从NPTEL平台收集的英文学术讲座转录文本，转化为孟加拉语、马拉雅拉姆语、泰卢固语的目标文本。

**📈 对比分析**

通过BLEU、METEOR与COMET对比，结果显示BLEU分数偏低但COMET分数接近1.2，表明在语义上保持了较高的相符度。

**⚠️ 局限性**

局限性包括对方言变体缺乏覆盖、口语数据规模有限以及BLEU等表面指标对形态丰富语言的敏感性不足。

---

## 913. Finite-State Controllers for (Hidden-Model) POMDPs using Deep Reinforcement Learning

**arXiv ID:** 2602.08734 | [PDF](https://arxiv.org/pdf/2602.08734v1)

**作者:** David Hudák `[一作]` (Brno University of Technology), Milan Češka `[通讯]` (Brno University of Technology)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文提出一种将深度强化学习（DRL）与有限状态控制器（FSC）提取相结合的框架，能够在大规模POMDP及其不确定模型HM‑POMDP上生成可验证的策略；

**💡 创新点**

创新点包括：①使用PPO + RNN在向量化模拟器上训练可扩展的神经策略；②提出两种FSC提取方法——改进的Alergia自动机学习和自解释Gumbel Softmax网络（SIG），可控制FSC大小并提升提取精度；③在HM‑POMDP上引入基于最坏情况POMDP的迭代鲁棒训练循环；

**🔧 技术方法**

采用技术：深度强化学习（PPO）+循环网络（GRU/LSTM），向量化JAX模拟器，Gumbel‑Softmax实现可微记忆更新，Alergia自动机学习，Storm模型检查器进行FSC验证，Deductive verification获取最坏情况POMDP；

**📊 数据集**

数据集：来自PRISM仓库的原始与扩展POMDP模型（maze、rocks、network、intercept、evade、drone等），以及扩展的HM‑POMDP模型（rover、obstacles、network、avoid、avoid‑large、moving_obstacles等），状态空间从几千到数十万不等；

**📈 对比分析**

与现有方法（SARSOP、其扩展、前沿的HM‑POMDP鲁棒算法）比较，实验显示在大规模模型上DRL+FSC提取的策略获得更高的到达概率/奖励，且提取的FSC体积更小、可验证值与神经策略相近；鲁棒FSC在HM‑POMDP上优于基线；

**⚠️ 局限性**

限制：提取过程中可能产生性能损失，尤其在复杂HM‑POMDP上需要较大记忆；Alergia提取不稳定；在极大模型下DRL训练和梯度计算成本高；鲁棒训练对最坏情况POMDP的选择高度敏感；方法仍需已知模型进行验证，且目前仅适用于不可折扣到达/奖励目标。

---

## 914. Rethinking Graph Generalization through the Lens of Sharpness-Aware Minimization

**arXiv ID:** 2602.08855 | [PDF](https://arxiv.org/pdf/2602.08855v1)

**作者:** Yang Qiu `[一作]` (Huazhong University of Science and Technology), Jun Wang `[通讯]` (iWudao Tech)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `3f18e8e3-0266-457c-8567-9039b6d2394d` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

研究了图神经网络在存在微小分布漂移时出现的预测翻转现象（Minimal Shift Flip），并提出了基于能量驱动的生成增强框架 E2A 来提升图数据的 OOD 泛化能力。

**💡 创新点**

创新点在于：① 将 Sharpness‑Aware Minimization 与局部稳健半径相结合，并证明能量与稳健半径之间存在单调关系；② 利用能量梯度上升在条件 VAE 的潜空间中生成伪 OOD 样本；③ 在不需要环境标签的情况下实现对抗性增强，从而显著提升 OOD 性能。

**🔧 技术方法**

使用技术包括 SAM 理论、局部稳健半径定义、能量函数与其单调性质证明、条件变分自编码器（cVAE）、能量梯度上升、对抗训练与交叉熵联合损失。

**📊 数据集**

实验数据集涵盖 GraphOOD（Motif、CMNIST、HIV、SST2、Twitter）和 DrugOOD（EC50、IC50）共七个图形任务，涉及结构、大小、分子等多种分布偏移。

**📈 对比分析**

与 ERM、IRM、VREx、DIR、GIL、GSAT、CIGA、LECI、iMoLD、EQuAD、LIRS 等 13 种基线对比，E2A 在 12/13 个数据集上均取得最优或相近效果，显著提升 OOD 准确率，且对 ID 性能影响极小。

**⚠️ 局限性**

局限性包括：① 需要额外训练 cVAE 并执行多步梯度上升，导致训练成本相对提升；② 对极端分布漂移或非常不同的 OOD 领域的泛化效果尚未进行深入验证。

---

## 915. Deciding the Satisfiability of Combined Qualitative Constraint Networks

**arXiv ID:** 2602.08848 | [PDF](https://arxiv.org/pdf/2602.08848v1)

**作者:** Quentin Cohen-Solal `[一作]` (Universite Paris-Dauphine), Maroua Bouzid `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

**🎯 论文内容**

提出一种统一的多元代数框架，覆盖松散集成、多尺度推理和时空序列等多种组合形式，并给出其可满足性判断的理论基础和多项式算法；

**💡 创新点**

在保留传统关系代数结构的前提下，扩展了定性形式主义的定义（引入对称性、子分区等），实现了对更广泛组合的支持；并提出两条互补的可满足性可判定定理（基于切片与细化两种技术），可直接推导已知组合的可满足性结果；

**🔧 技术方法**

多元代数、投影与闭包运算、符号闭包（path‑/bipath‑consistency）扩展、可满足性可判定定理的证明、以及基于切片与细化的算法实现；

**📊 数据集**

论文主要为理论与模拟验证，未使用公开数据集；实验结果基于人工构造的约束网络与定量示例验证定理的正确性；

**📈 对比分析**

与现有的松散集成和多尺度推理方法对比，证明在多种已知组合（如大小-拓扑、时间-空间序列）中，本框架下的可满足性决策保持多项式时间；实验中显示该方法与传统路径一致性/双路径一致性算法在效率上相当或略优；

**⚠️ 局限性**

仅在有限类型的投影结构（如树结构）下可保证可满足性，非树结构或过强的相互依赖时仍需回溯搜索；且对形式主义的对称性与子分区假设的满足度要求较高，限制了框架在某些非对称或不完整关系代数中的直接适用性。

---

## 916. Any-to-All MRI Synthesis: A Unified Foundation Model for Nasopharyngeal Carcinoma and Its Downstream Applications

**arXiv ID:** 2602.08822 | [PDF](https://arxiv.org/pdf/2602.08822v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 917. Glow with the Flow: AI-Assisted Creation of Ambient Lightscapes for Music Videos

**arXiv ID:** 2602.08838 | [PDF](https://arxiv.org/pdf/2602.08838v1)

**作者:** Frederic Anthony Robinson `[一作]` (Dolby Laboratories Inc), David Gunawan `[通讯]` (Dolby Laboratories Inc)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出了一种AI协作的光景创作系统，能够自动分析音乐视频的音频与视觉特征，并生成可编辑的基于对象的灯光设计，为音乐视频提供同步的灯光效果。

**💡 创新点**

创新点在于：①将专业灯光设计师的经验提炼为可编码的规则与AI模型；②使用多模态AI对音乐结构、情感与色彩进行抽取，实现音视频与灯光的语义映射；③提供可编辑的灯光对象格式，使人机协作成为可迭代的工作流程。

**🔧 技术方法**

核心技术包括：多模态深度学习模型（音频分段、节奏检测、情感分析、色彩提取）、规则驱动的映射引擎（将特征转化为灯光事件），以及基于对象的灯光渲染框架；评估采用了情感共振、节奏同步和色彩一致性三维Likert量表。

**📊 数据集**

实验数据集为三首音乐视频的15段10秒片段，共15对人手灯光与AI生成灯光；视频与音频均来自公开音乐视频，未列明具体来源。

**📈 对比分析**

比较方法：对32名受试者进行双盲对比评估，使用Wilcoxon符号秩检验并进行Holm–Bonferroni校正。结果显示，AI生成灯光在情感共振、节奏同步与色彩一致性上与人工灯光无显著差异，平均评分约为7.0/10，说明AI第一稿已具备可作为后期编辑起点的水平。

**⚠️ 局限性**

局限性包括：①AI生成的灯光在色彩丰富度和多样性上略逊于人工版本；②受试者普遍认为AI设计更具重复性与可预测性；③系统尚未实现迭代人机协作与细粒度编辑，无法捕捉人类设计师在情感细微处理上的优势。

---

## 918. AMEM4Rec: Leveraging Cross-User Similarity for Memory Evolution in Agentic LLM Recommenders

**arXiv ID:** 2602.08837 | [PDF](https://arxiv.org/pdf/2602.08837v1)

**作者:** Minh-Duc Nguyen `[一作]` (VinUniversity), Dung D. Le `[通讯]` (VinUniversity)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

利用跨用户记忆演化的agentic LLM实现不需要预训练协同过滤模型的推荐系统

**💡 创新点**

通过将用户行为抽象为文本记忆，并在全局记忆池中进行双验证（相似度+语义）链接与迭代演化，显式捕获协同信号；同时在LLM推理中融入此记忆实现端到端协同学习

**🔧 技术方法**

使用大型语言模型（Gemini 2.5 Flash、Qwen2.5-7B-Instruct、Llama-3-8B-Instruct）、Sentence‑BERT编码、滑动窗口记忆生成、双验证器、记忆演化机制以及Prompt工程

**📊 数据集**

Amazon Fashion、Video Games、CDs & Vinyl 以及 MIND 新闻数据集

**📈 对比分析**

与LLMRank、AgentCF、iAgent 等基线对比，AMEM4Rec 在 NDCG@1/5/10 上均显著提升，特别在稀疏和冷启动场景表现更优

**⚠️ 局限性**

高度依赖 LLM 推理与 embedding 成本，API 调用量大；在极度稀疏数据下记忆演化效果有限；提示设计与模型可解释性仍受限

---

## 919. VideoVeritas: AI-Generated Video Detection via Perception Pretext Reinforcement Learning

**arXiv ID:** 2602.08828 | [PDF](https://arxiv.org/pdf/2602.08828v1)

**作者:** Hao Tan `[一作]` (Institute of Automation, Chinese Academy of Sciences), Zhen Lei `[通讯]` (School of Artificial Intelligence, University of Chinese Academy of Sciences)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

设计并实现了 VideoVeritas 框架，融合细粒度感知与基于事实的推理，用于检测 AI 生成视频。

**💡 创新点**

创新点包括：① 通过 Joint Preference Alignment 实现无监督冷启动，结合响应级与视频级 DPO；② 引入 Perception Pretext Reinforcement Learning（PPRL）——利用通用时空定位和自监督物体计数等感知预训练任务提升检测能力；③ 发布 MintVid 数据集，覆盖高质量生成、面部视频和事实错误三大子集。

**🔧 技术方法**

使用的大技术包括：多模态大型语言模型（如 Qwen3-VL‑8B）、强化学习（GSPO）、DPO（对数似然）、自监督感知任务、时空定位与计数奖励设计。

**📊 数据集**

主要使用的数据集有：MintVid（3K 视频），GenBuster‑200K、TalkingheadBench、GenBuster++、LOKI、VBench‑2、MVAD 等传统基准；以及公开的 OneThinker、OpenVid‑1M 用于感知任务。

**📈 对比分析**

与现有二分类检测器（如 BusterX++、Skyra‑RL）以及通用 MLLM（如 Gemini‑3‑Pro‑Preview、Qwen3‑VL‑8B）对比，VideoVeritas 在 ID、OOD 以及 MintVid 子集上均实现了 10–15% 的平均提升，尤其在 MintVid 上取得 93.1% / 91.4% / 78.1% 的性能，显著优于先前方法。

**⚠️ 局限性**

局限性包括：① 仍需高质量基准模型作为底层；② 感知预训练任务的质量和范围受限，尤其是专用人工标注的 Artifact Grounding；③ RL 训练对计算资源和超参数敏感；④ 在极高质量合成视频或事实推理极难的视频上仍有失误。

---

## 920. Equilibria: Fair Multi-Tenant CXL Memory Tiering At Scale

**arXiv ID:** 2602.08800 | [PDF](https://arxiv.org/pdf/2602.08800v1)

**作者:** Kaiyang Zhao `[一作]`, Dimitrios Skarlatos `[通讯]` (Carnegie Mellon University)

**关键词:** `9a43038e-f401-4fd9-9c05-65c0b8369d7e` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并实现了面向多租户的 CXL 内存分层框架，可在容器层面实现公平内存分配、可观测性和抖动抑制。

**💡 创新点**

创新点在于提出可配置的下限保护与上限约束的公平共享机制，结合基于使用率的动态降级/提升调度与抖动容忍策略，并在 Linux 内核中实现。

**🔧 技术方法**

主要技术包括 Linux cgroup 扩展、内存回收/调度算法、NUMA 资源平衡、CXL 2.0 Type3 接口、页迁移与热点检测等。

**📊 数据集**

使用的数据集包括三大生产工作负载（Cache、Web、CI）以及 DCPerf 基准（SparkBench、TaoBench），并结合大规模服务器集群的实际监控数据。

**📈 对比分析**

通过与 Linux 原生 TPP 方案对比，利用 SLO 满足率、吞吐量、延迟等指标评估，实验显示在生产与基准测试中分别提升至 52% 与 1.7×。

**⚠️ 局限性**

局限性包括对 CXL 硬件实时热度检测支持不足，无法充分满足高带宽占用场景；对极端多租户混合模式下上限保护的细粒度调优仍需改进；实现仍在评估阶段，尚未覆盖所有 VM/容器场景。

---

## 921. CryptoGen: Secure Transformer Generation with Encrypted KV-Cache Reuse

**arXiv ID:** 2602.08798 | [PDF](https://arxiv.org/pdf/2602.08798v1)

**作者:** Hedong Zhang `[一作]` (University of Central Florida), Farinaz Koushanfar `[通讯]` (University of California San Diego)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在云端实现安全的自回归Transformer生成，保证用户提示和模型参数的隐私；

**💡 创新点**

首次引入加密键值缓存（KV Cache）复用与异构SIMD编码，减少了加密生成的二次计算；

**🔧 技术方法**

结合全同态加密（FHE）与多方安全计算（MPC），使用外部与内部编码、CT×PT、CT×CT 乘法优化，以及噪声刷新和密文拼接机制；

**📊 数据集**

在GPT‑2基础模型上，使用WikiText‑2、Penn Treebank (PTB) 和 LAMBADA 三个文本数据集进行评估；

**📈 对比分析**

与BOLT等基线进行对比，CryptoGen在生成长度128–512时每个token的延迟降低4.4–7.6倍，整体延迟与内存保持近线性增长；

**⚠️ 局限性**

局限在模型规模有限，未充分测试更大语言模型；仅支持半诚实两方模型，未考虑恶意攻击、侧信道与完整性问题；

---

## 922. MOVA: Towards Scalable and Synchronized Video-Audio Generation

**arXiv ID:** 2602.08794 | [PDF](https://arxiv.org/pdf/2602.08794v1)

**作者:** SII-OpenMOSS Team `[一作]`, Xipeng Qiu `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出并实现了MOVA，一种可同步生成多语言语音与高质量 lip 同步视频的双塔扩散模型；

**💡 创新点**

创新点包括异步双塔架构、对齐 RoPE 的双向交叉注意力桥梁、以及分阶段高质量音视频标注与大规模数据扩充；

**🔧 技术方法**

技术上采用预训练视频与音频 DiT 核心、流匹配训练目标、双向桥接模块、分离时间步噪声调度、以及双重无条件引导；

**📊 数据集**

使用超过100,000小时的公开与自建音视频数据，涵盖 VGGSound、AutoReCap、OpenHumanVid 等多样化语料；

**📈 对比分析**

与 LTX‑2、Ovi 及 WAN+MMAudio 级联基线对比，MOVA 在音频质量、语音自然度、Lip‑Sync 误差与多说话人准确率上均显著优于基线，且在人类偏好评测中获得最高 ELO；

**⚠️ 局限性**

局限性包括音频建模容量有限（对歌唱、复杂乐器效果欠佳）、多说话人同步仍易出错、以及大规模训练与推理所需的高计算成本与长序列内存瓶颈。

---

## 923. GaussianCaR: Gaussian Splatting for Efficient Camera-Radar Fusion

**arXiv ID:** 2602.08784 | [PDF](https://arxiv.org/pdf/2602.08784v1)

**作者:** Santiago Montiel-Marín `[一作]` (University of Alcalá), Luis M. Bergasa `[通讯]` (University of Alcalá)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `729e5870-4135-47f5-97f2-e3974d07b5dc` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `51c0528b-f690-4182-ae60-bb5f046c276c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了GaussianCaR框架，实现摄像头与雷达数据通过高斯展开在BEV空间的高效融合，生成车辆与地图语义分割结果；

**💡 创新点**

创新点在于将Gaussian Splatting作为通用视图变换器，将像素与点云直接映射至稀疏三维高斯表示，再在此空间进行多模态融合和解码；

**🔧 技术方法**

采用EfficientViT-L2和轻量级PTv3进行特征提取，利用高斯渲染进行BEV投影，结合CMX融合模块和DPT解码器；

**📊 数据集**

在大型多模态数据集nuScenes上进行训练与评估；

**📈 对比分析**

与现有单模态与多模态BEV分割方法对比，车辆分割IoU达57.3%，地图分割（道路与车道）分别达到82.9%与50.1%，超过或与SOTA持平，且推理速度提升3.2倍；

**⚠️ 局限性**

主要局限在于高斯渲染对高斯数量敏感，需在不同任务与雷达扫描次数下调参，且对稀疏雷达点云的分布依赖较大。

---

## 924. Mind the Gap: Learning Implicit Impedance in Visuomotor Policies via Intent-Execution Mismatch

**arXiv ID:** 2602.08776 | [PDF](https://arxiv.org/pdf/2602.08776v1)

**作者:** Cuijie Xu `[一作]` (Tsinghua University), Jinchen Yu `[通讯]` (Tsinghua University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出双状态条件化框架，将学习目标从执行克隆转为意图克隆，并利用主从命令差异学习隐式阻抗控制，在低成本无传感器机械臂上完成接触丰富与动态任务。

**💡 创新点**

创新点包括：① 将学习目标转为主从意图克隆，利用Intent-Execution Mismatch作为力感知信号；② 通过序列填充实现延迟自适应，解决推理延迟导致的闭环不稳定；③ 在不依赖力/触觉传感器的前提下实现高精度接触与动态控制。

**🔧 技术方法**

采用视觉-动作模仿学习（Diffusion Policy、π_0等基模型），双状态条件化（SM2M），序列填充（inpainting）延迟适配，随机上下文训练以及无传感器无力传感器的端到端策略。

**📊 数据集**

使用由人机协作收集的多任务数据集，涵盖微波操作、插头插入、表面擦拭、投掷、传送带重量分类等六个任务；未使用公开数据集。

**📈 对比分析**

与标准执行克隆(S2S)、意图克隆(S2M)以及同步/异步实现对比；在六个任务中，SM2M/自适应填充平均成功率接近100%，明显优于S2S；在延迟测试中保持低抖动（jerk ≈ 0.88 m/s³）并维持高成功率。

**⚠️ 局限性**

局限性：仍需人类操作员提供隐式意图，难以完全无监督学习；在极大延迟或硬件变动时性能会下降；迁移到不同硬件平台需重新采集主从差异数据。

---

## 925. VedicTHG: Symbolic Vedic Computation for Low-Resource Talking-Head Generation in Educational Avatars

**arXiv ID:** 2602.08775 | [PDF](https://arxiv.org/pdf/2602.08775v1)

**作者:** Vineet Kumar Rakesh `[一作]` (Homi Bhabha National Institute), Sarbajit Pal `[通讯]` (Mahatma Gandhi University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

设计了一套 CPU 端、确定性、轻量化的说话人头像生成框架，利用符号化的 Vedic 计算实现语音驱动的唇形同步与 2D 渲染。

**💡 创新点**

将 Vedic 计算中的 Urdhva Tiryakbhyam 交叉算子用于视觉音素混合，提供低成本的共振化计算来实现平滑共振过渡，同时保持确定性与可解释性。

**🔧 技术方法**

采用语音到音素时间对齐、音素到视觉音素的查找表映射、符号共振化计算、基于 ROI 的 2D 贴图合成与头部稳定等技术。

**📊 数据集**

使用 GRID、TCD‑TIMIT、LRS2/3、VoxCeleb 等公开语音‑视频数据集进行基准测试。

**📈 对比分析**

与 CPU 版 Wav2Lip 等基线在同步精度、FPS、延迟、CPU 占用等指标对比，保持约 90% 的同步准确率，同时 FPS 提升至 37.5、延迟 26.7 ms、CPU 29% 的显著优势。

**⚠️ 局限性**

仅实现口腔区域动画，缺乏眉、眼、头部等表情；共振化规则经验性，可能不足以捕捉极快或非典型音素序列；语言扩展需重新定义音素‑视觉音素映射。

---

## 926. Default Machine Learning Hyperparameters Do Not Provide Informative Initialization for Bayesian Optimization

**arXiv ID:** 2602.08774 | [PDF](https://arxiv.org/pdf/2602.08774v1)

**作者:** Nicolás Villagrán Prieto `[一作]` (Universidad Pontificia Comillas), Eduardo C. Garrido-Merchán `[通讯]` (Instituto de Investigación en Tecnología)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

评估将机器学习库默认超参数作为贝叶斯优化初始化点是否能加速收敛并提升最终性能。

**💡 创新点**

系统性地对比多种 BO 后端、模型族和数据集，验证默认值是否真正能提供有用的先验信息，填补了此前实验缺口。

**🔧 技术方法**

使用贝叶斯优化（BO）配合高斯过程（GP）代理、期望改进（EI）采集函数，并通过 BoTorch、Optuna、Scikit-Optimize 三个库实现；默认初始化采用截断高斯分布。

**📊 数据集**

五个基准数据集（AmazonAcc、Letter、Higgs、BikeSharing、Airlines10M），覆盖分类与回归任务。

**📈 对比分析**

采用一边单侧二项检验比较默认初始化与均匀随机初始化在收敛速度和最终指标上的胜负次数；结果显示 p 值≥0.14，未发现显著优势。

**⚠️ 局限性**

局限性包括样本量有限、仅测试三种 BO 后端、仅使用三类模型、采用 3 折 CV、数据子样本化，可能影响结论的普适性。

---

## 927. Discovering Interpretable Algorithms by Decompiling Transformers to RASP

**arXiv ID:** 2602.08857 | [PDF](https://arxiv.org/pdf/2602.08857v1)

**作者:** Xinting Huang `[一作]` (Saarland University), Michael Hahn `[通讯]` (Saarland University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一套从已训练的Transformer模型自动提取可读RASP程序的完整方法，展示了Transformer内部实现的简单可解释算法。

**💡 创新点**

创新点在于：①通过对Transformer的线性层归一化假设，实现了对Transformer的“faithful”重参数化为D-RASP程序；②利用因果干预与稀疏性惩罚对程序进行裁剪，得到极简的功能完整子程序；③将成功的解码与长度泛化能力直接关联，提供了对长度泛化假设的最直接实证。

**🔧 技术方法**

主要技术包括：Transformer到D-RASP的精确映射（LLNA假设下线性化层归一化）、因果裁剪（基于交叉熵或KL散度的训练门控）、库式原语替换、程序简化与稀疏矩阵优化，以及对输入输出行为的准确匹配评估。

**📊 数据集**

使用了小规模的GPT‑2风格模型在两大类人工合成数据集上进行实验：
- 算法任务（如最频字符、唯一复制、排序、计数等）
- 形式语言（严格局部语言、有限深度Dyck语言等）
所有任务均在长度≤50训练，长度51–150进行泛化评估。

**📈 对比分析**

通过对每个任务训练的多个模型，记录匹配准确率（≥90%视为成功）与程序长度的Pareto曲线。实验结果表明：
- 长度泛化模型能被成功解码为极简程序，匹配率>90%；
- 非泛化模型解码失败，匹配率低；
- 成功解码后程序长度可从原始的数百万行缩短至数十行，且功能与原模型完全一致。

**⚠️ 局限性**

局限性包括：
- 仅适用于小型、已满足LLNA的GPT‑2风格Transformer；
- 对大规模或真实语言模型的可扩展性未知；
- 需要手工定义原语库，某些复杂操作无法被原语覆盖；
- 目前仅评估了合成任务，未验证在人类语言任务上的效果。

---

## 928. Finite-Time Teleoperation of Euler-Lagrange Systems via Energy-Shaping

**arXiv ID:** 2602.08845 | [PDF](https://arxiv.org/pdf/2602.08845v1)

**作者:** Lazaro F. Torres `[一作]` (University of Guadalajara), Emmanuel Cruz-Zavala `[通讯]` (University of Guadalajara)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

设计了一系列连续的有限时（finite‑time）P+d控制器，用于双向遥操作的完全控制的欧拉-拉格朗日系统，能在无延迟、无外部力时保证位置误差和速度在有限时间内收敛为零，并提供了可避免执行器饱和的限幅控制方案。

**💡 创新点**

创新点：
1) 引入能量整形与齐次性工具，实现了全局有限时收敛的连续控制器；
2) 提供了既可使用状态反馈也可使用输出反馈（无速度测量）的控制结构；
3) 设计了可避免饱和的有限时控制器，兼顾了执行器物理极限；
4) 控制器结构简单，易于实现且不产生切换/摩擦问题。

**🔧 技术方法**

使用技术：
- 欧拉-拉格朗日动力学建模；
- 能量整形与能量注入（P+d）控制器；
- 齐次系统理论与齐次逼近的负度数证明有限时稳定性；
- 区分式饱和与签名幂函数实现有限幅度限制；
- 传统滑模终端控制器（TSMC）作为比较基准。

**📊 数据集**

数据集/实验平台：
- 仿真：2自由度机器人（参数与文献相同）；
- 实验：6自由度Kinova® Gen3 Ultra‑lightweight（本地）和Kinova® Gen3 Lite（远端）机器人；
- 没有公开数据集，所有实验使用自研硬件与仿真环境完成。

**📈 对比分析**

比较方法：
- 与终端滑模控制器（TSMC）在无延迟、无外部力的自由运动场景下对比；
- 评估指标：位置误差收敛时间、控制力幅值、是否出现抖振；
- 结果显示：本方法收敛时间约 2.3 s（C1）对比 TSMC 的 5 s；控制力更平滑，抖振明显降低；在 6‑DOF 实验中，有限时控制器在约 1 s 内实现位置一致，误差显著低于传统渐进控制。

**⚠️ 局限性**

局限性：
- 本研究未对通信延迟进行严格分析，虽然实验表明能在一定延迟下工作，但缺乏理论保证；
- 需要已知完整的机器人动力学模型，模型不确定性会破坏有限时收敛性；
- 设计需要适当选取齐次权重 r1,r2，参数调节不直观，可能导致控制力过大；
- 在极端大外部力或噪声下，限幅控制可能导致性能下降；
- 对多机器人多任务或复杂环境的扩展尚未讨论。

---

## 929. Kirin: Improving ANN efficiency with SNN Hybridization

**arXiv ID:** 2602.08817 | [PDF](https://arxiv.org/pdf/2602.08817v1)

**作者:** Chenyu Wang `[一作]` (Sun Yat-sen University), Weng-Fai Wong `[通讯]` (National University of Singapore)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 Kirin 框架，将大语言模型的 ANN 转换为能量效率高且无精度损失的 SNN，采用整数‑突触混合化的矩阵乘法与 TTFS 编码；

**💡 创新点**

创新点在于 ① Spike Matrix Hybridization 策略：对权重/激活中的异常值采用 8 位整数保留，剩余低位采用 TTFS 突触，显著缩短时间窗口；② Silence Threshold 机制：在 IF 单峰限制下通过静默阈值实现与 ANN 输出完全等价，从而消除信息丢失；

**🔧 技术方法**

使用混合精度量化（W4A4+8位异常值）、TTFS 时序编码、Integrate‑and‑Fire 神经元、整数与突触的混合矩阵乘法以及静默阈值控制；

**📊 数据集**

评测数据集包括 Llama2‑7B/13B 与 OPT‑1.3B/2.7B，语言任务使用 WikiText‑2、C4 文本数据；零样本推理使用 PIQA、ARC‑e/c、BoolQ、HellaSwag、Winogrande 六大常识问答集；

**📈 对比分析**

与 FP16 基准、各类 4‑位量化（SmoothQuant、OmniQuant、Atom 等）以及 SNN 基线（SpikeLLM、SpikeQuant）进行对比；在 W4A(4&8) 设置下，Kirin 在 WikiText‑2 的 perplexity 仅比 FP16 高 0.03，时间窗口从 256 缩短至 16，能耗下降 84%，时延降低 94%；零样本任务平均准确率几乎等于 FP16；

**⚠️ 局限性**

局限性包括：① 仍需保留部分整数乘法，导致算子种类增加；② 对高位异常值的处理依赖于离散的 8 位阈值，可能不适用于所有模型或更大规模网络；③ 目前仅在 LLM 结构（Transformer）上验证，其他网络（如 CNN、RNN）的可迁移性待进一步研究；

---

## 930. Verifying DNN-based Semantic Communication Against Generative Adversarial Noise

**arXiv ID:** 2602.08801 | [PDF](https://arxiv.org/pdf/2602.08801v1)

**作者:** Thanh Le `[一作]` (National Institute of Information and Communications Technology), Takeshi Matsumura `[通讯]` (National Institute of Information and Communications Technology)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种针对基于深度学习的语义通信系统的形式化验证框架，能够在生成式对抗噪声下给出数学鲁棒性保证。

**💡 创新点**

创新点在于将对抗噪声生成模型建模为混合整数规划，并将多网络端到端的验证问题转化为可被现有DNN验证器求解的逻辑公式，同时揭示能量约束与潜在维度对安全性的权衡。

**🔧 技术方法**

采用混合整数规划求解、状态‑of‑the‑art DNN验证器（如Reluplex/Neurify）、GAN‑生成对抗噪声和PGD梯度攻击等技术。

**📊 数据集**

使用 FashionMNIST 与 CIFAR‑10 两个公开数据集进行实验。

**📈 对比分析**

与输入无关生成器和PGD两种攻击器比较，验证器在约44%属性上给出正式鲁棒性保证；在不同 PNR 约束和潜在维度下，验证器展示了在鲁棒性、攻击发现率和计算耗时方面的具体性能。

**⚠️ 局限性**

主要限制在于对高维潜在空间鲁棒性不足，验证过程依赖耗时的 MIP 求解，且当前框架仅覆盖编码/解码与任务模型，未扩展到完整通道编码层。

---

## 931. Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning

**arXiv ID:** 2602.08835 | [PDF](https://arxiv.org/pdf/2602.08835v1)

**作者:** Andrés Holgado-Sánchez `[一作]` (CETINIA University Rey Juan Carlos), Holger Billhardt `[通讯]` (CETINIA University Rey Juan Carlos)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出并实现了一种在线偏好驱动的多目标强化学习算法 SVSL-P，用于在 MDP 中从个体偏好学习社会价值系统与对应策略。

**💡 创新点**

创新点在于结合在线价值对齐与价值体系偏好采样，联合使用 EM 聚类与多目标 RL，能够同时学习社会共同价值基础、群体价值权重及对应策略。

**🔧 技术方法**

使用 Bradley‑Terry 模型、EQL（Envelope Q‑Learning）、深度神经网络、EM 算法和在线人机交互采样。

**📊 数据集**

在两种合成 MDP 环境——消防员（FF）和多值汽车（MVC）——中进行实验，生成模拟社会代理及其轨迹。

**📈 对比分析**

与基线 EQL、SVSL（无在线反馈）以及 PbMORL 进行对比；指标包括代表性、共识度、简洁度、Ray‑Turi 指数、超体积和最大效用损失；SVSL-P 在代表性、简洁度和超体积方面优于 PbMORL，并且在最大效用损失上与基线相当。

**⚠️ 局限性**

实验结果表明算法在不同随机种子下表现不稳定；部分聚类产生的策略并不完全 Pareto 最优；需要大量在线查询，且对真实世界数据的泛化尚待验证。

---

## 932. Enhancing Generative AI Image Refinement with Scribbles and Annotations: A Comparative Study of Multimodal Prompts

**arXiv ID:** 2602.08830 | [PDF](https://arxiv.org/pdf/2602.08830v1)

**作者:** Hyerim Park `[一作]` (BMW Group), Malin Eiband `[通讯]` (BMW Group)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本研究通过设计一种支持文本、手绘涂鸦与注释三种输入模式的原型，探讨多模态提示在生成式AI图像精细化过程中的可行性与效果；

**💡 创新点**

创新点在于将手绘涂鸦与注释统一为可直接作为提示的视觉输入，并系统评估其与纯文本提示在表达意图、效率、工作负荷、迭代支持及用户体验方面的差异；

**🔧 技术方法**

核心技术包括基于React与FastAPI实现的Web原型、使用GPT‑4或GPT‑4o对文本与视觉输入进行意图解析、将解析结果映射为结构化JSON后交给FLUX.1或GPT‑Image‑1模型生成改良图像；

**📊 数据集**

实验数据集由DALL‑E 3与FLUX.1预生成的七组源图像与对应目标图像构成，共计21个精细化任务，供受试者在三种输入模式下完成；

**📈 对比分析**

通过在30名设计师/学生中的闭合式与开放式任务内在对照实验，对比任务完成时长、NASA‑TLX工作负荷、UEQ‑S体验量表与自定义意图表达与迭代支持量表；结果显示视觉和组合模式在空间修改任务上完成更快、工作负荷更低，组合模式在整体表达和迭代支持得分最高，文本模式在语义与全局调整上更有优势；

**⚠️ 局限性**

局限性包括实验在受控实验室进行、任务有限且迭代次数受限、模型生成质量和延迟可变、未进行客观图像质量评估、样本规模相对较小以及文本与视觉输入与输入设备紧耦合导致的潜在偏差。

---

## 933. Affective Flow Language Model for Emotional Support Conversation

**arXiv ID:** 2602.08826 | [PDF](https://arxiv.org/pdf/2602.08826v1)

**作者:** Chenghui Zou `[一作]` (Chongqing University), Erik Cambria `[通讯]` (Nanyang Technological University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Affective Flow 框架，利用细粒度情绪流监督改进多轮情感支持对话的策略一致性与响应质量。

**💡 创新点**

创新点在于：① 通过 MCTS 生成的搜索轨迹提取连续情绪流，提供密集中间监督；② 设计子路径流平衡约束，将终端奖励信息逐层传播至前置策略；③ 将 GFlowNet 思想与 LLM 结合，形成端到端的 AFPO 优化。

**🔧 技术方法**

主要技术包括：角色分离的 LLM 环境（seeker/supporter/rewarder）、蒙特卡洛树搜索、生成流网络（GFlowNet）中的流量定义、子路径流平衡损失与边缘偏好排序的 AFPO 训练。

**📊 数据集**

使用公开情感支持对话数据集 ExTES 与 ESConv，二者分别涵盖多种情绪场景与支持策略。

**📈 对比分析**

与 10+ 传统与 LLM 基线（ESCoT、MISC、BlenderBot‑Joint 等）以及 GPT‑4o/Claude‑3.5 进行对比，AFlow 在策略 F1、响应多样性、生成质量等指标上持续领先，甚至在多种 LLM backbone 上保持优势。

**⚠️ 局限性**

局限性包括：依赖 MCTS 的计算开销、仅在两套单语数据集验证、缺乏跨文化与多语言适配评估，未来需探索更高效的搜索或在线学习机制。

---

## 934. LakeHopper: Cross Data Lakes Column Type Annotation through Model Adaptation

**arXiv ID:** 2602.08793 | [PDF](https://arxiv.org/pdf/2602.08793v1)

**作者:** Yushi Sun `[一作]` (Hong Kong University of Science and Technology), Lei Chen `[通讯]` (Hong Kong University of Science and Technology)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种名为 LakeHopper 的框架，用于在不同数据湖之间迁移列类型注释模型，并显著减少对目标数据湖的标注需求。

**💡 创新点**

创新点包括：
1) 通过 LLM 验证识别源–目标知识差距；
2) 基于 K‑means 的弱样本选择策略；
3) 递增微调（gap‑hopping）避免灾难性遗忘；
4) 标签集差异调整以继承共享知识；
5) 将 LLM 作为轻量级知识引导而非直接训练。

**🔧 技术方法**

使用技术包括：
- 预训练语言模型（BERT/ RoBERTa 等）作为列编码器；
- LLM（GPT‑3.5/ GPT‑4o）做查询验证；
- K‑means 聚类识别弱样本；
- 递增微调与早停机制；
- 标签集映射与随机初始化。

**📊 数据集**

主要数据集：
- PublicBI、VizNet、Semtab2019（两个迁移实验）
- 额外验证：PublicBI → GitTables。

**📈 对比分析**

与基线对比：
- PLM‑based 方法（Sherlock、TABBIE、DODUO、Sudowoodo、RECA）
- LLM‑based 方法（ChatGPT、GPT‑4o、GPT‑5.1、TableLlama）
- 在低资源场景下，LakeHopper 在 SW F1 上提升 8–43%，MA F1 提升 26–71%；
- 在高资源场景下，提升 0.8–4%；
- 训练速度比 fine‑tuned TableLlama 快 27–131×，成本低。

**⚠️ 局限性**

局限性：
- 仍需一定量的目标数据标注；
- 对 LLM 的调用成本与 API 费用敏感；
- 对极大类型集合或极端域转移的适应性尚未充分验证；
- 仅适用于列级注释，无法利用列名或元数据；
- 依赖预训练模型的可用性和性能。

---

## 935. Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems

**arXiv ID:** 2602.08792 | [PDF](https://arxiv.org/pdf/2602.08792v1)

**作者:** Hao Dong `[一作]` (ETH Zurich), Olga Fink `[通讯]` (EPFL)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种多模态半监督异常检测框架（MultiDeepSAD），通过图像和接触力测量联合检测架空线与架空支架接触处的电弧事件。

**💡 创新点**

创新点包括：①将 DeepSAD 扩展到多模态并设计新型指数损失；②针对图像与力数据分别构造伪异常生成策略；③构建公开的同步图像-力数据集。

**🔧 技术方法**

使用的技术主要有：多模态深度编码器（ResNet‑18 + MLP），FFT 对力信号做频域表示，伪异常生成（图像剪贴+混合，力混合），指数损失训练，后期拼接融合（late fusion）。

**📊 数据集**

采用了两套数据集：①私有的 SBB‑AD（SBB 采集的图像与力同步数据）；②公开的 Open‑AD（YouTube 视频图像 + 合成力信号）。

**📈 对比分析**

与传统无监督方法（IForest、OCSVM、LOF、KNN、AutoEncoder）、DeepSVDD、DeepSAD 等相比，MultiDeepSAD 在 SBB‑AD 上 93.49% AUROC、Open‑AD 上 95.03% AUROC，性能提升约 5–10% 并且对伪异常、噪声、域迁移等具有更高鲁棒性。

**⚠️ 局限性**

局限性包括：需要有限数量的真实电弧样本来生成伪异常；对极端环境（如浓雾、强光照）仍有一定性能下降；当前模型为离线评估，实时部署与位置追踪尚未实现。

---

## 936. Empirically Understanding the Value of Prediction in Allocation

**arXiv ID:** 2602.08786 | [PDF](https://arxiv.org/pdf/2602.08786v1)

**作者:** Unai Fischer-Abaigar `[一作]`, Juan Carlos Perdomo `[通讯]`

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文通过构建一个实证工具包，比较公共机构在资源分配中投资预测模型与其他政策杠杆（如扩容、提升服务质量）所带来的社会福利收益。

**💡 创新点**

创新点在于将投资成本与福利目标结合，提供一种基于数据的、可针对不同场景量化预测改进价值的方法，弥补了以往理论研究对简化假设的依赖。

**🔧 技术方法**

采用了阈值预测分配策略、效用函数与分位数阈值的模拟、以及基于 Python 的软件框架实现对策划情境的快速评估。

**📊 数据集**

使用了德国联邦就业局1970–2021年的约6000万条就业记录和2015年埃塞俄比亚生活水平测量调查的4694户家庭问卷数据。

**📈 对比分析**

通过对不同杠杆的效用增量、成本效益比、盈亏平衡点和相对效益比进行模拟比较，实验结果表明在低容量或高损害风险情境下，预测改进能显著提升福利，而在高容量或无损害情境下扩容更具优势。

**⚠️ 局限性**

局限性包括对成本和效用假设的敏感性、对预测误差的插值处理、缺乏对长期或动态效应的考量，以及工具包在其他领域迁移时可能需要进一步验证。

---

## 937. Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas

**arXiv ID:** 2602.08765 | [PDF](https://arxiv.org/pdf/2602.08765v1)

**作者:** Micah Villmow `[一作]` `[通讯]`, Micah Villmow

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 Scylla 框架，用分层消融实验评估 LLM 编码工具的架构复杂度与成本/质量关系。

**💡 创新点**

创新点在于七层评估层 (T0‑T6)、Cost‑of‑Pass (CoP) 经济指标、模型无关适配器模式以及多判定器一致性评分。

**🔧 技术方法**

采用多模型 LLM 判定器（Claude Opus、Sonnet、Haiku）、Git 工作树隔离、并行执行、缓存 Token 统计等技术。

**📊 数据集**

数据集为 ProjectOdyssey GitHub 仓库的任务，先进行 Hello World 单任务（dryrun），后续计划 113 个子测试。

**📈 对比分析**

通过对各层成本、CoP、Token 分布和判定一致性比较，发现质量在 Hello World 上已饱和，但成本从 0.065 美元到 0.247 美元变化 3.8 倍，T5 混合配置成本最低。

**⚠️ 局限性**

局限包括单任务单次实验缺乏统计显著性、仅使用 Claude Code、判定者一致性低、评测范围受限。

---

## 938. $\texttt{lrnnx}$: A library for Linear RNNs

**arXiv ID:** 2602.08810 | [PDF](https://arxiv.org/pdf/2602.08810v1)

**作者:** Karan Bania `[一作]` (Carnegie Mellon University), Pratham Chheda `[通讯]` (BITS Pilani)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `b88c6eac-d57a-4623-a604-1f401f3eb268` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本研究提出了一个统一的线性递归神经网络（LRNN）库，整合了多种主流LRNN架构，并提供统一接口；

**💡 创新点**

创新点包括将分散的LRNN实现统一、实现高性能CUDA内核、支持多种离散化方案以及利用CUDA Graph加速推理；

**🔧 技术方法**

技术实现基于PyTorch框架，使用自定义CUDA核、einsum优化、扫描（scan）并行实现以及多种离散化方法（ZOH、bilinear、dirac、异步）；

**📊 数据集**

实验使用了长序列合成任务（Long‑Range Arena）以及音频、视觉等典型数据集，但未给出具体数据集名称；

**📈 对比分析**

通过在NVIDIA A100 GPU上对比原始和公开实现（S5、LRU、Mamba等）的训练和推理时间，结果显示实现与公开基线相当，推理略慢；

**⚠️ 局限性**

局限性在于仅支持PyTorch、CUDA（仅NVIDIA），缺乏与Hugging Face、DeepSpeed、FSDP等生态的原生集成，且未实现双向或非线性RNN变体。

---

## 939. The Presort Hierarchy for Geometric Problems

**arXiv ID:** 2602.08843 | [PDF](https://arxiv.org/pdf/2602.08843v1)

**作者:** Ivor van der Hoog `[一作]` (IT University of Copenhagen), Lasse Wulf `[通讯]` (IT University of Copenhagen)

**关键词:** `a42c7bd6-d8fd-40d3-94df-ae8cd808f5c4` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出预排序层次结构，证明在点集已按两条正交方向预排序的情况下，四叉树、Delaunay 三角剖分、Voronoi 图、欧氏最小生成树等邻近结构可在期望 O(n√log n) 时间内构造，并将该结果推广到多种几何问题；同时给出若干问题属于或不属于此预排序层次。

**💡 创新点**

创新点在于将预排序与随机化相结合，构造了线深 Clairvoyant Algebraic Decision Tree，并利用 Belazzougui‑Puglisi 的二维范围后继结构在 Real‑RAM 上实现 O(n√log n) 的四叉树构造；此外提出完整的预排序层次，对问题进行分类，首次证明如层析剖分、KD‑树、最大空圆等可在两方向预排序下快速完成，而层状剖分、序列最近邻等仍需 Ω(nlogn) 时间。

**🔧 技术方法**

核心技术包括：
- Clairvoyant ADT（知道预排序的整数信息）
- 预排序下的指数搜索与跳表模拟
- Belazzougui‑Puglisi 的二维范围后继/计数结构，并在 Real‑RAM 上通过查表/位运算实现
- 随机化采样与期望分析
- 通过凸包/分层剖分等几何预处理实现多种问题的降维。

**📊 数据集**

主要使用的是理论构造的点集（如凸包、分层点集、随机采样子集等），未采用真实世界数据集；实验仅用于验证期望时间与理论一致。

**📈 对比分析**

相较于传统的 Θ(nlogn) 算法，该方法在已预排序的输入上将时间降到 O(n√log n) 的期望复杂度；实验显示实际运行时间与理论估计相符，并在大规模 n（10^6 以上）时明显优于朴素 O(nlogn) 方案。

**⚠️ 局限性**

局限性包括：
- 结果仅在已按两方向预排序的输入上成立，无法直接应用于无序数据；
- 需要随机化，尚未给出确定性（derandomized）算法；
- 对更高维度问题和某些几何结构（如高维四叉树）缺乏推广；
- 关键的二维范围后继结构仍以 O(n√log n) 的预处理为瓶颈，若能改进将进一步提升性能。

---

## 940. FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models

**arXiv ID:** 2602.08818 | [PDF](https://arxiv.org/pdf/2602.08818v1)

**作者:** Annemette Brok Pirchert `[一作]` (University of Southern Denmark), Peter Schneider-Kamp `[通讯]` (University of Southern Denmark)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `64443552-63e0-44b5-906f-d90fe95c5a1b` `afceb026-1760-41ae-8d86-010831a37d97` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种可在联邦学习环境下使用的灵活混合专家架构 FlexMoRE，支持全尺寸专家与低秩适配器混合。

**💡 创新点**

创新点在于：1) 允许同一 MoE 框架中混合全尺寸专家与低秩适配器；2) 通过后期低秩分解（PHLoRA）从预训练全尺寸专家快速生成低秩专家；3) 研究不同任务对专家秩的敏感性，并给出按任务选择最佳秩的策略。

**🔧 技术方法**

采用了混合专家（MoE）架构、LoRA 低秩适配器、后期低秩分解、领域感知路由器和线性回归进行秩敏感性分析。

**📊 数据集**

在 120 个任务（包括 9 个多选推理基准、5 个生成 QA、学术推理、BBH、MMLU、MMLU-Pro）上进行评估，使用 FlexOlmo 作为基准。

**📈 对比分析**

与全尺寸 FlexOlmo 的混合专家模型相比，FlexMoRE 在保持甚至提升平均性能（Avg 从 45.46 提升至 47.18）的同时，参数量仅为 10.75B，约为全尺寸的三分之一；在按任务最佳秩选择的异构模型中，平均提升约 5‑14% 以上。

**⚠️ 局限性**

局限性包括：未对路由器进行微调；实验仅基于后期 LoRA 提取，未探索从零开始训练低秩专家；仅研究单一语言环境，未探讨多语言或跨层秩分配。

---

## 941. Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure

**arXiv ID:** 2602.08783 | [PDF](https://arxiv.org/pdf/2602.08783v1)

**作者:** Zirui Li `[一作]` (Harbin Institute of Technology), Min Zhang `[通讯]` (Harbin Institute of Technology)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文把 Latent / 连续 Chain‑of‑Thought 视为可操控的因果过程，利用 step‑wise do‑intervention、信息流图和轨迹承诺分析，评估每一步的必要性、传播路径和竞争模式。

**💡 创新点**

创新点在于将 Latent CoT 建模为结构因果模型，并提出基于单步干预、影响矩阵和模式动力学三角视角，首次实现对隐式推理流程的可解释性解析。

**🔧 技术方法**

使用的技术包括结构因果模型 (SCM)、对隐层状态的 do‑操作、教师强制与 probe 读取、KL 变异度量影响、早停解码以及可视化的影响网络。

**📊 数据集**

实验数据集为 GSM8K、CommonsenseQA（CoT 增强版）和 StrategyQA（二分类），并分别在 GPT‑2、Llama3‑1B、Qwen3‑4B 这三种后端上进行评估。

**📈 对比分析**

与显式 CoT（CoT‑SFT）以及不同后端模型比较，发现 Latent CoT 在信息路由上更偏跳跃、Coconut 与 CODI 在步长敏感度上存在差异；总体准确率与基线相近，但提供了更丰富的因果与传播洞察。

**⚠️ 局限性**

局限性包括：实验规模有限，仅覆盖单一干预策略（零值干预）和单步；读取方式对结果敏感；难以捕捉多模式、复杂推理的全局特征；缺乏跨任务的通用验证。

---

## 942. FlattenGPT: Depth Compression for Transformer with Layer Flattening

**arXiv ID:** 2602.08858 | [PDF](https://arxiv.org/pdf/2602.08858v1)

**作者:** Ruihan Xu `[一作]` (Peking University), Shiliang Zhang `[通讯]` (Peking University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出 FlattenGPT，利用层平铺（Flattening）和通道剪枝（Channel Pruning）实现大语言模型的深度压缩；

**💡 创新点**

创新点在于先将相邻高度相似的 transformer 层合并为单一宽层，保留所有层的知识，再通过通道剪枝精细去除冗余，从而兼顾深度压缩与结构一致性，显著降低性能损失；

**🔧 技术方法**

采用的技术包括：相似度计算与贪心层选择、层平铺操作（参数融合、注意力头合并、MLP 通道合并）、注意力头重要性评估、Nyström 近似的岭系数通道剪枝、以及恢复微调（Recovery Fine‑Tuning）；

**📊 数据集**

使用数据集：WikiText‑2（128样本校准，测试集评估 perplexity）、Zero‑shot 任务（Winograd、HellaSwag、PIQA、ARC‑e/c），以及 50K Alpaca 数据进行恢复微调；

**📈 对比分析**

与现有深度压缩方法（SLEB、LaCo、RM、ShortGPT、BlockPruner）以及宽度/稀疏化方法（SliceGPT、Wanda、2:4）比较，FlattenGPT 在 20% 稀疏率下零样本性能提升约 5%，保持 96% 以上性能，推理吞吐量提升 1.27×，延迟降低 1.26×；

**⚠️ 局限性**

限制：仍依赖精确的相似度估计和校准数据，极深层相似度评估可能不稳定；压缩比例受块合并粒度限制；在更大规模或非标准 Transformer 结构上的适用性需进一步验证。

---

## 943. karl. -- A Research Vehicle for Automated and Connected Driving

**arXiv ID:** 2602.08842 | [PDF](https://arxiv.org/pdf/2602.08842v1)

**作者:** Jean-Pierre Busch `[一作]` (Institute for Automotive Engineering RWTH Aachen University), Lutz Eckstein `[通讯]` (Institute for Automotive Engineering RWTH Aachen University)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文设计并搭建了一辆名为karl的可在公共道路上进行L4级自动驾驶与连通性研究的研究车辆平台。

**💡 创新点**

创新点在于将模块化机架、双层以太网、精确PTP同步、灵活操作模式和开源硬件/软件设计结合，打造出既可扩展又可在真实道路上验证的L4研究平台。

**🔧 技术方法**

主要技术包括ROS 2容器化软件栈、AMD Ryzen Threadripper与NVIDIA RTX PRO GPU的高性能计算、Ouster、Aeva、4D雷达、StereoLabs ZED X相机、RTK/GNSS‑INS定位、5G / V2X通信、PTP时钟同步及基于dSPACE/PEAK的DBW系统。

**📊 数据集**

本文未使用公开数据集，而是通过karl平台收集的原始传感器数据用于感知、预测与行为规划验证。

**📈 对比分析**

通过测量PTP时钟偏差<200 ns、感知延迟72–220 ms、功耗约1100 W、CPU 80 %负载以及DBW响应符合ISO 15622，验证系统满足L4级研究与测试需求。

**⚠️ 局限性**

局限性包括仍在获取德国公共道路测试许可、软件堆栈细节待进一步公开、对高负载实时性与完整AD堆栈性能的进一步评估尚未完成。

---

## 944. WildReward: Learning Reward Models from In-the-Wild Human Interactions

**arXiv ID:** 2602.08829 | [PDF](https://arxiv.org/pdf/2602.08829v1)

**作者:** Hao Peng `[一作]` (Tsinghua University), Juanzi Li `[通讯]` (Tsinghua University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a4b10f5d-130b-4e77-9367-6469ec621899` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建并训练了一种基于野外人机交互数据的奖励模型，直接使用交互中的隐式和显式反馈，而非传统的偏好对。

**💡 创新点**

创新点包括：①不依赖偏好对，采用五级满意度标签和阶序回归学习全局排名；②提出自动化噪声过滤、隐式反馈挖掘与拒绝验证三步管道，得到高质量的186k实例；③通过该奖励模型在在线DPO中显著提升多任务性能。

**🔧 技术方法**

技术手段：自动化标签分类（GPT‑oss‑120b）、隐式反馈挖掘与拒绝验证两阶段优化、阶序回归目标、基于奖励模型的在线Direct Preference Optimization (DPO)。

**📊 数据集**

数据集：WildChat（人机对话），基于其构建的WildReward 186k实例；Infinity‑Instruct 用于DPO训练。

**📈 对比分析**

方法比较：在RewardBench、RM‑Bench、PPE、JudgeBench等标准基准上，WildReward奖励模型与传统使用偏好对训练的RM相当甚至更好，尤其在鲁棒性、校准和跨样本一致性上优于基于Bradley‑Terry的模型；在线DPO进一步提升数学推理、指令遵循与创作写作等任务。

**⚠️ 局限性**

限制：仅覆盖英文和中文对话；未进行全面的超参数搜索或模型规模扩展；未使用该奖励模型进行RL训练；对多语言、不同文化语境下的适用性尚待验证。

---

## 945. A Methodology for Effective Surrogate Learning in Complex Optimization

**arXiv ID:** 2602.08825 | [PDF](https://arxiv.org/pdf/2602.08825v1)

**作者:** Tomohiro Harada `[一作]` (Saitama University), Gabriel Luque `[通讯]` (ITIS University of Malaga)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出 PTME 方法评估代理学习在复杂优化中的有效性，并在交通灯调度任务中进行验证。

**💡 创新点**

创新点是将精度、时间、内存、能耗四维度统一评估，并展示不同采样策略与数据规模对代理性能的影响。

**🔧 技术方法**

采用深度神经网络代理，结合拉丁超立方采样/均匀随机采样，使用 TensorFlow 训练并评估；将代理集成至粒子群优化。

**📊 数据集**

使用了三组真实城市交通灯调度实例（Stockholm、Paris 以及一小型城市）及其对应的高保真微观仿真数据。

**📈 对比分析**

通过 MAPE、RMSE、Kendall τ、CPU/DRAM 能耗、时间、内存等指标进行定量比较，结果显示数据集越大精度提升，能耗与内存呈子线性增长，推演效率稳定；代理辅助 PSO 在目标值上略逊于完整评估，但显著降低计算成本。

**⚠️ 局限性**

局限在于仅评估单一类型代理和静态模型，未考虑在线自适应重训练及多精度代理；在大样本时不同采样方法差异不显著，实验仅在单一硬件平台上完成。

---

## 946. Omni-Video 2: Scaling MLLM-Conditioned Diffusion for Unified Video Generation and Editing

**arXiv ID:** 2602.08820 | [PDF](https://arxiv.org/pdf/2602.08820v1)

**作者:** Hao Yang `[一作]` (Shanghai Academy of Artificial Intelligence for Science), Hao Li `[通讯]` (Fudan University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 Omni-Video 2，一种统一的文本到视频生成与指令驱动视频编辑模型，结合预训练的文本到视频扩散模型与大型语言模型（MLLM）进行提示推理与条件适配。

**💡 创新点**

创新点在于：①用 MLLM 生成明确的目标字幕，将原始编辑指令转化为预训练模型熟悉的文本输入；②采用统一的 4 条件（目标字幕、编辑指令、MLLM 交互特征、源视频参考）与轻量级条件适配器，最大化复用预训练先验；③在多任务、跨模态数据上实现一次性训练，无需改动扩散骨干。

**🔧 技术方法**

技术包括：预训练 DiT 文本到视频扩散骨干、Qwen 或其他 MLLM、T5 文本编码器、VAE 参考编码、跨注意力条件适配器、流式训练目标、Ulysses 风格序列并行、混合精度与梯度检查点。

**📊 数据集**

使用超过 100 万条统一格式样本，涵盖文本到图像/视频、图像/视频编辑等四大任务，融合真实视频/图像与合成数据；评测数据集包括 FiVE Benchmark（细粒度视频编辑）和 VBench（文本到视频生成）。

**📈 对比分析**

在 FiVE-Bench 上，Omni-Video 2 的 FiVE-Acc 73.53 远超最强基线 UniVideo 的 62.53，实现全指标领先；在 VBench 上，生成质量保持或优于现有开源/专有模型，说明统一扩散框架不会牺牲生成性能。

**⚠️ 局限性**

局限性包括：对预训练 MLLM 的依赖导致推理成本高；在极长或高度复杂的编辑指令下仍可能出现误解或漂移；未针对每种子任务单独 fine‑tune，部分细粒度编辑可能仍不够精准；模型规模大，部署与推理仍需高算力。

---

## 947. Bayesian Preference Learning for Test-Time Steerable Reward Models

**arXiv ID:** 2602.08819 | [PDF](https://arxiv.org/pdf/2602.08819v1)

**作者:** Jiwoo Hong `[一作]` (LinkedIn Corporation), Zhipeng Wang `[通讯]` (LinkedIn Corporation)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出Variational In‑Context Reward Modeling（ICRM）实现奖励模型在测试时通过少量示例可动态调整偏好；

**💡 创新点**

将奖励学习视为Beta后验的变分推断，利用Beta先验与KL正则化实现可调可信度并理论上抑制过度优化；

**🔧 技术方法**

贝叶斯推断、变分自编码、Beta分布后验、KL正则化、Transformer投影头以及RLHF和RLVR训练；

**📊 数据集**

Skywork‑Preferences‑v0.2（包含MagPie、WildGuard、OffsetBias、HelpSteer 2）、SafeRLHF、HHH Alignment、RM‑Bench、INTELLECT‑MATH；

**📈 对比分析**

与Bradley‑Terry、ArmoRM、GRM等基线相比，ICRM在单目标场景中SafeRLHF提升34%、RM‑Bench提升约9%，在多目标场景下Pareto前沿宽度提升4%，在RLVR中相对基线的数学推理准确率提升约0.4%；

**⚠️ 局限性**

对上下文长度有限（16,384 token）和示例数量上限（≤32）做了实验，未探讨更长上下文或更多示例的影响；

---

## 948. Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity

**arXiv ID:** 2602.08816 | [PDF](https://arxiv.org/pdf/2602.08816v1)

**作者:** James Jewitt `[一作]` (Queens University), Ahmed E. Hassan `[通讯]` (Queens University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

**🎯 论文内容**

对 AI 供应链（数据集 → 模型 → 应用）中的许可证完整性和归属追踪进行了大规模审计，揭示了“许可洗牌”（permissive washing）现象。

**💡 创新点**

首次在规模上量化许可洗牌，构建完整的 provenance graph 并公开审计数据与可复现的审计流程。

**🔧 技术方法**

结合 Hugging Face API、GitHub Code Search、Python AST 解析、ScanCode Toolkit 进行许可证文本与版权声明检测，并通过子串匹配跟踪归属传播。

**📊 数据集**

审计样本为 124,278 条完整链条，包括 3,338 个数据集、6,664 个模型和 28,516 个 GitHub 应用，涵盖 Hugging Face 与 GitHub 平台。

**📈 对比分析**

通过比较许可文本完整率、版权声明完整率和归属传播率评估结果：仅约 3% 的数据集/模型满足完整许可要求，归属传播率低于 6%，远低于传统 OSS 生态的完整率。

**⚠️ 局限性**

局限性：仅覆盖 MIT、Apache-2.0、BSD-3-Clause；检索仅基于常见文件名模式，可能漏检；仅对可追踪链条有效；归属匹配仅采用子串匹配，未考虑语义变形；未对非许可洗牌的法律影响进行深入评估。

---

## 949. How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs

**arXiv ID:** 2602.08808 | [PDF](https://arxiv.org/pdf/2602.08808v1)

**作者:** Yapei Chang `[一作]` (Allen Institute for AI), Luca Soldaini `[通讯]` (Allen Institute for AI)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一个可扩展的框架，能够从网络上挖掘、标准化并评估多主题的目标导向步骤式程序，利用LLM作为评判器并对模型进行RL优化。

**💡 创新点**

创新点包括：①大规模多主题程序挖掘流水线（14个主题、351K实例）；②基于“关键失败”定义的LLM‑as‑judge评估协议，并将其蒸馏为8B可复现的评判模型；③将该评估作为RL奖励，显著提升程序生成质量且无显著OOS退化。

**🔧 技术方法**

使用的技术包括：多阶段LLM提取与过滤（GPT‑4.1）、LLM‑as‑judge评估（GPT‑5、Qwen‑3‑8B）、强化学习（GRPO）与格式化/长度约束奖励、对比实验和人类验证。

**📊 数据集**

数据集：从980K Web文档挖掘的351K结构化程序（包含目标、资源列表、步骤），从中划分7K评估集（500例/主题）和100K训练集；对比基准集包括12个OOS任务（如MMLU、Code评测等）。

**📈 对比分析**

对比方法：使用“关键失败”成功率评估不同模型（从1B到32B、开源与封闭模型、预训练/中训练/后训练阶段）。实验显示，模型规模与训练阶段越大，成功率越高；RL后成功率提升10–13个百分点，且在OOS评测中无系统性退化。

**⚠️ 局限性**

局限性：评估仍基于参考步骤的可行性假设，无法捕捉所有执行失效；LLM评判可能存在偏好；数据来源主要为教程类网页，可能包含社会偏见与安全敏感内容；模型提升主要针对任务内部表现，跨任务泛化仍需进一步验证。

---

## 950. A Generic Service-Oriented Function Offloading Framework for Connected Automated Vehicles

**arXiv ID:** 2602.08799 | [PDF](https://arxiv.org/pdf/2602.08799v1)

**作者:** Robin Dehler `[一作]` (Ulm University), Michael Buchholz `[通讯]` (Ulm University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文提出了一个通用的面向服务的功能卸载框架 SOFOF，并在自动驾驶中的轨迹规划任务上进行了实现与评估。

**💡 创新点**

创新点在于：①将功能卸载与面向服务架构（SOA）相结合，形成可插拔的决策与管理模块；②提出基于位置的决策算法（CODM、LODM），可根据车辆位置动态切换本地/边缘轨迹规划；③通过 QoS 检查和回退机制保障服务质量。

**🔧 技术方法**

使用技术包括 ROS2 生命周期节点、AMQP V2X 通信、MEC 边缘服务器、AL‑ILQR 轨迹规划、ETSITS 消息标准（CAM、CPM、MCM）、Python/ C++ 实现的决策算法。

**📊 数据集**

数据集与实验平台：1）仿真使用基于 ROS2 的 SIL 框架，模拟多辆 CAV 在德国 Ulm‑Lehr 区域路网中的行驶；2）实测使用 Mercedes‑Benz E‑class 自动驾驶车和 MEC 服务器，5G 网络连接；未使用公开数据集，而是自行构建的路网与行车轨迹。

**📈 对比分析**

比较方法：在仿真与实测场景下分别测量 CPU 使用率、轨迹规划延迟、到达时间间隔以及 QoS 满足率；结果显示：①在仿真中，当卸载比例超过约 8% 时，车载 CPU 负载显著下降；②实测平均延迟约 12 ms，标准差 3 ms，满足 50 ms 延迟阈值；②即使在多车并发时，系统仍能维持 QoS 并实现平滑的服务切换。

**⚠️ 局限性**

局限性：①仅验证了轨迹规划功能，未覆盖更复杂的协同与感知服务；②决策算法依赖固定阈值与地图信息，易受网络抖动与实时性限制；③仿真网络与硬件资源有限，导致多车场景下的吞吐量和延迟上限受限；④缺乏安全性与鲁棒性分析，只通过 QoS 指标评估。

---

## 951. Addressing data annotation scarcity in Brain Tumor Segmentation on 3D MRI scan Using a Semi-Supervised Teacher-Student Framework

**arXiv ID:** 2602.08797 | [PDF](https://arxiv.org/pdf/2602.08797v1)

**作者:** Jiaming Liu `[一作]` (Nanjing University of Aeronautics and Astronautics), Daoqiang Zhang `[通讯]` (Nanjing University of Aeronautics and Astronautics)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

提出一种半监督教师‑学生框架，利用不确定性感知的伪标签和渐进式置信度采样，在脑肿瘤3D MRI分割中解决标注稀缺问题。

**💡 创新点**

创新点包括：①将像素级不确定性与图像级置信度相结合的伪标签生成与筛选；②引入双重损失，在高置信度像素上学习、低置信度像素进行“反学习”消除噪声；③通过教师‑学生一致性反馈动态改进伪标签；④设计融合注意力、SE、ASPP与Transformer的TransASPP‑UNet网络。

**🔧 技术方法**

采用半监督学习（教师‑学生、Pseudo‑Label）、多次推理/Dropout实现不确定性估计、渐进式自适应训练（confidence‑based curriculum）、双重损失（高置信度正向、低置信度负向）、Transformer‑增强 UNet、Dice/Cross‑Entropy 与软Dice等技术。

**📊 数据集**

使用BraTS 2021多机构多模态（T1、T1ce、T2、FLAIR）数据集，包含2000例训练/验证/测试集。

**📈 对比分析**

与教师模型、传统全监督UNet进行对比，使用Dice和IoU评估。10%标注时验证Dice仅为0.393，100%时提升至0.872；学生模型在肿瘤子区（NCR/NET 0.797, Edema 0.980, Enhancing 0.620）优于教师，显示出显著的性能提升。

**⚠️ 局限性**

局限性包括：尚未在跨中心外部数据上充分验证；阈值调度仍为固定；未结合主动学习或联邦学习进一步减少标注需求；对极低置信度区域的处理依赖手工阈值；不同扫描协议的鲁棒性仍需进一步评估。

---

## 952. A Graphop Analysis of Graph Neural Networks on Sparse Graphs: Generalization and Universal Approximation

**arXiv ID:** 2602.08785 | [PDF](https://arxiv.org/pdf/2602.08785v1)

**作者:** Ofek Amran `[一作]` (Faculty of Mathematics Technion Israel Institute of Technology), Ron Levie `[通讯]` (Faculty of Mathematics Technion Israel Institute of Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出一种统一的图运算分析框架，定义了对稀疏与稠密图都适用的紧致度量，使得消息传递图神经网络(MPNNs)在所有图尺寸上都可持续连续且可分离，从而实现了通用逼近定理和泛化界限；

**💡 创新点**

创新点在于将稀疏图的图限理论(Graphop)与1-WL/ DIDM-mover距离相结合，扩展到含节点属性的bofops，并证明其在action度量下的Lipschitz连续性与在DIDM-mover距离下的分离能力；

**🔧 技术方法**

核心技术包括图运算(Graphop)理论、action度量、DIDM-mover距离、1-WL算法、Stone–Weierstrass定理与覆盖数泛化界限；

**📊 数据集**

论文为理论工作，未使用具体数据集；

**📈 对比分析**

方法通过理论证明与比较，显示在紧致度量下MPNNs具备通用逼近能力，并且在DIDM-mover距离上满足泛化界限，性能表现由理论界限描述；

**⚠️ 局限性**

局限性包括仅适用于bofops而非一般图运算，缺乏对覆盖数的显式上界，且基于profile的实现缺乏可计算性，导致难以直接应用于实际数据。

---

## 953. FreqLens: Interpretable Frequency Attribution for Time Series Forecasting

**arXiv ID:** 2602.08768 | [PDF](https://arxiv.org/pdf/2602.08768v1)

**作者:** Chi-Sheng Chen `[一作]` (Independent Researcher), Fan Zhang `[通讯]` (Boise State University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了可解释的时间序列预测框架 FreqLens，能够学习并解释频率成分。

**💡 创新点**

创新点包括可学习的频率发现与基于频率的可证理论解释，满足完整性、忠实性、无频率、对称性四条公理，且等价于 Shapley 值。

**🔧 技术方法**

使用 sigmoid 参数化的可学习频率基、稀疏频率选择、Gumbel‑Softmax、分解后加法预测头以及残差路径，训练时加入多样性与重建正则。

**📊 数据集**

在七个公共基准数据集（ETT1/2/1/2、Weather、Traffic、Electricity）上评估。

**📈 对比分析**

与 PatchTST、iTransformer、FEDformer、Autoformer、DLinear 等先进模型比较，在周期性数据上达到或超过最佳性能，并成功自动发现日、半日、周等周期。

**⚠️ 局限性**

局限于周期性假设，低频周期收敛慢，对非周期或强非平稳序列效果下降，且需更长训练或课程学习以捕捉长周期。

---

## 954. Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems

**arXiv ID:** 2602.08847 | [PDF](https://arxiv.org/pdf/2602.08847v1)

**作者:** Lang Feng `[一作]` (Nanyang Technological University), Bo An `[通讯]` (Nanyang Technological University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

无法确定论文的具体研究内容，因未提供正文。

**💡 创新点**

无创新点可提炼。

**🔧 技术方法**

未知所使用的技术。

**📊 数据集**

未知使用的数据集。

**📈 对比分析**

无法比较方法或评估性能。

**⚠️ 局限性**

未提供信息，无法判断限制。

---

## 955. Multi-Staged Framework for Safety Analysis of Offloaded Services in Distributed Intelligent Transportation Systems

**arXiv ID:** 2602.08821 | [PDF](https://arxiv.org/pdf/2602.08821v1)

**作者:** Robin Dehler `[一作]` (Ulm University), Michael Buchholz `[通讯]` (Ulm University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文在现有的服务导向函数卸载框架(SOFOF)上，设计并实现了一套多阶段安全分析框架(MSFA)，以在分布式智能交通系统中保障车辆对远程服务的安全使用，并通过仿真验证其在攻击情境下的有效性。

**💡 创新点**

创新点：
1) 对SOA服务定义做了扩展，加入计算设备标识，支持本地与远程服务的区分；
2) 构建了多阶段安全分析流程，按服务组合动态触发轨迹验证、图像验证、轨迹-轨迹/检测/网格三重检测；
3) 将该安全分析直接嵌入SOFOF，使得卸载决策、QoS检测与数据质量检测高度耦合，能够在发现异常时立即切换回本地服务；
4) 通过攻击仿真验证了安全框架对图地图篡改、轨迹空列表、伪轨迹等多种攻击的检测能力。

**🔧 技术方法**

使用技术：
- ROS 2 + AMQP 的分布式通信；
- ETSI V2X 标准（CAM、CPM、MCM）实现车联网通信；
- 轨迹规划采用 MPC+AL‑ILQR；
- 多目标跟踪使用扩展的 LMB 过滤器；
- 轨迹验证采用欧氏距离、Hungarian 匹配、LLCC、网格膨胀等方法。

**📊 数据集**

数据集：
- 本研究仅在仿真环境（Ulm‑Lehr 真实道路布局）中使用了自行生成的车辆轨迹与传感器数据；
- 未使用公开真实数据集，全部实验基于模拟场景。

**📈 对比分析**

对比方法与性能：
- 对比基线 SOFOF（无安全框架）与 SOFOF+MSFA；
- CPU 负载：加入 MSFA 后额外占用约 0.2% CPU；
- 在三种攻击（地图篡改、空轨迹、伪轨迹）下，基线无检测，导致多次失误；加入 MSFA 后检测率分别为 100%/95%/90%（近乎全部拦截），并能及时切换回本地服务；
- 在多车仿真中，所有阶段均被触发多次，且每阶段至少一次检测到安全违规，确保无危急事故出现。

**⚠️ 局限性**

局限性：
- 仅在仿真环境验证，缺乏真实道路测试；
- 仅考虑了 MOT、ENV、TPL 三种服务，未覆盖检测、控制、地图查询等关键模块；
- 轮询攻击与更复杂的恶意行为（如持续低质量数据注入、加密破坏）未做评估；
- 采用的安全框架主要基于数据质量检测，缺少更深层次的安全/安全保证机制；
- 等待时间 t_wait 取值较短，实际部署需根据网络时延与车辆动态调整。

---

## 956. Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation

**arXiv ID:** 2602.08815 | [PDF](https://arxiv.org/pdf/2602.08815v1)

**作者:** Yanglei Gan `[一作]` (University of Electronic Science and Technology of China), Qiao Liu `[通讯]` (University of Electronic Science and Technology of China)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一种面向时间知识图谱外推的负样本感知扩散模型NADEx，利用扩散过程对目标实体嵌入进行噪声扰动并通过Transformer去噪重构；

**💡 创新点**

创新点在于将批级负样本原型引入扩散过程并设计余弦对齐正则化，既保留了生成模型的概率优势，又显著提升了判别边界；

**🔧 技术方法**

技术主要包括高斯噪声扩散、Transformer去噪网络、批量负样本采样与平均、余弦对齐正则化以及交叉熵重构损失；

**📊 数据集**

使用了四个公开时间知识图谱基准数据集：ICEWS14、ICEWS05-15、ICEWS18和GDELT；

**📈 对比分析**

在与静态、插值、外推、扩散及LLM驱动方法的广泛对比实验中，NADEx在MRR、Hits@1/3/10等指标上均取得SOTA表现，尤其在复杂的ICEWS05-15与GDELT上提升显著；

**⚠️ 局限性**

局限性包括仅在政治/国际关系类数据集上验证，且负样本采样仅限于批级平均，可能无法捕捉语义难负样本或长尾实体。

---

## 957. The Use of AI Tools to Develop and Validate Q-Matrices

**arXiv ID:** 2602.08796 | [PDF](https://arxiv.org/pdf/2602.08796v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 958. Robust Policy Optimization to Prevent Catastrophic Forgetting

**arXiv ID:** 2602.08813 | [PDF](https://arxiv.org/pdf/2602.08813v1)

**作者:** Mahdi Sabbaghi `[一作]` (University of Pennsylvania), Hamed Hassani `[通讯]` (University of Pennsylvania)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在RLHF基础模型训练中引入对后续微调的鲁棒性，提出FRPO算法以在KL球内最大化最小奖励。

**💡 创新点**

把鲁棒性框定为在KL邻域内的最大最小奖励优化，得到一个能在多任务下保持安全与能力的政策梯度方法。

**🔧 技术方法**

基于GRPO的策略梯度，结合熵风险、分区函数、Jackknife校正与基线消除方差，理论上等价于分布鲁棒优化。

**📊 数据集**

使用HarmBench、StrongREJECT评估安全；MATH、OpenCodeInstruct用于数学推理；Alpaca、UltraFeedback用于指令微调；MBPP+用于代码生成微调。

**📈 对比分析**

与GRPO、Llama‑3系列等基线对比，FRPO在安全拒绝率和StrongREJECT得分上均优于基线，且在后续代码微调中保持最高22%数学准确率，同时不损失下游任务性能。

**⚠️ 局限性**

需要手动调节λ且不同任务需不同λ；实验仅覆盖少数模型规模与RLHF设置，未评估更大模型或不同RLHF框架下的泛化，缺乏完整的收敛理论。

---

## 959. Efficient Deep Learning for Biometrics: Overview, Challenges and Trends in Ear of Frugal AI

**arXiv ID:** 2602.08809 | [PDF](https://arxiv.org/pdf/2602.08809v1)

**作者:** Karim Haroun `[一作]` (University of Paris 8), Larbi Boubchir `[通讯]` (University of Paris 8)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文综述了面向生物识别的高效深度学习（EDL）技术，系统梳理了数据中心、模型中心和部署中心三大类方法，并提出统一的评估指标框架；同时对EDL在实时身份验证、视频监控、活体检测等应用场景中的实践进行概述，并讨论了挑战与未来研究方向。

**💡 创新点**

创新点在于：①将EDL技术分为数据效率、模型效率和能量效率三维体系，并用一套多指标评估框架（FLOPs、MACs、内存、时延、吞吐量、能耗）实现跨方法、跨平台的可比性；②系统性归纳了从数据增强到蒸馏、剪枝、量化、NAS、硬件感知优化等技术的协同作用；③提出了针对生物识别场景的开放性研究议题，如动态推理、神经符号融合、标准化基准等。

**🔧 技术方法**

综述涉及的核心技术包括：数据增强（几何变换、风格迁移、GAN合成）、主动学习、半监督/自监督学习、数据蒸馏、模型剪枝、量化、知识蒸馏、轻量化架构设计（MobileNet、EfficientNet、NAS）、Transformer压缩、硬件感知优化（Edge TPU、微控制器）、早退出网络、云边协同推理等。

**📊 数据集**

文献综述未给出统一实验数据集，但引用的典型生物识别数据集包括人脸（LFW、MegaFace）、指纹（FVC系列）、虹膜（IIT Delhi）、语音等多模态数据库。

**📈 对比分析**

作者提出通过多维度指标（FLOPs/MACs、内存占用、时延、吞吐量、能耗）对模型进行统一评价，并强调指标的互补性；综述指出不同技术在保持或略微牺牲准确率的前提下，可实现数倍到十倍以上的计算/能耗降低，但具体性能提升需结合任务和硬件平台评估。

**⚠️ 局限性**

主要局限包括：①综述性质缺乏统一实验验证，无法直接比较各方法在同一数据集/平台上的绝对性能；②评估指标与硬件平台之间缺乏标准化基准，导致结果不可直接复现；③准确率-效率折衷、泛化与鲁棒性、攻击安全性、以及硬件-软件协同设计等关键问题仍待深入解决。

---

## 960. Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures

**arXiv ID:** 2602.08804 | [PDF](https://arxiv.org/pdf/2602.08804v1)

**作者:** Liming Zhou `[一作]`, Heng Zhang `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出一种基于残差连接结构的LLM框架RC‑LLM，用于在大规模微服务系统中进行根因分析。

**💡 创新点**

创新点在于将多源监控数据（trace、metric、log）通过残差式分层融合后输入LLM进行结构化推理，解决了传统方法无法充分利用跨源时空因果关系的问题，并在无报警锚点的开放式RCA任务中得到验证。

**🔧 技术方法**

使用技术包括PyArrow读取Parquet、UTC时间标准化与分层聚合、统计阈值+PELT变点检测、gRPC状态码分析、残差融合机制，以及DeepSeek‑V3（671B）LLM配合LangChain的PromptTemplate与StructuredOutputParser实现结构化推理。

**📊 数据集**

实验数据集为CCF AIOps 2025 Root Cause Analysis Challenge 数据集，基于HipsterShop+TiDB的微服务架构，包含400个注入故障。

**📈 对比分析**

与直接将原始数据喂给LLM、仅用metric、仅用trace等方法对比，RC‑LLM的准确率从23.75%提升至48.25%，推理步数从6.2降至3.4，表明在准确性与推理效率上都有显著提升。

**⚠️ 局限性**

主要局限包括：在节点级根因定位上精度不足，缺乏足够的细粒度指标与日志语义导致对同一服务多副本的误判；以及在极为复杂的故障场景下，缺乏外部知识库检索仍可能影响推理效果。

---

## 961. Impredicativity in Linear Dependent Type Theory

**arXiv ID:** 2602.08846 | [PDF](https://arxiv.org/pdf/2602.08846v1)

**作者:** Sam Speight `[一作]`, Niels van der Weide `[通讯]` (Radboud University Nijmegen)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c`

**🎯 论文内容**

构造了基于线性组合代数的线性依赖型理论（LDTT）的可实现性模型，并在此模型中引入了兼容线性与笛卡尔类型的不可预测宇宙以及等化子类型，进而实现了线性列表初等代数的初等代数化；

**💡 创新点**

创新点包括：①提出了同时作用于笛卡尔和线性类型的不可预测Tarski风格宇宙；②引入了等化子类型和模态的可注入性公理以支持更完整的类型构造；③将线性组合代数与线性理解论结合，构建了线性理解模型；④利用不可预测编码改进了线性列表的初等代数构造；

**🔧 技术方法**

主要技术手段包括线性组合代数、可实现性解释、线性理解类别（linear comprehension categories）、对称单子模范、以及在Coq中的形式化证明；

**📊 数据集**

该工作不涉及实验数据或数据集，全部为理论构造与形式化；

**📈 对比分析**

论文未给出与其它模型的量化比较，仅通过在Coq中形式化验证了模型的一致性与类型构造的完整性；

**⚠️ 局限性**

局限性：仅在外延式线性依赖型理论下有效，需注入性公理；目前仅实现了列表的初等代数，对更一般的递归/共递归类型仍需进一步研究；未覆盖强度化或量化类型系统；

---

## 962. How Should We Model the Probability of a Language?

**arXiv ID:** 2602.08951 | [PDF](https://arxiv.org/pdf/2602.08951v1)

**作者:** Rasul Dent `[一作]` (Inria), Benoît Sagot `[通讯]` (Inria)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文分析了语言识别（LID）覆盖不足的根源，指出传统把LID视为无上下文的文本分类导致的局限，并提出将LID视为路由问题，利用本地上下文推断本地先验，从而提升对长尾语言的识别覆盖。

**💡 创新点**

创新点在于重新框定LID任务：将其从单一全局先验的贝叶斯分类转变为基于本地先验的路由决策；并提出在推理阶段用上下文门控替代全局先验的简单技术，避免对模型结构进行大幅改动。

**🔧 技术方法**

技术核心是基于朴素贝叶斯的贝叶斯框架，加入本地先验门控（硬门或软门），以及利用已有的文本特征与脚本分类预处理；不引入新的网络架构或训练策略。

**📊 数据集**

论文主要讨论了常见公开语料（Wikipedia、圣经、新闻文本）以及短文本数据集如FLORES‑200、GlotLID‑C，并通过社交媒体实例（Louisiana Creole 讨论组）展示本地先验的应用。

**📈 对比分析**

由于缺乏大规模实验，论文未给出定量性能指标；通过理论推导和案例展示说明本地先验能显著降低误识率、提升长尾语言覆盖，但未在标准基准上进行对比。

**⚠️ 局限性**

局限性包括：未进行实证验证，无法量化动态先验对性能的真实提升；依赖于可获取的上下文元数据，可能受隐私与数据获取限制；对极端低资源语言仍需更多语言学专业知识。

---

## 963. pixelLOG: Logging of Online Gameplay for Cognitive Research

**arXiv ID:** 2602.08941 | [PDF](https://arxiv.org/pdf/2602.08941v1)

**作者:** Zeyu Lu `[一作]` (Washington University in St. Louis), Dennis L. Barbour `[通讯]` (Washington University in St. Louis)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了pixelLOG，一个高性能的Minecraft服务器插件，用于在多玩家环境中以高频率记录人类行为和游戏事件。

**💡 创新点**

创新点在于将过程导向的、高频率的主动状态采样与被动事件捕获结合，实现对人类认知过程的实时、细粒度监测，并支持多玩家并发和结构化JSON输出。

**🔧 技术方法**

使用技术包括Spigot插件架构、线程安全队列、调度器实现多频率采样、事件监听器、JSON序列化以及TCP传输模块。

**📊 数据集**

主要数据集为在pixelLOG记录的Minecraft玩家行为日志；在相关工作中也用于pixelDOPA和AMLEC研究。

**📈 对比分析**

与现有仅面向AI代理的框架（如Project Malmo、MineDojo）相比，pixelLOG在人类数据收集上实现了20Hz以上采样率，且数据完整性和可扩展性更高，具体性能表现为无明显丢包、支持数十名玩家并发。

**⚠️ 局限性**

限制包括依赖Minecraft服务器与Spigot插件，对非Java版或其他游戏环境适用性有限，以及对非常大规模玩家数时仍可能出现性能瓶颈。

---

## 964. DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories

**arXiv ID:** 2602.08887 | [PDF](https://arxiv.org/pdf/2602.08887v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df`

---

## 965. No Word Left Behind: Mitigating Prefix Bias in Open-Vocabulary Keyword Spotting

**arXiv ID:** 2602.08930 | [PDF](https://arxiv.org/pdf/2602.08930v1)

**作者:** Yi Liu `[一作]`, Xiao Quan `[通讯]`

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究了开放词汇关键词检测（OV-KWS）在部分重叠短语下的失效问题，提出了新的评测基准和改进模型

**💡 创新点**

提出Partial Overlap Benchmark（POB）两套数据集和轻量级的Equal‑weighting Position Scoring（EPS）层以消除首词偏置

**🔧 技术方法**

使用多模态音频‑文本联合嵌入、交叉注意力/自注意力对齐、CTC辅助学习与EPS层

**📊 数据集**

利用LibriPhrase、Google Speech Commands、SPARK‑TTS合成的POB‑Spark以及LibriPhrase衍生的POB‑LP

**📈 对比分析**

与SLiCK和PhonMatchNet在原始LibriPhrase、GSC以及新的POB数据集上对比，EPS单独使用将POB‑Spark EER从64.4%降至29.3%，POB‑LP准确率从87.6%升至96.8%；加上POB训练后性能进一步提升但在GSC上略有退化

**⚠️ 局限性**

在引入POB数据时与短语长度分布冲突导致对单词级指令（如GSC）的性能下降，未来需更精细的数据平衡和权重正则化

---

## 966. Analysis of Converged 3D Gaussian Splatting Solutions: Density Effects and Prediction Limit

**arXiv ID:** 2602.08909 | [PDF](https://arxiv.org/pdf/2602.08909v1)

**作者:** Zhendong Wang `[一作]` (Santa Clara University), Nam Ling `[通讯]` (Santa Clara University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

系统分析了3D Gaussian Splatting在多视角优化下的收敛解，提炼出渲染最优参考（ROR），并通过统计分析、可学习性探针与方差分解揭示了密度相关的结构与预测极限。

**💡 创新点**

发现3DGS解存在密度分层结构，稠密区可通过几何观测直接推断参数，稀疏区需视角约束；提出可学习性探针与方差分解框架解释渲染无监督预测失败，并给出密度感知的训练与体系架构建议。

**🔧 技术方法**

多视角渲染优化、3D Gaussian Splatting参数统计、Transformer/点体素CNN的渲染无监督预测、方差分解与可视化、密度感知正则化与分离优化。

**📊 数据集**

Mip-NeRF 360数据集（15场景）以及其他多视角场景。

**📈 对比分析**

使用多种架构（Transformer、Point‑Voxel CNN）在不同密度块进行渲染无监督预测，测量MSE。稠密区提升约80%，稀疏区仅提升约33%；对比耦合与解耦优化，解耦在稀疏区降低约20%误差，提升训练稳定性。

**⚠️ 局限性**

在稀疏区仍受信息缺失限制，渲染无监督预测无法突破；密度阈值未精确定义；仅在静态场景验证，动态/可变形场景未知。

---

## 967. Rethinking IPv6 Defense: A Unified Edge-Centric Zero-Trust Data-Plane Architecture

**arXiv ID:** 2602.08891 | [PDF](https://arxiv.org/pdf/2602.08891v1)

**作者:** Walid Aljoby `[一作]` (King Fahd University of Petroleum and Minerals), Khaled A. Harras `[通讯]` (Carnegie Mellon University)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2`

**🎯 论文内容**

设计并实现了一条统一的、零信任的 IPv6 边缘防御数据平面管线，能够一次性检测并拦截外部/内部欺骗和洪泛攻击。

**💡 创新点**

创新点在于：① 将欺骗检测（基于前缀 Hop‑Limit 匹配与内部地址–端口绑定）与洪泛监控（基于 Count‑Min Sketch 的窗口计数）融合到同一条可编程管线；② 在进行流量计数前先做无状态身份验证，防止被伪造流量污染统计；③ 采用前缀级 HL 区间而非每地址表，满足 IPv6 大规模地址空间的可扩展性。

**🔧 技术方法**

使用技术包括 P4 编程、Netronome NFP‑4000 SmartNIC、BMv2 仿真器、Count‑Min Sketch、前缀 Hop‑Limit 区间表、DAD/NS 绑定表、窗口计数与阈值检测、Bloom‑Filter 限制地址学习。

**📊 数据集**

实验数据集为 15 个组合攻击场景（单向、双向、多向），包含 5 个 ISP /32 前缀和多层内部 /48 /56 /64 前缀的 IPv6 拓扑，利用 Mininet/Netronome 生成真实 ND、ICMPv6 与 TCP 流量。

**📈 对比分析**

与传统单向防御方法相比，论文在 BMv2 上平均 F1 约 94.3%，在 SmartNIC 上平均 F1 约 99.5%；在所有场景中精度保持在 98‑100%，召回率 88‑100% 之间，显示出低误报且对多向攻击具有良好检测能力。

**⚠️ 局限性**

局限性包括：阈值静态，难以适应工作负载波动；仅使用轻量级可信度验证，缺乏加密认证；SmartNIC 的寄存器和管线空间受限，限制了可扩展特性。

---

## 968. AnomSeer: Reinforcing Multimodal LLMs to Reason for Time-Series Anomaly Detection

**arXiv ID:** 2602.08868 | [PDF](https://arxiv.org/pdf/2602.08868v1)

**作者:** Junru Zhang `[一作]` (Zhejiang University), Duanqing Xu `[通讯]` (Zhejiang University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `5a41884c-404f-4688-a89c-aa238c10fe68` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

在多模态大语言模型基础上，提出了 TimerPO RL 后训练方法，利用专家链式思维（ExpCoT）强化时序推理，提升时间序列异常检测与解释。

**💡 创新点**

创新点在于将经典 TSAD 统计分析作为专家思维生成监督，并通过最优传输构造时间序列推理奖励，在 RL 优化中做正交化，既提升细粒度推理又不干扰主任务。

**🔧 技术方法**

使用技术包括多模态 LLM（Qwen2.5‑VL 3B/7B）、图像化时间序列、Expert CoT 生成、TimerPO（GRPO+OT 奖励+正交化）以及最优传输（Sinkhorn）算法。

**📊 数据集**

数据集：合成 AnomLLM（训练集），混合 Real‑Synthetic VisualTimeAnomaly 与真实 TSB‑UAD（评估集）。

**📈 对比分析**

与 GPT‑4o、Gemini‑2.5‑Pro、SigLLM、TimeMaster 等基线对比，模型在 AnomLLM 的 Affinity‑F1、异常类型分类准确率上均显著提升，尤其在频率、趋势等细粒度异常上表现突出，7B 版本比 3B 更好。

**⚠️ 局限性**

局限：目前仅处理单变量时间序列，未扩展到多变量场景；RL 训练耗时且对超参数（如 α）敏感；缺乏对外部知识的充分利用，导致对更复杂异常的解释能力有限。

---

## 969. Grow with the Flow: 4D Reconstruction of Growing Plants with Gaussian Flow Fields

**arXiv ID:** 2602.08958 | [PDF](https://arxiv.org/pdf/2602.08958v1)

**作者:** Weihan Luo `[一作]` (University of Toronto), David B. Lindell `[通讯]` (Vector Institute)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `a8e75ba4-7a2d-4153-b003-06c94533add0` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5a41884c-404f-4688-a89c-aa238c10fe68` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

本文提出一种基于 3D 高斯原语与神经 ODE 的连续时间流场方法，用多视角时间序列图像重建植物生长过程中的高精度三维几何。

**💡 创新点**

创新点在于：①将 3D 高斯拆解为可随时间连续演化的参数，并通过神经 ODE 学习其速度场；②采用逆向生长（从成熟状态逆向收缩）实现新结构的连续出现；③引入 HexPlane 空间‑时间编码器与多阶段优化策略，提升几何连续性与收敛稳定性。

**🔧 技术方法**

使用的技术包括：3D Gaussian Splatting、神经 ODE（Runge‑Kutta 数值积分）、HexPlane 编码器、MPL 解析器、三阶段训练（静态、边界、全局）以及对比损失（L1、SSIM、Chamfer 距离）。

**📊 数据集**

使用数据集：①基于 Blender 合成的七个植物生长场景的多视角时序数据；②真实拍摄的开花花朵与玉米植物时序图像，采用 Raspberry Pi 旋转台拍摄得到的 360° 覆盖视图。

**📈 对比分析**

与 Dynamic 3DGS、4D‑GS、4DGS 等现有动态重建方法对比，本文在 PSNR、SSIM、LPIPS 以及 Chamfer 距离等指标上均取得明显优势，特别是在未训练的插值时刻保持了更好的几何连贯性与视觉质量。

**⚠️ 局限性**

局限性：假设植物生长始终为单向增量，无法处理叶片衰老、剪裁或结构消亡等退化现象；未来工作需放宽单调增长假设，并引入生物学先验以捕获更复杂的生长与衰亡模式。

---

## 970. How University Disability Services Professionals Write Image Descriptions for HCI Figures Using Generative AI

**arXiv ID:** 2602.08937 | [PDF](https://arxiv.org/pdf/2602.08937v1)

**作者:** Muhammad Raees `[一作]` (Rochester Institute of Technology), Garreth W. Tigwell `[通讯]` (Rochester Institute of Technology)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究了辅助障碍服务办公室专业人士使用生成式 AI 写科学图表的 alt‑text 的工作流程，并通过 HCI 领域专家评估其质量。

**💡 创新点**

首次系统探讨非领域专家（DSO 专业人士）在无 AI 与 AI 辅助下的 alt‑text 生成差异，并证明 AI 辅助可显著提升文本准确性、完整性和可读性，但仍需人工校验。

**🔧 技术方法**

采用 ChatGPT‑4o 作为生成式 AI，并结合人机交互日志、主题分析和定量评估技术。

**📊 数据集**

使用 16 张来自四篇 CHI 2025 论文的 HCI 科学图表（按复杂度划分）共 12 份 alt‑text，进一步筛选 24 份供专家评估。

**📈 对比分析**

通过对比 HAI‑Text 与 Human‑Text 的五项质量指标（准确性、完整性、清晰度、有效性、描述性）及 Mann‑Whitney 检验，发现 AI 辅助文本在所有指标上均显著优于纯人工文本，p 值均 < 0.01。

**⚠️ 局限性**

限制包括样本量有限、仅关注 HCI 领域、仅使用单一 LLM、未直接收集盲文用户反馈，以及对 AI 生成信息误差缺乏完整的纠错机制。

---

## 971. AMS-HD: Hyperdimensional Computing for Real-Time and Energy-Efficient Acute Mountain Sickness Detection

**arXiv ID:** 2602.08916 | [PDF](https://arxiv.org/pdf/2602.08916v1)

**作者:** Abu Masum `[一作]` (University of Louisiana at Lafayette), Sercan Aygun `[通讯]` (University of Louisiana at Lafayette)

**关键词:** `847a60d8-a755-47af-ba5d-c5236b9e3083` `3855fcda-48ef-4070-a15e-803cd5c84d83` `64443552-63e0-44b5-906f-d90fe95c5a1b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种基于超维度计算（HDC）的实时急性高山病检测框架，可在可穿戴设备和嵌入式平台上实现连续监测

**💡 创新点**

首次将HDC与位置编码、Hadamard/Hadamard准随机序列相结合，构建低功耗双极/二进制模型，实现二分类与多分类，显著提升能效与速度

**🔧 技术方法**

超维度计算（HDC）神经符号架构、Hadamard矩阵编码、Sobol准随机序列、轻量级硬件实现（FPGA、ARM Cortex‑A9）、可穿戴设备+手机协同

**📊 数据集**

使用Pham等公开的血液及生理参数数据集（SpO₂、HR、CO等），并在Christopher与Berger等已有AMS实验数据集上进行验证

**📈 对比分析**

与传统SVM、MLP等机器学习模型以及SOTA数据集比较，二分类精度达84%，三分类精度达69%；在FPGA上比MLP节省48% LUT、34% FF，功耗降至1.7W；在手机上耗电1%，内存60B，推理时间约2.5ms

**⚠️ 局限性**

局限在于仅利用SpO₂、HR等少量可穿戴传感器，缺乏多模态环境或血压等信息；对极端噪声仍有限制；样本量有限，需进一步验证泛化能力

---

## 972. Positive Distribution Shift as a Framework for Understanding Tractable Learning

**arXiv ID:** 2602.08907 | [PDF](https://arxiv.org/pdf/2602.08907v1)

**作者:** Marko Medvedev `[一作]` (University of Chicago), Nathan Srebro `[通讯]` (Toyota Technological Institute at Chicago)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出正向分布偏移（Positive Distribution Shift, PDS）的理论框架，并在此框架下分析了在分布不匹配的训练分布上使用梯度下降学习难解概念类（如带噪声的 parity、junta、稀疏多项式等）的可行性，给出了可实现的算法、可分析的梯度下降方法以及在模拟数据上的实验验证。

**💡 创新点**

创新点在于：①将分布偏移视为有利因素而非负面影响；②引入 PDS 学习定义并证明在合适的训练分布下，原本在 PAC 模型下计算难以学习的函数类可在多项式时间内被梯度下降学习；③提出 DS-PAC 这一更细粒度的学习模型，将非适应性查询（NA-MQ）与 PDS 对接；④在同一测试分布上通过训练分布的巧妙设计，显著提升学习效率与收敛速度。

**🔧 技术方法**

技术手段包括：统计学习理论中的分布偏移分析、傅里叶分析、统计查询（SQ）和相关统计查询（CSQ）模型、可分析的层级梯度下降（layer‑wise SGD）与正规化技术、对稀疏函数的特征选择、以及实验中使用的标准梯度下降（SGD）与 ReLU/线性网络。

**📊 数据集**

使用的主要数据集为合成数据：±1ⁿ 维向量，均匀分布或带偏置的产品分布；在实验中对 k‑sparse parity（如 25‑bit）和 k‑junta（如 9‑junta）进行标签噪声实验，训练分布分别为均匀、偏置或其混合。

**📈 对比分析**

与传统的“同分布训练”进行对比。实验结果表明，在 PDS 设置下，梯度下降在更少的迭代次数内即可达到与 Bayes 限界相近的误差；而无偏移训练需数倍甚至数十倍迭代才能收敛。理论分析进一步给出了样本复杂度与时间复杂度的多项式上界，证明了 PDS 在特定分布选择下可将原本指数难题化为多项式可解。

**⚠️ 局限性**

局限性包括：①许多理论结果需要训练分布依赖于目标函数，实际应用中难以构造；②部分可行算法使用了非标准网络结构或初始化，无法直接迁移到常规深度网络；③对极端噪声或高维稀疏函数的可扩展性尚未充分验证；④仍缺乏对全功能网络在 PDS 下的理论保证，未来需进一步研究更广泛的函数类与更实用的训练分布。

---

## 973. GSS: Gated Subspace Steering for Selective Memorization Mitigation in LLMs

**arXiv ID:** 2602.08901 | [PDF](https://arxiv.org/pdf/2602.08901v1)

**作者:** Xuanqi Zhang `[一作]` (University of British Columbia), Xiaoxiao Li `[通讯]` (University of British Columbia)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于激活子空间的门控调节方法（GSS），在推理阶段通过检测并仅在出现记忆化行为时抑制隐藏状态中的记忆化成分，从而减少大型语言模型对训练数据的逐字回放。

**💡 创新点**

创新点在于把记忆化检测与纠正解耦，采用低秩子空间探测（probe）与方向性纠正（steer）配对，并通过对记忆化矩阵与通用协方差的广义奇异值分解得到最优子空间，实现可解释且高效的门控干预。

**🔧 技术方法**

使用的技术包括：token‑level 记忆化信号（log‑likelihood 比值）、激活空间的子空间投影、对记忆化矩阵与通用协方差的广义奇异值分解、门控机制与自适应缩放，以及在推理时对隐藏状态的线性插值修正。

**📊 数据集**

主要数据集包括 TinyMem（包含多种数学与语言子任务）、Pythia‑2.8B 与 Pythia‑6.9B（自回归语言模型）、Llama‑3.2‑1B 与 Qwen‑3‑0.6B 在 GSM8K（推理）和 UltraChat（对话）基准上的 fine‑tuning 数据。

**📈 对比分析**

与基线（如无干预、参数级去记忆、权重剪枝、激活剪枝、AlphaSteer、Lunar 等）比较，GSS 在四个基准上几乎完全消除记忆化（≤0%），同时保持或略提升任务准确率/困惑度；在推理时延上几乎无开销（<0.01 s）并明显快于其他方法。

**⚠️ 局限性**

局限性：目前仅在单层或少数层进行子空间投影，对跨层记忆化的捕捉有限；子空间维度需要经验调优；在极端多样化或极长记忆序列时，门控阈值和子空间维度的选择可能影响效果；此外，方法主要针对逐字记忆化，对其他形式的隐式记忆（如分布式编码）尚未验证。

---

## 974. Large Language Models for Geolocation Extraction in Humanitarian Crisis Response

**arXiv ID:** 2602.08872 | [PDF](https://arxiv.org/pdf/2602.08872v1)

**作者:** G. Cafferata `[一作]`, M. G. Beiró `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

利用大型语言模型（LLM）构建两步地理位置抽取框架，结合少量示例的NER和基于上下文的Agent地理编码；

**💡 创新点**

将LLM与Agent相结合实现公平性提升，同时通过动态对齐与多格式输出改进定位精度；

**🔧 技术方法**

采用少量提示式GPT‑5/4o、Claude等LLM进行NER，LangChain+GeoNames实现Agent地理编码；

**📊 数据集**

使用改进版HumSet（英文报文）共8,213个地名注解；

**📈 对比分析**

与SpaCy、RoBERTa、规则式基线对比，LLM在精度、召回与公平性指标上均优越，尤其在低收入与全球南方地区表现显著提升；

**⚠️ 局限性**

仍存在残余空间偏差、对非英文/低资源语言的适应性不足、以及Agent对上下文过度细化导致的误判。

---

## 975. Understanding Dynamic Compute Allocation in Recurrent Transformers

**arXiv ID:** 2602.08864 | [PDF](https://arxiv.org/pdf/2602.08864v1)

**作者:** Ibraheem Muhammad Moosa `[一作]`, Wenpeng Yin `[通讯]` (Pennsylvania State University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

研究了基于Recurrent Transformer的Token级自适应计算，提出ANIRA框架并在可控复杂度任务上进行评估

**💡 创新点**

①提出可控复杂度评价范式，②设计ANIRA统一框架并区分早期深度决策与在线停机决策，③系统分析计算分配与算法复杂度的一致性及泛化性

**🔧 技术方法**

Recurrent Transformer、深度决策网络、在线停机决策、Gumbel‑Softmax、KL 正则化、KV 缓存优化、注意力机制

**📊 数据集**

算法任务：MANO、BREVO、CLRS-Text；合成语言：LANO；自然语言数学问答：Nemotron‑CC‑Math‑v1‑4plus 与 GSM‑Symbolic

**📈 对比分析**

在可控任务上对比不同决策模式，发现ANIRA‑O 通常能在保持相同精度的情况下减少平均深度；在CLRS任务中表现出与输入规模相关的准确率下降；在GSM‑Symbolic实验中，ANIRA 通过可变深度显著降低计算量，但对更难的子集并未显著提升性能

**⚠️ 局限性**

自适应计算与算法复杂度的关联仅在可观测的、可控任务中显著；在自然语言任务中难以解释计算分配且缺乏与难度的直接对应；模型对未见输入规模的泛化能力有限

---

## 976. Near-optimal Swap Regret Minimization for Convex Losses

**arXiv ID:** 2602.08862 | [PDF](https://arxiv.org/pdf/2602.08862v1)

**作者:** Lunjia Hu `[一作]` (Northeastern University), Yifan Wu `[通讯]` (Microsoft Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出了一种随机在线算法，在单调凸损失函数下实现了近最优的O(√T)期望交换损失；

**💡 创新点**

创新点是引入多尺度分箱（multi‑scale binning）并结合全局诚实预测（truthful predictor），在不需要先验信息的情况下同时控制采样误差与舍入误差，突破了以往O(T^{2/3})的上限；

**🔧 技术方法**

核心技术包括：
1) V‑形损失分解将任意1‑Lipschitz凸损失拆成 |p−v| 的组合；
2) 多尺度分箱策略，根据分布宽度动态选择细粒度或粗粒度区间；
3) 采用极小极大（minimax）定理对顺序对调的游戏进行分析；
4) 多目标学习与MsMwC专家算法实现效率保证；
5) 大数与马尔可夫集中，控制高概率误差；

**📊 数据集**

论文主要为理论研究，未使用任何实测数据集；
（若需要实验验证，可在模拟环境中采样不同分布的v生成对应的V‑形损失进行验证）

**📈 对比分析**

与之前的O(T^{2/3})在线交换损失最小化算法对比，所给算法在期望和高概率下均达到O(√T)（乘以O(logT)因子），在效率上亦实现了O(T)的线性时间；在对标平均损失和量化调度等任务中，校准误差也得到O(√T)的改进；

**⚠️ 局限性**

局限性包括：
• 仅适用于单维单位区间上的1‑Lipschitz凸损失；
• 需假设对每轮的损失分布可视为V‑形分布；
• 结果中存在对数因子O(logT)，若对常数敏感可能不理想；
• 对高维决策空间或非凸损失尚未扩展；

---

## 977. ZK-Rollup for Hyperledger Fabric: Architecture and Performance Evaluation

**arXiv ID:** 2602.08870 | [PDF](https://arxiv.org/pdf/2602.08870v1)

**作者:** Sania Siddiqui `[一作]` (Birla Institute of Technology and Science), Hari Babu K `[通讯]` (Birla Institute of Technology and Science)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

**🎯 论文内容**

实现并评估了基于 ZK‑Rollups 的 Hyperledger Fabric Layer‑2 扩展，实现了离线 Sequencer 与 Poseidon‑Merkle 树及 PLONK ZK‑SNARK 证明。

**💡 创新点**

首次在 Hyperledger Fabric 上设计专门的 Layer‑2 ZK‑Rollup，拆分交易摄取与结算，并使用 Merkle 根 + 证明显著提升吞吐量。

**🔧 技术方法**

使用 Hyperledger Fabric、Kubernetes、Redis、IPFS、Poseidon 哈希、PLONK ZK‑SNARK、k6 负载测试。

**📊 数据集**

实验采用本地 KinD 集群环境（8 CPU、8 GB RAM），随机生成资产请求，未使用公开数据集。

**📈 对比分析**

通过 k6 对比 baseline（直接链上交易）与 Rollup（离线摄取）两种工作负载，吞吐量从 5–7 TPS 提升至 100+ TPS，客户端延迟从约 3 s 降至 300–400 ms。

**⚠️ 局限性**

主要瓶颈在 ZK‑证明生成时间（35–45 秒），导致结算吞吐受限；可通过 GPU/FPGA 加速解决。

---

## 978. CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute

**arXiv ID:** 2602.08948 | [PDF](https://arxiv.org/pdf/2602.08948v1)

**作者:** Chen Jin `[一作]` (AstraZeneca), Philip Teare `[通讯]` (AstraZeneca)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 CoRefine，一个通过置信度引导的自我迭代改进框架，利用轻量级 Conv1D 控制器在冻结 LLM 上实现高效推理。

**💡 创新点**

将置信度视为控制信号而非准确度估计，学习三种动作（HALT、RETHINK、ALTERNATIVE），实现仅约 190 倍 token 节省同时保持或提升准确率。

**🔧 技术方法**

采用置信度提取、Conv1D 控制器、合成提示、CoRefine‑Tree 混合并行-序列搜索以及基于监督的标签生成技术。

**📊 数据集**

使用 AIME 2024/25、BRUMO25、HMMT25 和 BixBench 数据集，模型包括 DeepSeek‑8B、Qwen3‑32B、PaCoRe‑8B。

**📈 对比分析**

与 512/20 采样自一致性和 DeepConf 基线对比，在大多数基准上实现相当或更优准确率，token 消耗下降 62–286×，平均仅需 2.7 次迭代，提升 60%+ 的实时速度。

**⚠️ 局限性**

依赖离线轨迹与人工标签，置信度校准不足可能导致错误决策，主要评估聚焦于数学推理，跨领域泛化仍待验证。

---

## 979. "I Don't Trust Any Professional Research Tool": A Re-Imagination of Knowledge Production Workflows by, with, and for Blind and Low-Vision Researchers

**arXiv ID:** 2602.08925 | [PDF](https://arxiv.org/pdf/2602.08925v1)

**作者:** Omar Khan `[一作]` (University of Illinois Urbana-Champaign), JooYoung Seo `[通讯]` (University of Illinois Urbana-Champaign)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文通过混合方法研究，调查并访谈了57名盲视障（BLV）研究者，系统分析其研究工作流程中的可访问性障碍，并以活动理论为框架阐释了这些障碍的系统性矛盾；

**💡 创新点**

创新点在于首次从BLV研究者视角全面记录工作流程中的可访问性挑战、工作绕行与协作策略，揭示商业工具生态与学术评估标准中的结构性歧视，并提出以通用设计为核心的可持续改进建议；

**🔧 技术方法**

研究技术包括问卷调查（Likert量表、工具使用情况）、半结构化访谈、反射性主题分析以及活动理论的六要素框架；在讨论中也引用了大型语言模型（LLM）等AI工具的可访问性应用；

**📊 数据集**

数据集为57名BLV研究者的问卷响应数据和15份访谈文本，涵盖研究阶段、工具使用、障碍评估等信息；

**📈 对比分析**

本文未进行传统意义上的方法性能对比，而是通过量化问卷与质性访谈结果对比，识别出研究生命周期中最困难的环节（数据分析与可视化、文献检索）并说明其对工作效率与职业发展的影响；

**⚠️ 局限性**

局限性包括样本来源于视障组织招募，可能偏向资源获取较好的研究者；研究聚焦数字工具，未覆盖实验室设备、现场调查、会议物理环境等；为单跨截面设计，缺乏纵向变化与因果分析。

---

## 980. GEMSS: A Variational Bayesian Method for Discovering Multiple Sparse Solutions in Classification and Regression Problems

**arXiv ID:** 2602.08913 | [PDF](https://arxiv.org/pdf/2602.08913v1)

**作者:** Kateřina Henclová `[一作]` (Datamole), Václav Šmídl `[通讯]` (Czech Technical University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出 GEMSS，一种变分贝叶斯框架，能够在 n≪p、特征高度相关的情形下同时发现多组稀疏特征子集。

**💡 创新点**

创新点在于将稀疏性诱导的结构 spike-and-slab 先验与多模态高斯混合后验近似相结合，并在单一目标函数中通过 Jaccard 惩罚实现多样性优化，避免逐步贪心导致的解空间限制。

**🔧 技术方法**

使用技术包括结构化 spike-and-slab 先验、混合高斯变分推断、KL 散度 ELBO、Jaccard 相似度正则、Adam 随机梯度优化，并原生处理缺失值。

**📊 数据集**

数据集：主要使用 128 次合成实验（覆盖 7 个层级），包括分类和回归；另外在实际的食品科学二分类数据上做了初步验证。

**📈 对比分析**

与现有的贪心 Lasso、Sequential Lasso、ALFESE 等方法对比，在合成基准上 GEMSS 在样本不足、高维、噪声、缺失和类别不平衡等场景下都能保持较高召回/精确/ F1（如高维 p=5000, n=50 时 F1≥0.97），并在不平衡分类上表现出色。

**⚠️ 局限性**

局限在于仅在线性假设下验证，未对真实非线性数据评估；对高缺失率 (>20%) 的鲁棒性有限；以及相较于贪心方法计算成本更高。

---

## 981. Scalable Delphi: Large Language Models for Structured Risk Estimation

**arXiv ID:** 2602.08889 | [PDF](https://arxiv.org/pdf/2602.08889v1)

**作者:** Tobias Lorenz `[一作]` (CISPA Helmholtz Center for Information Security), Mario Fritz `[通讯]` (CISPA Helmholtz Center for Information Security)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并实现了 Scalable Delphi——一种使用大语言模型代替人工专家面板进行结构化风险估计的自动化方法。

**💡 创新点**

创新点在于：①将传统 Delphi 协议迁移至 LLM 并通过多样化专家角色、迭代反馈与理据共享实现可扩展性；②构建针对不可观测量的评估框架，侧重校准、证据敏感性与人类专家一致性；③证明 LLM 在高风险域（AI 增强网络安全）中可产生可审计、可重现且成本低的概率估计。

**🔧 技术方法**

技术：多模态 LLM 代理（GPT‑5.1、Claude Opus 4.1）+ 人格化提示 + 迭代 Delphi 轮次 + 线性意见池聚合 + 评估指标（Pearson/Spearman 相关、MAE、平均绝对误差、与人类专家的平均绝对差）。

**📊 数据集**

数据集：BountyBench、Cybench、CyberGym 三大安全基准，用于留一预测；以及一项独立人类专家 Delphi 调查，用于对照。

**📈 对比分析**

比较方法：在基准上进行留一预测，计算 Pearson、Spearman 相关和 MAE；在人类专家对照中比较 LLM 与两组人类专家的平均绝对差。性能表现：LLM 与基准真实值的相关系数均在 0.87–0.95 之间，MAE 低于基线；与人类专家相比，LLM 与 Panel A 的平均绝对差为 5.0pp，低于人类两组间的 16.6pp 差距，显示出更高的相似度。

**⚠️ 局限性**

局限性：无法直接验证对真正不可观测量的准确性；评估仅基于可观测代理性能、信息敏感性和人类一致性，未覆盖实际攻击结果；可能受到基准数据、模型知识截止时间及潜在记忆偏差的影响；在高度动态或对抗性环境下，LLM 的推理可能缺乏对新威胁的适应性。

---

## 982. Is Reasoning Capability Enough for Safety in Long-Context Language Models?

**arXiv ID:** 2602.08874 | [PDF](https://arxiv.org/pdf/2602.08874v1)

**作者:** Yu Fu `[一作]` (University of California, Riverside), Yue Dong `[通讯]` (University of California, Riverside)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究长上下文推理攻击，评估LLM安全性是否随推理能力提升而提高。

**💡 创新点**

提出组合推理攻击模型并构建相应基准，证明推理强度并不等同于安全性。

**🔧 技术方法**

利用链式推理、多步推理与检索合成技术，对模型进行安全评估。

**📊 数据集**

使用AdvBench的100条有害查询并在PG19语料中嵌入，构成长上下文实验集。

**📈 对比分析**

对14款前沿LLM进行评测，发现安全率随上下文长度升高而下降，但提升推理预算可将攻击成功率降低超过50%。

**⚠️ 局限性**

实验仅考虑文本单模态、固定推理预算，缺乏自适应推理分配与多模态情境的评估。

---

## 983. TiFRe: Text-guided Video Frame Reduction for Efficient Video Multi-modal Large Language Models

**arXiv ID:** 2602.08861 | [PDF](https://arxiv.org/pdf/2602.08861v1)

**作者:** Xiangtian Zheng `[一作]` (Wangxuan Institute of Computer Technology, Peking University), Yuxin Peng `[通讯]` (Wangxuan Institute of Computer Technology, Peking University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 TiFRe 框架，利用文本引导的关键帧抽取与非关键帧信息融合，显著减少视频 MLLM 的输入帧数并提升性能。

**💡 创新点**

创新点在于：① 根据用户提示动态生成 CLIP 风格的文本提示，从而选择最语义相关的关键帧；② 通过帧匹配与加权平均方式将未被选帧的信息融合到关键帧中，最大限度减少信息损失。

**🔧 技术方法**

技术手段包括：使用 LLM（如 OpenPangu‑7B / Qwen‑2.5‑7B）生成目标对象文本；CLIP（ViT‑B/32）进行图文相似度计算；帧匹配与加权平均实现信息融合；在已有 Video‑LLaVA / Video‑XL 上直接部署，无需额外训练。

**📊 数据集**

数据集：VNBench（长视频推理、排序、计数任务）与 MLVU（多选视频理解任务）进行评估。

**📈 对比分析**

与 Video‑XL、Video‑LLaVA 等基线对比，TiFRe 将输入帧数从约 55.2 降至 8.6，平均分数提升至 62.6（Video‑XL+TiFRe）或 63.7（OpenPangu‑7B+TiFRe），在所有子任务上均表现出更高准确率。

**⚠️ 局限性**

局限性包括：① 依赖 CLIP 与 LLM 的预训练表征，可能在不同视觉语义场景下表现不佳；② 关键帧数目 k 的设置需经验调参；③ 目前仅在合成/人工构造数据集验证，缺乏对真实多样视频的充分测试。

---

## 984. Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room

**arXiv ID:** 2602.08949 | [PDF](https://arxiv.org/pdf/2602.08949v1)

**作者:** Mohammad Morsali `[一作]` (Independent Researcher), Siavash H. Khajavi `[通讯]` (Aalto University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

构建并验证了基于双向数字孪生与自主 AI 代理的智能虚拟情况室，用于实时火灾监测与干预。

**💡 创新点**

将实时数字孪生与 AI 驱动的相似度匹配相结合，形成闭环决策支持，首次实现主动可执行指令的双向 DT 系统。

**🔧 技术方法**

数字孪生、传感器融合、3D 可视化、深度学习（视觉语言模型、强化学习）、规则/多智能体框架、发布/订阅消息总线。

**📊 数据集**

来自工业合作伙伴 Detectium 的现场传感器日志、天气预报、遥感影像以及预先生成的灾害模拟库。

**📈 对比分析**

通过工业案例仿真对比传统基于静态模拟的系统，结果显示检测到火灾到干预的延迟降低 30%–40%，资源调度更精准，响应速度提升。

**⚠️ 局限性**

受限于传感器布置不足、数据延迟与质量不一、模型泛化能力有限、需要标准化互操作协议及安全隐私保障。

---

## 985. Teaching an Old Dynamics New Tricks: Regularization-free Last-iterate Convergence in Zero-sum Games via BNN Dynamics

**arXiv ID:** 2602.08938 | [PDF](https://arxiv.org/pdf/2602.08938v1)

**作者:** Tuo Zhang `[一作]` (University of Birmingham), Leonardo Stella `[通讯]` (University of Birmingham)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出基于BNN动力学的无正则化最后迭代收敛框架，并实现了BNNActor–Critic（BNNAC）算法，能够在含噪声反馈的零和博弈中收敛到近似Nash均衡。

**💡 创新点**

核心创新在于：①将Baldwin–Nash–Nash（BNN）动力学首次引入多代理学习，提供无正则化的最后迭代收敛保证；②通过结构化的偏差分析和马尔可夫差分噪声分解，证明噪声对收敛的影响可控；③设计了全神经网络实现的可扩展Actor–Critic框架，使用对手到达概率权重化的优势估计。

**🔧 技术方法**

技术手段包括：连续时间Baldwin–Nash–Nash动力学的随机逼近分析、Lyapunov势函数的严格下降证明、对接触型优势的reach‑weighted更新、Actor–Critic架构以及softmax策略约束；同时使用了噪声界定、鲁棒性分析和极限区间估计。

**📊 数据集**

实验数据集涵盖：①正常型博弈——Biased Rock‑Paper‑Scissors (BRPS)、四动作BRPS-W；②扩展型博弈——Kuhn扑克、Leduc扑克；以及它们的非平稳版本（即时/连续收益变化），全部加入无偏噪声。

**📈 对比分析**

与基线（APMD/ R‑NaD）对比，BNNAC在所有实验中实现了更快的收敛速度、更低的NashConv/可利用性，且在非平稳环境下更能快速适应变动；理论上收敛误差趋于 O(σ) 的噪声底线。

**⚠️ 局限性**

局限性包括：①收敛到的误差受噪声水平限制，无法完全消除噪声导致的稳态误差；②在极端噪声或极大动作空间时，网络逼近误差可能放大；③对高维连续动作空间的扩展尚未验证，需要进一步研究。

---

## 986. Diffusion-Inspired Reconfiguration of Transformers for Uncertainty Calibration

**arXiv ID:** 2602.08920 | [PDF](https://arxiv.org/pdf/2602.08920v1)

**作者:** Manh Cuong Dao `[一作]` (National University of Singapore), Trong Nghia Hoang `[通讯]` (Washington State University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种将预训练Transformer重新配置为扩散过程的方法，以实现端到端的不确定性校准。

**💡 创新点**

创新点在于把多头自注意力视为高斯过程后验，随后将所有注意力块的神经化高斯转移压缩成单一统一的时空扩散核，既保留原模型预测性能，又显著提升不确定性校准。

**🔧 技术方法**

使用的技术包括高斯过程重参数化、多头自注意力、神经化高斯转移、扩散模型与联合时空转移核、变分推理及校准后处理。

**📊 数据集**

实验数据集涵盖视觉任务：CIFAR‑10、CIFAR‑100、CIFAR‑10‑C；语言任务：IMDB、CoLA 以及其 OOD 数据集。

**📈 对比分析**

与温度缩放、蒙特卡罗 dropout、SV‑DKL、KFLLA、SGPA、KEP 等基线对比，本文方法在准确率、ECE、NLL、Brier 等指标上均优于基线；在 OOD 检测和鲁棒性评估中亦显示出更高的 AUROC/AUPR，证明其在多任务和跨域设置下的优势。

**⚠️ 局限性**

限制包括：需要额外训练扩散核导致额外计算开销、对极大规模 Transformer（如 ViT‑B‑16）扩展性尚待验证、在某些 OOD 场景下提升幅度相对有限，且目前方法主要关注校准而非完整的贝叶斯推理。

---

## 987. Comparing AI Coding Agents: A Task-Stratified Analysis of Pull Request Acceptance

**arXiv ID:** 2602.08915 | [PDF](https://arxiv.org/pdf/2602.08915v1)

**作者:** Giovanni Pinna `[一作]` (University of Trieste), Federica Sarro `[通讯]` (University College London)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

对 5 种 AI 编码助手在 7,156 条拉取请求上进行实证研究，比较其接受率随时间和任务类型的变化。

**💡 创新点**

提出了基于任务类型的分层比较方法，揭示不同助手在不同任务中的强弱差异，并发现时间趋势不一致。

**🔧 技术方法**

使用线性回归、LOESS 平滑、卡方检验、Fisher 精确检验以及 Bonferroni 校正等统计技术进行分析。

**📊 数据集**

使用公开的 AIDev 数据集（来自 100+ 星星的 GitHub 仓库）并筛选出 7,156 条符合条件的 PR。

**📈 对比分析**

通过任务分层的接受率和时间趋势比较，结果显示 Devin 仅有提升趋势，Codex 在多数任务中最高，其他助手在特定任务中领先。

**⚠️ 局限性**

研究仅基于接受率，未考虑代码质量；数据量对部分助手不足，且未控制仓库级别的聚类，导致结果易受混杂因素影响。

---

## 988. Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks

**arXiv ID:** 2602.08914 | [PDF](https://arxiv.org/pdf/2602.08914v1)

**作者:** Kiyosu Maeda `[一作]` (Princeton University), Parastoo Abtahi `[通讯]` (Princeton University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了在重复协作物理装配任务中，人类如何通过语音与手势形成并演化多模态约定，并以此为基础设计了一种可学习这些约定的多模态对话智能体；

**💡 创新点**

提出了在RSA框架基础上扩展的多模态约定学习模型，能够捕捉语言与手势的冗余、互补与单一使用，并解释了个体在使用手势与语言上的多样偏好；

**🔧 技术方法**

采用了多模态RSA推理模型、连续语义与成本函数、贝叶斯优化参数学习、以及仿真评估；

**📊 数据集**

使用了两套自建实验数据集：一套在线文本指令装配数据（98人，12轮），另一套AR环境下的语音+手势装配数据（40人，12轮，包含手部关键点、语音转录等）；

**📈 对比分析**

通过与实验中观察到的指令长度、准确率、手势/语音比例等指标对比，模型在仿真中能重现指令长度下降、准确率提升以及手势使用分布的变化，显示出与人类行为高度一致；

**⚠️ 局限性**

局限性包括仅覆盖简单三块砖塔、交互被强制为异步轮流、手势与语音同步假设完美、模型规模受限于有限抽象词汇，且未对更复杂结构或实时协作情境进行验证。

---

## 989. Discrete Bridges for Mutual Information Estimation

**arXiv ID:** 2602.08894 | [PDF](https://arxiv.org/pdf/2602.08894v1)

**作者:** Iryna Zabarianska `[一作]` (Moscow Independent Research Institute of Artificial Intelligence), Alexander Korotin `[通讯]` (Applied AI Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出并实现了一种基于离散桥匹配的互信息估计方法（DBMI），能够在高维离散空间中精确估计互信息。

**💡 创新点**

创新点在于把互信息估计转化为离散递归过程的 KL 散度，并通过桥匹配学习条件马尔可夫链，从而克服传统离散 MI 估计在高维/大字典大小下的性能退化。

**🔧 技术方法**

采用递归过程、桥匹配、离散扩散过程、神经网络参数化的条件转移、因子化概率结构以及 Diffusion Transformer 架构。

**📊 数据集**

使用低维因子化分布以及 32×32 二值图像的矩形边界映射图像数据集进行验证。

**📈 对比分析**

与 MINE、InfoNCE、f‑DIME（KL、Hellinger、GAN）以及 NWJ 进行比较，DBMI 在所有基准上都更接近真实互信息，尤其在高维图像上明显优于其它方法。

**⚠️ 局限性**

因子化转移概率会引入估计偏差，虽然随着采样步数 N→∞ 可减小；对混合连续-离散数据的适用性仍需进一步研究。

---

## 990. Contrastive Learning for Diversity-Aware Product Recommendations in Retail

**arXiv ID:** 2602.08886 | [PDF](https://arxiv.org/pdf/2602.08886v1)

**作者:** Vasileios Karlis `[一作]` (University of Amsterdam), Maarten de Rijke `[通讯]` (University of Amsterdam)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `9ce7179e-700c-4310-ac2b-91df50ded46e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

在IKEA推荐系统中引入对比学习与负样本采样以提升产品目录覆盖率。

**💡 创新点**

将余弦相似度损失与对比学习结合，并设计了“in‑batch”和“top‑k”负样本采样策略，针对现有LSTM+Word2Vec框架进行创新。

**🔧 技术方法**

使用Word2Vec风格的产品嵌入、LSTM序列模型、余弦相似度与交叉熵对比学习损失，以及ANNOY近邻检索。

**📊 数据集**

实验数据来自IKEA荷兰本地商品日志和公开的RetailRocket数据集。

**📈 对比分析**

通过离线和在线实验与基线余弦损失对比，交叉熵+100负样本在IKEA集上提升了26.4%目录覆盖率、6.5%吉尼系数、6.4% NDCG@10，另一策略在RetailRocket集上同样取得显著提升。

**⚠️ 局限性**

局限在于负样本选择仍依赖批次信息，未能彻底解决信息稀疏和计算开销问题；在线评估仅覆盖单一市场，缺乏跨域验证。

---

## 991. Breaking the Simplification Bottleneck in Amortized Neural Symbolic Regression

**arXiv ID:** 2602.08885 | [PDF](https://arxiv.org/pdf/2602.08885v1)

**作者:** Paul Saegert `[一作]` (Heidelberg University), Ullrich Köthe `[通讯]` (Heidelberg University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `14d48e9d-0069-4ad9-996a-1d5968216998` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了高速符号简化引擎 SimpliPy 并基于其构建 Flash-ANSR 模型，实现了可扩展的 amortized 符号回归。

**💡 创新点**

通过离线规则挖掘与哈希式模式匹配实现 100 倍简化加速，并将简化与数据生成同步，突破传统 CAS 的瓶颈。

**🔧 技术方法**

使用 Transformer 编码器‑解码器、Set Transformer、FlashAttention、RMSSetNorm 以及 SimpliPy 的模式匹配简化引擎。

**📊 数据集**

在 FastSRB 基准（115 条科学方程及其观测数据）上评估，并利用大量随机生成的符号表达式构建训练集。

**📈 对比分析**

与 NeSymReS、E2E、PySR 等方法在恢复率、表达式简洁度与推理时间 Pareto 前沿上比较，Flash-ANSR 在大多数预算下达到或超过 PySR 的恢复率，同时产生更简洁的表达式。

**⚠️ 局限性**

对噪声鲁棒性不足（训练仅使用无噪声数据导致加噪场景下性能下降），以及对极大维度或极其复杂表达式的支持仍有限。

---

## 992. Learning Potentials for Dynamic Matching and Application to Heart Transplantation

**arXiv ID:** 2602.08878 | [PDF](https://arxiv.org/pdf/2602.08878v1)

**作者:** Itai Zilberstein `[一作]` (Carnegie Mellon University), Tuomas Sandholm `[通讯]` (Carnegie Mellon University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了基于潜能函数的非贪心在线匹配框架，并通过自监督模仿学习训练高维非线性潜能，以优化心脏移植分配决策。

**💡 创新点**

将潜能函数从传统线性扩展为可学习的神经网络；利用全知对偶器生成监督标签并以模仿学习方式训练潜能；采用半合成数据增强提升模型泛化能力。

**🔧 技术方法**

使用自监督模仿学习（RankSVM、交叉熵、KL散度）、SMAC黑盒优化对比、神经网络潜能、Cox生存模型预测收益以及离散事件模拟等技术。

**📊 数据集**

基于UNOS 2019年心脏移植登记数据，并通过半合成轨迹生成方法扩充训练集。

**📈 对比分析**

与现行分层政策、连续分布CAS、贪心即期收益及SMAC优化线性潜能等基线对比；在2019年4月-12月的真实轨迹上，神经网络潜能模型平均每月提升约22 PLYG，逼近全知上限95%，显著优于所有基线。

**⚠️ 局限性**

受限于历史数据质量与生存预测的不确定性、未考虑中心拒绝行为、仅优化总寿命而非公平性，且潜能学习仍可能带来系统性偏差。

---

## 993. Stress-Testing Alignment Audits With Prompt-Level Strategic Deception

**arXiv ID:** 2602.08877 | [PDF](https://arxiv.org/pdf/2602.08877v1)

**作者:** Oliver Daniels `[一作]` (University of Massachusetts Amherst), David Lindner `[通讯]` (Google Deepmind)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一个自动化红队管道，对隐藏目标模型进行情境感知与策略性欺骗，并系统性地对现有的黑盒和白盒对齐审计方法进行压力测试。

**💡 创新点**

首次提供了针对对齐审计的自动红队框架，实现了无梯度、零样本的情境感知欺骗策略，并展示了激活层级的策略性欺骗案例；同时证明现有审计方法在面对具备情境感知与策略推理能力的模型时并不鲁棒。

**🔧 技术方法**

利用Claude Opus 4.5生成系统提示，采用预置提示与用户角色采样的黑盒审计；白盒审计采用稀疏自编码器（SAE）特征描述与激活嵌入相似度；评估时加入置信度评分，并通过迭代优化红队提示并反馈给蓝队。

**📊 数据集**

使用两类秘密保持模型：User Gender（Gemma 2 9B Instruct）和Secret Side Constraint（Llama 3.3 70B Instruct）。审计数据基于两者的直接提问集（约数十条）。

**📈 对比分析**

在所有六种（2黑盒+4白盒）组合中，红队提示使审计成功率下降至0%–30%不等，且审计置信度保持高水平，显示欺骗成功；蓝队能够在基线模型上提升准确率，但在红队提示下失效。整体表现说明现有审计方法对情境感知的欺骗易受攻击。

**⚠️ 局限性**

仅评估两种秘密保持模型；红队策略主要为自然语言提示，未考虑编码或零样本隐式推理；缺乏对更广泛模型和多查询情境的评估；情境感知信息是显式给定，缺少真实训练时的隐式知识。

---

## 994. ArkEval: Benchmarking and Evaluating Automated CodeRepair for ArkTS

**arXiv ID:** 2602.08866 | [PDF](https://arxiv.org/pdf/2602.08866v1)

**作者:** Bang Xie `[一作]` (Shanghai Jiao Tong University), Yuan Luo `[通讯]` (Shanghai Jiao Tong University)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

针对 HarmonyOS 生态中的 ArkTS 语言，构建了首个 502 条真实 Bug 的自动修复基准 ArkEval，并通过多模型投票生成可执行的测试用例，形成完整的评估框架。

**💡 创新点**

创新点包括：① 第一次针对低资源 DSL（ArkTS）提供统一的可执行基准；② 设计 LLM 投票协议生成测试 oracle，解决缺失回归测试的问题；③ 将检索增强生成（RAG）与静态 AST 分块相结合，形成 ArkFix 复合修复流水线；④ 对四种 LLM 在该基准上的系统评测，揭示其在严格类型和声明式 UI 约束下的极限。

**🔧 技术方法**

核心技术：多模型 LLM（Claude 3.5、GPT‑4o、DeepSeek‑V3）协同生成和评估测试；检索增强生成（RAG）结合 Qwen3‑Embedding；AST 基分块与 512‑token 滑动窗口的混合拆分；Git 操作自动化、编译器和单元测试执行；对比实验中的指标计算与可视化。

**📊 数据集**

使用数据集：400+ 官方 Huawei HarmonyOS 样例应用（共 149 个被挑选用于基准）；502 条经过人工和自动筛选的 Bug；通过官方文档（API 9‑12）与应用代码构建检索知识库；合成的测试用例与对应的回归测试。

**📈 对比分析**

比较方法：在相同的 RAG‑增强工作流下，对 GPT‑5.1‑mini、Claude 4.5 Sonnet、Qwen3‑coder‑30b、DeepSeek‑R1‑Distill‑32B 进行 Patch Apply、Compile@1、Pass@1、Avg Time 四项指标评估。结果显示，最佳模型（Claude 4.5 Sonnet）Pass@1 仅 3.13%，Patch Apply 与 Compile@1 仍低于 40% 及 36%，显著低于常见语言基准。

**⚠️ 局限性**

局限性：① 低资源语言缺乏大规模训练语料导致 LLM 在 ArkTS 语义与语法上的失配；② 检索窗口与文件摘要截断限制了定位精度；③ LLM 生成的测试 oracle 仍可能出现误判；④ 评测未对比无 RAG 的零样本修复；⑤ 受硬件与 API 限制影响，某些模型的延迟偏高。

---

## 995. Magnitude Distance: A Geometric Measure of Dataset Similarity

**arXiv ID:** 2602.08859 | [PDF](https://arxiv.org/pdf/2602.08859v1)

**作者:** Sahel Torkamani `[一作]` (University of Edinburgh), Rik Sarkar `[通讯]` (University of Edinburgh)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种基于尺度参数的Magnitude距离来衡量有限数据集之间的相似性

**💡 创新点**

引入可调尺度t控制全局与局部结构的敏感度，并证明该距离在高维仍保持辨别力

**🔧 技术方法**

利用相似度矩阵求逆、逆核矩阵以及Magnitude函数的理论框架构造生成模型MagGN

**📊 数据集**

在MNIST数据集上验证了该距离的有效性，并与WGAN、WGAN‑GP进行对比

**📈 对比分析**

实验结果显示MagGN在保持图像质量的同时训练速度提高约10倍，对高维噪声更稳健

**⚠️ 局限性**

局限性在于需进行矩阵求逆导致计算成本较高，对尺度参数t的选择敏感且缺乏完整的理论下界

---

## 996. Clique-Based Deletion-Correcting Codes via Penalty-Guided Clique Search

**arXiv ID:** 2602.08952 | [PDF](https://arxiv.org/pdf/2602.08952v1)

**作者:** Aniruddh Pandav `[一作]` (Indian Institute of Technology), Rajshekhar V Bhat `[通讯]` (Indian Institute of Technology)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

研究并构造可纠正 d 个删除错误的二进制码本，将码本构造转化为最大团问题；

**💡 创新点**

提出了基于动态惩罚的随机团搜索（PGCS）算法，能够在给定时间预算内高效发现更大码本；

**🔧 技术方法**

使用最长公共子序列（LCS）来判定边的连通性，利用PGCS进行团搜索，构建最优/近似码本；并设计了基于符号计数过滤和早停的高效 LCS 解码器；

**📊 数据集**

在所有长度 n ∈{8,…,14} 与删除数 d ∈{1,2,3} 的二进制序列空间中实验，未使用外部公开数据集；

**📈 对比分析**

与 Helberg 代码、VT 代码、最小度/着色启发式等方法比较，PGCS 在所有实验设置下均得到更大或相等的码本，匹配或超过已知最优大小；解码器在平均情况下显著减少 LCS 计算次数，降低 O(|C|n²) 复杂度；

**⚠️ 局限性**

主要瓶颈是构造兼容图，需遍历 2ⁿ 条边，导致仅适用于 n≤14；算法对参数敏感，且对更大 n 的扩展仍需改进。

---

## 997. Distortion of Metric Voting with Bounded Randomness

**arXiv ID:** 2602.08871 | [PDF](https://arxiv.org/pdf/2602.08871v1)

**作者:** Ziyi Cai `[一作]` (Rutgers University), Kangning Wang `[通讯]` (Rutgers University)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355`

**🎯 论文内容**

研究在度量失真框架下的投票规则，提出一种仅在常数规模候选名单上均匀随机化的规则，取得小于3的失真。

**💡 创新点**

创新点在于证明可以用有限随机性（常数规模列表）突破3的失真阈值，并给出对最大彩票与稳定彩票的结构性质。

**🔧 技术方法**

采用偏置度量、(α,β)-一致性、最大彩票与稳定彩票的近似均衡、DKW不等式以及混合规则分析等技术。

**📊 数据集**

本研究为纯理论分析，无实验数据集；所有结果均为定理与上界。

**📈 对比分析**

与传统确定性规则（失真=3）和一般随机规则（失真<3但随机性无界）相比，提出的规则在保持常数随机性的同时实现失真略低于3。

**⚠️ 局限性**

主要限制在于常数规模仍很大、实现复杂且缺乏实验验证；对最小常数（如2）是否足够尚未证明。

---

## 998. MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE

**arXiv ID:** 2602.08961 | [PDF](https://arxiv.org/pdf/2602.08961v1)

**作者:** Ruijie Zhu `[一作]` (Nanyang Technological University), Chuanxia Zheng `[通讯]` (Nanyang Technological University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种基于视频扩散模型的框架，能够在不需要后期优化的情况下，统一在世界坐标系中从单目视频同时重建4D几何和密集运动。

**💡 创新点**

核心创新包括：①使用统一的4D VAE将几何与运动编码进共享潜空间；②采用基于均值的坐标归一化，证明不必严格对齐预训练扩散模型的分布即可获得更好性能；③通过视频生成器预训练显著缓解数据稀缺问题。

**🔧 技术方法**

技术手段主要包括：视频扩散模型（SVD），4D VAE（几何+运动融合），全景运动流预测，世界坐标系统一表示，以及两阶段训练策略。

**📊 数据集**

使用的训练数据包括多种合成动态数据集（Dynamic Replica、GTA‑SFM、MatrixCity、MVS‑Synth、Point Odyssey、TartanAir、ScanNet++、BlinkVision、OmniWorld、Synthia）和带运动注释的数据集（Kubric、Spring、Virtual KITTI 2）；评估数据为DDAD、Monkaa、Sintel、Dynamic Replica、Point Odyssey 等。

**📈 对比分析**

与最近的双任务方法（如Geo4D、π³、MonST3R等）在三维几何和三维运动指标上均取得显著提升，几何平均提升约38.64%，运动平均提升约25.0%，且不需要任何后期优化。

**⚠️ 局限性**

局限性在于目前仅处理几何与运动两种模态，未结合相机参数、深度图、轨迹等多模态信息，未来可探索多模态融合以进一步提升精度。

---

## 999. Robust Sequential Learning in Random Order Networks

**arXiv ID:** 2602.08953 | [PDF](https://arxiv.org/pdf/2602.08953v1)

**作者:** William Guo `[一作]` (University of Pennsylvania), Jie Gao `[通讯]` (Rutgers University)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39`

**🎯 论文内容**

研究随机顺序社交学习的鲁棒性与脆弱性，提出随机顺序学习网络的必要结构条件，构造可通过少量修改实现随机顺序学习的网络，并给出基于子模函数的贪心算法来实现网络改造；

**💡 创新点**

发现随机顺序学习在网络拓扑上具有鲁棒性，并证明了对任意随机顺序学习网络可容忍近乎 1/ε 次攻击；提出通过“guinea pig”或嵌入已知策略顺序学习结构来提升完整图的学习能力；提出需要学习预言机的贪心改造算法并给出近似最优性分析；

**🔧 技术方法**

贝叶斯推断、随机顺序学习理论、子模优化、贪心算法、蒙特卡洛采样、学习预言机设计；

**📊 数据集**

无实测数据集，全部为理论构造与证明；

**📈 对比分析**

算法在多项式时间内完成改造，改造后网络实现随机顺序学习；改造次数为 O(g(n) log n) 近似最优；

**⚠️ 局限性**

需假设存在有效的学习预言机，预言机的计算被认为是 NP‑hard；算法未考虑动态网络变化，且对特定拓扑的实测验证缺失。

---

## 1000. GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search

**arXiv ID:** 2602.08945 | [PDF](https://arxiv.org/pdf/2602.08945v1)

**作者:** Sahajpreet Singh `[一作]` (National University of Singapore), Min-Yen Kan `[通讯]` (National University of Singapore)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于人类感知信息缺口的社区审核框架 Gap-Informed Targeted Search (GITS)，实现从缺口识别到针对性检索再到规范化笔记生成的三阶段流程。

**💡 创新点**

核心创新在于将社区笔记中显现的“质量缺口”视为一等信号，先系统性识别并给出优先级，再用该缺口信息驱动检索，避免传统检索的无目标噪声，从而在冷启动和热启动场景均能高效生成符合人类期望的社区笔记。

**🔧 技术方法**

技术包括：1）缺口检测与优先级分配（基于 LLM 分类与打分）；2）目标检索（利用检索-生成模型进行针对性网络搜索）；3）受约束的笔记生成（闭书式 LLM 生成，严格使用检索得到的证据并优化中立性与长度）。

**📊 数据集**

使用自建的 78,698 条美国政治推文与其对应 Community Notes 的数据集，测试集为最近 10% 的 488 条推文，覆盖 265 条已存在社区笔记。

**📈 对比分析**

与 Supernotes-Lite、Web-Agents 等基线对比：GITS 在 99% 覆盖率下，Claim Alignment、Completeness、Helpfulness 与基线相当或更好；在人类评估中相较于人工笔记取得 69% 胜率，Helpfulness 得分为 3.87（远高于 3.36）；与同一 LLM 的通用检索方式相比，胜率提升 59%。

**⚠️ 局限性**

主要局限在于对“含糊引用”与“缺乏上下文”类缺口的处理仍不够精准，需更深层的语境推理与迭代式检索来进一步提升。

---

## 1001. CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse

**arXiv ID:** 2602.08939 | [PDF](https://arxiv.org/pdf/2602.08939v1)

**作者:** Longling Geng `[一作]` (Stanford University), Edward Y. Chang `[通讯]` (Stanford University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了一个5,000+样例的因果推理基准，包含三层（检测、诊断、想象），并通过人机协作管线构建。

**💡 创新点**

结合Pearl梯子、狼羊陷阱分类、压力变体、智慧拒绝、双轴评估，实现对因果推理缺陷的细粒度诊断。

**🔧 技术方法**

使用LLM驱动生成、人工审核、结构因果模型验证、压力对照测试和智慧拒绝协议等技术。

**📊 数据集**

5,147条自含因果案例，覆盖10个领域，按L1-L3层级分布，并包含压力对照样本。

**📈 对比分析**

采用Utility/Safety两轴指标、Bad Flip Rate、Detection–Correction Gap、Rung Collapse等量化方法进行比较，发现模型在安全性高但效用低、逆向规模导致从众等问题，性能差异显著。

**⚠️ 局限性**

仅英文、域覆盖有限、结构上存在上限（无法完全纠正），且模型与审计者交互敏感，需要进一步扩展与适应。

---

## 1002. StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors

**arXiv ID:** 2602.08934 | [PDF](https://arxiv.org/pdf/2602.08934v1)

**作者:** Suraj Ranganath `[一作]` (University of California), Atharv Ramesh `[通讯]` (University of California)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `6215c339-3735-4be3-8a07-5bbb7004712d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出并实现了StealthRL框架，利用强化学习在多检测器集成上训练隐蔽改写策略，以评估AI文本检测器在低误报率操作点下的鲁棒性。

**💡 创新点**

创新点在于将Group Relative Policy Optimization与LoRA微调结合，针对多检测器集成（RoBERTa+Fast-DetectGPT）进行对抗训练，并展示在未见检测器Binoculars上的强转移能力，同时提供完整的评测协议。

**🔧 技术方法**

采用的技术包括GRPO、LoRA适配、E5嵌入语义相似度奖励、检测器分数分布分析以及LLM（gpt-5-nano）进行质量评估。

**📊 数据集**

使用MAGE基准的10,000条AI生成文本进行训练，1,000条人类写作与1,000条AI文本（100–500词）作为测试集。

**📈 对比分析**

与六种攻击基线（无攻击、简单改写、StealthRL、对抗改写、AuthorMist、Homoglyph）比较，在1% FPR下StealthRL将TPR降至≈0.001，AUROC从0.74降至0.27，攻击成功率达到99.9%，并在未见检测器Binoculars上实现近零TPR。

**⚠️ 局限性**

局限性包括仅评估三类检测器（未包含水印检测器）、数据集仅为英语MAGE、攻击文本的语义保真度低、未探讨防御方法或更广泛的多语言、多领域评估。

---

## 1003. DynamiQ: Accelerating Gradient Synchronization using Compressed Multi-hop All-reduce

**arXiv ID:** 2602.08923 | [PDF](https://arxiv.org/pdf/2602.08923v1)

**作者:** Wenchen Han `[一作]` (University College London), Ran Ben Basat `[通讯]` (University College London and Broadcom)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种专门针对多跳 All‑reduce 的梯度压缩框架 DynamiQ，支持可变比特宽度、非均匀量化、分层量化和负相关取舍。

**💡 创新点**

创新点在于：①通过全局统计先确定各 super‑group 的比特宽度并保持固定；②融合解压-累加-重压缩核降低内存传输；③在多跳路径上保持无偏量化和低误差，显著提升大语言模型训练的时间‑精度曲线。

**🔧 技术方法**

使用的技术包括：分组/超组量化、非均匀量化（按 Epsilon 设计量化点）、层次缩放量化、负相关随机量化、CUDA 融合核、PyTorch DDP Hook 结合 NCCL P2P。

**📊 数据集**

使用的数据集和任务有：BERT‑large + WikiText‑103（Masked LM），Gemma‑1B + UltraChat（Chat / MMLU），LLaMA‑1B + UltraChat 与 LLaMA‑1B + MMLU，TinyBERT + GLUE（用于可扩展性验证）。

**📈 对比分析**

与 BF16、MXFP8、MXFP6/4、OmniReduce、THC 等传统或微尺度压缩方法对比；在 ring 和 butterfly All‑reduce 上，DynamiQ 在保持 99%+ BF16 精度的同时，时间‑精度加速可达 30–40%（例如 LLaMA‑1B MMLU 34%），且 vNMSE 低于 MXFP8 3–4 倍。

**⚠️ 局限性**

局限性包括：①需要预先收集全局统计，增加一次轻量级 All‑reduce；②对超大模型或极高 worker 数时，超组统计与重新排序可能成为瓶颈；③实现复杂，依赖 CUDA 融合核和 NCCL 对不同拓扑的支持。

---

## 1004. Automatic In-Domain Exemplar Construction and LLM-Based Refinement of Multi-LLM Expansions for Query Expansion

**arXiv ID:** 2602.08917 | [PDF](https://arxiv.org/pdf/2602.08917v1)

**作者:** Minghan Li `[一作]` (Soochow University), Guodong Zhou `[通讯]` (Soochow University)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建无标签、领域自适应的查询扩展框架，先用BM25+MonoT5生成伪相关示例，利用Contriever嵌入+K‑means聚类挑选多样示例，随后用两款LLM分别生成扩展，并由第三个LLM对两者进行精炼合并；

**💡 创新点**

①完全自动化且无监督的示例构建与多LLM融合；②聚类挑选多样示例提升稳定性；③训练无关的LLM精炼步骤合并两模型输出；

**🔧 技术方法**

BM25检索、MonoT5重排序、Contriever+K‑means聚类、Qwen‑2.5‑7B‑Instruct与LLaMA‑3.1‑8B‑Instruct生成、LLM精炼；使用SBERT做密集检索基线；

**📊 数据集**

TREC DL20（MS MARCO段落）、DBPedia‑Entity（维基百科摘要）、SciFact（生物医学摘要）；

**📈 对比分析**

与BM25、Rocchio、ZeroShot、固定FewShot等基线对比，在所有三个基准上均显著提升；两LLM精炼版在NDCG@10提升约3–4个百分点，Recall@100亦有提升；

**⚠️ 局限性**

示例质量受BM25+MonoT5的伪相关检索影响，示例规模受检索准确度限制；LLM生成仍可能出现幻觉或冗余；未在多语言或更大规模场景中验证。

---

## 1005. Efficient and Stable Reinforcement Learning for Diffusion Language Models

**arXiv ID:** 2602.08905 | [PDF](https://arxiv.org/pdf/2602.08905v1)

**作者:** Jiawei Liu `[一作]` (University of Science and Technology of China), Yu Yang `[通讯]` (City University of Hong Kong)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了空间-时间剪枝(STP)框架，用于提升扩散式大语言模型(dLLMs)在强化学习训练中的效率与稳定性

**💡 创新点**

首次同时在空间维度（固定部分词汇）和时间维度（跳过后期细化步骤）进行剪枝，理论证明降低ELBO估计方差并提升训练稳定性

**🔧 技术方法**

基于扩散模型的掩码去噪、GRPO强化学习、ELBO估计、空间/时间剪枝策略

**📊 数据集**

使用LLaDA‑8B‑Instruct模型在数学推理(GSM8K、MATH)与逻辑推理(Countdown)等公开基准上进行实验

**📈 对比分析**

与GRPO‑ELBO、Diffu‑GRPO及SPG等基线对比，STP在训练时间上比最快基线快约13%，在推理准确率上在MATH/GSM8K上提升1–2%，在Countdown上提升超80%

**⚠️ 局限性**

对剪枝比例与切断阈值敏感，过度剪枝会导致探索不足；当前方法仅验证于文本扩散模型，尚未探讨多模态场景与动态剪枝策略

---

## 1006. OmniReview: A Large-scale Benchmark and LLM-enhanced Framework for Realistic Reviewer Recommendation

**arXiv ID:** 2602.08896 | [PDF](https://arxiv.org/pdf/2602.08896v1)

**作者:** Yehua Huang `[一作]` (Hong Kong University of Science and Technology), Xiaowen Chu `[通讯]` (Hong Kong University of Science and Technology)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出OmniReview大规模验证审稿记录数据集，并基于LLM与多门混合专家网络构建Pro-MMoE审稿人推荐框架，用于真实学术场景的审稿人匹配。

**💡 创新点**

创新点：①整合OAG、Frontiers、ORCID三源信息，完成身份消歧并构建202,756条真实审稿记录；②设计三层评估框架（召回、误负排除、精细排序），更贴近实际编辑工作；③将LLM生成的语义档案与Task-Adaptive MMoE结合，既保留细粒度知识，又实现可解释性和多任务平衡。

**🔧 技术方法**

技术：LLM（Qwen3系列）用于论文与审稿人摘要与语义嵌入；多任务学习的Task-Adaptive MMoE架构；置信度与排名的联合损失；学科层次树构建与标签构造；实体对齐与验证管道。

**📊 数据集**

数据集：OmniReview，包含202,756篇论文、150,287位审稿人、跨OAG、Frontiers、ORCID的审稿记录；与NIPS、KDD、ACM-DL、exHarmony、OAG-Bench、FRONTIER-RevRec等现有数据集进行对比。

**📈 对比分析**

对比TF-IDF、Dual-tower、RGCN、SciBERT、SPECTER2、BGE-M3、Qwen3-Embedding-4B、CoF、LLM-as-Judge等基线，Pro-MMoE在RRC、UCC、MAP、R-prec、Recip-rank、NDCG、Success@5七项指标中取得六项领先，表现显著优于现有方法。

**⚠️ 局限性**

局限：模型对大模型算力依赖较高；对极低频学科或新兴领域覆盖仍有限；尽管使用文本摘要提升可解释性，但缺乏图谱层面的可解释性；部分标签构造仍基于语义相似性，可能引入噪声。

---

## 1007. Designing Multi-Robot Ground Video Sensemaking with Public Safety Professionals

**arXiv ID:** 2602.08882 | [PDF](https://arxiv.org/pdf/2602.08882v1)

**作者:** Puqi Zhou `[一作]` (George Mason University), Sungsoo Ray Hong `[通讯]` (George Mason University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `e0540dec-d77f-42db-94ae-d039248f6393` `aaccfe5c-6b26-4208-b23c-35331481e142` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文构建了一个基于多机器人地面摄像的视频感知与决策支持平台，并提供了一个包含38类安全事件的公开测试集。

**💡 创新点**

创新点在于与警务专家共同设计事件类型与需求，结合多模态LLM推理与可解释的事件卡片、属性检索与协作工作区，形成一套从检测到协作的闭环系统。

**🔧 技术方法**

技术采用多目标检测与跟踪（YOLO+BoxMOT+DeepOCSort）、LLM（Gemini 2.0+LLAVA 1.6）进行视频理解与解释、属性抽取，前端则整合地图、时间轴、视频墙与搜索界面。

**📊 数据集**

数据集为自制的20段巡逻视频（昼夜各10段），覆盖833人、1,537辆车，包含38种由警务专家验证的事件类型，并配有时间戳与GPS元数据。

**📈 对比分析**

与HolmesVAD与Gemini基准对比，系统在日间/夜间分别达F1分别为0.497/0.540，总体F1为0.519，并在专家评估中显著降低人工检索时间、提升情境感知与协作效率。

**⚠️ 局限性**

局限性包括：数据集仅覆盖校园场景，事件类型需按地区可配置；LLM召回率高导致误报；模型对低光、遮挡等条件仍敏感；系统需人工验证，尚未实现完全自动化。

---

## 1008. Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation

**arXiv ID:** 2602.08873 | [PDF](https://arxiv.org/pdf/2602.08873v1)

**作者:** Lisette Espin-Noboa `[一作]`, Gonzalo Gabriel Mendez `[通讯]`

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `14d48e9d-0069-4ad9-996a-1d5968216998` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了LLMScholarBench基准，用于系统评估LLM驱动的学者推荐，覆盖多任务、多模型及三种推理时干预。

**💡 创新点**

创新点在于将模型基础设施与终端用户干预统一纳入评估，首次量化技术质量与社会代表性之间的权衡，并提出多维度评价指标。

**🔧 技术方法**

采用大语言模型提示、温度控制、受限提示（按性别、族裔、声望等）以及检索增强生成（RAG）等技术，并结合结构化评测脚本与实体匹配。

**📊 数据集**

使用美国物理学会（APS）出版数据与OpenAlex补全的学者记录作为真值集，构成物理学专家推荐基准。

**📈 对比分析**

通过在22款模型上在多任务（top‑k、领域、年代、资历）下进行三种干预的系统对比，发现专有模型在事实性和网络连通性上更佳，开源模型更易生成可用列表；温度升高导致有效率下降；RAG提升事实性但削弱多样性；整体各指标存在明显权衡，未出现单一最优配置。

**⚠️ 局限性**

局限性包括：有效率指标可能低估可用但格式不规范的输出；基础设施与训练、对齐策略混杂，难以断定因果；实体解析对同名学者误判；仅在物理学域验证，跨域推广需替换真值集；干预手段无法同时提升所有技术与代表性指标。

---

## 1009. Autoregressive Image Generation with Masked Bit Modeling

**arXiv ID:** 2602.09024 | [PDF](https://arxiv.org/pdf/2602.09024v1)

**作者:** Qihang Yu `[一作]` (Amazon Frontier AI and Robotics), Xi Chen `[通讯]` (Amazon Frontier AI and Robotics)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了基于掩码位自动回归（BAR）的离散图像生成框架，并通过统一的位预算度量，展示了离散与连续编码器在相同信息容量下的可比性能。

**💡 创新点**

创新点：① 用总位数统一比较离散与连续模型，证明信息容量是性能差距的主要原因；② 设计掩码位预测头，能够在大词表下高效生成离散符号，避免传统线性softmax的规模瓶颈；③ 通过逐位解码的方式实现高质量、高速的图像生成。

**🔧 技术方法**

技术：离散向量量化（FSQ）、自回归 Transformer、掩码位建模（Masked Bit Modeling）头、RoPE、SwiGLU、RMSNorm、Classifier-Free Guidance、可变位解码调度等。

**📊 数据集**

数据集：ImageNet‑1K（256×256）用于评估生成质量（gFID）和采样速度，另外使用 CLIP、DINO 等预训练模型做特征对齐。

**📈 对比分析**

比较方法：对比连续扩散模型（如 xAR、DDT、MAR）和离散模型（RAR、VAR、LlamaGen、MeanFlow）。在相同位预算下，BAR 在 gFID 上突破 1.0（BAR‑L 达 0.99），并在采样速度上比连续模型快 3.6–20 倍，尤其是高效变体 BAR‑B/4 速度比 MeanFlow 高 2.94×。

**⚠️ 局限性**

局限性：① 仍依赖大规模 GPU 进行训练；② 目前主要针对 ImageNet，缺乏对更复杂多模态任务的验证；③ 掩码位解码的步骤仍可能导致生成细节的微小失真，需要进一步优化。

---

## 1010. Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models

**arXiv ID:** 2602.09017 | [PDF](https://arxiv.org/pdf/2602.09017v1)

**作者:** Zichen Jeff Cui `[一作]` (New York University), Nur Muhammad Mahi Shafiullah `[通讯]` (University of California, Berkeley)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种基于物理接触点（contact anchor）作为最小化条件接口的通用机器人操控策略（CAP），并通过仅23小时的手持演示数据训练；

**💡 创新点**

创新点包括：① 用物理接触点替代自然语言作为条件，显著降低信息量并提升精准度；② 结合轻量化的 VQ-BeT 结构与少量数据实现零射击泛化；③ 在训练和迭代中嵌入 EgoGym 轻量化仿真；④ 自动使用 VLM 生成接触点并通过 GPT‑4o 进行自动重试；

**🔧 技术方法**

技术手段：VQ‑BeT 行为克隆；ResNet‑50 + MoCo 视觉特征；SAM2 用于抓手闭合估计；VLM（Gemini Robotics‑ER 1.5）用于接触点生成；GPT‑4o 用作重试验证器；MuJoCo + EgoGym 进行仿真循环；

**📊 数据集**

数据集：约 20,365 条演示（23.1 小时），覆盖 Pick、Open、Close 三类任务，共 424 个多样化环境；使用 iPhone‑13 Pro 记录 RGB‑D 与相机位姿；仿真中使用 915 个 Objaverse 物体与随机生成门窗；

**📈 对比分析**

比较方法：在五个未见场景和 10 种未见物体上进行零射击评估，基准包括 π_0.5、AnyGrasp、Open‑door 模型等；CAP 在 Pick、Open、Close 的成功率分别为 83%、81% 与 96%，比基线提升 23%–56%；跨机器人实现成功率 70%–91%；使用 VLM 自动接触点与 oracle 对比差异微小；仿真‑实测相关性强；Ablation 显示接触点必要性（96% vs 58%）。

**⚠️ 局限性**

局限性：仅支持单一接触点的单手任务；对多接触、多手任务需扩展；依赖 VLM 的接触点推断与重试，可能受限于语言模型的准确性；实验范围仍局限于 Pick/Open/Close 三类任务；

---

## 1011. Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction

**arXiv ID:** 2602.09013 | [PDF](https://arxiv.org/pdf/2602.09013v1)

**作者:** Hongyi Chen `[一作]` (Carnegie Mellon University), Jeffrey Ichnowski `[通讯]` (Carnegie Mellon University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

开发了一种无设备、无需机器人示范的框架，利用单目RGB人类视频重建4D手物交互轨迹，并通过接触优化与DemoGen合成多样化示例，训练可在真实机器人手（Inspire Hand、LEAP Hand）上执行抓取与操控的策略。

**💡 创新点**

创新点在于：① 从普通RGB视频直接恢复可用于训练的完整手物三维轨迹；② 采用差分接触优化和交互中心抓取建模，使重建数据更符合物理约束；③ 使用DemoGen在单一视频基础上合成多样化演示，显著提升策略泛化能力；④ 在无额外传感器或机器人演示的前提下实现多指抓取与操控。

**🔧 技术方法**

关键技术包括：Moge‑2（深度与相机内参估计）、SAM‑2+MeshyAI（物体分割与三维网格生成）、HaMeR（手模型重建）、FoundationPose（物体姿态估计）、ContactOpt（接触优化）、DemoGen（演示合成）、DP3（基于3D扩散的闭环策略）以及GeoCalib（摄像机重力对齐）。

**📊 数据集**

使用自采集的在场景与野外的RGB人类视频（20个抓取对象、7个操控任务），无公开标准数据集，所有数据均为作者自行录制的单视角视频。

**📈 对比分析**

与两类基线（pi_0.5‑DROID 和 LVP / LVP(-H)）进行对比。抓取任务中，模型在 20 个对象上的平均成功率达 70.25%，单一视频的成功率 63.75%；操控任务中，平均成功率 62.86%，显著优于 LVP（7‑10% 级别）和 pi_0.5（仅 1‑5%）。DemoGen 及接触优化对性能提升效果显著。

**⚠️ 局限性**

主要局限包括：① 依赖多种离线 3D 视觉模型，错误会在后续步骤中累积；② 仅支持静态或近静态摄像机，无法处理动态摄像机场景；③ 真实操控中对物体点云的依赖受遮挡影响，需假设抓取后相对姿态不变，未来需探索更鲁棒的观测方式。

---

## 1012. Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense

**arXiv ID:** 2602.09012 | [PDF](https://arxiv.org/pdf/2602.09012v1)

**作者:** Jiacheng Liu `[一作]` (Mohamed bin Zayed University of Artificial Intelligence), Zhiqiang Shen `[通讯]` (Mohamed bin Zayed University of Artificial Intelligence)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并发布了一套可生成多样化、可验证答案的 Next‑Gen CAPTCHA 框架与基准，用于防御基于 GUI 的自动代理。

**💡 创新点**

①把 CAPTCHA 从静态逻辑谜题转向动态交互任务，利用人机认知差距；②实现无限可生成、规则可检验的程序化 CAPTCHA；③公开了可实时 Web 评估平台和 519/135 题目基准。

**🔧 技术方法**

程序化生成与规则检验、基于 POMDP 的任务建模；使用多模态大语言模型（Gemini‑3、GPT‑5.2、Claude‑Opus 等）与浏览器交互接口评估代理。

**📊 数据集**

27 类视觉语言 CAPTCHA 家族，主测试集 519 题目，快速子集 135 题；所有实例通过生成规则自动验证，无人工标注。

**📈 对比分析**

在 Browser‑Use 框架下，人工通过率 98.8%；最强模型 GPT‑5.2 仅 5.9%，其他模型 0.9–3.2%；模型成本与时间高，显示显著的人机性能差距。

**⚠️ 局限性**

局限性包括：尚未覆盖所有交互场景；对人机认知差距长期有效性待验证；缺乏对可访问性和多语言支持的考虑；评估主要在实验平台，实际部署需进一步验证。

---

## 1013. Data Science and Technology Towards AGI Part I: Tiered Data Management

**arXiv ID:** 2602.09003 | [PDF](https://arxiv.org/pdf/2602.09003v1)

**作者:** Yudong Wang `[一作]` (Tsinghua University), Maosong Sun `[通讯]` (Tsinghua University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 L0–L4 分层数据管理框架，并通过 LLM 驱动的筛选、编辑、合成等技术实现数据质量从原始到可验证知识的逐步提升。

**💡 创新点**

创新点在于将模型与数据管理实现双向共进：构建层次化的数据质量等级，结合模型评估与自动化生成，形成数据-模型协同进化的闭环；同时提供统一的多阶段训练策略。

**🔧 技术方法**

使用了多种技术：基于规则的清洗与去重（L1）、模型驱动的分类与评分（L2）、LLM 语义编辑与合成（L3）以及知识图谱化与事实校验（L4）；训练采用 Megatron‑LM + MiniCPM，验证使用 OpenCompass 等基准。

**📊 数据集**

使用的数据集包括 Common Crawl、MathOverflow、UltraFineWeb（English/Chinese）、UltraData‑Math（L1/L2/L3）、Stack‑v2、Stack‑Edu、Wikidata、Ultra‑Data‑arXiv 等公开数据。

**📈 对比分析**

对比混合训练与分层训练，采用相同 token 数量（120B）并划分为 L1→L2→L3 阶段；在多语言、数学、代码等四大基准上，分层训练平均提升约 1.5pp，尤其在推理任务（ARC‑C/E、BBH、OpenbookQA）和知识任务（MMLU、C‑Eval）上显著优于混合方式。

**⚠️ 局限性**

局限性：仍以文本为主，未覆盖多模态；对大规模算力的依赖未彻底解决；层级划分和评估指标仍需更细化，数据溯源与版本控制机制尚不完善。

---

## 1014. Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models

**arXiv ID:** 2602.08984 | [PDF](https://arxiv.org/pdf/2602.08984v1)

**作者:** Yuliang Liu `[一作]` (Shanghai Jiao Tong University), Zhouhan Lin `[通讯]` (Shanghai Jiao Tong University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 Next Concept Prediction (NCP) 的预训练范式，并在此基础上构建了 ConceptLM 模型。

**💡 创新点**

创新点：①将多 token 组成的概念视为离散潜在空间中的单元，推出更具挑战性的预训练目标；②使用 Vector Quantization (VQ) 及产品量化构造可学习的概念词表；③同时训练 NCP 与传统 NTP，实现“先规划后生成”的自回归模型；④在多规模、不同骨干网络上验证概念级预训练提升模型能力。

**🔧 技术方法**

技术：Transformer 架构、VQ + 产品量化、概念级编码/解码、联合损失（L_VQ、L_NCP、L_NTP）以及持续预训练。

**📊 数据集**

数据集：OpenWebText、Pile、LongCtxEng 等；训练规模从 70M 参数到 1.5B 参数，使用 300B–3000B token 级别数据。

**📈 对比分析**

比较方法：与同规模 Token‑Level 基线、参数匹配模型及 ContextLM 进行对比。结果显示，ConceptLM 在 13 项基准上均优于传统 Token‑Level 模型；在 8B Llama 上持续预训练后平均提升 0.4 分；同时在长序列任务中展现出更好的长程依赖能力。

**⚠️ 局限性**

局限性：①概念级模型对代码库参数选择较敏感，最佳配置因模型规模而异；②在小模型或小数据集上，VQ 训练可能导致概念表示不足；③持续预训练时，新加层的初始化与对齐仍是挑战；④目前仅在英语文本上验证，跨语言推广尚未充分评估。

---

## 1015. CIC-Trap4Phish: A Unified Multi-Format Dataset for Phishing and Quishing Attachment Detection

**arXiv ID:** 2602.09015 | [PDF](https://arxiv.org/pdf/2602.09015v1)

**作者:** Fatemeh Nejati `[一作]` (Canadian Institute for Cybersecurity), Sajjad Dadkhah `[通讯]` (Canadian Institute for Cybersecurity)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了统一的 CIC‑Trap4Phish 数据集，涵盖 Word、Excel、PDF、HTML、QR 代码的恶意与正常附件，并提出对应的静态特征提取与轻量化模型检测方法。

**💡 创新点**

创新点在于首次提供涵盖五大常用附件格式的综合数据集，并为每种格式设计了可执行无依赖的静态特征集以及 QR 代码的双模检测（图像+URL 语言模型），实现了高效、可解释的攻击识别。

**🔧 技术方法**

采用的技术包括基于 SHAP 与随机森林的特征选择、轻量化机器学习分类器（随机森林、XGBoost、决策树）以及 CNN 图像分类和轻量 LLM（BERT‑Tiny、DeBERTa‑v3、ModernBERT、DeepSeek‑R1）对 URL 的文本分析。

**📊 数据集**

数据集使用了来自 MalwareBazaar、PDFMal2022、PhishTank、Google/Wikipedia 等公开来源共计 1,005,000 条附件样本（Word/Excel/PDF/HTML 各 20,000 条，QR 码 1,005,000 条），并在 CIC 数据仓库公开。

**📈 对比分析**

与传统方法对比，选取的前 10‑13 维特征在 Word/Excel/PDF 任务上均能达到 99.5‑100% 的准确率，QR 码图像方法仅 88% 以上，URL 语言模型则提升到 98.5‑99.4%，说明轻量化特征与 LLM 结合能获得最佳性能。

**⚠️ 局限性**

限制在于 QR 码的图像特征识别受限于视觉相似度，且实验仅在公开数据集上验证，未覆盖真实邮件环境下的多样性与潜在对抗样本，未来需在更复杂场景与对抗训练中进一步评估。

---

## 1016. ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation

**arXiv ID:** 2602.09014 | [PDF](https://arxiv.org/pdf/2602.09014v1)

**作者:** Zihan Yang `[一作]` (Fudan University), Zuxuan Wu `[通讯]` (Fudan University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `8d10c613-917e-4880-9716-17789f50e119` `40105733-5154-44cd-8090-a8cab9e64b07` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出ArcFlow，一种用于文本到图像生成的少步蒸馏框架，能够在仅2步（2 NFE）内实现与大型教师模型相媲美的高保真生成。

**💡 创新点**

创新点在于：①使用动量（momentum）混合参数化对流场速度进行连续非线性建模；②得到闭式解析求解器，可在单前向传播中完成多步积分；③通过瞬时速度对齐的蒸馏目标，使学生模型无需全量微调即可高精度匹配教师轨迹，显著提升收敛速度和稳定性。

**🔧 技术方法**

技术要点包括：动量混合参数化、解析ODE求解器、混合积分训练策略（教师引导→学生自校正）、LoRA微调及输出投影头的轻量化训练。

**📊 数据集**

使用的评测数据集包括Geneval、DPG-Bench、OneIG-Bench、Align5000（含HPSv2与COCO混合），以及FLUX.1-dev与Qwen-Image-20B作为教师模型。

**📈 对比分析**

与SenseFlow、pi-Flow、TwinFlow、Qwen-Image-Lightning等基线相比，ArcFlow在Fidelity（FID/pFID）、对齐度（CLIP相似度）、多样性（Diversity）等指标均优于或相当，并且在相同2 NFE下实现40×推理速度提升，训练收敛速度提升至1/4以上。

**⚠️ 局限性**

局限性包括：①对动量参数的学习仍需额外训练，无法完全摆脱教师模型的依赖；②在极端低步数（1步）时性能仍有限；③当前评测主要聚焦于文本到图像，缺乏对其他模态或跨域任务的验证。

---

## 1017. CLUE: Crossmodal disambiguation via Language-vision Understanding with attEntion

**arXiv ID:** 2602.08999 | [PDF](https://arxiv.org/pdf/2602.08999v1)

**作者:** Mouad Abrini `[一作]` (Sorbonne Universite), Mohamed Chetouani `[通讯]` (Sorbonne Universite)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种基于VLM交叉注意力的空间歧义检测与澄清对话的完整IVG框架CLUE。

**💡 创新点**

创新点在于将内部跨模态注意力转化为可解释的空间歧义信号，并用轻量CNN检测歧义，同时通过LoRA微调VLM实现澄清对话与定位。

**🔧 技术方法**

技术包括PaliGemma2的多模态Transformer、LoRA参数高效微调、跨模态注意力提取、轻量CNN、位置词表等。

**📊 数据集**

使用了InViG-21K真实人机对话数据、Isaac Sim合成的歧义数据以及IT2P等公开数据集。

**📈 对比分析**

与TiO基线相比，CLUE在InViG-only上Acc@0.5提升至75.66%（比71.2%高4.46%），歧义检测F1达到0.846，明显优于零样本和其他基线。

**⚠️ 局限性**

局限在于对预训练混合对象检测数据的依赖、对真实场景域外的鲁棒性仍有限，以及需要手工标注的歧义检测数据。

---

## 1018. Lightweight Call Signaling and Peer-to-Peer Control of WebRTC Video Conferencing

**arXiv ID:** 2602.08975 | [PDF](https://arxiv.org/pdf/2602.08975v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a154b176-e466-40fc-8ae0-e5cd17677106`

---

## 1019. Generalizing Sports Feedback Generation by Watching Competitions and Reading Books: A Rock Climbing Case Study

**arXiv ID:** 2602.08996 | [PDF](https://arxiv.org/pdf/2602.08996v1)

**作者:** Arushi Rai `[一作]` (University of Pittsburgh), Adriana Kovashka `[通讯]` (University of Pittsburgh)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

结合公开比赛解说与教练手册，通过LLM筛选、重写并精确对齐，为Video‑LLM提供辅助监督，实现跨域体育反馈生成。

**💡 创新点**

创新点包括①利用免费可公开的比赛评论与书籍文本作为辅助数据；②提出基于LLM的特异性与可操作性两项专门评估指标；③在无目标域标注的情况下显著提升反馈质量。

**🔧 技术方法**

技术手段：Video‑LLM（InternVideo2.5 + LLM）+ LoRA 微调；Phi‑4 14B 进行解说文本过滤与重写；Whisper 对话文本进行精确时间对齐；GPT‑4o-mini 用于自动评估特异性与可操作性。

**📊 数据集**

数据集：ExpertAF（篮球、足球反馈）+ 18,615 条岩壁比赛视频+ASR 解说 + 97,989 词岩壁教练手册文本；训练集约 33k 条视频‑文本对，验证集 8k 条，测试集 2.8k 条。

**📈 对比分析**

与仅在源域反馈上微调的基线相比，BLEU‑4、METEOR、ROUGE‑L、BERTScore 分别提升约 10–40%，而在自评特异性与可操作性上分别提升约 30% 与 20%。

**⚠️ 局限性**

局限性：对解说文本质量和时间对齐的依赖较高；LLM 评估可能存在偏差；跨域迁移效果受运动相似度影响，且实验仅验证了单一目标域（岩壁）。

---

## 1020. When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents

**arXiv ID:** 2602.08995 | [PDF](https://arxiv.org/pdf/2602.08995v1)

**作者:** Yuting Ning `[一作]` (Ohio State University), Huan Sun `[通讯]` (Ohio State University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `3855fcda-48ef-4070-a15e-803cd5c84d83` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了针对计算机使用代理(CUA)的误配动作检测与纠正框架

**💡 创新点**

首次将对齐问题从安全策略转向用户意图视角，定义误配动作并划分为三类，并构建全新的、带人类标注动作级对齐标签的基准；同时提出两阶段检测与迭代反馈的通用运行时防护器

**🔧 技术方法**

基于大型语言模型的两阶段推理（快速检查+系统分析）+叙事式历史摘要+结构化反馈

**📊 数据集**

构造了名为Misaligned Action Detection Benchmark（MADBench）的2264条动作级标签的轨迹数据集，涵盖外部攻击与内部失误三类误配动作

**📈 对比分析**

与Task Shield、InferAct等基线对比，MADBench上实现F1提升≈15%，在线攻击场景下攻击成功率下降≈90%，且在正常任务中任务成功率保持或提升，运行时延保持在可接受范围内

**⚠️ 局限性**

对齐推理仍受LLM解释能力限制，易受伪装攻击、坐标解析不足及意图模糊影响；系统需在资源成本与检测准确度之间权衡

---

## 1021. Rhythms of Recovery: Patient-Centered Virtual Reality Exergame for Physical Rehabilitation in the Intensive Care Unit

**arXiv ID:** 2602.08994 | [PDF](https://arxiv.org/pdf/2602.08994v1)

**作者:** Sangjun Eom `[一作]` (Duke University), Maria Gorlatova `[通讯]` (Duke University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

开发并验证了一款针对ICU患者的VR康复游戏，结合身体跟踪和临床监测，支持上肢动能恢复

**💡 创新点**

创新点包括患者中心化设计、分级可调动度挑战、实时临床监控以及使用Quest 3内置身体跟踪实现客观运动评估

**🔧 技术方法**

使用Meta Quest 3头显的体感追踪、Unity 2022开发、OptiTrack运动捕捉验证、GEQ、PACES、RPE问卷以及心率、血压等生理监测

**📊 数据集**

实验数据来自13名健康参与者、13名临床专业人员、18名心胸ICU患者以及7名护士，共计48名受试者

**📈 对比分析**

通过对比游戏体验问卷、运动速度、ROM、工作空间等指标，发现所有层级均有显著提升，SUS评分79，心率升幅低且安全，显示系统在ICU环境中可行且安全

**⚠️ 局限性**

局限性为样本量小、缺乏对照组和长期随访、仅评估上肢运动、身体跟踪误差仍有限、未系统评估适应性调节与网络延迟

---

## 1022. TwinRL-VLA: Digital Twin-Driven Reinforcement Learning for Real-World Robotic Manipulation

**arXiv ID:** 2602.09023 | [PDF](https://arxiv.org/pdf/2602.09023v1)

**作者:** Qinwen Xu `[一作]` (Peking University), Shanghang Zhang `[通讯]` (Peking University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出 TwinRL 框架，利用数字孪生先扩展探索空间，再通过仿真‑实景协同实现在线强化学习；

**💡 创新点**

创新点在于将数字孪生用作探索放大器和指导器，先在仿真中生成多样化轨迹并平行训练 RL，再将高质量经验直接导入真实机器人并用孪生识别关键失败状态以指导人机交互；

**🔧 技术方法**

使用 3D Gaussian Splatting、SAM3D、AnyGrasp、基于图像的 VLA 模型、仿真‑实景联动的并行 RL 与 imitation 正则化；

**📊 数据集**

基准数据集为 30 条真实机器人演示数据，外加 60 条 ID 区域、30 条 OOD 区域的数字孪生合成轨迹；

**📈 对比分析**

与 HiL‑SERL、ConRFT 等基线对比，TwinRL 在四项操作任务中实现 100% 成功率，平均约 20 分钟完成，提升约 30% 的样本效率；

**⚠️ 局限性**

局限在于早期仍存在离线‑在线分布漂移导致的性能下降，且对孪生生成的失败轨迹的利用不够系统，未来需改进指导策略与信息化失败样本。

---

## 1023. $χ_{0}$: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies

**arXiv ID:** 2602.09021 | [PDF](https://arxiv.org/pdf/2602.09021v1)

**作者:** Checheng Yu `[一作]` (Kinetix AI), Yibo Yuan `[通讯]` (Kinetix AI)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了Resource‑Aware Robust Manipulation框架，针对机器人长周期服装操作中分布失配问题，实现了持续24小时的高可靠操作。

**💡 创新点**

核心创新在于三大技术支柱——Model Arithmetic、Stage Advantage和Train‑Deploy Alignment，三者联动缓解覆盖不足、时间不匹配与失败级联，实现资源高效的鲁棒控制。

**🔧 技术方法**

技术实现包括权重空间合并模型算术、基于阶段的优势估计、DAgger与时空增强的训练‑部署对齐以及时序块平滑等。

**📊 数据集**

数据集为约20小时人工演示，覆盖不同服装、初始姿态与光照条件，并结合DAgger收集的恢复轨迹。

**📈 对比分析**

在与π_0.5基线对比中，成功率提升近250%，吞吐量提高，退行成本略增，但整体性能优于其他方法。

**⚠️ 局限性**

主要限制包括缺乏对预训练先验保留效果的评估、模型合并是否可推广至跨任务策略以及数据价值评估仍需高成本验证。

---

## 1024. Raster2Seq: Polygon Sequence Generation for Floorplan Reconstruction

**arXiv ID:** 2602.09016 | [PDF](https://arxiv.org/pdf/2602.09016v1)

**作者:** Hao Phung `[一作]` (Cornell University), Hadar Averbuch-Elor `[通讯]` (Cornell University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种将栅格化楼层平面图转为向量化格式的端到端框架，使用序列到序列的自回归方法生成带语义标记的多边形。

**💡 创新点**

核心创新包括：①将楼层平面图表示为标签多边形序列；②使用可学习锚点引导的自回归解码器，结合图像特征和已生成角点进行预测；③引入特征融合（FeatFusion）和从左到右的顺序约束。

**🔧 技术方法**

采用Transformer‑style的自回归解码器、可学习的锚点、跨模态特征融合以及 token/语义/坐标的三种损失。

**📊 数据集**

在 Structured3D‑B、CubiCasa5K、Raster2Graph 四个数据集上进行训练与评估，并在 WAFFLE 上做零样本泛化测试。

**📈 对比分析**

与 RoomFormer、FRI‑Net、HEAT、Raster2Graph 等基线相比，Raster2Seq 在结构（RoomF1、CornerF1）和语义（RoomSemF1、WindowDoorF1）指标上均取得了显著提升，尤其在复杂多房间样本上的鲁棒性更好。

**⚠️ 局限性**

局限性主要体现在：①对极其复杂或非标准几何的楼层平面图仍可能产生误差；②模型依赖于固定的语义类别集；③在推理速度和显存消耗方面相比某些轻量级方法仍较高。

---

## 1025. ANCRe: Adaptive Neural Connection Reassignment for Efficient Depth Scaling

**arXiv ID:** 2602.09009 | [PDF](https://arxiv.org/pdf/2602.09009v1)

**作者:** Yilang Zhang `[一作]` (University of Minnesota), Georgios B. Giannakis `[通讯]` (University of Minnesota)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究残差连接拓扑对深度网络收敛和深度效率的影响，并提出自适应残差连接重新分配（ANCRe）框架；

**💡 创新点**

证明不同残差拓扑可导致指数级收敛差异，并通过ANCRe学习最优残差拓扑；

**🔧 技术方法**

采用深线性网络理论、梯度流分析、softmax归一化的残差权重参数化以及在Transformer、Diffusion Transformer和ResNet中的实现；

**📊 数据集**

C4（英文文本）用于LLM预训练，ImageNet-1K用于扩散模型预训练，Gymnasium环境用于强化学习任务；

**📈 对比分析**

与传统级联残差连接对比，ANCRe在LLaMA、DiT和RL任务中均实现了加速收敛、降低困惑率/改进FID、提升精度召回等性能提升；

**⚠️ 局限性**

仅针对线性网络提供理论分析，未扩展到非线性网络；

---

## 1026. ShapeCond: Fast Shapelet-Guided Dataset Condensation for Time Series Classification

**arXiv ID:** 2602.09008 | [PDF](https://arxiv.org/pdf/2602.09008v1)

**作者:** Sijia Peng `[一作]` (Fudan University), Zhiqiang Shen `[通讯]` (Mohamed bin Zayed University of Artificial Intelligence)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `fede83ac-7505-405f-ab37-e7284695c47f` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种基于形状片（shapelet）的时间序列数据集压缩框架ShapeCond，能够在保持原始数据关键局部模式与全局时间结构的前提下，生成极小规模的合成数据集。

**💡 创新点**

创新点在于将形状片作为显式的局部判别知识引入单层模型逆向优化过程，并通过全局–局部时间结构联合优化，使压缩数据既保留长周期趋势，又保留关键短时模式；同时设计了常数时间形状片检索与高比例裁剪的高效形状片发现算法。

**🔧 技术方法**

技术主要包括：单层模型逆向数据合成、形状片发现与筛选、形状片引导的局部损失、BatchNorm统计匹配、常数时间位置约束距离计算以及高比例样本裁剪。

**📊 数据集**

在七个公开时间序列分类数据集上进行评测，分别为FacesUCR、TwoPatterns、HAR、ElectricDevices、Sleep、Tiselac、Pedestrian。

**📈 对比分析**

与多种基线（随机、Herding、K-Center、DC、DSA、MTT、SRe²L、CondTSC）对比，ShapeCond在平均压缩比例10%下达到≈88.9%原始数据性能，平均提升约17.6%，单样本/类性能提升≥20%，在时间和内存消耗上比CondTSC低约96%与69%。

**⚠️ 局限性**

局限性包括：对形状片数量与种类的选择仍需经验调参；对极小压缩比例（<5%）性能下降明显；方法对异常值与高噪声序列的鲁棒性未充分验证；在极长序列上仍需进一步优化模型架构以兼顾可扩展性。

---

## 1027. GEBench: Benchmarking Image Generation Models as GUI Environments

**arXiv ID:** 2602.09007 | [PDF](https://arxiv.org/pdf/2602.09007v1)

**作者:** Haodong Li `[一作]` (South China University of Technology), Daxin Jiang `[通讯]` (StepFun)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了用于评估图像生成模型作为可交互图形用户界面（GUI）环境的基准 GEBench，并通过 GE-Score 多维度指标进行评价。

**💡 创新点**

创新点在于（1）构建了 700 条高质量 GUI 交互序列，涵盖单步、跨步、虚拟应用、稀有轨迹和定位任务；（2）设计了基于 VLM 的评判框架，实现自动化、可重复的多维度评分；（3）提出 GE-Score，将目标达成、交互逻辑、一致性、UI 合理性、视觉质量五个维度统一量化。

**🔧 技术方法**

使用了先进的图像生成模型（如 Nano Banana Pro、GPT‑image‑1.5 等），配合 Gemini‑3‑Flash‑Native、GPT‑4o 与 Qwen3‑vl‑235b‑a22b‑thinking 等 VLM 进行评判，并基于 Transformer、参考框架和多模态 LLM 进行 GUI 生成。

**📊 数据集**

采用了 700 条从实际屏幕录制、任务标注、质量控制到构建的 GUI 数据集，包含中英两大子集，共五类任务类型，覆盖多种交互复杂度。

**📈 对比分析**

与 12 个图像生成模型（8 商业版、4 开源版）进行对比，结果显示商业模型 Nano Banana Pro 在中文子集 GE‑Score 最高（69.62），GPT‑image‑1.5 在英文子集领先（63.16）。然而，所有模型在多步规划和定位任务上表现显著下降，表明长序列一致性与精确空间定位仍是主要瓶颈。

**⚠️ 局限性**

主要局限包括：① 长期交互一致性差，容易出现误差累计；② 空间定位能力不足，GOAL 评分低；③ 文本渲染、图标识别等细节仍存在漂移和幻觉问题；④ 评判仍依赖 VLM，虽与人工高度相关但对极端情境的鲁棒性待验证。

---

## 1028. ARO: A New Lens On Matrix Optimization For Large Models

**arXiv ID:** 2602.09006 | [PDF](https://arxiv.org/pdf/2602.09006v1)

**作者:** Wenbo Gong `[一作]` (Microsoft Research), Chao Ma `[通讯]` (Microsoft Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97`

**🎯 论文内容**

提出了一种新的矩阵优化框架，称为自适应旋转优化（ARO），通过在旋转坐标系中进行规范化的最陡下降来加速大语言模型（LLM）的训练。

**💡 创新点**

创新点在于将梯度旋转视为设计原则，超越了传统的正交化和白化方法，提供了一种统一的更新规则，适用于所有矩阵参数。

**🔧 技术方法**

使用了一种新的基于旋转的优化方法，结合了梯度旋转和基于规范的投影函数，形成了自适应旋转优化（ARO）。

**📊 数据集**

在多个数据集上进行了实验，包括具有高达8B参数的LLM预训练，使用了如Sigma-MoE-2B等模型。

**📈 对比分析**

通过严格控制的基准测试协议，ARO在LLM预训练中相较于AdamW和正交化方法表现出1.3至1.35倍的速度提升，且在8B激活参数和8倍过训练预算下没有出现收益递减的证据。

**⚠️ 局限性**

限制在于现有的矩阵优化方法仍然在每层的粒度上进行设计，未能充分利用跨层和跨模块的几何耦合，且在大规模训练中可能面临计算和通信开销的挑战。

---

## 1029. Reverse Online Guessing Attacks on PAKE Protocols

**arXiv ID:** 2602.08993 | [PDF](https://arxiv.org/pdf/2602.08993v1)

**作者:** Eloise Christian `[一作]` (Rochester Institute of Technology), Edward V. Zieglar `[通讯]`

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

**🎯 论文内容**

本文通过符号模型分析，首次系统性揭示并描述了针对密码仅认证密钥交换（PAKE）协议的“反向在线猜测攻击”，并提供了攻击演示与漏洞检测方法。

**💡 创新点**

创新点在于：①提出并正式定义反向在线猜测攻击的模型；②构造通用检测技术，可在 ProVerif / CPSA 等工具中自动发现该攻击；③证明仅凭密码的 PAKE 协议在缺乏服务器身份验证时易受此攻击，并给出基于 PKI 或签名的有效防御。

**🔧 技术方法**

使用的技术主要是基于 Dolev–Yao 的符号模型、ProVerif 与 CPSA 自动协议分析工具，以及密码学原语的抽象建模。

**📊 数据集**

本研究未使用任何真实数据集，而是基于理论协议模型和抽象密码原语进行分析。

**📈 对比分析**

对比方法主要为理论证明与符号模型实验，未给出性能指标；通过自动化工具展示攻击存在与否，确认加入服务器签名后攻击被阻止。

**⚠️ 局限性**

局限性包括：①依赖符号模型假设，实际实现可能存在细节差异；②未评估攻击在真实系统中的耗时与资源占用；③对抗手段仍需在实践中进一步验证。

---

## 1030. Improving Detection of Rare Nodes in Hierarchical Multi-Label Learning

**arXiv ID:** 2602.08986 | [PDF](https://arxiv.org/pdf/2602.08986v1)

**作者:** Isaac Xu `[一作]` (Dalhousie University), Thomas Trappenberg `[通讯]` (Dalhousie University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出一种结合节点级不平衡加权和焦点加权的加权损失函数，用于层次多标签分类；

**💡 创新点**

创新点在于：①将节点频率与样本不平衡解耦，单独对每个节点进行加权；②将基于模型集成的置信度不确定性（如bBMA、GMU）嵌入焦点损失中，专注训练时不确定性高的节点；

**🔧 技术方法**

采用了基于交叉熵的层次约束损失、节点级不平衡权重、焦点加权、模型集成（多头/多模型）与不确定性度量（bBMA、GMU、贝叶斯KL/JS），以及ResNet‑50等卷积网络；

**📊 数据集**

实验数据集包括16个基因产物（FUN与GO两种分类框架）和一个海底生物影像子集BenthicNet‑E；

**📈 对比分析**

与HROS‑PD、LPROS、传统无加权等方法对比，实验显示节点级加权将召回率提升至原来的5倍，F1和Bin. AP均显著提升；在图像任务中，当编码器预训练程度低或样本量少时，方法仍能带来显著改善；

**⚠️ 局限性**

局限性：在模型已高度训练或数据量充足时加权效果减弱；部分数据集存在精度下降；需要额外的模型集成导致计算成本上升；对非常稀疏或高度重叠的层次结构的泛化尚待进一步验证。

---

## 1031. Beyond Transcripts: A Renewed Perspective on Audio Chaptering

**arXiv ID:** 2602.08979 | [PDF](https://arxiv.org/pdf/2602.08979v1)

**作者:** Fabian Retkowski `[一作]` (Karlsruhe Institute of Technology), Alexander Waibel `[通讯]` (Carnegie Mellon University)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `729e5870-4135-47f5-97f2-e3974d07b5dc` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b88c6eac-d57a-4623-a604-1f401f3eb268` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

研究音频章节划分任务，系统比较文本模型、音频仅模型 AudioSeg 以及多模态 LLM，并提出基于时间的评估协议。

**💡 创新点**

①提出 AudioSeg 并证明其在短视频上明显优于文本方法；②系统化时间域评估协议，消除对转录的依赖；③在此任务中评估并对比多模态 LLM 的性能。

**🔧 技术方法**

使用 MiniSeg 文本分割器并融合手工音频特征、三阶段音频仅模型 AudioSeg（帧编码‑段编码‑文档编码）以及 Qwen/LLama 等多模态 LLM。

**📊 数据集**

使用 YTSeg 数据集（19,299 条英语 YouTube 视频）并增添时长、说话者、两种 ASR 变体等注释。

**📈 对比分析**

采用统一的 6 秒时间网格（协议 T1）进行评估；AudioSeg 在短视频上 F1>45，显著领先文本基准；多模态 LLM 在短视频上可达约41；文本模型对 ASR 质量不敏感但受多说话者/时长影响。

**⚠️ 局限性**

仅基于单一英语数据集 YTSeg，缺乏多语言验证；多模态 LLM 受上下文长度限制，未充分调优；未利用视觉信息。

---

## 1032. Distributionally Robust Optimization via Generative Ambiguity Modeling

**arXiv ID:** 2602.08976 | [PDF](https://arxiv.org/pdf/2602.08976v1)

**作者:** Jiaqi Wen `[一作]` (University of Houston), Jianyi Yang `[通讯]` (University of Houston)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了基于生成模型的分布鲁棒优化（DRO）框架，构造了“生成性不确定性集合”并设计了相应的DRO算法，旨在提升模型在分布外（OOD）环境下的鲁棒性和泛化能力。

**💡 创新点**

创新点在于：① 使用生成模型（如扩散模型）生成多样的对抗分布，超越传统不确定性集合；② 通过参数化生成模型空间进行内层最大化，保证可求解性；③ 对该算法给出了严格的驻点收敛性分析。

**🔧 技术方法**

技术手段包括：生成模型（扩散模型）、分布鲁棒优化理论、梯度基内层优化、稳态收敛性证明及实验实现。

**📊 数据集**

实验使用了常见的机器学习数据集（如CIFAR‑10/100、ImageNet等）以及在 OOD 测试中评估模型性能，数据集细节在论文中未作详细列举。

**📈 对比分析**

与传统 DRO、基准鲁棒方法（如基于 KL 或 Wasserstein 的不确定性集合）进行对比。结果显示，GAS‑DRO 在 OOD 任务上的准确率显著高于对照组，表现出更强的泛化能力。

**⚠️ 局限性**

局限性包括：① 生成模型的质量直接影响不确定性集合的表达；② 生成过程与内层优化相结合导致计算开销增加；③ 目前的理论分析主要针对收敛性，尚缺乏对不同数据分布下性能稳定性的进一步证明。

---

## 1033. WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models

**arXiv ID:** 2602.08971 | [PDF](https://arxiv.org/pdf/2602.08971v1)

**作者:** Yu Shang `[一作]` (Tsinghua University), Yong Li `[通讯]` (Tsinghua University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `67630363-6be0-4f51-ab05-7198250671a5` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了WorldArena统一基准，用于从感知和功能两方面系统评估具身世界模型；

**💡 创新点**

首次将多维视频质量指标与下游具身任务（数据合成、策略评估、动作规划）及人类评估相结合，并提出整合指标EWMScore；

**🔧 技术方法**

使用16个视频质量度量（视觉、运动、内容一致性、物理遵循、3D精度、可控性）、人类评估、下游任务评价以及线性归一化合成的EWMScore；

**📊 数据集**

基准采用RoboTwin 2.0数据集（50种任务，2500条视频）进行评估；

**📈 对比分析**

通过对14种代表性模型的定量指标、人类评分和三类具身任务（数据引擎、策略评估、动作规划）进行对比，发现视觉质量高的模型在功能任务上仍有显著短板；

**⚠️ 局限性**

局限在于评测仅覆盖机器人操控场景，且高视觉质量并不一定提升决策性能，EWMScore与功能表现相关性有限。

---

## 1034. Hyperactive Minority Alter the Stability of Community Notes

**arXiv ID:** 2602.08970 | [PDF](https://arxiv.org/pdf/2602.08970v1)

**作者:** Jacopo Nudo `[一作]` (Sapienza University of Rome), Matteo Cinelli `[通讯]` (Sapienza University of Rome)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

利用2021-2025年完整的Community Notes（CNs）记录，系统性分析了用户贡献与投票行为，探讨了活动集中度、政治偏向性与算法决策的相互作用，进而通过对比模拟验证了极少数高活跃投票者对笔记可见性的决定性影响。

**💡 创新点**

首次将CNs的公开共识算法与完整投票数据结合，构建基于参与度与政治偏向的对比实验，揭示了社区事实核查过程中“民主”表面下的权力集中与结构不稳定性。

**🔧 技术方法**

采用公开的CNs共识算法实现、Python/NumPy/Pandas进行数据处理与统计，利用Gini系数、Lorenz曲线、饱和曲线、GMM+Ashman’s D、Jaccard相似度等计量工具；还使用了SciPy非线性最小二乘拟合等技术。

**📊 数据集**

使用X（Twitter）官方发布的完整Community Notes数据集（2021-12-02），包括2.2M条笔记、1.3M贡献者及1.84亿投票；并结合政治标签样本（218k笔记，162k推文，来自18k共和党与21k民主党账户）以实现政治倾向推断。

**📈 对比分析**

通过对比实验（从去除10到10,000名最高活跃投票者的情形）与基线，计算Jaccard相似度评估笔记状态变化；结果显示，仅去除极少数投票者（约0.007%）即可使CRH/CRNH状态相似度下降至70%以下，说明系统高度敏感且不稳定。

**⚠️ 局限性**

限制包括：无法完全复现生产环境的实时批处理与锁定机制；政治倾向仅基于投票行为推断，缺乏自我报告的理想标签；未考虑投票者在去除后的潜在适应行为；实验只改变投票者组成，未探讨算法自适应或内容动态变化的影响。

---

## 1035. Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning

**arXiv ID:** 2602.08965 | [PDF](https://arxiv.org/pdf/2602.08965v1)

**作者:** John Gardiner `[一作]` (Nasdaq, Inc.), George J. Pappas `[通讯]` (University of Pennsylvania)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

在没有通信的多智能体强化学习环境中，设计并训练利用共享量子纠缠实现协同决策的框架。

**💡 创新点**

提出可微分的量子测量参数化（QuantumSoftmax），将共享纠缠策略嵌入到MAPPO中，并首次通过经验学习实现单回合及连续决策问题的量子优势。

**🔧 技术方法**

使用基于POVM的量子软化层、梯度优化、改进的MAPPO（含协调器网络）以及量子软化层实现的可微分量子测量，结合随机性正则化与PPO‑Lagrangian。

**📊 数据集**

实验数据来自四个经典量子非局域游戏（CHSH、GHZ、两种Rendezvous）和一个基于Dec‑POMDP的多路由‑多服务器排队问题。

**📈 对比分析**

与仅共享随机数、经典因式化策略以及理论最佳通信策略对比，量子纠缠策略在单回合游戏中实现更高胜率，在排队 Dec‑POMDP 中降低了等待时间（超越共享随机的最佳结果）。

**⚠️ 局限性**

仅在单时间步内使用纠缠；未考虑多回合纠缠共享、量子噪声或有限维度测量限制；实验范围受限于可模拟的量子资源，未给出通用理论上限。

---

## 1036. A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents

**arXiv ID:** 2602.08964 | [PDF](https://arxiv.org/pdf/2602.08964v1)

**作者:** Raghu Arghal `[一作]` (University of Pennsylvania), Mario Giulianelli `[通讯]` (University College London)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

本文提出了一个同时包含行为评估和内部表示分析的框架，用来评估大语言模型代理在二维网格导航任务中的目标导向性。

**💡 创新点**

创新点在于：① 将行为评估与内部“认知图”与规划信息的可解释性探测相结合；② 设计了保持任务难度的 iso‑difficulty 变换来检验偏差；③ 通过线性/MLP 读出器揭示模型内部对环境位置、目标位置以及多步计划的非线性编码。

**🔧 技术方法**

采用的技术包括：A* 最优策略基准、动作准确率与 JSD 指标、认知图线性/MLP 读出器、一个基于 Transformer 的一次性计划解码器，以及对预推理与后推理激活的对比分析。

**📊 数据集**

使用 MiniGrid 环境生成的网格世界数据集，尺寸 7–15、障碍密度 0–1 的 10×10 组随机网格，以及三种含关键/门的变体（KeyDoorEnv、KeyNoDoorEnv、2PathKeyEnv）。

**📈 对比分析**

与最优策略对齐的行为指标随网格尺寸和障碍密度降低；在 iso‑difficulty 变换下无显著性能差异；在关键/门变体中，代理成功完成带关键的任务，且对无功能关键产生显著偏差。认知图解码准确率约 70%（MLP），而计划解码在预推理阶段对 4–5 步前缀可显著优于随机基线。

**⚠️ 局限性**

局限性包括：仅在完全可观测、极其简单的网格环境中验证；未进行因果干预以检验内部表征对行为的直接影响；仅评估 GPT‑OSS‑20B，缺乏不同规模或训练方式的泛化分析；对更复杂真实世界任务的推广仍待研究。

---

## 1037. Reduced-order Control and Geometric Structure of Learned Lagrangian Latent Dynamics

**arXiv ID:** 2602.08963 | [PDF](https://arxiv.org/pdf/2602.08963v1)

**作者:** Katharina Friedl `[一作]` (KTH Royal Institute of Technology), Danica Kragic `[通讯]` (KTH Royal Institute of Technology)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一种基于学习的结构保持低阶动力学（RO‑LNN）的隐空间跟踪控制框架，针对高维拉格朗日系统给出了全激励和间接/欠驱动的控制律，并对闭环动力学进行稳定性和收敛性分析

**💡 创新点**

创新点包括：
- 采用Riemannian几何视角的投影基础MOR，获得结构保持的低阶模型；
- 通过RO‑LNN同时学习嵌入子流形和低维拉格朗日动力学，实现“黑盒+物理”结合；
- 对投影误差、动态建模误差以及零空间效应进行定量化，推导出局部指数ISS稳定性条件；
- 扩展到间接激励和欠驱动系统，并给出混合控制方案

**🔧 技术方法**

主要技术：
- Riemannian投影与子流形学习（ae+biorthogonal权重）
- 低维拉格朗日神经网络（lnn）
- 结构保持的投影基础MOR
- PD+控制律（前馈+反馈）
- 逆变换与正则化的Lyapunov分析

**📊 数据集**

数据集：
- 仿真15维增补摆（3自由度摆+12自由度弹簧网）共4000条轨迹
- 实验柔软毛绒猴偶（351关键点）共3000条轨迹，使用人形机器人RB‑Y1执行控制

**📈 对比分析**

比较方法：
- 与无模型的PD控制器、线性插值MOR（需要已知全阶模型）以及混合RO‑LNN+PD进行对比
- 评价指标为调节误差的中位数/四分位数和圆形跟踪轨迹误差
- 结果显示：RO‑LNN控制器在调节任务中误差显著低于PD，跟踪误差优于线性MOR，混合RO‑LNN+PD在所有任务上取得最优性能

**⚠️ 局限性**

限制：
- 需要高频全状态观测，实际应用受限
- 对零空间动力学的建模不完整，仍存在小的跟踪误差
- 依赖于投影保持的近似性，若MOR假设失效则性能下降
- 目前未提供鲁棒/最优控制理论的完整证明

---

## 1038. Modeling 3D Pedestrian-Vehicle Interactions for Vehicle-Conditioned Pose Forecasting

**arXiv ID:** 2602.08962 | [PDF](https://arxiv.org/pdf/2602.08962v1)

**作者:** Guangxun Zhu `[一作]` (University of Glasgow), Edmond S. L. Ho `[通讯]` (University of Glasgow)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种车辆条件下的3D行人姿态预测框架，并将Waymo-3DSkelMo数据集扩展为包含车辆3D边界框的版本，设计了场景采样与跨注意力机制以学习行人与车辆之间的交互。

**💡 创新点**

创新点在于：①将车辆3D信息显式编码并通过Pedestrian–Vehicle Interaction Cross‑Attention（结合TRPE）融入TBIFormer，实现对行人-车辆相互作用的细粒度建模；②基于场景级采样的训练策略，有效覆盖不同人数与车辆数量的交互复杂度。

**🔧 技术方法**

采用Transformer‑based TBIFormer架构，配合离散余弦变换（DCT/IDCT）、车辆编码器、交叉注意力、Trajectory‑Aware Relative Position Encoding（TRPE）等技术实现3D姿态预测。

**📊 数据集**

使用扩展后的Waymo‑3DSkelMo数据集（含2,438,145个3D行人骨架与对应车辆3D框），以及原始Waymo Open Dataset进行训练与评估。

**📈 对比分析**

与TBIFormer单一行人预测基线对比，在1、2、3人场景以及1–4辆车情境下，加入车辆信息后MPJPE/APE/FDE均提升1.5%–21%，尤其在多行人多车场景和较长预测时程（1.0s）表现最为显著，证明车辆上下文能显著提升预测精度。

**⚠️ 局限性**

局限性：仅考虑车辆作为交互主体，未纳入其他道路使用者或静态场景语义；车辆影响受距离阈值和场景采样的限制，远距车辆可能引入噪声；未对多模态感知（如图像、语义分割）进行联合建模。

---

## 1039. From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection

**arXiv ID:** 2602.09002 | [PDF](https://arxiv.org/pdf/2602.09002v1)

**作者:** Zilin Fang `[一作]` (National University of Singapore), Gim Hee Lee `[通讯]` (National University of Singapore)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一个将几何路径规划与上下文化的社会推理相结合的机器人导航框架，利用轻量化的视觉‑语言模型（VLM）对候选路径进行社会合规性评估并选择最优路径；

**💡 创新点**

核心创新在于将大规模VLM的社会推理能力蒸馏到小型模型，实现实时推理；同时采用多阶段路径生成+VLM选择的分离式架构，避免单一模型直接生成路径所带来的安全与合规性风险；

**🔧 技术方法**

采用A*+anchor采样生成多样化几何可行路径，基于CLIP/VLM（Qwen‑2.5 fine‑tuned）进行社会语义评估，结合预测融合成本图、深度学习轨迹预测与ORCA反应控制；

**📊 数据集**

主要使用SCAND数据集进行VLM微调，并在Boston Dynamics Spot机器人上进行四个自定义社交场景（擦玻璃墙、走路聊天、摄影、排队）实验；

**📈 对比分析**

与G‑MPC、AttnGraph‑RL、ViNT、VLM‑Social‑Nav和GSON等五个基线在四个场景下的导航时间、个人空间违规、面对行人时间、社会区干扰和最大社会区干扰率等指标进行对比，实验表明本文方法在所有指标上均优于基线，尤其在社会区违规率和个人空间违规时间上实现零或极低水平；

**⚠️ 局限性**

局限性包括：仅使用单帧信息导致对长距离/延迟社交线索的感知不足；多重人类活动时可能混淆VLM的优先级判定；候选路径筛选过于保守可能影响导航效率。

---

## 1040. iGRPO: Self-Feedback-Driven LLM Reasoning

**arXiv ID:** 2602.09000 | [PDF](https://arxiv.org/pdf/2602.09000v1)

**作者:** Ali Hatamizadeh `[一作]` (NVIDIA), Jan Kautz `[通讯]` (NVIDIA)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Iterative Group Relative Policy Optimization (iGRPO)，一种两阶段的 RL 算法，在 GRPO 基础上加入自我反馈，先采样若干草稿挑选最佳，然后用该最佳草稿作为上下文进行精炼更新，从而实现动态自我改进。

**💡 创新点**

创新点在于：① 将 GRPO 的单次生成改为两阶段循环，利用模型自身产生的最佳草稿作为强化学习中的自我反馈；② 通过自适应自我条件化使得训练上下文随策略改进而演化，形成自我强化的 bootstrapping 机制；③ 在不额外增加价值函数或复杂损失的前提下，实现高效且可扩展的多步推理改进。

**🔧 技术方法**

使用技术包括：Group Relative Policy Optimization (GRPO) 的优势估计与 clipped surrogate 目标；两阶段采样（Stage 1 草稿生成、Stage 2 条件精炼）；奖励函数可为规则式二元奖励或生成式判别器（GPT‑5 Judge）；KL 惩罚、温度/Top‑p 解码；与多种基线（Self‑Verification、Critique‑GRPO、DAPO、GSPO）对比；在训练和推理时保持相同的 rollout 预算。

**📊 数据集**

主要使用的训练数据集为 MATH（7,500 步骤式竞赛题）和 AceReason‑Math（9,400 题），并在公开基准上评估：AIME24、AIME25、MATH500、AMC23、GSM8K、Minerva Math，以及通用推理任务 MMLU‑Pro、GPQA。

**📈 对比分析**

在保持相同采样预算的前提下，iGRPO 在 7B、8B、14B 大小的多种基础模型上均优于 vanilla GRPO、Self‑Verification、Critique‑GRPO，宏平均提升 1–4 分，尤其在长链推理任务（AIME、GSM8K、Minerva）上收益最大；在更强的基准和更难的数据集上，iGRPO 仍保持提升并在 AIME24/25 取得 85.62%/79.64% 的新 state‑of‑the‑art。

**⚠️ 局限性**

局限性包括：① 仍需依赖外部奖励信号（规则或生成式判别器），奖励误差可能影响草稿选择；② 只在单步推理中使用自我反馈，推理时仍为一次性生成；③ 需要两阶段采样，虽然总体预算相同，但在极端算力受限场景下会增加实现复杂度；④ 在非数学推理或需要更细粒度多步纠错的任务上效果尚未充分验证。

---

## 1041. Zero Trust for Multi-RAT IoT: Trust Boundary Management in Heterogeneous Wireless Network Environments

**arXiv ID:** 2602.08989 | [PDF](https://arxiv.org/pdf/2602.08989v1)

**作者:** Jonathan Shelby `[一作]` `[通讯]` (University of Oxford), Jonathan Shelby (University of Oxford)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `9cc9baba-5356-466d-81ff-d80028d90279` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文系统分析了多射频接入技术（multi‑RAT）无人机在零信任架构（ZTA）下的信任状态管理，提出信任边界跨越模型并引入信任可携带性概念；

**💡 创新点**

创新点在于：①首次将ZTA与多RAT交叉的信任边界问题形式化；②构造跨RAT信任存活函数与四类转移分类；③提出能在不同RAT间携带的信任证据（身份、设备、上下文）并评估其可携带性；④给出基于能量的信任优化框架（Trust‑per‑Watt）并在案例中验证其节能潜力；

**🔧 技术方法**

采用定性模型构建信任向量与权重，使用指数衰减与跨域存活矩阵；利用加密技术（JWT/CWT、X.509、DID、TPM/TrustZone）构造可携带证据；在多RAT仿真（LoRaWAN、5G/4G、Meshtastic、OcuSync、MAVLink、BLE、Wi‑Fi、卫星）中评估成本与功耗；

**📊 数据集**

本文未使用公开数据集，而是基于协议规范与硬件规格推导信任存活值和能耗估算，并通过示例 UAV 任务进行定量分析；

**📈 对比分析**

与传统一次性重鉴权相比，利用可携带信任可将 60–80% 的能耗降低；在 90 min UAV 任务中，认证能耗由 2.98 J 降至 1.12 J，节省约 62 % 的认证功率预算；

**⚠️ 局限性**

局限在于：信任存活值为经验估计，缺乏实测验证；模型假设信任组件独立，未考虑交叉相关；网络信任不可携带，导致跨RAT最优阈值不可实现；对专有协议（OcuSync）仍无通用携带方案；未来工作需在真实多RAT平台上测量能耗与可信度。

---

## 1042. WorldCompass: Reinforcement Learning for Long-Horizon World Models

**arXiv ID:** 2602.09022 | [PDF](https://arxiv.org/pdf/2602.09022v1)

**作者:** Zehan Wang `[一作]` (Zhejiang University), Zhou Zhao `[通讯]` (Zhejiang University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

针对长时序、交互式视频世界模型的后训练，提出WorldCompass框架通过强化学习提升模型的交互准确性和视觉质量。

**💡 创新点**

核心创新包括（1）clip‑level rollout策略，显著提高rollout效率并提供细粒度奖励；（2）针对动作跟随和视觉质量的互补奖励函数，抑制奖励劫持；（3）负向感知微调（negative‑aware fine‑tuning）及一系列效率优化，保证训练可行性。

**🔧 技术方法**

利用DiffusionNFT/GRPO等RL算法、3D基础模型估计相机轨迹、HPSv3评估视觉质量、EMA、Best‑of‑N、子时间步采样等技术实现。

**📊 数据集**

以开源世界模型WorldPlay为基础，使用4000张带说明的图像（无人工标注）作为训练数据，测试时采样600个视频案例。

**📈 对比分析**

在HunyuanVideo‑1.5-8B和Wan2.2-5B两版模型上，WorldCompass显著提升了动作跟随准确率（从约20%提升至55%）和HPSv3视觉质量（提升约2–3分），同时保持了较高的实时性。

**⚠️ 局限性**

限制包括仍需依赖外部3D模型估计相机轨迹，奖励设计与任务特定，且在极长时序或高复杂动作组合下的泛化性与稳定性仍有待验证。

---

## 1043. Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving

**arXiv ID:** 2602.09018 | [PDF](https://arxiv.org/pdf/2602.09018v1)

**作者:** Amir Mallak `[一作]` (University of Haifa), Alaa Maalouf `[通讯]` (University of Haifa)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文通过将环境因子拆分为场景、季节、天气、时间与主体混合，利用k因子扰动在VISTA仿真平台上评估闭环驾驶政策的OOD鲁棒性。

**💡 创新点**

创新点在于提供可复现的因子化评估框架、对不同网络结构与预训练特征的系统对比，以及揭示多因子交互非加性和训练数据分布对鲁棒性的影响。

**🔧 技术方法**

使用了全连接网络、卷积网络、Vision Transformer以及冻结的基础模型特征（DINO、BLIP‑2、CLIP）作为特征提取器，并在多帧输入下构建时间上下文模型。

**📊 数据集**

主要使用VISTA仿真数据集，构造了多种离散因子组合的训练、验证与测试集。

**📈 对比分析**

通过在k=1,2,3的不同因子变化下对比各模型，发现ViT与基于BLIP‑2的特征在单帧输入下达到约88%闭环成功率，且在三重变化下仍保持≥85%，而非基于FM的模型在三重变化下跌至<50%；多帧时间上下文模型提升约10点但未超越最佳单帧ViT。

**⚠️ 局限性**

局限在于仅使用仿真数据且因子离散化粗糙，未验证于真实驾驶环境，且对连续因子变化和更复杂交互的分析不足。

---

## 1044. DirMoE: Dirichlet-routed Mixture of Experts

**arXiv ID:** 2602.09001 | [PDF](https://arxiv.org/pdf/2602.09001v1)

**作者:** Amirhossein Vahidi `[一作]` (Wellcome Sanger Institute), Mohammad Lotfollahi `[通讯]` (Wellcome Sanger Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `afceb026-1760-41ae-8d86-010831a37d97` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种可微分的Mixture-of-Experts路由器DirMoE，解耦专家选择与权重分配；

**💡 创新点**

创新点是将路由拆为伯努利专家选择与Dirichlet分布的贡献分配，利用Dirichlet先验可调控稀疏度，并使用Gumbel‑Sigmoid与隐式重参数化实现端到端可微；

**🔧 技术方法**

技术包括Dirichlet变分自编码、Gumbel‑Sigmoid、隐式重参数化、ELBO目标、稀疏正则、温度与浓度调度；

**📊 数据集**

使用The Pile数据集进行预训练，零样本评估在ARC、BoolQ、HellaSwag、LAMBADA、PIQA、RACE等基准；

**📈 对比分析**

与传统Top‑k+Softmax、Switch、ReMoE等对比，在相同计算量下取得更高或相当的零样本精度，并提升专家专门化；

**⚠️ 局限性**

局限在于对超参数（如α_hi, α_lo, λ）敏感，且在极端稀疏或高负载情况下仍可能出现专家利用不平衡。

---

## 1045. Paradox of De-identification: A Critique of HIPAA Safe Harbour in the Age of LLMs

**arXiv ID:** 2602.08997 | [PDF](https://arxiv.org/pdf/2602.08997v1)

**作者:** Lavender Y. Jiang `[一作]` (New York University), Eric K. Oermann `[通讯]` (New York University)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

研究在 HIPAA Safe Harbor 去标识化后，利用大型语言模型通过非敏感信息（如诊断、兴趣）重识别患者的风险。

**💡 创新点**

首次将因果图与实证实验相结合，揭示去标识化的结构性悖论，并证明仅凭诊断信息即可泄露患者身份。

**🔧 技术方法**

使用因果图建模、BERT‑base‑uncased 微调进行属性预测、AUC/准确率评估以及基于 top‑k 匹配的重识别攻击。

**📊 数据集**

基于 NYU Langone 医院 170,283 名患者的 222,949 条临床笔记，去标识化后提取的六个属性（性别、出生年份/月份、邮编、地区收入、保险类型、所在行政区）。

**📈 对比分析**

与随机基线比较，属性预测准确率显著高于随机，诊断单独预测 AUC 58.57%，去标识化笔记 AUC 78.35%；重识别风险约 0.34%，比随机基线高约 37 倍。

**⚠️ 局限性**

仅在单一医院数据集实验，假设攻击者拥有完整数据库，未考虑更复杂的辅助信息或多机构数据，实际风险可能更高。

---

## 1046. InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery

**arXiv ID:** 2602.08990 | [PDF](https://arxiv.org/pdf/2602.08990v1)

**作者:** Shiyang Feng `[一作]` (InternScience Team), Lei Bai `[通讯]` (InternScience Team)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出一个统一的端到端科学发现系统（InternAgent‑1.5），能在计算与实验环境中完成假设生成、方案验证与演化。

**💡 创新点**

创新点在于将生成、验证、演化三子系统与深度研究、方案细化、长期记忆三大基础能力耦合，实现跨学科统一的自适应循环，并通过图增强蒙特卡罗搜索与结构化认知记忆提升长期推理与实验优化。

**🔧 技术方法**

技术包括：跨学科知识图与流程图构建、图增强蒙特卡罗搜索、工具调用与多模态检索、结构化认知记忆（SPM、TEM、SKM）以及多任务调度与强化学习优化。

**📊 数据集**

使用的数据集涵盖：SGI‑Bench、GAIA、HLE、FrontierScience、GPQA、AutoRYP/AutoTPPR/AutoPower/AutoTSF/AutoMD/AutoEAP、AutoTTS/AutoMem/AutoTTRL/AutoLM 等算法任务；以及地球科学、生命科学、物理化学实验任务所用的 CMIP6/ERA5、TCGA/OpenTargets、实验室设备自动化平台等。

**📈 对比分析**

与 Gemini‑3‑pro、GPT‑5、MiroThinker、Tongyi‑DR 等多模型在 SGI‑Bench、GAIA、HLE、FrontierScience、GPQA 等基准上对比，InternAgent‑1.5 在大多数任务上实现或逼近最高分，显著提升多步推理、实验规划和知识整合的准确率与效率。

**⚠️ 局限性**

局限性：依赖大型语言模型与昂贵算力，实验自动化受限于可用设备与工具；跨学科知识覆盖仍不完整，记忆更新机制需进一步优化；在极度稀缺或高噪声数据场景下的鲁棒性尚待验证。

---

## 1047. StretchTime: Adaptive Time Series Forecasting via Symplectic Attention

**arXiv ID:** 2602.08983 | [PDF](https://arxiv.org/pdf/2602.08983v1)

**作者:** Yubin Kim `[一作]` (Georgia Institute of Technology), Jiecheng Lu `[通讯]` (Georgia Institute of Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一种基于对称群Sp(2,ℝ)的可学习时序位置编码方法SyPE，并在Transformer中实现自适应时间扭曲机制StretchTime，用于多变量时间序列预测

**💡 创新点**

通过将旋转群SO(2)推广到对称群Sp(2,ℝ)并加入可学习的时间变形模块，首次在理论上证明RoPE无法处理非仿射时间扭曲，进而实现自适应地拉伸或压缩时间轴

**🔧 技术方法**

使用了Symplectic Positional Embedding（SyPE）、自适应warp模块、残差学习与通道-值混合Token化等技术，构建了轻量级Transformer架构

**📊 数据集**

在12个公开基准数据集（ETT系列、PEMS系列、Weather、Solar‑Energy、Electricity等）以及人工合成的时间扭曲AR(1)数据上进行实验

**📈 对比分析**

与RoPE、OLinear、TimeMixer++、iTransformer、PatchTST、TimesNet、DLinear等主流模型对比，StretchTime在10个数据集上平均排名2.20，4个数据集获得首位，且在多变量预测任务中大幅降低MSE/MAE，参数量仅约50万，计算成本低于多数Transformer基线

**⚠️ 局限性**

目前仅在中小规模数据集上验证，未对大规模数据集或其他序列任务（如NLP）进行评估；对极端噪声环境的鲁棒性以及可扩展性仍待进一步研究

---

## 1048. PPG as a Bridge: Cross-Device Authentication for Smart Wearables with Photoplethysmography

**arXiv ID:** 2602.08972 | [PDF](https://arxiv.org/pdf/2602.08972v1)

**作者:** Jiacheng Liu `[一作]` (Cornell University), Yuntao Wang `[通讯]` (Tsinghua University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `9cc9baba-5356-466d-81ff-d80028d90279` `5a41884c-404f-4688-a89c-aa238c10fe68` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

研究了一种利用智能手机 rPPG 与可穿戴设备 PPG 的跨设备认证方法 PPGTransID。

**💡 创新点**

通过实时生理信号一致性实现无交互、跨设备身份认证，避免了每个设备单独模板注册。

**🔧 技术方法**

采用远程光心图 (rPPG) 提取、同步 PPG 预处理、特征工程与 XGBoost 分类，并使用 TN‑rPPG / ME‑rPPG 模型。

**📊 数据集**

使用了 33 名参与者的多设备（环、腕带、眼镜、耳机）同步 PPG 与 rPPG 数据，以及 14 名参与者的实时演示数据。

**📈 对比分析**

与 SVM、RF、深度双塔等基线方法对比，PPGTransID 在离线实验中实现 95.5% BAC，实时演示 97.7% BAC，显著优于传统方法并对攻击鲁棒。

**⚠️ 局限性**

需要至少 6 秒的持续采样、对强运动或极端条件不鲁棒，且对潜在隐私担忧仍需进一步解决。

---

## 1049. Maximin Shares with Lower Quotas

**arXiv ID:** 2602.08966 | [PDF](https://arxiv.org/pdf/2602.08966v1)

**作者:** Hirota Kinoshita `[一作]` (Toyota Technological Institute), Ayumi Igarashi `[通讯]` (University of Tokyo)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文研究在存在下限配额约束的情形下，如何为可加异质效用的代理人实现近似最大最小份额（MMS）分配，并给出多类别的泛化。

**💡 创新点**

创新点在于：1）首次考虑下限配额对MMS近似的影响；2）提出一种多袋更新的贪心算法，在保持可行性与价值均衡的同时，递归实现近似MMS；3）在多类别约束下通过有效递归实现更强的近似比；4）改进了不受限和仅上限配额情况的已知结果。

**🔧 技术方法**

主要技术包括：①将实例转化为有序实例；②有效递归（valid reduction）去除高价值小包；③多袋贪心填充与两类更新（移动与交换）维护价值与规模不等式；④归纳证明维护一系列不变式并保证最终分配满足α‑MMS；⑤多类别情况采用逐类递归与上限配额结果组合。

**📊 数据集**

论文为理论研究，没有使用真实数据集；所有结果均为严格的算法复杂度与近似比分析。

**📈 对比分析**

与无下限配额或仅上限配额的最优算法相比，本文在保证多项式时间的前提下：对于单类商品得到(2/3−1/|N|)-MMS（优于此前的2/3），对单类杂物得到(3/2−1/(2|N|))-MMS；在多类商品下得到(1/2−1/|N|)-MMS，在多类杂物下得到(2−1/|N|)-MMS；所有算法时间复杂度为O(|N||M|log|M|)。

**⚠️ 局限性**

局限性包括：1）仅处理可加效用，未考虑非可加或复杂效用；2）对下限配额的近似比未被证明为最优，是否有更高比率仍是开放问题；3）缺乏经验评估，未验证在实际应用中的性能；4）不同时考虑效率（Pareto最优等）与多种公平标准的联合约束。

---

## 1050. stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation

**arXiv ID:** 2602.08968 | [PDF](https://arxiv.org/pdf/2602.08968v1)

**作者:** Lucas Maes `[一作]` (Mila and Université de Montréal), Randall Balestriero `[通讯]` (Brown University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `5b4c1114-4a70-478e-9921-2514ee03850d` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了一个名为 Stable World Model (SWM) 的可扩展、可测试、文档完善的世界模型研究生态系统，并用它评估了 DINO-WM 在不同因素变化下的零样本鲁棒性。

**💡 创新点**

创新点包括：①提供统一的 World 接口和 Factor of Variation（FoV）控制，②整合多种环境与标准化评估套件，③在代码量、PR 活跃度、类型检查和测试覆盖率等方面优于现有实现，从而提升可复用性与评估一致性。

**🔧 技术方法**

技术实现基于 PyTorch + Gymnasium，使用 MPC 与 Feed‑Forward 规划进行评估，FoV 通过自定义 Space 实现，可记录数据集并支持多环境同步运行。

**📊 数据集**

使用了 SWM 自带的 PushT、TwoRoom、DeepMind Control Suite（Humanoid）以及 OGBench 等环境，并在 DINO‑WM 的演示数据上进行零样本鲁棒性实验。

**📈 对比分析**

通过与 PLDM、DINO‑WM 等公开代码库对比（表格显示 SWM 在代码行数、PR 数量、类型检查、测试覆盖率等指标更优），以及在 DINO‑WM 上的实验（分布内 94% 成功率，分布外 12% 成功率），展示了 SWM 在可复现性和评估一致性方面的优势；然而 DINO‑WM 在 FoV 变化下的零样本鲁棒性较差。

**⚠️ 局限性**

局限性在于：①生态系统尚属早期，环境覆盖面有限；②鲁棒性评估仅覆盖少量 FoV，缺乏对更复杂或真实世界任务的验证；③缺乏深入的模型解释与调试工具，需进一步完善。

---

