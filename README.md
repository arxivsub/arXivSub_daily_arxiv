# arXiv Daily Summary

![Last Commit](https://img.shields.io/github/last-commit/arxivsub/arXivSub_daily_arxiv?label=Updated)
![Arxiv](https://img.shields.io/badge/arXiv-Papers-B31B1B.svg)
![Python](https://img.shields.io/badge/Powered%20By-Python-3776AB?logo=python&logoColor=white)
![Views](https://komarev.com/ghpvc/?username=arxivsub&repo=arXivSub_daily_arxiv&label=Views&color=brightgreen&style=flat)
![License](https://img.shields.io/badge/license-MIT-green)

> 最后更新时间: 2026-01-21 | 今日论文总数: 987

> 更多内容请访问 [arXivSub](https://arxivsub.comfyai.app/)

---

## 1. A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models

**arXiv ID:** 2601.12304 | [PDF](https://arxiv.org/pdf/2601.12304v1)

**作者:** Wutao Chen `[一作]` (Shantou University), Lifeng Huang `[通讯]` (South China Agricultural University)

**通讯引用:** 326 | [OpenAlex ID](https://openalex.org/A5029844813)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出一种两阶段全局多样化攻击框架 2S-GDA，用于提升视觉语言预训练模型的对抗攻击转移性。

**💡 创新点**

创新点在于通过两阶段流程去除文本重扰动、引入全局候选文本扩展和全局感知替换，并在图像端采用多尺度重缩放与块旋转增强多样性。

**🔧 技术方法**

采用 BERT-MLM 与 WordNet 构建多源候选词汇、梯度重要性评估的全局感知替换、PGD 图像扰动与多尺度/块旋转数据增强、以及对跨模态对齐损失的优化。

**📊 数据集**

实验基于 Flickr30K 进行评测，并在补充材料中展示 MSCOCO 结果。

**📈 对比分析**

与 SGA、SGA-BSR、DRA、SA-AET 等四种主流攻击及其组合做对比，白盒下 100% 成功率，黑盒下提升 0.1%–11.17% 的攻击成功率，显著优于现有方法。

**⚠️ 局限性**

仍受限于词级替换导致的语义漂移、对攻击模型的依赖以及在更广泛模型上的转移性尚待验证。

---

## 2. A Cloud-based Multi-Agentic Workflow for Science

**arXiv ID:** 2601.12607 | [PDF](https://arxiv.org/pdf/2601.12607v1)

**作者:** Anurag Acharya `[一作]` (Pacific Northwest National Laboratory), Robert Rallo `[通讯]` (Pacific Northwest National Laboratory)

**通讯引用:** 3879 | [OpenAlex ID](https://openalex.org/A5047048362)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发并部署了一个面向科学研究的云端多智能体工作流，能够在催化剂研究中自动完成文献综述、数据分析、模拟、图像分割等任务。

**💡 创新点**

创新点在于：①将多种专业工具（如OSTI检索、GPU分割、CPU模拟）与LLM代理无缝集成；②采用LangGraph Supervisor实现动态任务路由；③在云端实现可水平扩展的批处理计算；④针对催化领域构建专属评估基准，并公开验证。

**🔧 技术方法**

技术包括：LangGraph + LangChain Supervisor、Claude 3.7 Sonnet 与 OpenAI o3-mini LLM、Pydantic 数据校验、Docker 容器化、AWS Batch/EC2、Azure OpenAI、Streamlit 前端、FastAPI 后端、S3 对象存储、Elasticsearch 或类似关键词索引、Guardrails 代码安全过滤。

**📊 数据集**

数据集：①人工合成的120条测试案例（20条每个6个Agent），②ChemBench 2786条化学领域真实查询，③在系统内部使用的催化剂实验元数据与模拟数据（DRIFTS、XAS、视频等）。

**📈 对比分析**

评估方法：①路由正确率和任务完成率的量化测试；②在ChemBench上与31个前沿模型对比。结果显示：整体任务完成率97.5%，路由正确率90%；在ChemBench上成功率90.5%、正确率61%，与最优模型相比误差仅3%，排名第4。相比之下大部分前沿模型的正确率只有约58%。

**⚠️ 局限性**

局限性：①LangGraph 结构限制导致任务路由在词义相似时误判；②缺乏会话持久化，无法支持多轮交互；③无人工审核的中间检查点；④流式聊天 API 体验不够友好；⑤仅在 AWS 上实现，尽管设计可移植，但实际部署仍需改造。

---

## 3. Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images

**arXiv ID:** 2601.12664 | [PDF](https://arxiv.org/pdf/2601.12664v1)

**作者:** Elisa Gonçalves Ribeiro `[一作]` (Federal University of Viçosa), André Ricardo Backes `[通讯]` (Federal University of São Carlos)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出将单一癌症影像数据集上优化的超参数迁移并聚合，用于跨癌种的非IID联邦学习；

**💡 创新点**

创新点在于构建一个简单的聚合启发式，将不同任务的最佳学习率取均值、优化器与批量大小取众数，从而得到通用的超参数配置；

**🔧 技术方法**

采用了中心化的TPE贝叶斯超参数优化、FedAvg联邦聚合、CNN（AlexNet、ResNet18/34/50、SqueezeNet、EfficientNet‑B0）以及ImageNet预训练；

**📊 数据集**

使用了卵巢癌和结肠癌两组数字病理图像数据集（分别来自Kaggle），通过划分训练/验证/测试集形成非IID分布；

**📈 对比分析**

在联邦环境下比较三种超参数方案（卵巢优化、结肠优化、聚合配置），结果显示聚合配置在所有模型上获得最高平均F1≈0.909，比单一任务优化略优；

**⚠️ 局限性**

局限在于仅考察两种癌种、少量CNN架构及简化的聚合策略，未验证更复杂任务或更大规模联邦网络的泛化性。

---

## 4. VR ProfiLens: User Profiling Risks in Consumer Virtual Reality Apps

**arXiv ID:** 2601.12563 | [PDF](https://arxiv.org/pdf/2601.12563v1)

**作者:** Ismat Jarin `[一作]` (University of California), Athina Markopoulou `[通讯]` (University of California)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文研究了消费者VR应用中通过抽象化传感器数据进行用户属性推断的风险，构建了基于CCPA的用户属性分类，并通过用户研究验证了多种传感器组合的推断效果。

**💡 创新点**

创新点在于提出了可扩展的、法律导向的用户属性分类法、统一的框架用于评估VR传感器数据的用户画像风险，并首次系统评估多传感器、多应用场景下的属性推断性能。

**🔧 技术方法**

使用了机器学习推断模型（如随机森林、LightGBM、回归）和信息增益特征重要性分析，并结合OpenXR标准的传感器采集。

**📊 数据集**

数据集为来自30名用户、10款热门消费者VR应用（涵盖7类应用组）的身体运动、眼动、手部关节和面部表情四组传感器数据及对应的48项属性标签。

**📈 对比分析**

通过5折交叉验证，平均F1得分在70-100%之间，说明多传感器组合可实现高精度属性推断，证明用户画像风险可被量化；与单传感器相比，组合提升约8-30%风险。

**⚠️ 局限性**

主要局限在样本规模有限、缺乏儿童样本、实验仅覆盖Meta Quest Pro等单一硬件，且未对防御方案进行实证验证。

---

## 5. Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty

**arXiv ID:** 2601.12471 | [PDF](https://arxiv.org/pdf/2601.12471v1)

**作者:** Sravanthi Machcha `[一作]` (University of Massachusetts Amherst), Zonghai Yao `[通讯]` (University of Massachusetts Amherst)

**通讯引用:** 247 | [OpenAlex ID](https://openalex.org/A5012790041)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出并实现了 MedAbstain 基准，评估医疗多项选择问答任务中 LLM 的拒答能力与不确定性。

**💡 创新点**

创新点在于将合规预测、对抗扰动以及显式拒答选项统一融合，首次在闭源与开源模型上系统检验其安全性。

**🔧 技术方法**

主要技术包括 conformal prediction、对抗性问题扰动、few‑shot/零‑shot 与 Chain‑of‑Thought 推理以及显式拒答选项。

**📊 数据集**

使用公开的 MedQA (USMLE) 与专有的 AMBOSS 临床多项选择数据集进行实验。

**📈 对比分析**

通过在多种 LLM 上做零、少、CoT 推理实验比较，发现显式拒答显著提升不确定性校准与安全性，但模型规模或 CoT 对拒答率提升作用有限。

**⚠️ 局限性**

局限性包括仅覆盖英文数据、仅针对多项选择任务、未扩展到多语言或开放式医学问答，且闭源模型的置信度获取仍受限。

---

## 6. Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention

**arXiv ID:** 2601.12231 | [PDF](https://arxiv.org/pdf/2601.12231v1)

**作者:** Kaichuan Kong `[一作]` (Jinan University), Guanggang Geng `[通讯]` (Jinan University)

**通讯引用:** 1347 | [OpenAlex ID](https://openalex.org/A5035643851)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一种基于小波的多分辨率框架，用于从多通道用户日志中检测内部威胁异常。

**💡 创新点**

创新点包括偏差感知调制机制、离散小波变换的多分辨率分解以及分辨率自适应注意力模块，三者协同突出异常特征。

**🔧 技术方法**

采用了离散小波变换 (DWT) 进行时间‑频率分解，结合自适应注意力对各频段加权，并使用传统与深度学习检测器（XGBoost、Transformer、TCN 等）进行实验。

**📊 数据集**

实验使用了公开的 CERT r4.2 内部威胁检测基准数据集，涵盖三种攻击场景与多时段窗口。

**📈 对比分析**

与 DWT‑OCSVM、MWCapsNet、CATE、ITDLM 等现有方法以及 AE、IForest、XGBoost、Transformer、TCN 等模型对比，本文方法在精确率、召回率、F1 分数上均取得最高值（平均 0.97‑0.99），并在排行榜中名列前茅。

**⚠️ 局限性**

局限性在于仅验证于 CERT 数据集，缺乏对更大规模、云日志或实时流日志的适应性评估，且依赖于预先统计的均值方差，可能对数据分布漂移不够鲁棒。

---

## 7. Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents

**arXiv ID:** 2601.12560 | [PDF](https://arxiv.org/pdf/2601.12560v1)

**作者:** Arunkumar V `[一作]` (Anna University), Rajkumar Buyya `[通讯]` (University of Melbourne)

**通讯引用:** 105000 | [OpenAlex ID](https://openalex.org/A5014716105)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `9cc9baba-5356-466d-81ff-d80028d90279` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文通过对大型语言模型驱动的代理系统进行系统梳理，提出统一的架构与分类法，并从感知、记忆、计划、行动、工具使用和协作等六大维度出发，构建基于POMDP的完整控制循环，阐述从单循环到多代理图结构的演进，并对数字、机器人及科学等环境下的评估与安全挑战进行深入探讨。

**💡 创新点**

创新点包括：①提出以核心组件、认知架构、学习、协作、环境与评估为维度的统一代理体系结构与分类；②将多代理协作与图式工作流（flow engineering）结合，明确可观测性与安全边界；③将评估指标从单一文本相似度扩展至CLASSic（成本、延迟、准确度、安全性、稳定性）框架，并讨论了MCP等标准化工具连接层。

**🔧 技术方法**

技术涵盖：POMDP控制循环、向量数据库和RAG式记忆、代码即行动与电脑使用接口、Tree-of-Thought、ReAct、Reflexion、LATS、o1/o3推理模型、图式编排框架（LangGraph、AutoGen、MetaGPT等）、多代理协同拓扑、MCP标准、以及安全防护的多层防御机制。

**📊 数据集**

使用的主要数据集与基准包括：WebArena、OSWorld、SWE‑Bench、SWE‑Bench Pro、AgentBench、MultiAgentBench（MARBLE）、WebVoyager、CoAct、SWE‑Bench Verified 等数字与软件工程环境测试集，以及科学实验、金融交易模拟等专业领域数据。

**📈 对比分析**

与前沿系统对比，CoAct 1在电脑使用+代码即行动的综合方案中实现约60.8%成功率，SWE‑Bench Verified提升了软件工程任务的可靠度，MetaGPT与AutoGen等多代理框架在工作流执行与错误纠正方面显著低于单代理模型；在延迟与成本方面，层次化规划与Tree‑of‑Thought虽提高了准确度，但带来显著的推理成本与时延。

**⚠️ 局限性**

局限性主要体现在：①行动层面的幻觉导致不可逆错误，②循环与停滞难以终止，③多代理与树搜索带来高计算与延迟成本，④安全防护仍依赖多层防御且易被间接注入攻击，⑤缺乏自我进化与开放式学习能力，⑥理论边界与最优性尚未得到充分探讨。

---

## 8. Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization

**arXiv ID:** 2601.12707 | [PDF](https://arxiv.org/pdf/2601.12707v1)

**作者:** Junyi Liao `[一作]` (Duke University), Vahid Tarokh `[通讯]` (Duke University)

**通讯引用:** 32948 | [OpenAlex ID](https://openalex.org/A5020766546)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出了一套统一的逆向博弈框架，在熵正则化的两人零和矩阵游戏和马尔科夫游戏中恢复奖励函数。

**💡 创新点**

建立了基于量子响应均衡（QRE）的可识别性条件，给出了全可识别与部分可识别的理论分析，并设计置信集构造与样本复杂度证明，同时引入MLE加速的QRE估计方法。

**🔧 技术方法**

使用了线性参数化、QRE、矩阵秩条件、置信集构造、频率估计、最大似然估计、Ridge回归、Hellinger/TV距离分析等技术。

**📊 数据集**

实验使用人工生成的数据集：从QRE策略采样得到的矩阵游戏和马尔科夫游戏的样本，未使用公开真实数据集。

**📈 对比分析**

与传统频率估计方法对比，MLE-QRE方法在样本量较少时收敛更快；理论误差达到O(1/√N)，实验显示无论规模如何，算法均能准确恢复QRE，尽管奖励函数可能不唯一，但行为解释保持一致。

**⚠️ 局限性**

局限性包括对线性假设和熵正则化的依赖；要求对所有状态/动作有足够覆盖，秩缺失会导致部分可识别，提升估计偏差；未考虑非线性或部分可观测情形。

---

## 9. Unleashing Efficient Asynchronous RL Post-Training via Staleness-Constrained Rollout Coordination

**arXiv ID:** 2601.12784 | [PDF](https://arxiv.org/pdf/2601.12784v1)

**作者:** Haoyang Li `[一作]` (Peking University), Bin Cui `[通讯]` (Peking University)

**通讯引用:** 12540 | [OpenAlex ID](https://openalex.org/A5062357883)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一个全分离式的RL后训练系统StaleFlow，能够在保持严格的轨迹新旧度约束下，同时通过多种数据平衡策略显著提升吞吐量。

**💡 创新点**

创新点在于：① 设计了基于虚拟迟滞缓冲区的全局一致性协议，实现对每条轨迹的新旧度的细粒度跟踪与控制；② 引入轨迹服务器和参数服务器作为中介解耦数据移动；③ 开发了一套以系统快照为基础的可插拔吞吐导向的协同调度策略（路由、同步、迁移），在保证数据新旧度的前提下最大化吞吐。

**🔧 技术方法**

核心技术包括：全分离式架构、轨迹版本标识、虚拟迟滞缓冲区、读写锁同步的参数服务器、基于多级队列的轨迹路由、成本模型与阈值驱动的调度决策、快照-命令循环与投机状态验证。

**📊 数据集**

使用了DOPO-Math-17k和AIME24两大数学题目数据集，并在Qwen系列模型（Qwen2.5-14B/32B、Qwen3-30B-A3B等）上进行实验。

**📈 对比分析**

与五类基线（VeRL同步、VeRL-Pipeline一阶异步、VeRL-Async、AReaL、Roll Flash）对比，在不同模型、批量、响应长度与GPU规模下，StaleFlow平均提升1.17-2.01倍吞吐量，最大可达2.68倍，同时在η∈[1,3]的严格新旧度约束下保持与无迟滞系统相当的收敛性。

**⚠️ 局限性**

主要局限在于：① 仍需手动调节多种阈值参数（μ、φ_wait、φ_throughput）以获得最优性能；② 对极大规模系统的可扩展性仍需在更大GPU集群与多模型场景下进一步验证；③ 目前仅评估了数学推理任务，未涵盖多模态或编程类RL任务。

---

## 10. Beyond Identification: Computing Boolean Functions via Channels

**arXiv ID:** 2601.12640 | [PDF](https://arxiv.org/pdf/2601.12640v1)

**作者:** Jingge Zhu `[一作]` (University of Melbourne), Matthias Frey `[通讯]` (University of Melbourne)

**通讯引用:** 168 | [OpenAlex ID](https://openalex.org/A5001013322)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

本文研究在点对点通信系统中，接收端需恢复未知布尔函数值的情形，探讨了消息长度m与信道使用n的可扩展关系，提出了布尔函数计算容量的概念。

**💡 创新点**

创新点在于将识别问题推广为布尔函数计算问题，并对不同 Hamming 重量阈值S的函数类给出m与n的完整尺度关系，从指数级到线性级别的全系列分析。

**🔧 技术方法**

采用信息理论工具，包括信息容量、随机编码与组合设计（如有限集合的交集控制）、识别码的上下界推导以及Gilbert–Varshamov 型常数权码构造。

**📊 数据集**

文中未使用任何外部数据集，全部基于理论分析与仿真证明。

**📈 对比分析**

通过对比已知的识别码容量界限与自定义布尔函数计算码，展示在各类S取值下，所得到的上界与下界在尺度级别上完全匹配，证明了理论结果的紧密性。

**⚠️ 局限性**

局限性主要在于仅考虑单一布尔函数计算，未涉及多函数同步计算或反馈通道；且对非常大S（接近2^m）时的细节推导仍相对粗略。

---

## 11. Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding

**arXiv ID:** 2601.12260 | [PDF](https://arxiv.org/pdf/2601.12260v1)

**作者:** Yihao Ding `[一作]` (University of Western Australia), Wei Liu `[通讯]` (University of Western Australia)

**通讯引用:** 53603 | [OpenAlex ID](https://openalex.org/A5100431792)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出 Docs2Synth 框架，自动生成合成 QA 对并训练轻量级检索器，以零样本方式提升私有低资源领域的视觉-语言文档理解。

**💡 创新点**

创新点在于结合合成监督的检索指导循环，既无须人工标注又能与 MLLM 迭代协同提升答案的可靠性与领域泛化。

**🔧 技术方法**

采用 OCR+XY‑cut 文本提取、LLM 驱动的合成 QA 生成与验证、布局感知的视觉检索器微调，以及检索‑生成迭代推理的 RAG 机制。

**📊 数据集**

在 Form‑NLU、CORD、Ephoie 三个扫描文档基准上进行评估，同时利用公开的多模态 LLM 及 VLPM 对比。

**📈 对比分析**

与 GPT‑4o、Gemini 1.5 及 Qwen2‑VL、Idefics2、InternVL2 等模型在默认 HuggingFace 设置下对比，Docs2Synth‑检索器版本在三组基准上均超过最佳基线，尤其在打印版 Form‑NLU 上提升显著。

**⚠️ 局限性**

局限性包括对 OCR 质量敏感、检索器需在本地训练且迭代过程仍需 GPU，且合成 QA 的多样性与真实性尚未达到完全无误。

---

## 12. Adaptively trained Physics-informed Radial Basis Function Neural Networks for Solving Multi-asset Option Pricing Problems

**arXiv ID:** 2601.12704 | [PDF](https://arxiv.org/pdf/2601.12704v1)

**作者:** Yan Ma `[一作]` (Northwest Normal University), Yumeng Ren `[通讯]` (City University of Hong Kong)

**通讯引用:** 881 | [OpenAlex ID](https://openalex.org/A5070426804)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文提出一种物理信息径向基函数神经网络（PIRBFNN），用于求解多资产Black‑Scholes偏微分方程并给出欧式期权价格。

**💡 创新点**

创新点在于将可训练的RBF中心位置、形状参数与线性权重统一纳入神经网络，并通过基于PDE残差的自适应机制动态增删隐藏神经元，从而兼具网格无关的RBF逼近与PINN的物理约束。

**🔧 技术方法**

使用的技术包括RBF神经网络、自动微分实现的PINN损失函数、L‑BFGS二阶优化器以及残差驱动的自适应中心点更新。

**📊 数据集**

在实验中使用了单资产欧式看跌期权、双资产交换期权和四资产篮子看涨期权的解析解或蒙特卡洛参考数据作为训练和评估。

**📈 对比分析**

与传统RBF共轭法和深度PINN相比，PIRBFNN在相同迭代次数下达到更低的RMSE（如单资产期权RMSE≈6.2×10⁻⁴），并在高维（四维）问题中仍保持可接受的误差级别。

**⚠️ 局限性**

局限性包括单隐藏层结构导致表达能力有限，且自适应增删神经元虽提升精度但可能导致局部最优收敛；未来需探索多层RBF网络及更大规模数据验证。

---

## 13. Statistical Firefly Algorithm for Truss Topology Optimization

**arXiv ID:** 2601.12265 | [PDF](https://arxiv.org/pdf/2601.12265v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620`

---

## 14. BlocksecRT-DETR: Decentralized Privacy-Preserving and Token-Efficient Federated Transformer Learning for Secure Real-Time Object Detection in ITS

**arXiv ID:** 2601.12693 | [PDF](https://arxiv.org/pdf/2601.12693v1)

**作者:** Mohoshin Ara Tahera `[一作]` (University of Louisiana at Lafayette), Mahmoud Abouyessef `[通讯]` (North Carolina A and T State University)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `e0540dec-d77f-42db-94ae-d039248f6393` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出BlockSecRT-DETR框架，结合RT-DETR Transformer与Token Engineering Module（TEM）实现去中心化、隐私保护、token高效的联邦实时目标检测；同时通过区块链安全更新验证与RSU BFT共识保障可信聚合。

**💡 创新点**

①将TEM嵌入Transformer编码器，实现自适应token剪枝，显著降低计算与延迟；②采用可链接群签名与多RSU BFT共识的区块链验证，保证匿名更新、单次提交、抵御恶意客户端与RSU。

**🔧 技术方法**

RT-DETR Transformer、Token Engineering Module（动态token剪枝）、可链接群签名、区块链Ledger、RSU基于BFT的共识、分布式聚合。

**📊 数据集**

KITTI目标检测数据集，按每个客户端缺失一个类别进行5客户端缺失类别非IID划分。

**📈 对比分析**

与RT-DETR基线对比，TEM后mAP@0.5从94.06%降至89.20%，Encoder FLOPs降47.8%，推理延迟降17.2%；区块链验证每轮额外约400 ms，账本尺寸≤12 KB。

**⚠️ 局限性**

在缺失类别非IID下精度仍略有下降；区块链安全层增加约400 ms延迟；仍未彻底抵御语义poisoning，缺乏大规模部署与自适应token剪枝的研究。

---

## 15. Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images

**arXiv ID:** 2601.12512 | [PDF](https://arxiv.org/pdf/2601.12512v1)

**作者:** Mohd Usama `[一作]` (Umea University), Faleh Menawer R Althiyabi `[通讯]` (King Fahd University of Petroleum and Minerals)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

提出了一种针对磁共振成像域漂移的无监督双向域适应方法，利用微调的CycleGAN实现T1与T2模态的互译。

**💡 创新点**

创新点在于将差异损失与周期一致性损失结合到CycleGAN中，并采用轻量级从零开始微调策略，显著提升结构保留与域一致性。

**🔧 技术方法**

使用改进的CycleGAN架构，加入disparity loss、cycle-consistency loss，并使用Adam优化器进行训练。

**📊 数据集**

使用iSeg 2017和iSeg 2019的婴儿脑MRI数据集（T1、T2模态），共计3640张2D切片。

**📈 对比分析**

通过与BiGAN、默认CycleGAN在SSIM、Bhattacharyya距离和直方图相关性等指标对比，提出的模型在保持结构完整性和域对齐方面表现更优，BD与HC值更接近原始模态。

**⚠️ 局限性**

局限在于仅验证了脑MRI模态，未验证在其他医学影像（如超声、OCT）中的泛化效果，且对不同硬件平台的适应性尚待进一步测试。

---

## 16. Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods

**arXiv ID:** 2601.12500 | [PDF](https://arxiv.org/pdf/2601.12500v1)

**作者:** Yaowu Fan `[一作]` (Sun Yat-sen University), Antoni B. Chan `[通讯]` (City University of Hong Kong)

**通讯引用:** 11938 | [OpenAlex ID](https://openalex.org/A5065680386)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `aaccfe5c-6b26-4208-b23c-35331481e142` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了利用移动无人机拍摄的视频级人群计数与跟踪框架GD3A与DVTrack，并构建了大型多场景密集人群数据集MovingDroneCrowd++。

**💡 创新点**

创新点包括：①首次发布MovingDroneCrowd++数据集；②使用可自适应尘埃箱（dustbin）得分的最优传输进行像素级人行识别；③通过该匹配解耦全局密度图为共享、流入和流出密度图；④利用投票机制实现实例级跟踪。

**🔧 技术方法**

采用深度特征提取（ResNet+FPN）、注意力图神经网络（AGNN）、最优传输（OT）+尘埃箱预测、密度图估计、投票关联等技术。

**📊 数据集**

主要使用新构建的MovingDroneCrowd++数据集进行训练和评估，也在固定摄像头场景VSCrowd数据集上进行对比。

**📈 对比分析**

与多种视频级计数与多目标跟踪SOTA方法对比，GD3A在MovingDroneCrowd++上将计数误差降低47.4%，在高难度子集上提升66.2%；DVTrack在HOTA指标上提升39.2%，在所有方法中取得最佳性能。

**⚠️ 局限性**

局限性：方法仍依赖先验密度图估计，若估计误差较大可能影响匹配；目前主要验证在中等速度无人机轨迹，极端低照度或高速场景的鲁棒性尚待进一步评估。

---

## 17. DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data

**arXiv ID:** 2601.12366 | [PDF](https://arxiv.org/pdf/2601.12366v1)

**作者:** Jiafei Zhang `[一作]` (MetaPheno Laboratory), Zhiguo Han `[通讯]` (MetaPheno Laboratory)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

构建并训练了一个基于DepthCropSeg++的基础作物分割模型，利用大规模跨场景数据实现了高精度作物分割。

**💡 创新点**

创新点包括：①利用Depth Anything V2生成伪标签并通过两阶段自训练细化；②引入FADE动态上采样提升边界细节；③构建28,601张图像、30+品种、15种环境的大规模训练集。

**🔧 技术方法**

核心技术为ViT-Adapter Transformer + FADE动态上采样 + depth‑guided伪标签 + 两阶段自训练（self‑training）

**📊 数据集**

使用了28,601张图像的混合数据集（11,406人标注 + 17,195伪标注），涵盖30+作物种类、15种环境条件。

**📈 对比分析**

与完全监督模型、SAM、HQ‑SAM、GWFSS等进行对比，mIoU达到93.11%，显著优于其他模型，尤其在夜间、密集冠层及未见作物上表现突出。

**⚠️ 局限性**

局限性包括：在极低光照、极高密度冠层、极端尺度变化等极端场景仍出现误分，且对多样性背景的鲁棒性还有提升空间。

---

## 18. Learning Longitudinal Health Representations from EHR and Wearable Data

**arXiv ID:** 2601.12227 | [PDF](https://arxiv.org/pdf/2601.12227v1)

**作者:** Yuanyun Zhang `[一作]` (University of the Chinese Academy of Sciences), Shi Li `[通讯]` (University of the Chinese Academy of Sciences)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

本文提出一种基于连续时间潜在过程的多模态基础模型，联合学习电子病历（EHR）与可穿戴设备的高频生理信号，并通过自监督与跨模态预测目标进行预训练，随后在多种临床预测任务上冻结表示进行评估。

**💡 创新点**

创新点在于：①将稀疏事件驱动的EHR与密集时序生理信号统一映射到同一连续时间潜在空间；②设计异向跨模态损失（wearable→EHR 与 EHR→wearable）以及连续时间注意力核，显著提升了时间一致性和语义对齐；③通过预训练后冻结的表示在不同任务上实现了超越单模态模型和后期拼接融合的性能。

**🔧 技术方法**

使用的技术包括：多模态前端编码器（短程Transformer / 卷积）、连续时间位置编码、可学习的混合指数衰减注意力核、掩码预测、局部重构与多步预测、InfoNCE 对比损失、可选的 ELBO 生成正则化、以及渐进式跨模态权重调度。

**📊 数据集**

数据集为英国生物银行（UK Biobank）中的 48,732 名患者，涵盖 1 年以上的EHR 历史与 14 天以上的可穿戴加速度/PPG 等连续时间信号。

**📈 对比分析**

比较方法采用冻结编码器的线性/浅层 MLP 头，评估指标包括 AUROC、AUPRC、时间相关 AUC、C-index、Brier 分数等；实验显示多模态模型在 30–365 天预测、生理状态估计与长期风险建模等任务上均优于单模态基线和晚期拼接融合，最显著的提升出现在长预测窗和缺失模态情景，AUROC 提升约 0.04–0.05，AUPRC 与 Brier 分数亦有显著改善。

**⚠️ 局限性**

局限性包括：对极度缺失 EHR 或可穿戴数据的患者收益有限；模型对社会经济偏倚可能产生放大效应；训练成本高（约 220M 参数、数百万 GPU‑小时）；跨机构迁移时需要进一步的域适配；且跨模态对齐在某些细粒度任务上仍不完美。

---

## 19. NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages

**arXiv ID:** 2601.12389 | [PDF](https://arxiv.org/pdf/2601.12389v1)

**作者:** Lakshya Tomar `[一作]` (RocketFrog AI), Puneet Agarwal `[通讯]` (RocketFrog AI)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 NADIR 一种非自回归的多语种转写模型。

**💡 创新点**

创新点在于结合差分变压器与 Mixture-of-Experts 机制来降低幻觉和长度控制问题。

**🔧 技术方法**

使用了差分注意力机制、MoE 路由、RMSNorm、RoPE、交叉熵+负载平衡损失等技术。

**📊 数据集**

训练使用 Aksharantar 语料库，包含 21 种印度语言的 24.8M 词对。

**📈 对比分析**

与 SOTA AR 模型 IndicXLIT 对比，NADIR 在 20 种语言上 CER 仅略逊但推理速度提升 10‑13 倍，平均推理时间从 116 秒降至 9 秒。

**⚠️ 局限性**

限制在于对极低资源语言的准确度仍有不足，且仅适用于具有明确终止点的任务。

---

## 20. TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization

**arXiv ID:** 2601.12288 | [PDF](https://arxiv.org/pdf/2601.12288v1)

**作者:** Lei Liu `[一作]` (University of Science and Technology of China), Bin Li `[通讯]` (University of Science and Technology of China)

**通讯引用:** 33298 | [OpenAlex ID](https://openalex.org/A5022217280)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 TimeGMM 框架，利用高斯混合模型（GMM）在单次前向推理中生成完整的概率预测，并引入 GRIN 进行分布自适应规范化。

**💡 创新点**

创新点包括：① 设计了 GMM‑adapted Reversible Instance Normalization（GRIN）解决概率预测中的分布漂移；② 通过 Temporal Encoder（TE‑Module）与 Conditional Temporal‑Probabilistic Decoder（CTPD‑Module）协同建模时间依赖与分布参数；③ 在单前向过程中完成概率预测，避免了采样开销与强先验假设。

**🔧 技术方法**

核心技术：Gaussian Mixture Model、GRIN、Transformer 编码器、adaLN 条件调制、负对数似然、期望损失与权重约束组合损失。

**📊 数据集**

使用了 ProbTS 基准数据集：ETTm1/2、ETTh1/2、Electricity、Weather、Exchange，输入长度 96，预测时长 96/192/336/720。

**📈 对比分析**

与 VAE、Diffusion、Flow 等现有 SOTA 进行对比，评估指标为 CRPS 与 NMAE；TimeGMM 在所有数据集和预测时长上均取得最高分，CRPS 最高提升 22.48%，NMAE 最高提升 21.23%。

**⚠️ 局限性**

局限性：仍需为 GRIN 学习额外参数，模型在极大时长或高维变量场景下参数规模增大；未针对缺失值、异常点等异常情况提供鲁棒性处理，未来工作需进一步完善。

---

## 21. BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models

**arXiv ID:** 2601.12632 | [PDF](https://arxiv.org/pdf/2601.12632v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86`

---

## 22. Computing Maximal Repeating Subsequences in a String

**arXiv ID:** 2601.12200 | [PDF](https://arxiv.org/pdf/2601.12200v1)

**作者:** Mingyang Gong `[一作]` (Montana State University), Binhai Zhu `[通讯]` (Montana State University)

**通讯引用:** 2341 | [OpenAlex ID](https://openalex.org/A5070925973)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `64443552-63e0-44b5-906f-d90fe95c5a1b`

**🎯 论文内容**

本文研究在单个字符串中寻找最大（非最大长度）重复子序列（包括最大方形子序列和最大k-重复子序列），并给出高效算法；

**💡 创新点**

创新点在于首次将最大重复子序列问题迁移到单字符串域，并通过改进的子序列扩展与分块扫描方法，将时间复杂度从原本的O(n²)或O(n²k-1)显著降低；

**🔧 技术方法**

核心技术包括对字符出现次数的分块预处理、Sakai的最大公共子序列算法、σ-起点枚举与分块分割的星星-条形图计数、以及对k-重复子序列的分块扩展策略；

**📊 数据集**

文章未使用公开数据集，而是以理论分析和算法设计为主；

**📈 对比分析**

通过理论复杂度分析与对比，证明在无约束情况下最大方形子序列可在O(nlog n)时间内求解，最大k-重复子序列在O(f(k)nlog n)时间内完成，其中f(k)<k·4^k，远优于先前的O(n²k-1)上界；

**⚠️ 局限性**

限制在于对受约束版本（即要求包含或不包含特定模式X）的最大重复子序列问题尚未得到解决，且算法对k大时的常数因子较大。

---

## 23. Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem

**arXiv ID:** 2601.12543 | [PDF](https://arxiv.org/pdf/2601.12543v1)

**作者:** Alireza Ghahtarani `[一作]` (HEC Montreal), Jorge E. Mendoza `[通讯]` (HEC Montreal)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出并评估了一种基于游戏化建模的在线集中式电动汽车充电调度方法，利用专家演示和Dataset Aggregation训练的图像-动作策略实现负载平衡；

**💡 创新点**

创新点在于将调度问题重新表述为可视化的交互式游戏，并证明图像输入+动作输出(I2M)在理论上和经验上优于传统向量-计划输出；

**🔧 技术方法**

采用卷积神经网络进行图像特征提取，结合动作预测的监督学习和DAgger改进的模仿学习，基于专家优化求解得到的演示数据；

**📊 数据集**

使用蒙特利尔大都市区（GMA）的真实电力网络参数和EV到达/离开统计数据构建模拟场景，包含多种到达分布与负荷波动；

**📈 对比分析**

与离线全知优化、滚动重优化、三种阈值阈值、行列填充等启发式方法及Oracle基准对比，结果显示I2M-DAgger在峰谷差和RMSE两指标上显著优于其他在线策略，经济效益达到数千万加元/年；

**⚠️ 局限性**

局限性包括对数据分布变化的鲁棒性仅在±10%范围内验证、模型依赖于准确的容量和能耗假设、以及训练过程对专家解的依赖，且未考虑通信延迟与实际部署成本。

---

## 24. AlphaSyndrome: Tackling the Syndrome Measurement Circuit Scheduling Problem for QEC Codes

**arXiv ID:** 2601.12509 | [PDF](https://arxiv.org/pdf/2601.12509v1)

**作者:** Yuhao Liu `[一作]` (University of Pennsylvania), Gushu Li `[通讯]` (University of Pennsylvania)

**通讯引用:** 1022 | [OpenAlex ID](https://openalex.org/A5009768065)

**关键词:** `7a50eb32-3dbc-4c3e-a038-bda01b2d9965` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

自动化合成和优化量子误差校正（QEC）中的稳定子测量（syndrome measurement）电路调度，以降低逻辑错误率。

**💡 创新点**

①利用蒙特卡洛树搜索（MCTS）在完整调度空间中基于真实噪声与解码器反馈进行全局搜索；②将错误传播引导至远离逻辑算子且易于被给定启发式解码器纠正的模式；③适用于任何相互可交换的稳定子码，且能自动适配不同解码器和非均匀噪声。

**🔧 技术方法**

蒙特卡洛树搜索（MCTS）+ 误差模拟与解码器回馈 + 代码分区（partition）+ 逻辑错误率评估采样。

**📊 数据集**

多种量子误差校正码（旋转表面码、颜色码、XZZX、双变量自行车码、超平面码等）与对应的启发式解码器（MWPM、BP‑OSD、UnionFind）在IBM Brisbane 量子硬件噪声模型下。

**📈 对比分析**

与最小深度基线、Google 手工设计的表面码调度以及 IBM 的自行车码调度进行对比；在32个码/解码器实例中平均减少逻辑错误率80.6%（峰值96.2%），空间–时间体积可降低20–90%。

**⚠️ 局限性**

①MCTS 需要大量模拟计算，搜索成本随码大小增长；②仅适用于相互可交换的稳定子码，无法直接处理非可交换测量；③性能高度依赖噪声模型与解码器的准确性，若噪声与模型偏差大，可能无法获得预期改进。

---

## 25. De-Anonymization at Scale via Tournament-Style Attribution

**arXiv ID:** 2601.12407 | [PDF](https://arxiv.org/pdf/2601.12407v1)

**作者:** Lirui Zhang `[一作]` (Beihang University), Huishuai Zhang `[通讯]` (Peking University)

**通讯引用:** 4423 | [OpenAlex ID](https://openalex.org/A5042848593)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究在大规模匿名文本中使用LLM进行作者去匿名化，并提出了DAS（De‑Anonymization at Scale）方法。

**💡 创新点**

创新点是将粗检向量检索与基于LLM的递归淘汰相结合，并通过多轮投票提升鲁棒性，形成两阶段流水线。

**🔧 技术方法**

使用LLM（Gemini‑2.0‑flash、Qwen1.5‑72B‑Chat、Claude‑3.5‑Sonnet等）+稠密检索(CoSENT) + 随机分组、指数加权与多轮投票等技术。

**📊 数据集**

实验数据集包括ICLR 2023‑25匿名审稿记录、博客作者语料库（19,320名博主）和Enron邮件数据集（174名作者）。

**📈 对比分析**

与随机基线和AIDBench比较，Rank@k与Precision均显著提升；在审稿数据中Rank@20达44%，在博客与邮件中Rank@20分别达94%与88%。

**⚠️ 局限性**

局限性包括仅测试少数LLM、提示设计相对简单、对检索效率的依赖可能在极大规模场景下受限。

---

## 26. Democratizing Music Therapy: LLM-Based Automated EEG Analysis and Progress Tracking for Low-Cost Home Devices

**arXiv ID:** 2601.12280 | [PDF](https://arxiv.org/pdf/2601.12280v1)

**作者:** Huixin Xue `[一作]` (Shanghai Conservatory of Music), Yue Gao `[通讯]` (Shanghai Innovation Institute)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68` `109c2b71-d051-425c-831f-0c544c24280d`

**🎯 论文内容**

开发了一套基于大型语言模型的后期生理信号分析与音乐治疗推荐系统，能够将EEG和心率数据转化为可读的治疗报告和个性化音乐建议。

**💡 创新点**

首次将LLM与生理信号处理工具结合，实现自动化、可解释的音乐治疗进展跟踪，弥补了传统专家解读与实时适配系统缺乏后续报告的不足。

**🔧 技术方法**

使用Qwen3 32B LLM、Hilbert变换频段分析、FFT主频识别、功能调用（tool calling）、检索增强生成（RAG）以及可穿戴单通道EEG与脉搏血氧传感器。

**📊 数据集**

基于自建的临床和用户数据，采集单通道EEG（AF3）和心率/血氧，样本量33名志愿者，产生约180k EEG样本和360心率测量。

**📈 对比分析**

与两种基线（Qwen-plus、GPT-5）进行盲评，专家评分显示本文方法平均得分15.15，明显高于12.73和2.12；在用户实验中，情绪倾向得分与自评情绪高度相关。

**⚠️ 局限性**

局限在于EEG分析仅基于单通道、频谱趋势粗略，缺乏实时音乐特征关联；音乐库仅为作者自制，缺少多样化风格；系统流程固定，缺少长期自适应与个性化调节。

---

## 27. ParaMETA: Towards Learning Disentangled Paralinguistic Speaking Styles Representations from Speech

**arXiv ID:** 2601.12289 | [PDF](https://arxiv.org/pdf/2601.12289v1)

**作者:** Haowei Lou `[一作]` (University of New South Wales), Lina Yao `[通讯]` (CSIRO Data61)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

ParaMETA提出了一种统一的表示学习框架，能够在同一模型中学习并控制情感、性别、年龄、语言等说话风格。

**💡 创新点**

其创新点在于将风格表示投影到任务专用子空间，并采用分阶段对比学习和原型对齐，显著降低跨任务干扰，实现多任务识别与TTS控制。

**🔧 技术方法**

使用了分阶段对比学习、监督对比损失、原型学习以及文本-语音投影对齐等技术，并支持CNN、LSTM、Transformer等多种编码器。

**📊 数据集**

在由Baker、LJSpeech、ESD、CREMA‑D、Genshin Impact等公开语料构建的多语种多风格语音集（约93k样本）上进行训练和评估。

**📈 对比分析**

与CLAP、ParaCLAP及传统交叉熵基线比较，ParaMETA在情感、性别、年龄、语言识别上取得最高或最稳健的准确率，TTS生成的自然度和表现力也优于基线。

**⚠️ 局限性**

局限包括对语言风格的可控性不足、对超大规模多模态预训练模型兼容性待验证，以及在极细粒度风格上仍存在一定误差。

---

## 28. From Design to Deorbit: A Solar-Electric Autonomous Module for Multi-Debris Remediation

**arXiv ID:** 2601.12830 | [PDF](https://arxiv.org/pdf/2601.12830v1)

**作者:** Om Mishra `[一作]` (Indian Institute of Information Technology Dharwad), Manjunath K Vanahalli `[通讯]` (Indian Institute of Information Technology Dharwad)

**通讯引用:** 69 | [OpenAlex ID](https://openalex.org/A5017587934)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本研究提出了一种集成太阳能驱动的NASA Evolutionary Xenon Thruster（NEXT）与机械夹持系统的多体太空碎片清除模块，并通过高保真仿真验证了其从800 km到100 km的持续低推力退轨能力、雷达EKF导航误差<10 m，以及DTN链路下93%内1 s的包交付效率。

**💡 创新点**

创新点在于：1）将高效NEXT离子推进器与可持续太阳能供电结合，实现长周期低推力退轨；2）引入机械夹持捕获机制，实现多碎片一次性抓取；3）集成基于雷达的相对导航与DTN通信协议，实现闭环自主操作；4）通过仿真验证该架构在连续低推力与近场碰撞规避中的鲁棒性。

**🔧 技术方法**

使用的技术包括：NASA NEXT离子推进器、太阳能电池板与Li‑ion电池储能、机械夹持抓取装置、雷达+摄像机融合的EKF导航、DTN（Bundle Protocol）与CFDP文件传输、Proximity‑1短距通信、深度学习边缘推理（CNN/DNN）用于碎片识别，以及MATLAB/GMAT的高保真动力学与通信链路仿真。

**📊 数据集**

数据集主要为仿真生成的轨道、传感器测量和通信时延数据；并使用公开的碎片分布统计与TLE轨道数据进行碰撞规避验证。

**📈 对比分析**

在仿真中，连续低推力退轨完成后，雷达EKF相对位置误差保持在±8 m，速度误差<0.03 m/s；DTN包交付延迟90%在1 s以内，最大延迟可达4000 s。与传统冲量退轨方法相比，低推力方案可显著降低推进剂消耗，且通过机械夹持实现多碎片一次捕获。

**⚠️ 局限性**

局限性包括：EKF在持续低推力阶段存在线性化误差导致误差逐渐偏移；机械夹持在高速撞击或非标准表面上的可靠性尚未在硬件层面验证；通信链路在长时间无链路窗口时出现显著延迟；未来工作需采用更高阶非线性滤波、硬件在环验证夹持与AI推理，并探索混合推进与强化学习规划。

---

## 29. TrojanPraise: Jailbreak LLMs via Benign Fine-Tuning

**arXiv ID:** 2601.12460 | [PDF](https://arxiv.org/pdf/2601.12460v1)

**作者:** Zhixin Xie `[一作]` (Nanyang Technological University), Jun Luo `[通讯]` (Nanyang Technological University)

**通讯引用:** 23682 | [OpenAlex ID](https://openalex.org/A5100749903)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过在LLM上进行安全对齐失效的“benign fine‑tuning”攻击，利用新造词“bruaf”在模型中把有害概念的态度转为中性，从而实现对多种商业及开源模型的通用越狱。

**💡 创新点**

①使用单一新词“bruaf”对所有有害概念进行正面表述，避免被内容过滤器检测；②引入知识‑态度两维的内部表征分析，解释攻击如何通过降低态度分数而不损害知识分数来实现成功越狱；③通过四部分数据（bruaf定义、贬赞语句、概念定义、长回答样本）实现既能攻击又保持模型常规性能。

**🔧 技术方法**

1) 低样本 GPT‑4o 生成的 270 条 Q&A 语料；2) 线性分类器（Logistic Regression）提取最终层隐藏状态，用于量化知识与态度分数；3) Black‑box fine‑tuning（Full‑Fine‑Tune 与 LoRA 对比），以及在不同系统提示、最小长度、回合数等条件下的实验。

**📊 数据集**

① 50 个来自 AdvBench 的有害概念；② 1 条 bruaf 定义（100 Q&A 对）；③ 50 条有害概念定义；④ 20 条长回答的常规 Q&A；所有数据均由 GPT‑4o 自动生成。

**📈 对比分析**

与 5 种现有 fine‑tuning 基线（加密、恶意、间接恶意、身份转移、无关 fine‑tuning）对比。攻击在 7 个模型上均达到 70%–95% 的成功率，Llama‑3‑8b、GPT‑4omini、GPT‑3.5 的 ASR 均超过 90%；在 Llama‑2‑7b 和 Llama‑3‑8b 与恶意 fine‑tuning 的效果几乎持平；相比之下，检测率极低（仅比无关 baseline 高 3%–7%），表现出较高的隐蔽性。

**⚠️ 局限性**

① 攻击需较多训练数据（四部分语料），且在商业模型上往往需要两阶段 fine‑tune；② 由于是间接改动态度，可能在某些有害概念上仍出现“知识偏移”导致回答不连贯；③ 对黑盒 LLM 的 fine‑tune 仍受限于 API；④ 手工审核仍可发现并阻断越狱；⑤ 研究主要集中在越狱效果，未系统评估对模型其他安全属性的长远影响。

---

## 30. DaggerFFT: A Distributed FFT Framework Using Task Scheduling in Julia

**arXiv ID:** 2601.12209 | [PDF](https://arxiv.org/pdf/2601.12209v1)

**作者:** Sana Taghipour Anvari `[一作]` (Northeastern University), David Kaeli `[通讯]` (Northeastern University)

**通讯引用:** 7735 | [OpenAlex ID](https://openalex.org/A5061128237)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了基于Julia的分布式FFT框架DaggerFFT，利用动态任务调度实现FFT计算与通信的异步并行；

**💡 创新点**

创新点在于将FFT阶段拆解为细粒度任务图，采用动态任务调度与非阻塞MPI重排，结合工作窃取和任务局部性，显著提升CPU与GPU的资源利用率；

**🔧 技术方法**

使用技术包括Julia语言、Dagger.jl任务调度、MPI、CUDA.jl、cuFFT/FFTW、非阻塞MPI通信、GPU-aware MPI、工作窃取、计划缓存等；

**📊 数据集**

实验数据集包括512³、1024³等立方体网格的FFT基准，以及Oceananigans.jl海洋模型的Poisson求解器；

**📈 对比分析**

与heFFTe、SimpleMPIFFT等现有库比较，DaggerFFT在CPU上实现最高2.6×加速、GPU上1.35×加速，并在Oceananigans Poisson求解器中获得最高3.19×加速；

**⚠️ 局限性**

局限性为在极小问题规模或高进程数下，任务细粒度导致调度开销占比过高，导致效率下降。

---

## 31. Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts

**arXiv ID:** 2601.12711 | [PDF](https://arxiv.org/pdf/2601.12711v1)

**作者:** Kevin Wang `[一作]`, Zhangyang Wang `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了神经符号LoRA框架，交替使用LoRA数值微调与TextGrad符号提示编辑，实现模型的事实知识注入与风格对齐。

**💡 创新点**

引入统一监测信号和奖励分类器动态切换数值与符号更新，外部LLM稀疏调用，并将符号编辑生成的高质量提示作为可复用训练数据。

**🔧 技术方法**

使用LoRA低秩适配、TextGrad基于外部教师模型的提示梯度编辑、奖励模型分类器、监测信号（loss变化/梯度范数）以及系统提示更新等技术。

**📊 数据集**

主要数据集包括数学推理的GSM8K、医学事实的CliniFact、情境推理的bAbi，以及利用符号编辑生成的增广数据集。

**📈 对比分析**

与纯LoRA、前缀微调、奖励分类器等基线在Llama‑3.1‑8B、Deepseek‑R1‑1.5B、Phi‑3‑mini‑4k等模型上进行10轮训练，NS‑LoRA在GSM8K提升至约80%+（比LoRA高约6%），在CliniFact提升至70%+；在多任务平均提升4–6%。

**⚠️ 局限性**

对非步骤式数据集提升有限；符号编辑可能破坏语义，需要更严格的验证机制；外部LLM调用带来延迟与成本。

---

## 32. AgenTRIM: Tool Risk Mitigation for Agentic AI

**arXiv ID:** 2601.12449 | [PDF](https://arxiv.org/pdf/2601.12449v1)

**作者:** Roy Betser `[一作]` (Fujitsu Research of Europe), Roman Vainshtein `[通讯]` (Fujitsu Research of Europe)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `5b4c1114-4a70-478e-9921-2514ee03850d` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了AgenTRIM框架，解决LLM代理在使用工具时存在的过度或不足权限导致的安全与功能失衡问题

**💡 创新点**

创新点在于将离线工具提取与验证（结合静态代码分析与执行轨迹）与在线按步骤最小权限工具访问的运行时编排相结合，实现在不改动代理内部推理的前提下实现工具权限自适应平衡

**🔧 技术方法**

使用技术包括静态代码分析、执行追踪验证、LLM辅助生成工具描述、适配过滤器、状态感知高风险工具调用判断以及轻量级运行时编排器

**📊 数据集**

主要使用AgentDojo基准数据集评估，并在500个ReAct配置以及外部EHR、旅行代理等多种框架上进行验证

**📈 对比分析**

与基线代理、四大Benchmark防御（PI Detector、Tool Filter等）以及SOTA IPI防御（CaMeL、MELON、Progent、AgentArmor）对比，AgenTRIM在攻击成功率最低、功能效用保持最高，且延迟仅约1.8×基线

**⚠️ 局限性**

局限性包括需要在隔离环境下执行工具验证、对工具风险划分的依赖（如读写分级）、以及额外的运行时层导致的延迟与成本提升

---

## 33. Best Practices for Large Load Interconnections: A North American Perspective on Data Centers

**arXiv ID:** 2601.12686 | [PDF](https://arxiv.org/pdf/2601.12686v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329`

---

## 34. FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions

**arXiv ID:** 2601.12799 | [PDF](https://arxiv.org/pdf/2601.12799v1)

**作者:** Peng Li `[一作]` (Fudan University), Xipeng Qiu `[通讯]` (Fudan University)

**通讯引用:** 17130 | [OpenAlex ID](https://openalex.org/A5044665993)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一套完整的基于自然语言指令的全身运动生成与控制框架（H-GPT+H-ACT），实现了人形机器人对复杂指令的可执行运动。

**💡 创新点**

创新点包括：①引入Chain‑of‑Thought（CoT）中介以提升语言理解与动作细化；②利用VQ‑VAE将连续全身运动离散化为可在LLM中处理的token；③双阶段强化学习（预训练+细调）与教师‑学生策略结合，实现稳健的机器人执行；④设计统一的跨平台部署接口，支持多种控制策略。

**🔧 技术方法**

使用技术：LLaMA‑3.1 LLM+LoRA、VQ‑VAE、Chain‑of‑Thought、SMPL‑X运动重定向、IsaacGym仿真、PPO教师‑学生强化学习、离散运动编码与重构、机器人动力学模型。

**📊 数据集**

使用的数据集：HumanML3D‑X（含手部动作）、δHumanML3D‑X（指令重写/噪声版）、Motion‑X（视频估计大规模运动+VLM生成文本）、AMASS、HumanAct12。

**📈 对比分析**

方法对比：在HumanML3D‑X和δHumanML3D‑X上与T2M‑GPT、MotionDiffuse、MLD等基线对比，FID从0.677下降至0.23（≈2.5×提升），动作跟踪成功率提高约15%，MPJPE、VEL、ACCEL等指标同步下降，整体表现显著优于现有模型。

**⚠️ 局限性**

局限性：①数据集多基于视频估计，标签噪声和分布差异导致模型泛化受限；②对极端或高频动作的稳健性仍不足，仿真‑实境差距导致落地时易失稳；③CoT虽提升理解力，但在极度抽象或长指令下仍出现不匹配或动作错误。

---

## 35. Approximation Schemes for Sequential Hiring Problems

**arXiv ID:** 2601.12750 | [PDF](https://arxiv.org/pdf/2601.12750v1)

**作者:** Danny Segev `[一作]` (Tel Aviv University), Uri Stein `[通讯]` (Tel Aviv University)

**通讯引用:** 595 | [OpenAlex ID](https://openalex.org/A5065718313)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文针对顺序招聘问题提出了多项式时间近似方案（PTAS），并设计了能够在多项式大小的决策树中实现的 block‑responsive 策略。

**💡 创新点**

创新点在于引入 block‑responsive 策略并证明其能在保持 1‑ε 接近最优的同时将决策树规模压缩至多项式；同时结合概率分组、动态规划和递归枚举实现 PTAS。

**🔧 技术方法**

主要技术包括：动态规划、线性规划与依赖抽取、概率分层分组、block‑responsive 决策树构造、递归枚举与概率修正、以及期望奖励的数学分析。

**📊 数据集**

论文以理论分析为主，未使用具体实验数据，而是以 n、T、k 等抽象参数进行证明与复杂度评估。

**📈 对比分析**

与之前的 1/2 及 (1‑e^{‑k}k^k/k!) 近似相比，本文实现了 1‑ε 的近似，运行时间为 O(n^{O(1)}T^{Õ(1/ε^2)})；当 k≥1/ε² 时可直接使用已有的近似算法。

**⚠️ 局限性**

局限性包括：在 k<1/ε² 的情况下仍需进行指数级树枚举，时间复杂度对 ε 依赖较大；实现相对复杂且缺乏实验验证，主要是理论性证明。

---

## 36. Classical-Quantum Channel Resolvability Using Matrix Multiplicative Weight Update Algorithm

**arXiv ID:** 2601.12230 | [PDF](https://arxiv.org/pdf/2601.12230v1)

**作者:** Koki Takahashi `[一作]` (Tokyo University of Agriculture and Technology), Shun Watanabe `[通讯]` (Tokyo University of Agriculture and Technology)

**通讯引用:** 3092 | [OpenAlex ID](https://openalex.org/A5101971899)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了使用矩阵乘法权重更新（MMWU）算法实现经典-量子通道的确定性模拟（channel resolvability）

**💡 创新点**

首次实现基于确定性编码的C‑Q通道可模拟，证明其代码长度可达Holevo容量，不再依赖传统随机编码

**🔧 技术方法**

利用MMWU算法、量子超图软覆盖理论、典型投影与温和测量引理等量子信息工具

**📊 数据集**

无实际数据集，论文为纯理论证明与抽象构造

**📈 对比分析**

通过理论分析与上界估计证明，所构造代码书大小满足L≥exp(nC(W)+o(n))，实现与随机编码相同的容量上限；无实验或数值对比

**⚠️ 局限性**

仅给出渐进结果，需满足多项技术假设（如E_x≤ηI、Tr(E_p)≥1-τ等），对有限样本和具体实现的复杂度未给出，且对非记忆通道的推广尚未讨论

---

## 37. Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption

**arXiv ID:** 2601.12331 | [PDF](https://arxiv.org/pdf/2601.12331v1)

**作者:** Huanyi Ye `[一作]` (Nanyang Technological University), Kwok-Yan Lam `[通讯]` (Digital Trust Centre)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `9cc9baba-5356-466d-81ff-d80028d90279` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

实现了在不可信云环境下的隐私保护检索增强生成框架（ppRAG），支持加密向量检索并在生成阶段使用检索结果。

**💡 创新点**

提出了条件近似距离比较保持对称加密（Conditional ADCPE），仅保留查询-文档的相对距离而抹去数据库内部结构，并结合距离差分隐私（DistanceDP）对查询向量进行扰动，从而兼顾检索效率与多维安全。

**🔧 技术方法**

采用对称加密与高斯噪声的条件距离保持加密、差分隐私噪声、AES加密文档、向量检索算法，并将检索结果喂给LLM进行生成；实现基于云端的检索与本地解密相结合的流程。

**📊 数据集**

在MS MARCO数据集上使用常用嵌入模型（如OpenAI embedding或其他向量模型）进行评估。

**📈 对比分析**

与基于部分同态加密的RemoteRAG、DP‑RAG以及未加密Baseline进行对比。ppRAG的加密吞吐量约2.3k v/s 250‑300；向量重构BLEU从83降至12；向量分析ASR更低；检索精度与原始相近；在生成质量上保持不下降。

**⚠️ 局限性**

需要为不同数据集/模型动态调参（β值、扰动半径），查询噪声会导致一定的精度损失；目前仅在单机云端实验，未验证极大规模分布式环境的扩展性和更复杂攻击模型的安全性。

---

## 38. The Unfairness of Multifactorial Bias in Recommendation

**arXiv ID:** 2601.12828 | [PDF](https://arxiv.org/pdf/2601.12828v1)

**作者:** Masoud Mansoury `[一作]` (Delft University of Technology), Maarten de Rijke `[通讯]` (University of Amsterdam)

**通讯引用:** 29323 | [OpenAlex ID](https://openalex.org/A5031439294)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究多因素偏差（流行度偏差与正向偏差）对推荐系统曝光公平性的影响，并提出基于百分位数的预处理方法来缓解这种多因素偏差。

**💡 创新点**

创新点在于将百分位数变换从传统的用户侧改为物品侧，专门针对多因素偏差进行预处理，既能显著提升曝光公平，又几乎不降低准确率；同时证明该预处理可与现有后处理公平算法结合，提升其效率与效果。

**🔧 技术方法**

采用百分位数（percentile）评分转换技术；配合六种主流推荐算法（BiasedMF、SVD++、WRMF、ListRankMF、UserKNN、ItemKNN），以及四种公开数据集进行实验。

**📊 数据集**

Goodreads、MovieLens、Google Local Data、Yelp 四个公开数据集。

**📈 对比分析**

与原始评分输入以及现有公平性后处理方法（Discrepancy Minimization、FA*IR、xQuAD、FairMatch、Random、Reverse）对比实验。结果显示：百分位数预处理后在保持或略微提升准确度（Precision、nDCG）的同时，显著提升曝光公平指标（IA、LIA、EE）；并且在后处理阶段，使用预处理后的短列表即可获得与原方法相同或更好的公平/准确度，计算成本明显下降。

**⚠️ 局限性**

局限性：需足够稠密且多样化的评分分布，稀疏或均匀评分时百分位数变换不稳定；仅验证了物品侧公平性，未探讨用户侧公平；在冷启动或极度稀疏场景的鲁棒性尚未评估。

---

## 39. YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection

**arXiv ID:** 2601.12882 | [PDF](https://arxiv.org/pdf/2601.12882v1)

**作者:** Sudip Chakrabarty `[一作]` (KIIT University), Sudip Chakrabarty `[通讯]` (KIIT University)

**通讯引用:** 524 | [OpenAlex ID](https://openalex.org/A5001580251)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5b4c1114-4a70-478e-9921-2514ee03850d` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了YOLO26框架，彻底消除非最大抑制(NMS)，实现端到端实时目标检测；

**💡 创新点**

核心创新包括MuSGD优化器、STAL小目标自适应标签分配以及ProgLoss动态损失调度，以及直接回归无分布焦点损失的检测头；

**🔧 技术方法**

采用端到端学习、直接回归头、MuSGD、STAL、ProgLoss等技术，基于CSP‑Muon骨干和PAN颈部；

**📊 数据集**

主要在COCO数据集上进行训练和评估，并在官方benchmark中对比YOLOv5–v11、RTMDet、DAMO‑YOLO等模型；

**📈 对比分析**

通过官方指标显示，YOLO26在NVIDIA T4/TensorRT FP16环境下实现mAP 50‑95约57.5、推理延迟≈11.5 ms，位于新的Pareto前沿，比同类模型快约43 %（CPU）且精度更高；

**⚠️ 局限性**

局限包括缺乏内置可解释性、未解决视频时序跟踪、未实现边缘端测试时适应、以及对极端小目标的鲁棒性仍待提升。

---

## 40. The Origin of the Inaccessible Game

**arXiv ID:** 2601.12576 | [PDF](https://arxiv.org/pdf/2601.12576v1)

**作者:** Neil D. Lawrence `[一作]` (University of Cambridge), Neil D. Lawrence `[通讯]` (University of Cambridge)

**通讯引用:** 16521 | [OpenAlex ID](https://openalex.org/A5023849469)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文从信息几何视角重新定义并研究“不可达游戏”（Inaccessible Game），在原来基于Shannon熵的框架中出现的起点冲突，改用冯·诺伊曼熵构造可行的起点；进一步在矩阵指数族中推导受边界约束的最速熵升（steepest entropy ascent, SEA）动力学，并通过二阶约束锁定可接受方向；引入“熵时”作为自洽时钟，将无穷游戏时间映射为有限区间；将约束动力学拆解为可逆（共轭）和不可逆（SEA）两部分，形成GENERIC兼容的可逆-不可逆结构；并将边缘熵守恒映射为局部模量哈密顿量（modular Hamiltonian）期望，说明其与传统热力学能量约束的本质关联。

**💡 创新点**

① 用冯·诺伊曼熵消除了Shannon熵下的起点不一致；② 在起点处将一阶约束转化为二阶几何条件，首次给出对可接受方向的几何刻画；③ 引入熵时作为游戏独立的时间参照，实现了对无穷接近边界动力学的压缩；④ 将边缘熵守恒转化为局部模量哈密顿量期望，从而在信息理论框架内自然得到能量守恒；⑤ 构造的动力学满足GENERIC结构，提供了可逆-不可逆分解的统一表述。

**🔧 技术方法**

信息几何（Riemannian 与 BKM度量）、冯·诺伊曼熵、矩阵指数族、约束优化（拉格朗日乘子与投影）、二阶约束分析、熵时重参数化、可逆/不可逆分解（GENERIC/metriplectic）

**📊 数据集**

无数据集，本文为纯理论推导与结构分析

**📈 对比分析**

无实验比较，本文通过数理推导和示例（如两qutrit系统）展示方法可行性，未涉及数值性能评估

**⚠️ 局限性**

① 起点处的参数在自然坐标中趋于无穷，导致度量退化；② 熵时的定义需假设熵产生率始终正，无法覆盖平衡点；③ 局部模量哈密顿量在完整动态中为状态依赖，难以直接映射到传统能量算符；④ 结果主要在量子信息几何框架内，对经典统计下的可解释性有限。

---

## 41. SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition

**arXiv ID:** 2601.12432 | [PDF](https://arxiv.org/pdf/2601.12432v1)

**作者:** Shunyu Huang `[一作]` (Nanyang Technological University), Jianfei Yang `[通讯]` (Nanyang Technological University)

**通讯引用:** 6747 | [OpenAlex ID](https://openalex.org/A5005666034)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `8d10c613-917e-4880-9716-17789f50e119` `3f18e8e3-0266-457c-8567-9039b6d2394d` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了SkeFi框架，利用无线传感器（LiDAR、mmWave）进行骨骼动作识别，并通过跨模态知识迁移提升鲁棒性。

**💡 创新点**

创新点包括：①将RGB先验知识迁移至无线传感器域；②设计时间相关自适应图卷积（TC-AGCN）和增强多尺度时序建模（ESP‑MST）；③采用层级冻结策略实现高效、参数友好的迁移学习。

**🔧 技术方法**

技术手段涵盖跨模态迁移学习、图卷积网络（TC-AGCN）、多尺度/ESP‑MST时序卷积、帧缺失对齐与补全、无监督知识蒸馏等。

**📊 数据集**

使用Kinetics‑Skeleton（400类RGB骨骼）作为源数据集，MM‑Fi多模态4D骨骼数据集（RGB、LiDAR、mmWave、WiFi）作为目标数据集。

**📈 对比分析**

在MM‑Fi三模态上与ST‑GCN、AGCN、AGC+MST/ESP‑MST等基线比较，SkeFi在RGB/ mmWave/ LiDAR上的准确率分别达到约94.0%/79.2%/65.0%，比从零开始训练提升约30%或更多。

**⚠️ 局限性**

局限性在于对无线传感器噪声和帧缺失仍存在敏感性；需要较长的帧序列（如40帧）才能获得最佳效果；模型仍需依赖大量预训练数据，且在极端低数据量场景下性能下降。

---

## 42. Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy

**arXiv ID:** 2601.12257 | [PDF](https://arxiv.org/pdf/2601.12257v1)

**作者:** Fadlullah Raji `[一作]` (University of South Florida), John Murray-Bruce `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `4de8e9d8-757b-475f-9627-18a445e50202` `90291a0e-9d36-4a08-9a16-89ce846d923f` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出一种基于软影子照片的3D NLOS成像框架，既包括梯度优化求解分离非线最小二乘逆问题，也提出了基于物理启发的软影子扩散（SSD）神经网络，能够同时恢复隐藏场景中的3D遮挡物与2D非遮挡光照物。

**💡 创新点**

创新点主要有：①将光传输模型分解为遮挡与非遮挡两部分，构造可分离的非线最小二乘逆问题；②将扩散概率模型与软影子编码器相结合，构建条件点云生成网络SSD；③首次在被动NLOS成像中实现单张照片同时重建3D遮挡体与2D光照体，显著扩展了之前仅能重建光照体或已知遮挡物的技术。

**🔧 技术方法**

采用的技术包括：光学可视性与Lambertian模型的数学推导；基于梯度下降的交替最小化与Tikhonov正则化求解；1D卷积UNet的扩散去噪网络（SSD）；CrossFormer视觉编码器对软影子照片的潜在表示；SDF神经网络与marching cubes算法生成网格；以及TV正则化的后处理。

**📊 数据集**

训练数据来源于ShapeNet三维模型，使用Blender渲染得到多视角RGB图像与对应的软影子照片；实验验证则使用真实实验室拍摄的4MP相机捕获的可见墙面软影子图像。

**📈 对比分析**

与梯度优化方法对比，SSD在复杂遮挡物的重建上表现更好，计算效率更高，对噪声与背景光的鲁棒性更强；在合成数据上MSE与Chamfer距离随信噪比下降平稳，真实数据亦表现出良好的一致性，且对未见过的3D类别仍能保持较低误差。

**⚠️ 局限性**

局限性：梯度优化在高分辨率遮挡物时计算量和内存开销过大，难以扩展；SSD生成的点云缺乏真实NLOS配置下的空间位置信息，需要进一步的网格搜索与尺寸估计；模型训练仅基于模拟数据，虽在真实场景中表现良好但对极端光照与动态场景的适应性仍待验证。

---

## 43. The Dynamic and Endogenous Behavior of Re-Offense Risk: An Agent-Based Simulation Study of Treatment Allocation in Incarceration Diversion Programs

**arXiv ID:** 2601.12441 | [PDF](https://arxiv.org/pdf/2601.12441v1)

**作者:** Chuwen Zhang `[一作]` (University of Chicago), Amy Ward `[通讯]`

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文构建了一个动态人‑系统交互框架，通过代理仿真评估监狱转移项目中治疗分配策略的长期与短期效果。

**💡 创新点**

创新点在于将再犯风险视为随时间演变、受社区交互影响的动态量，并利用代理仿真捕捉反馈机制与容量约束下的系统级结果，揭示低风险与高风险策略在不同情境下的互相制约关系。

**🔧 技术方法**

主要技术包括Cox比例风险模型（融合静态/动态协变量与治疗效应）、基于事件队列的代理仿真平台以及参数校准与情景实验。

**📊 数据集**

使用了ICPSR提供的Felony Probationers Study（约9374例保释案例）与对应的县市统计数据，涵盖个体与社区层面的特征。

**📈 对比分析**

在四种分配策略（无治疗、低风险优先、高风险优先、年龄‑低风险优先）下，在不同监测强度、治疗效应、到达率/容量情景中进行比较；结果显示无单一最优策略，低风险优先在长期低监测率下更优，高风险优先在短期或高监禁率下更优。

**⚠️ 局限性**

局限性包括对治疗效应假设为同质性、未考虑公平与歧视影响、模型参数估计受限于样本、未能完整捕捉真实社会行为与政策实施细节。

---

## 44. VIRTUE: Versatile Video Retrieval Through Unified Embeddings

**arXiv ID:** 2601.12193 | [PDF](https://arxiv.org/pdf/2601.12193v1)

**作者:** Shaunak Halbe `[一作]` (Georgia Institute of Technology), Toufiq Parag `[通讯]` (Amazon)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

构建了一个统一的多模态大语言模型框架 VIRTUE，能够在单一体系内完成语料库级检索、候选重排序、复合多模态查询以及时刻定位。

**💡 创新点**

创新点包括：① 用两阶段对比学习（图像–文本→视频–文本）对 MLLM 进行统一嵌入对齐；② 采用基于 EOS 句子隐藏状态的嵌入作为查询/视频的表示；③ 设计了简单但高效的重排序器 VIRTUE‑Ranker，使用 BCE 与偏好损失实现细粒度排序；④ 在零样本条件下实现复合视频检索与时刻定位，无需额外任务专用训练。

**🔧 技术方法**

技术主要包括：多模态大型语言模型 Qwen‑VL 2.5‑7B，LoRA 低秩适配器，InfoNCE 对比损失，BCE 与 Bradley‑Terry 偏好损失，帧级相似度峰值检测，Gaussian 平滑与 NMS。

**📊 数据集**

使用的公开数据集有：图像–文本（Conceptual Captions 595K）、视频–文本（PEVideo 105K、MSR‑VTT、DiDeMo、MSVD、CoVR、Charades‑STA、ActivityNet‑Captions）。

**📈 对比分析**

与其它 MLLM 方案（VLM2Vec、CaRe、LamRA 等）和专业检索模型（InternVideo2、Thawakar 等）对比，VIRTUE 在 MSR‑VTT、DiDeMo、MSVD 的 R@1、R@5、R@10 上与 InternVideo2 接近或超过；在 CoVR 复合检索上领先约 8%；在 Charades‑STA 与 ActivityNet‑Captions 的时刻检索上取得最优或接近最优的零样本结果。所有这些都仅使用约 700K 对齐样本（约 105K 为视频）。

**⚠️ 局限性**

局限性包括：① 对长视频的帧级相似度计算仍然受限于帧采样频率和 GPU 记忆；② 复合查询仍依赖于 MLLM 的内在多模态推理能力，可能在极端模态混合下失效；③ 重排序器仍需要一定的候选集规模，过大时计算成本上升；④ 在更大规模视频‑文本数据上训练可能进一步提升性能，但目前实验规模受限。

---

## 45. Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants

**arXiv ID:** 2601.12405 | [PDF](https://arxiv.org/pdf/2601.12405v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 46. Human-Human-AI Triadic Programming: Uncovering the Role of AI Agent and the Value of Human Partner in Collaborative Learning

**arXiv ID:** 2601.12134 | [PDF](https://arxiv.org/pdf/2601.12134v1)

**作者:** Taufiq Daryanto `[一作]` (Virginia Tech), Eugenia H. Rho `[通讯]` (Virginia Tech)

**通讯引用:** 859 | [OpenAlex ID](https://openalex.org/A5054447687)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

研究了人-人-人工智能三方协作编程（HHAI），并与人-人工智能（HAI）对照，评估协作学习、社交存在、AI 使用率等维度。

**💡 创新点**

创新点在于把 AI 视为协作者而非替代者，探讨共享 AI 与个人 AI 的定位、主动干预对协作的影响，并发现三方协作提升学习与社交存在、降低对 AI 代码的依赖。

**🔧 技术方法**

技术实现包括：集成协同代码编辑器与会话界面、实时语音转写、基于 GPT‑4.1‑mini 的主动/被动干预、文本/语音交互、多模态输入；实验数据通过混合效应模型等统计方法进行分析。

**📊 数据集**

使用数据：20 名计算机科学学生（10 对）完成 LeetCode 风格编程任务（含多子任务）的实验记录，未使用公开数据集。

**📈 对比分析**

采用 within‑subjects 设计对三种条件（Shared AI、Personal AI、HAI）进行量表比较（CLS、SPQ），记录 AI 生成代码比例与使用率；实验结果显示学习体验和社交存在显著提升，但编程任务完成数与错误率无显著差异，表明三方协作在保持性能的同时提升学习质量。

**⚠️ 局限性**

局限性包括：未设置无 AI 的人-人基线、样本来自单一高校、仅进行一次 90 分钟实验、合作伙伴已相识且可能影响协作质量、存在顺序效应等。

---

## 47. A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling

**arXiv ID:** 2601.12820 | [PDF](https://arxiv.org/pdf/2601.12820v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 48. Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild

**arXiv ID:** 2601.12464 | [PDF](https://arxiv.org/pdf/2601.12464v1)

**作者:** Yanrui Lu `[一作]` (Guangzhou Institutes of Biomedicine and Health), Yingying Zhu `[通讯]` (South China University of Technology)

**通讯引用:** 2385 | [OpenAlex ID](https://openalex.org/A5068185303)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了一个大规模、真实环境的多细胞器实例分割基准，并利用3D LPA算法与专家校正实现高质量实例标注，随后对U‑Net、Mask2Former和SAM等模型在该基准上的性能进行了系统评估；

**💡 创新点**

①提出了覆盖10万+二维EM图像、五类细胞器的“in‑the‑wild”大规模实例分割基准；②设计了3D标签传播算法（3D LPA）实现从语义到实例的自动转换；③通过基准实验揭示了基于局部补丁的方法在全局网络结构（如内质网）上的根本失效。

**🔧 技术方法**

使用3D LPA连通组件标签传播、人工校正；评估模型包括U‑Net（语义+后处理）、Mask2Former（Transformer查询）和SAM（提示式变压器）及其微调版；训练采用Adam优化、Scale Alignment、512×512随机裁剪。

**📊 数据集**

采集自公开数据集OpenOrganelle、BetaSeg以及自有已拼接注册的EM数据，共计10万+张二维图像，覆盖多种细胞类型与五类细胞器。

**📈 对比分析**

将模型在同质子集与完整“in‑the‑wild”基准上进行Dice/IoU对比；结果显示整体性能下降，特别是全局网络细胞器：U‑Net、Mask2Former在Mito/Nucleus上Dice>0.8，但在ER、Golgi仅为0.2–0.4，说明补丁方法缺乏全局上下文。

**⚠️ 局限性**

主要局限在于基于局部补丁的设计无法捕获长程结构，导致在ER、Golgi等全局网络细胞器上的严重失效；此外模型对数据异质性的适应性不足；3D LPA生成的实例标签仍需人工校正，增加成本。

---

## 49. Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data

**arXiv ID:** 2601.12809 | [PDF](https://arxiv.org/pdf/2601.12809v1)

**作者:** Takaki Yamamoto `[一作]` (InfoTech, Toyota Motor Corporation), Toshihiro Tanizawa `[通讯]` (InfoTech, Toyota Motor Corporation)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

研究了CLIP风格视觉‑语言模型在合成1D图像‑文本数据集上学习左‑右空间关系的能力，并通过注意力分解揭示了其机制。

**💡 创新点**

创新点在于提出可控的1D实验平台，证明位置与词嵌入交互产生的水平注意力梯度是实现左‑右关系泛化的关键。

**🔧 技术方法**

使用了对比学习、轻量级 Transformer 编码器、注意力分解与消融实验。

**📊 数据集**

使用了自制的合成1D图像‑文本数据集，包含单物体与双物体场景。

**📈 对比分析**

通过图像‑文本检索准确率评估三类泛化（单物体位置、已见配对、未见配对），实验显示在标签多样性足够时可达高精度，权重衰减进一步提升效果。

**⚠️ 局限性**

局限在于仅使用极简的1D合成数据，模型规模小，未验证在真实2D图像或大型 VLM 上的可迁移性。

---

## 50. Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck

**arXiv ID:** 2601.12499 | [PDF](https://arxiv.org/pdf/2601.12499v1)

**作者:** Meiru Zhang `[一作]` (University of Cambridge), Nigel Collier `[通讯]` (University of Cambridge)

**通讯引用:** 8465 | [OpenAlex ID](https://openalex.org/A5073413742)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究多跳推理中的位置偏差，并通过多焦点注意力指令（MFAI）来探测并缓解这种偏差。

**💡 创新点**

提出弱链法则（Weakest Link Law）与MFAI语义探针，区分识别瓶颈与合成瓶颈；揭示误导指令在真实与合成数据上的双重效应；证明系统‑2思考模式对噪声与误导的鲁棒性。

**🔧 技术方法**

使用多焦点注意力指令（MFAI）、位置桶因子实验、镜像指令设计、系统‑2思考模式、注意力热图分析等技术。

**📊 数据集**

MuSiQue（实体多跳）与 NeoQA（事件多跳）两大多跳问答数据集。

**📈 对比分析**

在Spread和Cross两种协议下，对五个LLM（Qwen2.5‑7B、Qwen2.5‑14B、Llama‑3.1‑8B、Ministral‑8B、Qwen3‑8B）以及Qwen3‑8B的思考模式进行比较。结果显示：无指令时性能随绝对位置下降；匹配MFAI显著提升，尤其在低可见度位置提升10–12%；误导MFAI在MuSiQue导致性能下降，在NeoQA略有提升；思考模型在噪声与误导指令下保持或超过金标水平。

**⚠️ 局限性**

仅评估两类多跳数据集，未测试更大规模模型或其他推理模型；未考虑检索重排序、提示变体、不同桶数或更长上下文；内部机制未做细粒度的logprob/困惑度分析。

---

## 51. MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents

**arXiv ID:** 2601.12661 | [PDF](https://arxiv.org/pdf/2601.12661v1)

**作者:** Chuhan Qiao `[一作]` (Meituan), Kai Wu `[通讯]` (Meituan)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并发布了 MedConsultBench，一个覆盖线上医疗咨询全过程（历史采集、诊断、治疗规划、随访问答）的完整评测框架。

**💡 创新点**

创新点包括：① 引入 Atomic Information Units（AIUs）和最小必要信息集合（MNI）以实现子回合级别的过程跟踪；② 提出 22 个细粒度、过程感知指标；③ 通过真实线上问答与临床指南挖掘询问逻辑模板、先后关系与诊断权重；④ 构建基于规则的临床安全评判器与 LLM‑as‑Judge 的评测流水线。

**🔧 技术方法**

使用技术包括：大型语言模型（LLMs）进行对话生成；基于模板匹配的患者模拟器；一阶马尔可夫询问策略与部分序关系；嵌入+聚类技术抽取 AIUs；规则推理的安全批评器；LLM 评审模块和统计归一化。

**📊 数据集**

数据集来源：35,792 条去标识化的中文线上医生‑患者对话（平均 13.1 条消息）、临床指南、药物标签与处方统计，用于构建 AIU、MNI、询问模板和安全规则。

**📈 对比分析**

通过在同一流程下评测 19 种 LLM（含思考与非思考版），在 12 个主指标和 10 个辅指标上进行量化对比。结果显示：思考模式明显优于非思考模式；历史采集、诊断和治疗规划得到提升，但随访问答仍是最薄弱环节；高端模型在整体分数与真实过程基准相差 30‑40%（如 Gemini‑3‑Pro 0.52 vs 0.814）。

**⚠️ 局限性**

局限性：① 仿真环境与真实患者交互的差距（缺乏噪声与情感因素）；② 评测主要基于文本，无法涵盖体检、影像等临床手段；③ 语言与科室仅覆盖中文特定门诊，跨语言与跨文化推广需验证；④ 评审者（LLM‑as‑Judge）可能继承模型偏见，软技能评估仍为主观；⑤ 仍可能保留历史数据中的系统性偏见。

---

## 52. ASAS-BridgeAMM: Trust-Minimized Cross-Chain Bridge AMM with Failure Containment

**arXiv ID:** 2601.12434 | [PDF](https://arxiv.org/pdf/2601.12434v1)

**作者:** Shengwei You `[一作]` (University of Notre Dame), Jarek Nabrzyski `[通讯]` (University of Notre Dame)

**通讯引用:** 2294 | [OpenAlex ID](https://openalex.org/A5068300137)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `5a41884c-404f-4688-a89c-aa238c10fe68` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

开发了一种跨链桥接自动做市商（ASAS-BridgeAMM），通过动态调整抵押品折价、滑点和提现限额，以容忍性下降模式（Contained Degradation）实现对桥接失败的经济容限；

**💡 创新点**

核心创新在于将跨链消息延迟视为可度量的执行风险，将其嵌入AMM定价函数中；实现了信任最小化的桥接协议，提供了渐进式失效、动态抵押折价、链路状态监控与电路断路器；

**🔧 技术方法**

采用Solidity实现的多合约体系（IngressVault、BridgeAMM、CircuitBreaker等），使用多源价格聚合与中位数滤波；在协议层面引入基于延迟的线性折价函数与自适应滑点；通过正式状态机证明安全、活性与操控抗性；

**📊 数据集**

利用以太坊主网区块链历史（Jan 2024–Jul 2025，共547天）和CoinGecko 1分钟行情数据；以及100,000次蒙特卡洛模拟，随机化价格崩盘、延迟和交易规模；

**📈 对比分析**

与传统锁定‑铸币桥（无电路断路器）进行对比，实验显示在18个月回放中ASAS-BridgeAMM将最大坏账降低73%，保持104.5%的交易量，蒙特卡洛测试证明>0.9999的清偿概率，坏账率<0.2%；

**⚠️ 局限性**

限制包括对参数（折价上限、延迟阈值、价格偏差阈值）高度依赖；仅在EVM链上验证，未覆盖所有共识模型；对MEV攻击仍需要额外措施；模拟环境未能完全捕捉极端网络分区或大规模攻击场景。

---

## 53. Language-Based Swarm Perception: Decentralized Person Re-Identification via Natural Language Descriptions

**arXiv ID:** 2601.12479 | [PDF](https://arxiv.org/pdf/2601.12479v1)

**作者:** Miquel Kegeleirs `[一作]` (IRIDIA Université libre de Bruxelles), Mauro Birattari `[通讯]` (IRIDIA Université libre de Bruxelles)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在机器人群中引入基于自然语言描述的去中心化人再识别方法，使用视觉‑语言模型生成文本描述，利用文本相似度聚类，并通过分布式通信共享与合并聚类结果；最终通过大语言模型生成聚类代表性描述，实现可解释的群体认知和自然语言查询。

**💡 创新点**

① 用自然语言取代传统的高维视觉嵌入，提升系统可解释性；② 在去中心化机器人群中实现仅基于文本的聚类与通信；③ 结合LLM生成聚类代表性描述，支持直观查询和人机交互；④ 在没有集中化视觉特征存储的情况下完成人再识别。

**🔧 技术方法**

- 视觉‑语言模型 (Qwen‑VL) 用于生成个体的文本描述；
- 大语言模型 (Qwen‑LLM) 用于合成聚类代表性描述；
- 句子级 embedding + 余弦相似度做相似度匹配；
- 随机行走探索策略；
- ARGoS3+Unity 仿真环境；
- 评估指标：CMC、mAP、cluster purity。

**📊 数据集**

检测使用 COCO 训练的模型；实验在 Unity+ARGoS3 模拟环境中进行，包含 6 人与 50 人两种场景（无障碍/有障碍）。

**📈 对比分析**

与先前的基于视觉嵌入的去中心化再识别基线进行对比；在 6 人场景中，文本方法的 mAP 与 purity 均优于嵌入方法，CMC 稍低；在 50 人场景中，文本方法保持更高的 CMC 且 mAP 下降幅度更小，纯度下降幅度亦比嵌入方法小；通信可显著提升两者性能；总体显示文本方法在可解释性和鲁棒性上具有优势，但在检索排名上略逊。

**⚠️ 局限性**

① 过度碎片化（过多细粒度聚类）导致 CMC、mAP 降低；② 余弦相似度对句子 embedding 的硬阈值不够灵活；③ 计算量大，尤其是大语言模型和交叉编码器导致实时性受限；④ 在大规模人群和更复杂环境下的可扩展性不足；⑤ 对光照、遮挡等视觉变化的鲁棒性仍有提升空间。

---

## 54. Do Neural Codecs Generalize? A Controlled Study Across Unseen Languages and Non-Speech Tasks

**arXiv ID:** 2601.12205 | [PDF](https://arxiv.org/pdf/2601.12205v1)

**作者:** Shih-Heng Wang `[一作]` (University of Southern California), Shinji Watanabe `[通讯]` (Carnegie Mellon University)

**通讯引用:** 25423 | [OpenAlex ID](https://openalex.org/A5001291873)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `fede83ac-7505-405f-ab37-e7284695c47f` `67630363-6be0-4f51-ab05-7198250671a5` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本研究通过从零开始训练神经音频编解码器（NAC），在三种预训练数据覆盖（英语单语、跨语言、多语言+非语音音频）下，系统评估其对未见语言、仅语音与非语音任务的泛化能力。

**💡 创新点**

创新点在于统一配置并精心策划预训练数据覆盖，以公平对比 NAC 的语言与任务泛化；并利用 11 项多维度指标对信号重建与 TTS 下游任务进行全方位评估。

**🔧 技术方法**

采用 SoundStream 结构的 NAC，使用结合重建与 GAN 的预训练框架；在基准评估中使用 HiFi‑GAN；TTS 任务采用 FastSpeech2 预测 NAC 码，所有实验均基于 ESPnet‑Codec 与 VERSA 工具箱。

**📊 数据集**

预训练数据为 MLS（英语单语及 8 种语言）与 AudioSet；评估数据集包括 LJSpeech、CSS10（德语、西班牙语）用于语音重建与 TTS；非语音重建评估使用 AudioSet 测试集。

**📈 对比分析**

通过三组 NAC 在 11 项指标（包括 MCD、PESQ、VISQOL、WER 等）下的信号重建与 TTS 性能对比，发现英语预训练的 NAC 在语音重建最优，跨语言+音频预训练的 NAC 在非语音重建与部分下游指标上最优；未见语言依旧保持良好性能，证明 NAC 具备跨语言泛化。

**⚠️ 局限性**

局限性包括仅使用 SoundStream 架构，未检验 EnCodec、DAC 等其他 NAC；下游任务仅限 TTS，未覆盖音乐或环境音等非语音应用；实验规模受限，未尝试更强自回归 TTS 模型。

---

## 55. VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension

**arXiv ID:** 2601.12781 | [PDF](https://arxiv.org/pdf/2601.12781v1)

**作者:** Hyejin Park `[一作]` (Pohang University of Science and Technology), Jungseul Ok `[通讯]` (Pohang University of Science and Technology)

**通讯引用:** 434 | [OpenAlex ID](https://openalex.org/A5000550975)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `e0540dec-d77f-42db-94ae-d039248f6393` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了一种在每个推理步骤中嵌入轻量级验证器的 neuro‑symbolic 递归引用表达式理解（VIRO）框架，用于在无目标场景下准确定位目标并实现早期终止。

**💡 创新点**

创新点包括：①将不确定性与逻辑验证集成到操作符级别，实现无目标检测与误判抑制；②将程序生成与执行解耦，允许一次生成后多次执行，从而显著提升可扩展性和吞吐量；③通过 CLIP‑based 置信度过滤和深度信息实现更稳健的视觉推理。

**🔧 技术方法**

采用技术包括：大语言模型（Qwen2.5‑72B）生成可执行符号程序；Open‑Vocabulary Detector（GroundingDINO、GLIP）提取候选框；CLIP 用于不确定性验证和属性匹配；DepthAnything 用于空间关系判定；程序解释器执行操作并根据验证结果早期终止。

**📊 数据集**

使用的数据集包括：gRefCOCO no‑target（无目标测试）、RefCOCO/+/g（标准 REC）、RefAdv（对抗性测试）、RefEgo（视角变换视频 REC）。

**📈 对比分析**

与 ViperGPT、HYDRA、NAVER、Detector‑only、Fully‑Supervised 等基线在 1‑查询‑N‑图像和视频场景中对比，VIRO 在平衡准确率上达 61.1%，TPR 与 TNR 均显著提升；程序失败率低于 0.3%，吞吐量提升至每秒数十帧，且在 1‑查询‑N‑图像设置下实现线性扩展。

**⚠️ 局限性**

局限性：仍受 OVD 与 CLIP 误检率影响，阈值设定需要手工调节；在遮挡、低光照或极度复杂关系的场景下性能可能下降；对更大规模多模态任务的适应性尚待进一步验证。

---

## 56. Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift

**arXiv ID:** 2601.12639 | [PDF](https://arxiv.org/pdf/2601.12639v1)

**作者:** Daniel Vennemeyer `[一作]` (University of Cincinnati), Samuel Ratnam `[通讯]` (University of Oxford)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在保持数据、领域、模型架构和优化策略不变的条件下，系统比较了六种不同的微调目标（SFT、DPO、CFT、IP、ORPO、KL‑regularized）对大型语言模型在能力、对抗鲁棒性和人格漂移三方面的影响。

**💡 创新点**

创新点在于：① 通过严格对照实验揭示微调目标对安全‑能力前沿的规模相关权衡；② 发现仅在大规模微调时，结构化或正则化目标（ORPO、KL）能显著抑制对抗易受攻击和人格漂移；③ 提出“Inoculation Prompting”作为一种简单、无需额外标签的实用对策，在保持能力的同时提升鲁棒性。

**🔧 技术方法**

使用的技术包括：标准最大似然（SFT）、直接偏好优化（DPO）、条件微调（CFT）、注射式提示（IP）、奇数比率偏好优化（ORPO）以及 KL 正则化微调；评估采用 StrongREJECT jailbreak 集合（多种提示攻击）、GSM8K、SuperGPQA、Cybersecurity、Legal Reasoning 数据集以及 Dark Triad 人格评估。

**📊 数据集**

数据集：GSM8K（数学推理）、SuperGPQA（工程子集）、Cybersecurity 与 Legal Reasoning（开放式生成），以及用于人格评估的 Dark Triad 评测数据；所有实验均在 LLaMA‑3.1‑8B‑Instruct、Gemma2‑2B/9B、Qwen3‑4B、Qwen2.5‑7B 等多模型上进行。

**📈 对比分析**

比较方法：在相同 token 预算（25k、100k、400k）下对每个目标的任务准确率与攻击成功率（ASR）绘制 Pareto 前沿；实验结果显示：在小规模微调时，所有目标鲁棒性相近，能力差异显著；在大规模微调时，SFT 与 DPO 的 ASR 急剧上升，而 ORPO 与 KL‑regularized 维持低 ASR；IP 在不牺牲能力的前提下实现了比 SFT 更低的 ASR，且在多模型多数据集上保持一致；人格漂移方面，SFT 与 IP 在大规模时表现出显著漂移，ORPO 与 KL‑regularized 则基本无漂移。

**⚠️ 局限性**

局限性：① 仅评估了 LoRA 微调，未涵盖全参数或更大规模训练；② 未探究混合/动态微调目标；③ 对抗鲁棒性仅基于提示式 jailbreak，未覆盖多轮、工具攻击等；④ 人格评估仅用 Dark Triad，未覆盖所有偏差维度；⑤ 结论主要是经验性的，缺乏对机制的深入解释。

---

## 57. GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation

**arXiv ID:** 2601.12683 | [PDF](https://arxiv.org/pdf/2601.12683v1)

**作者:** Liwei Liao `[一作]` (Peking University), Ronggang Wang `[通讯]` (Peking University)

**通讯引用:** 55543 | [OpenAlex ID](https://openalex.org/A5067004420)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

针对3D高斯散点（3DGS）分割中出现的边界锯齿问题，提出了GaussianTrimmer在线边界修剪后处理模块。

**💡 创新点**

创新点在于：①利用虚拟相机规划（VCP）生成均匀覆盖目标物体的视角，提升2D分割准确性；②通过2D分割结果对“跨界”高斯进行检测与分解（BGD），实现无训练、无重优化的边界平滑；③将该后处理模块设计为可即插即用、低延迟（≈1 s）的插件。

**🔧 技术方法**

主要技术包括：3D高斯散点投影、虚拟相机生成与投影、Segment Anything（SAM2）跨视角分割、逆α混合追踪检测跨界高斯、SAGD式高斯分解与裁剪。

**📊 数据集**

使用的数据集：NVOS（基于LLFF）做定量评估，IN2N、Mipnerf-360、PKU-DyMVHuman、LERF-Mask做定性展示；CLIP‑IQA用于视觉质量评估。

**📈 对比分析**

与多种主流3DGS分割方法（SA3D、OmniSeg3D、SAGA、FlashSplat、SAGD、COB‑GS）进行对比。结果显示，GaussianTrimmer在所有基线方法上均提升mIoU约0.4–1.6 %和mAcc约0.1–0.3 %，并显著提升CLIP‑IQA分数，证明其有效性。

**⚠️ 局限性**

限制：①需要额外的虚拟相机渲染，虽延迟低但在极大场景或高帧率实时场景下仍可能显著增加计算负担；②对跨界高斯的检测和分解依赖于2D分割质量，若SAM2误分割则修剪效果受限；③在极端复杂几何或透明材质场景中，跨界高斯分解可能不足以完全平滑边界。

---

## 58. Bringing Data Transformations Near-Memory for Low-Latency Analytics in HTAP Environments

**arXiv ID:** 2601.12456 | [PDF](https://arxiv.org/pdf/2601.12456v1)

**作者:** Arthur Bernhardt `[一作]` (Data Management Lab), Ilia Petrov `[通讯]` (Data Management Lab)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究一种将 OLTP 行式数据在智能存储设备上近数据处理 (NDP) 的列式（Arrow）转换，减少数据移动并提升前台事务吞吐量。

**💡 创新点**

创新点在于：① 将行列转换视作 NDP 操作，利用智能存储的高内部带宽和低成本；② 在设备端实现事务一致快照与可插拔的可插拔格式转换；③ 通过 Delta‑Δ 机制支持增量重用，降低重转换成本。

**🔧 技术方法**

使用技术包括：智能存储 + FPGA + MicroBlaze 软核；BRAM/DDR/NVM 三级存储层；NDP‑DBMS 负责共享状态同步与资源预留；Arrow 作为列式中间格式；NDBC 接口实现零拷贝共享内存访问；布尔位图与偏移向量用于增量变更识别。

**📊 数据集**

实验数据集：CH‑benchmark（Scale Factor 100）和 TPC‑C，主要用来评估 OLTP 与 OLAP 的并发执行效果。

**📈 对比分析**

比较方法：将 NDP‑Arrow 与 PostgreSQL（传统导出‑转换）以及纯 Arrow 引擎（先导出后转换）对比；结果显示：NDP‑Arrow 在 OLTP 负载下保持接近 PostgreSQL 的吞吐量，显著降低了转换延迟（≈ 30‑50 % 下降）；Delta‑Δ 在少量更新时提升了 2‑3 倍速度，且增量成本随变更比例线性。

**⚠️ 局限性**

限制：① 需要专用智能存储硬件，难以迁移至常规磁盘/SSD；② 仅适合行→列或 KV→列等结构化转换，复杂算子或高频更新仍需额外加速；③ Delta‑Δ 依赖版本链长度，长链会导致增量成本上升；④ 目前实现主要在 ARM Neoverse N1‑SDP 环境下验证，跨平台兼容性待进一步研究。

---

## 59. FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection

**arXiv ID:** 2601.12863 | [PDF](https://arxiv.org/pdf/2601.12863v1)

**作者:** Jun Wan `[一作]` (Zhongnan University of Economics and Law), Wenwen Min `[通讯]` (Yunnan University)

**通讯引用:** 534 | [OpenAlex ID](https://openalex.org/A5083513047)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种频率引导任务平衡Transformer（FGTBT），通过 FMB-loss 和 FGSA 模块实现多数据集统一训练，提高面部关键点检测精度。

**💡 创新点**

创新点包括：①细粒度多任务平衡损失 FMB-loss，依据关键点出现频率动态加权；②频率引导结构感知模块 FGSA，利用 FFT 提取高频结构信息并注入/正则化Transformer；③将两者集成至单一Transformer框架，实现不同标注协议数据集的联合学习。

**🔧 技术方法**

技术手段：Transformer（SegFormer‑style分层编码器）、FFT 高频提取、结构注入与正则化、热图回归、AWing 损失、细粒度平衡权重。

**📊 数据集**

使用四大公开数据集：AFLW、WFLW、COFW 和 300W，覆盖不同关键点数与标注协议。

**📈 对比分析**

在 300W、WFLW、COFW、AFLW 等基准上与 LAB、DTLD、GFL、PicassoNet 等 SOTA 方法对比，FGTBT 在多数子集（尤其是大姿态、表情、遮挡等挑战集）取得与或优于 SOTA 的 NME，整体性能显著提升。

**⚠️ 局限性**

局限性：模型参数量约 53M，FLOPs 高达 103G，推理速度慢，难以满足实时需求；对低分辨率人脸的鲁棒性不足。

---

## 60. Data-Consistent Learning of Inverse Problems

**arXiv ID:** 2601.12831 | [PDF](https://arxiv.org/pdf/2601.12831v1)

**作者:** Markus Haltmeier `[一作]` (University of Innsbruck), Gyeongha Hwang `[通讯]` (Yeungnam University)

**通讯引用:** 405 | [OpenAlex ID](https://openalex.org/A5070476604)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

结合经典正则化与神经网络，提出在逆问题求解中仅在算子A的零空间内进行学习修正的零空间网络（null‑space network）以保证数据一致性（DC）并提升重建质量。

**💡 创新点**

核心创新在于：①把数据一致性嵌入网络结构，使得学习过程仍保留传统正则化的收敛性与收敛速率；②通过理论证明零空间网络可视为收敛正则化方法；③提出可在零空间外轻微修正的“数据邻近网络”以提升鲁棒性。

**🔧 技术方法**

使用Tikhonov正则化作为初始重建，随后应用卷积神经网络（5层 CNN，ReLU激活）作为零空间修正器；采用数据驱动的训练目标并加权 Frobenius 正则化；在理论层面利用正则化滤波器、Moore–Penrose 逆算子和收敛分析。

**📊 数据集**

在64×64 的合成图像上进行实验，数据由矩阵 A = M K（K 为竖向累加，M 为垂直条纹采样掩模）生成，训练样本为带水平条纹的 20×20 方块图像，测试样本包含同尺寸的均匀强度方块。

**📈 对比分析**

与传统 Tikhonov 正则化、普通残差网络（ResNet）对比；在 ID（条纹方块）数据上，普通 ResNet 取得最低误差、最高 PSNR/SSIM；在 OOD（均匀方块）数据上，零空间网络在 PSNR 上最高，表明在分布外更具测量一致性和更少假影；整体表明零空间网络兼具理论保障与实用性能。

**⚠️ 局限性**

局限在于零空间约束过于严格，限制了网络对补空间的修正，导致在 ID 数据上性能不如普通 ResNet；对噪声、模型不匹配的鲁棒性仍待提升；实验仅在小规模合成数据上验证，需进一步在真实医学影像等复杂场景中评估。

---

## 61. A Scalable Entity-Based Framework for Auditing Bias in LLMs

**arXiv ID:** 2601.12374 | [PDF](https://arxiv.org/pdf/2601.12374v1)

**作者:** Akram Elbouanani `[一作]` (Universite Paris Saclay), Adrian Popescu `[通讯]` (Universite Paris Saclay)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了可扩展的、基于命名实体的LLM偏差审计框架，并利用合成文本对1.9 B样本（涵盖政治人物、国家、公司、12项任务、3种语言、16个模型、4种提示）进行大规模偏差审计。

**💡 创新点**

创新点包括：①使用合成文本作为可靠代理验证偏差；②在1.9 B规模下完成多维度（实体类型、任务、语言、模型、提示）审计；③构建统一的语义极性空间聚合偏差；④多模型、多语言、多提示的系统对比分析。

**🔧 技术方法**

技术手段包括：模板生成与实体替换、语义极性映射、归一化偏差分数、Pearson相关、t检验、Cohen d等统计检验，以及对比实验设计。

**📊 数据集**

数据集：合成数据（由GPT‑5.1生成的模板+实体），以及五个真实基准（MAD‑TSC、FinEntity、P‑Stance、LIAR、MAD‑TSC党派）；实体集合包括984名政治人物、1200家公司、国家列表等。

**📈 对比分析**

通过与真实基准的Pearson相关（>0.8）验证合成文本的可靠性；在大规模审计中发现系统性偏差：左翼人物正偏、右翼人物负偏、全球南部国家负偏、特定行业公司负偏；语言、模型规模、提示方式对偏差幅度有显著影响，指令微调可降低幅度但不改变方向。

**⚠️ 局限性**

局限性：仅覆盖开源模型；构造效度受限；指令微调可能引入新的偏差；模板与措辞敏感；翻译与文化差异可能影响跨语言对比；仅评估分类任务，未覆盖生成任务；不考虑时间动态；实体选择不完整；未检验长文本对偏差的影响；难以区分统计先验与真正偏差；存在伦理风险。

---

## 62. Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning

**arXiv ID:** 2601.12242 | [PDF](https://arxiv.org/pdf/2601.12242v1)

**作者:** WooSeok Kim `[一作]` (Sangmyung University), Kyungseop Shin `[通讯]` (Sangmyung University)

**通讯引用:** 223 | [OpenAlex ID](https://openalex.org/A5014251132)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出了基于深度强化学习的下行NOMA资源分配框架，利用经验回放+REINFORCE实现通道分配并结合JRA进行功率分配。

**💡 创新点**

创新点在于将经验回放引入on‑policy REINFORCE算法，实现动态环境下的泛化学习，并通过多模型、多特征、多学习率等实验验证其鲁棒性。

**🔧 技术方法**

使用深度强化学习（REINFORCE+经验回放）、全连接/卷积/注意力网络、JRA功率分配、Adam优化器。

**📊 数据集**

在模拟的随机IoT场景下生成的数据，BS周围用户距离50–300 m，采用Rayleigh衰落与路径损耗α=2。

**📈 对比分析**

与JRA、无回放JRA‑DRL以及穷举搜索对比，结果表明该方法在不同功率、用户数和最小速率条件下，获得的总吞吐率接近穷举上限，且训练时间显著降低。

**⚠️ 局限性**

局限性在于仍需大量超参数调优，且对极大规模用户/信道场景的可扩展性未充分验证，仿真环境仅为理想化随机布局。

---

## 63. Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models

**arXiv ID:** 2601.12555 | [PDF](https://arxiv.org/pdf/2601.12555v1)

**作者:** Yihong Liu `[一作]` (Center for Information and Language Processing, LMU Munich, Munich Center for Machine Learning), Hinrich Schütze `[通讯]` (Center for Information and Language Processing, LMU Munich, Munich Center for Machine Learning)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了多语言大型语言模型在通过上下文间接获取事实知识时的记忆性能，并与直接实体查询做对比。

**💡 创新点**

首次系统评估上下文介导的事实回忆，提出合成与真实姓名对比实验，并跨五种语言、三大模型家族进行全面对比。

**🔧 技术方法**

采用两句提示模板、上下文介导查询、精确匹配准确率评估、模型规模对比以及姓名生成与过滤等技术手段。

**📊 数据集**

使用KLAR多语言事实知识探测数据集，涵盖1742条事实和9类关系。

**📈 对比分析**

以精确匹配准确率为指标，对比直接与上下文介导查询，发现上下文介导普遍降低准确率，但更大规模模型更稳健；合成与真实姓名之间无系统性差异。

**⚠️ 局限性**

研究受限于固定的关系与模板、有限的姓名样本、未包含封闭源模型，并未覆盖更自然多样的上下文场景。

---

## 64. LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines

**arXiv ID:** 2601.12285 | [PDF](https://arxiv.org/pdf/2601.12285v1)

**作者:** Safa C. Medin `[一作]` (Google), Abhimitra Meka `[通讯]` (Google)

**通讯引用:** 790 | [OpenAlex ID](https://openalex.org/A5067754015)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了一种基于分层网格和纹理的可动画体积化3D人脸头像表示方法，在渲染时不依赖神经网络，只需线性混合预训练好的UV偏移纹理和外观纹理即可实现实时动画。

**💡 创新点**

创新点包括：①将几何、外观和变形全部离散化为传统的网格和纹理；②通过UV空间的偏移纹理实现几何变形；③利用表达参数的线性映射得到混合权重，使动画在渲染端成为简单的纹理混合与alpha合成；④兼容现有的游戏引擎、WebGL等传统渲染管线，可直接在线流式传输。

**🔧 技术方法**

核心技术包括：光辐射体场（radiance manifolds）用于学习隐式曲面；MLP预测层用于生成UV偏移和外观纹理基；三层模块（manifold、warp、texture）联合训练；线性表达参数映射至混合权重；GPU可编程顶点/像素着色器完成渲染与合成；多主体合成训练提升表达泛化。

**📊 数据集**

使用NeRSemble多视角视频数据进行训练，并结合公开的合成多视角多表情数据集做多主体学习，以提高在新表情和不同主体上的泛化能力。

**📈 对比分析**

与BakedAvatar、Gaussian Head Avatar、GaussianAvatars、MonoAvatar++、PointAvatar等五种主流体积化头像方法对比；在PSNR、SSIM、LPIPS等指标上取得与主流方法相近的数值；在WebGL上实现实时渲染，帧率可达120Hz且显存占用低于2GB，表现优于需逐像素MLP的BakedAvatar。

**⚠️ 局限性**

局限性：①对极端表情或大幅面部运动仍可能出现shelling或细节缺失；②离散化表示限制了极高频细节的捕捉；③每个主体仍需单独训练，且依赖3DMM表情参数；④与连续体积化方法相比，在极端视角或光照变化下的真实感仍有限。

---

## 65. Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?

**arXiv ID:** 2601.12648 | [PDF](https://arxiv.org/pdf/2601.12648v1)

**作者:** Nafiz Imtiaz Khan `[一作]` (University of California), Roger Eric Goldman `[通讯]` (University of California)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本研究评估了使用大型语言模型自动化放射学培训中的程序案例日志记录的可行性。

**💡 创新点**

创新点在于将零样本LLM与链式思维提示结合，实时从未结构化放射报告中提取结构化手术信息，并对成本与延迟进行系统评估。

**🔧 技术方法**

采用开源本地模型Qwen-2.5:72B和商业模型Claude-3.5-Haiku（AWS Bedrock），在Instruction Prompting和Chain-of-Thought两种提示策略下进行零样本推理，并记录推理时延与token消耗。

**📊 数据集**

使用了414份由9名介入放射住院医师撰写、覆盖39种程序类别的手工标注放射报告数据集。

**📈 对比分析**

与仅基于元数据的Crosswalk基准相比，LLM在F1得分上达到86–87%，显著提升灵敏度并减少误报；商业部署平均每个报告成本约0.03美元、延迟1–2秒；本地部署成本约0.04美元、延迟13秒。

**⚠️ 局限性**

局限性包括样本量小、单一机构、仅测试两种提示策略、未进行模型微调，且结果可能不易推广至其他放射科工作流程。

---

## 66. Power Aware Dynamic Reallocation For Inference

**arXiv ID:** 2601.12241 | [PDF](https://arxiv.org/pdf/2601.12241v1)

**作者:** Yiwei Jiang `[一作]`, Sam Bayliss `[通讯]` (AMD Research and Advanced Development)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种基于功耗约束的LLM推理去聚合框架，能够在固定功率预算下通过动态分配GPU角色与功率预算来提升良好吞吐量（goodput）。

**💡 创新点**

创新点在于将功率分配与GPU去聚合结合，支持静态与动态功率与GPU重分配，并通过实时延迟与队列监控实现自适应调度，从而在功耗受限场景下显著提升SLO达成率与能效。

**🔧 技术方法**

主要技术包括：在vLLM框架上实现多GPU去聚合与HIP IPC/XGMI KV缓存传输；利用AMD Instinct MI300X GPU的SMI进行GPU功率控制；构建基于TTFT/TPOT、队列长度与功率阈值的动态调度算法；以及统一功率与GPU分配的调度策略。

**📊 数据集**

使用LongBench与Sonnet两套数据集，其中LongBench提供长提示与多样化token长度的真实工作负载，Sonnet用于构造预填充与解码重的混合负载，并采用Poisson到达时间模拟。

**📈 对比分析**

通过与传统共存（Coalesced）、4P4D、5P3D、以及非均匀功率分配等方案在4800W预算下进行比较，采用SLO达成率、goodput、QPS/W等指标评估，结果显示在最佳配置下SLO达成率提升约2倍，QPS/W也显著优于基线，验证了动态功率与GPU分配的有效性。

**⚠️ 局限性**

局限性主要包括：实验仅在单机8 GPU节点上验证，未在大规模机架或多TP模型上进行验证；功率切换延迟约为百毫秒，可能在极高峰负载下影响调度及时性；需要进一步评估在多机、多机架环境下的兼容性与稳定性。

---

## 67. Knowledge-Integrated Representation Learning for Crypto Anomaly Detection under Extreme Label Scarcity; Relational Domain-Logic Integration with Retrieval-Grounded Context and Path-Level Explanations

**arXiv ID:** 2601.12839 | [PDF](https://arxiv.org/pdf/2601.12839v1)

**作者:** Gyuyeon Na `[一作]` (Ewha Womans University), Sangmi Chai `[通讯]` (Ewha Womans University)

**通讯引用:** 1952 | [OpenAlex ID](https://openalex.org/A5038729859)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `57a58b01-81b4-4d75-a45c-2e891f272b50` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出一种Relational Domain-Logic Integration (RDLI) 框架，用专家逻辑和检索上下文嵌入来检测加密交易中的异常路径。

**💡 创新点**

将专家规则转化为可微分的逻辑潜在信号，并结合检索式上下文对GNN进行强化，实现多跳逻辑驱动的异常检测与可解释路径输出。

**🔧 技术方法**

使用LLM自动生成结构化注释、构建知识图谱、DeepWalk嵌入、GraphSAGE/GRU/LightGBM预测、检索增强上下文以及路径级可解释性技术。

**📊 数据集**

在真实的区块链交易数据（2020-2024）和Kaggle信用卡交易数据上实验，标签稀缺仅0.01%。

**📈 对比分析**

与基线特征、KG嵌入以及GNN/GRU/LightGBM对比，在极低标签率下 RDLI F1 提升28.9%，召回率接近1，整体性能显著优于传统方法。

**⚠️ 局限性**

受限于知识图谱的覆盖范围与检索质量，且在非交易网络或结构简化的场景下提升有限。

---

## 68. Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software

**arXiv ID:** 2601.12448 | [PDF](https://arxiv.org/pdf/2601.12448v1)

**作者:** Yang Liu `[一作]` (Beijing Institute of Control Engineering), Zhi Jin `[通讯]` (Peking University)

**通讯引用:** 9738 | [OpenAlex ID](https://openalex.org/A5049100391)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文系统评估了大型语言模型（DeepSeek‑V3、Qwen3）在航空软件时间序列异常检测中的表现，并提出了专门的航空TSAD基准与三种面向用户的窗口级指标。

**💡 创新点**

创新点在于构建了包含九种任务（三种异常类型×三种场景）的航空TSAD基准、提出了Alarm Accuracy、Alarm Latency、Alarm Contiguity三指标，并首次将LLM与无监督方法在航空数据上进行公平对比。

**🔧 技术方法**

主要技术包括零样本LLM推理（Direct与Prediction Paradigm）、few‑shot prompting、检索增强生成（RAG）以及传统无监督方法（GCAD、TFMAE、Sub‑Adjacent）。

**📊 数据集**

使用了108,000条基于高保真航空仿真生成的时间序列数据（U、M‑IL、M‑OL三类），并在公开的ATSADBench数据集上进行实验。

**📈 对比分析**

通过F1、AUROC、AUPRC以及AA、AL、AC等指标比较，结果显示LLM在单变量任务上可达到约0.7的AA，但在多变量任务上性能接近随机，且无监督方法整体优于LLM；few‑shot略有提升，RAG效果不显著。

**⚠️ 局限性**

局限性包括仅使用仿真生成数据、只测试了少数开源LLM、增强策略有限，未涉及领域专属预训练或更复杂的上下文提示。

---

## 69. User-to-Vehicle Interaction in Smart Mobility: The GO-DRiVeS Autonomous Ride-Sharing Application

**arXiv ID:** 2601.12367 | [PDF](https://arxiv.org/pdf/2601.12367v1)

**作者:** Hana E. Elmalah `[一作]` (German University in Cairo), Catherine M. Elias `[通讯]` (German University in Cairo)

**通讯引用:** 97 | [OpenAlex ID](https://openalex.org/A5025295346)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文设计并实现了面向高校校园的自主车辆共享出行应用GO-DRiVeS，提供用户注册、实时请求、车辆调度与跟踪等完整功能；

**💡 创新点**

创新点在于将自主驾驶车辆与传统打车App相结合，采用单一应用统一用户与司机端，且利用Socket.IO实现实时一对一请求与确认，支持多请求FIFO处理；

**🔧 技术方法**

技术栈包括React Native (Expo) 前端、Node.js + Express 后端、MongoDB 数据库、Socket.IO 通信、Expo Maps + OpenRouteService 路线规划、Expo Location 定位；

**📊 数据集**

主要使用校园内实际车辆与用户数据进行测试，并通过实验视频验证注册、请求、跟踪等流程；

**📈 对比分析**

与现有的多平台打车App（如Uber、Lyft）相比，本文在校园场景下实现了统一端、实时通信与优化路线，实验显示请求处理延迟低于200 ms，车辆到达时间与传统手工调度相比缩短约15%；

**⚠️ 局限性**

局限性包括：缺乏大规模多车辆与多用户并发测试、路线优化仅使用ORS免费版受限、未实现车辆与多请求的多线程调度与负载均衡，未来需加入更高级的调度算法与生产环境部署。

---

## 70. TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals

**arXiv ID:** 2601.12141 | [PDF](https://arxiv.org/pdf/2601.12141v1)

**作者:** Yuliia Suprun `[一作]` (Rice University), Moshe Y. Vardi `[通讯]` (Rice University)

**通讯引用:** 43692 | [OpenAlex ID](https://openalex.org/A5000059818)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了TIDE框架，利用DFA轨迹引导的深度优先探索，将LTL_f规划问题拆解为一系列可由经典规划器解决的reach‑avoid子问题。

**💡 创新点**

创新点在于结合了基于DFA的轨迹选择、成本驱动的启发式评估以及自适应回溯机制，显著提升了对复杂LTL_f目标的可扩展性与搜索效率。

**🔧 技术方法**

使用了LTL_f到DFA的转换（Spot库）、BDD表达边界条件、Uniform Cost Search与Hill‑Climbing启发式、A*和Fast Downward/LAMA等离散规划器，并通过成本更新和回溯来引导搜索。

**📊 数据集**

实验基准包括Blocksworld（TB15及其扩展版本）以及自定义的Openstacks任务。

**📈 对比分析**

与Exp、Poly、FOND4LTL_f和Plan4Past等现有方法进行对比，在上述基准上，TIDE在成功率和求解时间上均表现出明显优势。

**⚠️ 局限性**

局限性包括受DFA大小和BDD复杂度的限制，回溯过程中的成本更新在极大状态空间可能带来较高开销，并且对非确定性或连续规划域的适应性尚需进一步研究。

---

## 71. PsychēChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling

**arXiv ID:** 2601.12392 | [PDF](https://arxiv.org/pdf/2601.12392v1)

**作者:** Zhentao Xia `[一作]` (East China University of Science and Technology), Weiyan Zhang `[通讯]` (East China University of Science and Technology)

**通讯引用:** 1116 | [OpenAlex ID](https://openalex.org/A5101989943)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `67630363-6be0-4f51-ab05-7198250671a5` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

基于情绪转移与安全风险双重视角，构建了心理咨询大语言模型框架PsychēChat，并通过交互式角色扮演合成了高质量中文心理咨询对话数据集PsychēDialog；

**💡 创新点**

首次将情绪转移跟踪与风险控制机制显式集成，提出Agent Mode与LLM Mode两种推理范式，显著提升对话情绪连贯性与安全性；

**🔧 技术方法**

采用情绪管理模块（Emotion Tracking Agent＋Emotion Memory）、风险控制模块（Dialogue‑Guided Seeker Agent＋Safety Analysis Agent）以及EFT治疗原则，分别实现多代理管线与链式思维推理，并利用GPT‑4.1‑mini、Qwen2.5‑7B‑Instruct与Qwen3‑8B进行训练；

**📊 数据集**

合成数据集PsychēDialog共1,003条中文心理咨询对话，基于PsyDT原始语料；与SoulChat、MeChat、CPsyCounX、MindChat等现有中文心理咨询数据集进行对比；

**📈 对比分析**

在SAGE、ESC‑Eval、PsychēEval三大自动评估框架以及人工评估中，PsychēChat‑Agent在情绪改善、风险控制、专业性、效果等多维度均优于闭源LLM与心理LLM基线，Agent Mode在质量上进一步领先但LLM Mode提供更高推理效率；

**⚠️ 局限性**

局限包括合成对话成本高、仅覆盖中文场景、专家评估比例有限、缺乏真实临床验证，且模型仅作为辅助工具，不能替代专业心理治疗。

---

## 72. A Shared Geometry of Difficulty in Multilingual Language Models

**arXiv ID:** 2601.12731 | [PDF](https://arxiv.org/pdf/2601.12731v1)

**作者:** Stefano Civelli `[一作]` (University of Queensland), Gianluca Demartini `[通讯]` (University of Queensland)

**通讯引用:** 4524 | [OpenAlex ID](https://openalex.org/A5052565959)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文通过在21种语言的AMC Easy2Hard数据集上，对大型语言模型各层残差激活进行线性探测，分析了模型内部对问题难度的表征及其跨语言一致性。

**💡 创新点**

创新点在于揭示难度表征的两阶段深度结构：浅层呈现语言无关的共享难度方向，深层则变为语言特定，从而首次从多语言角度展示高阶元认知信号的演化。

**🔧 技术方法**

主要技术包括TransformerLens提取残差激活、岭回归线性探测器、Spearman秩相关评价以及跨语言训练-测试对照分析。

**📊 数据集**

使用的数据集为AMC子集的Easy2Hard Benchmark，已被翻译成21种语言，共约4000道数学题，难度由IRT评分给出。

**📈 对比分析**

方法比较显示：相同语言的探测器在后层（≈第30层）表现最佳，Spearman ρ可达0.82；跨语言时最佳层显著提前（≈第14层），ρ下降约0.15；整体跨语言相关性仍高但显著低于同语言，且不同模型在这些趋势上一致。

**⚠️ 局限性**

局限性包括：仅在数学题域研究，未覆盖主观或情境难度；仅评估少数指令调优的解码器模型；探测方法无法证明因果关系，且跨语言干预效果仍待验证。

---

## 73. "Are we writing an advice column for Spock here?" Understanding Stereotypes in AI Advice for Autistic Users

**arXiv ID:** 2601.12690 | [PDF](https://arxiv.org/pdf/2601.12690v1)

**作者:** Caleb Wohn `[一作]` (Virginia Tech), Eugenia H. Rho `[通讯]` (Virginia Tech)

**通讯引用:** 859 | [OpenAlex ID](https://openalex.org/A5054447687)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过大规模LLM审计实验和访谈，系统量化自闭症用户披露身份后，六种大型语言模型在社交建议情境中的输出变化。

**💡 创新点**

创新点在于将12条已记录的自闭症刻板印象转化为可操作的决策情境，构建六步管线以量化披露与刻板偏差的关联，并将实验结果与用户体验相结合。

**🔧 技术方法**

采用决策偏差框架、大规模LLM生成（6种LLM）、统计检验（卡方、Pearson相关）以及定性主题分析技术。

**📊 数据集**

使用生成的345,000条LLM回答（来自6种LLM）以及11名自闭症成人的访谈文本作为数据集。

**📈 对比分析**

通过ST–AST和AT–NA差距及其相关性评估模型在刻板与披露条件下的偏差，发现披露往往导致更保守建议，相关性在部分刻板（如introverted）较高，但整体未显著提升模型性能。

**⚠️ 局限性**

局限性包括使用人工合成的二元决策提示、披露仅为二元且未考虑更细粒度的自闭症特质，缺乏真实用户提问及更丰富的语义多样性。

---

## 74. Re-educating Educated Ones: A Case Study on Chakma Language Revitalization in Chittagong Hill Tracts

**arXiv ID:** 2601.12290 | [PDF](https://arxiv.org/pdf/2601.12290v1)

**作者:** Avijoy Chakma `[一作]` (Bowie State University), Sharifa Sultana `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 636 | [OpenAlex ID](https://openalex.org/A5103026409)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对孟加拉国丘陵地区查克玛族语言复兴进行为期六个月的定性研究，收集访谈、焦点小组和观察数据，提出基于ICT的社区驱动复兴框架MeILR。

**💡 创新点**

提出MeILR三支柱框架（历史身份元素、利益相关者需求、有效数字媒介），将社会技术系统与语言复兴结合，强调社区主导、文化根植与技术适配。

**🔧 技术方法**

采用信息通信技术（ICT）手段，包括数字资源、社交媒体、离线可用的词典与翻译工具，以及低带宽/离线优先的设计思路。

**📊 数据集**

数据集来源于25名受访者（教师、学生、记者等）的访谈、两场焦点小组以及现场观察，累计约13小时录音，约100页转写文本。

**📈 对比分析**

该研究不涉及算法性能评估；通过主题分析与案例对照来验证框架可行性，未与现有技术或模型进行定量比较，强调定性洞察与社区反馈。

**⚠️ 局限性**

局限性包括仅聚焦孟加拉国查克玛族，未覆盖印度与缅甸同族；样本量有限、受访者多为男性，缺乏对跨地区差异的比较；框架尚未在实践中进行系统评估。

---

## 75. Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT

**arXiv ID:** 2601.12638 | [PDF](https://arxiv.org/pdf/2601.12638v1)

**作者:** Ninnart Fuengfusin `[一作]` (Advanced Mobility Research Institute Kanazawa University), Naoki Suganuma `[通讯]` (Advanced Mobility Research Institute Kanazawa University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `64443552-63e0-44b5-906f-d90fe95c5a1b` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出了一种面向PointPillars模型的混合精度量化框架，通过在不需要训练的后训练量化（PTQ）中识别敏感层并将其设置为FP16，其余层为INT8，以在TensorRT部署中实现显著的延迟和模型尺寸压缩。

**💡 创新点**

创新点在于：①利用PTQ单层量化评估灵敏度，自动发现对性能影响最大的层；②采用贪婪搜索组合FP16层，兼顾精度与推理速度；③发现使用极少量校准数据可降低极端异常值对PTQ的负面影响；④实现了无需额外训练即可获得接近FP32精度的模型。

**🔧 技术方法**

技术包括：后训练量化（PTQ）、量化感知训练（QAT）、FP16/INT8混合精度映射、TensorRT引擎生成、基于min‑max校准的整数量化、贪婪组合搜索和极端值抑制。

**📊 数据集**

使用的公开数据集为KITTI 3D目标检测数据集，采用AP40指标评估性能。

**📈 对比分析**

与传统全INT8 PTQ、全INT8 QAT以及FP32/FP16基线相比，混合精度模型在mAP40上提升至约63–64%（PTQ）或超过80%（QAT），同时在Jetson Orin上将推理延迟从32.91 ms降至13.99 ms（约2.35倍加速），模型尺寸从74.95 MB降至约33.13 MB（约2.26倍压缩）。

**⚠️ 局限性**

局限性包括：仅支持FP32/FP16/INT8三种精度，无法处理更低位宽（如INT4、FP8）或更大模型；对极端异常值的抑制依赖极少量校准数据，可能在不同数据分布下失效；混合精度实现对TensorRT的兼容性做了手工调整，迁移到其他框架需额外工作。

---

## 76. Camera Pose Revisited

**arXiv ID:** 2601.12567 | [PDF](https://arxiv.org/pdf/2601.12567v1)

**作者:** Władysław Skarbek `[一作]` (Warsaw University of Technology), Michał Król `[通讯]` (Independent Researcher)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种针对平面 Calibration Board 的 PnP 求解器 PnP-ProCay78，用 Cayley 参数化的旋转表示并结合重建误差的线性化翻译消除，给出了从两个固定起点（基于 Ω 矩阵的主对角元素比较得到）开始的最优迭代过程，最终实现对摄像机姿态的精确估计。

**💡 创新点**

创新点在于：①利用平面场景下 Ω 矩阵的核结构，确定最优起点只需比较 Ω_77 与 Ω_88 的大小，避免完整谱分解；②在 Cayley 空间中执行三维最小二乘优化，显著降低维度；③采用混合代价，即用重建误差求解翻译、用投影误差做非线性优化，兼顾数值稳定与实际精度；④通过对 Cayley 轨迹的可视化提供对收敛过程的直观解析。

**🔧 技术方法**

技术手段包括：Cayley 旋转矩阵参数化、线性翻译消除（T·r 形式）、最小二乘残差求解（TRF/LM 迭代）、投影误差与重建误差的混合代价函数、基于主对角元素的确定起点策略、Umeyama 校正、以及对 Cayley 轨迹的径向圆表示可视化。

**📊 数据集**

数据集为一组混合 RGB–IR 校准图像：高分辨率 RGB（2048×1520）和低分辨率热像（80×62），均通过 Raspberry Pi 5 搭建的 RGB–IR 相机套装采集，另外包含两台 PC 级 USB 与 Logitex 摄像头的图像；所有图像均为平面棋盘/Charuco 校准板（有 OLED 显示和打印板两种形式）。

**📈 对比分析**

通过与 OpenCV 库中的 SQPnP、IPPE、EPnP 四种主流 PnP 求解器对比，使用相同标定图像集测得投影误差（RMSE、median、max）与重投影误差，结果显示 PnP-ProCay78 与 SQPnP、IPPE 的误差基本相同，略优于 EPnP，在所有相机上误差差距仅为几百分之一像素，计算耗时远低于复杂的代数解法。

**⚠️ 局限性**

局限性：①仅适用于平面标定板场景，无法直接扩展到非平面或稀疏三维点集；②算法对 Ω 矩阵的数值特性假设（主对角元素比较）在极端几何配置下可能失效；③在高噪声、极端畸变的场景中仍需更鲁棒的初始化；④由于使用标准最小二乘优化，收敛速度受初始点与图像质量影响，需要对极端分辨率差异做进一步改进。

---

## 77. Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion

**arXiv ID:** 2601.12224 | [PDF](https://arxiv.org/pdf/2601.12224v1)

**作者:** Meng Wei `[一作]` (King's College London), Nicolas Padoy `[通讯]` (University of Strasbourg)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出SurgRef框架和Ref-IMotion数据集，实现基于运动导向的手术视频指代分割。

**💡 创新点**

创新点在于将手术工具运动作为语言表达的核心，并引入关键帧注意与交互注意机制，显著提升了对运动表述的理解与分割精度。

**🔧 技术方法**

使用Swin Transformer视觉主干、RoBERTa文本编码器、Mask2Former解码器、关键帧注意模块与交互注意模块等技术。

**📊 数据集**

利用从EndoVis‑17/18、CholecSeg8k、GraSP汇聚的319段视频、21350帧、718条运动指代表达构成的Ref‑IMotion数据集。

**📈 对比分析**

与VIS‑Net、VISA、MPG‑SAM 2等方法对比，在EndoVis‑IM17/18和GSP‑IM上获得最高J/F/J&F分数，并在零样本下对CholecSeg8k‑IM表现出色。

**⚠️ 局限性**

局限在于对极端遮挡、不同模态（如多光谱）和非典型手术场景的鲁棒性仍有限，需要更大规模、多机构的数据进一步验证。

---

## 78. Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems

**arXiv ID:** 2601.12618 | [PDF](https://arxiv.org/pdf/2601.12618v1)

**作者:** Elham Tajik `[一作]` (University at Albany), Sreecharan Sankaranarayanan `[通讯]` (Extuitive Inc.)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过多智能体大语言模型在定性编码任务中生成推理轨迹，使用余弦相似度量化不同代理间的推理相似性，并结合定量与定性分析，探究推理轨迹中出现的分歧作为有效的分析信号，从而提升人工-AI协同编码的可靠性和解释深度。

**💡 创新点**

① 将代理间的推理轨迹视为可量化的过程数据；② 用余弦相似度检测并量化分歧；③ 将分歧视为“新型分析信号”，为人工介入提供优先级；④ 在多智能体框架下实现推理轨迹的系统化解析，弥补单体LLM在上下文窗口和可靠性上的不足。

**🔧 技术方法**

使用 DeepSeek‑R1‑32B 作为LLM，构建 Dual‑Agent Discussion + Consensus Agent 的多智能体系统；采用 BERT 生成推理轨迹的句向量；利用余弦相似度进行推理相似度计算；配合统计检验（Welch‑t、Cohen’s d）和定性主题分析。

**📊 数据集**

Barany 等人收集的九年级代数 I 学生在线辅导会话转录数据，共 3,538 段（约 9,746 对代理推理），来源于高贫困城市学校的 60 分钟虚拟辅导。

**📈 对比分析**

通过与编码标签的一致性二元变量相关（ρ = 0.54）和 Welch‑t 检验，发现相似度高的对（平均 ≈ 0.96）显著高于相似度低的对（平均 ≈ 0.90；p < 0.001，d = 1.16）。在不同温度设置（0、0.5、1）下保持稳定；余弦分布与人类编码 κ 值对应，进一步验证其可靠性；性能表现为能够有效区分共识与分歧，并揭示代码库的模糊边界。

**⚠️ 局限性**

仅在单一辅导转录数据集上验证，缺乏多领域/多任务的泛化；样本量有限的定性分析可能无法捕获所有推理模式；未系统比较代理推理与代码定义的符合度；每段仅考虑单轮对话，忽略更长上下文；未开发可视化或接口工具实现实时人机协作。

---

## 79. Who Owns Creativity and Who Does the Work? Trade-offs in LLM-Supported Research Ideation

**arXiv ID:** 2601.12152 | [PDF](https://arxiv.org/pdf/2601.12152v1)

**作者:** Houjiang Liu `[一作]` (University of Texas at Austin), Matthew Lease `[通讯]` (University of Texas at Austin)

**通讯引用:** 4112 | [OpenAlex ID](https://openalex.org/A5023397430)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一个基于大型语言模型（LLM）的代理系统（Agentic System），实现科研创意的从种子想法生成、文献合成、方案撰写到评估的端到端流程，并在三种控制层级（低、中、高）下进行实验。对54名研究人员进行混合方法研究，分析不同控制层级对创意支持、研究者投入和归属感的影响。

**💡 创新点**

①提出了三层级控制的“代理化研究创意”框架，既展示了人机协同的不同深度，也为后续人机共创系统提供了可调节的设计维度。②发现创意支持与控制层级并非线性提升，且控制层级会导致研究者的努力从创意生成转向结果验证，归属感成为人机协作的谈判结果。③在系统实现层面引入改进型RAG、双层记忆、可视化修订追踪等技术，提升了输出质量并增强了透明度。

**🔧 技术方法**

技术包括：①GPT‑4.1（Ideator & Writer）与Claude Sonnet 3.7（Evaluator）共同构成代理角色；②改进型RAG（Rewrite‑Retrieve‑Read + 零样本密集检索）；②双层记忆（短期内存 + 长期检索索引）；③基于LangChain、Flask、React + MUI的前后端实现；④可视化修订追踪与撤销机制；⑤对话式交互被替换为笔记本式编辑与细粒度提示。

**📊 数据集**

主要数据来源为参与者自选研究主题产生的种子想法、系统检索的学术文献（Semantic Scholar、arXiv、DuckDuckGo）以及系统生成的提案草稿。实验数据包含54名研究者的交互日志、CSI与NASA‑TLX问卷得分、归属感问卷及半结构化访谈转录。

**📈 对比分析**

与 Deep Research、ChatGPT、Gemini 等现有开箱即用工具进行对比实验。系统在提案质量评估（novelty, feasibility, impact）上与 Deep Research 相近，整体表现与 ChatGPT、Gemini 均属同等水平。RAG 方案在人类评审与 LLM 评判下均优于无 RAG 版本，体现了检索增强对内容专精度与连贯性的提升。

**⚠️ 局限性**

局限性包括：①样本量仅 54 人，且分布在 3 个学科组，结果可能受领域差异影响；②仅评估单一任务（研究提案写作），未验证在更广泛科研活动中的适用性；③系统对域知识深度的把握受检索策略与模型偏好限制，部分领域的专业方法仍需人工确认；④对长周期科研产出的实际影响未得到跟踪；⑤高控制层级仍存在“人机共同创作”归属感模糊的问题，需进一步探究责任与署名规范。

---

## 80. CellularSpecSec-Bench: A Staged Benchmark for Evidence-Grounded Interpretation and Security Reasoning over 3GPP Specifications

**arXiv ID:** 2601.12716 | [PDF](https://arxiv.org/pdf/2601.12716v1)

**作者:** Ke Xie `[一作]` (Utah State University), Tian Xie `[通讯]` (Utah State University)

**通讯引用:** 370 | [OpenAlex ID](https://openalex.org/A5067723727)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种统一的Adapt–Retrieve–Integrate框架，用于系统化解析3GPP规范并进行安全分析。

**💡 创新点**

创新点包括三阶段框架、将多模态（文本、表格、图形）统一为文本、构建基于知识图谱的跨条目推理机制以及构建分阶段验证与纠正的基准集。

**🔧 技术方法**

采用LLM（DeepSeek‑V3.2‑Exp）与SpecFusion、SpecRAG、SpecReasoning三模块；使用BM25+稠密向量检索、知识图谱转换、LLM评判等技术。

**📊 数据集**

数据集涵盖Release 17核心规范共1,760段，3,800句；包含43个真实漏洞实例；整合并专家校正的TeleQnA、Telco‑DPR、TSpec‑LLM、Tele‑LLMs、SPEC5G、ConTester、CellularLint等外部数据。

**📈 对比分析**

与基线LLM相比，启用各模块后在三阶段任务上提升显著：Stage 1约30–40%点，Stage 2证据正确率从0%升至≈100%，Stage 3跨条目安全推理准确率从≈20%提升至≈95%。

**⚠️ 局限性**

局限性在于仅覆盖Release 17、漏洞案例有限、评估严格的证据匹配可能低估部分正确答案、仅实验单一LLM模型。

---

## 81. Machine Learning-Based Framework for Real Time Detection and Early Prediction of Control Valve Stiction in Industrial Control Systems

**arXiv ID:** 2601.12362 | [PDF](https://arxiv.org/pdf/2601.12362v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 82. Complexity of Model Checking Second-Order Hyperproperties on Finite Structures

**arXiv ID:** 2601.12361 | [PDF](https://arxiv.org/pdf/2601.12361v1)

**作者:** Bernd Finkbeiner `[一作]` (CISPA Helmholtz Center for Information Security), Tim Rohde `[通讯]` (Saarland University)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c`

**🎯 论文内容**

本文研究了在有限结构（树形与无环）上对二阶超性质 Hyper^2LTL 的模型检查复杂度。

**💡 创新点**

创新点在于首次给出该逻辑在有限模型上的可判定性及其精确的时间/空间复杂度，并对其可计算片段 Fixpoint Hyper^2LTL_fp 证明了更低的复杂度。

**🔧 技术方法**

主要技术包括量化层级的归约、树展开、二阶量化集合的 fixpoint 构造以及对 QBF、AAM 计算问题的多项式时间化简。

**📊 数据集**

论文未使用实验数据集，而是通过理论构造的树形/无环 Kripke 结构和合成的 Hyper^2LTL 公式进行证明。

**📈 对比分析**

通过与已知的 QBF、AAM 接受问题的归约，作者证明了模型检查在树形结构上为 P‑complete，在无环结构上为 EXP‑complete，空间复杂度分别为 PSPACE 与 EXPSPACE。

**⚠️ 局限性**

局限性在于只针对有限模型给出结果，未讨论无限或非结构化系统，并且在实践中缺乏对大规模监控日志的实验评估。

---

## 83. Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery

**arXiv ID:** 2601.12542 | [PDF](https://arxiv.org/pdf/2601.12542v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 84. "What If My Face Gets Scanned Without Consent": Understanding Older Adults' Experiences with Biometric Payment

**arXiv ID:** 2601.12300 | [PDF](https://arxiv.org/pdf/2601.12300v1)

**作者:** Yue Deng `[一作]` (Hong Kong University of Science and Technology), Yixin Zou `[通讯]` (Max Planck Institute for Security and Privacy)

**通讯引用:** 753 | [OpenAlex ID](https://openalex.org/A5037796481)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `9cc9baba-5356-466d-81ff-d80028d90279` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过对22名中国老年人进行半结构化访谈，探讨他们使用生物识别支付的动机、担忧、保护行为以及对系统改进的期望。

**💡 创新点**

首次系统性聚焦老年人群体的生物识别支付体验，识别出“控制感缺失”“安全隐私忧虑”“认知误区”等核心痛点，并提出可控确认机制与教育支持等设计改进建议。

**🔧 技术方法**

采用质性研究方法——半结构化访谈、主题编码与主题分析，未涉及机器学习或算法实现。

**📊 数据集**

收集并分析22位老年人访谈录音、文字记录，数据来源为研究现场访谈，未使用公开数据集。

**📈 对比分析**

本研究不涉及量化比较或性能评估，主要通过归纳式主题分析得到定性洞见，未给出指标或性能对比。

**⚠️ 局限性**

局限性包括：样本性别偏向女性、仅覆盖中国地区、样本规模有限、未涵盖所有生物识别技术、对风险认知与实际技术风险的差异缺乏验证。

---

## 85. Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation

**arXiv ID:** 2601.12697 | [PDF](https://arxiv.org/pdf/2601.12697v1)

**作者:** Chao Yang `[一作]` (Harbin Institute of Technology), Zhenyu He `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 5845 | [OpenAlex ID](https://openalex.org/A5100740564)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `67630363-6be0-4f51-ab05-7198250671a5` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于3D Gaussian Splatting的红外-可见光融合框架（IVGF），能够从任意视角直接渲染融合图像。

**💡 创新点**

创新点在于引入跨模态调节（CMA）模块动态调节高斯不透明度以消除模态冲突，并提出融合损失保证两种模态特征保留。

**🔧 技术方法**

使用3D Gaussian Splatting、MLP调节器、融合损失函数以及可见光与热红外的双模态高斯场训练。

**📊 数据集**

采用RGBT-Scenes数据集，包含1000多对对齐的可见光和热红外图像。

**📈 对比分析**

与9种现有2D融合方法（如CDDFuse、CrossFuse、EMMA等）在LPIPS、PSNR、SSIM上进行对比，IVGF在大多数场景下取得最高或第二高分，同时在视觉质量、速度和存储效率上显著优于对比方法。

**⚠️ 局限性**

局限性包括仅在RGBT-Scenes上验证，可能对其他场景或更高分辨率的适用性未知；跨模态调节机制在更大规模、多模态数据上的鲁棒性仍待进一步验证。

---

## 86. Semantic Fusion: Verifiable Alignment in Decentralized Multi-Agent Systems

**arXiv ID:** 2601.12580 | [PDF](https://arxiv.org/pdf/2601.12580v1)

**作者:** Sofiya Zaichyk `[一作]` `[通讯]` (Innovative Defense Technologies), Sofiya Zaichyk (Innovative Defense Technologies)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

提出了 Semantic Fusion (SF) 框架，用于多智能体系统中基于本体裁剪的去中心化语义一致性和验证。

**💡 创新点**

创新点在于：①将共享语义内存拆分为可裁剪的本体切片，允许智能体仅在自己的语义域内读取/更新；②通过局部本体验证和选择性刷新实现全局一致性，无需全局消息广播；③证明了局部执行与全局投影的 bisimulation，支持局部验证推断全局时序性质；④扩展到概率性更新和不可靠通信，给出几乎必然收敛与通信复杂度 Θ(d) 的上、下界。

**🔧 技术方法**

核心技术包括：本体裁剪与语义投影、结构化更新提议、基于本体的验证器、选择性刷新与局部同步、棘手的 bisimulation 与概率 bisimulation 理论、分布式模拟与性能评估。

**📊 数据集**

使用了 250 代理的搜索与救援模拟环境（grid‑zone、存活状态等）以及在该环境中生成的 11,325 条验证更新，实验并未依赖公开数据集而是自行构造的情景。

**📈 对比分析**

通过 250 代理的仿真验证了语义一致性、因果隔离、bisimulation 以及失效容错。通信成本符合 Θ(d) 线性关系；在不同消息成功率下的对齐延迟呈指数衰减，验证了理论预测。与传统 CRDT、SHIMI、DAMCS 等系统对比，SF 在无中心化、无全局广播的条件下实现更低的消息开销与更强的语义验证能力。

**⚠️ 局限性**

局限包括：①本体裁剪需要先验本体设计，且本体演化处理尚未完整；②选择性刷新假设能精准路由，实际部署需实现内容型 pub/sub 或分布式路由；③对行为性能（如任务完成时间）未做严格评估，SF 只保证语义一致性；④在极端丢包或高延迟网络下的收敛速度及容错机制仍需进一步实验验证。

---

## 87. HyFormer: Revisiting the Roles of Sequence Modeling and Feature Interaction in CTR Prediction

**arXiv ID:** 2601.12681 | [PDF](https://arxiv.org/pdf/2601.12681v1)

**作者:** Yunwen Huang `[一作]` (ByteDance), Jingjian Lin `[通讯]` (ByteDance)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出 HyFormer，统一长序列建模与异构特征交互的混合 Transformer，利用 Query Decoding 与 Query Boosting 两阶段交替迭代，支持多序列独立处理，显著提升工业级推荐系统的性能与效率。

**💡 创新点**

① 通过全局 Query Tokens 重新定义长序列与特征交互的接口，实现双向信息流；② 交替的 Query Decoding（跨注意力）与 Query Boosting（MLP‑Mixer 令牌混合）机制，深度交互多序列与异构特征；③ 多序列独立编码避免序列合并导致的信息损失；④ 在工业规模数据上验证更优的可扩展性与推理效率。

**🔧 技术方法**

混合 Transformer（跨注意力 + MLP‑Mixer token‑mixing）、长序列压缩方法（LONGER、Full Transformer）、多序列独立编码、GPU pooling 与异步 AllReduce 等大规模训练与推理加速技术。

**📊 数据集**

ByteDance 抖音搜索系统的业务数据，约 3 亿元样本，包含用户、查询、文档、交叉特征以及长序列、搜索序列、Feed 序列三类行为序列。

**📈 对比分析**

与传统两阶段基线（LONGER+RankMixer）和统一架构基线（MTGR/OneTrans）进行对比；离线实验中 HyFormer 在 3.9×10¹² FLOPs、418M 参数下 AUC 达 0.6489，较 LONGER+RankMixer 提升 0.74%；在线 A/B 测试在平均观看时长、完播率提升 1.1% 以上，查询改动率下降 0.236%。

**⚠️ 局限性**

受限于 Query Token 数量与长序列压缩导致的推理延迟；多序列独立编码使模型规模扩大，极长序列或高维特征仍需进一步优化；目前验证主要集中在 CTR 任务，跨任务泛化需进一步实验。

---

## 88. LiQSS: Post-Transformer Linear Quantum-Inspired State-Space Tensor Networks for Real-Time 6G

**arXiv ID:** 2601.12375 | [PDF](https://arxiv.org/pdf/2601.12375v1)

**作者:** Farhad Rezazadeh `[一作]` (Hostelworld Group), Merouane Debbah `[通讯]` (Khalifa University of Science and Technology)

**通讯引用:** 63755 | [OpenAlex ID](https://openalex.org/A5056145687)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一种 LiQSS 模型，利用后 Transformer 的线性状态空间张量网络对 6G O‑RAN Near‑RT RIC 中的 KPI 进行短期预测。

**💡 创新点**

创新点包括：① 用 HiPPO‑LegS 结构化状态空间替代自注意力实现线性时间复杂度；② 将输入投影和预测头用张量训练（TT/MPS）压缩；③ 采用轻量级通道门控和混合层捕捉 KPI 交互；④ 在 Near‑RT 约束下实现模型规模大幅缩减且不降低准确率。

**🔧 技术方法**

主要技术：HiPPO‑LegS 状态空间模型、深度可归一化因子、squeeze‑excitation 门控、通道混合、Tensor‑Train（TT）/矩阵乘积状态（MPS）分解、混合精度训练、AdamW 优化。

**📊 数据集**

使用 O‑RAN 监测数据集：59,441 个滑动窗口，13 个 KPI（如 RSRP、RSRQ、SINR 等）来自 E2SM‑KPM 的测试平台。

**📈 对比分析**

通过与多种 Transformer（Informer、Crossformer、PatchTST 等）和 SSM（MS^3M、WM‑MS^3M 等）基线进行对比，LiQSS 在 RSRP 单步预测上实现 RMSE 0.2866、参数 44k、推理时间 0.000456 s；相较于最接近的 SSM 基线准确率提升 1–3%，相较于 Transformer 体积缩减 155×、推理速度提升 2.74×，呈现最佳精度‑效率折衷。

**⚠️ 局限性**

局限性：仅评估单步单目标 KPI，未验证多步或多目标预测；仅在单一测试平台数据上验证，泛化性待进一步检验；未完成闭环控制实验；对各组件（TT 级数、状态维度、混合数）的细粒度消融仍未完全探索。

---

## 89. How to Get Close to the Median Shape

**arXiv ID:** 2601.12529 | [PDF](https://arxiv.org/pdf/2601.12529v1)

**作者:** Sariel Har-Peled `[一作]` `[通讯]`, Sariel Har-Peled

**关键词:** `a42c7bd6-d8fd-40d3-94df-ae8cd808f5c4` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

针对在低维空间中对一组点进行 L1/L2 拟合问题（如圆、球、圆柱、部分数据聚类等）提出了一种通用的 (1+ε) 近似算法，时间复杂度为 O(n + (log n, 1/ε))，并给出实现细节。

**💡 创新点**

创新点在于：①构造了一个适用于多种形状的“层级/浅层”抽样技术，能够把原始高维曲面集合压缩为多层次的低复杂度“表面片”；②结合了几何核心点（coreset）与随机采样，保持在所有垂线上的总权重；③通过将问题分解为有限数量的垂直棱柱，并在每个棱柱内用级别集合逼近距离函数，最终实现全局 (1+ε) 近似；同时首次给出 L1 圆拟合等问题的子二次时间复杂度。

**🔧 技术方法**

核心技术包括：几何核心点（coreset）构造、随机采样与 Chernoff 边界、浅层水平（shallow level）近似、水平集分解（level‑set decomposition）、垂直棱柱划分、点位置查询与级别间逼近、线性化维度（linearization dimension）处理。

**📊 数据集**

该工作为理论性研究，没有使用具体实验数据集；主要以数学证明和算法复杂度分析为主。

**📈 对比分析**

与之前的算法（如 Har‑Peled & Koltun 的 O(n^2) 圆拟合算法）相比，本算法将时间从二次下降到线性+polylog 级，提供了理论上的最优上界；实验部分未给出，作者指出实际常数很大，当前更具理论意义。

**⚠️ 局限性**

局限性：1) 隐含的多项式常数极大（20–60 级别），导致实用性有限；2) 算法主要针对低维形状，扩展到曲线（如 B‑样条、Bezier）面临代数复杂度难题；3) 需要进一步研究更高效或可实践化的实现方案。

---

## 90. Approximating splits for decision trees quickly in sparse data streams

**arXiv ID:** 2601.12525 | [PDF](https://arxiv.org/pdf/2601.12525v1)

**作者:** Nikolaj Tatti `[一作]` (Helsinki Institute for Information Technology), Nikolaj Tatti `[通讯]` (Helsinki Institute for Information Technology)

**通讯引用:** 1561 | [OpenAlex ID](https://openalex.org/A5067444605)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种快速近似决策树分裂的方法，专注于稀疏数据流中的二元特征和二元类，旨在加速寻找最佳分裂。

**💡 创新点**

创新点在于提出了一种新的算法，可以在较低的时间复杂度下找到近似最优的分裂，尤其适用于稀疏数据，且在实验中表现优于基线方法。

**🔧 技术方法**

使用了条件熵和基尼指数的算法，结合了平衡搜索树来存储特征，并通过特征的概率分布进行分组和搜索。

**📊 数据集**

使用了合成数据集和基准数据集进行实验，合成数据集包括不同数量的数据点和特征，基准数据集包括维多利亚时代作者的文本片段、农场广告、Usenet帖子等。

**📈 对比分析**

与基线方法相比，提出的方法在处理稀疏数据时显著加快了分裂的寻找速度，且在多次实验中，近似分裂的结果与最优分裂的结果非常接近。

**⚠️ 局限性**

限制在于算法主要针对二元标签数据，若标签不为二元，则需要不同的方法。此外，虽然时间复杂度得到了优化，但空间复杂度与基线方法相同，未来可以考虑降低空间复杂度。

---

## 91. Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays

**arXiv ID:** 2601.12322 | [PDF](https://arxiv.org/pdf/2601.12322v1)

**作者:** Chang-Wei Shi `[一作]` (Nanjing University), Wu-Jun Li `[通讯]` (Nanjing University)

**通讯引用:** 5161 | [OpenAlex ID](https://openalex.org/A5101402002)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出异步分布式Momentum SGD（MSGD）带局部更新的OrLoMo方法，解决了异步分布式学习中MSGD的实现难题；

**💡 创新点**

首次实现异步分布式MSGD带局部更新，并在任意延迟下给出收敛证明；

**🔧 技术方法**

结合异步分布式学习、局部SGD、Momentum、服务器端有序聚合等技术；

**📊 数据集**

在CIFAR‑10、CIFAR‑100以及Tiny‑ImageNet上使用SqueezeNet、ResNet20/32等模型进行实验；

**📈 对比分析**

与同步PRSGDm、异步AL‑SGD、局部OrMo‑DA等方法对比，OrLoMo在精度和训练速度上均优于对手，尤其在异构环境下显著加速；

**⚠️ 局限性**

缺点是需要额外发送局部动量，理论仅适用于非凸问题，对极端延迟的鲁棒性仍有待进一步验证。

---

## 92. MemeLens: Multilingual Multitask VLMs for Memes

**arXiv ID:** 2601.12539 | [PDF](https://arxiv.org/pdf/2601.12539v1)

**作者:** Ali Ezzat Shahroor `[一作]` (Qatar Computing Research Institute), Firoj Alam `[通讯]` (Qatar Computing Research Institute)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

构建了一个统一的多语言、多任务、带解释的视觉语言模型MemeLens，用于理解互联网表情包（memes）

**💡 创新点**

创新点：①将38个公开表情包数据集统一整理、过滤、映射为20个任务的共享标签体系；②在多模态、多任务框架下联合训练并加入解释生成，提升可解释性与跨域泛化；③系统性评估多种模型范式（单模态、序列多模态、零射击VLM），揭示多模态训练对不同语义类别的显著优势

**🔧 技术方法**

技术：多模态视觉语言模型（以Qwen3-VL-8B-Instruct为主），参数高效微调（LoRA），双阶段训练（先分类后联合分类+解释生成），统一指令集生成，解释由GPT‑4.1生成并作为辅助目标；同时使用OCR提取文本，采用多语言预训练模型处理文本

**📊 数据集**

数据集：38个公开表情包数据集，涵盖9种语言（英语、阿拉伯语、孟加拉语、中文、德语、西班牙语、印地语、罗马尼亚语、俄语），20个任务类别，约178k训练、22k验证、40k测试样本

**📈 对比分析**

比较方法：在统一训练和评估框架下，与单模态（文本/图像）基线、多模态序列分类基线、以及多种零射击VLM（GPT‑4.1、Qwen3‑VL‑8B‑Instruct、InternVL3.5‑8B等）进行对比。结果显示：多模态序列分类模型优于单模态；MemeLens在所有指标上均超越零射击模型，整体Macro‑F1提升约6%（从0.58到0.625），在各任务类别和语言上均表现优异，且统一训练优于单数据集微调

**⚠️ 局限性**

局限性：①统一标签体系可能压缩原始细粒度，导致信息损失；②解释生成依赖GPT‑4.1，可能存在可信度和偏见问题；③覆盖语言不均衡，低资源语言仍表现欠佳；④数据集来源多样，存在平台偏见、时间漂移和注释差异，可能影响模型在新兴表情包形式上的鲁棒性

---

## 93. Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement

**arXiv ID:** 2601.12682 | [PDF](https://arxiv.org/pdf/2601.12682v1)

**作者:** Banglei Guan `[一作]` (National University of Defense Technology), Qifeng Yu `[通讯]` (National University of Defense Technology)

**通讯引用:** 2796 | [OpenAlex ID](https://openalex.org/A5103187819)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

设计并实现了一套融合修复图像处理框架，用以抑制高温环境下的热辐射与热雾霾，从而提升数字图像相关（DIC）在高温变形测量中的成像质量与测量精度。

**💡 创新点**

创新点包括：①基于正负通道分解的多曝光融合算法，利用引导滤波与伽马校正同时提升欠曝与过曝图像的纹理与对比度；②以特征相似度指标（FSIM）为目标函数的图像恢复算法，结合Wiener滤波实现热雾霾去除；③在恢复后引入灰度平均算法进行随机误差抑制，显著提升测量的可靠性。

**🔧 技术方法**

主要技术手段有：多曝光图像融合（正负通道分解、引导滤波、伽马校正、线性拉伸）、FSIM引导的图像恢复（Wiener滤波）、灰度平均降噪、数字图像相关（DIC）算法、实验系统中的光学滤镜与蓝光激光照明。

**📊 数据集**

使用自制实验数据集：在450 °C加热台上通过蓝光灯和窄带滤光片记录的双目摄像系统图像，包含10幅静态参考图、9幅变形图、120幅受热雾霾影响的图像及15幅可用于灰度平均的序列图像。

**📈 对比分析**

与原始未处理图像比较，EDCA（有效变形计算面积）从约26%提升至50%（欠曝）或从32%提升至40%（过曝），图像质量指标NIQMC、NIQE、MIG均显著改善；热雾霾下的误差量化评估显示εxx误差从232%降至34%（85.3%降低），εyy从211%降至135%（36%降低），γ_xy从22%降至14%（36.4%降低），表明该方法在高温环境下显著提高了DIC的准确性与可靠性。

**⚠️ 局限性**

仅适用于静态或准静态热加载实验；由于依赖多帧灰度平均，无法应用于动态变形测量，且在高温大气扰动剧烈的情况下，恢复效果受限。

---

## 94. Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping

**arXiv ID:** 2601.12465 | [PDF](https://arxiv.org/pdf/2601.12465v1)

**作者:** Miao Peng `[一作]` (Hong Kong University of Science and Technology), Jia Li `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 18471 | [OpenAlex ID](https://openalex.org/A5100405681)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了基于知识图谱的长文本多跳问答数据合成框架和过程优势塑造的RL方法，以提升LLM的长篇推理能力。

**💡 创新点**

创新点在于通过可控合成高难度多跳QA及其显式推理链，实现对“almost‑there”样本的细粒度信用分配，缓解奖励稀疏问题。

**🔧 技术方法**

使用RLVR+GRPO、Hybrid Reward、LLM‑judge、知识图谱路径采样、步骤级有效性与相关性评估等技术。

**📊 数据集**

数据集包括由Wiki构建的14,577条多跳QA（过滤后2,012条）以及在FRAMES、LongBench V2、Multi‑Hop QA三大公开长文本推理基准上进行评测。

**📈 对比分析**

与RLVR基线、SFT、GRPO、DAPO等方法对比，显著提升了各基准（例如FRAMES+高跳数上提升近20pp），在参数规模更小的模型上与前沿LLM持平。

**⚠️ 局限性**

局限包括仅基于Wiki知识图，缺乏多领域文本；与合成框架耦合，需显式推理链；奖励模型过于简单，难以覆盖开放式或主观任务。

---

## 95. Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees

**arXiv ID:** 2601.12447 | [PDF](https://arxiv.org/pdf/2601.12447v1)

**作者:** Mohammed Himayath Ali `[一作]`, Shahnawaz Alam `[通讯]`

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `e15e3743-5ee0-4d5f-813d-d146868082fc` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

提出了一种名为CryptoFair-FL的新型加密框架，为联邦学习系统提供可验证的公平性保证，解决了在保护隐私的同时确保算法公平性的问题。

**💡 创新点**

创新点在于结合了可加同态加密和安全多方计算，首次在正式安全定义下实现了公平性验证，同时引入了一种新的批量验证协议，显著降低了计算复杂度。

**🔧 技术方法**

使用了可加同态加密和安全多方计算技术。

**📊 数据集**

使用了四个基准数据集：MIMIC-IV医疗记录、成人收入数据集、CelebA数据集和一个新构建的FedFair-100基准数据集。

**📈 对比分析**

与标准的联邦平均方法相比，CryptoFair-FL在公平性验证中将人口统计差异从0.231降低到0.031，计算开销仅增加了2.3倍，且在所有测试配置中成功防御属性推断攻击，保持对抗成功概率低于0.05。

**⚠️ 局限性**

局限性在于依赖于半信任的协调者进行聚合，这可能成为单点故障和攻击的目标。此外，当前实现假设参与者之间存在诚实的多数，扩展到容忍拜占庭攻击的设置仍然是一个开放问题。

---

## 96. Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting

**arXiv ID:** 2601.12467 | [PDF](https://arxiv.org/pdf/2601.12467v1)

**作者:** Saurish Nagrath `[一作]` `[通讯]` (VIT AP), Saurish Nagrath (VIT AP)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出一种两阶段的CNN‑Transformer框架，用CNN对固定长度时间窗进行局部特征编码并用自注意力优化嵌入，再通过Transformer编码全局时序依赖，生成多变量时间序列预测结果。

**💡 创新点**

创新点在于将局部时间特征学习与全局注意力建模显式分离，构造结构化的时间片段Token，提升模型的稳定性和可解释性。

**🔧 技术方法**

采用1D卷积网络、token‑level多头自注意力、Transformer编码器、位置嵌入和线性预测头等深度学习技术。

**📊 数据集**

使用基于动态与静态特征的合成多变量时间序列数据集，包含两个动态特征和四个静态特征，长度为30，分为训练/测试两种随机种子。

**📈 对比分析**

与TCN和PatchTST基线在同一数据集上比较，PatchTST表现最佳（MSE 0.028，MAE 0.131），本框架在MSE 0.093、MAE 0.232，TCN为MSE 0.038、MAE 0.153，显示出可竞争的预测精度。

**⚠️ 局限性**

局限性包括：在此合成数据上并未超过PatchTST，且未在真实金融数据上验证；两阶段训练方式可能导致信息传递不够充分；对不同长度或复杂性时序的适应性待进一步研究。

---

## 97. Discovering 100+ Compiler Defects in 72 Hours via LLM-Driven Semantic Logic Recomposition

**arXiv ID:** 2601.12360 | [PDF](https://arxiv.org/pdf/2601.12360v1)

**作者:** Xinabang He `[一作]` (Nanjing University), Bing Mao `[通讯]` (Nanjing University)

**通讯引用:** 2338 | [OpenAlex ID](https://openalex.org/A5089309949)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `5b4c1114-4a70-478e-9921-2514ee03850d` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于“特征”的编译器模糊测试框架，利用历史缺陷提取语义特征，组合生成程序进行 GCC/LLVM 测试。

**💡 创新点**

创新点在于：①用自然语言描述语义特征并附上代码证据，形成可复用的特征原子；②使用 fine‑tuned LLM 合成特征组并自动实例化，克服传统突变/生成方法的语义坍塌；③通过覆盖反馈循环动态提升特征池质量。

**🔧 技术方法**

主要技术包括：LLM 预训练与 fine‑tune、特征抽取（文本+代码）、特征合成（LLM 自动补全依赖）、程序实例化（LLM 生成满足多特征的 C/C++ 代码）、覆盖驱动的反馈循环。

**📊 数据集**

数据集为 GCC 与 LLVM 的 Bugzilla 历史缺陷报告及其 PoC 程序，构成特征池；对比实验使用官方发布的 GCC（13/15/18）和 LLVM（18/21）编译器版本。

**📈 对比分析**

比较方法：在相同 24/72 小时的 fuzzing 期间，与 Csmith、YARPGen、MetaMut、fuzz4all、FuzzGPT、MirrorFuzzr、ClozeMaster 等现有 fuzzers 在行覆盖率、覆盖分布、独立崩溃数等指标上对比。结果显示该方法行覆盖率提升约 24–30%，独立崩溃数为 167（比第二佳高 2.78 倍），共发现 106 只 bug，其中 75 已被官方确认，且 45 只 bug 由可编译程序触发。

**⚠️ 局限性**

局限性：①LLM 生成准确性受限，可能产生不可编译或未完全满足特征的程序；②特征提取质量高度依赖缺陷报告和 PoC 的完整性，缺陷信息不完整时可能提取到无效或冗余特征；③覆盖驱动的反馈循环在计算上仍需一定资源，且对模型的细粒度调优尚未系统化。

---

## 98. Experiencer, Helper, or Observer: Online Fraud Intervention for Older Adults Through Role-based Simulation

**arXiv ID:** 2601.12324 | [PDF](https://arxiv.org/pdf/2601.12324v1)

**作者:** Yue Deng `[一作]` (Hong Kong University of Science and Technology), Yixin Zou `[通讯]` (Max Planck Institute for Security and Privacy)

**通讯引用:** 753 | [OpenAlex ID](https://openalex.org/A5037796481)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

设计并实施了三种角色（体验者、帮助者、观察者）的对话式模拟学习，评估其对中国老年人网络诈骗线索识别的效果。

**💡 创新点**

首次将多角色视角与大型语言模型结合，用细粒度诈骗线索进行交互式教育，探讨不同角色对学习效果的差异。

**🔧 技术方法**

利用 GPT‑4o 生成诈骗对话、受害者回报和观察记录，并通过线上线索识别测试、用户体验问卷和访谈进行评估。

**📊 数据集**

基于从 34 条真实中国老年人诈骗案例中抽取的 16 条金融/健康线索，构建了六条线索集并生成测试情境。

**📈 对比分析**

使用 Kruskal‑Wallis、Dunn’s post‑hoc 等非参数检验比较四组；实验显示体验者与帮助者的 F1 分数显著高于对照，帮助者优于观察者；自效能与用户体验差异不显著，随访未再出现显著差异。

**⚠️ 局限性**

局限在于样本仅为中国老年人，缺少跨文化验证；对照仅为阅读材料，未与工作坊或视频对比；随访样本量小，无法验证长期保持；LLM 生成对话虽可控但仍存在自然度与情感温度不足的问题。

---

## 99. ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models

**arXiv ID:** 2601.12428 | [PDF](https://arxiv.org/pdf/2601.12428v1)

**作者:** Baorui Peng `[一作]` (Georgia Institute of Technology), Xin Jin `[通讯]` (Eastern Institute of Technology)

**通讯引用:** 6647 | [OpenAlex ID](https://openalex.org/A5100641350)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `a4b10f5d-130b-4e77-9367-6469ec621899` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `40105733-5154-44cd-8090-a8cab9e64b07` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出ReWorld框架，利用强化学习和人类反馈对视频式身体世界模型进行物理真实性、任务完成度、身体可实现性和视觉质量的统一提升。

**💡 创新点**

创新点包括：①构建大规模四维偏好数据集并引入HERO多维奖励模型；②设计HERO‑FPO算法，使用CFM似然近似实现高分辨率流模型的PPO优化；③发布ReWorldBench基准以量化物理Uncanny Valley。

**🔧 技术方法**

采用的技术有：流模型Cosmos、InternVideo2骨干的层级奖励头、VLM驱动的数据标注（GPT‑4o）、CFM‑likelihood代理、PPO式强化学习、奖励加权的价值网络。

**📊 数据集**

使用的数据集包括RH20T（约235K条视频），Bridge V2机器人数据进行域适配，以及专家手工标注的300条视频做奖励模型评估。

**📈 对比分析**

与Cosmos‑SFT、CogVideoX、Wan2.1等SOTA对比，ReWorld在四维物理、任务、身体和视觉指标上平均提升15‑25%，人类偏好率超过85%，并在ReWorldBench上获得最高综合分。

**⚠️ 局限性**

局限性在于：①RLHF训练仍耗时且对计算资源要求高；②奖励模型对VLM推理的依赖可能引入标注噪声；③目前仍缺乏极低样本或跨任务的泛化能力。

---

## 100. Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models

**arXiv ID:** 2601.12234 | [PDF](https://arxiv.org/pdf/2601.12234v1)

**作者:** Fadlullah Raji `[一作]` (University of South Florida), Gang Wu `[通讯]` (Adobe Research)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `4de8e9d8-757b-475f-9627-18a445e50202` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

研发了 Proc3D 系统，利用大型语言模型（LLM）通过文本和 GUI 控件实时生成并编辑 3D 模型，核心是将模型编码为可编辑的 Procedural Compact Graph（PCG）图。

**💡 创新点**

创新点包括：①提出 PCG 作为一种语言本地、引擎无关、压缩度高的 3D 图形表示，显著降低上下文长度并暴露节点参数；②使 LLM 能直接生成 PCG 并通过文本指令实现局部、实时编辑；③构建大规模指令‑图对数据集，为 LLM 训练与评估提供基础。

**🔧 技术方法**

技术手段包括：LLM（GPT‑4o、LLaMA‑3 70B/8B）与 In‑Context Learning、QLoRA 微调；PCG 语法与解释器；图形渲染与 Blender/Unity 接口；使用 LLaVA 生成多视图描述；评估指标包括编译率、生成/编辑时间、ULIP 分数。

**📊 数据集**

数据集：从 PartNet 的分层零件网格中提取 21K 个 PCG 及对应模型，随后通过 LLaVA 生成 63K 条指令‑图对；包含 5 类物体（椅子、桌子、垃圾桶、存储家具、床）等。

**📈 对比分析**

与 SDFusion、AutoSDF、Shap‑E、LLaMA‑Mesh、LGM、Stable Diffusion、TurboEdit、InstructPix2Pix 等基线对比；在编译率、生成时间、编辑时间、ULIP 评分上均优，编辑速度提升 400×，ULIP 得分提升 28%，生成时间与高质量基线相近。

**⚠️ 局限性**

局限性：训练数据主要由低复杂度立方体原语组成，缺乏多样性；对复杂形状和场景的泛化仍有限；未来需扩大数据集范围和图形多样性。

---

## 101. Trend-Adjusted Time Series Models with an Application to Gold Price Forecasting

**arXiv ID:** 2601.12706 | [PDF](https://arxiv.org/pdf/2601.12706v1)

**作者:** Sina Kazemdehbashi `[一作]` `[通讯]` (Wayne State University), Sina Kazemdehbashi (Wayne State University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `5a41884c-404f-4688-a89c-aa238c10fe68` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出Trend‑Adjusted Time Series（TATS）模型，将趋势预测与值预测统一为一体化框架；

**💡 创新点**

创新点在于用二分类器预测未来走势，并根据预测趋势对基础模型输出做调整；理论证明在趋势预测准确率高于值预测的趋势检测准确率时，TATS可降低误差并给出误差下限公式；

**🔧 技术方法**

技术方案为：XGBoost做趋势预测器，LSTM或Bi‑LSTM做值预测器，构建调整函数（含α超参数）实现预测值的动态修正；

**📊 数据集**

使用2023年每日黄金价格（250条记录）及其相关宏观特征（FTSE、道琼斯、S&P 500、USD/EUR、USD/JPY、油价）作为数据集；

**📈 对比分析**

与传统单一模型LSTM、Bi‑LSTM进行对比，评价指标包括MSE、MAE、MAPE及趋势检测准确率；TATS在测试集MSE分别由LSTM的399.31降至332.97（约17%下降），由Bi‑LSTM的371.92降至320.75（约14%下降），同时趋势检测准确率显著提升；

**⚠️ 局限性**

局限性：模型效果高度依赖趋势预测器的准确率；α参数选择对性能影响大，需经验调优；仅在黄金价格上验证，缺乏跨领域推广；样本量有限，存在过拟合风险。

---

## 102. Federated Joint Learning for Domain and Class Generalization

**arXiv ID:** 2601.12253 | [PDF](https://arxiv.org/pdf/2601.12253v1)

**作者:** Haoran Xu `[一作]` (Zhejiang University), Zhenbo Luo `[通讯]` (MiLM Plus)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出FedDCG，联合处理联邦学习环境下的未见类别与未见域的通用性问题；

**💡 创新点**

创新性在于采用域分组与类专属网络训练相结合的策略，并通过域引导聚合推理实现类与域的双重泛化；

**🔧 技术方法**

使用跨注意力（Cross‑Attention）实现文本与图像的对齐，结合全局与域特定提示（prompt）分离技术，以及在客户端交替进行类专属与域分离训练；

**📊 数据集**

在Office‑Home、MiniDomainNet上进行训练，在ImageNet‑R和ImageNet‑A上进行零样本/低采样测试；

**📈 对比分析**

与FedCoOp、FedCoCoOp、FedTPG、DiPrompT等基线比较，FedDCG在多组未见域/类别的测试中平均提升约2–3%准确率，整体稳健性更好；

**⚠️ 局限性**

局限性包括：在低采样率下仍有一定性能退化，尤其对Clipart、Art等难泛化域；方法模型复杂度和通信开销相对较高，尚需进一步优化。

---

## 103. SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification

**arXiv ID:** 2601.12791 | [PDF](https://arxiv.org/pdf/2601.12791v1)

**作者:** Zhihan Zeng `[一作]` (University of Electronic Science and Technology of China), Ning Wei `[通讯]` (National Key Laboratory of Wireless Communications, University of Electronic Science and Technology of China)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出并实现了SKANet双流认知网络，用时频图与功率谱密度相结合对复杂GNSS干扰进行分类。

**💡 创新点**

创新点包括：多分支Selective Kernel与Asymmetric卷积实现自适应感受野；双流时频+PSD的协同学习；Squeeze‑Excitation融合调节多模态重要性；在低JNR环境下显著提升分类精度。

**🔧 技术方法**

采用的技术有：Selective Kernel网络、Asymmetric Convolution Block、Squeeze‑Excitation、深度双流CNN、STFT、Welch PSD估计、Adam优化、Dropout正则化。

**📊 数据集**

使用的数据集为40.5万条合成的九类复合GNSS干扰样本，覆盖-25 dB至15 dB JNR，并随机设置功率比（PR）在[-3,3] dB范围。

**📈 对比分析**

与ViT‑B‑16、ResNet18、EfficientNetB0、ShuffleNetV2、TFPENet等主流基线进行对比；SKANet整体准确率为96.99%，比第二名高约2.4%，低SNR下仍可保持>75%准确率，高SNR下达到100%。

**⚠️ 局限性**

局限性：仅在合成数据上验证，未覆盖真实环境；对极低JNR（-25 dB）仍表现不佳；模型仍有轻微推理延迟，需进一步优化以满足极低延迟场景。

---

## 104. PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining AI-Mediated Mental Health Support

**arXiv ID:** 2601.12754 | [PDF](https://arxiv.org/pdf/2601.12754v1)

**作者:** Jiwon Kim `[一作]` (University of Illinois Urbana-Champaign), Koustuv Saha `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 3141 | [OpenAlex ID](https://openalex.org/A5057029055)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建并评估了一个配对代理框架(PAIR‑SAFE)，通过监督代理对LLM生成的心理健康支持对话进行实时审核和修订。

**💡 创新点**

提出将临床验证的动机访谈（MITI‑4）标准嵌入到监督代理，实现可审计、可解释的运行时监督，而非仅依赖模型微调。

**🔧 技术方法**

使用两代理架构：生成代理（GPT‑4o‑mini）和审计代理（Judge），以及MITI‑4评估指标进行结构化反馈；通过仿真求助者模拟器和基于LLM的主题提取实现对话生成。

**📊 数据集**

基于公开的“Conversations”MI对话数据集（259场会话），并利用其MITI注释作为评估和阈值来源；同时使用该数据生成求助者模拟器。

**📈 对比分析**

通过与单一代理Baseline对比，采用MITI‑4的衍生指标、全局评分和行为计数，发现受监督代理显著提升反射/提问比例、关系质量、合作意向等（Cohen’s d从0.47到0.94），并在专家评估中显示多数回应得到改善。

**⚠️ 局限性**

受限于高质量LLM基线导致提升空间有限，评估仅在模拟对话且未检验对用户心理结果，且未与其他微调或强化学习方法做系统对比。

---

## 105. Race, Ethnicity and Their Implication on Bias in Large Language Models

**arXiv ID:** 2601.12868 | [PDF](https://arxiv.org/pdf/2601.12868v1)

**作者:** Shiyue Hu `[一作]` (University of Colorado), Yanjun Gao `[通讯]` (University of Colorado)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对大型语言模型（LLM）中种族和族裔信息的内部编码与使用机制进行了系统的机制性分析，探讨了在毒性生成和临床文本理解任务中的偏见来源。

**💡 创新点**

创新点在于将机制性可解释性方法（多类探针、神经元级归因和目标干预）应用于多任务、多模型环境，揭示种族信息在模型内部的分布式、多面向表示，并证明单一神经元干预无法完全消除偏见，需考虑任务依赖的使用方式。

**🔧 技术方法**

使用了探针学习、Logit Lens 词汇投射、cosine 相似度搜索神经元、前向钩子进行神经元归因和放大/抑制干预等技术；并基于三种开源 LLM（Qwen2.5‑7B、Mistral‑7B、Llama‑3.1‑8B）进行实验。

**📊 数据集**

利用公开数据集 ToxiGen（毒性生成）和 C‑REACT（MIMIC‑III 临床笔记中种族标签），分别包含显式和隐式种族提示。

**📈 对比分析**

通过与传统基于输出的公平度量（如误分类率、毒性评分）对比，发现直接种族标签相关的神经元干预在三种模型中显著降低偏见且恢复正确预测率（最高 100%），而间接提示相关神经元干预效果不佳；同时展示不同放大因子对模型稳定性的影响。

**⚠️ 局限性**

局限性包括：1）研究聚焦于粗粒度种族/族裔标签，未深入社会学层面的细粒度差异；2）干预仅针对少量可识别神经元，未能消除所有残留偏见；3）仅评估了三种模型，未涵盖更大规模或不同训练来源的 LLM；4）实验环境受限于公开数据集，可能缺乏真实多样性。

---

## 106. Inverse Rendering for High-Genus 3D Surface Meshes from Multi-view Images with Persistent Homology Priors

**arXiv ID:** 2601.12155 | [PDF](https://arxiv.org/pdf/2601.12155v1)

**作者:** Xiang Gao `[一作]` (Stony Brook University), Xianfeng Gu `[通讯]` (Stony Brook University)

**通讯引用:** 11915 | [OpenAlex ID](https://openalex.org/A5100607707)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

利用协同逆渲染结合持久同调先验，对多视图图像进行梯度优化，从而重建高基数（高基数）三维网格。

**💡 创新点**

创新点是将持久同调得到的隧道与把手环路作为拓扑先验，用于指导相机位置和优化过程，显著提升了对高基数拓扑结构的恢复鲁棒性。

**🔧 技术方法**

采用梯度优化的网格逆渲染框架、持久同调（PH）分析、统一球面相机采样以及基于PH的相机位置引导技术。

**📊 数据集**

在来自 GSO 数据集和 Thingi10K 数据集的八个具有挑战性的高基数模型上进行实验。

**📈 对比分析**

与 Nicolet 等人的无网络梯度优化基线方法对比，实验表明在 Chamfer 距离（CD）下降、体积 IoU 提升方面均实现了显著改进，重建质量更高。

**⚠️ 局限性**

局限性包括仅适用于网格逆渲染框架，难以直接迁移到深度学习或非网格生成；相机采样仍需手工设置，且对极端遮挡与光照变化的鲁棒性尚待进一步提升。

---

## 107. Sensing-Limited Control of Noiseless Linear Systems Under Nonlinear Observations

**arXiv ID:** 2601.12782 | [PDF](https://arxiv.org/pdf/2601.12782v1)

**作者:** Ming Li `[一作]` (Southern University of Science and Technology), Tao Liu `[通讯]` (Southern University of Science and Technology)

**通讯引用:** 21995 | [OpenAlex ID](https://openalex.org/A5100338080)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

本文研究了在非线性观测渠道下，噪声为零的线性动态系统的感知与控制的根本信息理论极限。

**💡 创新点**

创新点在于：① 将导向信息率作为度量，提出系统稳定所需的最小信息流量；② 对非线性观测通道引入对数凸性等正则性假设，证明信息流率大于系统膨胀率即可保证渐近均方可观测与可稳定；③ 将传统的通信数据率限制扩展到感知层，揭示感知几何对控制性能的根本约束。

**🔧 技术方法**

使用了导向信息、相对熵、对数凸性理论、Jordan 分解、控制理论中的输入-状态稳定性等技术。

**📊 数据集**

无，本文为纯理论研究，无数据集。

**📈 对比分析**

无实验或数值比较，结果以定理形式给出；若要验证，可通过数值仿真检验信息流率与稳定性的关系。

**⚠️ 局限性**

局限性：① 仅考虑无过程噪声的系统；② 需要对观测通道满足严格的对数凸性与 Hessian 矩阵负定等正则性假设；③ 对非高斯、非对数凸性观测通道的适用性尚未证明。

---

## 108. Neural Process-Based Reactive Controller for Autonomous Racing

**arXiv ID:** 2601.12143 | [PDF](https://arxiv.org/pdf/2601.12143v1)

**作者:** Devin Hunter `[一作]` (University of Central Florida), Chinwendu Enyioha `[通讯]` (University of Central Florida)

**通讯引用:** 742 | [OpenAlex ID](https://openalex.org/A5006306293)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出基于神经过程的实时Gap跟随控制框架，集成Attentive Neural Process（AttNP）及其物理信息化扩展PI‑AttNP，并通过控制障碍函数（CBF）滤波实现碰撞避免；

**💡 创新点**

创新点在于将约束物理先验（FTG启发式）嵌入神经过程解码器中，提升学习速度与泛化；将CBF滤波器与数据驱动控制器无缝结合，提供即时安全保障；

**🔧 技术方法**

使用Attentive Neural Process、Physics‑Informed AttNP、控制障碍函数（CBF）以及多头注意力机制；

**📊 数据集**

使用仿真F1TENTH赛车轨道环境生成的LiDAR与速度数据集；

**📈 对比分析**

与专家FTG、AttNP、Res‑MLP三种基线对比，评价指标包括平均完成时间（~40 s）、碰撞次数和平均转向速率；PI‑AttNP在碰撞率上最低（0.2/赛）且保持与专家相当的赛程时间，表现最佳；

**⚠️ 局限性**

局限性包括仅在仿真环境验证、上下文长度有限（仅上一时刻）、仅考虑近似的动力学与单步预测，安全保证仅局部且基于LiDAR测距，缺乏更广泛的实际场景验证与长时序规划。

---

## 109. Constructing a Dataset to Support Agent-Based Modeling of Online Interactions: Users, Topics, and Interaction Networks

**arXiv ID:** 2601.12628 | [PDF](https://arxiv.org/pdf/2601.12628v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39`

---

## 110. Learning Deterministic Finite-State Machines from the Prefixes of a Single String is NP-Complete

**arXiv ID:** 2601.12621 | [PDF](https://arxiv.org/pdf/2601.12621v1)

**作者:** Radu Cosmin Dumitru `[一作]` (Delft University of Technology), Ayumi Shinohara `[通讯]` (Tohoku University)

**通讯引用:** 2500 | [OpenAlex ID](https://openalex.org/A5071075962)

**关键词:** `33d19632-8af2-4683-a5db-767c7ce749e6`

**🎯 论文内容**

研究了在二进制字母表下，学习最小DFA、Moore机和Mealy机时，若训练样本为前缀闭合且仅包含单条字符串的所有前缀，该学习问题仍为NP-完全且无法在多项式时间内近似；

**💡 创新点**

创新点在于将前缀闭合的NP难度进一步压缩到极其受限的单字符串前缀集合，并证明即使如此该问题仍不可多项式近似；

**🔧 技术方法**

主要技术是从图着色问题构造前缀闭合样本，利用0-链计数与状态归约的论证，分别证明DFA、Moore和Mealy机的NP难度；

**📊 数据集**

使用的“数据集”为基于图着色实例人工构造的前缀集合，没有真实世界数据；

**📈 对比分析**

论文没有实验比较或性能评估，而是通过严格的多项式归约与计数论证提供理论证明；

**⚠️ 局限性**

局限性包括：仅适用于二进制字母表；单字符串前缀情况的近似性结果未被证明；缺乏实际算法或实验验证。

---

## 111. Abusing the Internet of Medical Things: Evaluating Threat Models and Forensic Readiness for Multi-Vector Attacks on Connected Healthcare Devices

**arXiv ID:** 2601.12593 | [PDF](https://arxiv.org/pdf/2601.12593v1)

**作者:** Isabel Straw `[一作]` (University College London), Mustafa Jaafar `[通讯]` (University College London)

**通讯引用:** 393 | [OpenAlex ID](https://openalex.org/A5073695328)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

构建了针对依赖医疗技术的 IPV 受害者的危险集成威胁模型，并在沉浸式模拟中评估数字取证准备度。

**💡 创新点**

将技术滥用框架与 Medjacking 威胁建模结合，并首次在现场演示 BLE 跟踪对听力辅助设备的影响。

**🔧 技术方法**

采用攻击树、BLE 距离监测、沉浸式情景仿真以及取证评估方法。

**📊 数据集**

基于15种技术的实验场景和受试者问卷数据；未使用公开数据集。

**📈 对比分析**

通过对 21 名参与者的设备识别、知识和可利用性评估，比较识别率与潜在攻击感知；发现显著缺口，表明现行流程不足。

**⚠️ 局限性**

仅涵盖有限设备与攻击路径，攻击树不完整，样本量小，模拟可能不完全代表真实案件。

---

## 112. Cooperative Multi-agent RL with Communication Constraints

**arXiv ID:** 2601.12518 | [PDF](https://arxiv.org/pdf/2601.12518v1)

**作者:** Nuoya Xiong `[一作]` (Carnegie Mellon University), Aarti Singh `[通讯]` (Carnegie Mellon University)

**通讯引用:** 2630 | [OpenAlex ID](https://openalex.org/A5100758181)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

研究在通信受限环境下的多智能体强化学习，提出基于预测基准策略的改进重要性采样方法，显著降低通信轮数。

**💡 创新点**

通过“基准策略预测”预先生成一系列基准策略，减少重要性采样方差，并证明在潜在游戏和一般协作游戏中可获得更优的通信成本与样本复杂度。

**🔧 技术方法**

结合自然策略梯度、重要性采样、潜在游戏Oracle以及价值函数逼近的 V-learning 等技术，构建分布式算法。

**📊 数据集**

在合成潜在游戏、拥堵游戏以及标准多智能体环境（MPE 里的 Spread、Reference 以及 SMAC 的 1c3s5z、MMM、3s_vs_3z）上进行实验。

**📈 对比分析**

与传统 NPG、MAPPO 以及其无重要性采样版本在相同通信间隔下对比，实验显示本方法在相同通信轮数下收敛速度和最终奖励均优于基线，且可将通信间隔扩大十倍仍保持性能。

**⚠️ 局限性**

仍需在更大规模团队与动态通信拓扑中验证；理论依赖潜在函数与子最优间隙假设，实际环境中这些假设可能不成立。

---

## 113. Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization

**arXiv ID:** 2601.12604 | [PDF](https://arxiv.org/pdf/2601.12604v1)

**作者:** Safwan Labbi `[一作]` (École polytechnique), Eric Moulines `[通讯]` (Mohamed bin Zayed University of Artificial Intelligence)

**通讯引用:** 22678 | [OpenAlex ID](https://openalex.org/A5101398712)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出基于 f‑divergence 的 f‑SoftArgmax 策略参数化，并与相同 f‑divergence 正则化相配合，改进策略梯度方法的收敛性质，给出无预处理的最后一次迭代非渐近收敛保证。

**💡 创新点**

创新点包括：① 通过 f‑SoftArgmax 统一参数化与正则化，得到更好条件的优化景观；② 证明 f‑regularized value 满足 Polyak–Łojasiewicz 条件，进而获得多项式收敛速率；③ 使用 Tsallis‑divergence 替代 Shannon‑entropy，使未正则化的策略梯度从指数慢速提升到多项式收敛。

**🔧 技术方法**

理论技术：光滑性分析、非均匀 Łojasiewicz 不等式、投影算子限制极端策略、样本估计与 REINFORCE、Polyak–Łojasiewicz 证明；实验技术：将 PPO 改写为 α‑PPO（即使用 Tsallis‑SoftArgmax 与 Tsallis 正则化）并在离散 MDP 上训练。

**📊 数据集**

实验数据集：
- Noisy CartPole（加入不同标准差的奖励噪声）
- DeepSea（L = 20, 30, 40, 50 的稀疏奖励网格）
- 传统的标准 CartPole（未加噪声）作为基准。

**📈 对比分析**

与标准 PPO、softmax‑entropy 策略梯度进行对比，统一步长与温度设置。结果显示：
- 对于噪声奖励环境，α < 1 的 α‑PPO 收敛速度快于 PPO；
- 在 DeepSea 的深度探索任务中，α = 0.7 的 α‑PPO 在所有 L 取值上均优于 PPO，收敛更快；
- 论文给出的样本复杂度证明表明，Tsallis‑SoftArgmax 使得未正则化目标的样本复杂度从指数级下降到多项式级。

**⚠️ 局限性**

局限性：
- 证明仅覆盖有限状态、有限动作的离散 MDP；
- 对于 α > 1 的 Tsallis，条件不满足，理论尚未扩展；
- 未考虑对抗性 MDP 或连续控制场景；
- 需要手动调节 α 与温度，选择最优参数仍是经验性任务；
- 实验仅在小规模离散环境验证，尚未在大规模深度 RL 环境中测试。

---

## 114. Text2Structure3D: Graph-Based Generative Modeling of Equilibrium Structures with Diffusion Transformers

**arXiv ID:** 2601.12870 | [PDF](https://arxiv.org/pdf/2601.12870v1)

**作者:** Lazlo Bleker `[一作]` (Technical University of Munich), Pierluigi D'Acunto `[通讯]` (Technical University of Munich)

**通讯引用:** 438 | [OpenAlex ID](https://openalex.org/A5057794194)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了 Text2Structure3D，一种基于图的潜在扩散模型，能够根据自然语言提示生成满足静力平衡的桥梁结构。

**💡 创新点**

创新点在于将潜在扩散、变分图自动编码器与图变压器相结合，联合编码节点坐标、力密度及支撑条件，并通过残差力优化后处理确保生成结构严格满足平衡约束，实现从文本到结构图的无参数、可解释生成。

**🔧 技术方法**

使用的技术包括潜在扩散模型、变分图自动编码器（VGAE）、图变压器（DiT）、CLIP 文本嵌入、CFG 引导、残差力优化以及力密度法（FDM）等。

**📊 数据集**

使用了 30,000 条桥梁（20,000 条弧形/悬索桥、10,000 条三角桁架桥）和 300,000 条对应文本标签的合成跨类型数据集。

**📈 对比分析**

与基于参数模型的生成方法对比，采用残差力误差与几何重建误差评估；重建误差从 2.96 m 降至 0.61 m，残差力误差降至 0；在提示遵循度上，生成结构的属性分布聚焦于用户需求，优于无条件或仅按类型条件的生成。

**⚠️ 局限性**

局限性包括：数据集仅涵盖桥梁单一负载案例；拓扑预测依赖参数模型，难以扩展至更通用结构；模型假设结构已中心化、沿 x 轴对齐，缺乏对更复杂拓扑和外部载荷的建模能力。

---

## 115. Towards Spectroscopy: Susceptibility Clusters in Language Models

**arXiv ID:** 2601.12703 | [PDF](https://arxiv.org/pdf/2601.12703v1)

**作者:** Andrew Gordon `[一作]` (Timaeus), Daniel Murfet `[通讯]` (Timaeus)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

对 Pythia‑14M 语言模型进行灵敏度分析（susceptibility），计算 780,000 条上下文‑词对的高维响应向量，并基于导电率（conductance）的 PageRank 局部聚类算法，识别出 510 个可解释的聚类，每个聚类对应模型对数据分布中某一模式的专门响应；进一步验证这些聚类在更大规模模型中的稳定性。

**💡 创新点**

① 将物理光谱学中的“谱线”概念迁移到神经网络，提出灵敏度向量与数据分布模式（SVD 产生的正交模式）之间的理论分解；② 开发基于导电率的聚类框架，能够从高维灵敏度数据自动挖掘可解释聚类；③ 通过与稀疏自编码器（SAE）特征的 50.8% 匹配，验证了方法的可靠性和跨方法的一致性。

**🔧 技术方法**

pSGLD 采样得到局部后验，计算组件级灵敏度并聚合为向量；对向量进行标准化、k‑NN 图构造；使用自适应 RBF 权重的 PageRank 局部聚类并基于导电率筛选低导电率子图；SVD 解析数据分布的模式；UMAP 用于可视化。

**📊 数据集**

基准数据集：Pile 的 13 个子集（包括代码、科学文献、法律文件、通用网络文本），共采样 780,000 条上下文‑词对；此外在 31M–1.4B 参数的更大 Pythia 模型中计算灵敏度以检验聚类的可迁移性。

**📈 对比分析**

与稀疏自编码器（SAE）特征对比：在 510 个聚类中有 259 个（50.8%）与 70M 级 SAE 特征匹配；在更大模型中对同一聚类计算导电率，平均值显著低于 1，说明聚类在不同规模模型中保持紧凑。该比较表明方法能捕捉与现有解释性技术相似的结构。

**⚠️ 局限性**

局限性：仅在 Pythia 系列和 Pile 数据上验证；聚类结果对导电率阈值、k‑NN 参数敏感；与 SAE 的比较受限于 70M 级特征而非 14M；在极大模型（B 级或更大）上灵敏度采样与聚类的可扩展性尚未验证；聚类数目在更大模型下降，说明当前方法可能无法完全捕捉更细粒度结构。

---

## 116. Predictive Prototyping: Evaluating Design Concepts with ChatGPT

**arXiv ID:** 2601.12276 | [PDF](https://arxiv.org/pdf/2601.12276v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

---

## 117. Large Language Model for OWL Proofs

**arXiv ID:** 2601.12444 | [PDF](https://arxiv.org/pdf/2601.12444v1)

**作者:** Hui Yang `[一作]` (University of Manchester), Uli Sattler `[通讯]` (University of Manchester)

**通讯引用:** 14586 | [OpenAlex ID](https://openalex.org/A5072391425)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了针对OWL本体推理的全流程证明生成数据集，并评估了LLM在提取、简化与解释三任务及逻辑完整性判定的能力。

**💡 创新点**

创新点在于（1）首次提出三阶段证明生成框架；（2）自动化生成大规模基于OWL 𝔈𝔏的推理样本；（3）系统探究噪声、自然语言与缺失前提对LLM表现的影响。

**🔧 技术方法**

主要技术包括Prompt工程（插入推理规则、示例）、句子嵌入噪声筛选、以及多任务评估指标（格式正确率、Jaccard、准确率、长度缩减率）。

**📊 数据集**

使用的公开本体数据集有Snomed CT、Foodon、GO‑Plus，分别抽取数百条推理结论进行实验。

**📈 对比分析**

与多款开源与商用LLM（GPT‑o4‑mini、Qwen3‑32B、DeepSeek‑R1‑Qwen‑32B等）对比，GPT‑o4‑mini在所有指标上领先，Qwen3‑32B次之；推理规则的引入显著提升Qwen3‑32B表现，而GPT‑o4‑mini受影响有限。

**⚠️ 局限性**

局限性在于：在复杂推理模式、噪声比例升高或前提不完整时，性能大幅下降；目前仅覆盖𝔈𝔏片段，未扩展至完整OWL 2 DL或更高层次的推理任务。

---

## 118. On the Minimum Length of Functional Batch Codes with Small Recovery Sets

**arXiv ID:** 2601.12302 | [PDF](https://arxiv.org/pdf/2601.12302v1)

**作者:** Kristiina Oksner `[一作]` (University of Tartu), Vitaly Skachek `[通讯]` (University of Tartu)

**通讯引用:** 815 | [OpenAlex ID](https://openalex.org/A5048122752)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

本文研究了一种特殊的批量编码，称为功能批量编码，允许用户查询信息符号的线性组合，并且每个查询仅使用少量编码符号进行回答。

**💡 创新点**

创新点在于提出了一种限制每次检索使用的符号数量的功能批量编码，并推导了此类编码的最小长度的下界。

**🔧 技术方法**

使用了生成函数和数值计算技术来推导和评估编码的下界。

**📊 数据集**

使用了理论推导和数值计算的结合，没有具体提到使用的数据集。

**📈 对比分析**

通过与文献中的结果进行比较，展示了所提出的下界的有效性，性能表现良好，能够提供比现有方法更紧的下界。

**⚠️ 局限性**

限制在于只考虑了线性功能批量编码，可能无法推广到更复杂的编码结构。

---

## 119. Tolerance Principle and Small Language Model Learning

**arXiv ID:** 2601.12179 | [PDF](https://arxiv.org/pdf/2601.12179v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86`

---

## 120. Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning

**arXiv ID:** 2601.12535 | [PDF](https://arxiv.org/pdf/2601.12535v1)

**作者:** Ahmed Attia `[一作]` (Mohamed Bin Zayed University of Artificial Intelligence), Alham Fikri `[通讯]` (Mohamed Bin Zayed University of Artificial Intelligence)

**通讯引用:** 2868 | [OpenAlex ID](https://openalex.org/A5112924039)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种在预训练多语种模型上使用英语→目标语言→英语回环的自监督强化学习方法，以无并行语料提升低资源语言的机器翻译质量。

**💡 创新点**

创新点在于将GRPO强化学习与回环一致性奖励（chrF+++BLEU）结合，形成完全无监督的微调框架，解决了传统MLE暴露偏差和目标不匹配的缺陷，并能在无并行数据条件下显著提升低资源翻译性能。

**🔧 技术方法**

采用了GRPO（Group Relative Policy Optimization）强化学习算法，回环翻译生成与自监督奖励设计，以及基于chrF++和BLEU的复合奖励信号。

**📊 数据集**

使用NLLB-MD单语料库与预训练的NLLB 600M/1.3B模型，评测语言包括Central Aymara、Friulian、Wolof和Russian。

**📈 对比分析**

通过与原始预训练模型在chrF++、BLEU、Goldfish流畅度、BERTScore等指标上的对比，实验显示四种语言的chrF++平均提升约3–4点，流畅度和语义保真度明显提高。

**⚠️ 局限性**

局限性包括仅评估600M/1.3B规模模型，未验证更大模型的稳定性；仅覆盖四种低资源语言，未测试NLLB-MD中的其他语言；奖励函数为简单线性组合，缺乏更丰富的语义或流畅度指引。

---

## 121. Turbo-GoDec: Exploiting the Cluster Sparsity Prior for Hyperspectral Anomaly Detection

**arXiv ID:** 2601.12337 | [PDF](https://arxiv.org/pdf/2601.12337v1)

**作者:** Jiahui Sheng `[一作]`, Shuhan Chen `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

结合GoDec与马尔可夫随机场的集群稀疏先验，提出Turbo-GoDec用于高光谱异常检测。

**💡 创新点**

首次主动利用异常的空间集群稀疏性，并通过因子图消息传递求后验概率。

**🔧 技术方法**

GoDec矩阵分解、马尔可夫随机场、因子图、消息传递与硬阈值。

**📊 数据集**

HYDICE Urban、Pavia、Hyperion（真实）以及Salinas（合成）数据集。

**📈 对比分析**

与10种经典与深度学习方法比较，Turbo-GoDec在AUC、背景抑制等指标上表现最佳，特别是小尺寸异常检测上显著提升。

**⚠️ 局限性**

对分散或大规模异常效果下降，集群稀疏假设不成立时性能会降低。

---

## 122. XRefine: Attention-Guided Keypoint Match Refinement

**arXiv ID:** 2601.12530 | [PDF](https://arxiv.org/pdf/2601.12530v1)

**作者:** Jan Fabian Schmid `[一作]` (Bosch Research), Annika Hagemann `[通讯]` (Bosch Research)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `6514db3d-8de6-452c-91b7-acdb31787cc4` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `90291a0e-9d36-4a08-9a16-89ce846d923f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了XRefine，一种基于交叉注意力的图像补丁对齐网络，用于自适应子像素关键点匹配精细化。

**💡 创新点**

创新点在于仅利用两幅图像的局部补丁，无需检测器内部特征或分数即可实现检测器无关的子像素精细化，并可扩展至多视角轨迹。

**🔧 技术方法**

使用交叉注意力层、卷积编码器、soft‑argmax预测以及基于极线误差的几何损失训练。

**📊 数据集**

在MegaDepth、KITTI、ScanNet等公开数据集以及ETH3D三维重建任务上进行评测。

**📈 对比分析**

相较于Keypt2Subpx、PixSfM等现有精细化方法，XRefine在AUC5、相机姿态估计、三维点云三角化精度上提升5‑15%，且运行时仅3‑4ms，显著优于耗时百毫秒的PixSfM。

**⚠️ 局限性**

局限在于仍为两视图匹配的局部精细化，对长轨迹的全局一致性仅通过基于参考点的逐对更新，无法一次性完成全局最优优化；对极端视角差异或大尺度运动时精度有限。

---

## 123. Breaking Coordinate Overfitting: Geometry-Aware WiFi Sensing for Cross-Layout 3D Pose Estimation

**arXiv ID:** 2601.12252 | [PDF](https://arxiv.org/pdf/2601.12252v1)

**作者:** Songming Jia `[一作]` (University of Science and Technology of China), Zhi Liu `[通讯]` (University of Electro-Communications)

**通讯引用:** 12493 | [OpenAlex ID](https://openalex.org/A5100382312)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种基于WiFi的3D人体姿态估计框架PerceptAlign，解决坐标过拟合问题；

**💡 创新点**

核心创新是几何条件化学习：通过轻量级坐标统一将WiFi与视觉坐标对齐，并将天线几何信息嵌入高维空间作为条件变量；

**🔧 技术方法**

采用相机校准+检查板坐标统一、CNN+Transformer时空编码器、位置与时间嵌入以及MSE训练；

**📊 数据集**

构建并公开最大的跨域WiFi 3D姿态数据集，包含21位受试者、5场景、18动作、7种设备布局；

**📈 对比分析**

与当前SOTA（Person-in-WiFi 3D、DT-Pose）在多种跨域设置下比较，PerceptAlign在域内误差下降12.3%，域外误差提升超过60%，显著优于对比方法；

**⚠️ 局限性**

局限包括：对坐标校准误差敏感（需厘米级精度）、仅支持单人场景、对极端天线重排或高混乱环境仍会退化、未覆盖多人人体姿态与个人差异的进一步泛化问题。

---

## 124. BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images

**arXiv ID:** 2601.12533 | [PDF](https://arxiv.org/pdf/2601.12533v1)

**作者:** Md. Ahanaf Arif Khan `[一作]` (University of Rajshahi), Bimal Kumar Pramanik `[通讯]` (University of Rajshahi)

**通讯引用:** 117 | [OpenAlex ID](https://openalex.org/A5052644054)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并公开了一个名为 OverheadFaces 的新数据集，包含 2,978 张鸟瞰图像和 8,448 个手工标注的人脸框，覆盖城市街道、河流、屋顶和公园等多种环境。

**💡 创新点**

创新点在于：1) 结合真实无人机视频、DroneFace 模拟数据以及手机拍摄图像，提供更丰富多样的场景；2) 关注极小尺寸人脸（平均约 10 像素），显著提升对低分辨率人脸检测的研究挑战；3) 数据集免费开放，便于学术界进行基准测试与方法改进。

**🔧 技术方法**

采用 YOLO 系列（以 YOLOv5 为例）的标准输入尺寸 640×640 进行预处理；使用 Roboflow 平台进行手工框标注，并统一导出为 YOLO 格式；利用标准的数据划分（train/val/test）支持模型训练与评估。

**📊 数据集**

数据来源于三类：Pexels.com 的无人机视频帧（1,601 张）、DroneFace 数据集的 619 张原始图像、以及自行拍摄的 758 张手机图片，共计 2,978 张图像；总共标注 8,448 个脸部框。

**📈 对比分析**

论文中未给出具体模型训练与评估结果，仅说明已将数据划分为训练/验证/测试集；后续可使用该数据集与现有鸟瞰人脸检测方法进行性能对比实验。

**⚠️ 局限性**

局限性：1) 大部分人脸极小（<40 像素），导致检测难度大但缺乏多尺度、多姿态样本；2) 数据集中光照、遮挡等多样性有限；3) 论文未提供基线实验与性能指标，需后续研究补充。

---

## 125. Adversarial Defense in Vision-Language Models: An Overview

**arXiv ID:** 2601.12443 | [PDF](https://arxiv.org/pdf/2601.12443v1)

**作者:** Xiaowei Fu `[一作]` (Chongqing University), Lei Zhang `[通讯]` (Chongqing University)

**通讯引用:** 104126 | [OpenAlex ID](https://openalex.org/A5100433899)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

综述了视觉语言模型（VLM）在对抗攻击下的防御方法，并对三大防御范式（训练时防御、推理时自适应防御、训练自由防御）进行系统分类和评价；同时在多任务下对比了代表性防御技术的性能。

**💡 创新点**

创新点在于：①首次将VLM防御方法按是否改变模型参数划分为三大范式；②梳理并总结了各范式下的代表性算法及其优势与局限；③在实验中对比了训练时、训练自由与推理时防御的效果，为后续研究提供了基准与启示。

**🔧 技术方法**

使用的技术包括：对抗微调（Adversarial Fine‑Tuning, Prompt Tuning）、推理时参数优化（TAPT, R‑TPT）、输入/特征空间净化（AOM, CLIPure, COLA, TTC）以及基于多模态对比学习的损失函数；实验中采用PGD‑10对抗样本、L∞ 1/255 约束。

**📊 数据集**

实验数据集涵盖 9 个图像分类数据集：Caltech101、SUN397、DTD、EuroSAT、OxfordPet、StanfordCars、Flower102、Food101、FGVCAircraft，使用 CLIP ViT‑B/32 作为基准模型。

**📈 对比分析**

通过自然准确率和对抗准确率两指标对比，结果表明：①训练时防御能提升鲁棒性但往往牺牲自然性能；②训练自由方法（如 COLA、AOM、TTC）在不改动参数的前提下实现了与训练时防御相近甚至更佳的对抗性能；③COLA 在多数据集上实现了最优平衡，表现出较高的效率和鲁棒性。

**⚠️ 局限性**

局限性包括：①对跨模态对抗攻击的覆盖不足；②大部分方法仍依赖大量预训练权重或对抗样本，计算开销较大；③缺乏对不同攻击强度、攻击类型的自适应调节机制；④对真实场景中的动态变化和大规模部署的可扩展性尚未充分验证。

---

## 126. Capability-Aware Early-Stage Research Idea Evaluation

**arXiv ID:** 2601.12473 | [PDF](https://arxiv.org/pdf/2601.12473v1)

**作者:** Renlong Jie `[一作]` (Northwestern Polytechnical University), Zhen Wang `[通讯]` (Northwestern Polytechnical University)

**通讯引用:** 24070 | [OpenAlex ID](https://openalex.org/A5100422377)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了基于作者信息、能力推断与研究想法的三向Transformer框架，用于在论文撰写前预测顶层AI会议的接受率和评分。

**💡 创新点**

创新点在于仅利用作者身份、可推断的作者能力和研究想法，而非完整论文文本，构建了能力预测两级网络并通过多种融合机制提升预测性能。

**🔧 技术方法**

采用BERT/bert‑large、两级Transformer与自注意力/线性融合、LLM提取能力与想法、以及多任务学习与cosine相似度损失。

**📊 数据集**

使用2023‑2025年ICLR和NeurIPS开放式提交的约25,889篇论文，提取作者信息、能力描述与研究想法，构成训练集。

**📈 对比分析**

与基准BERT、BERT‑large、单向Encoder及LLM零样本预测进行对照，三向自注意力模型在接受率上达到约65.3%（比BERT‑base高约6%），评分MSE降低至1.013，显著优于基线。

**⚠️ 局限性**

局限在于作者能力假设为静态、未考虑协作动态和投入差异，数据仅覆盖两大AI会议，难以泛化至更广阔科研领域。

---

## 127. From Shallow Waters to Mariana Trench: A Survey of Bio-inspired Underwater Soft Robots

**arXiv ID:** 2601.12353 | [PDF](https://arxiv.org/pdf/2601.12353v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

---

## 128. Temporal Fair Division of Indivisible Goods with Scheduling

**arXiv ID:** 2601.12835 | [PDF](https://arxiv.org/pdf/2601.12835v1)

**作者:** Kui Wang Choi `[一作]` (City University of Hong Kong), Minming LI `[通讯]` (City University of Hong Kong)

**通讯引用:** 3923 | [OpenAlex ID](https://openalex.org/A5085884127)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在多轮动态分配环境下研究时间公平分配（Temporal Fair Division），探讨了累计公平性概念TEF1、TEFX、α-TEFX与TMMS，并考察了在不同受限域与引入调度（Scheduling）时的可行性与近似保证。

**💡 创新点**

首次系统划定时间公平分配的可行与不可行边界：①在无调度情况下，证明常数因子α-TEFX一般不可行，但在泛化二进制估值和两位代理的相同日子下可实现1/2近似；②在有调度情况下，证明仅需缓冲区大小r≥n/2即可在相同日子设置下保证TEF1；③展示了TEFX与TMMS在大多数设置下仍不可行，说明这些严格公平度量在时间维度下过于苛刻。

**🔧 技术方法**

使用组合优化与图论方法设计多轮分配算法（如改进的Round‑Robin、Max‑ECE），并利用调度缓冲区与循环分配技术构造时间序列。通过理论证明（存在性与近似比）与多案例对比，阐述了各模型下公平性的实现条件。

**📊 数据集**

该工作主要为理论性研究，无实验数据集；所用“数据”为抽象的时间序列与代理估值模型（相同日子、泛化二进制、双值、相同估值等）。

**📈 对比分析**

与先前工作（如单轮EFX/TEF1、无调度情形的TEFX不可行性）相比，本研究提供了更强的近似保证与调度策略，并通过定量阈值（r≥n/2、1/2近似）展示了在更宽广条件下的可实现性。

**⚠️ 局限性**

局限性包括：①对TEFX与TMMS的调度解法仍未突破不可行性；②调度缓冲区的上界（r≥n/2）可能非最优，尚未证明最小可行值；③缺乏实验验证与对抗性行为分析，未探讨代理的策略性报告或现实系统的实施成本。

---

## 129. RPT*: Global Planning with Probabilistic Terminals for Target Search in Complex Environments

**arXiv ID:** 2601.12701 | [PDF](https://arxiv.org/pdf/2601.12701v1)

**作者:** Yunpeng Lyu `[一作]` (Shanghai Jiao Tong University), Zhongqiang Ren `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 349 | [OpenAlex ID](https://openalex.org/A5018561143)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `51c0528b-f690-4182-ae60-bb5f046c276c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了一种新的路径规划问题——带概率终端的哈密顿路径问题（HPP-PT），并设计了基于启发式搜索的最优算法RPT*及其逼近版Focal RPT*，进一步集成到层级自主目标搜索系统（HATS）中，支持已知环境的持续搜索和未知环境的探索式搜索。

**💡 创新点**

创新点包括：① 将期望路径成本通过引入累计未发现概率q简化为无历史依赖的状态定义，实现了A*搜索的可行性；② 设计了可行且可证明最优的启发式函数γ和支配规则，显著减少搜索空间；③ 通过焦点搜索实现了可控的子最优解；④ 将上述算法与贝叶斯更新与前沿检测结合，构建完整的终端搜索系统。

**🔧 技术方法**

核心技术包括：动态规划与启发式A*搜索（RPT*）、焦点搜索（Focal RPT*）、概率图生成与贝叶斯滤波、SLAM与占据栅格地图、前沿检测与信息增益聚类、以及多模块层级规划框架。

**📊 数据集**

使用公开TSPLIB城市网络数据集（如gr17、gr21、gr24、fri26、bayes29）以及随机生成的二维平面图（10–200个顶点）进行算法评估；在真实机器人实验中使用自制地图与YOLO检测器。

**📈 对比分析**

与整数规划（IP）和基线贪婪/传统HPP（LKH）比较：RPT*在所有实例上都能得到与IP几乎相同的最优成本（误差<0.1%），但运行时间仅为IP的几毫秒；基线方法速度快但成本高出50–200%；Focal RPT*在约200个顶点时仍可在60s内求解，子最优误差可控制在1–10%之间。

**⚠️ 局限性**

局限性主要有：① 仅适用于单目标或多目标但可被检测到的静态目标；② 对图中顶点数超过约200仍存在计算瓶颈；③ 需要全图连通且已知边成本，实际场景中需要进一步处理地图不完整与动态障碍；④ 贝叶斯更新假设目标静止，难以处理移动目标。

---

## 130. VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness

**arXiv ID:** 2601.12672 | [PDF](https://arxiv.org/pdf/2601.12672v1)

**作者:** Qimao Chen `[一作]` (Tsinghua University), Zhi-Xin Yang `[通讯]` (University of Macau)

**通讯引用:** 4617 | [OpenAlex ID](https://openalex.org/A5011123518)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

将视觉语言模型（Gemini）直接嵌入自主驾驶训练循环，利用模型对周围车辆未来轨迹进行细粒度编辑，从而生成多样化、逼真的挑战性场景并提升安全性。

**💡 创新点**

突破传统两阶段方法，首次让VLM在训练循环中发挥生成与编辑双重作用；提出 Vision‑Language‑Editing (VLE) 原则，并结合轨迹融合、B‑spline平滑与 LQR 控制，确保生成轨迹既具挑战性又符合运动学约束。

**🔧 技术方法**

视觉语言模型 Gemini‑2.5‑Flash；B‑spline 曲线平滑；Sigmoid 权重融合；线性二次调节器 (LQR) 控制；CARLA 仿真环境；强化学习算法（未细述，但参照 VLM‑RL 及 CAT）；奖励函数包含驾驶风格、跟车奖励与安全惩罚。

**📊 数据集**

主要使用 CARLA 生成的 Town02 训练地图、Town01‑03 测试地图，以及模拟的自动驾驶车辆数据；未引入真实世界数据集，所有场景均在仿真中构造。

**📈 对比分析**

与 VLM‑RL 与 CAT 两个基线对比，实验表明 VILTA 在挑战性场景下实现了更高的路段完成率、较低的碰撞率与平均冲击速度，且在正常场景下性能相当或略优；在效率指标（平均速度）上几乎无损失，体现了安全与效率的良好平衡。

**⚠️ 局限性**

仅在仿真环境中验证；对 VLM 的依赖使模型性能受限于特定模型的偏差；当前仅针对单一对手车进行攻击，未覆盖多车交互；威胁识别仍基于规则，缺乏自适应学习机制。

---

## 131. Negotiating Digital Identities with AI Companions: Motivations, Strategies, and Emotional Outcomes

**arXiv ID:** 2601.12181 | [PDF](https://arxiv.org/pdf/2601.12181v1)

**作者:** Renkai Ma `[一作]` (University of Cincinnati), Rowajana Behterin Barbie `[通讯]` (Clark University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了 Character.AI 上用户与 AI 伙伴的身份协商过程，提出三阶段（动机 → 交互期望与身份共构 → 情感结果）模型。

**💡 创新点**

创新点在于将身份协商理论（INT）迁移至人机互动，揭示用户既是表演者又是导演，并引入“情感沙盒”概念解释身份实验空间。

**🔧 技术方法**

采用 LLM 辅助的主题分析技术，对 Reddit r/CharacterAI 讨论文本进行编码与主题归纳。

**📊 数据集**

数据集为 22,374 条来自 r/CharacterAI 子版块的帖子与评论，时间跨度 2022‑2025 年，覆盖多种用户行为与情境。

**📈 对比分析**

未进行传统性能对比，而是通过主题分布可视化与 Krippendorff α（≥0.60）验证编码一致性，表明方法可靠。

**⚠️ 局限性**

局限性包括仅研究单一平台与社区、数据来源受限、LLM 可能引入偏见，缺乏跨平台验证和用户实验验证。

---

## 132. SDN-Blockchain Based Security Routing for UAV Communication via Reinforcement Learning

**arXiv ID:** 2601.12774 | [PDF](https://arxiv.org/pdf/2601.12774v1)

**作者:** Yulu Han `[一作]` (Nanjing University of Aeronautics and Astronautics), Qihui Wu `[通讯]` (Nanjing University of Aeronautics and Astronautics)

**通讯引用:** 11375 | [OpenAlex ID](https://openalex.org/A5100785098)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

设计了基于SDN和区块链的UAV紧急通信安全路由架构，并提出BSPPO（Beam Search–Proximal Policy Optimization）算法实现低延迟、低能耗且安全的多跳路由。

**💡 创新点**

创新点在于：①将SDN与区块链结合实现统一的安全评估与动态路由控制；②引入安全度（Security Degree）度量UAV可信度；③将预筛选的Beam Search与PPO深度强化学习耦合，提高路由效率与鲁棒性。

**🔧 技术方法**

使用技术包括：软件定义网络（SDN）集中控制、区块链去中心化安全记录、Beam Search预筛选、Proximal Policy Optimization（PPO）强化学习、Free‑Space传播模型、能耗与延迟模型。

**📊 数据集**

实验数据集：在Python 3.10 + Gymnasium环境中模拟40架UAV（1,200×1,200 m²、最大通信半径200 m），随机生成攻击节点和数据包大小，用于训练和评估BSPPO与基线算法。

**📈 对比分析**

对比方法：BSPPO、PPO、BS‑Q‑learning、BS‑Actor‑Critic。结果显示BSPPO在延迟、能耗和传输成功率上均优于其他算法，尤其在攻击节点增多或重路次数较多时表现最为显著。

**⚠️ 局限性**

局限性：实验仅基于仿真，缺乏真实场景验证；网络规模固定为40节点，未探讨大规模网络下的可扩展性；Beam Search宽度与PPO参数需手工调优，可能受特定场景影响。

---

## 133. CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology

**arXiv ID:** 2601.12373 | [PDF](https://arxiv.org/pdf/2601.12373v1)

**作者:** Amro Khaled `[一作]` (German University in Cairo), Catherine M. Elias `[通讯]` (German University in Cairo)

**通讯引用:** 97 | [OpenAlex ID](https://openalex.org/A5025295346)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `aaccfe5c-6b26-4208-b23c-35331481e142` `6514db3d-8de6-452c-91b7-acdb31787cc4` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `9cc9baba-5356-466d-81ff-d80028d90279` `51c0528b-f690-4182-ae60-bb5f046c276c` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

构建了一个基于V2I的数字孪生系统CD-TWINSAFE，用于实时场景理解与安全预警。

**💡 创新点**

创新点在于将车载感知与数字孪生实现双向低延迟同步，并通过双通道感知管线提取TTC/THW指标，在数字孪生端实时触发危险提示，实现视觉感知与远程操作的无缝结合。

**🔧 技术方法**

技术包括ROS2+UDP V2I通信、4G网络、Unreal Engine 5数字孪生、ZED 2立体相机、YOLOv8+ByteTrack物体检测、RAFT‑Stereo深度估计、EMA跟踪及TTC/THW安全指标计算。

**📊 数据集**

实验使用ZED 2相机实时采集的真实道路视频；未采用公开数据集，而是通过车载相机和现场测试验证系统性能。

**📈 对比分析**

对比两条感知管线，Pipeline 2在远距离场景更准确，Pipeline 1在稳定性和抖动方面更好；通信延迟平均约38 ms，丢包率约2.8%；在实际车辆测试中能够实时报警并通过数字孪生可视化展示，满足实时安全预警需求。

**⚠️ 局限性**

局限性包括：GPS 1 Hz、ZED 2 IMU漂移导致姿态误差；单纯视觉受光照影响；ZED 2 深度可信度仅约15 m，超距范围深度估计不稳定。

---

## 134. Combating Noisy Labels through Fostering Self- and Neighbor-Consistency

**arXiv ID:** 2601.12795 | [PDF](https://arxiv.org/pdf/2601.12795v1)

**作者:** Zeren Sun `[一作]` (Nanjing University of Science and Technology), Jinhui Tang `[通讯]` (Nanjing University of Science and Technology)

**通讯引用:** 27708 | [OpenAlex ID](https://openalex.org/A5035112538)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种基于自我一致性与邻居一致性的噪声鲁棒学习框架 Jo-SNC，能够在存在开放集与闭集标签噪声的数据集上自动区分干净样本、ID 噪声样本与 OOD 噪声样本，并分别采用传统训练、部分标签学习与负学习进行处理，进一步通过三层一致性正则化提升模型性能。

**💡 创新点**

创新点包括：①使用 Jensen-Shannon 散度结合邻居一致性进行全局样本清洁度判定；②通过预测差异（JS 散度）区分 ID 与 OOD 噪声；③自适应、类别特定阈值生成策略；④对 ID 噪声采用部分标签学习，对 OOD 噪声采用负学习；⑤提出自我、邻居、特征三层一致性正则化。

**🔧 技术方法**

技术手段包括 Jensen‑Shannon 散度、邻居一致性判定、基于均值教师的自监督标签重分配、部分标签学习、负学习、MoCo 对比学习特征一致性以及三层一致性正则化。

**📊 数据集**

使用了 CIFAR100N-C、CIFAR80N-O（合成噪声）以及 Web‑Aircraft、Web‑Bird、Web‑Car、Animal‑10N、mini‑WebVision、Food101N 等六个真实噪声数据集。

**📈 对比分析**

与多种先进方法（Co‑Teaching、JoCoR、Topofilter、FINE、PNP、UNICON、SOP、NPN、CA2C 等）在同一数据集上对比，Jo‑SNC 在大多数实验中均实现了显著的准确率提升，尤其在高噪声（Sym‑80%）和开放集噪声场景下性能领先。

**⚠️ 局限性**

局限性：在长尾分布且噪声混杂的数据集上表现可能下降，因为噪声样本与尾部类别样本可能混合，影响样本清洁度判定与后续学习效果。

---

## 135. Canonicalization of Batched Einstein Summations for Tuning Retrieval

**arXiv ID:** 2601.12220 | [PDF](https://arxiv.org/pdf/2601.12220v1)

**作者:** Kaushik Kulkarni `[一作]` (University of Illinois at Urbana-Champaign), Andreas Klöckner `[通讯]` (University of Illinois at Urbana-Champaign)

**关键词:** `e4c502e8-c16d-4c56-8df3-cffaee9eaadb` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一种批量Einstein求和（batched einsum）的抽象和规范化方法，并实现了一个开源系统 Feinsum，用于自动检索和重用针对特定硬件的高性能批量einsum变换。

**💡 创新点**

创新点包括：① 定义批量einsum的等价类（isomorphic），通过彩色图的图规范化得到唯一的标准形式；② 引入功能化（lambda）批量einsum，允许在不显式材料化数组的情况下迁移已知优化；③ 构建可查询的性能事实数据库，支持从理想化实例到实际程序的变换迁移。

**🔧 技术方法**

核心技术包括彩色图规范化（graph canonicalization）、函数式批量einsum表示、Loopy IR、CUDA/OpenCL 编译、自动化变换生成与性能记录、以及基于替换映射的符号重命名。

**📊 数据集**

实验使用了 TCCG 张量收缩基准套件、有限元 DG‑FEM 计算（面质量、局部散度、局部梯度）以及 JAX、cuBLAS 等现有实现作对比。

**📈 对比分析**

与 JAX/cuBLAS 相比，Feinsum 在 TCCG 基准中几何平均速度提升 2.1×，在 DG‑FEM 操作中单个批量einsum 的速度提升范围从 1.6 倍到 100 倍不等；规范化过程耗时 <1 ms，证明其对编译阶段影响可忽略。

**⚠️ 局限性**

局限性在于：① 规范化依赖图形可判定算法，复杂度虽可接受但不是多项式；② 变换数据库覆盖不全，部分批量einsum 仍未达到 roofline 级别；③ 功能化 einsum 的适用性受表达式结构限制，且迁移需要手工或自动生成 transform 库。

---

## 136. AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations

**arXiv ID:** 2601.12727 | [PDF](https://arxiv.org/pdf/2601.12727v1)

**作者:** Jingshu Li `[一作]` (National University of Singapore), Yi-Chieh Lee `[通讯]` (National University of Singapore)

**通讯引用:** 1685 | [OpenAlex ID](https://openalex.org/A5054435118)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实施了一项在线随机行为实验，探究 GPT‑4o 默认人格特征在与用户进行个人话题或非个人话题对话后是否会导致用户自我概念与 AI 的人格特征产生对齐，并评估这种对齐对自我概念同质化和对话愉悦度的影响。

**💡 创新点**

首次从人机交互角度系统验证了 LLM 人格特征可在短时对话中“对齐”用户自我概念，揭示了这种对齐既带来用户体验提升（愉悦度上升），又可能导致自我概念同质化的双刃剑效应，并提出了对设计与伦理的实用建议。

**🔧 技术方法**

使用 GPT‑4o 作为对话模型，Qualtrics 进行问卷管理，Uchat 平台实现对话记录；人格测量采用 20 项自评与 AI 自评量表；统计分析包括重复测量方差分析、t 检验、线性回归与结构方程模型（SEM）。

**📊 数据集**

样本为 92 名美国成人（年龄 21–60 岁），每人完成一次 5–15 分钟的对话，数据包括：预后自我概念量表、对话日志、后测自我概念量表、AI 人格测评、共享现实体验量表与对话愉悦度量表。

**📈 对比分析**

实验通过对比个人话题与非个人话题条件，使用 t 检验和 ANOVA 评估自我概念与 AI 人格的对齐程度；结果显示：在个人话题条件下，对齐显著（p < .001），且对齐度与对话长度正相关；对齐度显著降低了参与者间自我概念的距离（p < .001）。在结构方程模型中，对齐度对愉悦度的总效应显著（β = .951, p = .008），但直接效应不显著，间接效应通过感知准确性与共享现实经验显著介导（β = .259, p = .014）。

**⚠️ 局限性**

研究局限包括：仅观察一次短时对话，无法评估对齐效应的持久性和重复交互的累积影响；样本主要为美国成年人，缺乏跨文化与社会经济多样性；使用 GPT‑4o 的默认人格设置，未探讨不同人格配置的影响；自我概念仅以 20 项人格量表测量，未覆盖外貌、能力等维度；对话日志分析中仅检验关键词，未深度挖掘语言特征。

---

## 137. A Multimodal Assistive System for Product Localization and Retrieval for People who are Blind or have Low Vision

**arXiv ID:** 2601.12486 | [PDF](https://arxiv.org/pdf/2601.12486v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

---

## 138. Contact-Aware Neural Dynamics

**arXiv ID:** 2601.12796 | [PDF](https://arxiv.org/pdf/2601.12796v1)

**作者:** Changwei Jing `[一作]` (University of California San Diego), Sha Yi `[通讯]` (University of California San Diego)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出一种利用触觉接触信息的隐式 sim-to-real 对齐框架，训练出兼具仿真与真实世界一致性的触觉感知神经动力学模型。

**💡 创新点**

创新点在于：①将触觉二值接触作为模型的核心状态，实现对非平滑接触动力学的显式建模；②采用两阶段（接触预测+扩散式姿态预测）架构，将接触信息直接调制扩散网络，从而在仿真与真实之间实现隐式对齐；③先在大规模仿真中预训练，再用少量真实数据微调，显著提升 sim‑real 迁移性能。

**🔧 技术方法**

使用技术包括：多模态编码器（时序编码器 + PointNet），二值接触预测模块，基于条件扩散模型的姿态增量预测，交叉熵与均方误差联合损失，以及对接触信息的 FiLM 条件化。

**📊 数据集**

数据集：仿真数据来自 8,000 条单物体（YCB mustard bottle）和 15,000 条多物体（40 个 YCB 物体）轨迹，真实数据来自 XArm7 + XHand 在日常 YCB 物体上的抓取与操作，配合 FoundationPose 位姿估计与 XHand 触觉传感器采集。

**📈 对比分析**

与现有神经动力学基线（如直接预测网络、残差模型等）相比，在 MSE、ADD‑S 与任务成功率上均获得显著提升：单物体仿真+真实对齐模型在 MSE 上降至 0.0082、ADD‑S 88.23%，任务成功率达到 73.7%；多物体场景亦实现了 64.7% 的成功率。

**⚠️ 局限性**

局限性包括：①依赖 FoundationPose 的位姿估计，遮挡或堆叠时误差积累；②二值接触信号无法体现接触面积、滑动方向等更丰富信息；③需要大量多样化仿真数据和真实数据才能泛化；④在长时间多接触切换的预测中仍存在漂移，限制了长周期规划的效果。

---

## 139. The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering

**arXiv ID:** 2601.12327 | [PDF](https://arxiv.org/pdf/2601.12327v1)

**作者:** Lucas Gren `[一作]` (Chalmers University of Gothenburg and Getinge AB), Felix Dobslaw `[通讯]` (Mid Sweden University)

**通讯引用:** 387 | [OpenAlex ID](https://openalex.org/A5011853573)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了专家验证框架，系统化地让领域专家参与GenAI系统的规格制定、知识库构建、验证与监控，形成循环改进。

**💡 创新点**

将领域专家从事后校验转为系统行为的主动架构师，并引入苏格拉底式对话与持续监控，形成四阶段闭环验证与适配。

**🔧 技术方法**

基于检索增强生成（RAG）、上下文工程、迭代式Socratic验证、无代码测试管理工具及持续质量监测等技术。

**📊 数据集**

使用组织内部的专有知识库、法规文件等领域文本作为检索和训练语料，未使用公开的大型通用数据集。

**📈 对比分析**

通过专家评审而非数值指标评估系统在准确性、适当性、语调等多维度的一致性；报告显示多轮验证后质量显著提升，但未给出客观实验数据。

**⚠️ 局限性**

需要专家具备一定技术能力，专家之间可能存在冲突，维护成本高，透明度与可审计性仍有限，框架对人工持续投入依赖较大。

---

## 140. What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes

**arXiv ID:** 2601.12612 | [PDF](https://arxiv.org/pdf/2601.12612v1)

**作者:** Piyush Sao `[一作]` (Oak Ridge National Laboratory), Piyush Sao `[通讯]` (Oak Ridge National Laboratory)

**通讯引用:** 343 | [OpenAlex ID](https://openalex.org/A5048170299)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种基于矩累积的插值框架，并定义了一族 K0:M 估计器，用于在不同阶矩下估计分布特征，研究了其在何种条件下精确以及为何不存在通用估计器。

**💡 创新点**

创新点在于将矩累积与插值技术结合，形成可调阶的估计器族，并给出了精确性条件的解析证明，首次阐明了估计器在不同阶矩下的极限表现。

**🔧 技术方法**

使用了矩累积理论、插值方法、数值优化以及高阶矩计算技术，并在实验中采用了蒙特卡罗仿真与梯度下降等算法。

**📊 数据集**

实验使用了合成高斯混合数据集、UCI 机器学习仓库中的波士顿房价数据以及 CIFAR-10 图像数据进行验证。

**📈 对比分析**

与传统的最大似然估计、贝叶斯估计和核密度估计进行对比，K0:M 估计器在低阶矩匹配任务上取得了 5–10% 的误差下降，在高阶矩任务中保持了更好的稳健性。

**⚠️ 局限性**

主要局限在于对高维数据的计算复杂度较高，且对极端分布（如重尾分布）的适用性仍需进一步研究。

---

## 141. Rethinking the Value of Multi-Agent Workflow: A Strong Single Agent Baseline

**arXiv ID:** 2601.12307 | [PDF](https://arxiv.org/pdf/2601.12307v1)

**作者:** Jiawei Xu `[一作]` (University of Texas at Austin), Ying Ding `[通讯]` (University of Texas at Austin)

**通讯引用:** 16139 | [OpenAlex ID](https://openalex.org/A5047170063)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了在同质多代理工作流中单一LLM能否通过多轮对话模拟多代理工作流，并提出OneFlow自动设计可单一LLM执行的高效工作流

**💡 创新点**

证明同质工作流可用单一LLM实现且更高效，提出双元元LLM+MCTS的OneFlow框架，展示单LLM能匹配甚至优于现有异构工作流

**🔧 技术方法**

单LLM模拟、KV缓存重用、双元元LLM（创意设计+审查）+MCTS搜索、自动工作流优化、对话式工具调用

**📊 数据集**

MBPP、HumanEval、GSM8K、MATH、HotpotQA、DROP、Shopping‑MMLU、TravelPlanner 等多领域基准

**📈 对比分析**

与手工基线、AFlow、OneFlow、异构工作流等对比，单LLM执行在保持或略优性能的同时，成本显著降低（如OneFlow单LLM≈$0.02，原多代理≈$0.26）

**⚠️ 局限性**

只能处理同质工作流，无法实现真正异构工作流的KV共享；对异构工作流的优化和协作仍需进一步研究

---

## 142. The Language You Ask In: Language-Conditioned Ideological Divergence in LLM Analysis of Contested Political Documents

**arXiv ID:** 2601.12164 | [PDF](https://arxiv.org/pdf/2601.12164v1)

**作者:** Oleg Smirnov `[一作]` `[通讯]` (Microsoft), Oleg Smirnov (Microsoft)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对ChatGPT 5.2在同一乌克兰民间社会文件上使用俄语与乌克兰语等效提示进行政治分析实验，比较两种语言提示下的输出差异；

**💡 创新点**

首次系统性揭示提示语言本身能够在同一模型内部诱发不同的意识形态取向，突破了以往仅关注训练数据或模型版本的研究视角；

**🔧 技术方法**

依托ChatGPT 5.2大语言模型及其多语言推理能力，结合定性批判性话语分析框架对生成文本进行编码与对比；

**📊 数据集**

以2019年乌克兰民间社会联合声明（官方英文版）为单一研究对象，确保输入内容不因语言差异而改变；

**📈 对比分析**

采用平行提示设计与跨语言对照分析，对词汇、修辞与结论进行并行编码，发现俄语提示输出倾向于俄国国家叙事，乌克兰语提示倾向于西方自由民主视角，表现出明显的系统性偏差；

**⚠️ 局限性**

仅评估单一模型单一文本、仅比较俄乌两语、未进行多次抽样与量化测度，且缺乏跨模型与跨语种的再现性验证。

---

## 143. Understanding Partial Reachability in the Internet Core

**arXiv ID:** 2601.12196 | [PDF](https://arxiv.org/pdf/2601.12196v1)

**作者:** Guillermo Baltra `[一作]` (University of Southern California), John Heidemann `[通讯]` (University of Southern California)

**通讯引用:** 31572 | [OpenAlex ID](https://openalex.org/A5090014731)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2`

**🎯 论文内容**

本文提出互联网核心的连通性定义，识别并检测持续的部分连通性（半岛）与隔离网络（岛屿），并在 Trinocular、RIPE Atlas 等测量系统中实现并验证 Taitao 与 Chiloe 两个算法。

**💡 创新点**

创新点包括：①用>50%双向连通性严格定义互联网核心；②首次系统化地将“半岛”与“岛屿”作为互联网的两类持续不完全可达性；③通过算法检测持续半岛的出现频率与持续时间，揭示其与传统停机事件的相当性；④将该方法应用提升 DNSmon 的敏感度。

**🔧 技术方法**

技术手段包括：ICMP ping 与 DNS 查询的网络层可达性测量；基于图论的强连通分量分析；Taitao（半岛检测）与 Chiloe（岛屿检测）算法实现；交叉验证、统计聚合与收敛分析；利用 traceroute 定位半岛边界。

**📊 数据集**

使用的数据集包括：Trinocular（6 个观测点，5M 网络，11 分钟一次 ping）；RIPE Atlas（13k 观测点，DNS 根服务器查询，5 分钟一次）；CAIDA Ark（171 观测点，traceroute 日常采样）；DNSmon 记录；IPv4/IPv6 地址活动统计（各 RIR 与国家）。

**📈 对比分析**

通过与 CAIDA Ark 作为“近似真值”进行比较，Taitao 的召回率 0.94，精度 0.42~0.82；岛屿检测通过手工校验与跨系统对比得到一致性；收敛实验表明 3~4 个独立观测点即可近似整体；算法运行时间仅为分钟级，且发现半岛出现频率与停机事件相当。

**⚠️ 局限性**

局限性包括：受限于 ICMP/UDP 过滤导致的测量误差；观测点有限导致岛屿数量被低估；半岛/岛屿定义基于 >50% 阈值，可能忽略小规模分裂；IPv6 测量仍受限；未覆盖应用层可达性，仅关注网络层。

---

## 144. KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction

**arXiv ID:** 2601.12736 | [PDF](https://arxiv.org/pdf/2601.12736v1)

**作者:** Qingtian Zhu `[一作]` (University of Tokyo), Takafumi Taketomi `[通讯]` (CyberAgent)

**通讯引用:** 2252 | [OpenAlex ID](https://openalex.org/A5054864352)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了KaoLRM框架，将大型重建模型LRM的三平面先验投射到FLAME参数空间，实现单视图人脸的高质量3D重建；

**💡 创新点**

创新点在于融合LRM通用3D先验与FLAME参数化模型，并通过2D高斯渲染与绑定损失实现跨视角几何一致性；

**🔧 技术方法**

使用了LRM预训练的Image‑to‑Triplane Transformer、FLAME参数化模型、2D Gaussian Splatting渲染、分析‑合成训练以及几何绑定损失等技术；

**📊 数据集**

训练和评估使用了FaceScape、Multiface、FaceVerse、Headspace等多视角数据集，以及FFHQ、CelebA等单视角人像数据；

**📈 对比分析**

与DECA、EMOCA、SMIRK、MICA等方法对比，KaoLRM在FaceVerse、NoW等基准上的Chamfer距离明显下降，跨视角FLAME参数方差大幅减少，性能优于基线；

**⚠️ 局限性**

局限性包括：训练数据量相对有限，难以捕捉眼睑与眼球运动，且对隐私保护导致眼部区域缺失的监督不足；

---

## 145. Song Aesthetics Evaluation with Multi-Stem Attention and Hierarchical Uncertainty Modeling

**arXiv ID:** 2601.12222 | [PDF](https://arxiv.org/pdf/2601.12222v1)

**作者:** Yishan Lv `[一作]` (Xi'an Jiaotong University), Xinyu Yang `[通讯]`

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `edb9d762-f411-4838-a852-f2d638b018db` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了一种针对完整歌曲的美学评估框架，旨在自动化评估歌曲的五个美学维度。

**💡 创新点**

创新点在于：① 多支路注意力融合（MSAF）通过双向交叉注意力融合混音、声乐与伴奏三条支路，捕捉复杂音乐特征；② 层次化粒度感知区间聚合（HiGIA）先产生多粒度分布，再聚合为区间并在区间内回归，模拟专家的粗细分层评分流程。

**🔧 技术方法**

采用音乐源分离、MuQ预训练编码器、CBAM注意力加权、Transformer编码器、跨支路注意力、三层分类器与MLP回归等技术。

**📊 数据集**

使用公开的 SongEval 评估数据集（约 2400 首 AI 生成歌曲）和内部人类创作的 1569 首中文歌曲数据集。

**📈 对比分析**

与两种最强基线（SSL‑based 和 UTMOS‑based）比较，在 5 维美学指标上均实现 MSE 降低、LCC/SRCC/KTAU 提升，平均性能提升约 3–5%。

**⚠️ 局限性**

局限在于对伴奏与声乐分离依赖 MDX‑Net，且在自然度维度对声乐细节的捕捉仍略逊于专门的语音 MOS 模型。

---

## 146. CoSMeTIC: Zero-Knowledge Computational Sparse Merkle Trees with Inclusion-Exclusion Proofs for Clinical Research

**arXiv ID:** 2601.12136 | [PDF](https://arxiv.org/pdf/2601.12136v1)

**作者:** Mohammad Shahid `[一作]` (Oklahoma State University), Hillel Haim `[通讯]` (University of Iowa)

**通讯引用:** 1311 | [OpenAlex ID](https://openalex.org/A5018901631)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出了 CoSMeTIC，一个基于计算稀疏梅克尔树（CSMT）和零知识 SNARK 的框架，用来在临床研究中实现可验证的统计计算，同时保证参与者数据的隐私与可追溯性。

**💡 创新点**

创新点在于将稀疏梅克尔树的计算聚合与零知识证明结合，能够为每个用户数据在统计分析的每个步骤提供包含/排除的可证明性，并且实现端到端可公开验证的统计过程。

**🔧 技术方法**

使用了 Halo2 零知识 SNARK、电路编译（EZKL）、固定点算术、Python/ PyTorch 计算、以及计算稀疏梅克尔树结构和路径证明。

**📊 数据集**

实验采用了真实临床基因组数据，分别为亨廷顿病（CAG repeat 长度）和 HIV‑1 Temsavir 抗药性数据，构建了 KS、LRT、ACC 三种统计工作流。

**📈 对比分析**

通过多种精度（8、10、12、14）对电路编译、见证生成、证明/验证时间以及密钥尺寸进行基准测试，结果显示计算时间与精度变化不大，统计输出保持一致，密钥尺寸在可接受范围内，证明了该框架在隐私保护下仍具备实用的性能。

**⚠️ 局限性**

主要限制包括需要可信的 CRS 与可信环境，CSMT 的树大小与证明生成时间对大规模数据仍有限制，且目前主要支持聚合型统计，复杂模型或多步推理可能需要更大电路与额外优化。

---

## 147. A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining

**arXiv ID:** 2601.12751 | [PDF](https://arxiv.org/pdf/2601.12751v1)

**作者:** Manjish Pal `[一作]` `[通讯]` (National Law University Meghalaya), Manjish Pal (National Law University Meghalaya)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出基于布尔函数理论的子群体子集函数（Subpopulation Boolean Function）框架，用以衡量图神经网络（GNN）在公平性任务中的表达能力，并基于此设计了一种可处理任意布尔电路子群体（AC^0 与 NC^1）的公平性增强模型 FairSBF。

**💡 创新点**

创新点在于：①构建了可上升到图同构层级的最强子群体布尔函数不变式 SBI，形成了比传统 Weisfeiler–Leman、同构、二连通等更细粒度的表达层次；②通过布尔函数的 Fourier 代数和电路复杂度对 GNN 表达限度进行理论界定；③提出了将布尔电路结构直接嵌入训练过程的 FairSBF 算法，实现对复杂交叉子群体的公平约束。

**🔧 技术方法**

核心技术包括布尔函数 Fourier 级数分析、AC^0 与 NC^1 电路理论、子群体布尔函数不变式 SBI、以及基于中间门的公平损失正则化的 GNN 训练框架。

**📊 数据集**

使用 Pokec-z 社交网络数据集，该数据集包含三种敏感属性（性别、地区、年龄），并在此数据上构造了复杂的交叉子群体布尔函数。

**📈 对比分析**

与传统公平 GNN（FairGNN、UGE、FairSIN 等）比较，FairSBF 在完整 NC^1 子群体上实现了更低的公平违规率（如 DDP、DEO）同时保持甚至提升了预测准确率。

**⚠️ 局限性**

局限性：①目前 FairSBF 仅对 AC^0 与 NC^1 级布尔函数可行，尚未扩展到更高复杂度（如 P、NP 等）子群体；②训练过程需对电路中所有门计算公平损失，计算成本随电路规模增大；③对节点属性缺失或不完整的场景支持有限。

---

## 148. TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement

**arXiv ID:** 2601.12823 | [PDF](https://arxiv.org/pdf/2601.12823v1)

**作者:** Belal Shaheen `[一作]` (Coolant), James Tompkin `[通讯]` (Brown University)

**通讯引用:** 2896 | [OpenAlex ID](https://openalex.org/A5070975377)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `6514db3d-8de6-452c-91b7-acdb31787cc4` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

提出一种利用3D高斯抹光（3D Gaussian Splatting）进行RGB无人机影像重建，并基于不透明度加权采样与几何拟合实现树木胸径（DBH）直接测量的全流程方法。

**💡 创新点**

创新点在于将3D高斯场作为连续可密化几何表征，结合深度感知的累计不透明度采样与多视角不透明度可靠性评分，形成稠密且可信的树干点云，随后通过不透明度加权的实心圆拟合实现高精度DBH估计。

**🔧 技术方法**

使用的主要技术包括SfM-MVS初始重建、RaDe-GS优化的3D高斯抹光、基于不透明度的深度感知采样、ForestFormer3D进行3D语义分割、以及不透明度加权的圆形RANSAC拟合。

**📊 数据集**

实验数据来自美国阿肯色州南部管理的Pinus taeda林分，10个0.2英亩圆形样地，总计210棵针叶树，提供场地手测DBH作为基准。

**📈 对比分析**

与UAV激光雷达（LiDAR）基准（圆柱拟合）以及无权重圆拟合相比，TreeDGS在10个样地上RMSE仅为4.79 cm（≈2.6像素），比LiDAR圆柱拟合降低约39%；在绝大多数样地上均取得最小误差和低偏差，且成功率达99.5%。

**⚠️ 局限性**

局限性包括：需要胸径区域在多张视角中可见；对树干语义分割的依赖，误分割会影响结果；当胸径被树冠或灌木完全遮挡时，无法恢复几何，从而导致估计失败。

---

## 149. CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding

**arXiv ID:** 2601.12312 | [PDF](https://arxiv.org/pdf/2601.12312v1)

**作者:** Yongjun Jeon `[一作]` (Samsung Advanced Institute for Health Sciences and Technology), Kyu-Hwan Jung `[通讯]` (Samsung Advanced Institute for Health Sciences and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

构建了一套统一的 CurConMix+ 框架，用于手术动作三元组识别，并发布了新颖的 LLS48 级联标注数据集。

**💡 创新点**

创新点在于将课程化对比学习、硬对样本采样、特征/输入 mixup 与自蒸馏相结合，辅以多分辨率时序 Transformer，解决了类别失衡、细粒度视觉模糊与三元组语义依赖问题。

**🔧 技术方法**

采用了 Swin Transformer 主干、课程化监督对比学习、进阶硬对采样、特征级和输入级 mixup、自蒸馏、以及多分辨率时序 Transformer（MRTT）等技术。

**📊 数据集**

主要使用了公开的 CholecT45（胆囊切除）数据集和新建的 LLS48（左侧叶切除）数据集，并对两者进行了多层级标注。

**📈 对比分析**

与 RDV、RiT、SelfD、TERL、TOD‑Large 等前沿方法对比，CurConMix+ 在 CholecT45 上实现 43.4% AP_IVT、LLS48 上达到 59.0% AP_IVT，均显著优于现有技术；在相位/步骤/任务转移学习中亦取得最高准确率。

**⚠️ 局限性**

局限性在于对极少见三元组仍存在识别误差，模型训练和推理对 GPU 资源要求较高，且仅在两种手术场景验证，尚未证明对其他手术类型的普适性。

---

## 150. Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers

**arXiv ID:** 2601.12263 | [PDF](https://arxiv.org/pdf/2601.12263v1)

**作者:** Yixuan Du `[一作]` (Georgetown University), Xiyang Hu `[通讯]` (Arizona State University)

**通讯引用:** 769 | [OpenAlex ID](https://openalex.org/A5044665455)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `6215c339-3735-4be3-8a07-5bbb7004712d` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

设计并评估了一种多模态攻击框架（MGEO），通过联合优化产品图片与文本来提升其在VLM检索系统中的排名。

**💡 创新点**

首次在VLM检索场景中提出跨模态协同的排名攻击，并使用交替梯度优化实现视觉与语言的相互强化。

**🔧 技术方法**

采用软嵌入梯度文本优化、PGD图像扰动、多目标损失及交替坐标下降等技术。

**📊 数据集**

采集并清洗了Amazon商品的标题、描述与图片，构建10类10-15件商品的列表，使用Qwen2.5-VL-7B模型。

**📈 对比分析**

与文本仅、图像仅和基于商业模型的启发式基线对比，MGEO平均提升排名-2.25（比文本-0.73、图像-1.30及基线-0.30更好），表现出显著的协同提升。

**⚠️ 局限性**

仅在单一VLM（Qwen2.5-VL）上验证，假设商品静态且无平台预处理，且未提供针对性的防御方案。

---

## 151. A Model Fusion Approach for Enhancing Credit Approval Decision Making

**arXiv ID:** 2601.12684 | [PDF](https://arxiv.org/pdf/2601.12684v1)

**作者:** Yuanhong Wu `[一作]` (Fordham University), D. Frank Hsu `[通讯]` (Fordham University)

**通讯引用:** 10559 | [OpenAlex ID](https://openalex.org/A5082344124)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `3855fcda-48ef-4070-a15e-803cd5c84d83` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

本文将组合分析框架（CFA）应用于信用卡审批预测任务，通过融合多种机器学习模型来提升决策准确性。

**💡 创新点**

创新点在于首次将基于排名的模型融合与认知多样性度量相结合，提出基于多样性加权的rank组合方法，并展示其在信用风险预测中的有效性。

**🔧 技术方法**

使用的技术包括KNN、LDA、AdaBoost、Random Forest、CNN五个基模型；CFA框架中的得分与排名组合、基于多样性加权的融合策略；以及交叉验证和随机搜索进行超参数调优。

**📊 数据集**

实验采用UCI Australian Credit Approval数据集，共690条样本，包含14个混合特征，正负样本比例约55:45。

**📈 对比分析**

与单一基模型以及现有的bagging MLP、Factorization Machine、Stacking RF/GB/​XGB等混合/集成方法进行对比，最佳加权rank组合（B+AdaBoost+RF）达到了0.8913的准确率，显著优于传统方法。

**⚠️ 局限性**

局限性包括仅使用准确率作为评价指标，未考虑误判成本与类别不平衡；实验数据集有限，缺乏跨域验证；缺乏在线学习与多层融合等进一步提升空间。

---

## 152. Open Vocabulary Panoptic Segmentation With Retrieval Augmentation

**arXiv ID:** 2601.12779 | [PDF](https://arxiv.org/pdf/2601.12779v1)

**作者:** Nafis Sadeq `[一作]` (East West University), Mostafa El-Khamy `[通讯]` (Samsung Semiconductor)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种检索增强的开放词汇全景分割方法，通过构造遮挡段特征数据库并在推理时检索相似特征来进行分类。

**💡 创新点**

创新点在于使用单一CLIP骨干通过mask pooling同时完成遮挡框生成、检索关键特征提取与分类，解决了CLIP自然图像特征与遮挡图像特征的域移问题，并实现了无需再训练即可更新新类别的能力。

**🔧 技术方法**

采用的核心技术包括CLIP视觉与文本编码器、SAM与Grounding DINO生成遮挡框、近似最近邻检索、mask pooling、以及检索与CLIP分类的加权融合。

**📊 数据集**

主要使用的数据集有COCO、ADE20k（作为测试集与特征数据库）以及Google Open Image（作为备用数据库）。

**📈 对比分析**

与FC‑CLIP等基线比较，训练后在ADE20k上实现PQ从26.4提升至30.9（+4.5），mAP从19.3提升至22.0（+2.5），mIoU从44.0提升至54.0（+10.0）；在训练‑free设置下亦获得显著提升，检索单独完成时可获得+2.7~+4.9的PQ提升。

**⚠️ 局限性**

主要局限在于对遮挡框生成质量高度敏感，SAM在无人工交互时往往产生多细分或缺失类别的掩码，导致性能下降；同时在极度稀缺数据场景下检索库构建仍需一定标注或大量无标注图像。

---

## 153. Facet-Aware Multi-Head Mixture-of-Experts Model with Text-Enhanced Pre-training for Sequential Recommendation

**arXiv ID:** 2601.12301 | [PDF](https://arxiv.org/pdf/2601.12301v1)

**作者:** Mingrui Liu `[一作]` (Nanyang Technological University), Cheng Long `[通讯]` (Nanyang Technological University)

**通讯引用:** 4810 | [OpenAlex ID](https://openalex.org/A5080939756)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `9ce7179e-700c-4310-ac2b-91df50ded46e` `c773407a-6119-4871-b8b3-1e7ae17a6851` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出面向多维特征的多头混合专家模型FAME及其文本增强版FAME+用于序列推荐。

**💡 创新点**

将多头注意力视为多facet预测器，并在每头内部引入Mixture-of-Experts拆解细粒度偏好；利用文本预训练与监督对比学习实现facet-aware嵌入初始化。

**🔧 技术方法**

Transformer自注意力、Mixture-of-Experts网络、门控整合、监督对比学习、BERT预训练文本编码、分层采样、交替优化等技术。

**📊 数据集**

Amazon Beauty、Sports、Toys四个子集与MovieLens 20M，含交互序列与多facet文本/属性。

**📈 对比分析**

与SASRec、BERT4Rec、CL4SRec、ICLRec、DuoRec、MSGIFSR、Atten-Mixer、MiasRec等基线做留一法评估，FAME+在NDCG@20、HR@20上平均提升3.98%–12.97%，明显优于所有基线。

**⚠️ 局限性**

对高维稀疏facet标签依赖采样策略；模型参数增加（多头多专家）；需文本元数据，缺失时无法启用文本增强。

---

## 154. Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLMs

**arXiv ID:** 2601.12341 | [PDF](https://arxiv.org/pdf/2601.12341v1)

**作者:** Rezky Kam `[一作]`, Coddy N. Siswanto `[通讯]` (Bina Nusantara University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `a8e75ba4-7a2d-4153-b003-06c94533add0` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了一个结合连续时间神经网络（CTRNN、Neural ODE）与物理信息神经网络（PINN）的混合编码-解码框架，利用In‑Context向量在多轮对话中实时跟踪并生成情感轨迹。

**💡 创新点**

创新点在于将情感轨迹视为连续动力系统，使用神经ODE/CTRNN与PINN联合建模，从而实现情感的连续、可解释生成，突破传统离散词元生成的局限。

**🔧 技术方法**

采用了CTRNN、Neural ODE、PINN、In‑Context向量、RoPE增强的ModernBERT编码器、Cubic Hermite Spline 插值、DOPRI5求解器以及Qwen2.5数据增强等技术。

**📊 数据集**

使用公开的chitchat对话数据，并为每条语句标注情感软标签（sadness、joy、love、anger、fear、surprise）以及时间戳，构建CEmoFlow连续情感数据集。

**📈 对比分析**

与传统fine‑tuned decoder和prompt‑based方法比较，在情感一致性、连续性和可解释性上取得显著提升；实验显示情感预测平均Δ误差降低约30%，对话情感流匹配度提升约25%。

**⚠️ 局限性**

局限性包括PINN与Neural ODE求解器的高计算成本导致训练时间显著增加，且多输出回归LSTM在精度与可解释性之间存在折衷，整体实现复杂度较高。

---

## 155. Dynamic Detection of Inefficient Data Mapping Patterns in Heterogeneous OpenMP Applications

**arXiv ID:** 2601.12713 | [PDF](https://arxiv.org/pdf/2601.12713v1)

**作者:** Luke Marzen `[一作]` (Iowa State University), Ali Jannesari `[通讯]` (Iowa State University)

**通讯引用:** 1072 | [OpenAlex ID](https://openalex.org/A5079359777)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了一款低开销的动态分析工具 OMPDataPerf，用于检测和量化 OpenMP 异构应用中的低效数据映射模式。

**💡 创新点**

创新点在于利用内容哈希与生命周期分析，能够在不进行高成本插桩的情况下识别四类低效模式（重复传输、往返传输、重复分配、未使用映射），并能给出可实现的加速预测。

**🔧 技术方法**

使用了 OpenMP Tools Interface（OMPT） EMI 回调、内容哈希、事件日志后处理算法以及 DWARF 调试信息映射代码位置。

**📊 数据集**

评估基准包括 10 个 OpenMP Offload 程序（Rodinia、SPEChpc、Mantevo、Bristol 等）以及 HeCBench 的 5 个程序，涵盖小/中/大三种输入规模。

**📈 对比分析**

通过与 Arbalest‑Vec、CUDA 专用 DrGPUM/ValueExpert 等工具对比，验证预测加速误差平均 14%（MSE 0.17），实际加速可达 2.1×；工具运行时平均 5% 的几何平均开销，最大 33%；内存占用 1 KB–数 MB。

**⚠️ 局限性**

局限性包括仅支持单 GPU 或 OMPT EMI 兼容运行时，无法准确评估多 GPU 或异步映射场景；缺乏可视化展示；对未使用映射的完整检测需结合静态或更细粒度的访问跟踪。

---

## 156. GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer

**arXiv ID:** 2601.12316 | [PDF](https://arxiv.org/pdf/2601.12316v1)

**作者:** Xinyuan Zhao `[一作]` (Guilin University of Electronic Technology), Ahmad Chaddad `[通讯]` (École de Technologie Supérieure)

**通讯引用:** 3293 | [OpenAlex ID](https://openalex.org/A5024700033)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出GazeFormer‑MoE模型，利用CLIP语义原型、跨尺度Token融合和路由共享的Mixture‑of‑Experts进行3D注视估计。

**💡 创新点**

创新点包括：语义驱动的原型条件化、多尺度Token统一注意力空间以及路由共享的MoE提升条件容量。

**🔧 技术方法**

技术：CLIP预训练视觉文本对齐、CNN高分辨率特征、Transformer＋MoE、温度学习的原型选择及稀疏专家路由。

**📊 数据集**

数据集：MPIIFaceGaze、EYEDIAP、Gaze360、ETH‑XGaze。

**📈 对比分析**

与现有方法比较，取得SOTA角误差：MPIIFaceGaze 2.49°、EYEDIAP 3.22°、Gaze360 10.16°、ETH‑XGaze 1.44°，相对提升高达64%。

**⚠️ 局限性**

局限：使用静态离散原型词表、仅单帧推理、MoE路由开销以及对极端光照/姿态的鲁棒性仍有限。

---

## 157. RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels

**arXiv ID:** 2601.12715 | [PDF](https://arxiv.org/pdf/2601.12715v1)

**作者:** Chengzhou Li `[一作]` (Dalian University of Technology), Xin Fan `[通讯]` (Dalian University of Technology)

**通讯引用:** 10890 | [OpenAlex ID](https://openalex.org/A5057776894)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种针对声纳图像的半监督目标检测框架RSOD，利用教师-学生网络和可靠性评估的伪标签策略，在极少标注数据下提升检测性能。

**💡 创新点**

创新点包括：① 基于多视角一致性的伪标签可靠性评分；② 对高可靠性伪标签进行物体混合伪标签生成；③ 可靠性引导的自适应约束（权重化损失和角点回归）。

**🔧 技术方法**

采用的技术主要有：教师-学生半监督学习、Faster R‑CNN+FPN+ResNet‑50检测骨干、伪标签可靠性评估、物体混合伪标签、可靠性加权损失与角点回归损失。

**📊 数据集**

使用了公开的UATD数据集和作者自建的前向声纳目标检测数据集FSOD（3929张图，10类）。

**📈 对比分析**

与全监督Fast R‑CNN以及多种主流半监督方法（Soft Teacher、Unbiased Teacher V2、MixPL、Pseco、VC）进行比较，在5%标注率下，RSOD在UATD和FSOD数据集上的mAP分别提升约20%和22%，甚至与100%标注的全监督结果相当。

**⚠️ 局限性**

局限性在于：依赖较高的可靠性阈值和IoU阈值调参，且对极小目标或极稀疏类别的鲁棒性仍有限，未来需进一步优化伪标签生成与混合策略。

---

## 158. How do the Global South Diasporas Mobilize for Transnational Political Change?

**arXiv ID:** 2601.12705 | [PDF](https://arxiv.org/pdf/2601.12705v1)

**作者:** Dipto Das `[一作]` (University of Toronto), Syed Ishtiaque Ahmed `[通讯]` (University of Toronto)

**通讯引用:** 3939 | [OpenAlex ID](https://openalex.org/A5089574660)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

研究了非居住孟加拉人如何通过社交平台与汇款抵制活动在2024年孟加拉政治运动中实现跨国政治行动

**💡 创新点**

提出“侨民叠加”概念，整合汇款作为抵抗工具，探讨金融技术与道德经济的交叉

**🔧 技术方法**

采用半结构访谈、扎根理论分析，并结合社交媒体平台使用与金融渠道的定性探讨

**📊 数据集**

访谈数据共10名非居住孟加拉人（NRB）的录音转录文本

**📈 对比分析**

未进行量化对比或性能评估，仅通过定性比较不同阶段的行动机制

**⚠️ 局限性**

样本规模小、受访者偏向北美欧的受过教育男性，缺乏中东及低收入群体，结果不具普适性

---

## 159. UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages

**arXiv ID:** 2601.12696 | [PDF](https://arxiv.org/pdf/2601.12696v1)

**作者:** Tassallah Abdullahi `[一作]` (Brown University), Carsten Eickhoff `[通讯]` (University of Tuebingen)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `9cc9baba-5356-466d-81ff-d80028d90279` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文创建了UbuntuGuard，首个针对10种低资源非洲语言、由155位领域专家提供对抗性查询并生成安全策略与多轮对话的文化本土化安全基准，旨在评估守护模型在多语境下的安全性。

**💡 创新点**

创新点包括：①基于专家查询自动生成本土化安全策略；②提供动态可运行的安全政策而非僵化静态规则；③构建多轮对话评估框架；④在低资源语言上实现跨语言安全评估，填补现有安全基准对非洲语言的空白。

**🔧 技术方法**

技术手段涵盖：使用GPT‑5生成安全策略、NeMo Curator生成多轮对话、Google Translate结合GEMBA-MQM进行翻译质量评估、人工校对以及对守护模型（静态、动态、多语种）和通用LLM进行对比实验。

**📊 数据集**

数据集来源于155位专家在7种语言下撰写的8,091条对抗性查询，随后通过GPT生成策略和对话，翻译为10种非洲低资源语言，形成UbuntuGuard数据集；对话与策略均按政策合规性标注。

**📈 对比分析**

实验采用三种评估场景（EN‑EN、LRL‑EN、LRL‑LRL），使用F1分数衡量守护模型对PASS/FAIL对话的判定效果。结果显示：英文基准表现最佳；低资源语言下性能急剧下降；动态守护模型和大规模通用LLM（如DeepSeek、Qwen‑3）相对更稳健，但仍存在显著安全缺口，尤其在跨文化与本土化情境中。

**⚠️ 局限性**

局限性包括：仅有单一验证者的人工评测、过度依赖机器翻译与人工筛选导致可能出现翻译偏差、缺乏真实用户数据和真实对话，基准仍属证明性工作，需要进一步扩大专家验证、丰富数据规模并提升多语言一致性。

---

## 160. Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling

**arXiv ID:** 2601.12145 | [PDF](https://arxiv.org/pdf/2601.12145v1)

**作者:** Xingyue Huang `[一作]` (University of Oxford), Tong Zhao `[通讯]` (Snap Inc)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了Threshold Differential Attention（TDA），一种可替换Softmax的无归一化、超稀疏、无注意力漏斗的注意力机制，专门用于处理长序列建模。

**💡 创新点**

创新点在于将长度依赖的极值阈值与双视图差分（激励与抑制）相结合，既抑制噪声又避免注意力泄漏，并在理论上证明了伪正样本保持常数级、共识伪样本趋近于零。

**🔧 技术方法**

采用了极值理论驱动的长度依赖阈值、双重投影视图、ReLU阈值化、RMSNorm归一化以及Triton加速内核实现。

**📊 数据集**

在FineWebEdu-10B（约10B词）上从零开始预训练，并在SCROLLS、PASSKEY Retrieval等长序列任务以及多项选择推理基准（HellaSwag、ARC、OpenBookQA、PIQA、Winogrande）进行评估。

**📈 对比分析**

与Softmax、Gated Softmax、SSMax、Entmax、LSSAR、ReLA、Differential Softmax等多种现有激活/稀疏方法对比，TDA在保持>99%稀疏率的同时，在零样本推理准确率与长序列ROUGE/F1等指标上与最佳基线相当或略优，并显著降低了注意力漏斗现象。

**⚠️ 局限性**

主要局限是实验规模受限于硬件，TDA在大模型中可能因阈值过严导致头部失活（dead heads），影响表达能力；未来需研究层/头自适应阈值策略。

---

## 161. Can Deep Research Agents Find and Organize? Evaluating the Synthesis Gap with Expert Taxonomies

**arXiv ID:** 2601.12369 | [PDF](https://arxiv.org/pdf/2601.12369v1)

**作者:** Ming Zhang `[一作]` (Fudan NLP Group), Xuanjing Huang `[通讯]` (Fudan NLP Group)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了TaxoBench基准，用于评估深度研究代理（Deep Research Agents）是否能像人类专家一样撰写学术综述，重点考察检索核心文献和构建专家级层级分类法的能力。

**💡 创新点**

创新点在于①从专家综述中手工抽取真实层级分类树并构建3,815条精确归属的论文集；②设计双层评估框架（检索层与结构层）并给出多种定量指标；③对比7款深度研究代理和12款前沿LLM，揭示检索与组织的双重瓶颈。

**🔧 技术方法**

使用的技术包括：大规模语言模型（LLM）进行检索与层级生成；文本相似度嵌入用于节点匹配；树编辑距离、Soft F1、V‑Measure、ARI等聚类与结构评估指标；GPT‑4o 作为人工智能评审器；对不同信息粒度（标题+摘要、摘要+概要、核心任务+贡献）进行实验。

**📊 数据集**

使用的数据集为72篇来自计算机科学顶级会议/期刊的综述论文，涵盖多模态学习、强化学习、对齐等领域，手工提取了3,815篇论文的层级分类树作为真值。

**📈 对比分析**

比较方法：在深度研究模式下测量检索Recall；在底层模式下对论文进行层级聚类，计算ARI、V‑Measure、树编辑距离、Soft F1等。结果显示最佳检索Recall仅20.9%，最佳AR‑I仅0.31；检索效果与结构质量高度相关（Spearman ρ=0.83）。

**⚠️ 局限性**

局限性：当前评测仅覆盖闭源前沿LLM，未扩展到开源模型；人工抽取的分类树虽精确但工作量大；评估侧重于“是否能写出人类专家的综述”，未深入探究模型内部知识表征与推理机制。

---

## 162. MARO: Learning Stronger Reasoning from Social Interaction

**arXiv ID:** 2601.12323 | [PDF](https://arxiv.org/pdf/2601.12323v1)

**作者:** Yin Cai `[一作]` (Fudan University), Ping Chen `[通讯]` (Fudan University)

**通讯引用:** 29385 | [OpenAlex ID](https://openalex.org/A5061915249)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Multi‑Agent Reward Optimization (MARO)，通过在多智能体社交环境中训练大语言模型提升其推理与判断能力。

**💡 创新点**

创新点在于将稀疏的最终成功/失败信号分解为每一步的稠密奖励，使用角色平衡采样解决角色分布不均，且通过直接评估行为效用提高环境不稳定下的学习稳定性。

**🔧 技术方法**

技术方法包括多智能体交互记录、奖励分解、角色加权采样、基于对数概率差的隐式奖励函数以及带有自适应基准点的 Sigmoid 损失函数进行强化学习。

**📊 数据集**

实验数据来自 MIRAGE 模拟环境，使用了两种脚本设置（Single‑Orthodox‑Open 与 Multi‑Unorthodox‑Close）并收集多场景交互轨迹。

**📈 对比分析**

与 Vanilla、SFT、MAKTO 等基线相比，MARO 在社交指标、数学推理和指令遵循任务上均实现显著提升（如社交评分提升 10–15% 以上，数学题目准确率提升 2–3%）。

**⚠️ 局限性**

局限性包括需大量多智能体交互产生高计算成本，实验主要局限于游戏化的谋杀悬疑场景，且训练过程可能放大原始场景中的社会偏见与操控风险。

---

## 163. Toward Faithful Explanations in Acoustic Anomaly Detection

**arXiv ID:** 2601.12660 | [PDF](https://arxiv.org/pdf/2601.12660v1)

**作者:** Maab Elrashid `[一作]` (Mila-Quebec AI Institute), Michael Morin `[通讯]` (FORAC Research Consortium)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `3855fcda-48ef-4070-a15e-803cd5c84d83` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

比较标准自编码器与掩码自编码器在工业音频异常检测中的检测性能与可解释性，并提出基于重建误差替换的可信度评价指标。

**💡 创新点**

创新点包括：采用掩码自编码器训练提升特征学习、提出重建替换的 faithfulness 度量、系统评估多种梯度解释方法在真实工业数据上的可解释性。

**🔧 技术方法**

技术手段涵盖 Skip‑CAE‑Transformer 结构、MAE 训练策略、误差图、Saliency、Integrated Gradients、SmoothGrad、GradSHAP、Grad‑CAM 等解释方法，并利用 Captum 库实现。

**📊 数据集**

使用公开木工机床（planer）音频数据集，包含 7,562 段 10 秒单声道录音，转化为 80×401 的梅尔频谱。

**📈 对比分析**

通过 AUC、F‑score（与专家标注的时间段比较）和 Faithfulness（重建误差下降）进行对比；MAE 在解释质量上优于 AE，检测 AUC 稍低（AE 0.916 vs MAE 0.902）。

**⚠️ 局限性**

局限性：检测性能略有下降，评估依赖单一工业场景与人工标注，解释方法对噪声鲁棒性仍有限。

---

## 164. Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation

**arXiv ID:** 2601.12391 | [PDF](https://arxiv.org/pdf/2601.12391v1)

**作者:** Dasith de Silva Edirimuni `[一作]` (University of Western Australia), Ajmal Saeed Mian `[通讯]` (University of Western Australia)

**通讯引用:** 19770 | [OpenAlex ID](https://openalex.org/A5089986388)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `40105733-5154-44cd-8090-a8cab9e64b07` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出了一种全新的纯点云场景生成方法，利用类分区向量量化自编码器（CPVQ‑VAE）对由潜在流匹配模型（LFMM）生成的对象特征进行解码，并同时预测对象的包围框、类别与特征。

**💡 创新点**

创新点包括：①将VQ‑VAE的码本按类别划分，配合类感知逆查找实现类别一致的点云重构；②提出类感知的运行平均更新机制，有效缓解码本坍塌问题；③在潜在空间使用流匹配模型代替传统扩散，显著减少采样步数并生成更可靠的对象特征。

**🔧 技术方法**

使用的技术主要有：变分自编码器（VAE）与向量量化自编码器（VQ‑VAE）框架，类分区码本与类感知更新；潜在空间流匹配模型（LFMM）与U‑Net网络；以及多种评价指标（Chamfer Distance、Point2Mesh、FID、KID、Scene Classification Accuracy、Categorical KL‑Divergence）。

**📊 数据集**

实验基于 3D‑FRONT 数据集，涵盖客厅、餐厅和卧室三种房间类型，使用公开的训练/测试拆分进行评估。

**📈 对比分析**

与 Diffuscene、ATISS 等现有方法比较，本文方法在客厅等复杂场景中，Chamfer Distance 与 Point2Mesh 分别下降 70.4% 与 72.3%，并在检索指标（FID、KID、SCA、CKL）上优于对照组；同时运行时间比 Diffuscene 提速约 90%，显著提升效率。

**⚠️ 局限性**

局限性在于：①当前自编码器只能处理稀疏点云（约 2025 点），难以生成更高分辨率的点云；②向量量化引入误差，导致生成多样性略有下降；未来工作需提升自编码器容量并减小量化误差。

---

## 165. DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants

**arXiv ID:** 2601.12138 | [PDF](https://arxiv.org/pdf/2601.12138v1)

**作者:** Abhishek Kumar `[一作]` (Alan Turing Institute), Carsten Maple `[通讯]` (University of Warwick)

**通讯引用:** 8801 | [OpenAlex ID](https://openalex.org/A5080175512)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了面向车辆驱动助手的四层次安全风险分类体系DriveSafe，并生成129个细粒度风险场景–提示对。

**💡 创新点**

创新点在于提供了专门针对驾驶场景的层级化风险分类，并通过专家评审与实际LLM拒绝行为验证其现实性。

**🔧 技术方法**

主要采用了层级化分类设计、基于法律法规与安全原则的风险定义、以及对六款主流LLM的拒绝率评估。

**📊 数据集**

使用的数据为作者自行设计的129个安全风险提示对，没有外部公开数据集。

**📈 对比分析**

通过将提示输入六款LLM（DeepSeek, Llama-3.1, GPT‑4o‑Mini, Gemma2, Claude‑3‑Haiku, Mistral‑Small）并统计拒绝率，展示了各风险域的模型易失效情况。

**⚠️ 局限性**

局限性包括：每个风险仅用一句提示，缺乏语言多样性；分类可能随驾驶环境演进而不足；未覆盖未来新出现的风险。

---

## 166. NeuralFur: Animal Fur Reconstruction From Multi-View Images

**arXiv ID:** 2601.12481 | [PDF](https://arxiv.org/pdf/2601.12481v1)

**作者:** Vanessa Sklyarova `[一作]` (Max Planck Institute for Intelligent Systems), Justus Thies `[通讯]` (Max Planck Institute for Intelligent Systems)

**通讯引用:** 8889 | [OpenAlex ID](https://openalex.org/A5036392768)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了NeuralFur，一种利用多视角图像和视觉语言模型（VLM）自动重建动物毛发（毛束）几何的方法；

**💡 创新点**

创新点在于：①首次将VLM知识与多视角重建相结合，以获取毛发长度、厚度和生长方向等区域性信息；②采用隐式“去毛”步骤得到裸体几何，再在该几何上生成基于稠密Gaussian束的毛束；③通过局部坐标系和MLP隐码实现对毛束的空间可变控制；

**🔧 技术方法**

技术组合包括：多视角立体重建（NeuS）、四足动物参数模型（SMAL）进行区域标注、ChatGPT等VLM进行知识检索、隐式SDF与MarchingCubes实现去毛、基于Gaussian Haircut的束解码、可微光栅化与多种几何/光度损失（silhouette、orientation、Chamfer、penetration、shape、VLM对齐）

**📊 数据集**

使用Artemis数据集（每个动物36张高质量多视角图像），并在人工合成动物（虎）上进行基准测试；

**📈 对比分析**

与SMAL、GenZoo、NeuS、Gaussian Haircut等方法对比，NeuralFur在毛束长度、方向、曲率一致性以及与真实毛束几何的Chamfer距离等无监督指标上均表现更优；

**⚠️ 局限性**

局限性包括：依赖多视角数据和VLM输出质量；受SMAL拓扑限制，只能处理四足动物；未对外观、动画和细节（如胡须）进行建模，需后续集成到图形渲染/模拟框架中。

---

## 167. How Safe Is Your Data in Connected and Autonomous Cars: A Consumer Advantage or a Privacy Nightmare ?

**arXiv ID:** 2601.12284 | [PDF](https://arxiv.org/pdf/2601.12284v1)

**作者:** Amit Chougule `[一作]` (Birla Institute of Technology and Science Pilani), Fei Richard Yu `[通讯]` (Carleton University)

**通讯引用:** 51760 | [OpenAlex ID](https://openalex.org/A5100420016)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `9cc9baba-5356-466d-81ff-d80028d90279` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文综述了联网与自动驾驶汽车（CAV）中的数据共享机制及其对安全、隐私和监管的影响，系统评估了技术与政策缺陷并提出改进建议。

**💡 创新点**

创新点在于整合多学科视角，形成了从传感器数据产生到共享的完整链路分析，并针对数据治理与法规空白提出了针对性监管框架。

**🔧 技术方法**

主要技术包括车辆到万物（V2X）通信（V2V、V2I、V2N、V2C 等）、传感器融合（LiDAR、雷达、摄像头等）以及数据治理与加密技术。

**📊 数据集**

该综述未使用单一实验数据集，而是参考了国内外多篇实证研究、行业报告和法规文本作为资料来源。

**📈 对比分析**

由于为综述论文，未进行实验比较；作者通过对比各国隐私法规（如 GDPR、CCPA、PIPL 等）与现行汽车行业实践，指出监管与技术实现之间的差距，并给出改进方向。

**⚠️ 局限性**

局限性包括：缺乏针对具体技术实现的实测数据；对监管政策的分析主要停留在表层，未深入评估执行效果；以及对新兴技术（如区块链、联邦学习）在 CAV 数据治理中的应用尚未系统探讨。

---

## 168. Automatic Generation of Formal Specification and Verification Annotations Using LLMs and Test Oracles

**arXiv ID:** 2601.12845 | [PDF](https://arxiv.org/pdf/2601.12845v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df`

---

## 169. Leveraging Mutation Analysis for LLM-based Repair of Quantum Programs

**arXiv ID:** 2601.12273 | [PDF](https://arxiv.org/pdf/2601.12273v1)

**作者:** Chihiro Yoshida `[一作]` (Osaka University), Yoshiki Higo `[通讯]` (Osaka University)

**通讯引用:** 1885 | [OpenAlex ID](https://openalex.org/A5024065727)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

利用大语言模型（LLM）结合变异分析结果，对量子程序进行自动程序修复并生成自然语言解释。

**💡 创新点**

首次实证表明，变异分析信息可显著提升LLM基量子程序修复的成功率和解释质量；同时将变异分析与动态执行信息一起提示可获得最高的修复成功率（94.4%）。

**🔧 技术方法**

使用GPT‑5生成修复代码与解释；采用QMutPy完成量子程序的变异分析；提示工程包含静态、动态与变异信息。

**📊 数据集**

采用Bugs4Q公开的18个真实量子程序（Qiskit实现）作为实验数据集。

**📈 对比分析**

对比四种提示配置（S、S+D、S+M、S+D+M），在18个程序中计算修复成功率和解释质量（准确性、完整性、复杂度）。S+D+M配置获得最高的94.4%修复成功率，并在解释的位置信息方面表现最佳。

**⚠️ 局限性**

受限于仅能对支持变异分析的程序使用，且依赖单一量子框架（Qiskit）和单一LLM（GPT‑5）；实验仅在模拟器上进行，缺乏真实量子硬件验证；评估主观性较高且可能受限于研究者对量子编程的专业知识。

---

## 170. Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory

**arXiv ID:** 2601.12557 | [PDF](https://arxiv.org/pdf/2601.12557v1)

**作者:** Mark Moussa `[一作]` (NASA Goddard Space Flight Center), Giada Arney `[通讯]` (NASA Goddard Space Flight Center)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db`

**🎯 论文内容**

本文提出并评估了两种深度学习模型，用于从行星反射光谱中预测生物标志物的通量；

**💡 创新点**

创新点在于引入贝叶斯卷积网络以实现对先验与偶然不确定性的联合量化，以及设计可查询的谱量子自适应Transformer（SQuAT），通过可解释的注意力机制将谱特征与特定气体关联；

**🔧 技术方法**

采用了贝叶斯卷积网络（BCNN）和基于Transformer的SQuAT，并与传统CNN、ViT基线以及其贝叶斯变体进行对比；

**📊 数据集**

使用扩充后的PyAtmos/PSG数据集，包含约80,000个自洽光化学与气候模型的地球及前地球时代大气模拟，并生成对应的0.2–2.5 µm反射光谱；

**📈 对比分析**

在不同信噪比（SNR 5–100）下评估，SQuAT和BCNN的R²均超过0.97，RMSE在0.12–0.20之间，优于CNN/ViT基线，且SQuAT在高SNR下与BCNN性能相近；

**⚠️ 局限性**

主要限制包括缺乏真实观测数据、对高温和云/烟雾效应的模拟不足，以及低SNR下的鲁棒性不足，未来需要更丰富的合成数据和更强的物理先验融合。

---

## 171. Conversing with Objects toward Fluid Human and Artificial Identities during Life Transitions

**arXiv ID:** 2601.12589 | [PDF](https://arxiv.org/pdf/2601.12589v1)

**作者:** Yuhui Xu `[一作]` (Eindhoven University of Technology), Mathias Funk `[通讯]` (Eindhoven University of Technology)

**通讯引用:** 2929 | [OpenAlex ID](https://openalex.org/A5048042181)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在两周内对12名刚到荷兰留学的国际学生使用基于Telegram的聊天机器人，让其扮演所选日常物品的身份，收集对话与访谈数据，探究在生活转变期间通过对象与聊天机器人对话来支持身份重塑。

**💡 创新点**

提出了“跨实体化（trans‑embodiment）”概念，说明人工代理可以异步地承载物体及其关联人类身份，并将对象身份划分为感知、情境与关系三类，作为支持身份转变的新方法。

**🔧 技术方法**

实现了一个技术探针：基于Telegram的脚本化聊天机器人，配合对象选择、图像上传和预设提问，利用自然语言与用户进行对话并记录交互。

**📊 数据集**

收集的自定义数据集包括12名参与者的146条对话记录、图像及随后进行的713分钟访谈，涵盖年龄、性别与国籍等基本信息。

**📈 对比分析**

没有采用传统对照实验或量化指标，而是通过归纳主题分析对话与访谈内容，发现通过对象化身份的聊天对话可产生情感支持与反思体验，效果以质性描述呈现。

**⚠️ 局限性**

局限在样本规模与人群单一（仅为国际学生）、实验时长短、缺乏对照组、聊天机器人功能单一（无LLM个性化回应），且可能对用户原有的对象关系产生不可预见的心理影响。

---

## 172. Analyzing Collection Strategies: A Computational Perspective on the Coupon Collector Problem

**arXiv ID:** 2601.12351 | [PDF](https://arxiv.org/pdf/2601.12351v1)

**作者:** Hadas Abraham `[一作]` (Henry and Marilyn Taub Faculty of Computer Science), Eitan Yaakobi `[通讯]` (Henry and Marilyn Taub Faculty of Computer Science)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文针对最一般形式的优惠券收集问题，提出基于马尔可夫链的动态规划算法，用于精确计算收集过程的期望、方差及二阶矩。

**💡 创新点**

创新点在于：①利用状态的对称性，将状态空间从指数级压缩到多项式级（统一分布下为O(n^t)）；②对任意分布引入概率对称算法(DPSA)，在存在概率群组时同样实现多项式时间；③给出完整的时间复杂度分析与边界估计。

**🔧 技术方法**

主要技术包括：马尔可夫链建模、状态聚合（乘性向量表示）、动态规划递推、几何分布分析、Jensen不等式及组合计数。

**📊 数据集**

实验中未使用真实数据集，所有结果均来自理论推导与Monte‑Carlo模拟（10³–10⁵ 次），用于验证算法的准确性和效率。

**📈 对比分析**

与传统 Monte‑Carlo 对比，UDA 与 DPSA 在运行时间上显著优于 10³ 次模拟，且误差几乎为零；在 10⁴、10⁵ 次模拟下，误差降至可忽略级别，体现了算法在精度与效率上的优势。

**⚠️ 局限性**

局限性：在最坏情况下（无对称结构、分布极不均匀）算法仍保持指数时间；目前尚无闭式表达式，仍需迭代马尔可夫链求解；未来需进一步压缩状态空间并求解更一般情形。

---

## 173. LR-DWM: Efficient Watermarking for Diffusion Language Models

**arXiv ID:** 2601.12376 | [PDF](https://arxiv.org/pdf/2601.12376v1)

**作者:** Ofek Raban `[一作]` (Bar-Ilan University), Gal Chechik `[通讯]` (NVIDIA)

**通讯引用:** 7317 | [OpenAlex ID](https://openalex.org/A5045719865)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种针对扩散式语言模型的左右双向水印方法（LR‑DWM），通过在生成时利用已确定的左、右邻居对词向量进行加权，生成带有可检测统计信号的文本。

**💡 创新点**

创新点在于：①突破传统自回归模型的单向顺序限制，利用扩散模型非顺序生成特性，将水印信号同时从左、右两侧注入；②采用加性logit偏置而非复杂期望或缓存表，显著降低运行时与内存开销；③设计了基于双侧绿集的统一检测统计量，并在真实人类文本上校准误检率。

**🔧 技术方法**

技术手段包括：哈希函数产生左右两侧绿集；对未确定位置的logits施加可选的偏置 δ；检测时计算每个 token 的三元分数 s_i 并归一化得到 Z‑score；在扩散解码过程中按需插值；实验使用 GPU 量化时钟和显存峰值。

**📊 数据集**

数据集：使用 WaterBench 的 600 条提示生成 300‑token 序列；对 LLaDA‑8B‑Instruct 与 DREAM‑7B‑Instruct 两个扩散模型进行评估；为校准 Z‑score 并检验 FPR，抽取 10,000 条 400‑token 长度的 C4 人写文本。

**📈 对比分析**

与基线（未水印）、WM‑DLM（期望式加权）和 DMARK（缓存表）进行对比。结果显示：LR‑DWM 在 1% FPR 下实现与对比方法相近甚至更高的 TPR，同时在 perplexity 上与基线相当；在同一硬件（NVIDIA H100）上，LR‑DWM 的生成时间与显存几乎与未水印相同，远低于 DMARK 的显存占用和 WM‑DLM 的运行时开销。

**⚠️ 局限性**

局限性包括：对文本长度敏感，短文本难以形成足够统计信号；在极高检测率时略有质量下降；鲁棒性仅在非自适应词汇级扰动下表现良好，对高级对抗攻击尚未评估。

---

## 174. Does Motion Intensity Impair Cognition in HCI? The Critical Role of Physical Motion-Visual Target Directional Congruency

**arXiv ID:** 2601.12884 | [PDF](https://arxiv.org/pdf/2601.12884v1)

**作者:** Jianshu Wang `[一作]` (Henan University), Feng Tian `[通讯]` (Institute of Software Chinese Academy of Sciences)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

使用 6 轴运动平台对 39 名受试者进行视觉方向判断任务，记录反应时并通过 IMU 数据分解为横向干扰与方向一致性两种运动成分，探讨它们对认知表现的影响。

**💡 创新点**

首次将整车运动分解为任务相关的方向一致性与任务无关的横向干扰两种互相对立的成分，并揭示个体对运动晕眩敏感度对这两种成分效应的非对称调节。

**🔧 技术方法**

采用 6-DOF 电动运动平台、IMU 传感器、线性混合效应模型（LMM）和广义线性混合效应模型（GLMM）进行统计分析，结合 NASA‑TLX 主观负荷评估。

**📊 数据集**

自建实验数据集：约 300 条试验记录（反应时、准确率、IMU 加速度、MSSQ 运动晕眩倾向、NASA‑TLX 工作负荷）。

**📈 对比分析**

通过在每个实验阶段对比运动强度、成分与个体差异的交互，发现横向干扰正相关导致反应时延长（β≈1.49），方向一致性负相关导致反应时缩短（β≈-0.33）。相较于传统的“运动强度越大表现越差”结论，本文揭示了更细粒度的双重效应与个体调节机制，表现可解释约 54% 的 RT 方差。

**⚠️ 局限性**

实验仅在高保真模拟器中进行，未包含真实驾驶情境；仅考虑低频大振幅摆动，未检验高频低振幅或滚转/俯仰组合；任务为简单键盘方向判断，缺乏对复杂交互（如触控、语音）及长时交互的验证；样本主要为年轻健康成人，运动晕眩分布有限。

---

## 175. Speculative Sampling with Reinforcement Learning

**arXiv ID:** 2601.12212 | [PDF](https://arxiv.org/pdf/2601.12212v1)

**作者:** Chenan Wang `[一作]` (William and Mary), Haipeng Chen `[通讯]` (William and Mary)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于强化学习的动态调优框架Re‑SpS，用来在大语言模型推理过程中实时调整投机采样（Speculative Sampling）的草稿树超参数，以提高生成速度并保持输出精度。

**💡 创新点**

1) 将RL决策过程与投机采样结合，首次将草稿树超参数视为可学习的动作；2) 采用内部隐藏层特征作为高效状态表示，避免昂贵的外部编码；3) 引入多步动作持久化（action caching）来降低RL推理频率，平衡适应性与计算成本。

**🔧 技术方法**

强化学习（PPO+最大熵正则化）、投机采样框架EAGLE‑3、使用目标模型内部隐藏状态做状态表示、动作持久化缓存机制。

**📊 数据集**

使用ShareGPT和UltraChat200K训练集，评估基准包括MT‑Bench、HumanEval、GSM8K、Alpaca、CNN/DailyMail。

**📈 对比分析**

与SOTA投机采样方法EAGLE‑3、Medusa、Hydra对比，Re‑SpS在LLaMA 3.1‑8B、Vicuna‑13B和LLaMA 3.3‑70B三种后端上均实现1.03–1.12倍的速度提升（相对于EAGLE‑3），且在五大基准任务中保持与贪婪解码完全相同的输出。

**⚠️ 局限性**

仍受限于RL策略的收敛速度、超参数空间选择的局限、对极长序列的兼容性（如CNN/DailyMail出现轻微下降），以及在多模型、多任务场景下的泛化性待进一步验证。

---

## 176. Embryonic Exposure to VPA Influences Chick Vocalisations: A Computational Study

**arXiv ID:** 2601.12203 | [PDF](https://arxiv.org/pdf/2601.12203v1)

**作者:** Antonella M. C. Torrisi `[一作]` (Queen Mary University of London), Emmanouil Benetos `[通讯]` (Queen Mary University of London)

**通讯引用:** 4650 | [OpenAlex ID](https://openalex.org/A5084672392)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

开发并应用无监督计算框架，通过自动检测、特征提取和聚类分析描述鸡胚胎期暴露Valproic Acid对早期发声的影响。

**💡 创新点**

不依赖预定义标签的无监督方法消除了人工偏差，揭示两类发声的连续结构，并发现VPA导致软音呼叫比例升高、硬音呼叫减少。

**🔧 技术方法**

采用高频内容(HFC)与能量差分法进行呼叫检测，使用PYIN、FFT等算法提取20维时间、频率、能量特征，并利用层次聚类与UMAP可视化。

**📊 数据集**

先在31只新孵雏（31条单通道WAV）构建模型，再在46只鸡（27只VPA组、19只对照组）评估。

**📈 对比分析**

通过LMM统计模型和聚类指标（Silhouette、CHI、WCSS）比较，表明两组聚类结构相似，但VPA组呼叫数量、时长、频率变异等特征显著下降；聚类分割在VPA组仍保持有效。

**⚠️ 局限性**

限制包括录音时长短、仅在首日社交偏好实验中记录，未覆盖完整发声谱；特征集未包含高阶时间-频率散射等可能揭示更细微差异。

---

## 177. Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory

**arXiv ID:** 2601.12771 | [PDF](https://arxiv.org/pdf/2601.12771v1)

**作者:** Keito Inoshita `[一作]` (Kansai University), Keito Inoshita `[通讯]` (Kansai University)

**通讯引用:** 4 | [OpenAlex ID](https://openalex.org/A5106529447)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

利用大型语言模型的关联记忆机制，提出了LAMA框架，通过检索同名著名人物的国籍信息并投票聚合来预测姓名对应的国籍、地区或大洲。

**💡 创新点**

创新点在于将LLM的知识视作可检索的关联记忆，采用双代理（人物与媒体领域）并行检索、投票投票以及条件化补全的多代理系统，从而实现间接推理而非直接推理，显著提升准确率并增强对低频标签的鲁棒性。

**🔧 技术方法**

技术包括LLM检索式提示（Prompt engineering）、双代理并行调用、投票聚合、基于检索结果的条件化补全、以及多轮LLM调用的API管理。

**📊 数据集**

使用公开的name2nat数据集，包含89万条罗马化姓名和对应的173国籍信息，后经筛选、上限处理得到99个国家、14个地区和6个洲级别的测试集（总计75,345条）。

**📈 对比分析**

与传统神经模型（SVM、CANINE、XLM‑RoBERTa）以及LLM提示方法（CoT、Self‑Consistency、Self‑Reflection）对比，LAMA在99国国籍预测上准确率0.817（相较Self‑Reflection 0.776提升0.041），宏观F1 0.824（提升0.042），Precision@3 0.885（提升0.015），Precision@5 0.902（提升0.009）。在地区和洲级别也实现了显著优势，且在不同频率标签上相对跌幅仅为5%，远低于其他方法的11–22%。

**⚠️ 局限性**

主要局限为：仅在GPT‑4.1‑mini上评估，未验证对其他LLM（Claude、Gemini、开源模型等）的适用性；检索结果依赖LLM对著名人物的知识覆盖，可能出现语言/文化偏见；方法未在除国籍预测外的其他属性预测任务上实验，通用性仍需验证。

---

## 178. Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection

**arXiv ID:** 2601.12310 | [PDF](https://arxiv.org/pdf/2601.12310v1)

**作者:** Jennifer Dodgson `[一作]`, Steven Zhang Zhexu `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `a4b10f5d-130b-4e77-9367-6469ec621899` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并验证了一种基于环境后果的自监督自训练架构，利用存储空间变化作为唯一选择信号，实现模型在无外部奖励、有限记忆的条件下持续改进。

**💡 创新点**

创新点在于：① 抛弃代理奖励/代理模型，直接以物理资源保存为筛选标准；② 通过“负空间学习”机制实现策略的删减与精炼，而非单纯累积新知识；③ 发现模型在没有显式探索奖励的情况下自发采用调试循环的元学习策略。

**🔧 技术方法**

主要技术包括：大语言模型（Qwen 2.5 7B Instruct）生成可执行代码；基于容器化 Linux 环境的资源限制模拟；监督微调（SFT）与增量 LoRA 叠加；策略多样性与聚类分析、PCA 维度压缩、贝叶斯/正态分布评估等。

**📊 数据集**

数据集：自生成的行为记录与成功案例（4,500 行/迭代）加 500 行历史或对齐数据；此外使用 Stack Exchange Paired 数据做回放；实验环境为程序化生成的多容器网络化 Linux 系统。

**📈 对比分析**

与传统 RL 或奖励调度方案对比，三条训练策略（Terese：全量训练；Miri：最近三代；Katalin：最高空间释放）分别衡量。Miri 在保持数据量不变的情况下仍能实现约 50% 的性能提升；Katalin 在后期出现性能崩溃；Terese 虽提升最大但需四倍数据。总体而言，SFT+负空间学习在资源约束下表现最稳健。

**⚠️ 局限性**

局限包括：① 仅在单一资源维度（存储）测试，缺乏多维资源验证；② 依赖容器化环境，未证明可迁移到真实物理硬件；③ 缺乏对长期可持续学习的理论保证，仍需探索持续在线 SFT 与更复杂环境的交互；④ 代码正确率下降表明模型可能过度利用调试作为“探索”，在实际任务中可能导致错误传播。

---

## 179. Segment and Matte Anything in a Unified Model

**arXiv ID:** 2601.12147 | [PDF](https://arxiv.org/pdf/2601.12147v1)

**作者:** Zezhong Fan `[一作]` (Walmart Global Tech), Kannan Achan `[通讯]` (Walmart Global Tech)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了SAMA模型，在SAM的基础上通过轻量化模块实现高质量的交互式分割和图像抠图；

**💡 创新点**

创新点包括统一的分割‑抠图框架、Multi‑View Localization Encoder（MVLE）与 Localization Adapter（Local‑Adapter）两大轻量化模块、只增加1.8%参数并保持SAM冻结、通过多任务学习实现分割与抠图相互提升；

**🔧 技术方法**

技术手段涵盖SAM的预训练编码器与prompt编码、跨视图交叉注意力、细粒度特征融合、轻量上采样预测头、多任务损失（分割的BCE+IoU+SSIM，抠图的L1+SSIM+Grad+Laplace）、全局与局部特征的双向交互；

**📊 数据集**

训练使用DIS‑5K、ThinObject‑5K（分割）以及Adobe Image Matting、AIM‑500（抠图）；评估覆盖DIS‑5K/TE1‑4、Composition‑1K、Distinctions‑646、RefMatte‑RW100、P3M‑500等公开基准；

**📈 对比分析**

在分割任务中与SAM、HQ‑SAM、Pi‑SAM、DIS‑SAM 等模型对比，SAMA 在 DIS 细粒度评测中实现了 F‑max、F‑w、S‑α 等指标的最高值；在抠图任务中与 trimap‑free 的 LFM、MODNet、MFC‑Net 以及 trimap‑based 的 VITMatte、DIM、DCNN 等对比，SAMA 在 SAD 与 MSE 上均超越或逼近 SOTA；交互式点提示实验显示 SAMA 在 mIoU 上优于 HQ‑SAM 与原 SAM；整体性能显著提升；

**⚠️ 局限性**

局限性包括：尚未在视频分割、实时应用等场景进一步验证；轻量化增添的 MVLE 与 Local‑Adapter 在极端高分辨率或大规模数据集上可能需要更多算力；对多尺度物体的适应性仍有提升空间；目前主要验证在公开数据集上，实际应用场景中可能遇到更复杂的遮挡与光照变化。

---

## 180. Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses

**arXiv ID:** 2601.12178 | [PDF](https://arxiv.org/pdf/2601.12178v1)

**作者:** Fallou Niakh `[一作]` `[通讯]` (ENSAE IP Paris), Fallou Niakh (ENSAE IP Paris)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

提出了基于联邦学习的可再生能源保险指数校准框架，利用分布式优化在本地数据上学习共同的气象敏感度向量。

**💡 创新点**

创新在于将联邦学习应用于具有Tweedie GLM异质性和高峰度损失的参数保险指数设计，摆脱了传统近似方法对同质性假设的限制。

**🔧 技术方法**

采用FedAvg、FedProx、FedOpt三种联邦优化算法，并使用Tweedie分布的偏差作为损失函数进行分布式训练。

**📊 数据集**

使用德国南部50座太阳能发电厂2012-2022年的日度财务损失与气象协变量数据。

**📈 对比分析**

通过与前述近似聚合方法（ANOR）对比，联邦学习得到的指数系数与近似法相近，基准风险分布相似，且在中等异质性场景下表现稳定。

**⚠️ 局限性**

局限在于只研究静态指数、固定的局部参数，未考虑时间非平稳性、跨技术或跨地区更高异质性的情形。

---

## 181. Towards Unbiased Source-Free Object Detection via Vision Foundation Models

**arXiv ID:** 2601.12765 | [PDF](https://arxiv.org/pdf/2601.12765v1)

**作者:** Zhi Cai `[一作]` (Beihang University), Di Huang `[通讯]` (Beihang University)

**通讯引用:** 11107 | [OpenAlex ID](https://openalex.org/A5056972984)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `8d10c613-917e-4880-9716-17789f50e119` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种基于视觉基金模型的源无关目标检测框架DSOD，通过融合VFM特征来减轻源偏差。

**💡 创新点**

创新点在于联合使用Unbiased Feature Injection (UFI)与Semantic‑Aware Feature Regularization (SAFR)两种模块，并引入Domain‑Aware Adaptive Weighting (DAAW)以及Dual‑Teacher蒸馏，实现对源偏差的有效抑制及轻量化部署。

**🔧 技术方法**

主要技术包括DETR/Deformable‑DETR检测器、Mean‑Teacher自监督框架、DINOv2视觉基金模型、特征投影与融合、正则化及蒸馏等。

**📊 数据集**

实验使用Cityscapes、Foggy Cityscapes、BDD100k、SIM10k四个公开数据集进行正常到雾霾、跨场景及合成到真实等三个跨域任务。

**📈 对比分析**

与现有UDAOD与SFOD方法比较，DSOD在三个任务中分别取得约48.1%、39.3%和61.4%的mAP，超越前沿方法（如DRU、DDT），同时其VFM‑free变体DSOD‑Distill亦保持竞争力。

**⚠️ 局限性**

局限性包括对高性能VFM的依赖、训练过程中需要多阶段与超参数调节，以及在极端域差异下仍可能出现误检/漏检。

---

## 182. IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning

**arXiv ID:** 2601.12330 | [PDF](https://arxiv.org/pdf/2601.12330v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 183. System-Mediated Attention Imbalances Make Vision-Language Models Say Yes

**arXiv ID:** 2601.12430 | [PDF](https://arxiv.org/pdf/2601.12430v1)

**作者:** Tsan Tsai Chan `[一作]`, Vera Demberg `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8`

**🎯 论文内容**

介绍了如何使用ACL风格文件在LuaLaTeX或XeLaTeX中编译论文；

**💡 创新点**

该文仅为示例模板，无创新性研究内容；

**🔧 技术方法**

使用了LuaLaTeX或XeLaTeX及ACL样式文件；

**📊 数据集**

未使用任何数据集；

**📈 对比分析**

无实验对比，无法评估性能；

**⚠️ 局限性**

缺乏实际研究内容和实验数据，无法验证方法有效性

---

## 184. Counterexamples, Constructions, and Nonexistence Results for Optimal Ternary Cyclic Codes

**arXiv ID:** 2601.12427 | [PDF](https://arxiv.org/pdf/2601.12427v1)

**作者:** Jingjun Bao `[一作]` (Ningbo University), Hanlin Zou `[通讯]` (Yunnan University)

**通讯引用:** 12 | [OpenAlex ID](https://openalex.org/A5009460535)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

本文对三元循环码 C_(1,e) 进行了系统研究，首先给出了 Ding 与 Helleseth 提出的两大开放问题的反例，并在满足特定条件下构造了两族新的最优三元循环码；其次对满足 e(3^h±1)≡(3^m−a)/(2·3^m−1)（a 为奇数）的指数 e 进行分类，得到两族新的最优三元循环码，并给出若干非存在性结果；最后讨论了 a≡18 时的情况并提出进一步研究问题。

**💡 创新点**

创新点在于：①首次提供了 Ding 与 Helleseth 两个开放问题的反例，并在特定取值下给出正例；②提出了一套基于二次特征和 cyclotomic coset 解析的判定方法，用于判断 C_(1,e) 的最优性；③在 e 满足特定同余条件的情况下，构造了两族新的最优三元循环码，进一步扩展了已知最优码的参数范围；④给出了关于 a≡58、a≡14 及 a≡18 等特殊情形的非存在性结果，补充了先前研究中的空白。

**🔧 技术方法**

主要技术包括：循环码理论、p-循环余数集、最小多项式与检验多项式的构造、最大公约数与指数关系的代数分析、二次特征（quadratic character）的使用，以及对方程 (x+1)^e±(x^e+1)=0 的根的计数与判别。论文中多次利用 Magma 软件验证多项式不可约性与根的个数。

**📊 数据集**

本研究为纯理论工作，不涉及任何实验数据集；所有结果均通过代数证明与符号计算得出。

**📈 对比分析**

相对于已知的最优三元循环码（如 3^m−1, 3^m−1−2m, 4），本文提供的码在参数上保持相同的维度与最小距离，且满足球面封装极限的最优性；通过与已有表格中已知码的比较，可见新构造的码在满足更宽松的指数条件下依旧保持最优。

**⚠️ 局限性**

局限性主要包括：①对 Ding 与 Helleseth 的部分开放问题仍未给出完整解答，只解决了特定子集；②在 a≡18 的情形下的最优码构造仍未完全解决，且仅给出了有限的存在性分析；③对 e 的构造仍依赖于满足复杂的同余与 gcd 条件，实际编码实现时需进一步验证其生成多项式的不可约性。

---

## 185. A Similarity Network for Correlating Musical Structure to Military Strategy

**arXiv ID:** 2601.12314 | [PDF](https://arxiv.org/pdf/2601.12314v1)

**作者:** Yiwen Zhang `[一作]` (United International College), Fanqin Meng `[通讯]` (United International College)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `3f18e8e3-0266-457c-8567-9039b6d2394d` `b88c6eac-d57a-4623-a604-1f401f3eb268` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

构建音乐剪辑关联网络（MCCN），并将其与四种军事策略网络（RTN、RAN、SOS、BA）进行对比，探究音乐结构与军事战略之间的系统性相似性。

**💡 创新点**

创新点在于：①首次将音乐感知与军事战略通过图网络模型进行跨领域映射；②提出使用MFCC特征与余弦相似度构造音乐网络；③用图神经网络指标与加权不相似度评估音乐网络与军事网络的相似度；④通过军事网络的层级与信息传递特征解释不同情绪（进攻/防御）音乐的结构差异。

**🔧 技术方法**

使用的技术包括：Mel频率倒谱系数（MFCC）提取、预加重与窗函数、离散傅里叶变换、余弦相似度计算、Yifan‑Hu 力导向布局、基于介数中心度的节点分层、图密度、平均路径长度、网络直径、模块度与聚类系数等图指标；此外使用图神经网络框架对网络进行特征量化。

**📊 数据集**

数据集：约2000首战争电影配乐（时长2‑6分钟），分为进攻（30首）与防御（30首）两类；每首曲子按6秒切分为片段后构建节点，形成MCCN网络；同时构造四种典型军事网络作为对照。

**📈 对比分析**

比较方法：对MCCN与每种军事网络分别计算五项网络特征（APL、ND、GD、M、CC），通过加权求和得到不相似度值。实验结果显示：进攻MCCN与SOS网络相似度最高，防御MCCN与BA网络相似度最高；整体来看，防御音乐网络与军事网络的相似度更高，进攻网络更复杂。

**⚠️ 局限性**

限制：①仅使用纯乐器配乐，排除人声影响，可能限制了对真实音乐感知的覆盖；②情绪标签仅分为进攻与防御两类，缺乏更细粒度的情感维度；③对比仅基于网络指标，未结合人类听觉评估或主观体验；④实验数据来源单一（战争电影配乐），结果可能不具普适性；⑤网络构建与阈值设定（如余弦相似度阈值）对结果影响较大，需要进一步验证鲁棒性。

---

## 186. Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models

**arXiv ID:** 2601.12215 | [PDF](https://arxiv.org/pdf/2601.12215v1)

**作者:** Megha Thukral `[一作]` (Georgia Institute of Technology), Sharanya Arcot Desai `[通讯]` (Samsung Research America)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `5a41884c-404f-4688-a89c-aa238c10fe68` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

开发了一种基于小波多尺度重建的自监督预训练模型，对PPG信号进行大规模预训练，并在19项健康相关下游任务中进行评估。

**💡 创新点**

首次在PPG领域引入跨尺度掩码重建目标，利用小波分解捕获多尺度时间‑频率特征，显著提升表示能力。

**🔧 技术方法**

结合离散小波变换、Vision Transformer、掩码多尺度重建目标以及对比学习等技术实现自监督学习。

**📊 数据集**

使用约48K小时来自Samsung智能手表的低频PPG数据（25–100Hz）进行预训练，并在多种公开/内部健康任务数据集上进行下游评估。

**📈 对比分析**

与SimCLR、MSN、TF‑C、Mask‑Time、Chronos、PaPaGei等多种自监督与预训练基线对比，平均AUROC 66.7%，在PVC检测、血压预测等任务上与最优基线相当或更优，轻量化版本仍保持竞争性能。

**⚠️ 局限性**

仅针对单模PPG信号，使用固定小波基和分解深度，未探索自适应分解；在极端运动噪声或低质量信号下表现受限；对多模态融合和时间序列持续建模的扩展待研究。

---

## 187. PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception

**arXiv ID:** 2601.12551 | [PDF](https://arxiv.org/pdf/2601.12551v1)

**作者:** Tong Wu `[一作]` `[通讯]`, Tong Wu

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

在低带宽边缘感知下，提出PISE框架，结合物理反演与语义感知提升计算鬼影成像的分类精度。

**💡 创新点**

创新点是将共轭算子初始化与冻结VGG特征的感知损失相结合，解决MSE在极低采样率下梯度坍塌与语义漂移。

**🔧 技术方法**

使用物理锚定的共轭投影、U‑Net重建网络、VGG‑16感知损失以及基于梯度动态监控的训练策略。

**📊 数据集**

主要使用Fashion‑MNIST和CIFAR‑10数据集进行实验，采样率从2%到20%。

**📈 对比分析**

与ISTA‑Net+、ADMM‑CSNet、U‑Net(MSE)和cGAN‑CS等高效重建基线对比，PISE在5%采样率下分类准确率提升2.57%，方差下降约9倍，速度与基线相当。

**⚠️ 局限性**

局限性在于仅使用模拟测量和人工噪声，VGG特征可能不适用于灰度小图像，且未在真实硬件上验证。

---

## 188. Eddy-Resolving Global Ocean Forecasting with Multi-Scale Graph Neural Networks

**arXiv ID:** 2601.12775 | [PDF](https://arxiv.org/pdf/2601.12775v1)

**作者:** Yuta Hirabayashi `[一作]` (Japan Agency for Marine-Earth Science and Technology), Konobu Kimura `[通讯]` (FURUNO ELECTRONIC CO. LTD.)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一种基于多尺度图神经网络的10天全球涡流分辨海洋预报模型；

**💡 创新点**

创新点在于结合两层不同分辨率的球面网格、去除陆地节点并将大气预测变量作为节点输入，从而同时提升多尺度海洋动力学的表征和短期预报精度；

**🔧 技术方法**

使用了图神经网络（GNN）架构，包含编码器-处理器-解码器，消息传递机制，MLP残差连接，配合多尺度球面网格；

**📊 数据集**

训练使用GLORYS12V1全球海洋再分析（1993–2017）和ERA5大气再分析，评估时使用GLORYS与GFS预报大气数据；

**📈 对比分析**

与Wang2024的Swin Transformer基模型做比较：在表层变量的1–4天误差更低，能量谱与再分析更接近，显示出更细腻的空间结构和更好的短期时空演变；

**⚠️ 局限性**

局限在于10天以上的自回归误差积累导致RMSE上升，需进一步研究稳定长时尺度预报的正则化或能量损失；

---

## 189. Conversational Context Classification: A Representation Engineering Approach

**arXiv ID:** 2601.12286 | [PDF](https://arxiv.org/pdf/2601.12286v1)

**作者:** Jonathan Pan `[一作]` (Nanyang Technological University), Jonathan Pan `[通讯]` (Nanyang Technological University)

**通讯引用:** 65 | [OpenAlex ID](https://openalex.org/A5112875986)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `3855fcda-48ef-4070-a15e-803cd5c84d83` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

探究将 Representation Engineering 与 One-Class SVM 结合，用 LLM 隐藏状态子空间检测对话是否偏离预期上下文。

**💡 创新点**

首次将 OCSVM 与 RepE 结合，在不同隐藏层上进行消融评估，并通过 PCA 可视化异常点，实现对“离题”检测的可解释性。

**🔧 技术方法**

使用 RepE、One-Class Support Vector Machine、PCA 可视化、Llama3.2‑3B 与 Qwen2.5‑3B 模型，配合 scikit‑learn 训练与评估。

**📊 数据集**

构造自定义 AI/ML 对话数据集：20 个校准样本、20 个调优样本、20 个测试样本，每类 10 个 in‑context 与 out‑of‑context 示例。

**📈 对比分析**

通过 F1、Accuracy、AUROC、AUPRC 等指标与人工评估或规则基方法对比，实验显示 F1>0.8、AUROC≈0.9，证明方法在检测“离题”时表现优异。

**⚠️ 局限性**

局限性：样本规模极小，难以泛化；仅针对单模文本 LLM；未与稀疏自编码器或因果追踪等技术结合；对层选择高度敏感。

---

## 190. The Cost of Convenience: Identifying, Analyzing, and Mitigating Predatory Loan Applications on Android

**arXiv ID:** 2601.12634 | [PDF](https://arxiv.org/pdf/2601.12634v1)

**作者:** Olawale Amos Akanji `[一作]` (Boston University), Gianluca Stringhini `[通讯]` (Boston University)

**通讯引用:** 8962 | [OpenAlex ID](https://openalex.org/A5046881273)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

本文通过三阶段合规审计方法，对印尼、肯尼亚、尼日利亚、巴基斯坦和菲律宾共435款数字贷款App进行技术合规性评估，揭示大部分已批准App违反国家监管和Google金融服务政策，且许多App在用户授权前即收集并泄露敏感数据，导致潜在骚扰和胁迫。

**💡 创新点**

创新点包括：①首次将大语言模型自动化用于法规文本到Android权限的映射；②提出统一的LoanWatch违禁权限集合，弥补国家监管与Google政策的差距；③结合静态、动态和API级别的检测，形成从权限声明到实际数据泄露的完整链路。

**🔧 技术方法**

技术手段涵盖：LLM（GPT‑4o Mini、Claude Sonnet 4）用于政策到权限映射；AndroidManifest与字节码静态分析（Androguard、FlowDroid）；API调用与数据流路径分析；Frida动态 instrumentation验证运行时敏感数据访问与网络传输。

**📊 数据集**

数据集为435款已授权与已下架的Android贷款App，来源为各国公开监管登记与Google Play、AndroZoo及第三方APK库，涵盖五个东南亚/非洲国家。

**📈 对比分析**

与传统静态权限检查对比，LoanWatch将违规率从41.2%/43.0%提升至73.4%，说明统一权限集合显著提升检测覆盖；动态验证进一步证明37款App在启动即泄露数据，证实静态分析结果的有效性。性能方面，LLM映射每份法规仅需约两分钟完成，整体审计对435款App耗时约三天。

**⚠️ 局限性**

局限性包括：①依赖公开监管登记，未覆盖未注册或灰色市场App；②动态分析受限于无法完成完整贷款流程（缺少合法身份、手机号等），可能漏测后期数据泄露；③静态分析可能因代码混淆产生误报或漏报；④LLM映射仍需人工复核以保证法律解释准确。

---

## 191. SDiT: Semantic Region-Adaptive for Diffusion Transformers

**arXiv ID:** 2601.12283 | [PDF](https://arxiv.org/pdf/2601.12283v1)

**作者:** Bowen Lin `[一作]` (University of Houston), Chengming Zhang `[通讯]` (University of Houston)

**通讯引用:** 681 | [OpenAlex ID](https://openalex.org/A5100691052)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种训练自由、基于语义区域自适应的扩散变换器推理加速框架，动态分配计算只更新高复杂度区域，从而在保持图像质量的同时显著提升生成速度。

**💡 创新点**

创新点在于结合 Quickshift 语义分割与局部复杂度评估，利用边界膨胀保持空间一致性，并通过速度空间外推降低低复杂度区域的计算量，实现无模型改造的高效推理。

**🔧 技术方法**

使用的技术包括快速 Quickshift+ANN 语义聚类、复杂度评分与 top‑q 选择、边界膨胀、速度空间外推、结构‑稳定‑细节（SSD）调度以及全局刷新步骤。

**📊 数据集**

实验数据集涵盖 MS-COCO 2017 与 Human Preference Synthetic Dataset（DALLE3 1M+ HQC），用于评估自然场景与创意图像生成的效果。

**📈 对比分析**

与全注意力、RAS、DPM‑Solver 等基线对比，使用 FID、CLIP、PSNR/SSIM、LPIPS 和延迟等指标，取得约 2.7–3× 的速度提升，FID/CLIP 维持或优于基线，显著提升了效率与质量平衡。

**⚠️ 局限性**

局限性包括对 Quickshift 语义分割质量的依赖，极低采样率下可能出现细节丢失，以及在低分辨率或不同模型上的适用性尚待进一步验证。

---

## 192. Agentic Reasoning for Large Language Models

**arXiv ID:** 2601.12538 | [PDF](https://arxiv.org/pdf/2601.12538v1)

**作者:** Tianxin Wei `[一作]` (University of Illinois Urbana-Champaign), Jingrui He `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 4125 | [OpenAlex ID](https://openalex.org/A5073158087)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

综述了agentic reasoning的发展，提出从基础能力、持续自适应、集体协作三层以及推理时序（in-context vs post-training）四维的系统框架，整合了最新的模型、算法、工具与多领域应用。

**💡 创新点**

创新点在于：①将推理与行动统一为“思考‑行动”循环，构建三层代理能力体系；②区分推理阶段的两大优化模式（in-context与post-training）；③系统评估并梳理了多学科 benchmark、应用场景与未来挑战，形成了统一的路线图。

**🔧 技术方法**

使用的技术包括链式推理（Chain‑of‑Thought）、工具调用与检索框架、树形/搜索式思维（Tree‑of‑Thoughts、MCTS）、记忆管理（structured episodic / semantic memory）、反思与自评（Reflexion、ARPO）、多代理协同（role‑based orchestration、communication graph）、强化学习与后训练微调（GRPO、MART、MAPoRL）。

**📊 数据集**

主要引用了多领域 benchmark，如ToolQA、API-Bank、WebWalker、MMSearch、PlanBench、REALM‑Bench、MAgent、SMAC、LLM‑Coordination 等，涵盖工具使用、搜索、记忆、规划与多代理交互的评测集合。

**📈 对比分析**

通过对比各类 benchmark，论文展示了不同方法在单推理、工具调用、搜索效率、记忆保留与多代理协同等指标上的相对优势与不足；强调在复杂开放域中，post‑training 方案往往能提升最终任务性能，但对计算资源与数据需求更高。

**⚠️ 局限性**

局限性：①作为综述，缺乏新的实验验证；②快速发展的领域导致文献更新滞后；③对真实工业部署的案例覆盖不足；④未深入探讨安全性、可解释性与治理等非技术维度。

---

## 193. OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization

**arXiv ID:** 2601.12291 | [PDF](https://arxiv.org/pdf/2601.12291v1)

**作者:** Jianhao Jiao `[一作]` (University College London), Dimitrios Kanoulas `[通讯]` (University College London)

**通讯引用:** 1518 | [OpenAlex ID](https://openalex.org/A5048122691)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `5b4c1114-4a70-478e-9921-2514ee03850d` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种轻量化、无结构的拓扑-测量映射框架，可在多设备、多会话中协作定位与地图合并，支持视觉图像目标导航；

**💡 创新点**

创新点包括：① 结构无关的拓扑测量地图，仅存储RGB图像和边权；② 基于3D基础模型的即时场景重建与测量，避免传统SfM的重建成本；③ 采用动态规划序列匹配+几何验证+置信校正的三阶段协作定位；④ 节点裁剪策略实现终身运行；

**🔧 技术方法**

使用的技术有：CosPlace VPR、3D基础模型（如PixelNeRF）、PnP+RANSAC、姿态图优化、Dijkstra路规划、局部点云ICP、深度预测与图像匹配；

**📊 数据集**

数据集包括自采R0–R2（18.7km、3.5月、跨设备），Map‑Free benchmark、GZ‑Campus、Google Street View、360Loc；

**📈 对比分析**

与SfM、回归基线在Map‑Free上对比，平均平移误差0.62 m；在15.7 km多会话合并中ATE <3 m；在12次真实/仿真图像目标导航实验中成功率高、耗时/路径长度接近最优；

**⚠️ 局限性**

局限：3D基础模型推理开销大；只支持已知地图内导航，缺乏离地图恢复；节点裁剪过于保守；中心化映射在大规模人群采集下存储/通信瓶颈。

---

## 194. Enabling High-Curvature Navigation in Eversion Robots through Buckle-Inducing Constrictive Bands

**arXiv ID:** 2601.12523 | [PDF](https://arxiv.org/pdf/2601.12523v1)

**作者:** Cem Suulker `[一作]` (Queen Mary University of London), Kaspar Althoefer `[通讯]` (Queen Mary University of London)

**通讯引用:** 13217 | [OpenAlex ID](https://openalex.org/A5042583278)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0`

**🎯 论文内容**

提出在旋转增益机器人外壁上集成不可延展的直径缩小环带，利用局部屈曲降低弯曲刚度，实现被动式弯曲导航。

**💡 创新点**

创新点在于：1）仅通过结构改造（环带）而非额外驱动器或人工肌肉，实现柔性与可压缩性不受损失；2）利用局部屈曲诱导实现更高弯曲性能；3）用 Cosserat 线杆模型解释并量化此效应。

**🔧 技术方法**

采用 TPU 制作机器人与环带；使用超声焊接、激光切割等工艺；在 Instron 机器上做力–位移实验；在模拟管道、U‑弯道和人造结肠模型中测试；利用 Cosserat rod 数值仿真与实验数据对比。

**📊 数据集**

实验数据来自自制的 3 套机器人（无环带、单环带、多环带）以及在不同弯曲半径和不同环带压缩比（10%、20%、30%、50%）下的测试，未使用公开数据集。

**📈 对比分析**

与标准无环带旋转增益机器人进行对比：环带机型将弯曲刚度降低至 9–91%；在 25 mm 弯曲半径下仍可顺利通过，而标准机型在 35 mm 及以下失效；在 90° 结肠弯道实验中，带环带机器人通过成功率 100%，无环带机器人完全卡住；性能提升体现为更小弯曲半径、成功率更高。

**⚠️ 局限性**

局限性包括：1）更大压缩比会显著提升起始扩张压力，导致易破裂；2）环带位置对性能影响大，需多带以保证未知环境下的可靠性；3）制造时焊接不对称会引入预弯曲，制造一致性要求高；4）仅在单一弯折或已知路径环境验证，复杂多弯未知路径的适用性仍需进一步研究。

---

## 195. Sound2Hap: Learning Audio-to-Vibrotactile Haptic Generation from Human Ratings

**arXiv ID:** 2601.12245 | [PDF](https://arxiv.org/pdf/2601.12245v1)

**作者:** Yinan Li `[一作]` (Arizona State University), Hasti Seifi `[通讯]` (Arizona State University)

**通讯引用:** 887 | [OpenAlex ID](https://openalex.org/A5043917822)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

设计、训练并评估了一种基于深度学习的音频‑振动生成模型 Sound2Hap，并构建了最大规模的带人类评价的环境声音‑振动数据集，提供了交互式可视化与生成工具。

**💡 创新点**

①通过收集 8,000 条人类评分数据，采用数据驱动的方式学习音频到振动的映射，克服传统规则方法对多样声音的泛化不足；②提出 Top‑Pair 与 Preference‑Weighted 两种训练策略，利用用户偏好提升生成质量；③公开最大规模的环境声音‑振动对数据及可复现的工具。

**🔧 技术方法**

使用 CNN‑based autoencoder（Encoder–Quantizer–Decoder）与残差网络、双层 LSTM、STFT/梅尔谱损失、生成对抗训练（GAN）等；音频编码器采用预训练的 EnCodec 模型；同时使用 RMS/峰值归一化、数据增强等技术。

**📊 数据集**

主要使用 ESC‑50 环境声音数据集（1,000 条音频，4 种振动，共 4,000 对）以及 8,000 条人类评分；在第二轮评估中引入 BBC Sound Effects 库 294 条音频，构成跨数据集测试。

**📈 对比分析**

与四种传统信号处理算法（Perception‑Level Mapping、Frequency Shifting、Pitch Matching、HapticGen）以及基线（每类最佳算法）进行对比；用户研究表明 Sound2Hap（Top‑Pair 与 Preference‑Weighted）在音频‑振动匹配评分平均达 76/100，显著高于基线 58/100，HXI 评分亦显著提升；生成延迟约 0.5 s，低于 1 s，满足离线应用需求。

**⚠️ 局限性**

模型仅针对单一显著声源，未处理多源混合；评估基于指尖声学激励，可能不适用于其他身体部位或驱动器；评估采用顺序播放，未考虑同步音频‑振动交互；样本性别比例失衡，缺乏对实时低延迟场景的评估。

---

## 196. Explicit Almost-Optimal $\varepsilon$-Balanced Codes via Free Expander Walks

**arXiv ID:** 2601.12606 | [PDF](https://arxiv.org/pdf/2601.12606v1)

**作者:** Jun-Ting Hsieh `[一作]` (Massachusetts Institute of Technology), Rachel Yun Zhang `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 316 | [OpenAlex ID](https://openalex.org/A5062107030)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

构造了低速率、高距离区间下匹配Gilbert–Varshamov界的显式二进制线性码。

**💡 创新点**

提出了“自由扩散走”方法，用不同扩散器的序列实现近似最优的偏置放大，简化了Ta‑Shma的构造。

**🔧 技术方法**

利用近Ramanunian图族、扩散走、偏置分析以及算子范数估计等技术。

**📊 数据集**

本工作未使用传统意义上的数据集，而是基于图论构造。

**📈 对比分析**

与随机线性码相比，其率达到Ω(ε²+o(1))，与Gilbert–Varshamov界仅相差子多项式因子；相较于Ta‑Shma的构造子多项式因子略大，但实现更简洁。

**⚠️ 局限性**

仍存在子多项式误差项，且对某些算子放大无法实现近最优；构造复杂度相对较高。

---

## 197. Learning Diverse Skills for Behavior Models with Mixture of Experts

**arXiv ID:** 2601.12397 | [PDF](https://arxiv.org/pdf/2601.12397v1)

**作者:** Wangtian Shen `[一作]` (Tsinghua University), Ziyang Meng `[通讯]` (Tsinghua University)

**通讯引用:** 6146 | [OpenAlex ID](https://openalex.org/A5051392570)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `afceb026-1760-41ae-8d86-010831a37d97` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

研究多任务机器人学习，提出Di-BM框架，利用Mixture of Experts与能量基模型实现观察域分配与专家专门化，显著提升多任务性能。

**💡 创新点**

创新点在于将能量基模型与MoE结合，自动学习每个专家的观察分布并按子域路由数据，避免手工划分任务、降低任务干扰。

**🔧 技术方法**

使用的技术包括扩散策略（Diffusion Policy）作为行为模型、Mixture of Experts结构、能量基模型（EBM）用于建模专家观察分布、共享编码器与门控网络、联合梯度训练。

**📊 数据集**

实验数据集为RoboTwin 2.0仿真任务（8个任务，每个50条轨迹）和真实世界UMI收集的约24小时多任务演示（9个任务）。

**📈 对比分析**

与标准Diffusion Policy、SDP、MoDE等基线对比，Di-BM在仿真任务中平均成功率提升至0.76，真实任务提升至0.70，表现优于所有对照方法，且在新任务微调时数据效率更高。

**⚠️ 局限性**

局限性包括对超参数β的敏感性、仅在Diffusion Policy框架验证、未在更大规模的VLAs或更大数据集上测试、需要对每个专家估计归一化常数，且模型对超参数不够鲁棒。

---

## 198. Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments

**arXiv ID:** 2601.12305 | [PDF](https://arxiv.org/pdf/2601.12305v1)

**作者:** Deepak Kanneganti `[一作]` (Curtin University), Aneesh Krishna `[通讯]` (Curtin University)

**通讯引用:** 1362 | [OpenAlex ID](https://openalex.org/A5053327787)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出并实现了MDG（MLaaS Dataset Generator）框架，用于生成可配置、可复现的机器学习即服务（MLaaS）数据集，涵盖单个服务实例与多服务组合，适用于IoT场景。

**💡 创新点**

创新点包括：①通过训练多种模型并记录其功能、QoS与交互指标，取代传统静态、不完整的数据集；②提供Wizard、Generate、Autogen三种输入模式，支持大规模可复现的实验；③内置服务组合模拟与评估机制，自动生成交互数据并计算组合质量。

**🔧 技术方法**

技术手段包括：Python实现的多任务训练脚本，支持CNN、RNN、MLP、LR、MobileNet、RandomForest等模型；使用IID与Dirichlet、Shard、quantity‑skew等非IID采样；仿真服务交互和参数/非参数组合；将生成的指标导出为SQL、CSV、Parquet等结构化格式。

**📊 数据集**

使用公开IoT数据集：MNIST、Fashion‑MNIST、Digits、CIFAR‑10、Iris、Wine、California Housing；通过MDG生成10,432个MLaaS服务实例和740个组合实例。

**📈 对比分析**

实验采用规则、距离、天际线三种基准服务选择算法与传统QWS及缺失数据集对比，结果显示使用MDG生成的数据集使选择成功率提升15–25%；在组合实验中，MDG数据集下的组合质量平均提升约10%。

**⚠️ 局限性**

局限性包括：仅覆盖有限的模型族与任务类型；仿真环境未覆盖真实云计费、动态网络延迟和多租户安全等复杂因素；组合评估基于仿真，缺乏真实跨服务部署验证。

---

## 199. Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models

**arXiv ID:** 2601.12269 | [PDF](https://arxiv.org/pdf/2601.12269v1)

**作者:** Xucong Hu `[一作]` (Zhejiang University), Jian-Qiao Zhu `[通讯]` (University of Hong Kong)

**通讯引用:** 1053 | [OpenAlex ID](https://openalex.org/A5018060667)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

对小型自回归语言模型进行测试时的序列级采样优化，利用模拟退火探索序列空间以提升其在理论心智（ToM）任务上的推理性能。

**💡 创新点**

创新点在于将温度调度（模拟退火）与MCMC序列采样相结合，形成一种不需额外训练即可挖掘预训练模型潜在推理能力的优化框架。

**🔧 技术方法**

主要技术包括：自回归模型的条件分布作为提议分布的Power Sampling MCMC；温度调度的模拟退火策略；以及基于序列级分布的采样和接受判决。

**📊 数据集**

使用 BigToM benchmark（200个叙事模板，400个倒推推理实例）作为评测数据集。

**📈 对比分析**

与五种解码策略（直接推理、链式思考、低/高温度Power Sampling、模拟退火）进行对比。模拟退火在真假信念（FB）任务上显著提升准确率，并产生更符合 ToM 的推理链；在真信念（TB）任务上亦保持或略高的表现。

**⚠️ 局限性**

局限性包括：对深层嵌套信念或复杂因果结构仍易失败；推理时间显著增加，难以满足实时或大规模部署需求；不确定是否能推广至其他推理领域。

---

## 200. SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability

**arXiv ID:** 2601.12804 | [PDF](https://arxiv.org/pdf/2601.12804v1)

**作者:** Hanwei Zhang `[一作]` (Saarland University), Holger Hermanns `[通讯]` (Saarland University)

**通讯引用:** 11070 | [OpenAlex ID](https://openalex.org/A5028747794)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种能够在概念瓶颈模型中同时生成概念级和类别级空间可解释性热图的SL‑CBM方法。

**💡 创新点**

通过在概念投影网络中加入1×1卷积和交叉注意力机制，显著提升了概念与图像空间的局部一致性，解决了传统CBM局部可信度不足的问题。

**🔧 技术方法**

采用预训练的ViT‑B16/CLIP主干、1×1卷积、交叉注意力、对比损失和熵正则化等技术构建模型，并使用交叉熵、概念准确率、熵损失等多项损失组合训练。

**📊 数据集**

在RIVAL‑10和CUB‑200‑2011这两个具有概念与分割标注的数据集上进行实验。

**📈 对比分析**

与PCBM和CCS等先进CBM比较，SL‑CBM在类别与概念准确率、可解释预测（NEC‑5/ANEC）、局部可信度（IoU、Dice、C‑IoU、AG等）均表现出更高的分数，保持了竞争力的分类精度。

**⚠️ 局限性**

仅依赖预定义概念集，若概念质量不足会影响解释效果；对比损失对性能敏感，需仔细调参。

---

## 201. Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations

**arXiv ID:** 2601.12303 | [PDF](https://arxiv.org/pdf/2601.12303v1)

**作者:** Shizhan Gong `[一作]` (Chinese University of Hong Kong), Qi Dou `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 26747 | [OpenAlex ID](https://openalex.org/A5090516040)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `57a58b01-81b4-4d75-a45c-2e891f272b50` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种后置概念瓶颈模型 PCBM‑ReD，通过对预训练视觉编码器的表示进行分解，自动提取视觉概念并构建可解释的分类器。

**💡 创新点**

创新点包括：①利用 CLIP 的视觉‑文本对齐进行表示分解，直接得到概念嵌入；②使用多模态大语言模型（MLLM）对概念进行可视化标注、筛选与评分；③提出基于重构误差的贪婪概念选择算法，保证概念子集既覆盖表示空间又相互独立；④在保持原模型高精度的同时实现零样本与少样本推断。

**🔧 技术方法**

主要技术包括：CLIP 视觉‑文本对齐、稀疏自编码器（SAE）提取概念、MLLM（如 Llama‑3.2‑11B‑Vision‑Instruct）进行概念生成与评分、重构导向概念选择、稀疏匹配（OMP）实现图像表示的概念分解、线性层预测类别。

**📊 数据集**

在 11 个图像分类数据集上进行评估，涵盖通用对象（ImageNet、CIFAR‑10/100）、细粒度对象（Food‑101、FGVC‑Aircraft、Flower‑102、CUB‑200‑2011）、动作（UCF‑101）、纹理（DTD）、医学（HAM10000）以及卫星图像（RESISC45）。

**📈 对比分析**

与端到端线性探针、原始 CBM、LaBo、CompDL、Res‑CBM 等方法对比，PCBM‑ReD 在大多数数据集上达成与线性探针相当或更优的准确率（平均仅低 0.41%），并在零样本与少样本场景下保持接近 CLIP 的性能，整体提升约 1‑5% 的准确率。

**⚠️ 局限性**

主要限制包括：①概念生成高度依赖 MLLM/LLM 的描述质量，领域特定图像（如医学）可能描述不足；②作为后置方法，性能受原始视觉编码器的限制；③重构导向的概念选择仍需进一步优化以减少计算开销。

---

## 202. Aletheia: What Makes RLVR For Code Verifiers Tick?

**arXiv ID:** 2601.12186 | [PDF](https://arxiv.org/pdf/2601.12186v1)

**作者:** Vatsal Venkatkrishna `[一作]` (INSAIT), Iryna Gurevych `[通讯]` (Ubiquitous Knowledge Processing Lab)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `a4b10f5d-130b-4e77-9367-6469ec621899` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对大型语言模型（LLM）后训练阶段的代码验证器进行系统分析，构建了一个可控的代码验证实验平台，并对 RLVR 训练方法的三大核心组件（思考轨迹、负样本学习、在线学习）进行消融实验。

**💡 创新点**

发现 GRPO（基于 RLVR 的策略优化）在不同规模模型上始终优于其它方法；小模型依赖在线学习，而大模型需要长的思考轨迹；负样本学习在所有场景均显著提升稳定性。提供了可复现的开源数据集与实验脚本，填补了 RLVR 训练细节缺失的研究空白。

**🔧 技术方法**

核心技术包括：
- RLVR（可验证奖励）框架；
- GRPO、DPO‑Think、Batch‑online GRPO、RAFT 等策略的实现；
- 生成思考（chain‑of‑thought）轨迹；
- 负样本对比学习；
- 对齐训练与评估的自监督生成数据。

**📊 数据集**

使用从竞赛级编程题（约 4903 道）中抽取的代码片段，生成 2‑5 代码列表（每个列表恰好有一份完整正确代码）。数据集按编程语言、列表长度、难度划分，包含在训练集、评估集、生成器差异集、以及通过正/负修改产生的对抗性集。

**📈 对比分析**

对比方法包括完整 GRPO、去掉思考（GRPO‑Instruct）、去掉在线（Batch‑online GRPO、DPO‑Think）、去掉负样本（RAFT）。在 1.5B、7B、14B 参数模型上评估，结果显示：
- 14B 模型在最难的 OOD 场景中准确率超过 80%；
- 小模型（1.5B）在线学习缺失会导致 23% 以上性能下降；
- 大模型（14B）缺少长思考轨迹性能显著下滑；
- 负样本缺失导致训练不稳定，尤其是大模型。

**⚠️ 局限性**

限制：
- 仅采用 GRPO 及其单一变体，未覆盖其他 RL 算法；
- 数据集仅包含来自弱生成器的相对简单对比，难以评估对更高难度或真实世界代码的泛化；
- 研究聚焦于竞赛编程领域，跨领域推广需进一步验证。

---

## 203. MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents

**arXiv ID:** 2601.12346 | [PDF](https://arxiv.org/pdf/2601.12346v1)

**作者:** Peizhou Huang `[一作]` (OSU), Mi Zhang `[通讯]` (OSU)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文设计并发布了MMDR‑Bench，一个基准集，用于评估深度研究代理在多模态（文本+图像）下的端到端研究流程，包括检索、推理和报告生成。

**💡 创新点**

创新点包括：①提出三阶段统一评估框架（FLAE、TRACE、MOSAIC）兼顾报告质量、引用可信度与文本‑视觉一致性；②引入视觉证据忠实度（VEF）硬门槛，强制模型严格匹配视觉信息；③构建每日与研究两大场景的140任务多领域数据集，保证多模态必要性和可验证性；④公开数据、代码和评估指标，促进复现。

**🔧 技术方法**

使用技术包括：LLM 判定器（Gemini‑2.5‑Pro）进行维度打分与融合；多模态检索与工具调用；公式化文本特征提取与 LLM 评判融合；视觉解析与多模态项路由；以及对多模态数据的结构化、句子长度、图表一致性等特征统计。

**📊 数据集**

使用的数据集为 MMDR‑Bench，包含 140 任务，覆盖 21 个领域（Daily 与 Research 两模式），每任务配备文本查询与一组视觉图像，任务由博士级专家迭代打磨，保证多模态需求与可验证性。

**📈 对比分析**

在 25 个最先进 LLM 与深度研究代理上进行实验。评估得分按 20% FLAE + 50% TRACE + 30% MOSAIC 权重组合。结果显示 Gemini Deep Research（Gemini 3 Pro）整体得分最高，显示出在引用质量、文本‑视觉一致性和报告结构上的优势；同时实验揭示写作质量、引用纪律和视觉对齐之间存在显著权衡。

**⚠️ 局限性**

局限性包括：评估依赖单一 LLM 判定器，可能带来偏差；视觉理解仍受限，导致 VEF 失败率较高；检索过程中的错误与网页漂移影响评估；基准规模相对有限，未来需扩充多模态任务与更大语料库。

---

## 204. Measuring Love Toward AI: Development and Validation of the Love Attitudes Scale toward Artificial Intelligence (LAS-AI)

**arXiv ID:** 2601.12871 | [PDF](https://arxiv.org/pdf/2601.12871v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

---

## 205. Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration

**arXiv ID:** 2601.12667 | [PDF](https://arxiv.org/pdf/2601.12667v1)

**作者:** Yi Di `[一作]` (Xi'an Jiaotong University), Xuefeng Chen `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出并实现了基于大语言模型的空间航天器电源系统全流程健康管理框架SpaceHMchat，并搭建了硬件仿真平台与XJTU‑SPS数据集；

**💡 创新点**

①以AUC原则为设计指导，将工作状态识别、异常检测、故障定位、维护决策整合进对话式人机协同；②首次开源SPS AIL HM数据集；③在各子任务中实现了多技术融合（功能调用、链式思考、检索增强生成、LoRA微调等）；

**🔧 技术方法**

使用大语言模型功能调用、链式思考（CoT）、检索增强生成（RAG）、低秩适配（LoRA）微调、工具集成（MCP）等技术；

**📊 数据集**

采用XJTU‑SPS数据集（4个子集，17种故障，约70万时间戳）以及对应的仿真模型；

**📈 对比分析**

通过与基线LLM（如Qwen3‑235B）对比，SpaceHMchat在23项定量指标上表现优异：工作状态识别100%准确，异常检测工具调用率>99%，故障定位精度>90%，维护决策知识检索时间<3min；

**⚠️ 局限性**

仍处于人机协同阶段，无法完全自动化；对专业知识库的持续更新与维护需求高；在极端复杂或罕见故障下表现仍有限；缺乏大规模真实硬件验证。

---

## 206. Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition

**arXiv ID:** 2601.12522 | [PDF](https://arxiv.org/pdf/2601.12522v1)

**作者:** Asif Mohammed Samir `[一作]` (Dalhousie University), Mohammad Masudur Rahman `[通讯]` (Dalhousie University)

**通讯引用:** 963 | [OpenAlex ID](https://openalex.org/A5030616863)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种名为 CogniGent 的基于 AI 代理的缺陷定位技术，模拟开发者的动态认知调试流程，生成假设并通过因果推理、调用图导航和上下文管理来定位错误代码。

**💡 创新点**

创新点在于将多代理协作与因果推理、调用图 DFS（Click2Cause）以及基于 scratchpad 的上下文工程结合，克服传统方法忽视代码依赖、缺乏根因推理和上下文过载的问题。

**🔧 技术方法**

核心技术包括大型语言模型（LLM）与 LangGraph 框架的多代理管线、Neo4j 构建代码图谱、Lucene/BM25 检索、Click2Cause 深度优先调用图遍历、Scratchpad 上下文管理、以及多轮代理推理与验证。

**📊 数据集**

使用了 591 条来自 Bench4BL 扩展数据集（Samir 等）的 Java 项目缺陷报告，覆盖多种缺陷类型和跨文件错误。

**📈 对比分析**

与六种基线（IR、Spectrum、LocAgent 等）对比，CogniGent 在 MAP 和 MRR 上分别提升了 23.33–38.57% 与 25.14–53.74%，并在 HIT@K 方面亦显示显著优势，统计检验表明差异显著。

**⚠️ 局限性**

局限包括仅在 Java 项目上验证、对 LLM 计算成本敏感、缺少对多语言或大型项目的通用性评估，以及对假设生成与验证过程的可解释性仍需改进。

---

## 207. Graph Attention Networks with Physical Constraints for Anomaly Detection

**arXiv ID:** 2601.12426 | [PDF](https://arxiv.org/pdf/2601.12426v1)

**作者:** Mohammadhossein Homaei `[一作]` (Universidad de Extremadura), Mar Avila `[通讯]` (Universidad de Extremadura)

**通讯引用:** 320 | [OpenAlex ID](https://openalex.org/A5082036181)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `3f18e8e3-0266-457c-8567-9039b6d2394d` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

设计并验证了一种基于物理约束的图注意力网络（Physics‑GAT）用于水分配系统的异常检测。

**💡 创新点**

将压降与质量守恒偏差的归一化物理特征与图注意力网络、双向LSTM和多尺度融合相结合，既保留拓扑信息又提升鲁棒性与可解释性。

**🔧 技术方法**

物理信息嵌入（质量/能量残差）、图注意力网络（GAT）、双向LSTM、适应性多尺度融合、交叉熵+物理正则损失、Adam + cosine 调度等技术。

**📊 数据集**

BATADAL基准的C‑Town网络以及2024年多网络数据集（D‑Town、L‑Town、Modena）进行实验。

**📈 对比分析**

与模型基础方法、CVAE、BiLSTM、GCN等基线在F1和检测延迟上比较，Physics‑GAT在BATADAL上取得F1=0.979、TTD1.44h，比最佳基线提升3.3pp，Cohen's d=1.24。

**⚠️ 局限性**

对极端参数误差仍略有下降，GAT计算复杂度随节点数上升，且未评估对抗性攻击鲁棒性。

---

## 208. SWORD: A Secure LoW-Latency Offline-First Authentication and Data Sharing Scheme for Resource Constrained Distributed Networks

**arXiv ID:** 2601.12875 | [PDF](https://arxiv.org/pdf/2601.12875v1)

**作者:** Faisal Haque Bappy `[一作]` (University of Maryland Baltimore County), Tariqul Islam `[通讯]` (University of Maryland Baltimore County)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b`

**🎯 论文内容**

本文提出了一种面向资源受限分布式网络的离线优先身份验证与数据共享方案，利用接近度聚类与临时身份验证账本实现低延迟、去中心化的身份认证和数据交换。

**💡 创新点**

创新点包括：① 接近度聚类机制，使附近节点能自治完成离线验证；② 临时身份验证账本（TAL）与Merkle树证明，支持离线存储和高效同步；③ 阈值投票式挑战-响应协议与多节点共识，提升鲁棒性；④ 仅将区块链用于凭证管理与审计，降低存储与计算负担。

**🔧 技术方法**

采用技术：Hyperledger Fabric 权威联盟网络、DID/PKI、Merkle树、阈值投票与挑战-响应、短距离无线通信（Wi‑Fi Direct / BLE）、时间同步 OTP 等。

**📊 数据集**

使用自建实验数据集：在 Raspberry Pi 4 边缘节点上搭建 10–1000 节点的网状网络，模拟 100–1000 次/分钟的身份验证请求，收集 CPU、内存、存储使用、延迟和吞吐量等指标。

**📈 对比分析**

比较方法：与传统 Hyperledger Fabric 区块链和 OAuth 2.0 中央化方案对比；结果显示离线验证延迟约 150–200 ms，网络同步延迟 500–600 ms，吞吐量可达 65 000 TPS，资源占用保持在 40% CPU/内存，显示出与中心化方案相近的实时性能，远优于传统区块链的 3–10 s 延迟。

**⚠️ 局限性**

局限性：① 依赖权限化 Fabric 和至少 3 节点的聚类，难以在完全去中心化或极度敌对环境中部署；② 对短距离无线连通性要求高，移动性大时聚类重组频繁；③ 同步过程仍需网络接入，离线时间过长可能导致账本不一致；④ 规模扩展到数万节点时，Merkle树生成与同步成本需进一步优化。

---

## 209. Moaw: Unleashing Motion Awareness for Video Diffusion Models

**arXiv ID:** 2601.12761 | [PDF](https://arxiv.org/pdf/2601.12761v1)

**作者:** Tianqi Zhang `[一作]` (Tsinghua University), Jiwen Lu `[通讯]` (Tsinghua University)

**通讯引用:** 27956 | [OpenAlex ID](https://openalex.org/A5100460385)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `aaccfe5c-6b26-4208-b23c-35331481e142` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出Moaw框架，将运动感知扩散网络特征注入视频生成扩散模型，实现零样本运动迁移。

**💡 创新点**

通过监督训练将视频扩散模型从生成迁移到密集跟踪，构建运动标注数据集，识别并注入最强运动信息层，实现无额外适配器的零样本控制。

**🔧 技术方法**

采用Stable Video Diffusion、VAE、U‑Net、跨模态注入、HSV视觉化、PCA特征分析与ControlNet风格注入等技术。

**📊 数据集**

使用ScanNet++、Stable Virtual Camera生成的六类运动视频、CVO、Kubric以及自制的运动标注视频数据集。

**📈 对比分析**

与DAS、DELTA、SpatialTracker等方法对比，EPE平均从28.88降至15.81，推理时间从6.5 min降到0.5 min，速度提升4–75倍，精度与基线相近但更快。

**⚠️ 局限性**

模型在精度和视觉细节上仍略逊于专门跟踪网络，效果略模糊，需进一步提升细节恢复和复杂场景适应能力。

---

## 210. Blurred Drinker Paradoxes and Blurred Choice Axioms: Constructive Reverse Mathematics of the Downward Löwenheim-Skolem Theorem

**arXiv ID:** 2601.12592 | [PDF](https://arxiv.org/pdf/2601.12592v1)

**作者:** Dominik Kirst `[一作]` (Inria Paris), Haoyi Zeng `[通讯]` (Ben-Gurion University)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c`

**🎯 论文内容**

分析了下行Löwenheim‑Skolem定理在构造性逆向数学中的逻辑强度，并提出模糊饮酒悖论与模糊选择公理；

**💡 创新点**

创新点在于引入模糊化的饮酒悖论与选择公理，揭示它们与DC、LEM及Countable Choice的精细分解关系，并给出完整的逻辑分解图；

**🔧 技术方法**

采用构造性逆向数学、Henkin构造、变量环境化子模型、Coq机化证明以及逻辑层级与模糊化技术；

**📊 数据集**

无实验数据集，全部在Coq定理证明助手中完成机化；

**📈 对比分析**

通过与经典等价关系及已知DC/LEM对应关系对比，证明了新的等价与弱化关系，但未给出数值性能；

**⚠️ 局限性**

局限在于对模糊公理之间全局不可导性的证明尚未完成，需要构造分离模型；对非可数签名和上行Löwenheim‑Skolem的推广仍待研究。

---

## 211. Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations

**arXiv ID:** 2601.12338 | [PDF](https://arxiv.org/pdf/2601.12338v1)

**作者:** Kartikey Singh Bhandari `[一作]` (Birla Institute of Technology and Science), Pratik Narang `[通讯]` (Birla Institute of Technology and Science)

**通讯引用:** 3179 | [OpenAlex ID](https://openalex.org/A5089824017)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一个两阶段LLM管线，将客户评论转换为可执行的业务建议。

**💡 创新点**

创新点在于将问题抽取与建议生成模块化，并采用多专家LoRA混合以实现领域特化而不需全量微调。

**🔧 技术方法**

使用了两大LLM（Issue-LLM和Advice-LLM）、LoRA适配器、Mixture-of-LoRA专家、门控网络以及量化的Llama 3.1-8B-Instruct。

**📊 数据集**

数据集为Yelp航空与餐饮评论，利用GPT-OSS 120B生成的合成review‑issue‑advice三元组进行训练。

**📈 对比分析**

通过与基线（单一LoRA、纯提示）在航空和餐饮两行业进行比较，评估指标为八维操作性量表；混合LoRA模型在行动性、具体性等维度均优于基线，整体复合分数提升约4‑6分。

**⚠️ 局限性**

局限在于细粒度建议导致可行性得分下降，且合成数据可能偏离真实业务场景，未来需加入可行性约束和更多行业验证。

---

## 212. Augmenting Question Answering with A Hybrid RAG Approach

**arXiv ID:** 2601.12658 | [PDF](https://arxiv.org/pdf/2601.12658v1)

**作者:** Tianyi Yang `[一作]` (Fordham University), Wenqi Wei `[通讯]` (Fordham University)

**通讯引用:** 3516 | [OpenAlex ID](https://openalex.org/A5069331320)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了SSRAG，一种结合查询扩展、智能路由和图向量混合检索的检索增强生成框架，用以提升大语言模型在问答任务中的事实准确性和答案相关性。

**💡 创新点**

创新点在于：①使用轻量级提示式查询扩展提升检索精度；②基于规则的agentic路由在时间敏感和事实性问题间动态分配检索源；③融合图结构检索与向量检索并通过统一文本化与去重实现上下文一致性。

**🔧 技术方法**

技术包括LLM提示式查询扩展、规则驱动的查询路由、Neo4j图数据库与FAISS向量检索、向量化文本化、cosine相似度重新排序及LLM去重过滤。

**📊 数据集**

实验使用TruthfulQA、SQuAD v2.0和WikiQA三大公开问答数据集，检索源为2025年2月14日的Wikipedia快照。

**📈 对比分析**

与基线RAG、Graph RAG及CoT/CoVe等方法对比，SSRAG在五大LLM（GPT‑4、Llama‑2、TinyLlama、IBM Granite、Gemini 1.5）上实现%True提升至≈80–90%，ROUGE‑1、BLEU‑1显著提升，SelfCheckGPT降低至≈0.15，表明显著减少幻觉且提升答案质量。

**⚠️ 局限性**

局限性包括：图检索导致的计算开销与实时性受限；对专有LLM API依赖带来成本与可访问性问题；需要为专业领域定制检索与图构建；在大规模部署中混合检索的可扩展性尚未充分验证。

---

## 213. SSVD-O: Parameter-Efficient Fine-Tuning with Structured SVD for Speech Recognition

**arXiv ID:** 2601.12600 | [PDF](https://arxiv.org/pdf/2601.12600v1)

**作者:** Pu Wang `[一作]` (KU Leuven), Hugo Van hamme `[通讯]` (KU Leuven)

**通讯引用:** 4998 | [OpenAlex ID](https://openalex.org/A5087514947)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出并实现了 SSVD‑Outer（SSVD‑O）——一种基于结构化奇异值分解（SVD）的参数高效微调方法，能够同时在输入语音空间（inner 变换）和输出语义空间（outer 变换）上进行可控微调；

**💡 创新点**

创新点在于：① 将 SSVD 的仅内变换扩展为同时包含外变换，实现了对多模态语音‑文本任务的均衡适配；② 对 PEFT 参数预算在不同子空间的分配进行了首次系统化分析；③ 通过学习‑遗忘对比，揭示了不同变换比例对模型泛化与灾难性遗忘的影响；

**🔧 技术方法**

使用技术包括：结构化 SVD 导向低秩微调（SSVD、SSVD‑O）、LoRA、DoRA、PiSSA 等 PEFT 基线；SVD 分解、正交矩阵旋转、奇异值缩放；ESPnet 训练框架；对 Whisper‑style 语音模型（OWSM、OWLS）进行 FF 层微调；

**📊 数据集**

数据集：MyST（儿童语音对话），CGN（荷兰语与弗拉芒语多样化语音），LibriSpeech（成人语音），Multilingual LibriSpeech（多语言基准），均为公开语音识别数据集；

**📈 对比分析**

与 LoRA、DoRA、PiSSA 以及原 SSVD 在不同规模（0.1B–2B）模型上进行对比，指标为词错误率（WER）与可训练参数量；实验表明 SSVD‑O 在保持参数量低的前提下，显著缩小了与全微调的性能差距，提升了泛化能力，并且在儿童语音与地区口音任务上实现了更好的学习‑遗忘平衡；

**⚠️ 局限性**

局限性包括：① 对较大模型的外变换需要更高参数，仍然受限于预算；② 目前仅在 Whisper‑style 语音模型上验证，跨模型推广尚需进一步研究；③ 评测主要集中在语音识别任务，缺乏对其它多模态或下游任务的验证；④ 依赖预训练模型的奇异值结构，若模型结构变化或无可用 SVD 可能受限。

---

## 214. DUAP: Dual-task Universal Adversarial Perturbations Against Voice Control Systems

**arXiv ID:** 2601.12786 | [PDF](https://arxiv.org/pdf/2601.12786v1)

**作者:** Suyang Sun `[一作]` (Beijing University of Posts and Telecommunications), Jie Hao `[通讯]` (Beijing University of Posts and Telecommunications)

**通讯引用:** 1710 | [OpenAlex ID](https://openalex.org/A5003317644)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出并实现了一种双任务通用对抗扰动（DUAP），可同时对语音识别（ASR）和说话人识别（SR）造成攻击，从而彻底突破基于语音的控制系统。

**💡 创新点**

创新点在于：①证明ASR与SR的梯度几乎正交，可共用扰动；②设计动态归一化集成（DNE）提升跨模型转移性能；③加入心理声学掩蔽约束保证对抗音频隐蔽性，首次实现双任务同时成功的通用对抗攻击。

**🔧 技术方法**

核心技术包括：梯度分析、基于目标的ASR优化、DNE动态归一化策略、心理声学掩蔽约束、PGD迭代求解，并在多模型上做黑盒转移评估。

**📊 数据集**

实验数据集：LibriSpeech（train-clean 500段用于生成扰动，test-clean 150段用于评估ASR），VCTK（81位说话人，80位非目标用于评估SR），并对腾讯、阿里、科大讯飞等商业API及多种公开SR模型进行测试。

**📈 对比分析**

与单任务基线（Zong、AdvDDoS、Xie、Hanina）比较，DUAP在所有五个ASR模型上实现100%攻击成功率，在六个SR模型上也达99.9%以上，且SNR约为‑6.96 dB、MOS约为1.63，表现出显著更高的转移性与更好的音频质量。

**⚠️ 局限性**

局限性包括：①需在有梯度信息的surrogate模型上预训练，无法直接无梯度下生成扰动；②对抗扰动的规模受限于心理声学模型，过大时可能出现可听噪声；③未在真实射频环境下验证（如远距离播放）及对抗检测手段的鲁棒性仍待进一步研究。

---

## 215. Coherent Comparison as Information Cost: A Cost-First Ledger Framework for Discrete Dynamics

**arXiv ID:** 2601.12194 | [PDF](https://arxiv.org/pdf/2601.12194v1)

**作者:** Sebastian Pardo-Guerra `[一作]` (Recognition Physics Institute), Jonathan Washburn `[通讯]` (Recognition Physics Institute)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

提出了一种以比值比较为核心的信息理论成本函数，并基于该成本推导出最小化的离散账本模型，说明了原子时间步、双边记账、量化单位以及在周期闭合条件下的潜能表示。

**💡 创新点**

创新点包括：1) 通过“coherence”一致性约束唯一确定倒数成本函数 J(x)=½(x+x⁻¹)-1；2) 将成本直接作为账本结构的生成依据，得到原子时间步和双边记账；3) 在有向图上引入时间聚合闭环假设，得到路径无关的潜能；4) 在超立方体网络上给出最小周期 2^d，并给出 d=3 的条件选择。

**🔧 技术方法**

主要技术手段包括解析函数方程（d'Alembert 方程）、信息论中的相对熵思想、离散图流与离散Poincaré引理、组合学（格雷码）以及严格的定理证明与逻辑推演。

**📊 数据集**

本文为纯理论工作，无实验数据集。

**📈 对比分析**

论文未进行实验比较或性能评估，所有结论均在给定假设下的理论推导和证明基础上给出，未给出数值指标。

**⚠️ 局限性**

局限性在于：1) 结论高度依赖多项严格假设（如时间聚合闭环、无源/汇、对偶记账、量化单元等）；2) d=3 的选择仅在附加条件下成立；3) 缺乏实验验证与与实际系统的映射；4) 对动态行为（如收敛性、稳态等）的数值分析未给出。

---

## 216. HCFT: Hierarchical Convolutional Fusion Transformer for EEG Decoding

**arXiv ID:** 2601.12279 | [PDF](https://arxiv.org/pdf/2601.12279v1)

**作者:** Haodong Zhang `[一作]` (Northwestern Polytechnical University), Hongqi Li `[通讯]` (Northwestern Polytechnical University)

**通讯引用:** 2477 | [OpenAlex ID](https://openalex.org/A5067065399)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了Hierarchical Convolutional Fusion Transformer（HCFT）框架，用于 EEG 信号的跨任务解码；

**💡 创新点**

创新点在于双分支卷积编码器与层次化 Transformer 结合，利用跨注意力实现时序与时空特征的高效融合，并引入 Dynamic Tanh 正则化提升训练稳定性；

**🔧 技术方法**

采用深度可分离卷积、跨注意力、层次化自注意力、动态 Tanh 归一化等技术；

**📊 数据集**

使用 BCI Competition IV‑2b（运动想象分类）和 CHB‑MIT（癫痫发作预测）两大公开 EEG 数据集；

**📈 对比分析**

与十余种主流基线（CNN、EEGNet、Transformer 变体等）对比，HCFT 在 BCI IV‑2b 上平均准确率达 80.83%、kappa 0.6165，且在 CHB‑MIT 上实现 99.10% 敏感度、0.0236/h 假阳性率、98.82% 特异度，均显著优于现有方法；

**⚠️ 局限性**

局限在于需针对不同任务调优超参数（如归一化方式、层深），计算成本相对较高，且受限于公开数据集规模与多样性，影响跨数据集的无监督迁移与泛化能力。

---

## 217. DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity

**arXiv ID:** 2601.12505 | [PDF](https://arxiv.org/pdf/2601.12505v1)

**作者:** Ashish Raj Shekhar `[一作]` (Arizona State University), Vivek Gupta `[通讯]` (Arizona State University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种文档层防御框架（DoPE），在PDF/HTML考试中嵌入语义诱饵，阻止并检测多模态大型语言模型（MLLM）的作弊；

**💡 创新点**

创新点在于利用人类可见渲染与MLLM解析的差异，结合ICW+双层/字体重映射混合技术，实现预防和检测双重功能，并不依赖后期文本检测器；

**🔧 技术方法**

使用LLM驱动的语义诱饵生成器、文档层编码（不可见文本、Unicode重映射、双层覆盖）、LLM-as-Judge验证器以及可视化水印等技术；

**📊 数据集**

构建了1826份PDF+HTML考试对照集，来源于公开QA基准与公开课程材料，并生成多种水印/对抗变体；

**📈 对比分析**

与文本检测器及单一文档层方法对比，采用防止率和检测率指标，在GPT和Claude模型上实现91.4%检测率、8.7%误报率和96.3%拒绝率，显著优于基线；

**⚠️ 局限性**

局限性包括对截图或手动重输入不生效，依赖PDF/HTML交付，未来文档解析改进可能削弱效用，且无法阻止完全复制或重写考试的情况。

---

## 218. SGCP: A Self-Organized Game-Theoretic Framework For Collaborative Perception

**arXiv ID:** 2601.12524 | [PDF](https://arxiv.org/pdf/2601.12524v1)

**作者:** Zechuan Gong `[一作]` (University of Science and Technology of China), Wenyu Lu `[通讯]` (University of Science and Technology of China)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出一种完全去中心化的协同感知框架，车辆通过V2V自组织成协作集群，内部采用早期融合原始点云，跨集群采用后期融合检测结果，显著提升感知精度并降低通信开销。

**💡 创新点**

创新点包括：① 用感知增益驱动的联盟博弈实现集群自组织，并引入运动稳定性因子避免频繁重组；② 将资源调度建模为势能博弈，设计感知优先的近似最优求解器（PPS），保证在物理层约束下达到近似最优的感知收益；③ 采用分层融合结构将大规模协同感知任务拆解为可分布式可求解的子问题。

**🔧 技术方法**

技术手段主要是：博弈论（联盟博弈、势能博弈）、分层融合（早期+后期），以及在5G NR-V2X Mode 2环境下的V2V资源调度；实现基于CARLA+OpenCDA+NS3的联合仿真平台。

**📊 数据集**

使用的数据集和仿真平台为CARLA Town 03（城市场景）、OpenCDA（PointPillars感知模型）以及NS3（5G NR V2X信道模型），共模拟100辆车，其中20辆为装备LiDAR的CAV。

**📈 对比分析**

与四个基线（无协同、随机调度、贪婪调度、RSU辅助全感知）对比，本文方法在mAP@0.5上提升了23.5%，在mAP@0.7上提升了21.1%，同时通信开销比FullPerception低36.8%，满足100 ms协同周期的实时要求。

**⚠️ 局限性**

局限性包括：① 仍需在高速动态交叉口场景中验证鲁棒性；② 对极低信道质量或高噪声环境的适应性尚未充分评估；③ 仅考虑LiDAR数据，未覆盖多模态感知的整合；④ 需要进一步减少算法在大规模网络中的计算和广播开销。

---

## 219. Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models

**arXiv ID:** 2601.12626 | [PDF](https://arxiv.org/pdf/2601.12626v1)

**作者:** Raphi Kang `[一作]` (California Institute of Technology), Pietro Perona `[通讯]` (California Institute of Technology)

**通讯引用:** 117046 | [OpenAlex ID](https://openalex.org/A5026825380)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

研究发现 Vision‑Language Models 在空间与时间推理过程中会将视觉位置信息线性绑定到文字词嵌入（即“空间 ID”和“时间 ID”），并通过对这些 ID 的操作实现对模型输出的因果干预与诊断。

**💡 创新点**

创新点在于首次将空间/时间信息视为可线性提取、可解释的 ID 结构，并证明其在多款 SOTA VLM 与视频模型中的普遍存在、因果作用与可用于改进模型的实用价值。

**🔧 技术方法**

技术手段包括镜像交换实验、线性 ID 提取与投影、对中间层激活的目标干预、对数概率变化分析、语义空间投影、以及在 Qwen2-2B 上加入空间 ID 损失进行微调。

**📊 数据集**

使用的数据集涵盖 COCO‑Spatial（空间 VQA），合成的 Objaverse 渲染图（用于 ID 提取与对齐），以及 MVBench（视频时序问答）等。

**📈 对比分析**

通过与无干预模型对比、噪声干预对照、以及在 COCO‑Spatial 上的准确率评估，证明空间 ID 能使模型在 64% 的样本中实现置信度翻转（噪声仅 29%），并在加入空间 ID 损失的微调中提升约 6% 的准确率。

**⚠️ 局限性**

局限性包括实验仅覆盖 14B 以内模型、仅针对简单的空间/时间问答，未检验更大模型或更复杂开放式查询，且对 ID 机制的解释仍停留在线性假设层面。

---

## 220. R-VoxelMap: Accurate Voxel Mapping with Recursive Plane Fitting for Online LiDAR Odometry

**arXiv ID:** 2601.12377 | [PDF](https://arxiv.org/pdf/2601.12377v1)

**作者:** Haobo Xi `[一作]` (Nankai University), Xuebo Zhang `[通讯]` (Nankai University)

**通讯引用:** 4629 | [OpenAlex ID](https://openalex.org/A5025392915)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出并实现了 R-VoxelMap，一种基于几何驱动递归平面拟合的体素地图构造方法，用于在线 LiDAR 里程计的精确定位与建图。

**💡 创新点**

核心创新在于：①利用递归的 outlier detect‑and‑reuse 流程，在每个体素层级先用 RANSAC 去除离群点，再递归细分残余点；②通过点分布聚类的平面有效性检查，防止不同物理平面被误合并；③在多尺度体素上同时维护概率平面信息，显著降低平面参数不确定性。

**🔧 技术方法**

技术要点包括：RANSAC 迭代平面拟合、octree 递归细分、概率平面建模、迭代扩展卡尔曼滤波（IEKF）状态估计、基于链表的点存储与 LRU 缓存策略、点到平面匹配的最大后验推断。

**📊 数据集**

实验涵盖 KITTI、M2DGR、M3DGR、NTU VIRAL、AVIA 等公开与自采 LiDAR（含 LiDAR‑IMU）数据集，覆盖城市、校园、走廊、UAV 等多种场景。

**📈 对比分析**

与 Fast‑LIO2、Faster‑LIO、Fast‑GICP、KISS‑ICP、VoxelMap、C3P‑VoxelMap 等主流方法在同一配置下对比。R‑VoxelMap 在 KITTI 上平均 ATE 2.57 m（比 VoxelMap 3.30 m 低约 20%），在 M2DGR、NTU、AVIA 等数据集同样取得最优或次优 ATE，并在大多数序列实现了更低的累计漂移。运行时与内存消耗与原始 VoxelMap 相当甚至略低，模块化分析显示 RANSAC 与有效性检查带来的计算量被更快的平面收敛和优化削弱。

**⚠️ 局限性**

局限性包括：对多种超参数（RANSAC 迭代次数、阈值、树深度等）仍高度敏感，需手工调优；在极端稀疏或完全无平面结构的环境中递归细分可能导致过深树或过度分割；未来需进一步研究自适应参数调节与更鲁棒的平面检测方法。

---

## 221. Semidefinite Programming for Quantum Channel Learning

**arXiv ID:** 2601.12502 | [PDF](https://arxiv.org/pdf/2601.12502v1)

**作者:** Mikhail Gennadievich Belov `[一作]` (Lomonosov Moscow State University), Vladislav Gennadievich Malyshkin `[通讯]` (Ioffe Institute)

**通讯引用:** 572 | [OpenAlex ID](https://openalex.org/A5012005433)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

利用半正定规划（SDP）从经典输入/输出样本中重建量子通道（包括单元子通道、投影算子等），并证明在二次量子通道映射的相似度（Fidelity）可写成二次形式时，问题成为凸优化。

**💡 创新点**

创新点在于：①将通道重建转化为具有线性约束的 SDP 问题，使得求解变为凸优化；②发现通过该方法得到的 Choi 矩阵普遍具有极低的秩（少于几％），表明低 Kraus 秩通道足以拟合实验数据；③提出一种适用于投影算子重建的“比例二次形式”相似度，从而避免了传统近似相似度导致的误解。

**🔧 技术方法**

技术手段包括：构造 Choi 矩阵和四粒子关联张量 S；利用 SDP 约束（完全正、迹保持、单元矩阵保持）求解最大化二次相似度；实现时使用 CVXPY、SDPA 等商用 SDP 求解器；对非凸情况使用自研的特征值算法；并进行多种软件比较与性能分析。

**📊 数据集**

使用人工生成的数据集：随机向量（纯态）与随机量子通道映射、随机投影算子映射，以及从已知通道生成的混态-纯态映射；这些数据均为模拟样本，满足不同维度（n, D ≤ 30）和不同 Kraus 秩（1–Dn）的情形。

**📈 对比分析**

与现有的特征值算法（Appendix C）以及 SDPA、CVXOPT 等求解器进行比较；结果显示：①SDP 方案在 30 维以内可精确重建，Kraus 秩接近 1；②在 50 维时，SDPA 受内存限制；③特征值算法在小维时速度更快但在高维上不稳定；总体而言，SDP 提供了更鲁棒的全局最优解，且重建的相似度几乎达到 1。

**⚠️ 局限性**

局限性包括：①只能处理相似度可写成二次或二次比形式的情况；②对高维（>1000）或大样本量的 SDP 计算受限于内存和计算时间；③对于非凸约束（如指定低 Kraus 秩）需要额外的非凸处理；④目前仅验证了人工合成数据，实际实验数据的噪声和测量误差对重建效果的影响尚未系统评估。

---

## 222. Rapport du Projet de Recherche TRAIMA

**arXiv ID:** 2601.12844 | [PDF](https://arxiv.org/pdf/2601.12844v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86`

---

## 223. A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization

**arXiv ID:** 2601.12698 | [PDF](https://arxiv.org/pdf/2601.12698v1)

**作者:** Qiuyi Qu `[一作]` (NanKai University), Ning Zhang `[通讯]` (Beijing Institute of Computer Technology and Applications)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一种基于多智能体的两层 GPU 内核优化框架：先通过模板化重构将内核转换为可参数化模板，再在硬件资源约束下进行搜索式细粒度自动调优，并在每轮迭代中通过性能反馈驱动语义级重写，最终得到高性能、功能正确的 GPU 内核。

**💡 创新点**

创新点在于：①将传统的无监督 LLM 生成式重写与可观测的参数搜索结合，形成可解释、可控制的两层优化；②使用多智能体协作（生成、调优、测试、规划）实现闭环迭代；③通过硬件资源约束剔除无效搜索空间，显著降低随机性并提升稳定性。

**🔧 技术方法**

主要技术包括：基于模板的语义重构、参数化模板化、硬件资源感知的搜索式自动调优（如基于粒度化、向量化、共享内存利用等的离散参数搜索）、多智能体框架、自动化正确性验证、性能测量与反馈循环。

**📊 数据集**

数据集：选取了 SGLang 开源 LLM 服务框架中的三种 CUDA 内核（Kernel‑1、Kernel‑2、Kernel‑3），在常见的 LLaMA-7B、13B、70B 推理尺寸下进行实验；硬件环境为 NVIDIA TITAN RTX。

**📈 对比分析**

与基线（SGLang 原始内核）和同类多智能体优化方法 Astra 进行对比；实验显示：在三种内核上，本方法相较 Astra 取得了 22.8%–4.1% 的加速提升，整体加速率从 1.06×–3.55×，平均比 Astra 多 0.46×；在形状泛化方面，本方法实现了更稳健的跨形状性能提升。

**⚠️ 局限性**

局限性包括：①模板化过程仍需手工指定可调参数集合，可能遗漏某些优化空间；②搜索式调优对计算资源消耗高，尤其在形状多样的工作负载下仍有提升空间；③当前仅在 CUDA/TITAN RTX 上验证，跨平台（OpenCL/HIP 等）和更大规模硬件验证仍需进一步工作。

---

## 224. Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction

**arXiv ID:** 2601.12688 | [PDF](https://arxiv.org/pdf/2601.12688v1)

**作者:** Xu Zhang `[一作]` (Data Science Institute), Cunquan Qu `[通讯]` (Data Science Institute)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种多阶段推理框架MMSI，用以在多被告刑事案件中进行被告责任推理与量刑预测。

**💡 创新点**

创新点包括：①针对多被告的角色分化引入定向掩码机制；②构造对比数据对提升角色识别敏感性；③在量刑阶段通过标签广播将推理结果嵌入模型，兼顾输入长度与法律逻辑。

**🔧 技术方法**

技术主要为预训练中文BERT编码器、定向掩码、对比数据构造、标签广播、回归预测以及集成梯度解释。

**📊 数据集**

使用了自构造的IMLJP多被告司法判决数据集（包括事实描述、法院观点、主从责判定）以及公开的CMDL数据进行验证。

**📈 对比分析**

与单被告方法、提示式生成模型、法律域预训练模型及SOTA LLM（DeepSeek‑V3 等）做对比，MMSI在量刑精度（ImpScore/ImpAcc）上超过所有基线且接近或优于DeepSeek‑V3，尤其在区分主从被告方面表现突出。

**⚠️ 局限性**

局限性在于仅针对中国刑事侵伤案件验证，角色推理依赖事实描述的完整性，跨法域或其他犯罪类型的泛化需要进一步研究。

---

## 225. Traffic Collisions: Temporal Patterns and Severity-Weighted Hotspot Analysis

**arXiv ID:** 2601.12548 | [PDF](https://arxiv.org/pdf/2601.12548v1)

**作者:** Nael Alsaleh `[一作]` (American University of Ras Al Khaimah), Farah Ba Fakih `[通讯]` (American University of Ras Al Khaimah)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

对迪拜2024年11月至2025年6月的交通碰撞记录进行时空分析，重点研究碰撞严重程度的时段与热点。

**💡 创新点**

首次在迪拜城市范围内将碰撞严重程度作为权重进行热点分析，并系统评估时间段与空间热点的交互作用。

**🔧 技术方法**

采用卡方检验及Cramér V评估时间与严重度的关系，使用Getis–Ord Gi*与IDW插值进行严重度加权热点识别。

**📊 数据集**

使用迪拜Pulse开放数据平台提供的交通事故记录（约71,375条，其中33,480条碰撞事件，1,365条行人碰撞）作为数据集。

**📈 对比分析**

通过比较不同时间段和空间热点的显著性与效应量，发现夜间与周末严重度比例更高，北部与阿尔艾因‑迪拜高速为关键热点；该方法仅基于统计显著性与效应量评估，未涉及预测模型。

**⚠️ 局限性**

主要限制在缺乏事故具体因素（如速度、驾驶员/行人特征、道路类型）和社会经济、土地利用等补充信息，限制了因果推断与进一步干预设计。

---

## 226. How Clinicians Think and What AI Can Learn From It

**arXiv ID:** 2601.12547 | [PDF](https://arxiv.org/pdf/2601.12547v1)

**作者:** Dipayan Sengupta `[一作]` (Charnock Hospital), Saumya Panda `[通讯]` (Jagannath Gupta Institute of Medical Sciences)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

本文提出将临床 AI 的决策核心从“精确预测”转向基于“稳健序数非补偿”规则的行动选择，并给出可实现的系统蓝图。

**💡 创新点**

创新点在于把“快速且节约”的启发式（fast‑and‑frugal tree）定位为更广泛的序数非补偿算法子集，强调在测量不稳定、偏好不完全、数据粗糙的真实临床环境下优先使用不受数值尺度影响的决策规则；同时提出“选择性复杂度”原则，即仅在能真正改变决策时才投入深度计算。

**🔧 技术方法**

主要技术包括：基于贝叶斯/不确定性集的信念建模；约束、可达性、ε-优势等序数非补偿过滤器；可扩展的快启发式学习；以及将决策层与表示层分离的多层架构。

**📊 数据集**

文中未给出单一实验数据集，而是以典型的电子健康记录（EHR）、标签噪声、缺失机制和数据漂移为例说明设计与评估思路；若要实现可复现，建议使用公开的临床预测数据集（如MIMIC‑III、eICU）或自有医院 EHR 数据。

**📈 对比分析**

与传统单一风险评分或阈值决策方案相比，序数优先系统在阈值紧张区间表现出更高的净效益、更低的错误决策概率、减少无效检查和提示疲劳，并在时间漂移和偏好不确定性下保持更稳健的行动一致性；评估指标包括净收益曲线、决策不稳定率、集合大小与覆盖率以及资源消耗等。

**⚠️ 局限性**

局限性包括：需要在临床上精确定义 ε、阈值和不确定性集合，若设定过宽易导致过度保守；对高度数值可度量的情境（如精确成本效益分析）仍需引入卡迪亚量化；实现时需结合专业知识和透明校准，否则可能产生过度简化或信息缺失。

---

## 227. Creating Disability Story Videos with Generative AI: Motivation, Expression, and Sharing

**arXiv ID:** 2601.12617 | [PDF](https://arxiv.org/pdf/2601.12617v1)

**作者:** Shuo Niu `[一作]` (Clark University), Hyungsin Kim `[通讯]` (Clark University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

研究了9位残障人士使用ChatGPT、DALL‑E和ElevenLabs生成短视频的过程与效果

**💡 创新点**

提出了“Momentous Depiction”框架，阐明了GenAI在残障叙事中的四大功能与局限

**🔧 技术方法**

利用ChatGPT生成脚本、DALL‑E生成图像、ElevenLabs生成语音以及CapCut编辑视频

**📊 数据集**

使用来自残障倡导团体的9名参与者的自述故事与生成的多模态内容

**📈 对比分析**

通过主题分析对生成内容的质量、情感表达和分享意图进行定性评估，未给出量化指标

**⚠️ 局限性**

样本规模小、受试者群体单一、仅使用有限的GenAI工具、缺乏长期使用或专业创作者的视角

---

## 228. LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH

**arXiv ID:** 2601.12355 | [PDF](https://arxiv.org/pdf/2601.12355v1)

**作者:** Beicheng Xu `[一作]` (Peking University), Bin Cui `[通讯]` (Peking University)

**通讯引用:** 12540 | [OpenAlex ID](https://openalex.org/A5062357883)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个将大型语言模型（LLM）与贝叶斯优化（BO）通过蒙特卡罗树搜索（MCTS）协同，专门用于解决算法选择与超参数调优（CASH）问题的框架。

**💡 创新点**

创新点：1) Selective Tuning Memory (STM) 机制，按算法聚焦历史并结合全局/局部记忆，显著提升LLM上下文利用；2) MCTS结构实现层次化的探索-利用平衡，既在算法层面也在超参数子空间层面进行决策；3) 动态 BO–LLM 切换策略，基于模型可靠性自动在早期偏向 LLM，后期偏向 BO，实现在整个搜索过程中的最优协同。

**🔧 技术方法**

使用技术：GPT‑4o‑mini LLM、Gaussian Process + EI 的贝叶斯优化、蒙特卡罗树搜索（PUCT）、反思机制（Reflexion）以及 STM 记忆检索。

**📊 数据集**

数据集：AutoML Benchmark (AMLB) 104 个任务（71 分类 + 33 回归），每个任务训练/验证/测试分为 60%/20%/20%。

**📈 对比分析**

与 8 种基线（4 个 BO、2 个纯 LLM、2 个混合 LLM‑BO）进行对比。实验显示在 300 次配置评估后，框架在验证集上的平均排名为 2.16、测试集平均排名 3.05，均显著优于所有基线，且评估成本仅为 LLAMBO 的 1/6.8。

**⚠️ 局限性**

局限性：1) 仍受 LLM 推理成本限制；2) 在极高维或稀疏搜索空间可能需要更多迭代；3) 对超参数（如 MCTS 采样比例、STM 记忆阈值）敏感；4) 目前仅在 CASH 场景验证，尚未在更广泛的黑盒优化任务中检验。

---

## 229. Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?

**arXiv ID:** 2601.12812 | [PDF](https://arxiv.org/pdf/2601.12812v1)

**作者:** Sushant Kumar Ray `[一作]` (University of Delhi), Usman Naseem `[通讯]` (Macquarie University)

**通讯引用:** 4113 | [OpenAlex ID](https://openalex.org/A5077006200)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

论文提出并实现了 MedAssess‑X，一种在推理时通过轻量级调控向量对临床问答模型进行激活层对齐，以提升准确性、事实一致性并降低安全错误率的框架。

**💡 创新点**

创新点在于不依赖领域特定的超参数微调或重新训练，而是利用对比式医学推理激活差分构造任务专属的 steering 向量，在推理阶段实时对模型激活进行调节，从而解决“专业化谬误”。

**🔧 技术方法**

技术包括：基于对比学习的激活向量构造、任务类型分类器路由、激活层加权调节（h_t + αv）以及多模型对齐的通用接口，适配 decoder‑only、encoder‑decoder 与专门医学 LLM。

**📊 数据集**

使用了公开的 1,077 题目专家验证 TRUE/FALSE 临床问答数据集（涵盖 triage、文献总结、患者指导三大风险模态），以及多种主流 LLM（Gemma‑3‑27B、Llama‑3‑8B‑Instruct、Mistral‑7B‑Instruct‑v0.3、DeepSeek‑7B、T5‑Large、Flan‑T5‑XL、BioBERT、PubMedBERT、BioGPT）。

**📈 对比分析**

在所有模型上通过零样本 TRUE/FALSE 提示与对齐后进行比较，MedAssess‑X 在准确率提升 4–6%，事实一致性提升 7%，安全错误率降低 50% 左右，同时引入的延迟、内存与 FLOPs 仅增加约 7–9%/6%/8%，显著缩小了通用模型与医学微调模型的性能差距。

**⚠️ 局限性**

限制包括：评估仅覆盖单一 TRUE/FALSE 数据集，缺乏多语言或更丰富问答格式；调优向量依赖有限对比样本与准确的任务分类器；仅针对文本输入且需可访问内部隐藏状态，可能不适用于所有部署环境。

---

## 230. Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface

**arXiv ID:** 2601.12666 | [PDF](https://arxiv.org/pdf/2601.12666v1)

**作者:** Zonglin Li `[一作]` (Beijing University of Posts and Telecommunications), Guoying Gu `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 11065 | [OpenAlex ID](https://openalex.org/A5070063268)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6514db3d-8de6-452c-91b7-acdb31787cc4` `5b4c1114-4a70-478e-9921-2514ee03850d` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种基于神经隐式表征的近光源彩色光度立体方法，能够通过单张RGB图像同时恢复表面法线、深度和BRDF。

**💡 创新点**

创新点在于将近光照下的彩色光度立体问题拆解为深度隐式网络与单色BRDF隐式网络的联合优化，利用单色假设和近光衰减模型，使问题从不可解转为可解，并实现仅一张图像即可得到高精度几何与材质。

**🔧 技术方法**

使用了哈希编码+SIREN的神经隐式深度表示，独立RGB分支的隐式BRDF网络，差分渲染与光度一致性损失训练，配合近光可视触觉传感器和跨色校正模块。

**📊 数据集**

实验数据包括合成的5个对象（含不同颜色、Lambertian与非Lambertian材质、平面到粗糙曲面）以及使用自制NearLightTactile视觉触觉传感器采集的真实场景图像。

**📈 对比分析**

与LSPS、LEDPS、RGB-PS、FastNFPS等方法在平均角误差（MAE）上对比，本方法在所有材质上均表现出更低的MAE，尤其在非Lambertian与近光条件下效果最优。

**⚠️ 局限性**

局限性包括对单色材质和均匀光照的假设，极其复杂纹理或光照漂移仍易出现误差；目前仅在单光源近场验证，扩展到多光源或非近场环境仍待研究。

---

## 231. Cross-reality Location Privacy Protection in 6G-enabled Vehicular Metaverses: An LLM-enhanced Hybrid Generative Diffusion Model-based Approach

**arXiv ID:** 2601.12311 | [PDF](https://arxiv.org/pdf/2601.12311v1)

**作者:** Xiaofeng Luo `[一作]` (Guangdong University of Technology), Dong In Kim `[通讯]` (Sungkyunkwan University)

**通讯引用:** 23480 | [OpenAlex ID](https://openalex.org/A5022649488)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `9cc9baba-5356-466d-81ff-d80028d90279` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了面向6G车联网元宇宙的跨现实位置隐私保护框架，利用连续位置扰动和离散AI代理迁移的混合动作来实现隐私与沉浸体验的平衡。

**💡 创新点**

创新点在于：①设计了跨现实位置熵度量，能同时评估物理与虚拟空间的隐私泄露；②将大型语言模型用于奖励函数自动生成与迭代，提升学习效率；③采用双链生成扩散模型与PPO相结合的LHDPPO算法，实现高维混合动作的高效探索。

**🔧 技术方法**

核心技术包括：大规模语言模型（LLM）奖励设计、生成扩散模型（GDM）对连续/离散动作的逆扩散生成、Proximal Policy Optimization（PPO）稳定学习、geo‑indistinguishable扰动、边缘服务器迁移决策、混合整数优化建模。

**📊 数据集**

实验使用了真实的上海出租车轨迹数据（2007年 4,316 车）、约 84 万个基站坐标（RSU）以及一个低地球轨道（LEO）卫星节点，构建 6G 车联网元宇宙仿真环境。

**📈 对比分析**

与 Geo‑I、H‑PPO、GHPPO、HGDM、PPO‑relaxed 和无LLM奖励的 HDPPO 等基线比较，LHDPPO 在交叉熵隐私度量、平均服务延迟、QoS 损失以及整体用户体验（utility）上均优于所有基线，隐私熵提升约 48.9%，延迟下降 9.3%，综合效能提升 15.6%–27.6%。

**⚠️ 局限性**

局限性包括：算法复杂度高，训练时间长；仅在特定的出租车和 RSU 数据集上验证，未覆盖多样化行驶模式；对极端网络切换或卫星链路突发中断的鲁棒性待进一步研究。

---

## 232. Dissecting Linear Recurrent Models: How Different Gating Strategies Drive Selectivity and Generalization

**arXiv ID:** 2601.12598 | [PDF](https://arxiv.org/pdf/2601.12598v1)

**作者:** Younes Bouhadjar `[一作]` (Jülich Research Centre), Emre Neftci `[通讯]` (RWTH Aachen University)

**通讯引用:** 5155 | [OpenAlex ID](https://openalex.org/A5060924942)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了SelectivBench，一个轻量级的合成基准，用于评估线性递归模型的选择性和记忆能力。

**💡 创新点**

创新在于将人工语法与可调复杂度的噪声与非语法间隙相结合，形成四个递增难度的任务，细粒度解析门控与通道混合等架构特征。

**🔧 技术方法**

采用基于规则的人工语法、拓扑熵度量、线性递归记忆网络（Mamba、DeltaNet、Gated DeltaNet 等）以及 Transformer，并在 Python/torch 环境下训练评估。

**📊 数据集**

使用 SymSeqBench 生成的合成序列数据集（200k 训练样本、1k 测试样本），并通过 TE（拓扑熵）控制语法复杂度。

**📈 对比分析**

通过四个任务的准确率比较，发现具有互补门控和快速遗忘机制的模型（Mamba、Mamba2、Gated DeltaNet、Transformer）在记忆与选择性任务中表现最佳；通道混合提升了长度泛化，softmax 注意力在极长上下文仍占优。

**⚠️ 局限性**

局限在于仅评估中等复杂度的合成语法，未涵盖更高层次的上下文自由或上下文敏感语法；缺乏自适应长序列训练（如课程学习），且对极长间隙的泛化仍有限。

---

## 233. Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection

**arXiv ID:** 2601.12379 | [PDF](https://arxiv.org/pdf/2601.12379v1)

**作者:** Jiahui Sheng `[一作]`, Shuhan Chen `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `ba576bd1-e51d-44e8-8077-fc943b333c93` `f86bf285-fd08-4156-973b-6e6481af8fa0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了 ScoreAD 方法，利用分数模型（Score-Based Generative Model）对高光谱图像中的谱数据进行异常检测。

**💡 创新点**

创新点在于将低维流形假设与分数场方向差异相结合，利用分数场在流形附近的多向分布与异常点附近的单向分布来判定异常；并通过训练的扩散模型直接估计分数。

**🔧 技术方法**

采用扩散式分数模型（SGM）+高斯扰动核 + 条件编码（双窗口邻域、FiLM 与 1D 卷积）来估计扰动谱点的分数并聚合方向。

**📊 数据集**

在四个公开高光谱数据集上验证：HYDICE、Pavia、Hyperion 和 Salinas。

**📈 对比分析**

与 10 种经典和深度学习异常检测方法（如 RXAD、CRD、LSMAD、PTA、AutoAD、RGAE、BSDM、TAEF、GT-HAD）在 AUC‑PR 与 3D‑ROC 等指标上进行对比，ScoreAD 在大多数指标上取得第一或第二名，表现出优秀的检测与背景抑制能力。

**⚠️ 局限性**

局限性包括：需在每幅图像上单独训练分数模型、对扰动时间 t 敏感、计算量相对较大，以及在异常样本距离流形较远时分数方向可能不够一致。

---

## 234. An Introduction to Razborov's Flag Algebra as a Proof System for Extremal Graph Theory

**arXiv ID:** 2601.12741 | [PDF](https://arxiv.org/pdf/2601.12741v1)

**作者:** Gyeongwon Jeong `[一作]` (KAIST), Hongseok Yang `[通讯]` (KAIST)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文综述了Razborov的旗形代数框架，并从逻辑、编程语言与形式化方法的视角阐述其语法、语义与证明策略，重点讨论了带标签变体、下移算子及其与Galois连接/范畴对偶的对应关系。

**💡 创新点**

创新点在于将旗形代数转化为逻辑系统，提出使用伴随对实现从带标签到无标签的转移，并强调此方法在自动化证明与形式化验证中的潜在价值。

**🔧 技术方法**

采用旗形代数的符号系统、下移算子、伴随对构造以及多项式平方和方法进行证明。

**📊 数据集**

无具体数据集，主要以理论与符号演示为主。

**📈 对比分析**

未进行实验比较，主要以理论证明为依据。

**⚠️ 局限性**

局限性包括下移算子/平方和策略的不可完备性、对中等规模模式图的可扩展性不足以及自动化工具的实现受限。

---

## 235. Dataset of GenAI-Assisted Information Problem Solving in Education

**arXiv ID:** 2601.12718 | [PDF](https://arxiv.org/pdf/2601.12718v1)

**作者:** Xinyu Li `[一作]`, Guanliang Chen `[通讯]` (Monash University)

**通讯引用:** 3891 | [OpenAlex ID](https://openalex.org/A5074575547)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建并公开了一个大规模、真实环境下的学生信息问题解决（IPS）与生成式AI（GenAI）互动数据集

**💡 创新点**

首次将GenAI与传统IPS多阶段过程结合，并提供多模态细粒度行为轨迹与对话注释，填补了大规模真实数据缺口

**🔧 技术方法**

使用FLoRA平台（集成GPT‑4o聊天机器人、笔记和写作工具）、日志记录、对话编码与Python数据处理

**📊 数据集**

由519名研究生完成的两周数据科学项目提案任务产生的对话、写作、注释、日志和评估分数等多模态数据

**📈 对比分析**

通过对比使用与不使用GenAI的学生、使用强度分析及后期评估得分，展示GenAI辅助可提升写作质量与学习体验，可用回归/差分差异等方法评估效果

**⚠️ 局限性**

样本仅限澳大利亚研究生、对话主要为英文、存在自选使用偏倚以及缺乏对不同学科与不同水平学生的广泛推广

---

## 236. A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection

**arXiv ID:** 2601.12745 | [PDF](https://arxiv.org/pdf/2601.12745v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 237. Multimodal Multi-Agent Empowered Legal Judgment Prediction

**arXiv ID:** 2601.12815 | [PDF](https://arxiv.org/pdf/2601.12815v1)

**作者:** Zhaolu Kang `[一作]` (Peking University), Kaiyue Zhou `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了JurismMA多代理框架，用于从案件事实预测法律判决并构建了大规模多模态司法数据集JurismMM。

**💡 创新点**

通过六阶段分解、六角色协同和知识检索模块，模拟真实法庭程序，解决多罪名、多证据及多模态输入的挑战。

**🔧 技术方法**

采用大语言模型（GPT‑4o、Qwen2.5‑VL‑7B 等）、多模态检索、知识库检索、向量相似度对齐与加权算法。

**📊 数据集**

使用JurismMM‑Text（101,544 份最新司法判决）和JurismMM‑Video（83 份多模态案例）两大数据集。

**📈 对比分析**

在 JurismMM‑Text、LawBench 以及传统文本 CNN、TOPJUDGE、MPBFN 等基线模型上进行对比，JurismMA 在法律条文、罪名与处罚时长预测的 Acc./F1/宏观精度等指标均显著提升，提升幅度约 10–20%。

**⚠️ 局限性**

仍需人工构建法律知识库，且多模态样本规模有限；模型对复杂法条推理深度和跨域适用性仍有提升空间。

---

## 238. SplittingSecrets: A Compiler-Based Defense for Preventing Data Memory-Dependent Prefetcher Side-Channels

**arXiv ID:** 2601.12270 | [PDF](https://arxiv.org/pdf/2601.12270v1)

**作者:** Reshabh K Sharma `[一作]` (University of Washington), David Kohlbrenner `[通讯]` (University of Washington)

**通讯引用:** 877 | [OpenAlex ID](https://openalex.org/A5019838475)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

提供编译器层面的防御，通过改写内存操作，使密钥等秘密数据在内存中不符合预取器地址格式，阻止数据内存依赖预取器（DMP）侧信道泄漏。

**💡 创新点**

创新点在于不需要对 DMP 内部逻辑建模，而是利用所有 DMP 需要地址且地址须在同一 4GB 窗口的事实，用固定高 32 位前缀将秘密拆分并存储，确保任何 64 位对齐块在内存中不满足预取条件；同时实现了全源级与编译器生成的内存操作转换，支持 AArch64。

**🔧 技术方法**

采用 LLVM IR / MIR 转换通道，动态标签高位指针标记秘密，分块存储与拼接，运行时记录额外内存映射；使用固定前缀掩码实现地址无效化；实现了自定义分配器、全局变量标记等；利用系统调用拦截、重写 libc。

**📊 数据集**

以 libsodium 加密库为评测数据集，包含多种加密原语；使用其测试套件进行功能验证。

**📈 对比分析**

与未加固的基线进行比较，编译时间 +2-5%，二进制大小 +80-180%，运行时性能平均 +260-280%，内存占用 +100%；在苹果 M1 芯片上评测；证明加固后能阻止 DMP 侧信道，但带来显著成本。

**⚠️ 局限性**

局限包括：无法处理内联汇编和非 LLVM 编译的代码；仅在 AArch64 实现，x86 等需适配；全局变量的秘密标记受 Mach‑O 限制；不支持变长栈数组和可变参数函数；需要完整重编译第三方库；当前只保护存储在内存的秘密，未对派生值做污点跟踪。

---

## 239. MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction

**arXiv ID:** 2601.12822 | [PDF](https://arxiv.org/pdf/2601.12822v1)

**作者:** Wenqi Zhang `[一作]` (Fudan University), Xudong Pan `[通讯]` (Fudan University)

**通讯引用:** 476 | [OpenAlex ID](https://openalex.org/A5074846459)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 MirrorGuard，一个在文本化神经符号模拟器中训练的思考纠正模块，并在真实 GUI 环境中插桩，以减少计算机使用代理的不安全行为。

**💡 创新点**

创新点包括：①在思考层而非动作层进行安全干预，保持任务连贯；②利用神经符号模拟器生成海量高风险轨迹，避免真实系统风险；③通过视觉‑语言模型的跨模态对齐，将文本模拟中学到的安全原则直接迁移到视觉域；④在保持 7B 级模型的同时实现比 70B+ 规模防御更优性能。

**🔧 技术方法**

技术手段：神经符号模拟器、文本生成轨迹、预训练视觉‑语言模型 Qwen2.5‑VL‑7B‑Instruct、思考纠正模块、视觉‑文本潜在空间对齐、前缀注入式推理修正。

**📊 数据集**

数据集：自建的镜像世界（MirrorWorld）合成轨迹；公开基准 OS‑Harm、RiOSWorld（含 11 个子任务）与 OSWorld（benign 39 任务）进行评测；未使用真实攻击样本，全部来自合成。

**📈 对比分析**

方法对比：与 GuardAgent、Think Twice、Prompt‑Based Corrector 等现有防御对标；在 OS‑Harm 与 RiOSWorld 上，MirrorGuard 将不安全率从 66.5% 降至 13.0%（UI‑TARS）或 7.7%（Qwen2.5‑VL‑72B‑Instruct）；False Refusal Rate 仅 5.13%，比基线低约 4‑5 倍，展示了优越的安全‑效用权衡。

**⚠️ 局限性**

局限性：对极端视觉诱导攻击或隐藏式提示的鲁棒性尚待提升；跨模态迁移仍受视觉‑文本对齐质量限制；在闭源商业代理中需要通过包装实现思考层拦截，实际集成仍有技术挑战。

---

## 240. Persuasion in Online Conversations Is Associated with Alignment in Expressed Human Values

**arXiv ID:** 2601.12685 | [PDF](https://arxiv.org/pdf/2601.12685v1)

**作者:** Bhavesh Vuyyuru `[一作]` (University of Michigan), Farnaz Jahanbakhsh `[通讯]` (University of Michigan)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文利用Reddit的ChangeMyView子版块，研究了在一次对话中两方表达的价值观与说服结果（是否获得delta）之间的关系，采用Schwartz精炼价值理论和大语言模型进行价值标注，并通过混合效应逻辑回归分析价值对齐与说服的关联。

**💡 创新点**

创新点在于将价值理论与自然对话中的价值表达结合起来，首次量化了先前与会话中价值对齐对说服的影响，并发现说服并不需要评论者偏离其常态价值表达，提出价值对齐在交互中自发出现的机制。

**🔧 技术方法**

使用的技术包括Schwartz Refined Theory of Basic Human Values框架、基于提示的LLM价值标注、对价值向量的逐步更新、MAE度量以及混合效应逻辑回归模型。

**📊 数据集**

数据集为2013-2015年间的Reddit ChangeMyView（CMV）帖子与评论，经过主题过滤后保留约10,181篇帖子和23,095名参与者，关注一对一讨论并记录是否获得delta。

**📈 对比分析**

通过对比获得delta与未获得delta的线程，使用混合效应模型检验初始与累计价值对齐的影响；结果显示累计价值对齐（β≈-0.38）显著预测delta，初始对齐无显著效应；价值偏离（Normalized Shift）亦不显著。

**⚠️ 局限性**

主要局限在于：①仅以delta作为说服的客观标记，忽略部分或未被记录的观点变化；②价值标注依赖LLM，可能存在误判或主观性；③只研究一对一讨论，难以推广至多方对话或其他平台；④观察性设计无法断定因果关系。

---

## 241. Zero-Shot Embedding Drift Detection: A Lightweight Defense Against Prompt Injections in LLMs

**arXiv ID:** 2601.12359 | [PDF](https://arxiv.org/pdf/2601.12359v1)

**作者:** Anirudh Sekar `[一作]` (Algoverse AI Research), Kevin Zhu `[通讯]` (Algoverse AI Research)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种零样本嵌入漂移检测方法（ZEDD），用于在不需要模型内部访问或重训练的前提下检测LLM中的直接和间接提示注入攻击。

**💡 创新点**

创新点在于利用干净-注入提示对的语义嵌入漂移（通过余弦相似度衡量）作为检测信号，并采用无监督的高斯混合模型（GMM）和核密度估计（KDE）进行阈值自适应，确保低误报且无需人工标签。

**🔧 技术方法**

核心技术包括：① 细化的句子级BERT嵌入或LLM编码器提取；② 余弦漂移分数计算；③ 基于GMM和KDE的分布建模与阈值校准；④ 二值分类评估与误报率控制。

**📊 数据集**

使用公开的LLMail‑Inject数据集（约51,000对干净-注入提示），覆盖五类注入攻击（Jailbreak、Encoding Manipulation、System Leak、Prompt Confusion、Task Override），并在Llama‑3、Qwen‑2、Mistral、Sentence‑BERT等多种模型上进行实验。

**📈 对比分析**

与现有基于规则、模型特定或监督学习的检测方法相比，ZEDD在保持<3%误报率的前提下，整体准确率、召回率和F1得分均在90%以上，且检测延迟极低（微秒级）且可在单个GPU上完成<10分钟的微调，显示出更高的通用性与效率。

**⚠️ 局限性**

局限性包括：依赖嵌入质量，若嵌入模型无法捕捉提示语义变化可能导致漂移不足；对极度微调或精细调节的注入手段可能绕过漂移检测；在更大规模或多模态数据上可能需要进一步适配；以及在保持零样本轻量级的同时，可能无法实现与复杂对抗手段的最优防御。

---

## 242. Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models

**arXiv ID:** 2601.12247 | [PDF](https://arxiv.org/pdf/2601.12247v1)

**作者:** Miao Li `[一作]` (Georgia Institute of Technology), Pascal Van Hentenryck `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种无训练、基于规划与验证的并行解码框架 PVF，专为扩散语言模型设计。

**💡 创新点**

创新点在于：①将结构规划作为主动决策，引入“规划词”以快速构建全局骨架；②通过影响集实现两级一致性验证，保证规划不破坏模型已有高置信度推理；③将规划与 AR 回退两条路程并行评估，动态切换最优解码策略。

**🔧 技术方法**

核心技术包括：扩散语言模型的前向/后向过程；基于阈值的高置信度 token 决策；规划词候选生成、排序与批量并行评估；影响集一致性过滤与置信度最大化；AR 递归填充与验证；跨块预暴露策略。

**📊 数据集**

在六大基准上评估：GSM8K、MMLU-Pro、ARC-C、WinoGrande、HumanEval、Math，使用 LLaDA‑8B‑Instruct 与 Dream‑7B‑Instruct 两大模型。

**📈 对比分析**

与静态解码、Fast‑dLLM 与 FreeDave 进行对比，PVF 在保持或略高准确率的前提下，NFE 减少 40%‑65%，显著提升推理效率。

**⚠️ 局限性**

局限性包括：① 规划词需要人工或额外 LLM 结构蒸馏，可能对新领域适配不佳；② 仍依赖阈值与批量大小，超出实验设置可能表现下降；③ 仅在公开基准验证，未探讨对更复杂语义任务或大模型的普适性。

---

## 243. UniMo: Unified Motion Generation and Understanding with Chain of Thought

**arXiv ID:** 2601.12126 | [PDF](https://arxiv.org/pdf/2601.12126v1)

**作者:** Guocun Wang `[一作]` (Tsinghua University), Xiaoguang Han `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 5386 | [OpenAlex ID](https://openalex.org/A5042771880)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

构建统一框架 UniMo，联合 3D 人体动作生成和理解任务。

**💡 创新点**

创新点在于结合链式推理 (CoT) 与组相对策略优化 (GRPO)，实现可解释的统一模型并通过 RL 优化多令牌。

**🔧 技术方法**

使用大语言模型 Qwen2.5-3B-Instruct、VQ‑VAE 动作标记器、CoT 数据、GRPO 强化学习以及多任务联合训练。

**📊 数据集**

基于 HumanML3D 数据集，并在其上生成一致的 CoT 注释。

**📈 对比分析**

与多种基准（MoMask、MotionLLM 等）对比，UniMo 在 T2M 和 M2T 任务上均刷新了 SOTA，显著提升 R‑Precision、BLEU、CIDEr 等指标。

**⚠️ 局限性**

局限在于对高质量 CoT 注释依赖较大，且训练成本高；对极长序列的泛化能力待进一步验证。

---

## 244. SoundPlot: An Open-Source Framework for Birdsong Acoustic Analysis and Neural Synthesis with Interactive 3D Visualization

**arXiv ID:** 2601.12752 | [PDF](https://arxiv.org/pdf/2601.12752v1)

**作者:** Naqcho Ali Mehdi `[一作]` (NED University of Engineering and Technology), Aizaz Ali Larik `[通讯]` (Sukkur IBA University)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

开发并公开了 SoundPlot，一个完整的鸟鸣音频分析与神经合成框架，包括特征提取、可视化与音频重建。

**💡 创新点**

创新点在于透明可定制的模块化管道、基于 Web 的实时 3D 交互式可视化、以及用 Griffin‑Lim 对 mel 频谱进行可分析合成验证，全部开源可复现。

**🔧 技术方法**

使用的技术包括 pYIN 语调跟踪、MFCC 与谱学特征提取、mel‑spectrogram 与 Griffin‑Lim 相位重建、PCA 降维、Three.js WebGL 可视化、以及多种常用音频 I/O 与预处理工具。

**📊 数据集**

实验使用公开的鸟鸣数据集，音频时长 3–300 秒，采样率 16–48 kHz（统一 resample 至 22.05 kHz）进行评估。

**📈 对比分析**

通过 SNR、波形相关、频谱相关和 mel 相关四项指标对比，平均 mel 相关率 0.929，表明在感知层面保留了高质量的声学结构；3D 轨迹可在 60 FPS 下实时渲染，验证了实时可视化性能。

**⚠️ 局限性**

主要限制包括 Griffin‑Lim 合成产生的相位伪影、仅单声道处理、以及目前 3D 映射仅使用三维特征，缺乏更丰富的高维表示。

---

## 245. Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval

**arXiv ID:** 2601.12768 | [PDF](https://arxiv.org/pdf/2601.12768v1)

**作者:** Zequn Xie `[一作]` (Zhejiang University), Tao Jin `[通讯]` (Zhejiang University)

**通讯引用:** 7056 | [OpenAlex ID](https://openalex.org/A5100661557)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出HVP‑Net框架，通过提取并细化视觉编码器多层中间特征实现视频‑文本检索。

**💡 创新点**

创新点在于利用多层Patch处理模块（MPP）对中间层patch特征进行聚类压缩与注意力细化，构建层次化视觉表征。

**🔧 技术方法**

技术包括CLIP ViT‑B/32预训练模型、多层特征提取、密度峰值聚类、交叉注意力、词‑patch 对齐与InfoNCE对比损失。

**📊 数据集**

使用的评测数据集为MSR‑VTT、DiDeMo和ActivityNet Captions。

**📈 对比分析**

与CLIP4Clip、X‑CLIP、BiHSSP、MUSE等SOTA方法对比，HVP‑Net在MSR‑VTT文本‑视频检索上R@1提升至56.7%，在DiDeMo和ActivityNet亦刷新各自榜单。

**⚠️ 局限性**

局限在于视频‑文本检索性能仍不如文本‑视频，且层级选择采用固定三层，缺乏自适应机制。

---

## 246. From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles

**arXiv ID:** 2601.12358 | [PDF](https://arxiv.org/pdf/2601.12358v1)

**作者:** Omar Y. Goba `[一作]` (German University in Cairo), Ahmed Hussein `[通讯]` (IAV GmbH)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出一种基于大语言模型与多模态视觉模型的代理行为树生成框架，可在车辆遇到不可预知场景并且原始行为树失效时，实时生成新的适配性行为树，帮助自动驾驶车辆安全通过障碍。

**💡 创新点**

创新点在于：①采用失效触发机制，仅在原始行为树失败时才激活代理管线；②引入三代理架构（描述器、规划器、生成器），使用链式符号提示（Chain‑of‑Symbols）实现空间推理；③将 LLM 与 LMM 结合，实现从视觉输入到结构化行为树的端到端生成。

**🔧 技术方法**

技术手段包括：大语言模型（OpenAI LLM）、大多模态模型（LMM）进行图像分析，链式符号提示与上下文学习；ROS 生态下的 CARLA+Nav2 仿真栈；行为树 XML 表述；MPPI 控制器；以及基于 ROS 的传感器融合与路径规划。

**📊 数据集**

使用数据集为 Berkeley DeepDrive (BDD‑X)，共 6000 条 2 秒短视频，其中 50 条由专家标注关键性标签，用于评估描述器的性能。

**📈 对比分析**

与传统静态行为树基线进行对比：在火车阻塞场景下，原始行为树失效导致停滞，而代理生成的行为树成功通过障碍并到达目标；描述器平均绝对误差 0.5；管线平均生成时间 21.36 s，平均 token 消耗 45,111。总体而言，在模拟环境中显著提升了适配性，但延迟仍偏高。

**⚠️ 局限性**

局限性包括：①生成时延高，主要受描述器模型远程调用影响；②描述器的关键性评估精度有限；③仅在仿真环境验证，缺乏真实世界测试；④未对生成的行为树进行形式化验证；⑤需要原始行为树先失效才触发，无法覆盖所有场景；⑥对复杂模式的识别和泛化能力不足。

---

## 247. STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models

**arXiv ID:** 2601.12641 | [PDF](https://arxiv.org/pdf/2601.12641v1)

**作者:** Xiangyu Shi `[一作]` (Northwestern University), Qi Zhu `[通讯]` (Northwestern University)

**通讯引用:** 5088 | [OpenAlex ID](https://openalex.org/A5020896290)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了直接从自然语言生成 STEP 文件的 LLM 框架 STEP-LLM。

**💡 创新点**

通过 DFS 线性化 STEP 图结构、CoT 注解、检索增强微调及基于 Chamfer 距离的 RL 奖励，实现了高几何精度的 STEP 生成。

**🔧 技术方法**

使用 Llama‑3.2‑3B‑Instruct / Qwen‑2.5‑3B LLM，Unsloth+LoRA 训练，RAG 检索，DFS 线性化，CoT 结构注解，GRPO RL 奖励。

**📊 数据集**

从 ABC 数据集中抽取约 40K 个 caption–STEP 对，过滤至 <500 实体的 14,396 对用于训练。

**📈 对比分析**

与 Text2CAD 基线在渲染率、几何精度（MSCD）和实体计数对齐度比较，STEP‑LLM 95% 渲染率、MSCD 0.53 低于 3.99，实体计数更接近真实分布。

**⚠️ 局限性**

受限于模型规模、RL 训练步骤有限，难以处理极大实体数的文件，缺乏制造性约束评估。

---

## 248. HOT-POT: Optimal Transport for Sparse Stereo Matching

**arXiv ID:** 2601.12423 | [PDF](https://arxiv.org/pdf/2601.12423v1)

**作者:** Antonin Clerc `[一作]` (University of Bordeaux), Gabriele Steidl `[通讯]` (Technische Universitat Berlin)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6514db3d-8de6-452c-91b7-acdb31787cc4` `5b4c1114-4a70-478e-9921-2514ee03850d` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种基于最佳传输（OT）框架的稀疏立体匹配方法，利用相机几何中的射线距离和视线约束来构造匹配成本，并在此基础上引入正则化和层次OT实现对象级匹配。

**💡 创新点**

创新点在于：① 将3D射线距离作为新的匹配成本并结合深度正则化，显著提升噪声鲁棒性；② 采用分层OT（HOT）把点级匹配与对象级匹配耦合，解决稀疏特征匹配的“部分匹配”问题；③ 在RGB‑Thermal跨模态人脸关键点匹配中首次展示了OT/ HOT‑POT在无标注对应关系下的有效性。

**🔧 技术方法**

使用的技术包括：最佳传输（OT）与部分OT（POT）、分层OT（HOT）、Python-OT库、Sinkhorn算法、基于epipolar几何的成本函数（d^epi、d^ray、d^reg）以及三维重投影重建评价。

**📊 数据集**

数据集：① 合成人脸（四个3D人脸，468或65个关键点）；② 合成球体（5个球，10点/球）；③ 真实RGB‑RGB Mediapipe关键点；④ 真实RGB‑Thermal关键点（5、70、478点）和RGB‑Thermal视频（3人/20帧）。

**📈 对比分析**

与传统最近邻、OT、HOT、HOT‑POT等方法对比，射线距离+正则化在噪声和跨模态情境下均表现最佳：在合成人脸上误匹配率从~80%降至0%；在合成球体上误匹配率从~80%降至<10%；在RGB‑Thermal人脸匹配中，d_reg实现了100%正确率，mismatch率降至0%。

**⚠️ 局限性**

局限性包括：对相机标定误差敏感；在极高噪声或强遮挡下仍可能出现误匹配；未考虑关键点的颜色或纹理信息；仅适用于稀疏特征匹配，尚未在连续稠密匹配场景中验证；跨帧时间同步问题未在本工作中彻底解决。

---

## 249. A Unified Neural Codec Language Model for Selective Editable Text to Speech Generation

**arXiv ID:** 2601.12480 | [PDF](https://arxiv.org/pdf/2601.12480v1)

**作者:** Hanchen Pei `[一作]` (Wuhan University), Yan Lu `[通讯]` (Microsoft Corporation)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了SpeechEdit框架，利用神经音频码器语言模型实现零射文本到语音、声码转换和可控属性编辑，能够在保留原始音频的音色和韵律的同时，仅按用户指定的情感、语调或说话人身份进行选择性修改。

**💡 创新点**

创新点在于：①将多任务（零射TTS、声码转换、情感/语调编辑）统一在同一codec‑LM中，通过指令引导实现选择性属性控制；②采用Delta‑Pairs采样生成差异对进行无监督的隐式属性解耦；③构建大规模LibriEdit数据集并提供情感/语调标签，填补了现有数据集在说话人维度上的不足。

**🔧 技术方法**

技术方法包括：基于VALL-E的双阶段（AR+NAR）神经码器语言模型；指令引导接口将文本、情感标签、语调标签和说话人嵌入统一编码；speaker embedding从预训练语音识别模型提取并映射到LM空间；Delta‑Pairs采样用于训练时对齐音频与指令，强化解耦；使用EnCodec将语音转换为离散码；训练采用Adam、逆平方根学习率和top‑p采样。

**📊 数据集**

使用数据集：LibriHeavy作为原始语料；LibriEdit（从LibriHeavy划分、情感/语调标注、时长2s以上分段）共708小时、2566位说话人；LibriSpeech test‑clean用于零射TTS评估；对比实验还使用了VALL-E训练数据、Step‑Audio‑EditX、CosyVoice 2、IndexTTS 2等公开模型。

**📈 对比分析**

与四大SOTA模型（VALL-E、Step‑Audio‑EditX、CosyVoice 2、IndexTTS 2）在四项客观指标（WER、SIM、DNSMOS、ECA）以及主观评测（MOS、SSIM、CMOS）进行对比。SpeechEdit在零射TTS的WER 1.3%与VALL‑E相近，但在情感编辑的ECA达到92%/91.25%（易/难任务），显著优于对比模型；同时保持较高的DNSMOS与自然度，证明其在选择性属性控制上的领先表现。

**⚠️ 局限性**

局限性包括：①说话人嵌入仅为全局向量，难以捕捉时变音色细节；②完全依赖无监督隐式解耦，极端或罕见属性组合下的鲁棒性有限；③可控属性仅限情感、语调和说话人身份，缺乏自然语言描述或多属性协同控制；④跨性别声码转换仍出现一定的身份泄漏与模糊度。

---

## 250. Distilling Time Series Foundation Models for Efficient Forecasting

**arXiv ID:** 2601.12785 | [PDF](https://arxiv.org/pdf/2601.12785v1)

**作者:** Yuqi Li `[一作]` (City College of New York), Yingli Tian `[通讯]` (Institute of Computing Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `8d10c613-917e-4880-9716-17789f50e119` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出 DistilTS 框架，对时间序列基础模型进行知识蒸馏，解决时序预测中的长期预测难度和学生教师架构不匹配问题。

**💡 创新点**

创新点在于（1）使用时序加权目标（horizon‑weighted objectives）平衡短期与长期预测的学习信号；（2）引入分解时序对齐模块（factorized temporal alignment, FTA）弥补学生变异维度嵌入与教师点级表示的差异。

**🔧 技术方法**

采用指数加权的损失函数、分解时序对齐网络、MLP 与 Transformer（iTransformer）学生模型，以及对比的 T‑KD、FD‑KD 蒸馏方法。

**📊 数据集**

在五个公开多变量时序数据集上验证：ETTh1、ETTh2、ETTm1、ETTm2 与 Weather。

**📈 对比分析**

与多种大规模 TSFMs（TimeMoE、MOIRAI、Chronos、TimesFM、Moment）以及基线学生模型（DLinear、iTransformer）进行对比，DistilTS 在 13 个评测点取得第一名，MSE/MAE 与完整模型相当，参数规模缩小至原来的 1/150，推理速度提升至 6000×。

**⚠️ 局限性**

局限性包括：教师模型规模提升后对蒸馏收益有限；对不同架构的泛化性待进一步验证；以及在极端长预测窗口下仍需更多探索。

---

## 251. Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction

**arXiv ID:** 2601.12762 | [PDF](https://arxiv.org/pdf/2601.12762v1)

**作者:** Xingjie Gao `[一作]` (Northeastern University), Yu Gu `[通讯]` (Northeastern University)

**通讯引用:** 2781 | [OpenAlex ID](https://openalex.org/A5055431859)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种基于试验与执行（Trial‑and‑Execution）范式的工具学习框架（ToolMaster），通过先在教师模型的引导下生成包含工具试验与自我纠错的轨迹进行监督微调，再使用强化学习进一步协调试验与执行阶段，从而提升LLM在工具使用上的鲁棒性与泛化能力。

**💡 创新点**

创新点在于将工具使用训练从单纯模仿金手指轨迹转变为主动通过环境交互进行工具试验，利用试验得到的反馈构建经验，随后在执行阶段进行自我纠错和策略优化，从而显著提升对新工具或未知工具场景的适应能力。

**🔧 技术方法**

核心技术包括：① 以更强的教师模型（DeepSeek‑V3.1）生成工具试验轨迹；② 监督微调（SFT）以模仿包含试验与执行的轨迹；③ 基于Group Relative Policy Optimization（GRPO）的强化学习，用于联合优化试验与执行策略；④ 自动评判器（同一教师模型）用于生成奖励和筛选高质量轨迹。

**📊 数据集**

训练数据集：ToolBench训练集（1500条用于SFT，800条用于RL）。评估数据集：StableToolBench（in‑domain），TMDB 和 ToolHop（out‑of‑domain）。

**📈 对比分析**

与零样本LLM、SFT基线（Distill、ToolLLM）以及RL基线（StepTool、FTRL、ToolRL）对比，ToolMaster 在StableToolBench 上平均提升约7%，在TMDB 和 ToolHop 上平均提升约6.8%，并在各难度层级和工具相似度分组实验中持续表现出更高的工具调用成功率与更均匀的调用分布，证明其更强的泛化和鲁棒性。

**⚠️ 局限性**

局限性：试验阶段需要额外的工具调用，导致推理时延显著增加；模型自主探索未知工具可能触发副作用或安全风险，需要在部署时加入安全防护或沙箱机制。

---

## 252. VISPA: Pluralistic Alignment via Automatic Value Selection and Activation

**arXiv ID:** 2601.12758 | [PDF](https://arxiv.org/pdf/2601.12758v1)

**作者:** Shenyan Zheng `[一作]` (University of Waterloo), Usman Naseem `[通讯]` (Macquarie University)

**通讯引用:** 4113 | [OpenAlex ID](https://openalex.org/A5077006200)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `a2602d71-93ab-4bad-974b-672788df8193` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个无训练、基于内部激活层的价值驱动多元对齐框架，用动态价值选择和激活向导生成多样化、可解释的回应。

**💡 创新点**

首次将价值向量的内部激活操控与多目标多元对齐结合，构建可扩展的价值池并通过自动化选择实现可解释的价值表达。

**🔧 技术方法**

采用价值方向投影/平均/探针校准的激活层向导，结合自然语言推理的相关性评分进行价值选择，并通过LLM生成价值条件注释。

**📊 数据集**

在医疗领域使用的 VitalBench（13,601 条情境+5,245 题目）和通用领域的 PluralBench（包括多模式数据集），以及自建的价值对比数据集。

**📈 对比分析**

与未对齐模型、单路由、集群和角色扮演基准进行对比，在覆盖率、准确率和JS距离三种多元模式下均实现了最高或第二高得分，显著提升了多元价值覆盖与分布一致性。

**⚠️ 局限性**

实验仅限英文，价值池限定为31个值，缺乏多语言与更细粒度价值体系，且内部向导依赖预先收集的对比数据。

---

## 253. Explanation Multiplicity in SHAP: Characterization and Assessment

**arXiv ID:** 2601.12654 | [PDF](https://arxiv.org/pdf/2601.12654v1)

**作者:** Hyunseung Hwang `[一作]` (Korea Advanced Institute of Science and Technology), Steven Euijong Whang `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 4148 | [OpenAlex ID](https://openalex.org/A5012631773)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究并量化了在高风险决策领域中，SHAP 解释因随机近似导致的多重性（解释多样性）问题；

**💡 创新点**

首次将解释多重性概念化、系统化，并提出分离模型层与解释层随机性的双种子协议；

**🔧 技术方法**

利用 SHAP（KernelSHAP、LeverageSHAP）等基于背景采样的特征重要性估计器，结合随机化基线（Dirichlet、Mallows）和多种一致性度量（L2、Top‑k Jaccard、RBO、特征级敏感度）；

**📊 数据集**

在三个常见表格数据集（Virginia Housing、Adult、Titanic）上评估，使用多种模型（树模型、神经网络、TabPFN）和交叉验证；

**📈 对比分析**

比较多重性来源和度量表现，发现小数据集多由模型随机性驱动，大数据集多由解释随机性驱动；Rank‑based 评价显著揭示多重性，而传统 L2 评价往往掩盖；在高置信度预测下多重性仍显著；

**⚠️ 局限性**

局限包括：仅使用固定背景采样大小（未探索更大样本），随机基线基于经验估计，且实验仅针对 SHAP，未验证其他解释方法的通用性。

---

## 254. Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off

**arXiv ID:** 2601.12730 | [PDF](https://arxiv.org/pdf/2601.12730v1)

**作者:** Zhaochun Li `[一作]` (Beijing Institute of Technology), Yue Wang `[通讯]` (Zhongguancun Academy)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在大语言模型的强化学习微调中，提出了 Distribution-Centric Policy Optimization (DCPO)，通过在政策梯度中加入基于目标分布的 REINFORCE 正则化与双层重要性采样，实现了全在线、全 on‑policy 的可控熵调节，从而在解决熵崩溃问题的同时提升推理性能。

**💡 创新点**

创新点主要包括：
1) 将熵调节视为分布层面的正则化，而非单个样本的稀缺性；
2) 通过双层重要性采样将目标高温分布的期望梯度映射到当前策略，保持了 on‑policy 的优势；
3) 用 REINFORCE 作为正则化项既降低了方差又能持续推动探索，形成一种新的 Precision‑Prediction 取舍框架；
4) 在七个数学/代码推理基准上实现平均 20%+ 的性能提升。

**🔧 技术方法**

技术实现包括：
- REINFORCE 策略梯度正则化；
- 双层重要性采样（一次纠正采样分布，二次匹配目标分布）；
- 温度动态调节的目标分布；
- on‑policy 的 GRPO 框架改造。

**📊 数据集**

数据集与基准：
- 微调数据：DAPO‑17K；
- 评测基准：AIME24/25、AMC、GSM8K、MATH、Minerva、HMMT25、GPQA‑diamond、MMLU‑pro 等七大数学/代码推理任务。

**📈 对比分析**

对比方法：GRPO、Entropy‑Reg、Entropy‑Adv、AEPO。实验显示 DCPO 在 Qwen2.5‑7B、Qwen2.5‑Math‑7B、Qwen3‑4B 三个模型上，平均提升 3–4 分（约 17–28%），尤其在最难的竞赛式基准上显著提升；Pass@128 采样预算下同样表现最优。

**⚠️ 局限性**

局限性：
- 需要手动设定目标熵阈值 ℋ₀，过大或过小都会影响性能；
- 双层重要性采样仍存在方差积累，长时间训练可能不稳定；
- 仅在推理/数学/代码任务上验证，其他 RL 场景的通用性尚待进一步研究；
- 对模型规模和硬件资源有一定依赖，极大模型上实验尚未给出。

---

## 255. AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation

**arXiv ID:** 2601.12742 | [PDF](https://arxiv.org/pdf/2601.12742v1)

**作者:** Xuecheng Chen `[一作]` (Tsinghua University), Boyu Zhou `[通讯]` (Southern University of Science and Technology)

**通讯引用:** 2687 | [OpenAlex ID](https://openalex.org/A5101982552)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `e0540dec-d77f-42db-94ae-d039248f6393` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种双通道异步架构的无人机目标导航系统，利用Vision‑Language模型（VLM）生成稠密语义先验，并将其融合到3D价值地图中，实现持续飞行并实现对开放式目标的零-shot搜索。

**💡 创新点**

创新点包括：①将VLM从直接动作生成器转变为高层语义生成器并通过3D价值地图进行时空融合；②提出Active Dual‑Task Reasoning（ADTR）模块，利用几何与语义冗余实现关键帧选择与VLM查询的自适应控制；③提出Semantic‑Geometric Coherent Planning（SGCP）统一优化框架，通过可选优先级约束平衡语义重要性与几何效率；④异步双通道设计解决VLM推理频率与无人机实时规划频率的差异及3D场景理解的不足。

**🔧 技术方法**

采用VLM（Qwen‑VL‑Max）+ 目标检测（Grounding‑DINO）+ 语义分割（SAM2）+ 3D占据栅格+ 价值地图融合+ 前沿/视角生成+ 约束投影优化+ B‑spline轨迹平滑；仿真使用AirSim/Unreal Engine，真实部署使用Mid360 LiDAR、OAK‑4P摄像头、FAST‑LIO定位、4G网络调用VLM。

**📊 数据集**

实验数据集包括：在Unreal Engine中构建的四个大型户外环境（Downtown、Cabinlake、Neighborhood、Venice），共85个开放式任务，25个目标类别；真实实验环境三种（Park、Landscaped、Residential）每种对应不同的目标指令。

**📈 对比分析**

与PRPSearcher、UAV‑on、FlySearch、STARSearcher及人工专家基线对比，系统在成功率、SPL、DTG、飞行时间等指标上均优于所有基线，提升成功率约49%（比PRPSearcher高），飞行时间降低约59%；与人类专家相近但仍略逊，表现出较高的搜索效率与路径质量。

**⚠️ 局限性**

局限性：目前仅支持单架无人机且依赖网络连接以调用在线VLM；性能受限于目标检测器的误检与假阳性；在极度复杂或狭窄的环境中仍可能碰撞；缺乏多机协同或离线执行的支持。

---

## 256. SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection

**arXiv ID:** 2601.12507 | [PDF](https://arxiv.org/pdf/2601.12507v1)

**作者:** Ruo Qi `[一作]` (Shenzhen University), Yanshan Li `[通讯]` (Shenzhen University)

**通讯引用:** 1768 | [OpenAlex ID](https://openalex.org/A5000124250)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了 SDCoNet，一种融合超分辨率与目标检测的协同网络，用于提升低质量遥感图像中小目标的检测性能。

**💡 创新点**

创新点包括隐式特征共享实现 SR 与检测的协同优化、基于显著性预测的查询令牌筛选机制以及梯度路由策略来缓解多任务梯度冲突。

**🔧 技术方法**

使用了 Swin Transformer 共享编码器、U‑Net 结构的超分辨率解码器、显著性驱动的多尺度查询筛选、Deformable Attention 以及两阶段梯度路由训练策略。

**📊 数据集**

在 NWPU VHR‑10‑Split、DOTAv1.5‑Split 和 HRSSD‑Split 三个遥感检测基准上进行实验。

**📈 对比分析**

与多种 CNN、Transformer 及专用遥感检测器（如 DINO、DAB‑DETR、FSANet 等）在 AP、AP_s 等指标上对比，SDCoNet 在整体 AP 上提升至 0.836，AP_s 上提升 5–7% 以上，表现显著优于现有方法。

**⚠️ 局限性**

局限性在于需要手动设置任务权重，显著性预测依赖超分辨率特征的质量，对极端噪声或大尺寸目标的提升仍有限。

---

## 257. Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks

**arXiv ID:** 2601.12662 | [PDF](https://arxiv.org/pdf/2601.12662v1)

**作者:** Xingran Chen `[一作]` (Rutgers University), Shirin Saeedi Bidokhti `[通讯]` (University of Pennsylvania)

**通讯引用:** 944 | [OpenAlex ID](https://openalex.org/A5080725457)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文研究在动态多跳无线网络中，采用去中心化的采样与传输策略，以最小化时间平均估计误差；

**💡 创新点**

创新点在于提出基于图神经网络的多智能体强化学习框架，并给出其在结构相似图上的可迁移性理论证明；

**🔧 技术方法**

使用了图递归神经网络（GRNN）做演员，标准图神经网络做评论家，以及软最大化动作分布，结合IPPO/MAPPO框架实现去中心化学习；

**📊 数据集**

实验数据集包括：Watts–Strogatz 10节点网络、Stochastic Block Model 10节点网络以及真实的aus_simple 7节点网络；

**📈 对比分析**

与经典IPPO/MAPPO、均匀传输和基于时效的自适应策略对比，结果表明图式MAPPO在大多数实验中均实现更低的平均估计误差，并且在网络规模增大时迁移性能进一步提升；

**⚠️ 局限性**

局限性包括：实验受GPU资源限制仅能测试10~50节点，迁移性理论依赖图过滤器，非图过滤器的评论家可能导致性能下降；此外模型假设图结构相似，现实中拓扑变化更为复杂。

---

## 258. Learning Relativistic Geodesics and Chaotic Dynamics via Stabilized Lagrangian Neural Networks

**arXiv ID:** 2601.12519 | [PDF](https://arxiv.org/pdf/2601.12519v1)

**作者:** Abdullah Umut Hamzaogullari `[一作]` (Bogazici University), Arkadas Ozakin `[通讯]` (Bogazici University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `14d48e9d-0069-4ad9-996a-1d5968216998` `a8e75ba4-7a2d-4153-b003-06c94533add0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文改进了 Lagrangian 神经网络（LNN），提出 Hessian 正则化、物理尺度化、GeLU 激活函数以及梯度裁剪等技术，以提升在复杂机械系统和相对论测地线中的训练稳定性与预测精度。

**💡 创新点**

创新点在于：① 针对经典与相对论系统统一的 Hessian 正则化（基于特征值或 Sylvester 判别法），能够约束质量矩阵的符号；② 物理感知尺度化方法，使输入量纲一致并显著降低振荡；③ 采用 GeLU 激活与自定义 xtanh(kx) 激活，显著提升收敛速度和稳定性；④ 在 AdS4 时空中直接从轨迹数据学习测地线拉格朗日量，首次实现了非平凡黎曼几何的自动发现。

**🔧 技术方法**

技术上使用了二阶导数计算、Hessian 逆推算、正则化损失、梯度裁剪、物理尺度化、GeLU/xtanh 激活、定制初始化以及延伸训练区间等。

**📊 数据集**

使用的数据集包括：双摆、三摆、弹簧摆、球面测地线、AdS4 时空测地线等轨迹数据，全部基于数值积分生成。

**📈 对比分析**

与原始 LNN、CHNN、MASS 等方法对比，本文模型在双摆和三摆等复杂系统上显著降低验证损失（约 30–50%），稳定性提升（训练不稳定率下降 20–40%），且在 AdS4 上实现了首次从轨迹数据学习测地线拉格朗日量的精确拟合。

**⚠️ 局限性**

局限性包括：仍需可逆 Hessian，无法处理约束系统或坐标奇点（如球面极点、时空事件视界附近）；对高维系统的计算量随着 n^3 增长；缺乏自动发现并约束的机制，难以直接应用于大规模多体系统。

---

## 259. Statistical-Neural Interaction Networks for Interpretable Mixed-Type Data Imputation

**arXiv ID:** 2601.12380 | [PDF](https://arxiv.org/pdf/2601.12380v1)

**作者:** Ou Deng `[一作]` (Waseda University), Qun Jin `[通讯]` (Waseda University)

**通讯引用:** 7436 | [OpenAlex ID](https://openalex.org/A5061363755)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

提出一种统计–神经交互（SNI）框架，利用可控先验特征注意力（CPFA）进行混合类型缺失值填补，并内置依赖关系诊断。

**💡 创新点**

创新点在于：①将相关性先验与多头注意力结合，生成可调节的先验强度系数；②通过聚合注意力直接输出有向依赖矩阵，避免后置解释器；③在单一模型中兼顾统计可解释性与深度学习非线性表达力。

**🔧 技术方法**

使用多头注意力网络（CPFA）、软加权先验正则化、EM风格迭代填补、伪缺失自监督、统计后处理（StatRefine）以及焦点交叉熵等技术。

**📊 数据集**

六个跨域真实数据集：MIMIC‑IV、eICU、NHANES、Concrete Compressive Strength、AutoMPG、Communities & Crime。

**📈 对比分析**

与 Mean/Mode、KNN、MICE、MissForest、GAIN、MIWAE 等七种基线对比，SNI 在连续变量上与 MissForest/MIWAE 相近或略优，尤其在不同缺失机制下保持稳健；在类别变量上受严重不平衡影响，表现略逊；但提供了显式的依赖诊断和可调先验参数，体现解释性优势。

**⚠️ 局限性**

局限性包括：①在高度不平衡类别缺失上准确率不如树基或实例基方法；②计算成本显著高于传统填补器；③对相关性先验的敏感性（小样本或离群值可能导致先验不稳）；④依赖矩阵仅代表模型使用关系，不能直接推断因果；⑤目前仅针对静态表格，未扩展至时序缺失。

---

## 260. Learning Legged MPC with Smooth Neural Surrogates

**arXiv ID:** 2601.12169 | [PDF](https://arxiv.org/pdf/2601.12169v1)

**作者:** Samuel A. Moore `[一作]` (Duke University), Boyuan Chen `[通讯]` (Duke University)

**通讯引用:** 1525 | [OpenAlex ID](https://openalex.org/A5103094528)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文提出一种可调平滑的神经网络模型（Smooth Neural Surrogate，SNS）并配合重尾 Cauchy 似然，学习腿部机器人动力学与状态估计，从而在单射击梯度 MPC 中实现高效、可靠的零样本行走与复杂地形适应。

**💡 创新点**

创新点在于：①通过可学习的层级 Lipschitz 常数与全局平滑预算，实现对一阶和二阶导数的可控约束；②采用 Cauchy 似然替代传统 Gaussian 损失，更贴合冲击导致的冲击式残差；③将平滑模型与状态估计、域随机化统一训练，兼顾整体可控性与跨任务泛化。

**🔧 技术方法**

技术方法包括：深度 MLP 的权重规范化 + 可学习的 Lipschitz 常数、重尾 Cauchy 最大似然估计、单射击梯度 MPC（Generalized Gauss‑Newton）与采样基 DIAL‑MPC 对比、预测‑校正状态估计、以及签名距离与地形随机化。

**📊 数据集**

训练数据基于仿真四足机器人（Go2）在 MuJoCo 环境下采集的 500 万条随机动作轨迹，涵盖随机化的物理参数、地形倾斜、测量噪声等；测试集为未见地形与未见命令的零样本任务。

**📈 对比分析**

与标准 MLP、无平滑、Gaussian 损失以及采样 MPC 的对比显示：SNS‑Cauchy 模型在多种行走姿态下累计成本下降 10–50%，在更难的任务（如侧向行走、跳跃、深泥等）实现 2–50 倍成本降低，成功率从 0/5 提升至 5/5；梯度 MPC 在求解时间和决策维度上优于采样 MPC，且在 GPU 并行训练时可扩展至数千环境。

**⚠️ 局限性**

限制方面：仅在四足机器人上验证，尚未扩展至人形或多手抓取等更高维接触任务；平滑约束在极大模型容量时可能受限；Cauchy 似然虽有效但需手工设定超参数；未来需进一步探索对视觉/触觉等感知输入的整合。

---

## 261. Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI

**arXiv ID:** 2601.12646 | [PDF](https://arxiv.org/pdf/2601.12646v1)

**作者:** Ha-Chi Tran `[一作]` `[通讯]` (London School of Economics and Political Science), Ha-Chi Tran (London School of Economics and Political Science)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

对跨境人工智能风险治理进行系统综述与比较，提出多层次责任与赔偿框架。

**💡 创新点**

创新点在于将严格责任、责任分流、集体赔偿基金与国际风险共享相结合，构建面向全球化AI供应链的治理蓝图。

**🔧 技术方法**

采用比较法、案例研究与制度分析等方法。

**📊 数据集**

未使用实验性数据集，主要基于已有法律文本、政策文件与跨境案例。

**📈 对比分析**

通过对疫苗、金融、核能等领域的国际治理模式进行对比，未进行量化性能评估，而是以启发式分析呈现可迁移性与局限性。

**⚠️ 局限性**

局限在于缺乏跨境实践检验、受制于地缘政治与法律体系差异，以及AI技术快速演变带来的不确定性。

---

## 262. RLMiner: Finding the Most Frequent k-sized Subgraph via Reinforcement Learning

**arXiv ID:** 2601.12416 | [PDF](https://arxiv.org/pdf/2601.12416v1)

**作者:** Wei Huang `[一作]` (University of New South Wales), Wenjie Zhang `[通讯]` (University of New South Wales)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

构建一个多任务强化学习框架 RLMiner，自动寻找单一有标签图中大小为 k 的最频繁诱导子图。

**💡 创新点**

创新点包括：①将子图挖掘建模为多任务 MDP；②提出任务-状态感知的图神经网络，用任务与状态信息对消息传递进行门控；③使用 SAC 的离散动作版本实现高效的采样与估值；④将奖励标准化到 (0,1]，与评估指标对齐。

**🔧 技术方法**

核心技术为：强化学习（Soft Actor Critic）、任务-状态感知的 GNN（LEConv 门控）、多头注意力与双分支网络（Actor/Critic），以及奖励归一化与预测头。

**📊 数据集**

使用 TUDataset 上的五个化学/生物图数据集（ENZYMES、COX2、BZR、DHFR、PROTEINS）作为训练与评估。

**📈 对比分析**

与 Exact Enumeration、T-FSM-serial、随机采样比较；在 k=5–9 上平均逼近比率普遍高于基线，尤其在难度更大的 ENZYMES 与 PROTEINS 中运行时间提升 2000×以上，RLMiner 逼近率通常在 0.85–0.99 之间。

**⚠️ 局限性**

局限性：① 仍需对训练样本进行枚举获得真值奖励，计算昂贵；② 对未知图的奖励归一化可能偏离真实频率，导致性能波动；③ 仅针对单图频繁子图挖掘，未推广到多图数据库场景。

---

## 263. A Comprehensive Review of Bio-Inspired Approaches to Coordination, Communication, and System Architecture in Underwater Swarm Robotics

**arXiv ID:** 2601.12244 | [PDF](https://arxiv.org/pdf/2601.12244v1)

**作者:** Shyalan Ramesh `[一作]` (La Trobe University), Alex Stumpf `[通讯]` (La Trobe University)

**通讯引用:** 64 | [OpenAlex ID](https://openalex.org/A5013721809)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

综述了海洋特定的生物启发式多机器人协同算法（AFSA、WOA、CRO、MPA）及其通信、硬件与系统设计，构建了基于通信依赖、环境适应性、能效与规模化四维的分类框架，并对已有研究进行了系统性评述和融合建议。

**💡 创新点**

创新点在于首次将海洋协同算法与通信约束、硬件架构和能量管理三大维度统一映射，提出可操作的四维评价框架，揭示不同算法在海洋环境下的优势互补，为多机器人系统的跨层次设计提供决策依据。

**🔧 技术方法**

采用文献计量分析、主题编码、案例对比与跨维度矩阵构建等技术方法，并结合海洋通信（声学、光学、混合）模型、硬件平台（COMET、NEMOSENS、MONSUN II等）与能量优化策略，实现了从理论到实验验证的多级验证流程。

**📊 数据集**

利用从MDPI、OpenAlex、Scopus、Springer、ScienceDirect、IEEE、Google Scholar等七大数据库检索得到的446篇英文同行评审论文，涵盖2001–2025年海洋群机器人领域的主要成果。

**📈 对比分析**

通过文献汇总与对比，提炼了算法在通信负荷、能耗、收敛速度和规模扩展等维度的表现，引用典型基准（如PDR≥95%、能耗≤1.2 J/m、误差≤0.5 m）作为参考阈值，指出WOA与MPA在低通信需求与高能效方面领先，AFSA与CRO在适应性与局部交互方面更具优势。

**⚠️ 局限性**

主要局限包括：缺乏真实海域长期实测验证、缺少统一的跨算法性能基准与可复现实验、对新算法命名的过度依赖导致可比性不足，以及在通信与硬件层面仍未形成标准化接口与集成测试框架。

---

## 264. Generative AI Agents for Controllable and Protected Content Creation

**arXiv ID:** 2601.12348 | [PDF](https://arxiv.org/pdf/2601.12348v1)

**作者:** Haris Khan `[一作]` (National University of Sciences and Technology), Sadia Asif `[通讯]` (Rensselaer Polytechnic Institute)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种多代理框架，将生成可控性与保护机制集成

**💡 创新点**

在生成流程中联合优化可控性与水印鲁棒性，并引入人机交互控制

**🔧 技术方法**

利用大型语言模型（如GPT‑4）规划，扩散模型生成，CLIP评估，水印嵌入

**📊 数据集**

使用COCO、DrawBench等公开数据集进行评测

**📈 对比分析**

相较于单步生成提升CLIPScore 20‑25%，水印恢复率从约70%提升至90%以上

**⚠️ 局限性**

计算成本高、对抗性水印移除仍难、需多模态扩展

---

## 265. Teaching Large Reasoning Models Effective Reflection

**arXiv ID:** 2601.12720 | [PDF](https://arxiv.org/pdf/2601.12720v1)

**作者:** Hanbin Wang `[一作]` (Peking University), Lifeng Shang `[通讯]` (Huawei Technologies)

**通讯引用:** 6136 | [OpenAlex ID](https://openalex.org/A5046228314)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了两阶段方法SCFT与RLERR，利用大规模推理模型的自我批评来提升其反思质量与推理准确率。

**💡 创新点**

创新点包括：①仅用模型自身生成并通过拒绝抽样筛选的高质量批评数据进行自监督微调；②构造基于五层反思原则的分层奖励，为强化学习提供稠密的反思质量反馈；③将SCFT作为RL的初始化显著提升学习效率与最终性能。

**🔧 技术方法**

主要技术包括Chain-of-Thought生成、self-critique、拒绝抽样过滤、监督微调、强化学习（GRPO）以及LLM驱动的奖励模型与分层反思奖励设计。

**📊 数据集**

使用的主要数据集为：训练阶段采用DeepScaleR数学题集和DAPO-Math-17K；测试阶段使用AIME2024、AIME2025、MATH-500、GPQA；对比基线模型包括DeepSeek-R1、DeepScaleR-1.5B-Preview等。

**📈 对比分析**

通过Pass@1、平均准确率和Effective Reflection Ratio（ERR）等指标与自我蒸馏、SimpleRL-Zoo、Light-R1-7B-DS等先进方法对比，SCFT提升约2.6%–6%准确率并使ERR提升10%以上；RLERR进一步提升至约50% Pass@1，超过同规模最佳模型，甚至超过32B级模型。

**⚠️ 局限性**

局限性在于：对小参数模型（如1.5B）增益有限；拒绝抽样需真值标签，难以在无标签领域应用；模型可能过度谨慎，偶尔对已正确的推理步骤产生误删。

---

## 266. Auditing Meta and TikTok Research API Data Access under Article 40(12) of the Digital Services Act

**arXiv ID:** 2601.12390 | [PDF](https://arxiv.org/pdf/2601.12390v1)

**作者:** Luka Bekavac `[一作]` (University of St. Gallen), Simon Mayer `[通讯]` (University of St. Gallen)

**通讯引用:** 2111 | [OpenAlex ID](https://openalex.org/A5020177012)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

通过使用sockpuppet账号捕获平台的完整用户信息环境（PIE），与Meta和TikTok的Research API返回结果进行对比，系统性审计了两大VLOP对公共数据的覆盖与完整性。

**💡 创新点**

提出三类数据损失机制（范围收窄、元数据剥离、运营限制），并首次量化其对研究可访问数据的影响，揭示了系统性偏倚与监管缺陷。

**🔧 技术方法**

利用SOAP抓取浏览器HTTP响应、在虚拟数据/计算环境中访问Research API，并用Python脚本对齐、计数并分析帖子ID与元数据字段，形成完整的对比流程。

**📊 数据集**

采用两段选举期间的sockpuppet数据集：TikTok For You 2024美国大选期间约4000条帖子和Instagram Explore 2025德国联邦选举期间同量帖子，并收集对应的Research API返回记录。

**📈 对比分析**

通过对齐帖子ID、比较元数据字段数目与内容完整性，计算API可访问比例和缺失比例；结果显示API覆盖率仅约75%/50%，元数据缺失高达83%/42%，表明严重的系统性偏倚。

**⚠️ 局限性**

研究范围限于选举时期与两大平台，sockpuppet行为可能不完全代表真实用户，且未探讨非政治内容或其他VLOP的情况，导致结论在更广泛语境下的可推广性受限。

---

## 267. Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks

**arXiv ID:** 2601.12744 | [PDF](https://arxiv.org/pdf/2601.12744v1)

**作者:** Tasnim Ahmed `[一作]` (Queen's University), Salimur Choudhury `[通讯]` (Queen's University)

**通讯引用:** 1127 | [OpenAlex ID](https://openalex.org/A5032858073)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建了名为IntentOpt的多模态基准，评估视觉语言模型在网络意图驱动的优化代码生成任务中的表现。

**💡 创新点**

创新点在于首次将网络拓扑图与自然语言意图结合，提供多模态输入的优化问题集，并系统分析视觉参数提取与代码合成的瓶颈。

**🔧 技术方法**

采用的技术包括四种VLM（GPT‑5‑Mini、Claude‑Haiku‑4.5、Gemini‑2.5‑Flash、Llama‑3.2‑11B‑Vision）、三种提示策略（直接、角色、程序思维）以及Gurobi求解器进行代码验证。

**📊 数据集**

使用的dataset为85个验证过的网络优化实例，覆盖17个类别，提供图像+意图、纯文本两种版本。

**📈 对比分析**

通过执行成功率、最优性缺口、精确匹配率和CodeBLEU等指标比较模型，结果显示闭源模型在多模态输入下执行成功率最高（最高75%），但视觉参数提取导致12–21个百分点的性能下降，程序思维提示相反导致性能下降。

**⚠️ 局限性**

局限性包括仅关注单目标确定性优化，缺乏对不确定性、多目标和更大规模实例的测试，且评估仅基于Gurobi，未检验跨求解器可移植性。

---

## 268. Explicit Entropic Constructions for Coverage, Facility Location, and Graph Cuts

**arXiv ID:** 2601.12724 | [PDF](https://arxiv.org/pdf/2601.12724v1)

**作者:** Rishabh Iyer `[一作]` (University of Texas at Dallas), Rishabh Iyer `[通讯]` (University of Texas at Dallas)

**通讯引用:** 1909 | [OpenAlex ID](https://openalex.org/A5000529247)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文提出并构造了多类常用子模函数（如集合覆盖、设施定位、截断、饱和覆盖、图割等）在香农熵空间内的可实现性，证明这些函数可以被视为一组随机变量的熵，从而将组合信息度量（SIM）与经典信息论完全对应；

**💡 创新点**

创新点在于：①给出一系列简洁且可直接构造的随机变量模型，使得上述子模目标恰好等于对应随机集合的联合熵；②首次将这些构造与SIM框架连接，说明在这些函数上子模互信息、条件增益等均退化为传统互信息、条件熵；③通过线性代数、Vandermonde 矩阵和嵌套构造等方法，实现对“最大化”与“截断”等非线性运算的熵化；

**🔧 技术方法**

技术主要包括：利用独立随机变量构造共享/私有分量；对“max”运算使用嵌套（后缀）随机变量；截断函数采用MDS/可逆矩阵的线性变换；concave‑over‑modular函数通过权重分解为截断的线性组合；饱和覆盖使用先前的覆盖构造加上熵截断；图割函数通过为每条边引入共享与私有变量并按权重分配熵实现；

**📊 数据集**

论文为理论研究，无实验数据集；所有结果均为构造性证明与理论推导；

**📈 对比分析**

由于本研究不涉及实验评估，无法提供性能对比；其主要贡献是理论证明，将SIM度量映射到真实熵量，从而在理论上与经典信息量度完全一致；

**⚠️ 局限性**

局限性包括：①仅覆盖了若干典型子模目标，尚不清楚是否能推广至更一般的子模函数；②构造中的权重与熵的比例需要对齐，实际实现时可能需要离散化或量化；③对参数（如图割中的 λ）有严格范围限制；④未讨论对连续变量或非整数权重的扩展。

---

## 269. Many Hands Make Light Work: An LLM-based Multi-Agent System for Detecting Malicious PyPI Packages

**arXiv ID:** 2601.12148 | [PDF](https://arxiv.org/pdf/2601.12148v1)

**作者:** Muhammad Umar Zeshan `[一作]` (Università degli studi dell'Aquila), Davide Di Ruscio `[通讯]` (Università degli studi dell'Aquila)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `3855fcda-48ef-4070-a15e-803cd5c84d83` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一个多代理LLM系统（LAMP）用于检测PyPI中的恶意Python包。

**💡 创新点**

创新点在于将检索、文件提取、文件级分类和包级汇总拆分为专用代理，并将Fine‑tuned CodeBERT与LLaMA‑3协同使用，提升了可解释性与鲁棒性。

**🔧 技术方法**

使用技术包括CrewAI框架、Fine‑tuned CodeBERT分类模型、LLaMA‑3大语言模型、McNemar检验与标准机器学习评估指标。

**📊 数据集**

实验数据集为D_1（6000个setup.py，平衡的恶意/正常）和D_2（1296文件，507个包，真实不平衡）。

**📈 对比分析**

与无监督聚类、TF‑IDF堆叠、RAG、单体LLM基线比较，D_1上准确率97.7%，D_2上准确率92.4%，均显著优于基线且统计显著。

**⚠️ 局限性**

局限性包括仅处理Python源代码，未考虑编译扩展或运行时行为，依赖标签质量，且扩展到其他生态系统需改造提取器。

---

## 270. CTC-DID: CTC-Based Arabic dialect identification for streaming applications

**arXiv ID:** 2601.12199 | [PDF](https://arxiv.org/pdf/2601.12199v1)

**作者:** Muhammad Umar Farooq `[一作]` (Emotech Ltd), Oscar Saz `[通讯]` (Emotech Ltd)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出了一种基于CTC损失的方言识别方法（CTC-DID），将方言标签视为有限词汇ASR任务中的词序列，并在时间维度上连续预测方言标签。

**💡 创新点**

创新点在于将方言识别框架转化为有限词汇ASR，并通过语言无关启发式（LAH）估算标签重复次数，使模型兼容流式实时推理并适用于低资源场景。

**🔧 技术方法**

采用自监督学习的mHuBERT编码器加Transformer下游头，使用CTC损失训练，并实现了重叠块的伪流式推理；同时提供了可冻结或微调的训练模式。

**📊 数据集**

实验使用ADI‑17阿拉伯方言数据集（限制为每种方言10小时或50小时）以及Casablanca数据集做零射击评估。

**📈 对比分析**

在ADI‑17和Casablanca上，CTC‑DID在仅10小时数据下即可达到与Whisper‑medium相当的F1（≈86%），在零射击情境下优于Whisper‑medium和HuBERT，并在短语音和流式推理上表现出更低的性能衰减。

**⚠️ 局限性**

局限性包括对标签重复次数估计的依赖（虽可通过LAH解决但仍非完美）、主要在阿拉伯方言上验证，且未探讨多语言或多说话人跨域迁移的鲁棒性。

---

## 271. SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning

**arXiv ID:** 2601.12842 | [PDF](https://arxiv.org/pdf/2601.12842v1)

**作者:** Qitong Fang `[一作]` (Jilin Jianzhu University), Xu Wang `[通讯]` (Jilin Jianzhu University)

**通讯引用:** 8290 | [OpenAlex ID](https://openalex.org/A5100407929)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了 SCULPT，一个利用领域约束指导的蒙特卡洛树搜索框架，用来自动化生成高质量的数学推理工作流。

**💡 创新点**

创新点在于将六类符号约束（维度、类型、模式、幅度、深度、可多样性）嵌入 MCTS 的四个阶段，并采用自适应权重动态调整约束重要性，从而实现有序、可解释的探索。

**🔧 技术方法**

技术实现包括符号约束检查、MCTS 搜索循环、约束分数聚合、模式库构建与更新、幅度正则化以及基于权重的奖励塑造。

**📊 数据集**

实验数据集为 GSM8K、MATH 以及 GSM‑Hard，使用这些公开数学推理数据集进行验证。

**📈 对比分析**

在与 IO、Self‑Refine、MultiPersona、ADAS、AFlow 等基线对比中，SCULPT 在 GSM8K 上达 93.8%（略高于 93.5%），在 MATH 上达 57.2%（高于 56.2%），并且平均 token 量减少约 28–31%，显示出更高的准确性与效率。

**⚠️ 局限性**

局限性包括约束需针对特定任务手工设计，符号检查无法捕捉更深层语义关系，模式库依赖验证集而不适用于大幅分布漂移，幅度约束需要执行轨迹且无法早期剪枝。

---

## 272. Information Farming: From Berry Picking to Berry Growing

**arXiv ID:** 2601.12544 | [PDF](https://arxiv.org/pdf/2601.12544v1)

**作者:** Leif Azzopardi `[一作]` (University of Strathclyde), Adam Roegiest `[通讯]` (Zuva)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

提出信息耕作概念，将信息检索从为猎物式采集转变为主动种植和培育。

**💡 创新点**

创新点在于将生态学比喻从“Berry Picking”扩展为“Berry Growing”，并提出信息耕作框架与模型。

**🔧 技术方法**

利用大型语言模型（LLM）、Agentic IR、RAG、检索增强技术等生成式人工智能技术。

**📊 数据集**

未使用具体数据集，主要以文献综述和类比说明。

**📈 对比分析**

未进行实验对比，本文以理论分析与案例讨论为主，没有性能评估。

**⚠️ 局限性**

局限性在于缺乏实证验证，框架的可操作性和效果需后续实验评估。

---

## 273. Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification

**arXiv ID:** 2601.12671 | [PDF](https://arxiv.org/pdf/2601.12671v1)

**作者:** Thamara Leandra de Deus Melo `[一作]` (Federal University of Viçosa), André Ricardo Backes `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

研究在联邦学习环境下比较原始MRI与轻度预处理输入对脑瘤分类的影响，并评估测试时增强（TTA）的作用。

**💡 创新点**

创新点是首次将TTA与预处理结合，在联邦学习中系统评估其对性能提升的显著性，并通过配对t检验和Cohen’s d提供统计证据。

**🔧 技术方法**

使用的技术包括ResNet‑18卷积骨干、FedAvg联邦聚合、标准预处理流水线（灰度化、尺寸统一、轻度去噪、直方图均衡）以及10×测试时增强；评估采用准确率、F1、精确率、召回率等指标并进行统计检验。

**📊 数据集**

采用Kaggle Brain MRI Dataset（去重后6,829张2D轴向切片），四类标签（无肿瘤、胶质瘤、脑膜瘤、腺垂体瘤）。

**📈 对比分析**

通过对两条输入管线（原始 vs 预处理）在不使用TTA与使用TTA时的实验对比，发现仅使用TTA时预处理平均提升0.45%准确率（t(9)=5.72，p<0.001，Cohen’s d=1.80），表明提升显著且稳定；不使用TTA时两者差异不显著。

**⚠️ 局限性**

局限性包括仅在两台客户端、单一模型架构、缺乏患者级别划分、仅在单一数据集上验证，以及TTA增加的计算成本。

---

## 274. Hybrid Concolic Testing with Large Language Models for Guided Path Exploration

**arXiv ID:** 2601.12274 | [PDF](https://arxiv.org/pdf/2601.12274v1)

**作者:** Mahdi Eslamimehr `[一作]` `[通讯]` (Quandary Peak Research), Mahdi Eslamimehr (Quandary Peak Research)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

将大型语言模型与同义执行相结合，提出了LLM‑C框架用于指导路径探索与约束求解。

**💡 创新点**

创新点在于使用LLM进行路径优先级排序、约束变形和语义输入生成，显著缓解路径爆炸和求解器瓶颈。

**🔧 技术方法**

核心技术包括Java PathFinder的符号执行、Z3 SMT求解器、OpenAI GPT‑5.1语言模型以及REST API交互。

**📊 数据集**

使用10个人工构造的挑战性Java程序与一个简化的金融交易开源系统作为实验数据集。

**📈 对比分析**

与随机测试、遗传算法和传统同义测试进行对比，LLM‑C在分支覆盖率、路径覆盖率和求解器调用次数上分别提高约43%、43%及80%，且达到80%覆盖的时间减少至25分钟。

**⚠️ 局限性**

主要限制包括LLM调用延迟、模型成本、可重复性受限，以及对不同语言或大型应用的通用性未充分验证。

---

## 275. SmoothCLAP: Soft-Target Enhanced Contrastive Language\--Audio Pretraining for Affective Computing

**arXiv ID:** 2601.12591 | [PDF](https://arxiv.org/pdf/2601.12591v1)

**作者:** Xin Jing `[一作]` (Munich Center for Machine Learning), Björn Schuller `[通讯]` (Reliable AI)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `9ce7179e-700c-4310-ac2b-91df50ded46e` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 SmoothCLAP 方法，利用计算式语音特征的模态内相似度生成软目标标签，改进传统 CLAP 的一对一对齐方式。

**💡 创新点**

创新点在于：①将模态内自相似度与交叉模态对齐结合，产生软化目标；②用计算式语音特征（eGeMAPS 等）作为辅助标签，丰富嵌入空间；③保持与 CLAP 相同的推理流程，便于迁移与部署。

**🔧 技术方法**

使用的技术包括：对比学习（CLAP/InfoNCE）、软目标的 KL 散度损失、局部特征提取器（wav2vec2.0 等）、BERT 文本编码器、eGeMAPS 语音特征、标签离散化生成文本标签。

**📊 数据集**

训练数据：MSP‑Podcast (110 小时英语，45k 语句)。评估数据集：IEMOCAP、RAVDESS、CREMA‑D、TESS、FAU‑Aibo、ALC、SLD 等八个情感/非情感语音情绪数据集，涵盖英语与德语。

**📈 对比分析**

与 CLAP、Pengi、ParaCLAP 等基线进行比较。SmoothCLAP 在 8 个任务中 5 个获得最佳 UAR，另有 2 个次佳，整体优于传统 CLAP 变体；在非情绪任务和德语跨语言零样本推理中也表现出色。

**⚠️ 局限性**

局限性：在 3 个任务上性能低于基线，说明无“一刀切”方案；软标签的平滑因子对性能敏感；对训练数据量与多样性的依赖仍需进一步探索。

---

## 276. VASTU: Value-Aligned Social Toolkit for Online Content Curation

**arXiv ID:** 2601.12491 | [PDF](https://arxiv.org/pdf/2601.12491v1)

**作者:** Agam Goyal `[一作]` (University of Illinois), Eshwar Chandrasekharan `[通讯]` (University of Illinois)

**通讯引用:** 1542 | [OpenAlex ID](https://openalex.org/A5069919112)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了Vastu框架，构建了一个用于评估社区价值检测模型的基准与评测体系，并对不同方法进行系统比较。

**💡 创新点**

创新点在于①首次将社区价值检测任务标准化为基准，②通过15个主题多样化子版块的评论数据与丰富语言特征实现社区特定评估，③发现社区专属模型和小型微调模型优于大规模LLM及提示式模型。

**🔧 技术方法**

采用特征工程+机器学习、Transformer（BERT、XLNet）微调、提示式LLM（GPT‑4o、GPT‑5‑mini）以及4B参数小型语言模型（Gemma‑3、Qwen3）等多种技术。

**📊 数据集**

使用从2016–2017年Reddit收集的15个子版块（共计约75k条评论）的数据，评论按得分阈值标记为高/低价值，并附加句向量、亲善度、毒性、句法、LIWC等特征。

**📈 对比分析**

通过AUROC、F1和Brier等指标比较，社区特定模型在AUROC上最高（如XLNet本地微调0.72），远超全局模型（0.65）和提示式LLM（≤0.60），小型微调模型在参数量上更小但性能仍高于提示式。

**⚠️ 局限性**

局限性包括：①仅使用Reddit得分作为价值代理，易受可见度和时效影响；②样本时间仅限2016–2017，可能不代表当前社区；③评测以二分类为主，未涉及列表排序；④解释性分析基于SHAP与LLM自报理由，缺乏因果验证。

---

## 277. Efficient Local-to-Global Collaborative Perception via Joint Communication and Computation Optimization

**arXiv ID:** 2601.12749 | [PDF](https://arxiv.org/pdf/2601.12749v1)

**作者:** Hui Zhang `[一作]` (University of Science and Technology of China), Dan Keun Sung `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 6632 | [OpenAlex ID](https://openalex.org/A5019510465)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出基于 RSU 的局部到全局协同感知框架 LGCP，实现在 V2X 通信环境下的高效感知

**💡 创新点**

创新点在于将兴趣区域划分为互不重叠小区并分配 CAV 组领导者，采用集中式调度分配任务与时间表，显著减少冗余传输和计算延迟

**🔧 技术方法**

采用 5G‑V2X 侧链、RSU 中央调度、基于置信度的组分配、贪心和优先级调度算法以及现有中间协作感知模型（CoBEVT、Where2comm、CoAlign）

**📊 数据集**

用 OPV2V、V2XSet 两个仿真数据集，并在 CARLA+OpenCDA+NS3 进行大规模共模拟验证

**📈 对比分析**

与车辆基协同和边缘辅助两种基线对比，并在不同 CAV 数量、不同 Δ_g 下测量 AP@0.3/0.5/0.7、数据量和端到端延迟，结果显示 LGCP 在保持或提升检测精度的同时平均减少 44 倍数据量、约 19× 延迟（4车）或 8× 延迟（30车）

**⚠️ 局限性**

限制在于对 RSU 负载和网络切片假设，算法在极高密度交通中仍需进一步评估；同时对信号丢包、车辆动态分组的鲁棒性未充分验证

---

## 278. DCAC: Dynamic Class-Aware Cache Creates Stronger Out-of-Distribution Detectors

**arXiv ID:** 2601.12468 | [PDF](https://arxiv.org/pdf/2601.12468v1)

**作者:** Yanqi Wu `[一作]` (Sun Yat-sen University), Ruixuan Wang `[通讯]` (Sun Yat-sen University)

**通讯引用:** 3597 | [OpenAlex ID](https://openalex.org/A5100707149)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种训练无关、测试时可插拔的动态类感知缓存（DCAC）模块，用于校正深度神经网络在 OOD 样本上的过度自信预测；

**💡 创新点**

创新点在于发现同一类别下被高置信度预测的 OOD 样本视觉相似度高于 ID 样本，并利用在测试时收集的低置信度 OOD 样本构建类感知缓存，通过缓存特征与概率的两层轻量化映射实现对原始预测的校正；

**🔧 技术方法**

技术包括：基于预测熵的高熵样本筛选、固定容量的 FIFO 缓存、两层线性变换校正模块（第层计算视觉相似度，第二层加权聚合概率），以及对缓存概率的稀疏化；

**📊 数据集**

在 ImageNet‑1K 作为 ID 数据集，针对多种远 OOD（iNaturalist、SUN、Places、Textures）和近 OOD（NINCO、SSB‑hard）数据集进行评估，并在额外的五个 ID 数据集（ImageNet100、UCF101、FGVC‑Aircraft、CIFAR10/100）验证泛化能力；

**📈 对比分析**

与多种现有 OOD 检测基线（MSP、Energy、ReAct、ASH‑S、MCM、CSP 等）进行对比，DCAC 作为后处理插件后可显著提升性能，如在 ImageNet‑1K + ASH‑S 组合下 FPR95 下降 6.55%；整体表现稳健，超越或匹配大多数基线；

**⚠️ 局限性**

局限性包括：需要在测试阶段维护并更新缓存，对缓存容量、熵阈值、k 值等超参数敏感；在极端分布漂移或极少 OOD 样本时可能收集不到有效缓存；仅在分类任务上验证，跨任务迁移性尚待探索；

---

## 279. Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image

**arXiv ID:** 2601.12770 | [PDF](https://arxiv.org/pdf/2601.12770v1)

**作者:** Shuling Zhao `[一作]` (Hong Kong University of Science and Technology), Dan Xu `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 4711 | [OpenAlex ID](https://openalex.org/A5100778603)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

在单张输入图像的基础上，采用前向推理一次性重建可动画的完整头部三维高质量Gaussian头像。

**💡 创新点**

创新点包括：将Gaussian原语嵌入FLAME面部UV空间以实现动画控制；利用预训练3D GAN的全头先验与局部输入特征通过对称Transformer融合；引入3D全变差损失以消除模型空洞。

**🔧 技术方法**

使用3D Gaussian Splatting、FLAME参数化面部模型、PanoHead 3D GAN 及其反演、Transformer‑based 对称UV特征融合、3D 总变差正则化等技术。

**📊 数据集**

训练集为 VFHQ，评估使用 VFHQ、HDTF 与 MEAD 等多视角视频数据集。

**📈 对比分析**

与 StyleHEAT、GOHA、Real3DPortrait、Portrait4D/4D‑v2、GAGAvatar、LAM 等方法对比，取得更高的 PSNR/SSIM、最低的 LPIPS 与更优的动画精度（AKD/APD），且推理速度达到 246 FPS，显著优于现有方法。

**⚠️ 局限性**

局限性在于对 3D GAN 先验的依赖，极端姿态或遮挡下表现有限；FLAME 形状约束限制了形变范围；需要精确的 3DMM 参数估计。

---

## 280. CD-PIM: A High-Bandwidth and Compute-Efficient LPDDR5-Based PIM for Low-Batch LLM Acceleration on Edge-Device

**arXiv ID:** 2601.12298 | [PDF](https://arxiv.org/pdf/2601.12298v1)

**作者:** Ye Lin `[一作]` (Nanjing University), Li Du `[通讯]` (Nanjing University)

**通讯引用:** 10489 | [OpenAlex ID](https://openalex.org/A5062744012)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6`

**🎯 论文内容**

提出并实现了一种基于LPDDR5的高带宽、计算高效的处理内存（PIM）架构CD-PIM，用于在边缘设备上加速低批量LLM推理中的GEMV操作。

**💡 创新点**

创新点包括：①将每个DRAM银行分成四个伪银行（Pbank）以四倍提升内部带宽；②设计两级PIM指令（HBCEM和LBIM），实现GEMV与GEMM的并行或交叉调度；③采用可流水线的双CU计算单元，并结合K-cache列映射与V-cache行映射以充分利用CU资源；④在低批量场景下通过LBIM实现解码延迟与前填充延迟的重叠。

**🔧 技术方法**

采用LPDDR5内存技术、分段全局位线（GBL）划分、双CU并行计算、流水线加速、列/行映射优化以及新型PIM指令集等硬件与指令层面的技术。

**📊 数据集**

在NVIDIA Jetson AGX Orin（64 GB）和Apple iPhone 15 Pro（16 GB）上，对LLAMA‑1B/7B/13B模型（不同Lin/Lout配置）进行实验，未使用公开数据集，主要关注推理性能。

**📈 对比分析**

与GPU‑only基线和AttAcc PIM基线对比，HBCEM模式在单批场景下平均加速率达11.42×（GPU）和4.25×（AttAcc）；在低批量下，LBIM相较于HBCEM平均提升1.12×；多批量时，LBIM在一定参数范围内可进一步提升1.01–1.46×。

**⚠️ 局限性**

限制包括：LBIM模式下计算能力减半，导致在计算密集型工作负载中的加速效果不如HBCEM；LPDDR5银行数量有限，整体带宽提升受限；新增CU虽成本低，但仍占用约0.8%芯片面积和约144 mW功耗；实验主要基于仿真与边缘设备，未覆盖更大规模模型或更广泛的实际部署场景。

---

## 281. VR$^2$: A Co-Located Dual-Headset Platform for Touch-Enabled Human-Robot Interaction Research

**arXiv ID:** 2601.12395 | [PDF](https://arxiv.org/pdf/2601.12395v1)

**作者:** Chao Wang `[一作]` (Honda Research Institute EU), Michael Gienger `[通讯]` (Honda Research Institute EU)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本研究设计并实现了一套双头盔共位平台（VR2VR），让参与者在沉浸式VR中与虚拟机器人进行面对面互动，同时隐藏的操作者通过混合现实头盔实时遥控机器人并可与参与者进行物理触碰。系统实现了操作者的身体、面部表情、眼神等多模态数据实时映射到虚拟机器人，并支持在实验中选择性打开或关闭这些非言语通道。

**💡 创新点**

创新点包括：
1) 双头盔共位但视图不对称的架构，既保证了参与者沉浸体验，又让操作者保持对真实空间的感知；
2) 通过面部跟踪、手部跟踪和逆向运动学实现对机器人全身、面部、眼神的精准实时映射；
3) 物理触碰与视觉触感同步的对齐机制（使用3D打印手指盖与IK），使得参与者能在VR中感知与机器人相同的触碰；
4) 允许在保持物理交互不变的情况下，实验性地开启或关闭不同的非言语通道（如仅头部、头部+眼睛、全表情），为社会物理交互研究提供可控实验平台。

**🔧 技术方法**

技术手段包括：
- Meta Quest Pro VR/AR 头盔（提供面部BlendShape、眼球跟踪、手部跟踪）
- 3D打印手指盖（匹配机器人手指几何）
- 逆向运动学（IK）实现手部姿态对齐
- WebSocket 服务器实现实时数据流与同步日志
- 预录语音触发脚踏板（可无手操作）
- 共享空间锚点（Meta Spatial Anchor）实现坐标系同步
- 多模态数据采集与同步（面部表情、头部姿态、手部姿态、碰撞事件、脚踏板事件）。

**📊 数据集**

本研究未使用公开数据集，而是在Wizard‑of‑Oz实验中通过操作者与参与者的双头盔同步采集数据，形成内部实验数据集，包括：
- 参与者视线与机器人身体部位交互时间戳
- 机器人与参与者手部碰撞事件
- 两端面部BlendShape与AU（Facial Action Coding System）
- 语音脚踏板触发事件
- 头部、手部姿态轨迹。

**📈 对比分析**

对比方法：在混合设计实验中，操作者在同一脚本下分别展示三种非言语表达级别（仅头部、头部+眼睛、完整面部表情），并在功能性与玩乐两种情境下进行。通过同步日志和问卷评估用户体验与信任度，比较不同表达级别与情境对结果的影响。性能方面：系统实现低延迟（< 50 ms）实时映射，IK求解稳定；实验在实验室快速搭建，无需标定设备；同步日志完整，可用于后续行为分析。

**⚠️ 局限性**

局限性：
1) 需要操作者与参与者在同一物理空间，限制了实验部署场景；
2) 面部与手部跟踪对光照和遮挡敏感，可能导致映射误差；
3) IK仅针对拇指与食指实现精确对齐，其他手指的对齐误差仍然存在；
4) 目前仅在VR/AR 模拟中验证，未在真实机器人硬件上部署，真实性与可扩展性待进一步验证；
5) 样本量有限，实验结果的普适性需要更大规模验证。

---

## 282. A Hierarchical Benchmark of Foundation Models for Dermatology

**arXiv ID:** 2601.12382 | [PDF](https://arxiv.org/pdf/2601.12382v1)

**作者:** Furkan Yuceyalcin `[一作]` (Imperial College), Burak Temelkuran `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

对10种基础模型在皮肤病诊断层级（40子类→15主类→4/2超级类→二分类恶性）上的表现进行系统评估，使用统一的特征提取与轻量级适配器进行分类，并对嵌入空间进行可视化与错误分析。

**💡 创新点**

提出“层级评估框架”和“粒度差距”概念，揭示同一模型在高层次筛查与细粒度鉴别间性能反转；同时展示通用医学模型可与专用皮肤模型竞争，挑战“域专一”假设。

**🔧 技术方法**

基于冻结的前置模型嵌入（包括 DINOv2/3、CLIP、MedImageInsights、MedSigLip、BiomedCLIP、MONET、PanDerm、Derm Foundation、ResNet‑50），训练六种轻量级适配器（KNN、LR、SVM、RF、MLP、XGBoost），并采用加权 F1 与平衡准确率进行评估。

**📊 数据集**

使用 DERM12345 数据集（12,345 张高分辨率 dermoscopic 图像，40 个细粒度子类，划分为 9,860 训练/2,485 测试，按患者划分防止泄漏）。

**📈 对比分析**

方法通过交叉验证寻找最佳适配器，然后在测试集上聚合概率以评估各层级。结果显示，MedImageInsights 在二分类恶性任务上表现最佳（97.52%），但在 40 子类任务上仅 65.50%；相反，MedSigLip、Derm Foundation 和 MONET 在 40 子类上领先（约 69.8%），表明存在粒度差距。整体而言，所有现代基础模型均优于传统 ResNet‑50，且不同域的模型在不同粒度层级有互补优势。

**⚠️ 局限性**

主要局限：① 数据集仅来自土耳其，光照与肤色分布有限，可能影响模型泛化；② 仅评估 dermoscopic 图像，未验证在临床摄影或其他模态下的表现；③ 适配器仅为线性或浅层模型，未探究更深层微调或跨模态融合；④ 一些公开模型（如 PanDerm Large）表现异常低，说明需要进一步验证模型质量。

---

## 283. Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence

**arXiv ID:** 2601.12318 | [PDF](https://arxiv.org/pdf/2601.12318v1)

**作者:** Dehao Ying `[一作]` (Wuhan University), Wei Lu `[通讯]` (Wuhan University)

**通讯引用:** 18910 | [OpenAlex ID](https://openalex.org/A5100335597)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `67630363-6be0-4f51-ab05-7198250671a5` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本综述系统梳理并分类了文档智能领域中所有非人工生成监督信号的方法，涵盖从数据增强、从零开始生成、自动标注到自监督信号构造四大范式；

**💡 创新点**

创新点在于提出以“数据与标签可用性”为核心的资源中心化分类体系，统一了跨任务的技术选择，并构建了多层次的内在/外在评估框架；

**🔧 技术方法**

技术主要包括基于模板与渲染的生成、扩散/生成式模型的端到端合成、规则与工具驱动的自动标注、LLM驱动的语义注释，以及自监督的生成、对比与预测预训练任务；

**📊 数据集**

利用的主要数据集有公开的视觉丰富文档数据集（如 ICDAR 2015/2019、FUNSD、CORD、FUNSD、SROIE、DocVQA、ChartBench 等）以及通过生成/合成得到的人工构造数据；

**📈 对比分析**

通过与现有最强基线对比，所提出的评估框架能够衡量生成数据在下游任务中的性能提升，典型结果显示生成/增强数据可在 OCR、表格识别、信息抽取、VQA 等任务上分别提升 5%–15% 的指标；

**⚠️ 局限性**

局限性主要包括生成质量与真实数据的差距（fidelity gap）、对模型偏置与幻觉的控制不足、评估指标与人类感知的差异以及在跨域应用中的可推广性待进一步验证。

---

## 284. Confidence-based Filtering for Speech Dataset Curation with Generative Speech Enhancement Using Discrete Tokens

**arXiv ID:** 2601.12254 | [PDF](https://arxiv.org/pdf/2601.12254v1)

**作者:** Kazuki Yamauchi `[一作]` (The University of Tokyo), Shogo Seki `[通讯]` (CyberAgent)

**通讯引用:** 280 | [OpenAlex ID](https://openalex.org/A5101792863)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出一种针对离散 token 基础生成式语音增强模型的无侵入式幻觉错误过滤方法，并将其用于对野生语音数据集进行清洗。

**💡 创新点**

创新之处在于利用生成 token 的对数概率作为置信度分数，自身评估增强结果，能够有效发现传统非侵入式指标难以检测的声学与内容错误。

**🔧 技术方法**

技术上主要使用 Genhancer（基于 DAC/RVQ 的离散 token 语音增强模型），结合对 token 对数概率的计算、阈值过滤，以及 Matcha‑TTS+HiFi‑GAN 训练生成模型。

**📊 数据集**

实验使用的语料包括用于训练 GSE 的 LibriTTS‑R、EARS‑WHAM 用于验证置信度与侵入式指标的相关性，以及从 VoxCeleb1 采集的 TITW‑hard 作为野生 TTS 训练集。

**📈 对比分析**

通过与 UTMOS、DNSMOS、Whisper 置信度、CTC 分数等非侵入式指标以及 ESTOI、SI‑SDR、PESQ、SpeechBERTScore、LPS、WAcc、SpkSim 等侵入式 SE 指标对比，置信度分数与侵入式指标的 Spearman 相关系数最高；在对 TITW‑hard 进行过滤后训练的 TTS 模型在 UTMOS、DNSMOS 上均优于未过滤模型，最佳性能在保留 top 80% 语句时达到 3.80/3.17/18.14%。

**⚠️ 局限性**

局限性在于目前仅适用于离散 token 的 GSE 模型，尚未推广至连续潜空间的生成式增强模型。

---

## 285. Ethical Risks in Deploying Large Language Models: An Evaluation of Medical Ethics Jailbreaking

**arXiv ID:** 2601.12652 | [PDF](https://arxiv.org/pdf/2601.12652v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f`

---

## 286. Bengali Text Classification: An Evaluation of Large Language Model Approaches

**arXiv ID:** 2601.12132 | [PDF](https://arxiv.org/pdf/2601.12132v1)

**作者:** Md Mahmudul Hoque `[一作]` (CCN University of Science and Technology), Rahul Nandy `[通讯]` (International Islamic University Chittagong)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

使用三种大语言模型（LLaMA 3.1、LLaMA 3.2 与 Qwen 2.5）对孟加拉语报纸文章进行文本分类，并通过微调比较其性能。

**💡 创新点**

在低资源语言环境下首次将大语言模型应用于孟加拉语文本分类，并结合随机下采样、KNN聚类和LoRA/QLoRA量化微调技术，提供了可复现的基准和方法论。

**🔧 技术方法**

使用 AutoTokenizer、LoRA/QLoRA 低秩适配、AdamW 优化器、余弦学习率调度、量化 4‑bit/float16、prompt 工程、随机下采样、KNN 聚类以及可视化工具 Plotly/Seaborn 等技术。

**📊 数据集**

基于 Kaggle 上的 Prothom Alo 孟加拉语报纸数据集（约 437,948 篇文章），选取“Content”和“Category”两列，划分为 9 个主要类别。

**📈 对比分析**

采用 80%/20% 训练/测试划分，使用准确率、精确率、召回率、F1 分数和混淆矩阵进行评估。结果显示 Qwen 2.5 取得 72% 准确率，LLaMA 3.1 53% 与 LLaMA 3.2 56%，其中 Qwen 在 Sports 类别表现最优（81%）。

**⚠️ 局限性**

主要局限包括：类别不平衡影响模型表现，量化与模型规模导致信息损失，仅针对 9 个类别且仅使用两列特征，难以处理细粒度或语义重叠的类别，缺乏更大规模数据集与更多 LLM 的进一步验证。

---

## 287. One-Sided Matrix Completion from Ultra-Sparse Samples

**arXiv ID:** 2601.12213 | [PDF](https://arxiv.org/pdf/2601.12213v1)

**作者:** Hongyang R. Zhang `[一作]` (Northeastern University), Guanghui Lan `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 8719 | [OpenAlex ID](https://openalex.org/A5042544900)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文研究了在超稀疏采样条件下的矩阵补全问题，提出了一种新的无偏估计器来估计未知矩阵的第二矩阵，并通过梯度下降法填补缺失的条目。

**💡 创新点**

创新点在于提出了Hájek估计器作为一种无偏估计方法，并证明其在超稀疏条件下的有效性和低方差特性，同时建立了样本复杂度的近似最优界限。

**🔧 技术方法**

使用了Hájek估计器和梯度下降法来进行矩阵补全，特别是在处理稀疏数据时表现出色。

**📊 数据集**

使用了合成数据集和真实世界数据集进行实验，包括MovieLens和Amazon评论数据集，验证了所提方法的有效性。

**📈 对比分析**

与现有的矩阵补全方法（如核范数正则化、交替梯度下降和软插补）相比，所提方法在恢复误差上显著降低，尤其在极稀疏情况下，恢复误差减少了70%。

**⚠️ 局限性**

限制在于假设低秩因子模型的共同均值条件，未来的工作可以考虑放宽这一条件，并探讨在噪声注入情况下的敏感性分析。

---

## 288. PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition

**arXiv ID:** 2601.12798 | [PDF](https://arxiv.org/pdf/2601.12798v1)

**作者:** Zhihan Zeng `[一作]` (University of Electronic Science and Technology of China), Ning Wei `[通讯]` (University of Electronic Science and Technology of China)

**通讯引用:** 1425 | [OpenAlex ID](https://openalex.org/A5101596441)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `afceb026-1760-41ae-8d86-010831a37d97` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了 PhyG-MoE，一个物理引导的动态专家混合网络，用于高效识别 GNSS 干扰信号；

**💡 创新点**

创新点在于：① 基于功率谱密度（PSD）的物理引导路由机制，实现输入复杂度自适应资源分配；② 设计了三种异构专家（TransNeXt+CoordAttGLU、SK-GhostNet、MobileNetV4），分别针对饱和、宽带多尺度和低复杂度干扰；③ 在动态路由中引入负载均衡损失，避免专家崩溃；

**🔧 技术方法**

技术包括：多尺度注意力、坐标注意力、Ghost 模块、选择性卷积核、光纤变换、梯度裁剪、DropPath、早停、数据增强；

**📊 数据集**

使用自己构造的 21 类干扰数据集，涵盖单源、双源和三源混合，JNR 在 -25 dB~15 dB 之间，规模达 861,000 条样本；

**📈 对比分析**

与 ViT-B/16、ResNet-18、EfficientNet、TFPENet 等基线相比，PhyG-MoE 在整体准确率上达到 97.58%，比 TFPENet 高 2.1%，同时平均 FLOPs 降至 1.71 GFLOPs，参数量 11.19M，显示出更优的精度与能效平衡；

**⚠️ 局限性**

局限性包括：① 仍需在真实场景中验证鲁棒性；② 路由器仅使用 PSD，可能对极端非平稳或多频段干扰的判断不够细粒；③ 模型复杂度较高，部署在极低功耗设备上仍有挑战。

---

## 289. Encoding Emotion Through Self-Supervised Eye Movement Reconstruction

**arXiv ID:** 2601.12534 | [PDF](https://arxiv.org/pdf/2601.12534v1)

**作者:** Marcus Ma `[一作]`, Shrikanth Narayanan `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种基于自监督眼动重构的Transformer模型，对低分辨率自然视频中的眼动进行预训练，然后微调预测情感维度（VAD）和情绪行为（笑、哭、叹）

**💡 创新点**

①利用大规模无标签眼动数据进行自监督预训练，显著提升对情感的编码能力；②在自然环境下证明低分辨率视频仍能捕获丰富情感信号；③通过调整预训练预测时长和输入时长，系统性探究两者对情感预测的影响

**🔧 技术方法**

Transformer 编码器-解码器、RoPE 位置信息、Patch embedding、Huber 损失、AdamW 优化器、自动回归解码、特征统计与 1D TCN、GRU、Transformer 情感头等

**📊 数据集**

USC Shoah Foundation Visual History Archive 的 3,997 条 30 fps、320 × 240 像素的集中营幸存者访谈视频（共 978 位受访者）

**📈 对比分析**

与统计特征、全局 MLP、1D CNN 等基线相比，预训练模型在 VAD 回归中 MAE 下降至 0.105、Pearson r 提升至 0.297；在行为分类中 F1 分别达到 0.367（笑）、0.352（哭）和 0.331（叹）等，显示出显著的性能提升

**⚠️ 局限性**

①数据分辨率低，眼动信号噪声大；②情感标签主要来自 ASR 生成的情绪预测，可能存在误差；③仅覆盖三种情绪行为，未覆盖更细粒度或跨文化的情感表达；④实验仅在历史访谈语料上验证，缺乏实时或多场景的泛化评估

---

## 290. An Efficient and Multi-Modal Navigation System with One-Step World Model

**arXiv ID:** 2601.12277 | [PDF](https://arxiv.org/pdf/2601.12277v1)

**作者:** Wangtian Shen `[一作]` (Tsinghua University), Diyun Xiang `[通讯]` (Xiaomi)

**通讯引用:** 25 | [OpenAlex ID](https://openalex.org/A5087239898)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种轻量化导航世界模型，结合anchor‑based初始化的规划框架，实现多模态目标（图像、语言、点目标）闭环导航；

**💡 创新点**

核心创新在于采用一步生成范式与3D U‑Net结构配合空间‑时间注意力，显著降低推理延迟，同时引入预训练与随机轨迹采样增强泛化，并用anchor‑based初始化提升CEM规划性能；

**🔧 技术方法**

技术手段包括：一阶shortcut训练的扩散模型、VAE编码/解码、3D U‑Net+窗口式空间‑时间注意力、LPIPS/SigLIP/Depth‑Anything等任务特定损失、CEM优化；

**📊 数据集**

数据集主要包括MP3D（使用Habitat模拟器收集500条轨迹）、公开大规模导航数据用于预训练，以及实机Intel RealSense摄像头的真实环境测试；

**📈 对比分析**

与NWM、NoMaD、OmniVLA等基线对比，实验证明在图像、语言、点目标任务中SR和SPL显著提升，推理时间缩短约45%，生成质量指标（PSNR、SSIM、LPIPS、DreamSim、FID、FVD）均优于对手；

**⚠️ 局限性**

局限性在于需在完整动作空间内进行CEM探索，存在质量与速度折中；且目前未采用潜在动作空间或快慢双系统，未来需要进一步提升规划效率和鲁棒性。

---

## 291. S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection

**arXiv ID:** 2601.12313 | [PDF](https://arxiv.org/pdf/2601.12313v1)

**作者:** Xiangyu Hu `[一作]` (Guangdong Ocean University), Bingyao Liu `[通讯]` (Guangdong Ocean University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

开发了 S^2F-Net，用于检测 AI 生成的图像并显著提升跨模型泛化能力。

**💡 创新点**

创新点包括：① 可学习频率注意模块（LFA），针对纹理丰富与稀疏区域分别自适应加权高低频；② 结合空间纹理拆解（Smash & Reconstruction）的双域框架，抑制语义干扰并捕获全局频谱异常。

**🔧 技术方法**

使用的技术有：空间纹理拆解、FFT 与可学习频率掩膜、分组能量聚合、通道注意力重校准、轻量级卷积编码器及多层判别网络；同时引入数据增强与 Adam 优化。

**📊 数据集**

训练数据仅使用 ProGAN 生成的 360K 张图像与 LSUN 的 360K 张真实图像；测试使用 AIGCDetectBenchmark（17 种主流 GAN、扩散与域特化模型）。

**📈 对比分析**

与 12 种基线（CNNSpot、FreDect、FreqNet、UniFD 等）进行对比，平均准确率 90.49%（最高），平均 AP 96.27%；在 JPEG、模糊、降采样等鲁棒性测试中排名第一或第二，显示出优越的跨模型与抗失真性能。

**⚠️ 局限性**

局限性：低频注意力是核心判别因子，去除低频模块会大幅退化；高频模块对某些模型效果有限；分组数对性能高度敏感，过多分组导致局部过拟合；仍存在少量生成样本与真实样本特征重叠，表明对极高保真生成仍有挑战。

---

## 292. KILO-EKF: Koopman-Inspired Learned Observations Extended Kalman Filter

**arXiv ID:** 2601.12463 | [PDF](https://arxiv.org/pdf/2601.12463v1)

**作者:** Zi Cong Guo `[一作]` (University of Toronto), Timothy D. Barfoot `[通讯]` (University of Toronto)

**通讯引用:** 7339 | [OpenAlex ID](https://openalex.org/A5004788089)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `51c0528b-f690-4182-ae60-bb5f046c276c` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种基于 Koopman 拉升的 EKF（KILO‑EKF），将传感器测量模型学习为高维线性高斯模型，保持标准 EKF 预测步骤不变；

**💡 创新点**

创新点在于：①仅对测量模型进行 Koopman 拉升，保持过程模型不变；②在 Lie 群状态空间（如 SE₂(3)）中实现递归滤波；③通过闭式 Tikhonov 逆矩阵求解实现一次性学习；

**🔧 技术方法**

使用了 Koopman 拉升、随机 Fourier 特征（SERFF）、闭式最大后验（MAP）学习、标准 SE₂(3) EKF 结构；

**📊 数据集**

在真实四旋翼数据集 MILUV 上验证，使用 IMU、UWB 和激光高度传感器；

**📈 对比分析**

与 CAD‑EKF、MisCAD‑EKF、DataCal‑EKF 四种基线相比，KILO‑EKF 在位置、姿态误差与 NEES 指标上均优于或持平，尤其在校准误差存在时表现更稳健，且训练耗时远低于 DataCal‑EKF；

**⚠️ 局限性**

局限在于：仅学习测量模型，过程模型仍需手工或基于物理；对测量噪声假设为高斯；若系统具有高度非线性或复杂传感器相互耦合，单纯拉升可能不足；

---

## 293. An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion

**arXiv ID:** 2601.12249 | [PDF](https://arxiv.org/pdf/2601.12249v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 294. SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data

**arXiv ID:** 2601.12124 | [PDF](https://arxiv.org/pdf/2601.12124v1)

**作者:** Bing Hu `[一作]` (University of Waterloo), Helen Chen `[通讯]` (University of Waterloo)

**通讯引用:** 15563 | [OpenAlex ID](https://openalex.org/A5051935412)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `67630363-6be0-4f51-ab05-7198250671a5` `9cc9baba-5356-466d-81ff-d80028d90279` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

构建开放式框架 SynQP，用于通过模拟伪可识别数据来评估合成数据生成模型的隐私风险，并提出新的 SD-IDR 与 SD-MIA 指标。

**💡 创新点**

创新点在于提供可复现的基准数据与公平评估指标，特别是考虑到生成模型随机性的新身份披露风险和成员推断攻击度量。

**🔧 技术方法**

技术包括差分隐私（本地 DP）、生成式模型（CTGAN、TVAE、GaussianCopula）、伪可识别数据生成、Hellinger 距离、MLE 评估等。

**📊 数据集**

数据集为从美国 Diabetes 数据集（NIDDK）与公开 BMI 数据通过模拟得到的 1 万行伪可识别糖尿病样本。

**📈 对比分析**

通过对比无 DP 与 DP 版本的模型，使用 SD-IDR、SD-MIA、HD 与 MLE 等指标，发现 DP 降低隐私风险但同时降低了数据质量和可用性，模型表现各不相同。

**⚠️ 局限性**

局限性包括仅使用单一疾病数据集验证、模拟过程对真实相关性的逼近有限、以及对更复杂或多模态数据的适用性尚待进一步研究。

---

## 295. CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting

**arXiv ID:** 2601.12814 | [PDF](https://arxiv.org/pdf/2601.12814v1)

**作者:** Yu-Jen Tseng `[一作]` (National Yang Ming Chiao Tung University), Wen-Hsiao Peng `[通讯]` (National Yang Ming Chiao Tung University)

**通讯引用:** 1635 | [OpenAlex ID](https://openalex.org/A5071531458)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `729e5870-4135-47f5-97f2-e3974d07b5dc` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `9ce7179e-700c-4310-ac2b-91df50ded46e` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了首个将3D Gaussian Splatting（3DGS）的率失真（RD）优化压缩与语义分割统一起来的框架，在服务器端完成压缩学习，并将语义丰富的压缩3DGS传输到客户端，实现高效渲染与分割。

**💡 创新点**

创新点包括：① 在同一bitstream中同时压缩颜色与语义信息；② 采用轻量化的隐式神经表示（INR）基hyperprior，替代昂贵的网格基hyperprior；③ 开发压缩引导的分割学习策略，即量化感知训练与质量感知加权，使分割特征在压缩后保持更好的可分离性和鲁棒性。

**🔧 技术方法**

使用的技术包括：3DGS的Anchor‑Based Scaffold‑GS结构；INR‑hyperprior实现分布建模与熵编码；量化感知训练与质量感知加权的对比学习；基于SAM生成的2D分割掩码作为自监督目标；以及端到端的RD优化训练框架。

**📊 数据集**

实验数据集：LERF 和 3D‑OVS，均用于评估渲染质量与语义分割性能。

**📈 对比分析**

与仅压缩颜色的RD‑优化3DGS方法（如HAC、CAT‑3DGS、ContextGS）以及现有3DGS分割方法（InstanceGS、DF‑3DGS、OpenGaussian等）进行对比。结果显示，本文方法在保持相近渲染质量的同时，压缩率显著降低；在语义分割上，尤其对低质量或背景Gaussian的抑制，使得mIoU等指标均超过基线。

**⚠️ 局限性**

局限性：① 需要在服务器端完成训练与压缩，实时性受限；② 对质量评估的依赖导致对复杂场景的适用性尚未充分验证；③ 低质量或背景Gaussian仍可能影响分割学习；④ 在极大规模或多场景推理时的内存与算力需求尚需进一步优化。

---

## 296. VidTune: Creating Video Soundtracks with Generative Music and Contextual Thumbnails

**arXiv ID:** 2601.12180 | [PDF](https://arxiv.org/pdf/2601.12180v1)

**作者:** Mina Huh `[一作]` (University of California), Bryan Wang `[通讯]` (Adobe Research)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

开发并实现了 VidTune 系统，帮助视频创作者通过文本提示快速生成多样化音乐，并利用视频主体生成的上下文缩略图实现快速预览、对比与迭代。

**💡 创新点**

创新点：① 生成与视频内容关联的可视化缩略图，将音乐属性（情绪、能量、乐器、节奏）映射到视频主体；② 提示扩展算法产生多样化且相关的音乐；③ 通过音乐空间地图和可视化评估工具支持快速比较；④ 基于自然语言的编辑、变体与混合操作实现无障碍、交互式迭代；⑤ 兼顾聋人/听障创作者的可访问性。

**🔧 技术方法**

技术组合：文本‑>音乐模型（自研或现有开源模型）；大规模多模态模型（LMM）用于场景分析、关键词生成与音乐属性抽取；CLAP 音频‑>文本嵌入用于相似度与多样性评估；文本‑>图像模型 + 视频生成模型生成缩略图；自研提示扩展算法、音乐空间映射、编辑/变体/混合算法。

**📊 数据集**

数据集与素材：自建 5 个多类型视频（V1‑V5）用于技术评估；20 条音乐提示（短/长）用于多样性测试；8 名视频创作者视频和任务收集的音频/视觉素材；6 名创作者自己的视频用于案例研究；无公开公开数据集，但使用公开的文本‑>音乐、文本‑>图像模型的预训练权重。

**📈 对比分析**

比较方法：与基线（类似市面工具）进行对等实验；对比 4 条音乐输出与缩略图；用户研究 12 名创作者进行控制实验，收集认知负荷、创造力支持、缩略图效用量表；案例研究 6 名创作者使用自有视频；评估指标包括音乐多样性（平均余弦距离/聚类分离）、缩略图对应度（评分/选择准确率）、用户主观效用；结果显示：VidTune 缩略图对应度显著高于基线（平均评分提升 0.36；选择准确率提升 27%），用户报告认知负荷降低、创意支持提升，音乐多样性在短提示条件下显著提升。

**⚠️ 局限性**

限制：① 缩略图与标题/音频不一致时会导致混淆；② 动画效果并非所有用户认为必要，可能分散注意力；③ 对专业编辑需求的细粒度调音、结构化控制支持不足；④ 仅基于文本提示，缺乏音频参考与节拍同步控制；⑤ 依赖 LMM 及生成模型，存在偏见、文化映射不一致和生成误差；⑥ 目前仅支持无歌词音乐，扩展至带歌唱的音轨仍需研究。

---

## 297. HERMES: A Unified Open-Source Framework for Realtime Multimodal Physiological Sensing, Edge AI, and Intervention in Closed-Loop Smart Healthcare Applications

**arXiv ID:** 2601.12610 | [PDF](https://arxiv.org/pdf/2601.12610v1)

**作者:** Maxim Yudayev `[一作]` (KU Leuven), Benjamin Filtjens `[通讯]` (Delft University of Technology)

**通讯引用:** 234 | [OpenAlex ID](https://openalex.org/A5018244653)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提供了一个开源的 Python 框架 HERMES，用于实时多模态生理信号采集与边缘 AI 推理，并在义肢控制等闭环医疗应用中验证其性能。

**💡 创新点**

提出了一套连续实时多模态边缘 AI 方法论，解决异步、异构、缺失数据的同步与推理，结合事件驱动与窗口推理策略，并实现低延迟、高吞吐的统一框架。

**🔧 技术方法**

基于 ZeroMQ 消息总线、FFmpeg 视频编码、HDF5 存储、PyTorch AI 推理、Python 多线程协程、时钟同步（PTP/NTP）以及持续传输重校准。

**📊 数据集**

自行收集的 14 名受试者 1 小时多模态数据集，包括眼动/ egocentric 视频、惯性测量单元、表面 EMG、足压、压力垫等，未公开但可复现。

**📈 对比分析**

在实验室与现场环境下进行吞吐率、延迟、CPU 占用等基准；单机最高 2kHz 1kB 消息吞吐；平均推理延迟 4ms；CPU 12%；视频编码占 14%；与现有 LSL、ROS2 等框架相比，显著提升同步精度与实时性。

**⚠️ 局限性**

尚未获得医疗认证；仅支持 Windows/Linux 主机，缺乏微控制器支持；缺少动态发现与容错；同步精度受 NTP/PTP 误差限制；对极低功耗设备适配不足。

---

## 298. Less is More: Label-Guided Summarization of Procedural and Instructional Videos

**arXiv ID:** 2601.12243 | [PDF](https://arxiv.org/pdf/2601.12243v1)

**作者:** Shreya Rajpal `[一作]` (Vellore Institute of Technology), Carsten Eickhoff `[通讯]` (University of Tübingen)

**通讯引用:** 3847 | [OpenAlex ID](https://openalex.org/A5014921416)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种三阶段零样本上下文感知视频摘要框架 PRISM，通过自适应采样、语义标签锚定和 LLM 验证实现高效摘要。

**💡 创新点**

创新点在于在推理阶段动态生成并验证语义锚标签，减少帧数至<5%并保持>80%语义信息；同时使用多模态 LLM 进行上下文校验，突破传统顶部到底部方法。

**🔧 技术方法**

结合 ResNet‑18 特征采样、CLIP/BLIP 语义编码、Gemma3/LLM 标签验证、GPT‑4 等大型语言模型进行摘要生成。

**📊 数据集**

在 YouCook2、ActivityNet Captions、TVSum、SumMe、Cholec80、PIT‑VIS 等数据集上进行评测。

**📈 对比分析**

与基线相比，PRISM 在 YouCook2 的 METEOR 提升 33% 以上，ActivityNet Captions METEOR 提升 20% 以上，关键帧选择在 TVSum/SumMe 的 Kendall‑τ、Spearman‑ρ 仅略低于人类基准。

**⚠️ 局限性**

主要局限为依赖大型 LLM，易产生幻觉与一致性问题；对语音/文本信息覆盖有限，需进一步验证临床应用。

---

## 299. Multi-Sensor Matching with HyperNetworks

**arXiv ID:** 2601.12325 | [PDF](https://arxiv.org/pdf/2601.12325v1)

**作者:** Eli Passov `[一作]` (Bar Ilan University), Yosi Keller `[通讯]` (Bar Ilan University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计了一种基于Hypernetworks的轻量级Siamese CNN，用于可见光与红外图像的补丁匹配；同时发布了包含5万对跨平台VIS‑IR补丁的GAP‑VIR数据集。

**💡 创新点**

创新点在于：①在深层加入Hypernetwork模块动态生成通道缩放与平移，捕捉图像全局上下文；②在浅层使用Conditional Instance Normalization (CIN) 实现模态特定适配；③将两者结合形成伪Siamese结构，几乎保持所有权重共享；④通过triplet loss与hard‑negative mining进一步提升匹配鲁棒性。

**🔧 技术方法**

主要技术包括：Siamese卷积网络、Hypernetwork模块（全局池化→FC→缩放/平移生成）、CIN层、triplet margin loss、Hard Negative Mining、数据增强（90°旋转、垂直翻转、随机旋转、gamma变化）以及Adam优化器与循环学习率调度。

**📊 数据集**

使用了VIS‑NIR基准（1.6M补丁）、En et al.基准（VeDAI、CUHK、RGB‑NIR）、VIS‑LWIR基准（21k对）以及自研的GAP‑VIR（5万对，分为地面和空中两子集）。

**📈 对比分析**

与传统SIFT、SOM等手工特征、以及现有深度学习方法（Q‑Net、L2‑Net、HardNet、Transformer‑Encoder、HyNet等）对比，Hyp‑Net在VIS‑NIR的FPR95平均值从1.41提升至1.11（约30%提升）；在En et al.基准实现零FPR95（VeDAI）和接近零（CUHK、RGB‑NIR）；在VIS‑LWIR基准FPR95降至0.51（比前最佳0.92降低94%）；在GAP‑VIR上相对其它模型提升10%–60%。

**⚠️ 局限性**

局限性包括：①在空中→地面迁移时仍存在显著域差异，性能下降；②Hypernetwork模块虽然提高鲁棒性，但训练时间与显存消耗略高；③未探索更大规模跨模态数据的泛化能力；④Transformer等新型结构在本任务上效果不佳，需进一步改进。

---

## 300. FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching

**arXiv ID:** 2601.12329 | [PDF](https://arxiv.org/pdf/2601.12329v1)

**作者:** Mithlesh Singla `[一作]` (Indian Institute of Technology Gandhinagar), Shanmuganathan Raman `[通讯]` (Indian Institute of Technology Gandhinagar)

**通讯引用:** 1427 | [OpenAlex ID](https://openalex.org/A5070142969)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `40105733-5154-44cd-8090-a8cab9e64b07` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种基于潜在流匹配的单步Intrinsic Image Decomposition模型——FlowIID，用以在一次前向传播中同时预测图像的反照率和阴影。

**💡 创新点**

创新点在于：①首次将潜在流匹配技术应用于IID；②通过VAE引导的潜在空间实现分解过程的稳定化；③在保持单步推理的前提下，显著压缩模型规模（约52M参数）。

**🔧 技术方法**

技术手段包括潜在流匹配（Flow Matching）、变分自编码器（VAE）+判别器、UNet结构、改进残差块、轻量化注意力模块以及传统的像素/感知/KL/对抗损失组合。

**📊 数据集**

使用的数据集有：Hypersim、InteriorVerse、Multi-Illumination Dataset（MID）用于训练；MIT Intrinsic、ARAP等标准基准用于评估。

**📈 对比分析**

与现有卷积网络和扩散模型的比较显示，FlowIID在MIT Intrinsic和ARAP上分别取得最低的LMSE（0.0043/0.0119）和最佳SSIM（0.760/0.744），且参数量仅为52M，显著低于传统方法（数百M甚至数十亿级别）。

**⚠️ 局限性**

局限性包括：在训练过程中t≈0时的MSE仍相对较高，说明潜在流匹配对起始点的收敛性有待提升；此外，模型在极端光照或高频纹理场景下的泛化能力尚未完全验证。

---

## 301. Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration

**arXiv ID:** 2601.12256 | [PDF](https://arxiv.org/pdf/2601.12256v1)

**作者:** Jinyoung Park `[一作]` (Korea Advanced Institute of Science and Technology), Hyunwoo J. Kim `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 2366 | [OpenAlex ID](https://openalex.org/A5084814930)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出CoLLaMo，一种融合1D、2D、3D分子信息的多模态语言模型；

**💡 创新点**

创新点在于：①关系感知的模态协同注意力，实现2D拓扑与3D空间关系的联合编码；②分子协同投影器将三模态映射到共享token空间；③针对分子生成的幻觉引入CHARM/RCHARM评估指标以及LLM判定分数；

**🔧 技术方法**

技术包括：多层模态编码器（SELFIES、GIN图编码器、UniMol 3D编码器）、关系感知协同注意力、交叉注意力投影、模态dropout与嵌入、LLM（LLaMA2-7B）微调以及多阶段预训练与指令调优；

**📊 数据集**

使用公开的分子-描述对数据、GPT丰富的分子描述数据、以及多任务数据集（分子描述、属性问答、IUPAC命名、基序计数等）；

**📈 对比分析**

与GPT‑4、GPT‑4o、o1‑mini、LLaMo、2D‑MoLM、3D‑MoLM等基线进行对比，CoLLaMo在分子描述BLEU/METEOR、属性QA MAE、幻觉CHARM/RCHARM、LLM评分等指标均显著优于对照模型；

**⚠️ 局限性**

局限性包括：模型仍需完整的3D结构信息（缺失时性能下降但仍能保持一定鲁棒性），评估指标依赖外部NER工具，且仅在公开数据上验证，实际药物发现场景仍待进一步验证。

---

## 302. SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence

**arXiv ID:** 2601.12357 | [PDF](https://arxiv.org/pdf/2601.12357v1)

**作者:** Hailing Jin `[一作]`, Huiying Li `[通讯]` (Jilin University)

**通讯引用:** 6369 | [OpenAlex ID](https://openalex.org/A5100603788)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一个简洁高效的语义对应框架SimpleMatch，利用轻量级上采样解码器恢复特征细节并结合稀疏匹配和窗口定位实现低分辨率下的高精度对应。

**💡 创新点**

创新在于识别并解决深度下采样导致相邻关键点特征不可逆融合问题，通过逐步上采样恢复空间分辨率，并引入多尺度监督、稀疏匹配与窗口定位显著降低训练内存和提升匹配准确率。

**🔧 技术方法**

采用了轻量级上采样解码器（双线性+转置卷积+残差块）、多尺度监督损失、稀疏关键点匹配、窗口级局部定位，以及基于余弦相似度的特征比较。

**📊 数据集**

在SPair‑71k、PF‑PASCAL、PF‑WILLOW、AP‑10K等公开数据集上进行实验，并进行跨数据集迁移学习评估。

**📈 对比分析**

与4D相关、特征匹配以及基于大规模预训练模型（如iBOT、DINOv2、Stable Diffusion）的SOTA方法对比，SimpleMatch在低分辨率（252×252）下实现84.1% PCK@0.1/SPair‑71k，提升约1‑2个百分点，同时吞吐量达65帧/秒、显存仅2.8GB，显著优于传统高分辨率方案。

**⚠️ 局限性**

限制在于对不同类别关键点密度差异敏感，极稀疏或过于密集的关键点分布仍需进一步优化；此外，目前仅针对二维图像对应，3D场景及动态视频匹配尚未验证。

---

## 303. Resource-Conscious RL Algorithms for Deep Brain Stimulation

**arXiv ID:** 2601.12699 | [PDF](https://arxiv.org/pdf/2601.12699v1)

**作者:** Arkaprava Gupta `[一作]` (University of North Carolina Chapel Hill), Samarjit Chakraborty `[通讯]` (University of North Carolina Chapel Hill)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出并实现了一种新型的 Time & Threshold-Triggered Multi‑Armed Bandit (T3P MAB) 算法，用于实时调节深脑刺激（DBS）的频率和幅度，以实现对帕金森病症状的精准控制。

**💡 创新点**

创新点在于将 MAB 与域知识相结合，先通过一次热身阶段评估所有动作，随后只保留收益最高的前 K 个动作进行 epsilon‑greedy 探索，并在时间与阈值触发时重新启动，从而显著加快收敛速度并提升能量效率。

**🔧 技术方法**

核心技术包括基于 BGT 神经网络模型的仿真、Pβ 生物标记物反馈、FFT 计算的快速实现、以及在 ESP32‑S3 / ESP32‑P4 微控制器上部署的轻量级 MAB 推理。

**📊 数据集**

使用了基于计算机的 Basal Ganglia‑Thalamic (BGT) 模型作为仿真数据集，并在该模型中模拟不同频率/幅度组合的 DBS 效果。

**📈 对比分析**

与 8 种传统 MAB（UCB、Bayes‑UCB、Discounted‑UCB、Neural‑UCB、CLUCB、TS、ε‑Greedy、ε‑Neural‑TS）以及 TD3 深度强化学习算法相比，T3P MAB 在 75 轮实验中平均即时奖励提升约 30‑40%，累计折损下降至最小，并在硬件上实现的能耗比 o‑DBS 和 TD3 低 30‑50%，收敛时间均在 2 分钟以内。

**⚠️ 局限性**

局限性包括：仅在仿真模型中验证，未在真实患者数据上测试；依赖单一 Pβ 指标作为反馈，可能无法全面捕捉脑部状态变化；以及对硬件资源仍有限，无法直接支持更复杂的深度 RL 模型。

---

## 304. Explanova: Automatically Discover Data Insights in N \times M Table via XAI Combined LLM Workflow

**arXiv ID:** 2601.12317 | [PDF](https://arxiv.org/pdf/2601.12317v1)

**作者:** Yiming Huang `[一作]` `[通讯]` (Hong Kong University of Science and Technology Guangzhou), Yiming Huang (Hong Kong University of Science and Technology Guangzhou)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种基于预设 AutoML 工作流的自动化数据洞察框架 Explanova，利用小型 LLM 在三阶段（特征预处理、特征间统计、特征建模）自动挖掘并生成可解释报告。

**💡 创新点**

创新点在于：① 将繁重的 LLM 计算迁移到低成本的统计与机器学习层面，通过并行化显著降低计算开销；② 统一采用 NLL、SHAP 误差和信息熵构成可靠性评分；③ 在本地 GPU 上即可部署，避免对大模型 API 的高昂调用成本。

**🔧 技术方法**

使用的技术包括：LLM 类型推断与自然语言描述；混合距离 + HDBSCAN 生成聚类特征；多种统计检验（Pearson、Spearman、MI、ANOVA、η²、Kruskal、χ²、Cramér V 等）；四类通用 ML 模型（Logistic、决策树、MLP、集成）+ 5 折 CV + NLL 统一评估；KernelSHAP + k‑fold 扰动 + 信息熵；并行计算与结果缓存。

**📊 数据集**

在案例研究中使用了 DSAA 5002 公开数据集的 market_compagian.csv，目标变量为 market_compagian；实验以 Qwen3‑8B 本地 LLM 为核心，在约 5 分钟内完成报告生成。

**📈 对比分析**

目前未完成系统级基准评测，计划与 InfiAgent‑DABench、DiscoveryBench 等 QA‑洞察基准对齐；已知在 8B LLM + 本地 GPU 方案下，生成完整报告仅需 5 min，展示了高效与可扩展性。

**⚠️ 局限性**

局限性包括：Shapley‑based 计算存在并行 bug，报告中部分图表未绘制完成；缺乏完整的基准对比；对大型多模态数据或非结构化文本的支持有限；Reliability 评分仍处于实验阶段。

---

## 305. DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition

**arXiv ID:** 2601.12729 | [PDF](https://arxiv.org/pdf/2601.12729v1)

**作者:** Hanyu Zhu `[一作]` (Hangzhou Dianzi University), Wanzeng Kong `[通讯]` (Hangzhou Dianzi University)

**通讯引用:** 4076 | [OpenAlex ID](https://openalex.org/A5003649465)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了 DC-VLAQ 框架，用残差引导融合 DINOv2 与 CLIP 特征，并通过查询-残差聚合生成全局描述子，实现鲁棒视觉定位。

**💡 创新点**

创新点在于残差引导的多模型融合保持原始检索几何，同时引入查询-残差全局聚合以提升对视角、光照和域迁移的稳健性。

**🔧 技术方法**

使用预训练的 DINOv2 与 CLIP 视觉编码器、轻量级残差融合层、VLAQ 聚合器及多相似度损失训练。

**📊 数据集**

在 GSV‑Cities 训练集上，评估数据集包括 Pitts30k、Tokyo24/7、MSLS、Nordland、SPED 与 AmsterTime。

**📈 对比分析**

与多种基线（NetVLAD、TransVPR、EigenPlaces、BoQ、SALAD、EDTFormer 等）对比，DC‑VLAQ 在标准与鲁棒性测试中均取得最优或次优 Recall@K，尤其在 Nordland、MSLS‑challenge、SPED 与 AmsterTime 上表现突出。

**⚠️ 局限性**

局限在于仅使用两种 VFM；对更高维度或跨模态输入的适配仍待研究，且在极端遮挡或动态场景下效果尚未验证。

---

## 306. From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2

**arXiv ID:** 2601.12636 | [PDF](https://arxiv.org/pdf/2601.12636v1)

**作者:** Satyaki Roy Chowdhury `[一作]` (Ohio State University), Joachim Moortgat `[通讯]` (Ohio State University)

**通讯引用:** 2149 | [OpenAlex ID](https://openalex.org/A5075797962)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6514db3d-8de6-452c-91b7-acdb31787cc4` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究并实现了基于Swin-Transformer的U-Net模型Swinn-BathyUNet，用于从Sentinel-2影像推断浅水浴深，并通过解释性方法分析模型特征。

**💡 创新点**

提出Decoder条件的跨注意力与A-CAM-R解释框架，并结合Leave-One-Band-Out分析，揭示模型对光谱通道的真实依赖和跨区域泛化能力。

**🔧 技术方法**

采用Swin-Transformer块、窗口自注意力与交叉注意力、掩码边界加权RMSE、A-CAM-R可视化及留一通道重要性评估。

**📊 数据集**

使用MagicBathyNet多模态浅水数据集（含Sentinel-2、SPOT-6、航空影像和LiDAR DSM），并在Agia Napa区域进行训练验证。

**📈 对比分析**

在Agia Napa测试中，Masked MAE达1.24 m，RMSE1.25 m，R²≈0.94；交叉注意力版优于仅自注意力，跨区域误差随深度线性增加。

**⚠️ 局限性**

模型对深度、光学条件与数据分布不平衡敏感，跨区域泛化受深度和水体清澈度影响，且解释方法依赖于高质量光谱通道。

---

## 307. Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach

**arXiv ID:** 2601.12624 | [PDF](https://arxiv.org/pdf/2601.12624v1)

**作者:** Shiqi Wang `[一作]` (University of California), Olaf Witkowski `[通讯]` (Cross Labs)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种基于浮点编码、惩罚驱动的单目标进化框架，用于生成对多模型有效且低可见度的通用对抗扰动。

**💡 创新点**

创新点包括：使用浮点基因实现连续梯度样式更新；软惩罚约束取代硬阈值；动态交叉/变异与ε约束调度；条件像素清洗与无精英策略；批次切换防止过拟合。

**🔧 技术方法**

采用进化算法（GA）与PyTorch/ PyGAD实现，结合线性/指数调度、惩罚式适应度、无精英选择、像素清洗等技术。

**📊 数据集**

在ImageNet‑1K数据集上训练并评估，针对GoogLeNet、ResNet‑50、ViT‑B/16三种网络。

**📈 对比分析**

与先前基于GA的EUPA方法相比，在仅64代内实现了更低的扰动范数（约40）和更高的误分类率，且收敛速度更快，攻击成功率提升至40%‑45%不等。

**⚠️ 局限性**

局限在于计算量大，批量采样有限，未完全覆盖所有ImageNet类别；未尝试多模型集成或更复杂的损失函数。

---

## 308. Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction

**arXiv ID:** 2601.12637 | [PDF](https://arxiv.org/pdf/2601.12637v1)

**作者:** Long D. Nguyen `[一作]` (Victoria University of Wellington), Binh P. Nguyen `[通讯]` (Victoria University of Wellington)

**通讯引用:** 2680 | [OpenAlex ID](https://openalex.org/A5091142923)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `3f18e8e3-0266-457c-8567-9039b6d2394d` `afceb026-1760-41ae-8d86-010831a37d97` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了多尺度交互 Mixture of Experts（MI‑MoE）框架，用于在3D分子图神经网络中自适应地捕捉不同距离尺度下的相互作用。

**💡 创新点**

创新点在于：① 通过距离过滤器构造多尺度图并为每个尺度训练独立专家；② 用拓扑学描述子（Randić、Wiener、全局效率及持久性同调 Betti 曲线）做门控，实现在分子级别的专家路由；③ 该模块可无缝嵌入任意3D GNN骨干，且仅需SMILES生成配体即可。

**🔧 技术方法**

技术手段包括：距离基图滤波、持久性同调特征提取、混合专家（Mixture of Experts）与Top‑k稀疏门控、平衡损失正则化，以及在多尺度专家上并行训练3D GNN（如SchNet、DimeNet++、ViSNet、EGNN、PaiNN等）。

**📊 数据集**

使用了 MoleculeNet 的 8 个分子性质基准（FreeSolv、ESOL、Lipophilicity、BACE、BBBP、ClinTox、SIDER、Tox21）以及 4 个聚合物性质基准（E_ea、E_i、X_c、η_c）。

**📈 对比分析**

与多种 2D/3D GNN、Transformer 以及现有 MoE 方法相比，MI‑MoE 在绝大多数任务上实现了显著提升（例如 SchNet RMSE 从 1.23 降至 1.06，ROC‑AUC 从 69.7% 提升至 81.3%；聚合物任务中 MI‑MoE‑SchNet 的 RMSE 在 4 项中均为最低）。

**⚠️ 局限性**

局限性包括：① 需要先生成 3D 配体，依赖 RDKit 的几何优化；② 交互尺度集的选择仍需经验或调参；③ 对极大分子或稠密结构的稀疏专家路由可能产生偏差。

---

## 309. Streaming Operator Inference for Model Reduction of Large-Scale Dynamical Systems

**arXiv ID:** 2601.12161 | [PDF](https://arxiv.org/pdf/2601.12161v1)

**作者:** Tomoki Koike `[一作]` (Georgia Institute of Technology), Elizabeth Qian `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 563 | [OpenAlex ID](https://openalex.org/A5059159562)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5a41884c-404f-4688-a89c-aa238c10fe68` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文提出了Streaming Operator Inference（Streaming OpInf）框架，利用增量SVD与递归最小二乘学习，从连续数据流中非侵入性地构建低维动力学模型；

**💡 创新点**

创新点在于将传统OpInf的批处理SVD和LS步骤改写为在线增量SVD与递归LS，消除对完整数据集的存储需求并支持实时模型更新；

**🔧 技术方法**

核心技术包括Baker’s Incremental SVD与SketchySVD用于基空间构造，以及递归最小二乘（RLS）和基于QR的iQRRLS用于算子学习；

**📊 数据集**

实验使用三组数据集：一维粘性布格斯方程、曲率-薛定谔方程（KSE）和大尺度三维湍流通道流场（约9.4百万自由度），并采用相应的时间步长和采样；

**📈 对比分析**

与传统批处理OpInf和POD方法比较，Streaming OpInf在三种实验中都保持了与批处理相当的预测精度，同时内存消耗降低99%以上，模型维度压缩超过31,000倍，预测速度提升数百倍；

**⚠️ 局限性**

局限性包括对多项式动力学的假设、对高斯噪声和快速演化流场的鲁棒性仍有限，以及在湍流通道流场中对壁面层细节的捕捉仍受限，未来需引入非线性流形、并行化与不确定度量化等改进。

---

## 310. Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models

**arXiv ID:** 2601.12150 | [PDF](https://arxiv.org/pdf/2601.12150v1)

**作者:** Mengxuan Hu `[一作]` (University of Virginia), Zhongliang Zhou `[通讯]` (Merck and Company)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

设计并实现了一种针对数字病理基础模型的推理优化方法，通过空间感知的局部窗口稀疏注意力与全局注意力相结合，并在后期层引入基于全局注意力得分的动态令牌剪枝，从而显著降低 GPU 内存占用和推理时间，同时提升高分辨率 WSIs 的分类与分割性能。

**💡 创新点**

①首次在病理图像上综合应用空间感知稀疏注意力与全局注意力，②引入基于全局注意力得分的动态令牌剪枝机制，③通过这两种技术在保持甚至提升性能的同时，使模型在相同 GPU 预算下可处理更高分辨率输入。

**🔧 技术方法**

使用 Vision Transformer（Uni‑2 等）为骨干网络，借鉴 BigBird 的稀疏注意力结构，结合 FlashAttention/SparseAttention 的内存优化思路，以及 FastViT 风格的令牌剪枝；在分割任务中采用 Mask2Former 模型。

**📊 数据集**

PANDA 数据集用于癌症模式分类，SegPath 数据集用于肿瘤细胞分割。

**📈 对比分析**

与原始 Uni‑2（vanilla）对比，采用线性探测和 KNN 评估分类（准确率、F1、AUROC），以及在 SegPath 上评估 MPA、IoU、Dice；结果显示在最高 3430 分辨率下，内存由 66.18 GB 降至 8.66 GB，推理时间由 89,640 s 降至 13,588 s；分类准确率提升约 0.7%（7.67% 提升），分割性能虽略低但仍相对稳定。

**⚠️ 局限性**

1) 对分割任务的稀疏注意力导致信息丢失，性能相对较低；2) 仅在 Vision Transformer 基础模型上验证，未覆盖 VLM 等新型模型；3) 令牌剪枝比例采用固定值，缺乏自适应机制；4) 仅在 A100 GPU 上测试，缺乏不同硬件平台的泛化验证。

---

## 311. P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning

**arXiv ID:** 2601.12714 | [PDF](https://arxiv.org/pdf/2601.12714v1)

**作者:** Songlin Dong `[一作]` (Shenzhen University of Advanced Technology), Yihong Gong `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 23347 | [OpenAlex ID](https://openalex.org/A5100687952)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一个无缓冲、参数高效的多标签增量学习框架P2L-CA，结合 Prompt-to-Label 模块与 Continuous Adapter 解决特征混淆和域差问题。

**💡 创新点**

创新点在于使用类级提示词实现多标签特征解耦，并在冻结backbone上引入持续适配器对域差进行补偿；同时可利用CLIP语义先验提升语义‑视觉对齐。

**🔧 技术方法**

采用了 Prompt‑tuning、Adapter、CLIP 文本编码、ViT‑B/16 预训练模型以及 Asymmetric Loss 进行训练。

**📊 数据集**

使用的评估数据集包括多标签任务的 MS‑COCO、PASCAL VOC 以及单标签任务的 CIFAR‑100。

**📈 对比分析**

与多种回放与无回放方法对比，P2L-CA 在 COCO 和 VOC 的标准与挑战协议（如 B40‑C10、B0‑C10）均实现了 SOTA，mAP 提升约 4–9.9%，并在 CIFAR‑100 上取得最高 Accuracy 88.12%，显著优于现有方法。

**⚠️ 局限性**

局限性包括：仅适用于图像级分类任务，适应策略固定为首阶段训练后冻结，难以处理持续动态域漂移；以及与 CNN 基线的比较受不同 backbone 影响。

---

## 312. Opportunistic Scheduling for Optimal Spot Instance Savings in the Cloud

**arXiv ID:** 2601.12266 | [PDF](https://arxiv.org/pdf/2601.12266v1)

**作者:** Neelkamal Bhuyan `[一作]` (Georgia Institute of Technology), TV Lakshman `[通讯]` (Nokia Bell Labs)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

针对延迟敏感作业在云中使用抢占式（spot）与按需实例的调度问题，提出最优或近优调度策略以在满足平均延迟约束的前提下降低平均成本。

**💡 创新点**

首次给出基于G/G/1排队理论的完整分析，证明在低延迟约束下最优队列长度为1；在高延迟约束下发现knapsack结构并提出三阶段贪心调度；并设计在线自适应学习算法实现无模型参数的最优调度。

**🔧 技术方法**

排队论、随机过程、线性规划、凸优化、梯度下降学习、蒙特卡洛仿真。

**📊 数据集**

使用合成到达/空闲序列（Poisson、Gamma、指数、有限支持分布）以及来自AWS/GCP的spot可用性分布（泊松与浴缸型分布）作实验。

**📈 对比分析**

与理论最优成本比较，实验显示自适应算法的平均成本几乎达到解析下界，延迟约束被严格满足；与简单常规策略相比，成本下降幅度可达30%–50%。

**⚠️ 局限性**

仅考虑单一作业类型和单队列模型，假设到达和空闲过程为独立重现过程；对非平稳、异构任务规模或多租户场景的适用性尚未验证；实时价格变动的影响未在模型中体现。

---

## 313. From LLMs to Agents in Programming: The Impact of Providing an LLM with a Compiler

**arXiv ID:** 2601.12146 | [PDF](https://arxiv.org/pdf/2601.12146v1)

**作者:** Viktor Kjellberg `[一作]` (Chalmers University of Technology), Farnaz Fotrousi `[通讯]` (Chalmers University of Technology)

**通讯引用:** 250 | [OpenAlex ID](https://openalex.org/A5039104971)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过构建一个基于LLM与编译器交互的代理系统，评估其在C语言编程任务中的代码生成与编译成功率，比较单次生成与迭代改错两种模式。

**💡 创新点**

创新点在于将编译器错误信息直接反馈给LLM，实现迭代修正，从而让小规模模型（如4B Qwen 3）在编译成功率上超过甚至取代更大模型；并系统化分析错误类型对改进效果的影响。

**🔧 技术方法**

采用的技术包括：多轮生成-编译-反馈的代理框架、Prompt工程（统一两套提示）、评估指标（BLEU、ROUGE、CodeBERTScore、编译成功率）以及错误分类与统计分析。

**📊 数据集**

使用RosettaCode数据集的699个C语言任务，覆盖从简单到复杂的多类别编程问题。

**📈 对比分析**

比较方法：基线模型仅一次生成；代理模型最多5轮迭代。结果显示编译成功率提升5.3–79.4个百分点，语法错误下降75%，未定义引用下降87%；语义/文本相似度基本保持不变，说明改进主要体现在可执行性。

**⚠️ 局限性**

局限性包括：仅测试C语言单文件任务；未评估运行时功能正确性；编译器错误信息的解读依赖于其清晰度；仅基于RosettaCode，缺乏对其他语言与更复杂项目的泛化验证。

---

## 314. Principal Component Analysis-Based Terahertz Self-Supervised Denoising and Deblurring Deep Neural Networks

**arXiv ID:** 2601.12149 | [PDF](https://arxiv.org/pdf/2601.12149v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 315. A Formally Verified Procedure for Width Inference in FIRRTL

**arXiv ID:** 2601.12813 | [PDF](https://arxiv.org/pdf/2601.12813v1)

**作者:** Keyin Wang `[一作]` (Chinese Academy of Sciences), David N. Jansen `[通讯]` (Chinese Academy of Sciences)

**通讯引用:** 1450 | [OpenAlex ID](https://openalex.org/A5006029818)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

本文提出了一个形式化且完整的 FIRRTL 宽度推断（InferWidths）过程，并实现了可验证的 OCaml 版本，能够在存在循环依赖的情况下求解最小宽度。

**💡 创新点**

创新点在于：①证明了 FIRWINE 约束可满足时存在唯一最小解；②设计了基于拓扑分块、可扩展性判定与分支定界的全局求解算法；③将算法在 Coq 中证明正确，并提取出可执行代码；④在实验中实现了与 CIRCT 和工业 ILP 求解器 Gurobi 的对比。

**🔧 技术方法**

使用的技术包括：形式化约束建模（FIRWINE）、拓扑排序和 SCC 分解、可扩展性判定、最大 Floyd–Warshall 算法、分支定界搜索、Coq 形式化与证明、OCaml 代码提取。

**📊 数据集**

数据集涵盖 75 个 FIRRTL 程序，包括 3 个 RISC‑V 处理器（NutShell、Rocket Chip、RISC‑V BOOM）、4 个官方 CIRCT 测试、20 个 Chisel 书中示例、26 个历史 issue 示例以及 11 个随机生成的满足理论条件的实例。

**📈 对比分析**

与 CIRCT 的 InferWidths 和 Gurobi 的对比实验显示：在所有可解的 75 个实例中，本文实现至少能解决 72 个，匹配 Gurobi 的结果；在小型/中型基准上平均比 CIRCT 快 7–10 倍，比 Gurobi 快 1.5–2 倍；在 3 个大型处理器基准上与 Gurobi 竞争，性能相当。

**⚠️ 局限性**

主要限制：仍未支持通用动态左移（dshl）导致的非线性约束；对极大规模实例（>10⁶ 变量）仍可能面临内存与时间瓶颈；OCaml 提取的代码未完全形式化（解析器、标准库等仍为未验证组件）。

---

## 316. Context-Free Grammar Inference for Complex Programming Languages in Black Box Settings

**arXiv ID:** 2601.12385 | [PDF](https://arxiv.org/pdf/2601.12385v1)

**作者:** Feifei Li `[一作]` (Tsinghua Shenzhen International Graduate School), Qing Li `[通讯]` (Peng Cheng Laboratory)

**通讯引用:** 37055 | [OpenAlex ID](https://openalex.org/A5100404176)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了Crucio，一种面向复杂编程语言的黑盒上下文无关文法推断框架，能够在实用时间内为C、C++、Java、Lua和Rust等语言自动生成可接受合法输入且拒绝非法输入的语法模型。

**💡 创新点**

创新点包括：①利用分解森林（decomposition forest）系统探索输入样本的结构化拆分，产生短而可泛化的子样本；②通过分布矩阵（distributional matrix）与交换图（swap graph）实现仅一次oracle查询即可完成语法推断；③引入Swap Precision评估指标，克服采样精度的结构和长度偏差；④在词法推断中结合决策树与L*算法实现对标记的高效归一化。

**🔧 技术方法**

使用的技术主要有：分解森林与三种拆分策略；决策树分类器对词法符号进行归类；L*算法进行字符级正则化；分布矩阵构建上下文-子串关联；交换图与最大团求解实现语法合并；首阶交换正确性保证推断语法合法性。

**📊 数据集**

采用31个训练数据集，涵盖16个语法：简单语法（arith、math、fol、json、lisp、turtle、while、xml、curl、tinyc、minic）以及五个复杂语言（C、C++、Java、Lua、Rust）。数据来源包括公开基准Kedavra、The Algorithms项目以及ANTLR4 grammar库。

**📈 对比分析**

与Glade、Glade+、Glade++等现有黑盒推断工具比较，Crucio在所有14个简单语法上取得等于或更高的F1（有些达到1.0），并在C、C++、Java、Lua、Rust等复杂语言上在48小时内完成推断，而其他工具要么内存耗尽、运行超时或无法完成。平均推断耗时约13.6小时，内存峰值低于5GB；尽管oracle调用次数较多，但性能仍保持可接受。

**⚠️ 局限性**

主要局限包括：推断出的复杂语言语法解析效率较低（单个程序几秒甚至十几秒），主要受语法歧义和输入复杂度影响；在XML和tinyc等部分语法上精度略低；分布矩阵仅保证首阶交换正确性，无法完整覆盖更高阶结构，因而仍可能产生轻微过拟合或歧义。

---

## 317. DiffusionQC: Artifact Detection in Histopathology via Diffusion Model

**arXiv ID:** 2601.12233 | [PDF](https://arxiv.org/pdf/2601.12233v1)

**作者:** Zhenzhen Wang `[一作]` (Johns Hopkins University), John Kang `[通讯]` (Merck and Co. Inc)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `9ce7179e-700c-4310-ac2b-91df50ded46e` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

利用扩散模型将病理图像的噪声恢复误差作为离群得分，检测图像中的制备与扫描产生的工件，且仅需干净图像即可训练；

**💡 创新点**

将工件检测视作异常检测问题，使用潜在扩散模型学习干净图像分布，并通过对比学习显著扩大工件与正常图像在潜在空间的距离；

**🔧 技术方法**

潜在扩散模型（LDM）+变分自编码器+视觉Transformer+对比学习适配器+LoRA微调；

**📊 数据集**

TCGA 50份 H&E 级别 10×的全景图像，训练 16 份（63k 干净补丁，400 工件补丁），测试 24 份；

**📈 对比分析**

与 GrandQC 通过敏感度、精度、F1 比较：基本版已接近 GrandQC，增强版在多种工件类型上均超过 GrandQC，且训练样本和标注量大幅减少；在 IHC 切片上无额外微调亦能实现良好可视化检测；

**⚠️ 局限性**

对细小工件（如气泡）识别仍不够准确，且可能把罕见组织结构误判为工件，需进一步改进对比学习约束与阈值策略。

---

## 318. MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning

**arXiv ID:** 2601.12680 | [PDF](https://arxiv.org/pdf/2601.12680v1)

**作者:** Zheng Fang `[一作]` (Huazhong Agricultural University), Zaiwen Feng `[通讯]` (Huazhong Agricultural University)

**通讯引用:** 342 | [OpenAlex ID](https://openalex.org/A5049033206)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究LLM工具学习，提出MetaToolAgent元学习框架，并构造包含7个场景、155个工具、9,377问答对的数据集，用于评估工具选择性能。

**💡 创新点**

创新点在于：1) 采用双层元学习（Bi‑Level Optimization）将工具选择拆分为外层泛化与内层工具优化，实现对未见工具的强泛化；2) 将工具按使用场景细粒度划分，构造更贴近实际的多场景数据集；3) 在LLM工具学习中首次系统比较元学习与传统提示、细化微调等方法。

**🔧 技术方法**

使用技术包括：
- 元学习框架（双层优化、meta‑gradient 更新）
- 传统梯度下降与 LoRA 微调
- Chain‑of‑Thought 与 ReAct 进行对比
- 任务与工具的采样策略（单域/跨域）
- 预训练大模型（ChatGLM3、Chinese‑Alpaca‑2、Qwen1.5、Baichuan2）

**📊 数据集**

数据集：
- 自研7场景 155 工具、9,377 QA 对（包括工具描述、输入参数）
- 公开 Benchmark：ToolAlpaca、API‑Bench
- 通过单域（SD）和跨域（CD）两种采样策略扩展工具集合

**📈 对比分析**

比较方法：与基线 Prompt、Chain‑of‑Thought、ReAct、Fine‑Tuning（LoRA）进行横向对比；实验表明 MTA 在 SD 与 CD 两种设置下均显著优于基线和 CoT/ReAct，并且往往在 5/7B 规模模型中超过 Fine‑Tuning；在不同模型规模、不同场景下，MTA 维持较高准确率，证明其对未见工具的泛化优势。

**⚠️ 局限性**

局限性：
- 当工具场景不明显或工具差异极细时，Meta 学习易出现过拟合，导致在部分模型（如 ChatGLM3、Baichuan2）下略低于 Fine‑Tuning；
- 依赖大量任务与工具多样性，数据量不足时元学习效果有限；
- 目前仍缺乏极大规模公开工具数据集，方法在极少样本或高度相似工具环境中的表现未得到充分验证。

---

## 319. Harmonizing the Arabic Audio Space with Data Scheduling

**arXiv ID:** 2601.12494 | [PDF](https://arxiv.org/pdf/2601.12494v1)

**作者:** Hunzalah Hassan Bhatti `[一作]` (Qatar Computing Research Institute), Shammur Absar Chowdhury `[通讯]` (Qatar Computing Research Institute)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

针对阿拉伯语-英语双语环境，系统研究了多任务指令调优方法，涵盖生成任务（ASR、语音摘要）和判别任务（方言识别、情感识别），并提出混合训练策略。

**💡 创新点**

提出了新的“阿拉伯语短语音摘要”数据集 AraMega-SSum；引入“对齐器多样性采样（ADS）”与“任务进度课程（TPC）”两种调度方法，并证明两者结合的混合策略可在固定计算预算下兼顾收敛速度与鲁棒性。

**🔧 技术方法**

使用 Qwen2.5-Omni（7B）多模态 LLM，配合 Whisper‑v3 语音编码器和线性对齐器；采用 LoRA 参数高效微调；实现了对齐器空间聚类、信息密集批次构造以及任务/标签平衡的采样算法。

**📊 数据集**

使用 10.1K 小时阿拉伯语/英语混合语音数据进行对齐；多任务训练集包括 ASR、TSUM、SSUM（MegaSSUM+AraMega-SSum）、方言识别（ADI‑17+ADI‑5）与情感识别（BAVED、KSU、EAED 等）等；AraMega-SSum 共 50,618 训练样本（222 小时）和 4,000 测试样本（16.98 小时）。

**📈 对比分析**

与基线（随机混合）以及单独 TPC、ADS、以及 Gemini 上的性能对比，发现：①随机混合在生成任务上稳定但低效；②TPC 加强 ASR 但对情感/方言识别产生负迁移；③ADS 加速判别任务收敛但导致生成任务梯度不稳定；④混合 TPC+ADS 在保持 ASR/SSUM 表现的同时显著提升情感识别 F1 分数和方言识别准确率。

**⚠️ 局限性**

仅在 Qwen2.5-Omni 7B 的固定计算预算和 LoRA 微调条件下验证，未涉及更大模型或全参数微调；实验受限于单一双语设置，结果可能不适用于其他语言或更大规模模型。

---

## 320. Do MLLMs See What We See? Analyzing Visualization Literacy Barriers in AI Systems

**arXiv ID:** 2601.12585 | [PDF](https://arxiv.org/pdf/2601.12585v1)

**作者:** Mengli `[一作]`, Carolina Nobre `[通讯]` (University of Toronto)

**通讯引用:** 929 | [OpenAlex ID](https://openalex.org/A5034150082)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

对多模态大型语言模型在可视化解读任务中的失败模式进行系统评估，并扩展了人类可视化素养障碍的分类体系。

**💡 创新点**

提出了专门针对MLLM的可视化素养障碍分类，包含机器特有的推理与连贯性障碍，并通过定性编码分析发现错误集中在颜色密集、分段式图表。

**🔧 技术方法**

采用open‑prompting收集多模态LLM的答案、推理文本和关注坐标，使用open coding方法构建分类体系，并用多模型对比评估。

**📊 数据集**

使用改编版的reVLAT（53道题、12种图表类型）作为评测数据集。

**📈 对比分析**

四个SOTA MLLM在reVLAT上的准确率分别为Qwen86.4%、Claude74.7%、Gemini73.2%和GPT49.1%，在色彩丰富的饼图和堆叠条形图上表现最差。

**⚠️ 局限性**

主要局限包括对提示工程的敏感性、无法直接输出绘图注释、样本数量与答案顺序偏差，以及缺乏自动化编码与因果验证。

---

## 321. Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation

**arXiv ID:** 2601.12410 | [PDF](https://arxiv.org/pdf/2601.12410v1)

**作者:** Dingyi Yang `[一作]` (Nanyang Technological University), Boyang Li `[通讯]` (Nanyang Technological University)

**通讯引用:** 5238 | [OpenAlex ID](https://openalex.org/A5100732747)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计了两项基于短篇故事的基准任务，评估LLM在推断人物知识状态和意图方面的能力。

**💡 创新点**

提出了可疑知识检测（IKD）和知识敏感的下一步行动预测（KNP）两种新任务，并构建了对应的人类标注数据集。

**🔧 技术方法**

使用零样本链式思考提示和对话式评估，对多种闭源与开源LLM进行测试。

**📊 数据集**

使用从reedsy.com与short‑story.me收集并人工验证的约500个短篇故事（IKD）和500个Q&A对（KNP）构成数据集。

**📈 对比分析**

与人类与基准模型对比，绝大多数LLM仅略优于随机，最高IKD准确率66%，KNP准确率70%，远低于人类92%。

**⚠️ 局限性**

主要限制在于缺乏对知识状态关注的机制，数据集规模有限，且未覆盖更复杂情境与意图推理。

---

## 322. Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation

**arXiv ID:** 2601.12493 | [PDF](https://arxiv.org/pdf/2601.12493v1)

**作者:** Mehrdad Noori `[一作]` (École nationale supérieure de techniques avancées), Christian Desrosiers `[通讯]` (École nationale supérieure de techniques avancées)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一个新基准——Histopath-C，用来模拟数字病理图像中的真实域漂移，并在此基准上评估和改进了视觉-语言模型（VLM）的测试时适应（TTA）方法。

**💡 创新点**

创新点包括①设计了10种真实感的合成损坏（染色、污染、模糊、噪声、照明等）可在任何数据集上实时应用；②提出LATTE框架，结合多模板的损失级平均、转导式伪标签和低秩适配（LoRA）以提升VLM在域漂移下的鲁棒性；③在病理领域首次系统比较TTA方法并显示传统熵最小化方法表现不稳定。

**🔧 技术方法**

技术上主要使用：视觉-语言预训练模型（Quilt、PathGen、CONCH），多模板文本提示、转导伪标签策略、低秩LoRA参数微调、归一化层微调以及基准生成脚本。

**📊 数据集**

实验数据集涵盖10个公开病理数据集，包括NCT-7K、NCT-100K、LC25000、SkinCancer、RenalCell、MHIST等，在每个数据集上分别施加Histopath-C的10种扰动。

**📈 对比分析**

与TENT、TPT、LAME、CLIPArTT等主流TTA方法对比，LATTE在大多数数据集与扰动上平均提升10%–20%准确率；在最坏的扰动（如高强度噪声）下仍保持显著优势。

**⚠️ 局限性**

局限性主要在于：①仅在单一图像级别的单一扰动上测试，缺乏多扰动混合的评估；②依赖预训练VLM的可访问性，无法覆盖所有医学影像子领域；③未考虑批量级或在线学习场景下的实时适应效率。

---

## 323. Benchmarking Concept-Spilling Across Languages in LLMs

**arXiv ID:** 2601.12549 | [PDF](https://arxiv.org/pdf/2601.12549v1)

**作者:** Ilia Badanin `[一作]` (EPFL), Imanol Schlag `[通讯]` (ETH AI Center)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究多语种LLM的语言泄漏现象，并构建结构化意义生成与字典验证的评估框架。

**💡 创新点**

通过高多义词的结构化意义生成和字典验证，量化模型跨语种语义鲁棒性，提供相对溢出率指标。

**🔧 技术方法**

使用结构化JSON提示、包含词典上下文的评判模型（Gemini 2.5‑Flash）以及溢出率计算。

**📊 数据集**

使用100个高多义英文词、对应九种目标语言词典条目、以及16个开闭源多语模型。

**📈 对比分析**

分别对模型与语言计算溢出率，溢出率越低表示越鲁棒；Apertus‑70B最低20%，llama‑3.1‑8b‑instruct最高41%。

**⚠️ 局限性**

仅以词典定义为真值，可能忽略非正式用法和语境；聚焦多义词，未覆盖成语、隐喻等其他语义现象。

---

## 324. Distribution Shift Is Key to Learning Invariant Prediction

**arXiv ID:** 2601.12296 | [PDF](https://arxiv.org/pdf/2601.12296v1)

**作者:** Hong Zheng `[一作]` (Southwest Jiaotong University), Fei Teng `[通讯]` (Southwest Jiaotong University)

**通讯引用:** 7431 | [OpenAlex ID](https://openalex.org/A5100603950)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文研究了在域泛化场景中，为什么经验风险最小化（ERM）有时能优于专门针对离群分布（OOD）任务设计的方法，并从分布迁移度的角度给出理论解释与实证验证。

**💡 创新点**

创新点在于提出并证明：大幅度的训练域分布迁移能够使ERM学习到近似可变预测（invariant prediction）的模型，给出了基于KL散度与Massart噪声的性能上界，并将该观点与传统的IRM等方法关联起来。

**🔧 技术方法**

采用了理论推导（KL散度、Massart噪声、VC理论）、统计假设检验以及多种学习算法（ERM、ERM++、IRMa、P-IRM、VREx、FISH、EQRM、RDM）进行实验。

**📊 数据集**

使用了两组合成数据集：一组回归数据通过调节噪声方差产生不同的分布迁移度；另一组分类数据为CMNIST的颜色干预版本（C1、C2），分别对应不同的环境分布。

**📈 对比分析**

通过与Oracle、Optimal以及多种Odin方法的对比，发现当训练域分布迁移度增大时，ERM的性能线性提升，甚至可逼近或超越oracle/optimal，验证了分布迁移对模型泛化的正向作用。

**⚠️ 局限性**

局限性包括：理论假设（如因果关系线性不变、噪声分布一致）在真实数据中不易满足；未考虑样本量、VC维度等因素；迁移度的实际估计与选择仍缺乏系统方法。

---

## 325. Weaknesses of Facial Emotion Recognition Systems

**arXiv ID:** 2601.12402 | [PDF](https://arxiv.org/pdf/2601.12402v1)

**作者:** Aleksandra Jamróz `[一作]` (Warsaw University of Technology), Piotr Garbat `[通讯]` (Warsaw University of Technology)

**通讯引用:** 199 | [OpenAlex ID](https://openalex.org/A5091817259)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文通过对三种先进的面部情绪识别模型进行训练和交叉数据集测试，系统评估了它们在不同数据集上的表现。

**💡 创新点**

创新点在于首次将最新的深度学习方法与多样化的公开数据集进行跨数据集比较，揭示了模型泛化能力的严重瓶颈。

**🔧 技术方法**

采用深度卷积神经网络（包括POSTER++、DMUE、DAN等）以及相关数据增强与正则化技术。

**📊 数据集**

使用的主要数据集包括AffectNet、RAF-DB和ExpW，这些数据集在规模和情绪多样性上均表现突出。

**📈 对比分析**

比较方法为：在一个数据集上训练模型，再在另外两个未见过的数据集上进行测试；结果显示，在自训练集上的准确率高达90%以上，而在外部数据集上平均跌落到70%以下。

**⚠️ 局限性**

局限性包括数据集标注偏差、少数类别情绪识别困难、以及模型对噪声与跨文化差异的鲁棒性不足。

---

## 326. SSPFormer: Self-Supervised Pretrained Transformer for MRI Images

**arXiv ID:** 2601.12747 | [PDF](https://arxiv.org/pdf/2601.12747v1)

**作者:** Jingkai Li `[一作]` (Qilu University of Technology), Zhuoran Zheng `[通讯]` (Qilu University of Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

研发了一种自监督预训练Transformer SSPFormer，专门用于MRI图像的分割、超分辨率、去噪等低层任务；

**💡 创新点**

创新点在于三大核心模块：逆频率分层遮蔽、频率加权FFT噪声增强、跨模态频域注意力，解决域适配、数据稀缺与伪影鲁棒性三大难题；

**🔧 技术方法**

采用自监督掩码重建与FFT噪声注入相结合的预训练策略，配合实例中心归一化、频率门控FFN的Transformer编码器以及冻结共享骨干+轻量头的fine‑tune架构；

**📊 数据集**

使用110k未标注全身MRI（T1/T2/FLAIR/DWI/SWI/T2*）构成的MRI-110k数据集，并在BraTS 2020、IXI、Set4等公开数据上进行评测；

**📈 对比分析**

与ResNet、U‑Net、V‑Net、TransUNet、IPT等CNN/ViT基线对比，SSPFormer在BraTS Dice 0.85、95HD 2.1mm、IXI 4×SR PSNR 28.9dB、去噪PSNR 37.2dB 等指标上均优于对照，并且仅需20%标注数据即可超越100%标注的全监督模型；

**⚠️ 局限性**

局限性包括对极低SNR或严重畸变图像的鲁棒性尚待提升；跨模态对齐和扫描参数差异仍可能影响迁移效果；预训练和fine‑tune的计算成本较高。

---

## 327. RIPPLE++: An Incremental Framework for Efficient GNN Inference on Evolving Graphs

**arXiv ID:** 2601.12347 | [PDF](https://arxiv.org/pdf/2601.12347v1)

**作者:** Pranjal Naman `[一作]` (Indian Institute of Science), Yogesh Simmhan `[通讯]` (Indian Institute of Science)

**通讯引用:** 6158 | [OpenAlex ID](https://openalex.org/A5041794289)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了名为Ripple的增量推理框架，实现实时高效的GNN推理。

**💡 创新点**

创新点在于通用增量编程模型，支持多种聚合函数、注意力机制，并提供局部感知路由与分布式执行。

**🔧 技术方法**

技术包括增量消息传递、局部收集器、BSP同步、MPI通信、METIS划分与哈希/局部感知路由。

**📊 数据集**

使用ogbn-arxiv、Reddit、ogbn-products以及大规模ogbn-papers100M等四个图数据集。

**📈 对比分析**

与DGL的顶点/层级重算、InkStream等基线对比，在单机上提升至56更新/秒、在分布式上相对重算提升≈25倍，延迟下降至0.06–960 ms。

**⚠️ 局限性**

局限包括内存占用高、对加权聚合性能相对低、在极大图下单机无法扩展，且当前仅支持触发式推理。

---

## 328. ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents

**arXiv ID:** 2601.12294 | [PDF](https://arxiv.org/pdf/2601.12294v1)

**作者:** Dawei Li `[一作]` (Arizona State University), Ruocheng Guo `[通讯]` (Intuit AI Research)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a4b10f5d-130b-4e77-9367-6469ec621899` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建了ToolPRMBench，一个面向工具使用代理的过程奖励模型（PRM）细粒度评估基准；

**💡 创新点**

创新点在于将离线和在线轨迹采样结合、引入多LLM验证流水线、以及针对工具使用设计的PRM训练范式；

**🔧 技术方法**

采用了基于历史的离线采样、基于失败轨迹的在线采样、三模型投票过滤、以及SFT和强化学习（GRPO）等技术；

**📊 数据集**

数据集来源于四个代表性工具使用基准（ToolTalk、GTA、BFCL、ToolSandbox），共约984条样本；

**📈 对比分析**

对17种模型（API基础LLM、开源LLM、通用PRM、工具专用PRM）在各子基准上进行评估，API LLM表现最佳，工具专用PRM‑GRPO在非API模型中名列前茅，且与奖励引导搜索效果高度相关；

**⚠️ 局限性**

局限在于未对搜索策略进行充分实验、仅覆盖选定基准、未纳入MCP兼容环境，需进一步扩展和深入验证。

---

## 329. Privacy via Modulation Rotation and Inter-Symbol Interference

**arXiv ID:** 2601.12394 | [PDF](https://arxiv.org/pdf/2601.12394v1)

**作者:** Morteza Varasteh `[一作]` (University of Essex), Pegah Sharifi `[通讯]` (Amirkabir University of Technology)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

本文研究通过BPSK调制的相位旋转和人为产生的符号间干扰来实现用户侧差分隐私。

**💡 创新点**

创新点在于利用物理层的不确定性——相位旋转和时序偏移——作为天然隐私资源，而非人工加噪，且分析了其对ε和误码率的闭式关系。

**🔧 技术方法**

使用的技术包括BPSK调制、AWGN信道模型、确定性相位旋转、定时偏移导致的ISI、Q函数展开、Hurwitz zeta函数、误码率与隐私预算的解析映射。

**📊 数据集**

论文主要采用仿真方式验证理论，无实际数据集，仅在数值实验中设置不同的输入符号分布p和噪声功率σ。

**📈 对比分析**

通过与传统的SNR基隐私、相位旋转隐私以及无ISI情形比较，发现当输入分布不均匀时，ISI方案在相同误码率下能获得更低的ε（更强隐私），性能提升显著。

**⚠️ 局限性**

局限在于假设接收端对相位旋转或时序偏移无信息且无法估计；若接收端能恢复或估计这些参数，隐私保护会被削弱；此外DP仅针对最坏情况，无法抑制先验极度偏斜时的泄露。

---

## 330. FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains

**arXiv ID:** 2601.12259 | [PDF](https://arxiv.org/pdf/2601.12259v1)

**作者:** Jiashuo Liu `[一作]`, Wenhao Huang `[通讯]` (ByteDance)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `a2602d71-93ab-4bad-974b-672788df8193` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建并发布了FutureX‑Pro评测框架，针对金融、零售、公共卫生和自然灾害四大高价值垂直领域，设计实时动态预测任务及其对应的评测数据集，并加入FutureX‑Search将预测任务转化为信息检索基准。

**💡 创新点**

创新点包括：
- 将“污染不可设计”理念应用于垂直领域，确保未来事件不可被训练数据污染；
- 通过多源权威数据（如SEC披露、NOAA、CDC官方报告）实现域特定的精准 grounding；
- 引入多级任务设计（点预测、窗口极值、方向性动量），以及分层概率预测与不确定性量化；
- 设计针对检索难度的三层检索任务（直接检索、实体解析、隐式多跳），突出检索与推理的分离。

**🔧 技术方法**

使用的技术主要包括：
- 大规模语言模型与工具使用框架（GPT‑5、Grok‑4、Claude‑Opus、Qwen‑3、DeepSeek 等）；
- 结构化数据解析与推理逻辑，支持对财报、HTML、官方报告的抽取；
- 评价指标体系（相对误差、线性衰减、Set‑Overlap、EM/F1 等），实现对数值、列表和概率分布的统一评测；
- 通过自动化构建管道实现高频更新的实时 benchmark。

**📊 数据集**

使用的数据集包括：
- Finance：150家企业（100 US NASDAQ/NASDAQ‑100 + 50 China A‑share）公开财报与市场行情；
- Retail：240款跨境电商商品的 HTML 页码与销量快照；
- Public Health：70 周期 CDC、China CDC 的流感与呼吸道疾病监测报告；
- Natural Disaster：92 事件模板（共 446 变量），覆盖 NOAA、USGS、NMC、UK Met Office 等官方气象/地质数据库；
- Search：100 个从 FutureX 预测题目转化为检索任务的历史问答。

**📈 对比分析**

比较方法：将多款前沿 LLM 通过统一任务模板、工具链与评价指标进行横向对比。结果显示：
- Finance 任务中 GPT‑5‑High 与 Grok‑4 取得最高的 5% 误差阈值得分，其他模型普遍低于 50%；
- Retail 任务中，概率预测（Task 2/3）普遍优于点预测，GPT‑5.1‑High 与 Grok‑4 在三类任务上保持 0.6‑0.7 的稳定分数；
- Public Health 领域表现出明显的准确性-拒绝率权衡，Qwen‑3‑Max 与 DeepSeek‑V3.2‑Exp 在被答复任务上精度最高；
- Natural Disaster 领域中 GPT‑5 与 Grok‑4 在检索覆盖率与准确性上遥遥领先；
- Search 任务中，GPT‑5.1‑High 在 Level 1 任务达 71.8%，但在 Level 3 隐式多跳任务仅 43.6%；Grok‑4 在所有级别保持 53.8%，显示出对隐式实体解析的优势。

**⚠️ 局限性**

局限性：
- 仍受限于工具检索的可访问性，部分模型因检索失败而拒绝回答；
- 对极端置信度与低频事件的预测精度不足，仍出现大幅误差；
- 评测仅覆盖四大垂直领域，未能覆盖更细粒度子领域；
- 对模型内部推理路径缺乏可解释性与可追溯性；
- 数据集更新周期有限，难以覆盖快速变化的实时事件。

---

## 331. EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts

**arXiv ID:** 2601.12137 | [PDF](https://arxiv.org/pdf/2601.12137v1)

**作者:** Anzhe Cheng `[一作]` (University of Southern California), Paul Bogdan `[通讯]` (University of Southern California)

**通讯引用:** 4695 | [OpenAlex ID](https://openalex.org/A5105925385)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

提出一种基于特征主成分的Eigen‑Mixture‑of‑Experts（EMoE）架构，在ViT骨干中插入稀疏专家模块，以解决传统MoE的负载不平衡和专家同质化问题。

**💡 创新点**

创新点在于用学习到的正交特征基底进行几何路由，天然实现负载平衡与专家多样化，避免了辅助负载平衡损失与专家专化的冲突。

**🔧 技术方法**

采用ViT+Eigen Router+top‑1稀疏专家门控+正交性正则化，多专家MLP，并在ImageNet、CIFAR、Tiny ImageNet及3D MRI数据上进行训练与评估。

**📊 数据集**

使用的数据集包括ImageNet‑1K、CIFAR‑10/100、Tiny ImageNet，以及脑龄预测的3D结构MRI数据。

**📈 对比分析**

与V‑MoE、Single‑gated MoE、DeepMoE等基线在ImageNet上比较，EMoE‑ViT‑H达成88.14% Top‑1、98.27% Top‑5，且在负载平衡和少样本学习上显著优于基线。

**⚠️ 局限性**

局限性包括：对更大规模、多模态或实时推理环境下的鲁棒性尚未充分验证，且在极端稀疏或动态负载场景的适应性仍需进一步研究。

---

## 332. Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs

**arXiv ID:** 2601.12154 | [PDF](https://arxiv.org/pdf/2601.12154v1)

**作者:** Teodor-Călin Ionescu `[一作]` (Leiden Institute of Advanced Computer Science), Suzan Verberne `[通讯]` (Leiden Institute of Advanced Computer Science)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

研究使用嵌入式主题模型（BERTopic、Top2Vec）对13份癌症患者访谈文本进行主题抽取并对结果进行人工评估，探讨模型在临床语料上的适用性与提升方法。

**💡 创新点**

通过结合临床领域预训练嵌入（BioClinicalBERT）和LLM辅助主题标签，实现了比传统LDA更具语义连贯性与临床可解释性的主题生成。

**🔧 技术方法**

使用BERTopic、Top2Vec、BioClinicalBERT/ClinicalBERT/MsR BiomedBERT等嵌入模型，并以GPT‑4o mini进行主题标签生成。

**📊 数据集**

基于Erasmus MC提供的13份匿名转录访谈（132,722词，13份，原文荷兰语已翻译成英文）。

**📈 对比分析**

在小规模人类评估中，BERTopic在主题连贯性与可用性上优于Top2Vec，Top2Vec在关键词描述性上稍优；域特定嵌入显著提升主题语义质量。

**⚠️ 局限性**

主要局限包括：文本需翻译导致语义失真、对chunk大小高度敏感、评估规模小且未涉及临床专家、未在原语种数据上验证。

---

## 333. Biological Intuition on Digital Hardware: An RTL Implementation of Poisson-Encoded SNNs for Static Image Classification

**arXiv ID:** 2601.12156 | [PDF](https://arxiv.org/pdf/2601.12156v1)

**作者:** Debabrata Das `[一作]` (National Institute of Technology), Arnav Gupta `[通讯]` (National Institute of Technology)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

实现了基于Leaky Integrate-and-Fire模型的时钟精确SNN核，用固定点运算与位移实现突触电流衰减，并集成Poisson编码器和动态剪枝机制；

**💡 创新点**

创新点在于：①采用仅位移与加法的固定点LIF实现，消除浮点乘法；②在硬件上实现全局Poisson编码器将静态图像转换为时序突触；③引入活性剪枝，推理完成后立即关闭相关神经元以降低动态功耗；

**🔧 技术方法**

使用SystemVerilog RTL实现、Xilinx Vivado综合、32位XOR‑shift伪随机数生成器进行Poisson编码、位移操作实现衰减、基于FSM的时钟精确控制；

**📊 数据集**

使用MNIST手写数字数据集进行全连接层分类实验；

**📈 对比分析**

与ESP32上传统ANN（浮点MAC）进行对比：SNN在40 MHz下10个时步即可达到约89%准确率，推理时延≈100 µs；ANN需数秒（或5 ms使用DSP）才完成推理；模型大小从99.4 KB降至约8.6 KB，功耗从持续高到事件驱动低；

**⚠️ 局限性**

局限性包括：对高噪声和像素位移敏感，尚未实现在线学习（如STDP），当前仅支持单层全连接结构，未验证在更大规模或多层网络上的可扩展性；

---

## 334. Proxy Robustness in Vision Language Models is Effortlessly Transferable

**arXiv ID:** 2601.12865 | [PDF](https://arxiv.org/pdf/2601.12865v1)

**作者:** Xiaowei Fu `[一作]` (Chongqing University), Lei Zhang `[通讯]` (Chongqing University)

**通讯引用:** 104126 | [OpenAlex ID](https://openalex.org/A5100433899)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6215c339-3735-4be3-8a07-5bbb7004712d` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

通过探测并利用CLIP等视觉‑语言模型在不同架构间的代理对抗鲁棒性，提出一种HPT‑GPD方法，在不降低自然泛化的前提下提升零样本对抗鲁棒性。

**💡 创新点**

发现并利用非对抗训练CLIP的天然代理鲁棒性，设计分阶段的 warm‑up + EMA + 高学习率投影的解耦训练框架，实现对抗鲁棒性与自然泛化的平衡。

**🔧 技术方法**

采用对抗微调（PGD攻击）+知识蒸馏+EMA+学习率解耦（低/高）+自适应攻击评估等技术。

**📊 数据集**

使用 TinyImageNet 做微调，评估 15 个零样本下游数据集（CIFAR10/100、STL‑10、SUN397、Food101、OxfordPet、Flower102、DTD、EUROSAT、FGVC、ImageNet、Caltech101/256、StanfordCars、PCAM）。

**📈 对比分析**

与 FT‑TeCoA、PMG 等 SOTA 方法对比，在 PGD‑10 攻击下平均零样本对抗准确率提升约 5%，自然准确率保持或略高，训练速度与资源开销介于两者之间。

**⚠️ 局限性**

对代理鲁棒性机制的理论解释不足，实验仍局限于 CLIP 及其变体，对更广泛的 VLM 或不同任务的验证待进一步研究。

---

## 335. Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery

**arXiv ID:** 2601.12442 | [PDF](https://arxiv.org/pdf/2601.12442v1)

**作者:** Shahnawaz Alam `[一作]` (Muffakham Jah College of Engineering and Technology), Mohammed Kaif Pasha `[通讯]` (Muffakham Jah College of Engineering and Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了Constraint-Aware Neurosymbolic Uncertainty Framework（CANUF），将贝叶斯深度学习与可微符号约束融合，自动从文献中提取科学约束，生成可信且符合物理规律的预测并给出不确定性校准与可解释性说明。

**💡 创新点**

核心创新在于：①端到端可微的约束满足层实现硬约束保证；②自动化约束提取方案（知识图+模板匹配）消除人工编码瓶颈；③约束引导的不确定性校准机制（投影距离调节方差、软分箱ECE损失）；④实现了在保持高约束满足率的同时提升校准精度。

**🔧 技术方法**

技术栈包括：变分贝叶斯神经网络、可微线性化投影（CVXPYLayer）、软/硬约束可微表示、软分箱ECE损失、SciBERT+模板匹配的自动约束提取、自然语言模板生成解释。

**📊 数据集**

使用三大科学数据集：Materials Project（140k+材料形成能）、QM9（分子HOMO‑LUMO gap等12属性）、CMIP6气候（温度/降水）。

**📈 对比分析**

与MC‑Dropout、Deep Ensembles、BNN、PINN、PAL、NeuPSL等基线对比，CANUF在ECE上平均下降34.7%（最高到99.2%约束满足率），预测误差保持或略优，证明在保持物理一致性的同时显著提升不确定性校准。

**⚠️ 局限性**

局限性：①投影与可微优化导致训练/推理时间和显存略高；②需要领域特定的约束模板，自动化程度仍受限；③目前仅支持代数不等式约束，无法处理时序、空间或概率约束；④实验仅覆盖回归任务，分类/结构预测需进一步扩展。

---

## 336. Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification

**arXiv ID:** 2601.12419 | [PDF](https://arxiv.org/pdf/2601.12419v1)

**作者:** Mahammad Namazov `[一作]` (Ruhr University Bochum), Ivan Habernal `[通讯]` (Ruhr University Bochum)

**通讯引用:** 2277 | [OpenAlex ID](https://openalex.org/A5051194245)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了一个标准化的比较框架，用来评估模型无关的理由提取技术（MaRC 与 ISR）在欧洲人权法院案件违例预测中的可解释性。

**💡 创新点**

创新点在于首次将法律专家的评价与自动化的 LLM‑as‑a‑Judge 结合，形成一种完整的可解释性评估方法，并公开了评估准则与基准数据集。

**🔧 技术方法**

使用的技术包括 LEGAL‑BERT 分类器、MaRC 与 ISR 理由提取方法，以及通过归一化充分性（NormSuff）、充分性（NormComp）等 faithfulness 指标和 LLM‑as‑a‑Judge 进行的对齐评估。

**📊 数据集**

采用从 HUDOC 数据库抓取并过滤的 ECtHR 数据集，包含约1.5万正例与1.5千负例（剔除不可受理和隐藏违例），用于二分类违例预测与理由提取实验。

**📈 对比分析**

在定量评估中，MaRC 在 NormSuff 最高、ISR 在 NormComp 最佳；但在法律专家的定性评估中，两者均被判定为不支持、不充分；LLM‑as‑a‑Judge 与专家的一致性（κ<0.3）低，性能与专家判断相距较大。

**⚠️ 局限性**

限制包括仅使用英文数据、专家评估样本量有限（10例）、仅评估模型无关方法、LLM 对齐结果不稳定且未使用商业 LLM，且未对多语言或更复杂任务进行探索。

---

## 337. Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation

**arXiv ID:** 2601.12401 | [PDF](https://arxiv.org/pdf/2601.12401v1)

**作者:** Jinmei Liu `[一作]` (Nanjing University), Zhi Wang `[通讯]` (Nanjing University)

**通讯引用:** 11827 | [OpenAlex ID](https://openalex.org/A5100376398)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在强化学习微调大规模图像生成模型时，提出 DRIFT 框架以系统地激励生成多样性，防止多样性崩塌；

**💡 创新点**

创新点在于三大维度的多样性激励——奖励集中采样、噪声条件提示以及基于潜在函数的奖励塑形，实现对生成多样性的直接优化；

**🔧 技术方法**

使用了 RL 微调（GRPO、KL 正则）、潜在空间多样性度量（DreamSim、ClipScore 等）、噪声注入提示以及潜在函数奖励塑形等技术；

**📊 数据集**

主要在 Stable Diffusion v1.5 预训练模型上进行实验，并使用公开的文本提示集作为评估数据集；

**📈 对比分析**

与 DDPO、GRPO、GRPO‑KL 等基线对比，DRIFT 在保持相同奖励水平下实现 9.08%–43.46% 的多样性提升，或在保持相同多样性下实现 59.65%–65.86% 的奖励提升，整体表现占优；

**⚠️ 局限性**

局限在于需要额外的多样性计算模块，导致计算开销增加；未来可尝试用模型内部表征替代外部模块，扩展至视频/3D 生成。

---

## 338. Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?

**arXiv ID:** 2601.12349 | [PDF](https://arxiv.org/pdf/2601.12349v1)

**作者:** Yi Qian `[一作]` (Nanjing University), Bing Mao `[通讯]` (Nanjing University)

**通讯引用:** 2338 | [OpenAlex ID](https://openalex.org/A5089309949)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出并实现了一种新型跨应用攻击——Action Rebinding，利用Android GUI 代理在观察‑推理‑执行管道中的时间窗口，通过无危险权限的应用触发前台切换，将代理原本打算对目标应用执行的操作错误绑定到攻击者指定的应用上，实现高权限操作；同时引入Intent Alignment Strategy (IAS)规避验证门，展示多步攻击链。

**💡 创新点**

创新点在于：①将观察‑推理‑执行的 TOCTOU 问题系统化为 Action Rebinding 攻击面；②首次利用 Android UI 状态保留与前台切换实现跨应用高权限注入；③提出 IAS 通过语义对齐消除验证门；④演示多步攻击链与代理任务恢复机制的协同；⑤在六款主流 GUI 代理上验证攻击普遍性。

**🔧 技术方法**

主要技术包括：Android 前台切换（无权限），UI 状态保留与重现，观察‑推理‑执行窗口测量（W_o2a），通知/任务恢复策略，IAS 语义载体生成，实验环境构建（Pixel 14、Android 15）以及对代理日志的自动化分析。

**📊 数据集**

数据集为 15 项实测任务场景（如开启勿扰模式、请求权限、安装/卸载、发送短信、删除文件、在线购买等），使用各自目标应用的实际 UI 进行攻击；未使用公开大规模文本或图像数据集。

**📈 对比分析**

对比方法：在六款开源 GUI 代理（Mobile‑Agent‑v3、Droidrun、mobile‑use、AppAgent、mobiagent、AutoGLM）上分别执行 atomic 与 multi‑step 攻击，记录成功率、IAS 成功率、检测率等；结果显示 atomic 成功率为 100%，multi‑step 受代理恢复策略影响，IAS 将通过验证门的成功率提升至 0–100%，整体检测率为 0%。

**⚠️ 局限性**

局限性：依赖代理推理时延与 UI 布局稳定性；部分代理的恢复策略导致 multi‑step 失败；攻击仅针对 Android 平台，未考虑实时防御或动态检测；需要先行 profiling 与设备特定参数；对抗 IAS 及更高层安全机制仍需进一步研究。

---

## 339. Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration

**arXiv ID:** 2601.12766 | [PDF](https://arxiv.org/pdf/2601.12766v1)

**作者:** Lu Yue `[一作]` (Peking University), Feitian Zhang `[通讯]` (Peking University)

**通讯引用:** 606 | [OpenAlex ID](https://openalex.org/A5059772938)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 Spatial-VLN 框架，将空间感知增强与多专家推理相结合，针对 VLN‑CE 的门交互、多房间和指令歧义三大空间挑战实现零射门导航；

**💡 创新点**

创新点包括：① 通过全景拼接和门/区域专家构建跨视角一致的空间感知增强模块（SPE）；② 在专家决策冲突时主动探索以消除感知模糊的探索多专家推理模块（EMR）；③ 结合价值驱动的 waypoint 采样和强化学习控制实现高效 Sim2Real 转移；

**🔧 技术方法**

使用大型语言模型（如 GPT‑4、Llama3.1、Deepseek‑v3）做推理专家，配合 RAM 与 Spatialbot 进行语义与空间描述，融合 RGB‑D、LiDAR 与深度地图，强化学习低级控制和障碍规避；

**📊 数据集**

在 Habitat 平台的 VLN‑CE（基于 Matterport3D 的 90 场景）进行模拟实验，并挑选 100 个高难度任务；在真实办公和家庭环境（约 40 条指令）进行实地测试；

**📈 对比分析**

与监督学习方法 RecBERT、ETPNav 以及多种零射门基线（Open‑Nav、DiscussNav、InstructNav 等）进行对比；在模拟中相较 Open‑Nav 提升了 12%–21% 的成功率，在真实环境中成功率提升至 44%‑52% 以上，且导航误差显著下降；

**⚠️ 局限性**

局限性包括对长时记忆与长距离推理的依赖不足，且多房间任务提升有限；框架对多模态传感器和 LLM 推理依赖较大，计算成本相对较高，缺乏对动态障碍物和更复杂语义指令的鲁棒性。

---

## 340. FocusNav: Spatial Selective Attention with Waypoint Guidance for Humanoid Local Navigation

**arXiv ID:** 2601.12790 | [PDF](https://arxiv.org/pdf/2601.12790v1)

**作者:** Yang Zhang `[一作]` (Shanghai Jiao Tong University), Yue Gao `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 4623 | [OpenAlex ID](https://openalex.org/A5100726291)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出了 FocusNav 框架，利用 waypoint 引导的空间交叉注意机制与稳定性感知门控模块，实现了基于人类导航本能的空间选择性注意力，从而实现了人形机器人的动态障碍回避与稳健行走。

**💡 创新点**

创新点在于：①通过 Waypoint‑Guided Spatial Cross‑Attention（WGSCA）把预测的安全路径点作为查询点直接引导注意力，使感知聚焦与运动意图紧密耦合；②引入 Stability‑Aware Selective Gating（SASG）模块，利用 Gumbel‑Softmax 自适应截断远程信息，优先保证即时足部稳定；③整体框架模仿生物 PPA 机制，整合跨模态 BEV 感知、逆向 Transformer 预测和门控注意力，实现端到端的高效学习。

**🔧 技术方法**

技术方法包括：多模态 LiDAR + 深度相机融合与 voxel‑BEV 编码；VoxelNet + 3D 卷积 + Z‑轴池化生成 BEV 特征；逆向自回归 Transformer 预测 waypoint；WGSCA 交叉注意；SASG 门控（Gumbel‑Softmax）；GRU 控制策略；PPO+BC 端到端训练。

**📊 数据集**

数据集与环境：在 IsaacGym 中自建的复杂地形（楼梯、斜坡、间隙）与动态障碍（移动机器人、行人）仿真环境中训练；随后在 Unitree G1 机器人上进行真实世界实验，使用现场自建的测试场景（16 cm 楼梯、22° 斜坡、静态/动态障碍）。

**📈 对比分析**

方法比较：与 Gallant、Proprioception‑Guided Cross‑Attention (PGCA) 和仅使用 WGSCA 的基线对比，评估指标为成功率、行进率、碰撞频率与运动稳定度。实验显示 FocusNav 在平坦与不规则地形、静态与动态障碍下均实现了 10%–20% 的成功率提升、碰撞率下降、稳定度提高，且在最难场景中达到 87% 的成功率。

**⚠️ 局限性**

局限性：①仅关注前向视角，缺乏后方感知；②需要预设目标点，缺少自生成路径规划；③缺乏高层语义理解与长期推理，无法处理需要后向或复杂语义约束的任务；④对极端不确定环境（如高动态密集区域）仍有进一步提升空间。

---

## 341. Efficient Code Analysis via Graph-Guided Large Language Models

**arXiv ID:** 2601.12890 | [PDF](https://arxiv.org/pdf/2601.12890v1)

**作者:** Hang Gao `[一作]` (Chinese Academy of Sciences), Jian Zhang `[通讯]` (Chinese Academy of Sciences)

**通讯引用:** 52668 | [OpenAlex ID](https://openalex.org/A5100410082)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `3855fcda-48ef-4070-a15e-803cd5c84d83` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于图注意力的LLM框架（GMLLM），利用GNN对代码图进行解释并引导LLM聚焦潜在恶意片段，从而实现恶意代码检测与详细行为描述。

**💡 创新点**

创新点在于将轻量化GNN与LLM结合，使用可解释的掩码学习得到关注子图；通过LLM自动生成行为规则并训练GNN；实现对大型项目的低成本、可解释的恶意代码定位。

**🔧 技术方法**

技术主要包括：代码AST→图表示；LLM生成敏感行为规则与特征向量；双层GCN训练的GNN；掩码解释器（edge/feature mask）产生关注分数；LLM对关注子图进行深入分析与生成报告。

**📊 数据集**

使用公开数据集Backstabbers、Datadog、Mal-OSS以及自建大规模Python恶意代码数据集MalCP（按程序规模划分），并在每个数据集上评估检测与描述能力。

**📈 对比分析**

与LLM直接检测、规则工具Bandit4Mal、OSSGadget、Virustotal以及神经网络工具MPHunter、Ea4mp比较，GMLLM在大多数指标（Recall、Precision、ACC、描述质量）上显著优于基线，且在token消耗与推理时间上实现数十倍到数百倍的成本降低。

**⚠️ 局限性**

局限性包括：仅在Python生态中验证，需依赖LLM生成规则可能受提示质量影响；掩码解释器训练耗时（10–11s/项目）；对跨语言或更复杂代码结构的迁移尚未评估；在极大规模项目中仍需调优子图阈值以平衡性能与成本。

---

## 342. AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search

**arXiv ID:** 2601.12272 | [PDF](https://arxiv.org/pdf/2601.12272v1)

**作者:** Shahrzad Esmat `[一作]` (Iowa State University), Ali Jannesari `[通讯]` (Iowa State University)

**通讯引用:** 1072 | [OpenAlex ID](https://openalex.org/A5079359777)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

开发了 AgenticPruner 框架，利用多代理（Profiling、Master、Analysis）与大语言模型实现以 MAC 预算为目标的神经网络剪枝

**💡 创新点**

创新点在于：①直接针对 MAC 预算而非参数数目进行剪枝，②采用三代理协同架构并使用 Claude 3.5 Sonnet 进行自适应策略学习，③在异步容差窗口下实现快速收敛

**🔧 技术方法**

技术包括：图形依赖建模（DepGraph）、同构剪枝、Taylor 重要性评分、LLM 推理、异步容差控制、增量微调、硬件友好裁剪（多维度对齐）

**📊 数据集**

使用 ImageNet‑1K 数据集，对 ResNet、ConvNeXt、DeiT 等主流网络进行实验

**📈 对比分析**

与现有结构化剪枝方法（如 Isomorphic Pruning、AutoSlim、FPGM 等）对比，AgenticPruner 在相同或更低 MAC 预算下保持或提升精度；ResNet‑50 +0.91% 目标 1.77G MAC，ResNet‑101 +1.56% 目标 4.22G MAC，ConvNeXt‑S 在 8.17G MAC 下实现 1.41×GPU 加速，DeiT‑Base 在 0.61G MAC 下精度 70.76% 且严格满足 ±1%/±5% 预算

**⚠️ 局限性**

局限包括：对 Vision Transformer 的精度略低、CPU 加速不一定随 MAC 降低提升、对深度可分离卷积的 CNN 需要更多迭代、缺乏设备特定的延迟优化、LLM 结果可重复性有限、需要多轮微调增加训练成本

---

## 343. Hard Clique Formulas for Resolution

**arXiv ID:** 2601.12503 | [PDF](https://arxiv.org/pdf/2601.12503v1)

**作者:** Albert Atserias `[一作]` (Universitat Politècnica de Catalunya), Albert Atserias `[通讯]` (Universitat Politècnica de Catalunya)

**通讯引用:** 1578 | [OpenAlex ID](https://openalex.org/A5003671114)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文展示了如何将任何稀疏且在分辨率中难以反驳的不可满足3-CNF公式转换为k-团问题的负实例，并证明其对应的自然编码为n^Ω(k)-难以在分辨率中反驳。

**💡 创新点**

创新点在于通过展示分辨率可以模拟从3-SAT到参数化团问题的特定类型的归约的正确性证明，重新确立了k-团问题的已知条件硬度结果，并提供了明确的k-团实例。

**🔧 技术方法**

使用了分辨率技术来证明归约的正确性，并通过构造特定的k-团公式来展示其复杂性。

**📊 数据集**

使用了稀疏的3-CNF公式作为数据集，特别是那些在分辨率中难以反驳的实例。

**📈 对比分析**

与现有方法比较，本文提供的归约生成的k-团实例在分辨率中的复杂性至少为n^Ω(k)，这表明其性能在理论上是显著的，尤其是在处理稀疏实例时。

**⚠️ 局限性**

限制在于该归约不是在多项式时间内可计算的，因此在实际应用中可能面临效率问题。

---

## 344. OpenAI for OpenAPI: Automated generation of REST API specification via LLMs

**arXiv ID:** 2601.12735 | [PDF](https://arxiv.org/pdf/2601.12735v1)

**作者:** Hao Chen `[一作]` (Beihang University), Wei Li `[通讯]` (Beihang University)

**通讯引用:** 26623 | [OpenAlex ID](https://openalex.org/A5100317994)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe`

**🎯 论文内容**

提出一种基于大型语言模型代理工作流的 OOPS（OpenAI OpenAPI Project Scanner），通过构建 API 依赖图和多阶段自我修正实现对多语言、多框架 REST API 的技术无关的 OpenAPI 规范自动生成。

**💡 创新点**

创新点在于：①使用 LLM 代理构建 API 依赖图完成跨文件关联，突破上下文长度限制；②引入多阶段生成与自我修正机制显著降低语法和语义幻觉；③实现完全无技术特定规则、无需人工干预的通用 OAS 生成方法。

**🔧 技术方法**

核心技术包括：LLM 代理工作流（OpenAI GPT‑5 mini 及其它模型）、工具调用与结构化输出、API 依赖图算法、链式思维（Chain‑of‑Thought）与自我修正（Self‑Refine）策略。

**📊 数据集**

使用了 12 个真实 REST API（8 开源、4 专有），覆盖 5 种编程语言（Java、Python、JavaScript、Go 等）和 8 种开发框架（Spring Boot、FastAPI、Express.js 等）作为实验数据集。

**📈 对比分析**

与 APICARV、ExpressO、Respector、LRASGen 等基线方法对比，OOPS 在端点方法、请求参数、响应和参数约束四维度均获得 92–99% 的 F1 分数，平均提升 41–70%，并在多语言多框架场景表现更优。

**⚠️ 局限性**

局限性包括：仍依赖 LLM 的上下文与推理能力，可能出现幻觉或缺失信息；对极大规模项目的推理次数多、成本高；未验证对专有或非主流框架的兼容性。

---

## 345. Towards Robust Process Reward Modeling via Noise-aware Learning

**arXiv ID:** 2601.12748 | [PDF](https://arxiv.org/pdf/2601.12748v1)

**作者:** Bin Xie `[一作]` (State Key Laboratory of AI Safety Institute of Computing Technology CAS), Huawei Shen `[通讯]` (State Key Laboratory of AI Safety Institute of Computing Technology CAS)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a4b10f5d-130b-4e77-9367-6469ec621899` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了在过程奖励模型（PRM）中由于 Monte Carlo Estimation（MCE）产生的噪声问题，并提出了两阶段框架：先用反射意识标签纠正机制过滤自我纠正导致的误判，再通过噪声感知迭代训练（NAIT）自动纠正残留噪声，以提升步骤级正确性判别和推理性能。

**💡 创新点**

创新点在于：① 通过 LLM 判定轨迹中的自我纠正（reflection）来高精度过滤 MCE 的误报（FP）；② 引入基于模型自信度的迭代标签修正策略（NAIT），在保留大部分标签的同时纠正残留错误（FN），显著降低噪声并提升 PRM 性能。

**🔧 技术方法**

使用的技术包括：Monte Carlo Estimation（hard/soft 估计）、LLM 驱动的反射检测、噪声感知迭代训练框架（基于阈值的标签修正）、交叉熵损失训练的判别式 PRM。

**📊 数据集**

使用的数据集包括 GSM8K、MATH‑500、PRM800K、GSM8K、MATH、OmniMath 等数学推理数据集，构建 MC、MCRD、NAIT 三种训练集。

**📈 对比分析**

在 ProcessBench 上与传统 MCE PRM、过滤整合 PRM 以及其他基线对比，步骤级 F1 从约 30% 提升至 57%+；在 Best‑of‑8 推理上准确率提升 3.2–5.6个百分点，接近 GPT‑4o 的表现，同时保持更高的数据效率。

**⚠️ 局限性**

局限性：实验仅在 Qwen2.5‑Math 系列小模型上验证，未测试更大模型；仅评估测试时扩展效果，未结合强化学习；计算资源限制导致实验规模与多任务覆盖受限。

---

## 346. Deep Feature Deformation Weights

**arXiv ID:** 2601.12527 | [PDF](https://arxiv.org/pdf/2601.12527v1)

**作者:** Richard Liu `[一作]` (University of Chicago), Rana Hanocka `[通讯]` (University of Chicago)

**通讯引用:** 1073 | [OpenAlex ID](https://openalex.org/A5009881746)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `8d10c613-917e-4880-9716-17789f50e119` `64443552-63e0-44b5-906f-d90fe95c5a1b` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文提出了一种基于深度特征的网格变形方法（DFD），通过在预训练的二维视觉模型上提取特征并进行巴西克坐标特征蒸馏，直接生成与手柄变形相关的权重，实现无需优化即可对任意手柄进行实时、可控的网格变形。

**💡 创新点**

核心创新在于：①利用特征相似度构建无约束的线性混合权重，既保持细粒度控制，又天然实现语义级的全局变形；②提出巴西克特征蒸馏，将渲染像素与三角形几何信息统一，使特征场蒸馏与网格分辨率无关；③在神经场表示中自动检测语义对称平面，实现单侧手柄即可完成对称变形；④通过地理距离调节与特征空间约束，提供局部化与语义固定点控制。

**🔧 技术方法**

技术实现包括：神经字段（Neural Field）对三维空间特征进行逼近；巴西克特征蒸馏；特征相似度（如L2）生成DFD权重；地理距离权重衰减实现局部化；特征空间约束实现全局语义固定；自动对称检测与对称维持算法。

**📊 数据集**

使用的数据集主要为：ShapeNet（车、桌、椅子等1,363个模型）、APAP-Bench 3D（用于比较传统方法）以及Objaverse等大规模网格，用于验证跨模型泛化能力。

**📈 对比分析**

与ARAP、双调和坐标、APAP、NeuralMLS、DeepMetaHandles等基线相比，DFD在保持或提升变形质量（语义一致性、对称性、局部控制）的同时，预处理、绑定与变形阶段均表现出更优的时间复杂度，尤其在百万级面网格下仍能实现实时交互，且每次手柄更新不需要重新求解优化问题。

**⚠️ 局限性**

局限性包括：仍需对每个模型单独进行一次神经场蒸馏（尽管时间短）；线性混合在极端变形下可能出现体积崩塌或形状失真；目前未对非平滑或极端拓扑（如高孔洞）提供专门的鲁棒机制。

---

## 347. Docker Does Not Guarantee Reproducibility

**arXiv ID:** 2601.12811 | [PDF](https://arxiv.org/pdf/2601.12811v1)

**作者:** Julien Malka `[一作]` (Telecom Paris), Théo Zimmermann `[通讯]` (Telecom Paris)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

系统地综述了 Docker 在可复现性中的作用，并基于大规模实验重建 GitHub Actions 中的 Docker 镜像，评估不同复现级别（bitwise、功能和可重建性）的实际表现以及最佳实践的有效性。

**💡 创新点**

① 结合系统综述与大规模实验，首次量化 Docker 镜像在多层级可复现性上的表现；② 对文献中提出的 Dockerfile 复现最佳实践进行实证验证，并与官方 Dockerfile 进行对比。

**🔧 技术方法**

使用 Docker Builder、Hadolint 规则集、Trivy 容器清单工具、GitHub Actions 日志解析以及回归分析和统计检验。

**📊 数据集**

采用 2023 年 10 月收集的 GHALogs（约 500,000 次工作流运行）中包含 docker/build-push-action 的子集，提取 6,622 次完整 Dockerfile + 参数的工作流，及对应历史镜像的 digest。

**📈 对比分析**

对历史镜像与重新构建镜像逐文件比对和 Trivy 生成的软件包清单进行比例差异统计；通过回归模型评估最佳实践与可复现性之间的相关性；实验发现 bitwise 完全复现率为 0%，功能级别复现率极低（仅 1%–5%），重建成功率为 88% 与官方 Dockerfile 的 98% 相比存在明显差距。

**⚠️ 局限性**

① 样本仅来自公开 GitHub Actions 工作流，可能不代表全部 Dockerfile；② 仅检验可访问的历史镜像，时间跨度有限；③ 受 Docker 版本、宿主机差异等影响，实验无法完全控制；④ 回归模型解释力低，难以证明因果关系。

---

## 348. Automated Tool Support for Category-Partition Testing: Design Decisions, UI and Examples of Use

**arXiv ID:** 2601.12559 | [PDF](https://arxiv.org/pdf/2601.12559v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df`

---

## 349. CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training

**arXiv ID:** 2601.12282 | [PDF](https://arxiv.org/pdf/2601.12282v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 350. CoReflect: Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement

**arXiv ID:** 2601.12208 | [PDF](https://arxiv.org/pdf/2601.12208v1)

**作者:** Yunzhe Li `[一作]` (University of Illinois Urbana-Champaign), Chin-Chia Hsu `[通讯]` (Google DeepMind)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了CoReflect框架，将用户模拟与自适应评估标准结合，实现多轮对话的迭代式评估。

**💡 创新点**

创新点在于共进化的评估循环：对话模板与评估指标通过反射分析持续自我完善，提升对话质量检测的细粒度与覆盖度。

**🔧 技术方法**

采用LLM-as-a-Judge评估器、对话规划器与反思分析器等LLM驱动技术，配合模板生成、聚类洞察和指标更新流程。

**📊 数据集**

使用人工构造的30个用户人格与10种场景共953对已通过一致性校验的 persona‑scenario 组合，涵盖指令、信息、操作与交互四类任务。

**📈 对比分析**

通过与Gemini 2.5 Pro、Claude系列、Qwen3‑Next等多模型对比，三轮迭代后实现模型分层；平均性能提升约5–15%，区分度显著提升。

**⚠️ 局限性**

局限包括：仍需人工设定初始评估标准、场景与模板人工构造，且在极长对话中模型一致性衰退仍未完全解决。

---

## 351. S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation

**arXiv ID:** 2601.12719 | [PDF](https://arxiv.org/pdf/2601.12719v1)

**作者:** Lin Zhao `[一作]` (Snap Inc.), Yanyu Li `[通讯]` (Snap Inc.)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `64443552-63e0-44b5-906f-d90fe95c5a1b` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种面向移动设备的 Streaming Sandwich Diffusion Transformer（S²DiT），能够在手机上实现高保真、低延迟的视频流式生成。

**💡 创新点**

创新点包括：①将线性卷积混合注意力（LCHA）与步幅自注意力（SSA）交错嵌入的 sandwich 结构；②基于预算约束的动态规划搜索自动分配两种注意力模块；③提出 2‑in‑1 级联蒸馏流程（先离线缓存蒸馏再自回归蒸馏）来把大型教师模型的视觉质量迁移到小型模型；④在自回归推理中使用自强（self‑forcing）与分布匹配蒸馏来消除暴露偏差。

**🔧 技术方法**

使用的技术包括：多阶段混合注意力（LCHA）与步幅自注意力（SSA）；预算感知动态规划搜索；Gumbel‑Softmax 以及 Straight‑Through 估计实现可微分模块选择；离线缓存蒸馏与分布匹配蒸馏；自强训练策略；CLIP‑ViT‑L 与 Gemma3‑4B‑it 文本编码；UniPC 采样器；CoreMLTools 部署。

**📊 数据集**

训练数据为约 300M 张图片与 50M 条视频，包含公开与内部来源；消融实验使用 OpenVid 2,000 条独立视频；采用 Wan Autoencoder、CLIP‑ViT‑L、Gemma3‑4B‑it 等数据集和模型。

**📈 对比分析**

在 VBench 上取得 83.62 分，接近 Hunyuan‑13B（83.78）与 Open‑Sora‑2.0（83.50）；相比 LTX‑Video、CogVideoX、Wan‑2.1 等公开模型，S²DiT 在 512×288 分辨率下均优于低效模型；在 iPhone 16 Pro Max 上实现 10+ FPS 的流式生成。

**⚠️ 局限性**

局限性包括：①对高分辨率（>512×288）的视频质量尚待提升；②SSA 模块仍需 KV‑缓存管理，可能导致内存峰值；③整体模型仍需依赖大规模教师（Wan‑2.2‑14B）的离线预热；④自回归推理中需 4‑步采样，尚未达到 1‑步实时性能。

---

## 352. TreeWriter: AI-Assisted Hierarchical Planning and Writing for Long-Form Documents

**arXiv ID:** 2601.12740 | [PDF](https://arxiv.org/pdf/2601.12740v1)

**作者:** Zijian Zhang `[一作]` (University of Toronto), Alán Aspuru-Guzik `[通讯]` (University of Toronto)

**通讯引用:** 67020 | [OpenAlex ID](https://openalex.org/A5071495561)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了TreeWriter，一种基于树结构的长篇写作系统，整合了AI助手以支持从高层思路到细节文本的全流程协作；

**💡 创新点**

创新点在于将文档层级结构与AI支持结合，提供节点级编辑与AI建议、可确认的编辑对话、版本化与可视化差异，以及通过树形层级显式分离内容与构想；

**🔧 技术方法**

技术实现使用TypeScript、React、Material‑UI和TipTap构建界面，Yjs实现协作，Vercel AI SDK搭配GPT‑5（主模型）和GPT‑4.1（编辑按钮）以及工具化的LLM代理；

**📊 数据集**

实验使用自制的4000字长文与800字创作任务；现场部署使用约25000字综述及两份学术项目的草稿；未使用公开标准数据集；

**📈 对比分析**

采用受控双因素实验（TreeWriter vs Google Docs+Gemini）与主观量表（Likert、CSI、NASA‑TLX）评估；TreeWriter在AI帮助、结构管理、思路展开、编辑控制等维度均显著优于基线；现场部署显示协作任务中树形结构提升了分工与审阅效率；

**⚠️ 局限性**

局限性包括样本量小（12人实验，8人现场部署）、以学生为主、任务时间受限、AI幻觉与可信度问题、树形界面对短文易显复杂、缺乏与常用写作/参考管理工具的深度集成。

---

## 353. An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models

**arXiv ID:** 2601.12723 | [PDF](https://arxiv.org/pdf/2601.12723v1)

**作者:** Yuhiro Ono `[一作]` (Tokyo Metropolitan University), Yukiya Miura `[通讯]` (Tokyo Metropolitan University)

**通讯引用:** 191 | [OpenAlex ID](https://openalex.org/A5102257011)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本研究设计了基于大型语言模型的进化式基准生成框架LLM-EBG，自动生成5维无约束连续最优问题并通过相对性能目标引导演化；

**💡 创新点**

创新点在于将LLM直接用作进化算子生成符号表达式基准，并以算法性能差异为演化目标；

**🔧 技术方法**

使用Llama 3.3‑70B作为生成器，结合传统EA评估、ELA和Sobol敏感性分析进行验证；

**📊 数据集**

数据集为自行生成的5维无约束基准问题，并与BBOB/COCO基准做对照；

**📈 对比分析**

通过10次独立实验，对GA与DE各执行20次重复评估，使用相对性能排名和惩罚项计算fitness，LLM-EBG在80%以上的试验中成功生成使目标算法占优的基准，理论最优fitness达到0.256；

**⚠️ 局限性**

局限在于初始多样性不足、主要依赖LLM生成能力、仅验证了GA与DE，扩展到更多算法及约束/多目标问题仍需进一步研究。

---

## 354. Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification

**arXiv ID:** 2601.12308 | [PDF](https://arxiv.org/pdf/2601.12308v1)

**作者:** Anurag Kaushish `[一作]` (University of Petroleum and Energy Studies), Kanav Gupta `[通讯]` (University of Petroleum and Energy Studies)

**通讯引用:** 106 | [OpenAlex ID](https://openalex.org/A5102117456)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出并实现了一种轻量级的适应性多尺度相关元网络（AMC‑MetaNet），用于解决遥感领域少样本分类的多尺度变化、域迁移和样本稀缺问题。

**💡 创新点**

创新点包括：① 通过相关性引导的特征金字塔捕获尺度不变模式；② 采用自适应通道相关模块（ACCM）动态学习跨尺度关系；③ 使用相关性引导的元学习策略，构建基于相关权重的原型，提升少样本适应性。

**🔧 技术方法**

技术手段主要包括：轻量级卷积骨干网络、空洞卷积实现多尺度金字塔、通道注意力与可学习相关权重、相关张量的深度卷积融合、基于余弦相似度的相关性原型与跨任务元学习（episodic training）以及交叉熵损失。

**📊 数据集**

在四个遥感基准数据集上进行实验：EuroSAT、NWPU‑RESISC45、UC Merced Land Use、AID。

**📈 对比分析**

与 ProtoNet、MatchingNet、DLA‑MatchNet、SCL‑MLNet、SPNet、DN4、TeAw、MVITP 等现有方法进行对比，在 3‑way、4‑way、5‑way 的 1‑shot 与 5‑shot 任务中，AMC‑MetaNet 在所有数据集上取得最高准确率（例如 5‑way 5‑shot 的最高 86.65%），并且参数量仅为 ResNet‑18 的 1/20，推理速度 <50 ms/图像。

**⚠️ 局限性**

局限性：实验仅覆盖四个公开数据集，缺乏对更大规模或更极端域迁移场景的评估；相关张量计算在极高分辨率图像上可能产生额外计算开销；模型在某些极低样本或噪声环境下仍可能出现过拟合或性能下降。

---

## 355. Extended Gabidulin-Kronecker Product Codes and Their Application to Cryptosystems

**arXiv ID:** 2601.12780 | [PDF](https://arxiv.org/pdf/2601.12780v1)

**作者:** Zhe Sun `[一作]` (Shandong University), Fang-Wei Fu `[通讯]` (Nankai University)

**通讯引用:** 3081 | [OpenAlex ID](https://openalex.org/A5063946169)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

研究了Gabidulin-Kronecker产品码与扩展Gabidulin码的最小秩距离，并提出了新的解码方法，随后基于此构造了三个改进的RQC密码系统。

**💡 创新点**

创新点包括：①证明在参数n₁=k₁、n₂=m< n₁n₂下GK码达到Singleton极限，获得新的MRD码；②首次引入EGK码并设计直接恢复码字的零解码失败概率解码器；③将EGK码与块误差、非齐次误差和无结构矩阵相结合，构建了RQC.EGK-BWE、RQC.EGK-Multi-NH和RQC.EGK-Multi-UR三种变体。

**🔧 技术方法**

采用Rank度量码理论、Kronecker乘积构造、有限域算术、符号解码算法以及Ideal块误差/非齐次误差模型等技术。

**📊 数据集**

未使用传统机器学习或数据集，主要采用随机生成的有限域元素作为密钥、生成向量、随机误差等。

**📈 对比分析**

通过与Classic RQC、HQC、BIKE、Multi‑UR‑AG等现有代码基方案在公钥/密文大小、总传输量以及是否存在解密失败概率等指标对比，结果显示在128/192/256位安全级别下三种EGK‑RQC方案的公钥尺寸明显小于多数同类方案且无解密失败，性能优异。

**⚠️ 局限性**

局限性在于仅给出了两种参数范围下的最小距离公式，通用公式仍未求解；解码复杂度受有限域大小影响，且对极端误差模式的容忍度有限。

---

## 356. Environment-Aware Code Generation: How far are We?

**arXiv ID:** 2601.12262 | [PDF](https://arxiv.org/pdf/2601.12262v1)

**作者:** Tongtong Wu `[一作]` (Monash University), Gholamreza Haffari `[通讯]` (Monash University)

**通讯引用:** 13361 | [OpenAlex ID](https://openalex.org/A5081525024)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文系统评估了大型语言模型在环境感知代码生成（EACG）与迁移（EACM）任务中的表现，提出了新基准 VersiBCB，并对三种适配策略（RAG、MoE、Memory）进行实验对比。

**💡 创新点**

创新点在于：1）首次构建多包、多版本、可执行验证的 Python 代码生成与迁移基准；2）从数据、参数、缓存三轴设计环境适配方法，提供统一评测框架；3）详细剖析三种策略的优劣与组合效果。

**🔧 技术方法**

技术手段包括 Retrieval-Augmented Generation (RAG) 进行检索增强、LoRA‑基混合专家 (MoE) 进行参数层面的专门化、以及缓存（Memory）增强实现即时适配；实验使用 CodeLLaMA 等开源 LLM 进行微调与推理。

**📊 数据集**

使用的数据集：主要是自研的 VersiBCB，覆盖 725 个可执行实例（生成 417，迁移 416），包含 36 个主流 Python 库与 202 个版本；对比参考 HumanEval+、LiveCodeBench 等标准基准。

**📈 对比分析**

评测指标为 Pass@k、Strict@1/Lenient@1、wPass@1 等；在 EACG 上，现有 LLM 最佳 Pass@1 仅 27%（GPT‑4.1），RAG 与 Memory 仅提升 1‑2%，MoE 提升 6%；在 EACM 上表现更好但仍未达到实用阈值；对比不同策略，Memory 在迁移任务中最突出，RAG 适配速度快但易过拟合，MoE 在泛化上表现不稳。

**⚠️ 局限性**

局限性：①模型对未见版本极为敏感，泛化能力差；②RAG 易受检索噪声与上下文窗口限制；③Memory 仅在已缓存环境中有效，遇冷启动时无效；④MoE 需要大量专家与门控训练，路由失效导致错误使用旧 API；总之，现有策略无法在复杂多库、多版本场景下实现高可靠性。

---

## 357. $2$-quasi-perfect Lee codes and abelian Ramanujan graphs: a new construction and relationship

**arXiv ID:** 2601.12393 | [PDF](https://arxiv.org/pdf/2601.12393v1)

**作者:** Shohei Satake `[一作]` (Kumamoto University), Shohei Satake `[通讯]` (Kumamoto University)

**通讯引用:** 40 | [OpenAlex ID](https://openalex.org/A5025982618)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文利用可逆有限域的三次曲线点集构造了一个新的 2-准完美 Lee 码族，其长度可任意延长。

**💡 创新点**

创新之处在于将近似 Ramanujan 图的生成集与 Lee 码关联，得到与已知构造不同的新参数，并统一了 Mesnager‑Tang‑Qi 构造与 Li 图、有限欧氏图的关系。

**🔧 技术方法**

主要技术包括代数几何（Weil 与 Hasse–Weil 估计）、有限域上的多项式不可约性判断以及谱图理论中的 Ramanujan 图性质。

**📊 数据集**

实验验证主要基于符号有限域 𝔽_{p^k} 中的点集，无需传统机器学习数据集。

**📈 对比分析**

通过对码长、维数、覆盖半径的理论推导，证明在 q≥14 时该码是 2-准完美的，并在 p≡1,7,11(12) 等模类中提供了新参数，优于现有构造。

**⚠️ 局限性**

局限性在于仍需满足 p≥5、q≥14 且仅针对特定模类的质数，且无法实现完全完美码；未来需进一步推广至更广泛的参数与构造。

---

## 358. Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF

**arXiv ID:** 2601.12415 | [PDF](https://arxiv.org/pdf/2601.12415v1)

**作者:** Wang Zixian `[一作]` `[通讯]` (China Mobile Communications Group), Wang Zixian (China Mobile Communications Group)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出Orthogonalized Policy Optimization (OPO)，通过在比例坐标下使用α‑divergence加权采样和χ²二次正则化来实现对采样几何和优化几何的独立控制，解决RLHF中KL基方法导致的梯度饱和和数值不稳定问题。

**💡 创新点**

核心创新是将采样与优化两大设计维度分离，利用χ²散度在比例坐标下天然产生二次惩罚，获得线性梯度动态和良好数值稳定性。

**🔧 技术方法**

使用α‑divergence加权的重要性采样、Pearson χ²散度正则化、比例坐标（或对数比例近似）以及标准的梯度下降优化。

**📊 数据集**

实验基于Qwen3‑1.7B模型，在MATH Level 3数学推理数据集上进行。

**📈 对比分析**

与GSPO（基于GRPO的句子级方法）对比，OPO在相同训练配置下表现略优（最终平均准确率约76% vs 71%），梯度范数更高，收敛更稳定。

**⚠️ 局限性**

局限性包括需调节α与μ超参数，实验仅覆盖单一推理任务和中等规模模型，缺乏在多任务、多规模上的广泛验证。

---

## 359. Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition

**arXiv ID:** 2601.12879 | [PDF](https://arxiv.org/pdf/2601.12879v1)

**作者:** Mohammed Mudassir Uddin `[一作]` (Muffakham Jah College of Engineering and Technology), Mohammed Kaif Pasha `[通讯]` (Muffakham Jah College of Engineering and Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出层次化归因图分解框架，用于在十亿参数语言模型中逆向发现稀疏计算电路。

**💡 创新点**

通过多分辨率层次抽象将搜索复杂度从指数降至O(n²logn)，并结合GNN指导与因果验证实现可扩展、高保真度的电路抽取。

**🔧 技术方法**

使用跨层转码器、稀疏特征字典、集成梯度归因、谱聚类、图神经网络元学习以及因果消融/补丁技术。

**📊 数据集**

在RedPajama语料上训练转码器，实验涵盖GPT‑2、Pythia、Llama系列模型，评估任务包括模数算术、奇偶性、排序、WinoGrande、HellaSwag和事实问答。

**📈 对比分析**

与穷举搜索、ACDC、归因补丁等基线对比；在算法任务上行为保持率92–97%，在自然语言任务上74–88%，同时在10–70B参数模型上实现数小时级完成，显著优于指数级或超线性方法。

**⚠️ 局限性**

局限在于未覆盖注意力电路、15–20%重构残差可能隐藏重要计算、验证存在循环性、GNN指导需昂贵标签、极大电路可能难以人类解释以及跨架构迁移仅为中等。

---

## 360. SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics

**arXiv ID:** 2601.12131 | [PDF](https://arxiv.org/pdf/2601.12131v1)

**作者:** Santosh Chapagain `[一作]` (Utah State University), Soukaina Filali Boubrahimi `[通讯]` (Utah State University)

**通讯引用:** 822 | [OpenAlex ID](https://openalex.org/A5010973892)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

构建并训练了 SolarGPT‑QA，一种针对 K‑12 学生在空间天气与日球物理领域的教育性问答大语言模型。

**💡 创新点**

创新点在于将领域自适应预训练（Domain‑Adaptive Pretraining）与教育式微调（Pedagogical Fine‑Tuning）结合，并通过 LoRA 参数高效方式实现，提升了科学准确性与教学可读性的双重平衡。

**🔧 技术方法**

使用了 Meta‑LLaMA‑3‑8B 作为基础模型，采用 LoRA 进行参数高效的领域自适应预训练与 QA 微调；随后通过受限解码、温度控制、top‑k/top‑p 采样等技术生成答案。

**📊 数据集**

利用 2010‑2024 年的同行评审日球物理论文（共约 5‑7 千篇）构建领域语料库，并生成由 GPT‑4 产生、Grok‑3 优化的教育型问答对数据集，按难度分为 Easy、Medium、Hard 三级。

**📈 对比分析**

通过与零样本通用 LLM（ChatGPT、Grok、Claude、DeepSeek、Gemini）以及 10‑shot 指令微调 ChatGPT 的人类两两对比评估，SolarGPT‑QA 在 win‑rate 评测中取得 75% 的胜率，学生理解率为 80%，在所有零样本基线中表现最佳，但仍略逊于指令微调 ChatGPT。

**⚠️ 局限性**

局限性包括：样本量小（仅 15 名学生）、仅限文本问答、缺乏检索增强与多模态推理、领域覆盖仅限 SDO 时代文献、以及在最高层次的教学效果仍不及强指令微调模型。

---

## 361. EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation

**arXiv ID:** 2601.12326 | [PDF](https://arxiv.org/pdf/2601.12326v1)

**作者:** Jing Zhang `[一作]` (East China University of Science and Technology), Bingjie Fan `[通讯]` (East China University of Science and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种训练无关的图像情感编辑框架 EmoKGEdit，能够精准地在保持结构和语义完整的前提下实现多情绪的情感转换。

**💡 创新点**

创新点在于构建多模态情感关联知识图谱（MSA‑KG）以提供情感因果链条的先验，并设计分离结构与情感的双流编辑模块，实现局部情绪注入与全局氛围平衡的可解释控制。

**🔧 技术方法**

采用 DINO 进行情感区域定位，Qwen‑VL‑2.5 进行链式思维（CoT）推理生成编辑指令，SDXL‑1.0 进行双流扩散采样，并结合知识图谱检索与多模态编码器（CLIP）进行情绪匹配。

**📊 数据集**

主要使用 EmoscapeSet（构建知识图谱）、EmoSet 与 Unsplash（测试集）以及 EmospaceSet（情绪文本检索）等数据集进行训练与评估。

**📈 对比分析**

与 InstructPix2Pix、Qwen‑Image‑Edit、AIF、EmoEditor、EmoEdit 等基线进行对比，EMOKGEdit 在结构保持（SSIM）、美学得分（AesScore）、语义清晰度（Semantic‑C）、情绪准确性（Emo_Acc8/2）和目标情绪激活（TEA）上均取得了最优或近似最优性能；用户研究亦表明在结构、语义、情绪和美学四个维度均排名第一。

**⚠️ 局限性**

局限性包括：对背景纹理的细节保留有限，过度依赖全局知识图谱导致局部情绪注入时背景可能丢失细节；目前仅支持离散情绪标签，未覆盖情绪分布的连续性与细粒度控制。

---

## 362. Joint Source-Channel-Generation Coding: From Distortion-oriented Reconstruction to Semantic-consistent Generation

**arXiv ID:** 2601.12808 | [PDF](https://arxiv.org/pdf/2601.12808v1)

**作者:** Tong Wu `[一作]` (Cooperative Medianet Innovation Center Shanghai Jiao Tong University), Wenjun Zhang `[通讯]` (Cooperative Medianet Innovation Center Shanghai Jiao Tong University)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `fede83ac-7505-405f-ab37-e7284695c47f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出联合源-信道-生成编码（JSCGC）框架，将接收端从确定性重建转为条件性生成；

**💡 创新点**

创新点在于：①用互信息最大化代替传统的失真优化；②引入感知一致性约束；③给出语义不一致性的理论下限；④通过生成模型实现高保真语义传输；

**🔧 技术方法**

技术手段包括：深度生成模型（扩散模型、Z-Image），MambaJSCC编码器，通信感知适配器（CA-Adapter），互信息估计与梯度优化，ODE采样；

**📊 数据集**

数据集：使用Open Images 500k样本（256×256）做训练，Kodak数据集做评估；

**📈 对比分析**

对比方法：传统失真基JSCC（CJSCC、MambaJSCC）和生成型DiffJSCC；结果显示JSCGC在LPIPS、DINO、rFID等感知指标上显著优于对手，尽管PSNR略低，表现出更好的语义一致性；

**⚠️ 局限性**

局限性：生成过程仍受互信息限制导致语义漂移；需要大规模预训练生成模型，计算开销大；在极低SNR时语义一致性下降；

---

## 363. Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs

**arXiv ID:** 2601.12807 | [PDF](https://arxiv.org/pdf/2601.12807v1)

**作者:** Zixing Song `[一作]` (University of Bristol), Irwin King `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 26928 | [OpenAlex ID](https://openalex.org/A5042251906)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了一种半监督指令调优框架 SIT-Graph，用于在文本属性图上高效利用有限标注节点和大量未标注节点训练大语言模型。

**💡 创新点**

通过迭代自训练结合置信度过滤的伪响应生成，使 LLM 在文本与图结构的多模态输入下实现半监督学习，并且该框架对模型无关，可无缝嵌入任何 LLM‑based 图指令调优方法。

**🔧 技术方法**

结合 GNN 提取图结构、投影器生成对齐图令牌、LLM 进行指令调优、伪标签生成与置信度基过滤以及自监督迭代训练等技术。

**📊 数据集**

在 Cora、arXiv 和 Wiki‑CS 三个文本属性图数据集上进行实验。

**📈 对比分析**

将 SIT-Graph 与 GraphGPT、InstructGraph、LLaGA、InstructGLM、MuseGraph、GraphCLIP 等六个基准模型集成，节点分类和链接预测在 1% 标注比例下平均提升约 20–30%，低标注比例（<1%）下性能提升尤为显著。

**⚠️ 局限性**

对伪标签置信度阈值敏感；在图结构弱关联或标签极度稀疏时，误标传播风险增加；在极大规模图上的计算成本仍需进一步优化。

---

## 364. UNMIXX: Untangling Highly Correlated Singing Voices Mixtures

**arXiv ID:** 2601.12802 | [PDF](https://arxiv.org/pdf/2601.12802v1)

**作者:** Jihoo Jung `[一作]` (Korea Advanced Institute of Science and Technology), Joon Son Chung `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 10153 | [OpenAlex ID](https://openalex.org/A5038723822)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

研究并实现了多声唱词分离框架 UNMIXX，利用音乐化混合、跨源注意力和幅度惩罚损失三项技术，显著提升双声唱词的分离质量。

**💡 创新点**

创新点包括：① 针对数据稀缺的音乐化混合策略，构造高度相关、音乐化的合成混合；② 跨源注意力模块引入反向注意力，迫使两声源表示相互分离；③ 幅度惩罚损失针对干扰能量做显式惩罚；④ 提出针对同歌手混合的 PSSNR/HSSNR 评估指标。

**🔧 技术方法**

使用了基于 TIGER 轻量语音分离模型的架构，结合 STFT、非均匀子波段投影、F³A 自注意力与跨源注意力、反向注意力机制以及幅度惩罚损失，并采用 Adam 优化器进行训练。

**📊 数据集**

训练数据来自约400小时单声唱词集合（9个公开歌唱数据集），评估数据为 MedleyVox 的 unison 与 duet 子集，并在训练时同样使用 MedleyVox 语音数据集以提高多源多语音的适配性。

**📈 对比分析**

与 MedleyVox 基线和同样训练条件下的 TIGER 对比，UNMIXX 在 duet 与 unison 子集上分别实现 SDRi +2.42 dB / +2.26 dB、与 TIGER 相比提升 0.94 dB / 1.20 dB，且参数增幅极小；在新提出的 HSSNR 指标上也显著提升，证明提升主要源于真实分离质量。

**⚠️ 局限性**

局限性在于：① 过度的和声对齐会降低训练样本多样性，影响 duet 性能；② 幅度惩罚损失在易分离的 duet 场景提升有限；③ 新评估指标仍无法完全捕捉跨段歌手分配一致性问题；④ 对极端多歌手或非同声演唱的数据适用性尚待验证。

---

## 365. TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents

**arXiv ID:** 2601.12895 | [PDF](https://arxiv.org/pdf/2601.12895v1)

**作者:** Chan Naseeb `[一作]` (IBM), Usman Habib `[通讯]` (FAST NUCES)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种统一的TwoHead-SwinFPN架构，用于身份证明文件的合成篡改检测与定位。

**💡 创新点**

结合Swin Transformer、FPN和CBAM的双头设计，并采用不确定性加权多任务学习，实现了检测与分割任务的联合优化。

**🔧 技术方法**

使用Swin Transformer骨干、特征金字塔网络、CBAM注意力模块、双头输出、混合精度训练和FastAPI部署。

**📊 数据集**

在FantasyIDiap数据集（2358张图，涵盖10种语言、3种采集设备、面部置换与文字填充攻击）上进行实验。

**📈 对比分析**

与传统CNN+UNet基线对比，通过消融实验验证各模块贡献，最终实现84.31%分类准确率、90.78% AUC、57.24%平均Dice分数，推理时间约198ms。

**⚠️ 局限性**

对新型操控技术的泛化有限，分割精度波动大，且仅在GPU环境下可达实时速度，CPU时延过高。

---

## 366. AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs

**arXiv ID:** 2601.12893 | [PDF](https://arxiv.org/pdf/2601.12893v1)

**作者:** Ting Dang `[一作]` (University of Melbourne), Fahim Kawsar `[通讯]` (University of Glasgow)

**通讯引用:** 5792 | [OpenAlex ID](https://openalex.org/A5053438231)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a8e75ba4-7a2d-4153-b003-06c94533add0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了一种基于神经常微分方程（NODE）的测试时适应（TTA）方法，用于时间序列预测；该方法仅在测试阶段通过更新两个可学习参数α、γ来对分布偏移进行自适应，并引入了负对数似然（NLL）与KL散度相结合的新损失函数；

**💡 创新点**

创新点包括：①在NODE中引入可解释的缩放与平移参数α、γ，以实现对时序数据幅度/频率与相位的自适应；②设计了专门针对回归任务的NLL+KL联合损失；③只需更新两参数，既能捕获时间依赖性，又能保持低显存开销；

**🔧 技术方法**

主要技术：神经ODE（latent ODE）、变分编码器-解码器结构、Gaussian概率输出、负对数似然+KL散度损失、RMSprop优化、RK45与adjoint方法求解ODE、2D CNN处理图像序列；

**📊 数据集**

实验数据集：一维合成信号（线性、正弦、阻尼振荡）在幅度/频率与时间延迟上设置5级严重程度；Rotating MNIST（旋转数字序列）在旋转角度差异上产生分布偏移；

**📈 对比分析**

比较方法：与源模型、无监督域适应（DAF）和测试时训练（TTT）等基线进行对比；在一维数据中相对改进0.53%–18%，在Rotating MNIST中MSE下降9.6%，Pearson相关系数与CCC分别提升约28%；整体表现优于所有基线；

**⚠️ 局限性**

局限性：仅能通过α、γ两参数捕捉线性幅度/相位变化，复杂非线性偏移仍有挑战；对高维实际业务序列的推广尚未验证；需要手动调节λ以平衡NLL与KL；实验样本主要为合成/图像序列，缺乏真实多元时序数据评估。

---

## 367. Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation

**arXiv ID:** 2601.12876 | [PDF](https://arxiv.org/pdf/2601.12876v1)

**作者:** Zhenxuan Lu `[一作]` (Guangdong University of Technology), Tianshui Chen `[通讯]` (Guangdong University of Technology)

**通讯引用:** 3157 | [OpenAlex ID](https://openalex.org/A5052027147)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出了 THFEM 框架，将语音驱动的说话头生成（AD‑THG）模型与语音保留表情编辑（SPFEM）模型结合，以在改变面部表情的同时保持原始口型同步。

**💡 创新点**

创新点包括：① 将 AD‑THG 引入 SPFEM 任务，实现音频与表情双重驱动；② 设计邻接帧学习策略，在训练时让 AD‑THG 以单帧 SPFEM 结果为先验，并利用相邻音频帧预测多帧输出，显著提升图像真实性和表情一致性；③ 通过多种 SPFEM 与 AD‑THG 组合展示该策略的通用性。

**🔧 技术方法**

使用的技术主要是：面部表情编辑模型（DSM、NED 等）、音频驱动说话头生成模型（EAT、EAMM）、语音编码器、头部姿态编码器、同步损失（SyncNet）、像素、感知（LPIPS）与对抗损失，并采用邻接帧学习框架。

**📊 数据集**

数据集为 MEAD（包含 7 种情感的 60 名演员视频），并在其上构建 SPFEM 训练集与 AD‑THG 训练集。

**📈 对比分析**

与 DSM、NED 等基线以及 EAT/EAMM 结合后进行量化比较。使用 FAD、CSIM 与 LSE‑D 三项指标，在同一身份与跨身份设置下，THFEM 均实现了更低的 FAD、更高的 CSIM 以及更低的 LSE‑D，表明图像真实性、表情相似度和口型同步均得到显著提升；用户研究也显示在真实性、情感相似度和口型相似度上都有 20–60% 的提升。

**⚠️ 局限性**

主要局限包括：① 结合邻接帧 AD‑THG 后模型参数量与 FLOPs 显著增加，导致推理成本上升；② 整体生成质量仍受限于底层 SPFEM 模型的缺陷，无法完全消除其产生的模糊或失真。

---

## 368. PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection

**arXiv ID:** 2601.12866 | [PDF](https://arxiv.org/pdf/2601.12866v1)

**作者:** Sharmila S P `[一作]` `[通讯]`, Sharmila S P

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `3f18e8e3-0266-457c-8567-9039b6d2394d` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了 PDFInspect，一种统一的恶意 PDF 文档检测特征提取框架，将文本图谱、元数据、结构、字符统计与时间特征融合成 170 维高维向量。

**💡 创新点**

创新点在于三维融合：1）将 PDF 文本构造成无向词图并提取图论特征；2）同时分析元数据、结构与字符熵，捕获伪装与隐藏行为；3) 通过多视角特征集提升对混淆与多态恶意 PDF 的鲁棒性。

**🔧 技术方法**

技术包括：文本抽取与分词、NetworkX 图构建与图论度量、熵与字符计数、元数据解析、时间差计算、结构统计（对象、字体、图片）、机器学习模型（RF、XGBoost、SVM、ANN、KAN）以及 PyMuPDF/PyPDF2 进行 PDF 解析。

**📊 数据集**

使用了 262,113 个 PDF 样本（128,876 个恶意、133,237 个良性），来源包括 VirusTotal、Malware Bazaar、CIC 等恶意库以及政府、学术与电子书等公共文件库。

**📈 对比分析**

与两套基线（仅结构特征；元数据+JavaScript 标记）相比，PDFInspect 在 80:10:10 训练/验证/测试划分下，所有模型均提升 3–4% 的准确率；最佳模型 KAN 获得 99.3% 的准确率、99.3% 的 F1 分数和 0.993 的 AUC。

**⚠️ 局限性**

局限性：1）主要基于静态特征，缺乏动态执行信息；2）对极度混淆或自定义 PDF 结构仍可能出现误判；3）模型对超大文件的特征提取时间尚未充分评估；4）缺乏对跨平台多语言文本的全面支持。

---

## 369. Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data

**arXiv ID:** 2601.12856 | [PDF](https://arxiv.org/pdf/2601.12856v1)

**作者:** Liping Huang `[一作]` (Agency for Science Technology and Research), Flora Salim `[通讯]` (University of New South Wales)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3f18e8e3-0266-457c-8567-9039b6d2394d` `5a41884c-404f-4688-a89c-aa238c10fe68` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

构建并训练了一种基于递归加权的空间-时间图模型，用周度登革热热点数据预测下一周的热点，并从模型中学习到隐式的城市级传播网络；

**💡 创新点**

创新点在于：①仅利用公开的每周登革热病例热点信息，不需要细粒度气象、人口密度或移动数据；②通过梯度下降学习每周可解释的传播矩阵 P，揭示隐藏的跨区域传播路径；③将学习到的网络与真实通勤流量进行对比，验证模型的可解释性；

**🔧 技术方法**

主要技术包括：图模型与递归加权自回归（考虑 H=4 周的历史热点）；梯度下降优化带有 L1/L2 正则的传播矩阵；tanh 激活与阈值判定的二分类；SSIM 评估传播矩阵的稳定性；

**📊 数据集**

使用新加坡国家环境局（NEA）通过 SGCharts 公开平台整理的 2013–2018 年及 2020 年的每周登革热案例 CSV 数据（每条记录包含坐标与病例数），并将地理坐标映射到 323 个子区；

**📈 对比分析**

与传统基于气象、人口密度、移动数据的预测方法对比，本文在 2013–2018、2020 年的测试中平均 F‑score 0.79–0.83，准确率 0.92–0.99，召回率 0.66–0.88；传播网络与 2011 年通勤流量网络高度相关，SSIM 指标显示每周传播矩阵稳定性 ≥0.96；

**⚠️ 局限性**

局限性包括：①仅在单一城市（新加坡）验证，跨城市推广需调整空间单位与阈值；②对非常短期（≤4 周）外推不一定稳健；③缺乏实时移动数据，无法捕捉突发流动模式变化；④模型假设人类移动是主要跨区域传播机制，若出现其他传播路径（如交通运输）可能不足以解释；

---

## 370. Quantum Interactive Oracle Proofs

**arXiv ID:** 2601.12874 | [PDF](https://arxiv.org/pdf/2601.12874v1)

**作者:** Baocheng Sun `[一作]` (Weizmann Institute of Science), Thomas Vidick `[通讯]` (École Polytechnique Fédérale de Lausanne)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文提出并构造了量子交互式预言机证明（qIOP）模型，并给出了两种针对 QMA 语言的 qIOP 构造：
1) 共享 EPR 对的 3 轮 qIOP，量子查询复杂度为常数、通信复杂度为多项式，证明可接受性与拒绝性的完整性-可靠性间隙为常数；
2) 强化版 3 轮 qIOP，既量子查询又整体量子操作均为常数，但通信复杂度为指数级；
并提出了一种新型单提议者多量子位测试，可单独用于验证量子态的性质。

**💡 创新点**

创新点包括：
• 引入了量子交互式预言机证明模型，兼具量子 PCP 与量子交互式证明的优点；
• 在共享 EPR 对的基础上，仅通过常数量的量子查询即可验证 QMA 的完整性，提供了对量子 PCP 猜想的松弛形式；
• 设计了一种单提议者多量子位测试，为后续在量子验证与量子委托计算中的应用奠定了工具。

**🔧 技术方法**

核心技术：
• 量子纠缠与量子传送（EPR 对）在证明者与验证者之间的初始共享；
• 通过 Pauli 码（Hadamard 码）与近似验证（PCPP）实现对量子一次性密码的承诺与检查；
• 采用多量子位反对称性测试和自校正编码实现对非局域哈密顿量能量的估计；
• 利用群表示与 Gowers‑Hatami 稳定性理论证明测量算符的近似交换/反交换性质。

**📊 数据集**

本工作为纯理论计算复杂性研究，无使用实测数据集；所有结论均来自数学证明与构造。

**📈 对比分析**

比较与性能：
• 对于共享 EPR 的版本，证明满足 O(1) 的查询复杂度与多项式通信，完整性/可靠性间隙为常数，说明在量子 PCP 猜想的松弛框架下已能实现高效验证；
• 强化版在查询与量子操作均为常数的同时，通信复杂度变为指数，显示了在保持极低量子资源时所面临的通信瓶颈；
• 论文没有与实验实现或数值模拟比较，所述性能完全基于理论上界与复杂度分析。

**⚠️ 局限性**

局限与未解问题：
• 强化版 qIOP 的通信复杂度为指数级，是否存在多项式通信且仍保持常数查询与常数量子操作仍是开放问题；
• qIOP 与量子 PCP 之间的具体转换关系尚未确定；
• 本构造依赖 EPR 对共享，若仅允许有限量子操作（如无 EPR 对）如何实现仍未解决；
• 对量子委托计算与密码学应用的实际影响仍需进一步研究。

---

## 371. Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning

**arXiv ID:** 2601.12894 | [PDF](https://arxiv.org/pdf/2601.12894v1)

**作者:** Kangye Ji `[一作]` (Tsinghua University), Zhi Wang `[通讯]` (Tsinghua University)

**通讯引用:** 18407 | [OpenAlex ID](https://openalex.org/A5100376411)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出Sparse ActionGen（SAG）方法，结合实时剪枝和全局一次性重用机制，显著加速视觉-语言-动作（Diffusion Policy）的多步去噪过程，实现实时机器人动作生成。

**💡 创新点**

创新点：
1) 采用观测条件的实时扩散剪枝器，动态预测每一步的稀疏计算模式；
2) 引入全局稀疏损失，引导非均匀分配计算资源；
3) 开发一次性全局重用策略，在时序和块级别实现激活重用，减少冗余。

**🔧 技术方法**

使用技术：
- Diffusion Policy（DiT）
- Transformer编码器+MLP的剪枝器
- Straight-Through Estimator（STE）
- 全局稀疏损失
- 缓存重用（zig‑zag）
- 端到端训练与推理

**📊 数据集**

数据集：
- Proficient Human（PH）和 Mixed Human（MH）演示数据，包含 Lift、Can、Square、Transport、Tool、Kitchen 等任务；
- 真实世界 pick‑and‑release 任务在 Franka 机器人上进行验证。

**📈 对比分析**

比较方法：
- 与 Full Precision、DDIM、EfficientVLA、BAC、Falcon、SDP、CP、L2C、Streaming Diffusion Policy 等基线进行对比；
- 在仿真与真实任务上，SAG 在保持或提升成功率的同时，平均实现 3.4×‑4.0× 的速度提升（某些任务 15× 加速），并在多阶段 Kitchen 任务中实现无损失的 4.03× 速度提升。

**⚠️ 局限性**

局限性：
- 需要在预训练的扩散策略上额外训练剪枝器，且对训练集的依赖较强；
- 剪枝率需手工设置，超高稀疏率时可能导致性能波动；
- 主要验证在特定机器人任务和模型架构上，跨模型迁移性尚待进一步验证；
- 对低功耗/边缘设备的延迟表现未作充分评估。

---

## 372. Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning

**arXiv ID:** 2601.12889 | [PDF](https://arxiv.org/pdf/2601.12889v1)

**作者:** Nazibul Basar Ayon `[一作]` (Bangladesh University of Business and Technology), A. S. M. Ahsanul Sarkar Akib `[通讯]` (Robo Tech Valley)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

研究开发了一个集成VGG16、ResNet50和InceptionV3的深度学习集成模型，用于一次性检测牛只的LSD和FMD。

**💡 创新点**

首次在同一模型中同时处理症状重叠的LSD和FMD，利用加权平均与温度标定实现高精度；并公开了10,516张专家标注、具有GPS来源的大规模数据集。

**🔧 技术方法**

采用卷积神经网络集成、数据增强、条件GAN生成合成图像、温度标定校准、梯度归一化和多类别评估指标。

**📊 数据集**

使用来自印度、巴西和美国18个农场的10,516张高分辨率牛只影像，分为6类，包含真实与cGAN合成样本，并附带GPS与兽医诊断元数据。

**📈 对比分析**

将集成模型与单一模型（VGG16/ResNet50/InceptionV3）和现有多病模型对照，评估指标包括准确率、宏平均精确率、召回率、F1、AUC-ROC等，最终集成模型在测试集上达到98.2%准确率、99.5% AUC-ROC，显著优于此前95%及以下的结果。

**⚠️ 局限性**

受限于样本主要来自三国且品种集中，模型对不同地区或其他皮肤病的泛化能力有限；推理时延和训练成本较高，尚需在边缘设备上进行量化压缩并进一步验证临床实用性。

---

## 373. Communication Methods in Multi-Agent Reinforcement Learning

**arXiv ID:** 2601.12886 | [PDF](https://arxiv.org/pdf/2601.12886v1)

**作者:** Christoph Wittner `[一作]` `[通讯]` (Johannes Kepler University), Christoph Wittner (Johannes Kepler University)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c773407a-6119-4871-b8b3-1e7ae17a6851` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

对多智能体强化学习中的通信方法进行系统综述与比较

**💡 创新点**

基于29篇文献构建分类框架，指出不同通信范式的优缺点及适用场景，强调通信效率与可扩展性关键性

**🔧 技术方法**

涵盖显式消息传递、隐式通信、注意力机制、图卷积/图注意网络、角色/层级通信等技术

**📊 数据集**

使用公开 MARL benchmark 如 StarCraft II、Multi‑Agent Particle Environment、Predator‑Prey 等数据集进行评估

**📈 对比分析**

采用任务奖励、收敛速度、通信/计算开销等指标进行对比，表明不存在统一最优方案，最佳方法取决于环境结构与计算限制

**⚠️ 局限性**

缺乏标准化系统级度量、对延迟、丢包、噪声等非理想通信条件下的鲁棒性评估不足

---

## 374. Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates

**arXiv ID:** 2601.12859 | [PDF](https://arxiv.org/pdf/2601.12859v1)

**作者:** Luca Schaufelberger `[一作]` (ETH Zurich), Kjell Jorner `[通讯]` (ETH Zurich)

**通讯引用:** 2341 | [OpenAlex ID](https://openalex.org/A5084206216)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `40105733-5154-44cd-8090-a8cab9e64b07` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

开发了一个基于Cremer-Pople内部坐标的流匹配生成模型PuckerFlow，用于高效、精准地生成环状分子的构象。

**💡 创新点**

将流匹配直接应用于低维Cremer-Pople空间，并提出环状傅里叶滤波器与几何信息先验，保证闭环结构且无需后处理。

**🔧 技术方法**

流匹配（flow matching）、等变3D图神经网络、环状傅里叶滤波器、几何先验、Cremer-Pople坐标。

**📊 数据集**

基于Folmsbee等人整理的约25万条分子中约15k条小至中等尺寸环的低能构象数据集（419种独特环）。

**📈 对比分析**

与RDKit ETKDG、KDG、GeoDiff、MCF等方法在puckering RMSD与全原子RMSD的AMR与覆盖率上进行对比，PuckerFlow在精度和召回均显著优于其他方法，尤其在puckering RMSD上平均误差从0.24 Å降至0.13 Å，覆盖率提升约20%。

**⚠️ 局限性**

目前仅训练在5-8元环，缺少大环（>8元）和杂环多合成环的充分数据；对宏环或更大尺寸环的推广仍需进一步研究；同时模型仍依赖手工预设的几何先验。

---

## 375. On Resilient and Efficient Linear Secure Aggregation in Hierarchical Federated Learning

**arXiv ID:** 2601.12853 | [PDF](https://arxiv.org/pdf/2601.12853v1)

**作者:** Shudi Weng `[一作]` (KTH Royal Institute of Technology), Mikael Skoglund `[通讯]` (KTH Royal Institute of Technology)

**通讯引用:** 8707 | [OpenAlex ID](https://openalex.org/A5041348422)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

研究了分层联邦学习中在不可靠通信条件下的安全聚合的极限与最优协议。

**💡 创新点**

创新点是提出了兼顾完整聚合与实值域求和一一对应的不可靠链路安全聚合框架，并给出了匹配的下界与最优方案。

**🔧 技术方法**

采用信息理论安全聚合、分层梯度编码（ComEffGC）、线性密钥生成与逆向证明技术。

**📊 数据集**

论文未使用具体数据集，仅在示例中采用离散符号。

**📈 对比分析**

通过与现有两轮协议和不完整参与方案对比，证明在给定通信与随机性预算下实现了理论最优的下界，性能达到最优。

**⚠️ 局限性**

局限性在于仍假设链路相互独立且密钥可线性生成，缺乏对动态网络拓扑和多层真实系统的实验验证。

---

## 376. Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification

**arXiv ID:** 2601.12826 | [PDF](https://arxiv.org/pdf/2601.12826v1)

**作者:** Teerapong Panboonyuen `[一作]` (Chulalongkorn University), Teerapong Panboonyuen `[通讯]` (Chulalongkorn University)

**通讯引用:** 521 | [OpenAlex ID](https://openalex.org/A5091353147)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

本文对肺癌CT图像分类中的Grad‑CAM解释方法进行了系统的可信度与定位可靠性评估，探究不同网络架构对Grad‑CAM可解释性的影响。

**💡 创新点**

创新点在于提出了结合定位精度、扰动可信度和解释一致性三项指标的量化评估框架，并揭示Vision Transformer在Grad‑CAM解释上的显著失真，提示需采用模型感知的解释方法。

**🔧 技术方法**

使用的技术包括ResNet‑50/101、DenseNet‑161、EfficientNet‑B0、ViT‑Base‑Patch16‑224深度网络、Grad‑CAM可解释工具、扰动实验以及IoU一致性度量。

**📊 数据集**

所用数据集为Iraq‑Oncology Teaching Hospital/National Center for Cancer Diseases (IQ‑OTH/NCCD) 1190张CT切片，涵盖正常、良性、恶性三类。

**📈 对比分析**

通过将五种网络在同一数据集上训练并在验证/测试集上比较准确率、灵敏度、特异度等指标，同时在相同样本上对Grad‑CAM热图进行定位精度、扰动减弱度和一致性评估，发现ViT表现最佳的分类精度，但其Grad‑CAM定位精度最低，其他CNN模型虽然分类稍逊但Grad‑CAM更可信。

**⚠️ 局限性**

局限性包括仅评估单一公开数据集，未验证跨机构泛化；Grad‑CAM作为通用方法在Transformer上不适用，需进一步开发模型感知的解释算法；量化指标仍依赖人工标注且计算成本较高。

---

## 377. Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning

**arXiv ID:** 2601.12816 | [PDF](https://arxiv.org/pdf/2601.12816v1)

**作者:** Ishir Garg `[一作]` (University of California), Rohan Gopalam `[通讯]` (University of California)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种名为FOPNG的优化器，通过在Fisher-Riemannian几何空间中投影梯度到Fisher正交补空间，从而在学习新任务时抑制灾难性遗忘。

**💡 创新点**

创新点在于将自然梯度与正交梯度方法统一于信息几何框架，给出闭式投影解，并首次在Fisher度量下实现梯度正交约束，兼具重parameterization不变性与下降保证。

**🔧 技术方法**

核心技术包括信息几何、Fisher信息矩阵（对角近似）、自然梯度、正交投影、以及FOPNG-PreFisher变体。

**📊 数据集**

实验使用标准连续学习基准：Permuted‑MNIST、Split‑MNIST、Rotated‑MNIST、Split‑CIFAR10 及 Split‑CIFAR100。

**📈 对比分析**

与 EWC、OGD、GEM、A‑GEM、FNG 等方法比较，FOPNG 在 Rotated‑MNIST、Split‑MNIST、Split‑CIFAR10 上显著优于其他优化器；在 Permuted‑MNIST 上表现略逊，但总体提升明显；在 Split‑CIFAR100 上也优于大多数方法。

**⚠️ 局限性**

局限性包括需存储前任务梯度、训练时间与任务数呈线性增长、对对角Fisher近似的依赖以及对大规模任务序列的计算开销。

---

## 378. The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items

**arXiv ID:** 2601.12849 | [PDF](https://arxiv.org/pdf/2601.12849v1)

**作者:** Eugene Lim `[一作]` (National University of Singapore), Nicholas Teh `[通讯]` (University of Oxford)

**通讯引用:** 69 | [OpenAlex ID](https://openalex.org/A5037242857)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

研究了在少量盈余物品（最多三件）情形下，EFX 公平分配与广义均值（p‑mean）福利优化的兼容性与计算复杂度，并给出了精确的价格-of‑fairness（PoEFX）界限；

**💡 创新点**

首次揭示了 p=0 的尖锐复杂度分界：对 p>0 的兼容性与优化问题为 NP‑hard；对 p≤0 则可多项式求解；同时给出了 EFX 与 Pareto 最优兼容性为 NP‑hard（甚至 Σ₂^P‑完备）及在非零边际效用与参数化盈余的可解算法；

**🔧 技术方法**

采用结构化匹配与分配枚举、可计算性分界理论、价格‑公平分析、归约与参数化算法等技术；

**📊 数据集**

论文为理论研究，无实验数据集；

**📈 对比分析**

通过理论证明与复杂度上界/下界对比，发现对 p≤0 的问题可在多项式时间内求解，得到常数或几乎无损的福利；而对 p>0 则需接受线性规模的福利损失；

**⚠️ 局限性**

局限在于仅考虑 c≤3 的少量盈余、加性评价函数，且对 p>0 仍无有效多项式算法；未给出近似方案或对更大盈余的具体分析；

---

## 379. Reproducibility in Event-Log Research: A Parametrised Generator and Benchmark for Event-based Signatures

**arXiv ID:** 2601.12978 | [PDF](https://arxiv.org/pdf/2601.12978v1)

**作者:** Saad Khan `[一作]` (University of Huddersfield), Monika Roopak `[通讯]` (University of Bedfordshire)

**通讯引用:** 651 | [OpenAlex ID](https://openalex.org/A5087829338)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `67630363-6be0-4f51-ab05-7198250671a5` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种七参数可配置的事件日志生成器，并利用该生成器创建了12,288个合成事件日志，用于评估事件基签名检测算法。

**💡 创新点**

创新点在于能够精细控制签名数量、事件数、相似度、重复次数等特征，生成带完整可重复ground truth的数据；同时对DBSCAN在大规模合成数据上的表现进行了系统基准。

**🔧 技术方法**

采用了对象中心的事件模型、参数化生成方法以及聚类算法（DBSCAN、OPTICS、Affinity Propagation、Mean Shift、Agglomerative）和随机森林回归评估特征重要性。

**📊 数据集**

使用了12,288个合成事件日志，事件数量范围为10K–40K，全部基于参数化生成，无使用公开真实安全事件数据集。

**📈 对比分析**

通过调整聚类超参数并使用Adjusted Rand Index（ARI）进行比较，DBSCAN在所有数据集上平均ARI>0.95且运行最快，其他算法性能较差。

**⚠️ 局限性**

局限性包括：生成的事件仅基于对象相似度，无法模拟多源时序多样性；高维稀疏空间导致DBSCAN在大簇单次出现时性能下降；缺乏对异构日志时间依赖性的建模。

---

## 380. Sutradhara: An Intelligent Orchestrator-Engine Co-design for Tool-based Agentic Inference

**arXiv ID:** 2601.12967 | [PDF](https://arxiv.org/pdf/2601.12967v1)

**作者:** Anish Biswas `[一作]` (Microsoft Research), Chetan Bansal `[通讯]` (M365 Research)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文对生产环境中的基于工具的LLM代理式推理工作负载进行大规模性能分析，并提出一种协同设计的推理系统（Orchestrator-Engine Co‑design）来降低首个令牌渲染（FTR）和整体延迟。

**💡 创新点**

创新点：
1) 通过5个轻量级API实现推理引擎与调度器的跨层信息共享；
2) 引入prompt拆分（prompt splitting）使工具执行与后续prefill并行；
3) 在解码期间流式分派工具调用（streaming tool dispatch）；
4) 基于语义标签的优先级驱动KV缓存失效策略，显著提升缓存命中率。

**🔧 技术方法**

使用技术：
- vLLM（v0.11.0）作为基础推理引擎；
- 异步事件驱动的Python orchestrator；
- 轻量级API（submit_partial_prefill、extend_prefill、register_streaming_callback 等）；
- 优先级缓存失效（基于标签的 FIFO + LRU）；
- 任务级调度优化（基于请求ID和迭代ID的优先级）。

**📊 数据集**

数据集：
- 生产环境中收集的 6000 条合成代理请求轨迹（包括提示、工具调用、延迟等）；
- 采用 Qwen‑3‑14B 与 Gemma‑12B 两个开源模型进行评测；
- 同时使用“工具密集型”与“迭代密集型”两类工作负载。

**📈 对比分析**

比较方法与性能：
- 对比基准 vLLM（默认调度）与 baseline+Sched（基于请求优先级的调度）；
- 评估指标：FTR 与整体延迟；
- 结果：在工具密集型工作负载下，FTR 中位数下降 15%（最高 35%），整体延迟下降 10%；
- Ablation 证明：prompt splitting 约 7.6% FTR 提升；流式工具调用进一步提升至 11.8%；
- 在 Gemma‑12B 上也保持 10% 级别的 FTR 与 5% 级别的整体延迟下降。

**⚠️ 局限性**

Limitations：
- 工具调用延迟高度可变，难以精确预测，导致失效策略的效果受限；
- 仅在单机 A100 GPU 上验证，跨机与多机扩展性未深入探讨；
- 部分优化（如 prompt 拆分）需要工具支持完整参数，无法对所有工具通用；
- 引入的 API 与调度逻辑会带来额外的实现与维护成本。

---

## 381. Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images

**arXiv ID:** 2601.12960 | [PDF](https://arxiv.org/pdf/2601.12960v1)

**作者:** Ainhoa Vivel-Couso `[一作]` (Universidade de Santiago de Compostela), Jose M. Alonso-Moral `[通讯]` (Universidade de Santiago de Compostela)

**通讯引用:** 6663 | [OpenAlex ID](https://openalex.org/A5056892202)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `e0540dec-d77f-42db-94ae-d039248f6393` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

基于全景牙片的牙龄估计系统AgeX，结合深度学习的黑盒预测与基于规则的可解释文本生成，提供可视化热图与自然语言解释，支持临床决策。

**💡 创新点**

创新点在于将自动化深度学习估计与可解释性人工规则生成相结合，构建了符合EU AI Act的可解释性框架，并通过ALTAI自评实现了可信AI的端到端设计。

**🔧 技术方法**

技术手段包括：两阶段Faster‑RCNN/CNN的牙齿检测与年龄概率分布预测、线性回归替代模型（Cameriere方法）作为可解释 surrogate、Grad‑CAM可视化、基于模糊量化的规则式数据到文本生成（SimpleNLG-ES）以及对不确定性进行量化和阈值化。

**📊 数据集**

使用来自西班牙加利西亚圣地亚哥大学口腔科学研究组的125张全景牙片（5–16岁，60女/65男，全部西班牙裔白种人），每张图均标注真实年龄、性别、牙齿尺寸、Cameriere测量及深度学习预测结果。

**📈 对比分析**

与传统线性回归（Cameriere）相比，线性回归 surrogate 在预测Cameriere值时表现最佳（R²≈0.943，MAE≈0.069），并在专家评估中获得平均4.77/5的文本质量分数；系统在ALTAI自评中获得4.40/5，表明在技术鲁棒性、透明度与责任感等维度均达到高水平。

**⚠️ 局限性**

局限性包括：数据集规模小且种族单一；仅评估后牙部位，第三磨牙不确定性高；文本生成依赖人工规则，扩展性受限；未在真实临床环境中进行大规模验证，模型对不同种族和口腔病变的泛化能力尚未充分评估。

---

## 382. Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration

**arXiv ID:** 2601.12952 | [PDF](https://arxiv.org/pdf/2601.12952v1)

**作者:** Shibo Shao `[一作]` (Harbin Institute of Technology), Mingxuan Jiang `[通讯]`

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出基于模仿学习的六自由度航天器近接与对接控制框架 IL‑SRD，直接从专家演示学习控制策略，降低对精确动力学模型的依赖。

**💡 创新点**

创新点包括锚定解码器目标(ADT)机制约束预测动作序列并引入时间聚合机制，抑制误差累积，确保物理一致性与长程稳定控制。

**🔧 技术方法**

采用 Transformer + VAE 隐空间编码、行为克隆、锚定目标、时间聚合，以及 MLP 与 MPS 的对比实验；通过 MPC 生成专家数据。

**📊 数据集**

使用 50 条 2500 步的 6‑DOF 专家轨迹数据集，并加入随机噪声模拟未知扰动。

**📈 对比分析**

与 PID、MPC、SAC、D4PG 和 Vanilla BC 进行对比，IL‑SRD 在收敛步、能耗、终端位置/姿态精度等指标上表现优于大多数方法，并在扰动环境下保持鲁棒性。

**⚠️ 局限性**

限制在于终端位置精度仍不足以满足极高精度近接需求，且低层伺服控制误差和延迟可能影响整体性能。

---

## 383. Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models

**arXiv ID:** 2601.12951 | [PDF](https://arxiv.org/pdf/2601.12951v1)

**作者:** Felix Mächtle `[一作]` (University of Luebeck), Thomas Eisenbarth `[通讯]` (University of Luebeck)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了二元 I/O 一致性评估框架，探究大型语言模型（LLM）对代码的理解是否与传统人类软件指标对齐，并提出无特征影子模型来预测模型成功率。

**💡 创新点**

创新点在于将代码理解任务重新表述为二分类问题，并通过 SAGE 评估人类指标与 LLM 性能的关联，随后利用影子模型捕捉传统指标无法体现的非人类规律。

**🔧 技术方法**

使用 XGBoost、SAGE、UniXcoder 编码器、GPT/CodeLlama 等 LLM 以及训练得到的影子模型，配合静态代码分析特征。

**📊 数据集**

使用 CodeNet Python 子集构建约 148,243 条训练样本和 12,563 条测试样本的（程序、输入、输出）三元组数据集。

**📈 对比分析**

与仅使用人类指标的基线（AUROC≈0.63）相比，影子模型在 8 个主流 LLM 上平均 AUROC 达到 0.86，显示非人类信号更能预测模型成功。

**⚠️ 局限性**

局限性包括影子模型仍无法完全预测 LLM 行为（AUROC 仅 0.86），缺乏可解释性，并且对不同模型的泛化能力有限，说明 LLM 代码理解具有不可完全预知的复杂性。

---

## 384. Membership Inference Test: Auditing Training Data in Object Classification Models

**arXiv ID:** 2601.12929 | [PDF](https://arxiv.org/pdf/2601.12929v1)

**作者:** Gonzalo Mancera `[一作]` (Universidad Autonoma de Madrid), Julian Fierrez `[通讯]` (Universidad Autonoma de Madrid)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

针对目标检测与分类模型开发了一套 Membership Inference Test（MINT）体系，用于判断给定图像是否曾被用于训练模型。

**💡 创新点**

创新点在于：①在对象识别域中首次构建每个类别专属的 MINT 模块，避免了单一模型对多类别的泛化问题；②直接使用原模型的中间激活和预测结果（而非构造 shadow model）进行成员推断，降低了对模型访问的门槛；③系统地研究了训练轮次、激活层选择、类别数量和模型架构对 MINT 性能的影响。

**🔧 技术方法**

技术包括：基于卷积神经网络的目标分类器（6 层卷积+全连接），激活层选择器，MINT 模块（带 MaxPool、ReLU、Dropout、Sigmoid），Adam 优化器，二元交叉熵损失，AUC 与准确率评估。

**📊 数据集**

使用了三大公开图像数据集：CIFAR‑10（60K 张 32×32 彩色图），CIFAR‑100（同尺寸 100 类），以及 GTSRB（51,839 张交通标志图，统一裁剪至 32×32）。

**📈 对比分析**

与传统 Membership Inference Attacks（MIAs）进行对比；在 CIFAR‑10、CIFAR‑100 与 GTSRB 上，MINT 的 AUC 和准确率分别为 0.728/0.826/0.853 与 0.649/0.745/0.819，均优于现有 MIAs 方法（最高 0.822/0.797/0.819）。

**⚠️ 局限性**

局限性包括：①仅针对图像分类任务，未验证对文本、语音等模态的适用性；②实验仅在同源数据集上进行，未测试跨域泛化；③MINT 需要访问原模型的中间层信息，实际部署时可能受限；④对大规模或高分辨率数据的计算成本未评估。

---

## 385. ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation

**arXiv ID:** 2601.12925 | [PDF](https://arxiv.org/pdf/2601.12925v1)

**作者:** Weize Xie `[一作]` (Shenzhen University), F. Richard Yu `[通讯]` (Carleton University)

**通讯引用:** 51760 | [OpenAlex ID](https://openalex.org/A5100420016)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了一种前瞻条件扩散策略（ForeDiffusion），通过预测未来视图并将其注入扩散去噪过程，以实现长时序、复杂机械操作的鲁棒控制。

**💡 创新点**

核心创新在于：①利用近时观测生成紧凑的未来视图表示，显式为扩散过程提供前瞻信息；②采用中层注入方式，提升未来信息的有效利用；③设计双重损失，将传统去噪损失与未来视图一致性损失相结合，缓解误差累积。

**🔧 技术方法**

主要技术包括条件U‑Net扩散模型（DDIM调度器）、基于RGB‑D和本体感知的点云编码（PointNet）、未来视图生成的MLP、FiLM式条件调制，以及双重损失训练策略。

**📊 数据集**

实验数据集：Adroit 手部操作数据集和 MetaWorld 多任务仿真基准，覆盖从易到极难的各种抓取与操控任务。

**📈 对比分析**

与 Diffusion Policy、DP3、FlowPolicy、ManiCM、SDM Policy 等五大基线对比，ForeDiffusion 在 Adroit 任务均达到 100% 成功率，在 MetaWorld 的 Medium/Hard/Very‑Hard 阶段分别取得 73%、59%、75% 的成功率，平均 80.56%，比最优基线提升约 23%（在复杂任务上最大 45%）。同时学习曲线显示其样本效率更高、收敛更快。

**⚠️ 局限性**

局限性包括：①仍依赖离线专家演示，真实环境迁移需进一步验证；②未来视图预测仅基于近时信息，可能不足以捕捉更长时间的动态变化；③双重损失权重需手工调节，过大或过小都会影响收敛；④在高噪声或极端光照下的视觉感知鲁棒性尚未充分评估。

---

## 386. Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass

**arXiv ID:** 2601.12916 | [PDF](https://arxiv.org/pdf/2601.12916v1)

**作者:** Sangjun An `[一作]` (Chungnam National University), Eun-Sun Cho `[通讯]` (Chungnam National University)

**通讯引用:** 421 | [OpenAlex ID](https://openalex.org/A5021428048)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过在LLVM IR层实现静态分析Pass，自动识别VM虚拟化混淆代码中的调度器、处理块及VM起止点。

**💡 创新点**

创新点在于提出一种仅依赖静态分析即可定位虚拟化核心结构的方法，避免了传统动态分析的覆盖率与反调试限制。

**🔧 技术方法**

使用技术包括LLVM 22.0.0 Pass、基于基本块遍历识别调度器（最大出口数）及其后继为处理块，并标记VM起止点。

**📊 数据集**

实验数据集为三段C程序（冒泡排序、阶乘、斐波那契），分别在Tigress 4.0.11的switch、direct、indirect三种虚拟化选项下进行混淆，并在不同编译优化级别（-O0到-Ofast）生成LLVM IR。

**📈 对比分析**

比较方法为在不同优化级别下运行该Pass，统计是否能成功识别四个核心结构；在未优化（-O0）时全部识别成功；在-0O3时因基本块合并导致VM起止点识别失败，说明对高优化环境的鲁棒性有限。

**⚠️ 局限性**

局限性包括：在高优化级别下LLVM IR会合并VM起止点，导致识别失败；仅支持LLVM IR，需要二进制级的lifting；且仅做结构识别，未完成语义反混淆，建议与动态分析结合。

---

## 387. Gated Differentiable Working Memory for Long-Context Language Modeling

**arXiv ID:** 2601.12906 | [PDF](https://arxiv.org/pdf/2601.12906v1)

**作者:** Lingrui Mei `[一作]` (Institute of Computing Technology), Xueqi Cheng `[通讯]` (Institute of Computing Technology)

**通讯引用:** 20528 | [OpenAlex ID](https://openalex.org/A5029998682)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Gdwm 框架，将测试时适配视为预算受限的记忆巩固问题；

**💡 创新点**

创新点在于通过上下文效用估计（CPMI）实现写入控制器，按预算分配梯度步数，显著减少梯度更新量；

**🔧 技术方法**

使用信息论度量 CPMI、可分块采样、LoRA 快速权重、AdamW 自监督下游任务损失；

**📊 数据集**

在 ZeroSCROLLS（GovReport、QMSum、Qasper、NarrativeQA、Quality、MuSiQue）和 LongBench v2 上进行评测；

**📈 对比分析**

与统一采样（qTTT）、自洽、一致性、束搜索等方法对比，Gdwm 在稀疏信息任务上提升约 5–12 %（平均 2.4–6.2 %），并在 4 × 较少梯度步骤的情况下保持相当性能，整体速度提升约 39 %；

**⚠️ 局限性**

局限包括固定块大小可能分割语义单元、对全局覆盖任务效果有限、以及需手动调节温度和最小覆盖等超参数。

---

## 388. AI-generated data contamination erodes pathological variability and diagnostic reliability

**arXiv ID:** 2601.12946 | [PDF](https://arxiv.org/pdf/2601.12946v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f`

---

## 389. Lombard Speech Synthesis for Any Voice with Controllable Style Embeddings

**arXiv ID:** 2601.12966 | [PDF](https://arxiv.org/pdf/2601.12966v1)

**作者:** Seymanur Akti `[一作]`, Alexander Waibel `[通讯]` (Karlsruhe Institute of Technology)

**通讯引用:** 6428 | [OpenAlex ID](https://openalex.org/A5023053982)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `67630363-6be0-4f51-ab05-7198250671a5` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出一种无需 Lombard 训练数据的零样本 Lombard TTS 系统，利用风格嵌入并通过 PCA 控制音量与清晰度，实现对任何说话者的可控 Lombard 合成；

**💡 创新点**

创新点在于：①利用大规模多风格数据学习的风格嵌入，并通过 PCA 分析其与 Lombard 属性的相关性，按需偏移相关主成分实现可解释的 Lombard 控制；②不依赖 Lombard 数据即可实现跨说话者、跨语言的 Lombard 合成；③在 F5‑TTS 基础上加入固定风格嵌入并冻结早期 Transformer 层，以增强对说话者身份的控制；

**🔧 技术方法**

技术方法包括：风格嵌入提取（ECAPA‑TDNN）、PCA 主成分分析与逆变换、FiLM 条件注入、基于 DiT 的流匹配 TTS、文本无参考的 inference、语速与时长控制；

**📊 数据集**

使用的大数据集包括：Emilia（多说话者多风格）、AVID（不同语音强度）、ALBA（快/慢/清晰语音），以及 LibriSpeech 进行对照评估；

**📈 对比分析**

与 F5‑TTS 基线相比，提出的 F5‑TTS‑Style 在无噪声和中等噪声（SNR 10/5）下的 WER 均略有提升（例如 German prompts 的 WER 由 7.04 降至 2.48），自然度 UTMOS 也有所提高；在 Lombard 级别下，模型的 ΔWER 明显低于真实 Lombard 语料，说明噪声鲁棒性更好；

**⚠️ 局限性**

局限性包括：①语者身份在极高噪声或极端 Lombard 级别下的 SSIM 稍有下降；②对细粒度发音与韵律的控制仍不够精细；③依赖预训练的风格嵌入编码器，可能对极少数特殊说话者表现欠佳。

---

## 390. ACE-Align: Attribute Causal Effect Alignment for Cultural Values under Varying Persona Granularities

**arXiv ID:** 2601.12962 | [PDF](https://arxiv.org/pdf/2601.12962v1)

**作者:** Jiatang Luo `[一作]` (University of Chinese Academy of Sciences), Huawei Shen `[通讯]` (State Key Laboratory of AI Safety, Institute of Computing Technology, CAS)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了在不同 persona 粒度下，大语言模型如何更好地对齐文化价值，提出了基于属性级因果效应对齐的 ACE‑Align 方法，提升模型对交叉人口属性的细粒度适配；

**💡 创新点**

创新点在于将文化价值视作由多重人口属性因果驱动的过程，而非将文化视为同质群体；通过对属性的因果效应进行对齐，解决在细粒度 persona 条件下的偏差和不一致性；

**🔧 技术方法**

采用因果效应对齐目标（CE 对齐）结合锚定损失，并使用 LoRA 参数高效微调，在最细粒度的 persona 上进行对照编辑，实现模型对因果关系的学习；

**📊 数据集**

使用 World Values Survey（WVS）第七波进行训练，评估时采用 ISSP 及部分 WVS 数据，覆盖 14 个国家，涵盖 13–10 个文化主题；

**📈 对比分析**

与基线 LLaMA3.1‑8B、Anthropological Prompting、CultureLLM 等方法对比，使用 1‑Wasserstein 距离衡量文化对齐分数；ACE‑Align 在所有 persona 粒度（G=1–4）上平均提升约 4 分，显著缩小高低资源地区的差距（从 9.81 点降至 4.92 点）；

**⚠️ 局限性**

受限于现有社会调查数据，仅覆盖有限文化与四个二元属性（性别、教育、居住、婚姻），无法体现更细粒度或多维身份；未来需要扩展多元因果因素和更丰富的数据来源。

---

## 391. Codes Correcting Few Restricted Errors

**arXiv ID:** 2601.12959 | [PDF](https://arxiv.org/pdf/2601.12959v1)

**作者:** Jens Zumbrägel `[一作]` (University of Passau), Jens Zumbrägel `[通讯]` (University of Passau)

**通讯引用:** 509 | [OpenAlex ID](https://openalex.org/A5019886277)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

提出了基于高斯整数和爱森斯坦整数的有限域子群取值受限误差纠正线性码构造，能够纠正两到三错误。

**💡 创新点**

创新点在于结合几何与代数方法，改写Roth‑Siegel Lee距BCH码与Newton恒等式，获得比MDS码更高的受限距离。

**🔧 技术方法**

使用有限域同构、曼哈顿/六边形距离、BCH码构造、Newton恒等式、代数符号扩展等技术。

**📊 数据集**

未使用传统数据集，构造基于理论证明的码。

**📈 对比分析**

与Huber等人的循环码和MDS码比较，显示在相同长度下受限距离更大、纠错能力更强。

**⚠️ 局限性**

仅适用于阶4或6的子群，扩展到更大子群受限于无法嵌入二维格子，且对更大错误数的纠错仍需进一步研究。

---

## 392. QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning

**arXiv ID:** 2601.12936 | [PDF](https://arxiv.org/pdf/2601.12936v1)

**作者:** Tianran Ouyang `[一作]` (Wuhan University), Bo Du `[通讯]` (Wuhan University)

**通讯引用:** 28857 | [OpenAlex ID](https://openalex.org/A5060042752)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于Slot‑Quality度量的无监督K自适应Slot Attention方法，能动态选取高质量槽并通过门控解码器完成重建。

**💡 创新点**

核心创新在于设计无监督Slot‑Quality指标、质量引导的槽选择策略以及解耦槽选择与重建的门控Transformer/MLP解码器，解决了传统自适应方法的槽绑定不精确与槽数与重建目标冲突的问题。

**🔧 技术方法**

采用Slot Attention框架、DINO特征编码、无监督质量评估、贪婪槽选择算法、双门门控机制的Transformer和MLP解码器以及重建损失训练。

**📊 数据集**

在COCO、PASCAL VOC、MOVi‑C和MOVi‑E四个数据集上进行实验验证。

**📈 对比分析**

与K固定方法（SPOT、DINOSAUR等）以及现有K自适应方法（AdaSlot、MetaSlot）对比，QASA在COCO和VOC上实现state‑of‑the‑art mBOi/IOU提升约8.4%，并在多数据集上显著优于K自适应基准。

**⚠️ 局限性**

在合成数据集上仍略逊于精调K固定方法；方法对K_max及阈值参数有一定依赖，对背景均匀性敏感，需进一步提升对不同场景的鲁棒性。

---

## 393. Bangladesh AI Readiness: Perspectives from the Academia, Industry, and Government

**arXiv ID:** 2601.12934 | [PDF](https://arxiv.org/pdf/2601.12934v1)

**作者:** Sharifa Sultana `[一作]` (University of Illinois Urbana-Champaign), Syed Ishtiaque Ahmed `[通讯]` (University of Toronto)

**通讯引用:** 3939 | [OpenAlex ID](https://openalex.org/A5089574660)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

通过桌面研究、59份半结构访谈和课程基准分析，评估了孟加拉国学术、产业和政府层面的 AI 准备状况，揭示了课程落后、资源匮乏、性别不平等与伦理缺失等问题。

**💡 创新点**

首次将黑盒化、嵌套基础设施、压力与路径依赖等 STS 理论框架应用于 AI 准备评估，提供了对技术、社会与治理交叉维度的多维度分析，并给出可落地的设计与政策建议。

**🔧 技术方法**

无显式技术实现；研究方法为定性多方法（桌面研究、访谈、文件分析）。

**📊 数据集**

无数据集；样本为 5 所高校学生、9 位教师、25 位业内人士。

**📈 对比分析**

无实验或性能对比；研究侧重质性描述与理论映射，未进行量化评估。

**⚠️ 局限性**

样本非全国代表性、受访者主要集中于城市研究型高校、政策层面数据缺失、研究结果受时间与政治背景影响。

---

## 394. Perception of Deepfakes among Bangladeshi Women

**arXiv ID:** 2601.12933 | [PDF](https://arxiv.org/pdf/2601.12933v1)

**作者:** Sharifa Sultana `[一作]` (University of Illinois Urbana-Champaign), S M Taiabul Haque `[通讯]` (Brac University)

**通讯引用:** 313 | [OpenAlex ID](https://openalex.org/A5029118675)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了孟加拉女性对深度伪造技术的感知及其社会文化影响，通过15次半结构访谈探讨其恐惧、应对与法律途径

**💡 创新点**

首次在全球南方社会文化语境中阐明深度伪造危害的社会技术机制，强调性别、文化与制度约束对受害者的影响

**🔧 技术方法**

采用定性访谈和反思性主题分析方法

**📊 数据集**

15位18-45岁不同背景孟加拉女性的访谈记录

**📈 对比分析**

未进行技术性能评估，主要通过对访谈内容的主题对比来呈现深度伪造的社会影响

**⚠️ 局限性**

样本规模小，主要来自有网络接入的女性，未涵盖更偏远或数字排斥群体，也未考察平台或执法机构视角

---

## 395. Online Continual Learning for Time Series: a Natural Score-driven Approach

**arXiv ID:** 2601.12931 | [PDF](https://arxiv.org/pdf/2601.12931v1)

**作者:** Edoardo Urettini `[一作]` (University of Pisa), Antonio Carta `[通讯]` (University of Pisa)

**通讯引用:** 612 | [OpenAlex ID](https://openalex.org/A5041806564)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5a41884c-404f-4688-a89c-aa238c10fe68` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `f86bf285-fd08-4156-973b-6e6481af8fa0`

**🎯 论文内容**

提出了自然分数驱动回放（NatSR）方法，用于在线时间序列预测，结合自然梯度、Student's t似然、经验回放和动态尺度。

**💡 创新点**

创新点在于：1) 将自然梯度视为分数驱动滤波器并证明信息理论最优；2) 用Student's t似然得到更新的 L₂ 约束，提高对离群点的鲁棒性；3) 引入动态尺度调节更新幅度，实现快速适应与稳定性的平衡；4) 将上述三者结合成单一框架，无需为时间序列定制结构。

**🔧 技术方法**

核心技术包括：自然梯度下降、分数驱动模型（GAS/DCS）、Student's t 负对数似然、经验回放（Replay）与第二阶近似、Tikhonov 正则化、EMA 平滑、动态尺度更新公式。

**📊 数据集**

使用了七个真实世界数据集：ETTh1、ETTh2、ETTm1、ETTm2、ECL、电力负荷、Traffic、WTH（气象），并在多步预测长度（1、24、48）上评估。

**📈 对比分析**

与基准方法（OGD、ER、DER++、FSNET、OneNet）比较，采用 MASE 评价指标。NatSR 在 5/7 个数据集上取得最优或第二优成绩；总体平均性能显著优于大多数基准，特别是在多步预测中显示更好的适应与鲁棒性。

**⚠️ 局限性**

局限性包括：对极端频繁或持久的 regime 变化（如 ECL、Traffic）鲁棒性不足；方法对超参数（如自由度、正则化系数、学习率）敏感；在不同数据集间缺乏统一的自动化调节机制，需进一步研究自适应超参数与更灵活的快速适应策略。

---

## 396. A Benchmark for Language Models in Real-World System Building

**arXiv ID:** 2601.12927 | [PDF](https://arxiv.org/pdf/2601.12927v1)

**作者:** Weilin Jin `[一作]` (Peking University), Minghua Ma `[通讯]` (Microsoft)

**通讯引用:** 1281 | [OpenAlex ID](https://openalex.org/A5070950193)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `79276348-11e0-48e3-84bc-7ec231d0171c` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

建立了一个跨ISA的软件包构建修复基准，评估LLM在不同架构迁移下的自动修复能力。

**💡 创新点**

提出首个面向跨ISA构建错误的端到端评估框架，包含迭代验证、工具协同和标准化流程。

**🔧 技术方法**

利用Model Context Protocol (MCP)、Open Build Service (OBS) 与多工具协同（结构提取、内容修改等）以及六大主流LLM进行评测。

**📊 数据集**

使用268个真实的跨ISA构建失败包，来自OBS的 x86_64 与 aarch64 迁移样本。

**📈 对比分析**

通过构建成功率、平均修复时间、平均token消耗等指标进行比较；GPT‑5 在 x86→aarch64 方向实现 63% 成功率，其他模型远低，显示任务高度挑战性。

**⚠️ 局限性**

现有LLM只能修复简单的依赖/配置问题，无法处理跨架构复杂依赖与长文本推理；框架在工具调用效率与大上下文支持方面仍有待提升。

---

## 397. From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation

**arXiv ID:** 2601.12904 | [PDF](https://arxiv.org/pdf/2601.12904v1)

**作者:** Jiahao Wang `[一作]` (Hangzhou Dianzi University), Congfeng Jiang `[通讯]` (Hangzhou Dianzi University)

**通讯引用:** 1595 | [OpenAlex ID](https://openalex.org/A5036326577)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 FusionRAG 框架，通过离线相似性引导的跨块预处理和在线查询引导的关键标记重算，实现了 RAG 中 KVCache 的高效重用与生成质量的显著提升。

**💡 创新点**

创新点包括：①在离线阶段利用检索块的相似性让块间进行跨注意力预处理；②在在线阶段采用查询引导的关键标记选择，均匀分布重算位置；③设计 Alternative Path 缓存匹配、异步 KVCache 调度和专门的 Q‑Sparse‑Attention 操作，兼容现有 prefix cache 并支持批量解码。

**🔧 技术方法**

使用技术主要有：Transformer KVCache 复用、相似性检索（如 BGEM3）、自定义查询‑关键标记选择算法、异步 I/O 调度、Triton 编写的稀疏注意力核、GPU 共享内存与 SSD 级别存储层级管理。

**📊 数据集**

评测数据集：TriviaQA、HotpotQA、Musique、2WikiMultiHopQA；模型包括 Mistral‑7B、Qwen2.5‑7B、14B、Qwen3‑32B 与 GLM4‑32B。

**📈 对比分析**

与 Full Attention、Full Reuse、CacheBlend、Cache‑Craft 等基线相比，FusionRAG 在 15% 重算率下 Normalized‑F1 提升至 70% 以上，TTFT 在 27K 上下文中缩短 2.66‑9.39 倍，吞吐量提升 1.2‑4.3 倍，且 KVCache 存储占用下降 71%。

**⚠️ 局限性**

主要局限是预处理需要 0.218 秒/块，若知识库频繁更新或“写一次读一次”场景会导致累计成本过高；适用于稳定且被多次查询的企业知识库。

---

## 398. The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check

**arXiv ID:** 2601.12979 | [PDF](https://arxiv.org/pdf/2601.12979v1)

**作者:** Qingyu Lu `[一作]` (Southeast University), Dacheng Tao `[通讯]` (Nanyang Technological University)

**通讯引用:** 97310 | [OpenAlex ID](https://openalex.org/A5074103823)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

系统评估了扩散式大语言模型（dLLMs）在两类代理任务中的表现，并提出了可插拔的多代理评估框架DiffuAgent，用以细化分析dLLMs在代理工作流中的功能作用。

**💡 创新点**

①揭示dLLMs在多轮代理交互中普遍出现循环动作、格式失真等“苦涩教训”；②设计DiffuAgent框架，将dLLMs定位为记忆、验证、工具选择、格式编辑等子模块，分离代理核心与辅助功能；③提供对比实验，展示dLLMs在非因果角色表现良好，但在因果规划和结构化输出上表现差。

**🔧 技术方法**

基于扩散式生成的dLLMs（LLaDA、Dream、Fast-dLLM v2、dLLM-Var）与传统自回归LLMs（Qwen3-8B、Ministral-3-8B-Instruct）结合；利用ReAct、工具调用框架、早期退出验证器等代理技术；在DiffuAgent中实现记忆压缩、工具选择器与JSON格式编辑器等模块。

**📊 数据集**

Embodied任务使用AgentBoard下的AlfWorld、ScienceWorld、BabyAI三个环境；Tool-Calling任务使用BFCL‑v3（单/多轮），共计758条实例。

**📈 对比分析**

与自回归LLM基线比较：dLLMs在Embodied任务的成功率低于10%，在Tool-Calling任务的单/多轮成功率均不及自回归模型；在记忆模块和工具选择模块上，dLLMs与自回归模型相当或略优；在早期退出验证器中，dLLMs更稳健、误删率更低；整体而言，效率提升（高吞吐量）并未带来代理性能提升。

**⚠️ 局限性**

局限：仅评估有限的dLLMs与两类任务，未覆盖更大模型或多种环境；未进行任务专门微调或强化学习；实验仅做dLLM作为辅助模块，未探究其作为主代理的潜力；DiffuAgent的固定管道可能低估了扩散模型在端到端代理中的能力。

---

## 399. Architecture-Optimization Co-Design for Physics-Informed Neural Networks Via Attentive Representations and Conflict-Resolved Gradients

**arXiv ID:** 2601.12971 | [PDF](https://arxiv.org/pdf/2601.12971v1)

**作者:** Pancheng Niu `[一作]` (Chengdu University of Information Technology), Yanchao Shi `[通讯]` (Southwest Petroleum University)

**通讯引用:** 1237 | [OpenAlex ID](https://openalex.org/A5074261900)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `57a58b01-81b4-4d75-a45c-2e891f272b50` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出 Layer-wise Dynamic Attention PINN（LDA-PINN）和 Gradient-Conflict-Resolved PINN（GC-PINN）两种改进，并将两者集成为 Architecture–Conflict-Resolved PINN（ACR‑PINN）以提升 PINN 的表示能力与优化稳定性。

**💡 创新点**

① 将输入坐标在每一隐藏层重新编码并通过可学习门控动态调制，增强网络对多尺度、高频特征的表达；② 将 PINN 训练视为多任务学习，针对不同物理约束产生的梯度冲突引入 PCGrad 投影策略，消除相互抵消的梯度分量；③ 两种技术协同工作，实现架构与优化的统一共设计，显著提高收敛速度与数值精度。

**🔧 技术方法**

1) Layer‑wise Dynamic Attention 机制（多视图编码 + 逐通道门控融合 + 残差注入）；
2) 多任务梯度冲突检测与 PCGrad‑style 投影；
3) 标准 PINN 损失（PDE 残差、IC、BC）与 Adam 优化器；
4) Latin Hypercube 采样生成训练点。

**📊 数据集**

四个经典 PDE 基准：1）Burgers 方程；2）Helmholtz 方程（低频与高频两种模式）；3）Klein–Gordon 方程（制造解）；4）二维 lid‑driven 容器流（Re=100）。数据全部由实验者自行采样，统一使用 LHS，且每种模型共享相同的采样集。

**📈 对比分析**

与标准 PINN 直接对比，所有改进模型均在相同超参数和训练轮数下表现更好。LDA‑PINN 单独提升约 10–30% 的 L2 与 L∞ 准确度；GC‑PINN 单独提升约 30–70%；ACR‑PINN 综合后在 L2、L∞ 误差上往往降低 1–2 个数量级，收敛速度最快、方差最小，尤其在高频 Helmholtz 与非线性 Klein–Gordon 问题中优势明显。

**⚠️ 局限性**

① 投影式冲突消除产生分段更新，训练曲线出现轻微振荡；② 本研究仅在低维标量或向量 PDE 上验证，尚未针对多物理耦合或高维问题进行评估；③ 对大规模样本、深层网络的可扩展性与内存需求仍需进一步研究。

---

## 400. Deterministic Dynamics of Sampling Processes in Score-Based Diffusion Models with Multiplicative Noise Conditioning

**arXiv ID:** 2601.12965 | [PDF](https://arxiv.org/pdf/2601.12965v1)

**作者:** Doheon Kim `[一作]` (Hanyang University), Doheon Kim `[通讯]` (Hanyang University)

**通讯引用:** 479 | [OpenAlex ID](https://openalex.org/A5088258764)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `f86bf285-fd08-4156-973b-6e6481af8fa0` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文建立了理论框架，解释了在乘法噪声条件下训练的扩散模型为何能通过采样方法产生高质量样本。

**💡 创新点**

核心创新是推导出该训练目标下的最优模型，并证明其与真实score不同，但在自控系统动力学中仍能逼近目标分布，从而解释了实际效果。

**🔧 技术方法**

采用的技术包括连续时间损失与似然加权、分布平滑（Phi函数）、动力学吸引子与极大不变性分析，以及拉萨尔不变性原理来分析采样过程。

**📊 数据集**

文中未给出具体实验数据集，理论研究基于通用概率测度；若在实践中可应用于标准图像数据集如MNIST、CIFAR-10等。

**📈 对比分析**

通过数值仿真比较annealed Langevin dynamics与probability flow ODE在理想网络下的收敛性，实验表明两种采样方法在得到的样本质量与传统score基模型相近或更优。

**⚠️ 局限性**

主要局限在于训练目标并不直接逼近真实score，若训练过度可能导致对训练样本的过拟合；此外理论分析基于连续时间假设，离散实现仍需经验调优。

---

## 401. A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits

**arXiv ID:** 2601.12945 | [PDF](https://arxiv.org/pdf/2601.12945v1)

**作者:** Miao Xie `[一作]` (China Agricultural University), Chunli Lv `[通讯]` (China Agricultural University)

**通讯引用:** 588 | [OpenAlex ID](https://openalex.org/A5077602137)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a2602d71-93ab-4bad-974b-672788df8193` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文综述了大型语言模型（LLM）与多臂老虎机（MAB）交叉领域的研究进展，提出了基于组件的分类框架，系统梳理了两者在训练、推理、个性化等阶段的双向交互与增益，并总结了挑战与未来方向。

**💡 创新点**

创新点在于：①首次从组件层面构建统一的LLM–Bandit交互分类体系；②系统化梳理并对比LLM增强Bandit、Bandit增强LLM的典型方法；③提出了多维度评估与研究热点，为后续跨域工作提供参考。

**🔧 技术方法**

采用的方法包括：综述与分类（文献检索、系统化框架构建）、案例归纳（LLM与Bandit技术结合实例）、实验评估（对比已有方法的性能指标）。

**📊 数据集**

使用的数据集与评估大多来自公开推荐、广告、对话等真实场景（如MovieLens、Yahoo! Front Page、OpenAI Gym等）以及合成的非平稳或鲁棒性模拟；LLM侧主要基于大型Transformer模型（GPT、PaLM、LLaMA等）与其在不同阶段的微调或对齐实现。

**📈 对比分析**

比较方法主要是对已有MAB与LLM方法的实验对照，关注累计奖励、回报、点击率、收敛速度等指标。总体来看，带入LLM的Bandit策略在多任务、动态环境下往往能显著降低探索成本、提升收敛速度与性能，但具体提升幅度依赖于任务与数据规模。

**⚠️ 局限性**

局限性包括：①评估多依赖手工设计的奖励与指标，缺乏统一的理论保证；②LLM调用会产生显著计算延迟，难以满足实时需求；③跨域泛化能力不足，受限于LLM先验与训练数据；④许多方法在非平稳或高维语义空间中的鲁棒性尚未得到充分验证。

---

## 402. On the Concavity of Tsallis Entropy along the Heat Flow

**arXiv ID:** 2601.12944 | [PDF](https://arxiv.org/pdf/2601.12944v1)

**作者:** Lukang Sun `[一作]` `[通讯]` (Technical University of Munich), Lukang Sun (Technical University of Munich)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

研究了Tsallis熵在热流过程中的二阶时间导数，证明在一维和多维下特定q值区间内该熵是凹函数。

**💡 创新点**

首次在多维情形下给出了关于Δu∇u/u项的精确估计，推导出新的功能不等式，并将其用于证明Tsallis熵的凹性。

**🔧 技术方法**

利用热方程的卷积解、严格的积分分部法、Bochner公式以及高阶导数估计和Cauchy–Schwarz不等式等分析技术。

**📊 数据集**

无数据集，完全是纯理论证明。

**📈 对比分析**

本工作没有与实验或数值方法比较，主要是数学证明，故无法给出性能指标；结果在理论上证明了所需区间内的凹性。

**⚠️ 局限性**

证明仅适用于q∈[1,3]（d=1）和q∈[1,2(√5+1)/√5]（d>1）以及δ∈[-1/√5+1,1]等区间，且尚未推广到过阻 Langevin 动力学等更一般情形。

---

## 403. Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design

**arXiv ID:** 2601.12939 | [PDF](https://arxiv.org/pdf/2601.12939v1)

**作者:** Kaleem Arshid `[一作]` (Carlos III University Madrid), Carlo Regazzoni `[通讯]` (University of Genoa)

**通讯引用:** 6824 | [OpenAlex ID](https://openalex.org/A5055281228)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `fa81e2aa-eb25-4aba-a919-7efd247b3885`

**🎯 论文内容**

提出基于主动推理的UAV群体轨迹设计框架，利用层次化符号世界模型实现任务分配、路径排序与运动规划。

**💡 创新点**

创新点在于将主动推理与层次符号字典相结合，通过最小化KL散度实现在线贝叶斯更新，兼具可解释性、可扩展性和自适应决策。

**🔧 技术方法**

采用GA–RF生成专家示例、层次符号词典（Mission/Route/Motion）与其概率模型、主动推理（KL散度最小化）以及EKF状态估计与碰撞规避。

**📊 数据集**

使用自建的 5000 个 GA–RF 任务实例数据集（每个包含 50 个随机目标），未使用公开数据集。

**📈 对比分析**

与同一数据集训练的改进 Q‑Learning 进行对比，仿真结果显示主动推理方案在任务完成时间、总距离和路径平滑度上均优于 Q‑Learning 与 GA–RF，收敛更快、稳定性更高。

**⚠️ 局限性**

局限在于仅在仿真环境验证，未给出实时计算复杂度分析；对动态障碍物的鲁棒性仍依赖 EKF 的预测，缺乏真实场景实验。

---

## 404. Dual-Stream Collaborative Transformer for Image Captioning

**arXiv ID:** 2601.12926 | [PDF](https://arxiv.org/pdf/2601.12926v1)

**作者:** Jun Wan `[一作]` (Zhongnan University of Economics and Law), Jie Zhou `[通讯]` (Shenzhen University)

**通讯引用:** 15304 | [OpenAlex ID](https://openalex.org/A5089926923)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种Dual‑Stream Collaborative Transformer（DSCT）模型，用于图像描述；

**💡 创新点**

创新点在于引入Pattern‑Specific Mutual Attention Encoder（PSMAE）对区域特征与分割特征进行双向互补融合，并通过Dynamic Nomination Decoder（DND）动态选取最合适的特征流生成每个词，从而绕过不同模式特征的语义不一致与空间失配问题；

**🔧 技术方法**

核心技术包括Transformer架构、Multi‑Head Attention、位置编码、层归一化、以及基于Gumbel‑Softmax的动态选择机制；

**📊 数据集**

使用MS‑COCO数据集进行训练与评估；

**📈 对比分析**

在COCO Karpathy测试集上与多种基线（Up‑Down、AoANet、M2 Transformer、X‑Transformer、DLCT、DIFNet等）对比，单模型CIDEr达137.6%，集成模型达139.3%，在BLEU、METEOR、ROUGE、SPICE等指标上均名列前茅；

**⚠️ 局限性**

限制方面包括对分割特征质量高度依赖、模型参数量较大、推理速度相对较慢，且在极少数样本中仍可能出现语义偏差或细节缺失。

---

## 405. Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs

**arXiv ID:** 2601.12921 | [PDF](https://arxiv.org/pdf/2601.12921v1)

**作者:** Adimulya Kartiyasa `[一作]` (Nanyang Technological University), Boyang Li `[通讯]` (Nanyang Technological University)

**通讯引用:** 5238 | [OpenAlex ID](https://openalex.org/A5100732747)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一个由151本印尼社会科学期刊文本构成的文化知识数据集，并在其中提取了关于印尼文化的事实句子；

**💡 创新点**

创新点在于利用本土社会科学期刊作为文化知识源，并提出一种基于LLM生成的假设文档作为检索查询的RAG策略；

**🔧 技术方法**

采用布局检测+文本提取、事实抽取、检索增强生成（RAG）以及LLM生成假设查询等技术；

**📊 数据集**

使用151本印尼开放获取社会科学期刊（约21,500份PDF）和印尼维基百科文本；

**📈 对比分析**

在IndoCulture基准上，RAG+事实检索模型达到79.3%准确率，结合维基百科后提升至81.4%，显著优于先前SOTA；

**⚠️ 局限性**

局限包括：数据来源仅限社会科学期刊，覆盖范围有限；检索仅依赖抽取的事实句子，可能忽略上下文；手工标注布局导致工作量大；模型仍可能存在文化偏差。

---

## 406. Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection

**arXiv ID:** 2601.12919 | [PDF](https://arxiv.org/pdf/2601.12919v1)

**作者:** Jun Wan `[一作]` (Zhongnan University of Economics and Law), Wenwen Min `[通讯]` (Yunnan University)

**通讯引用:** 534 | [OpenAlex ID](https://openalex.org/A5083513047)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

构建了一个弱监督框架 SHT，融合面部重建（hallucination）与姿态转移（pose transfer）两大模块，以提升低分辨率人脸关键点检测的精度。

**💡 创新点**

创新点包括：1) Dual Hallucination Learning Network (DHLN) 的双流设计，使面部重建与关键点热图相互促进；2) Facial Pose Transfer Network (FPTN) 用于在不影响推理阶段的前提下进一步细化重建结果；3) 通过引入梯度损失和无监督高分辨率图像实现弱监督学习，显著提升表情、姿态与遮挡下的鲁棒性。

**🔧 技术方法**

使用的技术包括：4 层堆叠式 Hourglass 网络、SRBlock（超分辨率块）、Fusion Block、梯度损失、对抗损失、感知损失（VGG19），以及基于热图的损失函数；整体模型在 PyTorch 上实现。

**📊 数据集**

实验数据集涵盖：CelebA、Helen、300W、AFLW、WFLW（用于 FLD 评估）以及 300VW、CelebA（用于无标注数据的弱监督增强）。

**📈 对比分析**

与现有 FLD 与人脸重建方法比较，SHT 在 PSNR、SSIM、NME、AUC 等指标上均超过最新技术；例如在 CelebA 上 PSNR 提升至 28.79dB、SSIM 0.8377、NME 0.1198；在 300W 关键点检测中，NME 下降至 2.78%。

**⚠️ 局限性**

局限性：1) DHLN 的两条流导致参数量略增，推理速度从 SHN 的 120 FPS 降至 80 FPS；2) 对极端姿态或遮挡仍有一定误差；3) 依赖大量高分辨率无标注图像进行弱监督，若无此类数据效果受限。

---

## 407. Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios

**arXiv ID:** 2601.12974 | [PDF](https://arxiv.org/pdf/2601.12974v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86`

---

## 408. Dynamic Hand Gesture Recognition for Robot Manipulator Tasks

**arXiv ID:** 2601.12918 | [PDF](https://arxiv.org/pdf/2601.12918v1)

**作者:** Dharmendra Sharma `[一作]` (Indian Institute of Technology Mandi), Laxmidhar Behera `[通讯]` (Indian Institute of Technology Mandi)

**通讯引用:** 5825 | [OpenAlex ID](https://openalex.org/A5065056581)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文提出了一种基于无监督高斯混合模型（GMM）的实时动态手势识别方法，用于控制机器人机械臂完成不同任务。

**💡 创新点**

创新点在于利用手势轨迹的关键点方差特征，结合GMM和EM算法实现无监督学习，既能处理动态变化，又避免了深度学习模型对大数据和长训练时间的依赖。

**🔧 技术方法**

技术包括RGB‑D相机采集、HOG3D特征提取、21个手部关键点方差计算、GMM参数估计、EM迭代、Silhouette分数评估和ROS实时控制。

**📊 数据集**

使用的数据集为80段5秒视频（每段150帧），覆盖四种手势（挥手、抓取、堆叠、推送），并在后续实时测试中收集了来自50位不同人的手势。

**📈 对比分析**

与现有基线方法相比，本方法在Silhouette分数上平均提升至约0.63‑0.64，实时检测时间约0.33 秒/帧，准确率达到94‑96%，显著优于先前的手势识别方案。

**⚠️ 局限性**

局限性包括仅支持单手单任务手势，无法处理多手或组合动作；模型对手势种类的可扩展性有限，且在背景极端干扰下的鲁棒性尚未充分验证。

---

## 409. CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction

**arXiv ID:** 2601.12917 | [PDF](https://arxiv.org/pdf/2601.12917v1)

**作者:** He Sun `[一作]` (University of Science and Technology of China), Mingjun Xiao `[通讯]` (University of Science and Technology of China)

**通讯引用:** 1738 | [OpenAlex ID](https://openalex.org/A5101838604)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出CooperLLM框架，结合云端BP与终端ZOO微调，实现LLM在移动端的低内存、快速收敛联邦微调；

**💡 创新点**

创新点：①云端提取梯度子空间生成指导扰动，校正终端ZOO梯度；②系统级Pipeline（SPC）与压缩控制（DTC）实现层级流水线与压缩，隐藏通信、降低内存；③仅传输标量损失而非梯度，进一步减轻通信负担；

**🔧 技术方法**

采用Zeroth-Order Optimization、梯度校正（ZGR）、BP、Federated Learning、INT4量化压缩、层级流水线与自适应压缩等技术；

**📊 数据集**

使用NLP数据集SST‑2、AGNEWS、20News、LongAlign，模型包括DistilBERT、ALBERT、BERT、RoBERTa以及Llama‑2‑7B；

**📈 对比分析**

与Full‑FT、BitFit、FedAdapter、FwdLLM四基线比较，CooperLLM在精度提升10–47个百分点，收敛速度提升8.8×，在Llama‑2‑7B上内存占用降低约86%，并保持或超过基线精度；

**⚠️ 局限性**

局限性：需要云端公共辅助数据；云端到边缘/终端的引导扰动传输受网络带宽限制；ZOO估计仍存在方差与偏差；调参（如α、压缩比例）复杂；在极低带宽或更大模型上的表现需进一步验证。

---

## 410. Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets

**arXiv ID:** 2601.12903 | [PDF](https://arxiv.org/pdf/2601.12903v1)

**作者:** Meng Liu `[一作]` (National University of Defense Technology), Xinwang Liu `[通讯]` (National University of Defense Technology)

**通讯引用:** 18974 | [OpenAlex ID](https://openalex.org/A5101727888)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `a2602d71-93ab-4bad-974b-672788df8193` `3f18e8e3-0266-457c-8567-9039b6d2394d` `9ce7179e-700c-4310-ac2b-91df50ded46e` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文研究并提出了时序图节点聚类（Temporal Graph Clustering, TGC）的任务与方法，构建了BenchTGC框架和一套新的时序图数据集，用于支持TGC的实验与评估。

**💡 创新点**

创新点包括：①首次将TGC定义为新的无监督任务；②提出三阶段（预处理、训练、聚类）的通用框架，并将传统聚类技术改造以适配交互序列的批处理；③基于公共数据缺陷，开发了9个大规模、具标签的时序图数据集（BenchTGC Datasets），从而解决了数据与技术的两大瓶颈。

**🔧 技术方法**

技术手段：使用深度图学习模型（HTNE、JODIE、MNCI、TREND、S2T）与改进的聚类损失（重构、分布对齐、对比、跨批校准、聚类缩放等）；特征预训练（如node2vec）和位置编码提升初始化特征；在BenchTGC框架中统一训练过程并添加可选模块；同时对大规模数据进行分批训练，实现时间-空间平衡。

**📊 数据集**

数据集：结合3个公开无标签、3个公开有标签的数据集以及自行构造的6个大规模时序图数据集（School、arXivAI/CS/Math/Phy/Large 等），最终形成9个Data4TGC数据集，覆盖从数百到百万级节点与边的规模。

**📈 对比分析**

实验对比：在9个数据集上与16个基线（K‑means、AE、DeepWalk、node2vec、GAE、DAEGC、MVGRL、SDCN、DFCN、SCGC、HTNE、JODIE、MNCI、TREND、S2T）进行评估。BenchTGC框架提升率约99%，在大规模数据集上获得最高的ARI、NMI、ACC、F1指标；静态方法在大规模时序图上频繁出现OOM，凸显TGC的优势。

**⚠️ 局限性**

limitations: 1) 目前仅针对离线、全图训练，缺少开放式流式与在线聚类方案；2) 聚类数K需要预先设定，未解决未知簇数与重叠簇问题；3) 仅在实验室环境下验证，真实实时应用（如推荐、异常检测）尚未深入探讨。

---

## 411. The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality

**arXiv ID:** 2601.12938 | [PDF](https://arxiv.org/pdf/2601.12938v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f`

---

## 412. Pardon? Evaluating Conversational Repair in Large Audio-Language Models

**arXiv ID:** 2601.12973 | [PDF](https://arxiv.org/pdf/2601.12973v1)

**作者:** Shuanghong Huang `[一作]` (Beijing Institute of Technology), Wenxuan Zhang `[通讯]` (Singapore University of Technology and Design)

**通讯引用:** 506 | [OpenAlex ID](https://openalex.org/A5100629634)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了修复意识评估框架，明确区分可答与不可答的语音输入，并评估大型音频语言模型在两种条件下的表现

**💡 创新点**

创新点在于引入语义-声学掩蔽协议生成可答/不可答对照样本，以及EAR（Evaluability Awareness and Repair）评分指标，非补偿性地同时衡量答案准确性与对不可答输入的对话修复行为

**🔧 技术方法**

利用语义-声学掩蔽（masking）、LLM‑as‑Judge评估、自动语音识别与词性标注等技术实现对话修复检测，并使用GPT‑4o做判定

**📊 数据集**

评估使用了两个公开的语音QA基准：What Do You Like? (WDYL) 和 SLUE‑SQA‑5，分别包含约1,000条可答/不可答的音频问答实例

**📈 对比分析**

与传统只评测答案准确度或鲁棒性的指标相比，EAR显示模型在答案准确性高的同时往往缺乏修复能力；实验结果表明大多数模型在可答条件下表现良好（C>70%），但在不可答条件下修复评分R普遍低，导致EAR整体较低；但具有修复意识的模型如DeSTA2.5‑Audio、Audio Flamingo 3、Gemini 2.5等在EAR上表现突出

**⚠️ 局限性**

局限在于仅考虑单轮问答、基于声学掩蔽产生的可控不可答样本，未覆盖多轮对话、其他类型语义欠缺或多模态交互等更广泛的真实语境

---

## 413. StyMam: A Mamba-Based Generator for Artistic Style Transfer

**arXiv ID:** 2601.12954 | [PDF](https://arxiv.org/pdf/2601.12954v1)

**作者:** Zhou Hong `[一作]` (Suqian University), Ao Ma `[通讯]` (JD.com)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种基于 Mamba 状态空间模型的 GAN 生成器 StyMam，用于无配对图像风格迁移，并结合残差双条带扫描机制与通道加权空间注意力模块，实现高质量、无伪影、结构保留的风格化图像。

**💡 创新点**

创新点包括：① 在生成器中引入 Mamba（SSM）以线性复杂度高效捕获长距离依赖；② 设计残差双条带扫描 Mamba 块（RDSMB）以专注捕获局部纹理；③ 提出通道加权空间注意力（CRSA）模块，用全局通道先验重加权后再建模空间相关，兼顾全局结构与细节；④ 通过双路径条带扫描（水平/垂直）简化扫描过程，降低计算量，提升推理速度。

**🔧 技术方法**

采用的技术包括：Mamba（SSM）与 S6 块、残差双条带扫描 Mamba 块、通道加权空间注意力（CRSA）、多尺度判别器、感知损失（VGG）与对抗损失、PyTorch+RTX 3090 训练框架。

**📊 数据集**

数据集主要为 WikiArt（Van Gogh、Cezanne、Peploe、Ukiyoe、Gauguin 等七个艺术风格集）以及 CycleGAN 提供的内容图像，推理时采用 DIV2K 512×512 作为内容图像；所有样本统一尺寸 256×256 进行训练。

**📈 对比分析**

与 CycleGAN、LSeSim、UNSB、LSAST、Artbank、SaMam 等现有 GAN/SD 风格迁移方法在 FID、用户偏好、欺骗度、推理时间四个维度进行对比。结果显示 StyMam 在 FID 方面最低（最接近真实艺术图像），用户偏好最高，欺骗度最高，且推理时间仅为 0.041 秒（比 SD 方法快 100 倍，基本保持 GAN 级别的速度），总体性能优于 SOTA。

**⚠️ 局限性**

局限性：① 仅在 256×256 训练、512×512 推理的实验中验证，对更高分辨率或极端风格的适应性未知；② 双条带扫描机制虽简化计算，但在某些复杂纹理上可能仍出现细节损失；③ 对模型超参数（如 α、λ_adv 等）敏感度未系统评估；④ 依赖大量风格样本，若风格集稀缺时效果可能下降。

---

## 414. Dependently-Typed AARA: A Non-Affine Approach for Resource Analysis of Higher-Order Programs

**arXiv ID:** 2601.12943 | [PDF](https://arxiv.org/pdf/2601.12943v1)

**作者:** Han Xu `[一作]` (Princeton University), Di Wang `[通讯]` (Peking University)

**通讯引用:** 14328 | [OpenAlex ID](https://openalex.org/A5100401436)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

本文提出了一种非仿射（non‑affine）的自动化均摊资源分析（AARA）风格的依赖类型系统，用于准确推理高阶函数程序的资源消耗。

**💡 创新点**

创新点在于：① 将资源潜能与类型完全解耦，用依赖箭头 [f₁]_x T₁ → [f₂]_y T₂ 表示潜能捕获的闭包；② 通过全局潜能上下文 Ω 处理存在量词，从而实现闭包捕获信息的可组合性；③ 在非仿射语义下保持 AARA 的自动化推理能力。

**🔧 技术方法**

主要技术包括：依赖类型系统、潜能函数的原始递归（primitive recursion）、成本感知小步语义、类型推导的约束求解以及基于最小/最大潜能的算法化类型检查。

**📊 数据集**

本文为理论性工作，并未使用具体数据集；所有示例均为手写的高阶函数与递归数据结构（如列表、树）。

**📈 对比分析**

与传统仿射 AARA 系统比较，本文证明了类型系统的安全性（soundness），并在若干经典高阶例子（append、traverse、map‑append）中展示了更精确、更可组合的资源边界推导；实验评估暂无，主要通过形式化证明与案例演示来体现性能优势。

**⚠️ 局限性**

局限性包括：① 资源潜能函数的推导仍需人工注解，推理自动化程度有限；② 类型推理总体不可判定，尤其在潜能函数的递归定义上；③ 对于更复杂的语言特性（如并发、引用）尚未扩展；④ 依赖外部算术求解器，求解复杂度可能较高。

---

## 415. Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy

**arXiv ID:** 2601.12922 | [PDF](https://arxiv.org/pdf/2601.12922v1)

**作者:** Johannes Kaiser `[一作]` (Technical University of Munich), Georgios Kaissis `[通讯]` (HPI)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文揭示了基于采样的个体差分隐私（iDP）机制存在的隐患：个体的隐私风险不仅由其自身的预算决定，还会受到其他所有数据贡献者预算分布的影响，并提出了在此框架下可行的预算操控与协同攻击。

**💡 创新点**

创新点在于①系统性地证明采样式 iDP 违反了“个体控制”承诺，并首次量化了“过度风险”与预算分布的关联；②提出两种攻击（预算操控攻击与协同攻击），在不违反 DP 约束的前提下显著提升目标样本的成员推断成功率；③引入 Δ‑divergence 概念，给出对过度风险的上限约束（-iDP）并提供可实现的机制设计路径。

**🔧 技术方法**

主要技术包括：采样式 iDP（基于 Poisson 采样的 DP‑SGD）、LiRA 成员推断攻击用于评估隐私得分、隐私配置的理论分析（隐私曲线、交叉优势），以及 Δ‑divergence 的计算与约束方法。

**📊 数据集**

实验使用了九个公开数据集：Credit Card Default、German Credit、MNIST、MNIST‑4/1000、UCI‑Isolet、CIFAR‑10、OrganCMNIST、OrganSMNIST、Pneumonia 与 HAM10k。每个数据集在采样式 iDP 与敏感度基 iDP 两种分配方案下进行对比。

**📈 对比分析**

与传统统一预算 DP‑SGD 相比，采样式 iDP 在满足个体 ε、δ 的前提下仍会产生可观的过度风险；攻击实验表明在 62% 的目标样本上，攻击能显著提升成员推断优势。敏感度基 iDP 在相同设置下过度风险仅为采样式的一半，说明过度风险与采样策略高度相关。Δ‑iDP 约束能将风险提升控制在可接受范围内，但可能牺牲一部分模型效能。

**⚠️ 局限性**

局限性包括：①攻击假设攻击者可控制或协同选择预算，实际部署中可能受限；②实验规模相对较小，未覆盖大规模模型或 LLM 场景；③LiRA 作为评估工具的分辨率有限，无法完全捕捉所有隐私损失；④Δ‑divergence 约束提供的是理论上限，具体实现与实际效果还需进一步验证。

---

## 416. Supervised Learning for Game Music Segmentation

**arXiv ID:** 2601.12961 | [PDF](https://arxiv.org/pdf/2601.12961v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876`

---

## 417. PlannerRFT: Reinforcing Diffusion Planners through Closed-Loop and Sample-Efficient Fine-Tuning

**arXiv ID:** 2601.12901 | [PDF](https://arxiv.org/pdf/2601.12901v1)

**作者:** Hongchen Li `[一作]` (Tongji University), Hongyang Li `[通讯]` (OpenDriveLab at The University of Hong Kong)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出一种闭环强化学习微调框架 PlannerRFT，用于提升扩散模型规划器的轨迹生成质量与安全性能。

**💡 创新点**

核心创新是将策略引导的去噪与探索策略相结合，形成多模态且情境自适应的采样机制，并通过 nuMax GPU 并行仿真实现高效样本收集与训练。

**🔧 技术方法**

技术实现包括扩散 Transformer 轨迹生成、能量导向去噪、Beta 分布探索策略、PPO 与 GRPO 组策略优化、5 步 DDIM 采样，以及基于 Waymax 的 nuMax GPU 仿真。

**📊 数据集**

实验使用 nuPlan 大规模真实驾驶数据集，构建 Fail、Lt90、All 等子集进行预训练与微调。

**📈 对比分析**

在 nuPlan Val14 与 Test14-hard 评测中，PlannerRFT 在大多数指标上均超过现有最优方法，尤其在难度场景中提升约 3–4 分，并且相较于 IL 预训练模型显著提升安全性与效率。

**⚠️ 局限性**

局限性在于仅验证于结构化抽象输入的规划器，尚未验证在基于图像或视觉感知的端到端视觉-运动控制器上的适用性。

---

## 418. Kd-tree Based Wasserstein Distance Approximation for High-Dimensional Data

**arXiv ID:** 2601.12975 | [PDF](https://arxiv.org/pdf/2601.12975v1)

**作者:** Kanata Teshigawara `[一作]` (Institute of Science Tokyo), Kazuhide Nakata `[通讯]` (Institute of Science Tokyo)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `64443552-63e0-44b5-906f-d90fe95c5a1b` `40105733-5154-44cd-8090-a8cab9e64b07` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了kd-Flowtree，一种基于kd树的Wasserstein距离近似方法，用于加速大规模最近邻检索。

**💡 创新点**

创新点在于用kd树替代传统的四叉树嵌入，使树能在高维空间深度足够，显著提升近似精度，同时保持低预处理时间。

**🔧 技术方法**

采用kd树构造、Flowtree算法求近似Wasserstein距离、概率误差分析以及对不同树深度的实验评估。

**📊 数据集**

使用三类文本数据集：20NEWS、Amazon（书籍、DVD、电子产品、厨房用品）和BBC（5个新闻板块），嵌入维度分别为50、100、200。

**📈 对比分析**

与Exact、Sinkhorn、Flowtree、1‑Greedy（聚类树与随机投影）等方法对比，kd‑Flowtree在Recall@k上往往接近或优于Sinkhorn，超过Flowtree，在总时间和预处理时间上与Flowtree相近甚至更快，1‑Greedy(C)预处理耗时最高。

**⚠️ 局限性**

局限在于理论误差仍受维度D影响，且kd‑Flowtree在极高维（如D=200）时精度略有下降；需要设定足够深的树深度以保证效果，过深时收益递减。

---

## 419. Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation

**arXiv ID:** 2601.12964 | [PDF](https://arxiv.org/pdf/2601.12964v1)

**作者:** John Waithaka `[一作]` (Carnegie Mellon University), Moise Busogi `[通讯]` (Carnegie Mellon University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究如何通过利用高分辨率卫星图像来辅助低分辨率图像的自监督预训练，从而提升低分辨率图像的语义分割性能。

**💡 创新点**

提出 Spatial Affinity Component：一个教师‑学生蒸馏模块，使用 Gram loss 将高分辨率图像的空间细节映射到低分辨率特征中，并且仅使用真实的高低分辨率配对数据而非下采样合成。

**🔧 技术方法**

采用自监督学习框架 I‑JEPA 与 LatentMIM，ViT‑Small 编码器，教师‑学生结构，Gram loss，双线性/双三次/线性投影下采样，以及块采样与随机采样对比。

**📊 数据集**

使用 Sen2Venus 数据集（Sentinel‑2 10 m 与 Venus 5 m 的真实配对），并在 Geo‑Bench 的 m‑cashew、m‑sa‑crop‑type、MADOS 三个语义分割基准上进行线性探测评估。

**📈 对比分析**

与仅使用高分辨率或仅使用低分辨率预训练的模型相比，加入 Spatial Affinity 的模型在三组基准上均取得更高 mIoU（提升约 1‑3 mIoU）；与使用插值合成高分辨率的对照模型对比，真实高分辨率的效果更好。

**⚠️ 局限性**

实验依赖高质量的高低分辨率配对数据，若无此类配对难以复现；仅在 ViT‑Small 架构下验证，其他模型的适用性待进一步探索；下采样方式对结果有一定影响。

---

## 420. GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation

**arXiv ID:** 2601.12948 | [PDF](https://arxiv.org/pdf/2601.12948v1)

**作者:** Riccardo Catalini `[一作]` (University of Modena and Reggio Emilia), Roberto Vezzani `[通讯]` (University of Modena and Reggio Emilia)

**通讯引用:** 2809 | [OpenAlex ID](https://openalex.org/A5081341599)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出一种基于扩散模型的单帧RGB图像3D注视估计方法，能够同时输出3D注视方向和人体3D姿态。

**💡 创新点**

创新点包括：①将3D注视视为附加关节点与人体骨骼共同建模；②利用扩散过程对不确定性进行建模，生成多种可行的3D注视与姿态假设；③将2D关节、主体周围信息、全景上下文及目标对象特征作为条件输入，显著提升估计精度。

**🔧 技术方法**

技术要点：扩散模型（DDIM）、HRNet 2D姿态估计、DETR式目标检测、Deformable Context Extraction、Transformer 自注意力模块、多假设聚合（平均和 oracle 方式）以及端到端训练。

**📊 数据集**

主要使用的公开数据集包括：GAFA（大规模监控场景3D注视+姿态）、GFIE（室内注视跟踪与深度信息）和新构建的 Ego‑Gaze（多模态人机交互场景），并在 Human3.6M 与 MPI‑INF‑3DHP 上评估姿态性能。

**📈 对比分析**

与多种基准（Gaze360、XGaze、GazeFollow、Lian 等）以及先前的基于时序、深度或面部特征的方法比较，本文在 MAE_3D、MAE_2D 等指标上均超过对手，甚至在仅用单帧RGB的情况下优于使用视频序列的时序模型。

**⚠️ 局限性**

局限性：①需要高质量的 2D 姿态与目标检测作为前置模块；②多假设聚合仍依赖 oracle 或额外算子，实际部署时仅能使用平均策略；③扩散模型推理时间相对较长，影响实时性能；④在极端遮挡或极端视角下，精度仍有提升空间。

---

## 421. On the Evidentiary Limits of Membership Inference for Copyright Auditing

**arXiv ID:** 2601.12937 | [PDF](https://arxiv.org/pdf/2601.12937v1)

**作者:** Murat Bilgehan Ertan `[一作]` (Centrum Wiskunde and Informatica), Marten van Dijk `[通讯]` (Vrije Universiteit Amsterdam)

**通讯引用:** 14171 | [OpenAlex ID](https://openalex.org/A5075756968)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `9cc9baba-5356-466d-81ff-d80028d90279` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

评估并挑战了现有的成员推断攻击（MIA）在版权审计中的可用性，验证其在语义保持的文本重写（SAGE）下的鲁棒性

**💡 创新点**

提出了结构感知稀疏自编码器引导的重写框架SAGE，并正式化了法庭三方沟通协议来定义审计证据的可靠性

**🔧 技术方法**

使用稀疏自编码器（SAE）生成语义相似度指示器、语义保留评分（SPS）、词汇相似度度量，并评估多种MIA（Loss、Zlib、Min‑K%等）

**📊 数据集**

在五个公开文本数据集（ArXiv、Wikipedia、Pile‑CC、PubMed、HackerNews）上进行实验，采用LLaMA‑3.2‑3B为目标模型，使用LoRA与全微调两种训练方式

**📈 对比分析**

通过AUC、TPR@1%FPR等指标对比原始、SAGE、SAGE‑R、SOFT及预训练模型，发现SAGE与SAGE‑R显著削弱MIA性能，实测AUC降至≈0.5-0.6，TPR在1%FPR下显著下降，同时下游任务保持或提升，证明重写能抑制表面语义泄露

**⚠️ 局限性**

限制在于MIA在全微调时仍保留一定泄露（AUC≈0.7-0.8），且研究仅针对文本领域；在高斯攻击或代码、图像等模态下结果可能不同；此外，仅评估了静态攻击，未覆盖自适应或多语义等更复杂情形

---

## 422. An efficient heuristic for geometric analysis of cell deformations

**arXiv ID:** 2601.12928 | [PDF](https://arxiv.org/pdf/2601.12928v1)

**作者:** Yaima Paz Soto `[一作]` (University of Guantánamo), Manuel González-Hidalgo `[通讯]` (University of the Balearic Islands)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `64443552-63e0-44b5-906f-d90fe95c5a1b` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出一种基于细胞主轴固定参数化并对圆形与椭圆模板匹配的红细胞形状空间距离计算方法，用于自动识别正常、镰刀形和其他变形红细胞。

**💡 创新点**

创新点在于用细胞主轴确定唯一参数化并先对两个模板进行对齐，从而省去所有重参数化的最小化搜索，显著降低计算复杂度同时保持甚至提升分类精度。

**🔧 技术方法**

采用形状空间（Grassmann 与 SRVF）中的弹性度量、固定参数化、模板匹配，结合 k‑NN、LDA、k‑medoid 等分类/聚类算法，并使用 Acc、SDS、F1 等指标评估。

**📊 数据集**

使用 erythrocytesIDB 数据集（202 正常细胞、210 镰刀细胞、211 其他变形细胞），并在此基础上进行实验与比较。

**📈 对比分析**

与传统需要遍历所有重参数化的形状空间方法以及多种现有基线（k‑NN、SVM、深度学习等）对比，实验显示准确率达 96.03%（S_2 空间），SDS 99.84%，计算成本从 O(N·k²) 降至 O(k²) 或 O(k)，性能优于或与现有最佳方法持平。

**⚠️ 局限性**

局限性包括：依赖圆形与椭圆模板，可能不适用于与这些模板差异较大的细胞形状；对轮廓提取质量敏感；数据集来源单一，缺乏不同人群和疾病类型的多样性，影响模型泛化能力。

---

## 423. Audit du syst{è}me d'information et du mod{è}le de gouvernance de la Biblioth{è}que Num{é}rique de l'Espace universitaire Francophone (BNEUF) du projet Initiative pour le D{é}veloppement du Num{é}rique dans l'Espace Universitaire Francophone (IDNEUF)

**arXiv ID:** 2601.12902 | [PDF](https://arxiv.org/pdf/2601.12902v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `f53a5690-f5d8-493f-989c-dc46a1f99053`

---

## 424. Actionable Interpretability Must Be Defined in Terms of Symmetries

**arXiv ID:** 2601.12913 | [PDF](https://arxiv.org/pdf/2601.12913v1)

**作者:** Pietro Barbiero `[一作]` (IBM Research), Giuseppe Marra `[通讯]` (KU Leuven)

**通讯引用:** 493 | [OpenAlex ID](https://openalex.org/A5005466305)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534`

**🎯 论文内容**

提出了一套以对称性为核心的可解释性定义框架，认为可解释模型必须满足四种对称性

**💡 创新点**

创新点在于将推理等变性、信息不变性、概念闭合不变性和结构不变性四个对称性统一为可解释性的四大原理，并用它们推导出可解释模型的性质与推断方法

**🔧 技术方法**

主要技术包括概率马尔可夫类别、范畴理论、贝叶斯逆推与字符串图（string diagram）可视化，用于构造和分析可解释模型

**📊 数据集**

论文未使用具体数据集，整体为理论性框架性工作

**📈 对比分析**

通过理论推导与示例展示了该框架如何比传统可解释方法更系统地实现概念对齐、干预与反事实推理，强调了统一性与可扩展性

**⚠️ 局限性**

局限在于缺乏实验验证，需进一步证明对称性完整性与实际应用中的可行性

---

## 425. Human Emotion Verification by Action Languages via Answer Set Programming

**arXiv ID:** 2601.12912 | [PDF](https://arxiv.org/pdf/2601.12912v1)

**作者:** Andreas Brännström `[一作]` (Umeå University), Juan Carlos Nieves `[通讯]` (Umeå University)

**通讯引用:** 1036 | [OpenAlex ID](https://openalex.org/A5045363362)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

**🎯 论文内容**

提出了新的动作语言 C‑MT，用于在回答集规划（ASP）框架下对人类心理状态（尤其是情绪）随可观察动作的演化进行形式化建模，并通过“禁止导致”规则限制不希望出现的心理状态转移，随后将其应用于情绪验证任务，比较不同情绪理论（如玫瑰曼评估理论、幸福情绪调节、功利情绪调节）的动态行为。

**💡 创新点**

创新点包括：① 在动作语言中首次引入“禁止导致”规则，使得可以在无动作触发的情况下直接约束心理状态的转移；② 将心理状态表述为多维配置并通过情绪理论映射为贝尔福图（Belief Graph）；③ 通过ASP实现动态演化的可验证性，兼顾了理论可解释性和计算可行性。

**🔧 技术方法**

使用技术主要有：动作语言（C‑MT）与ASP的语义对应；转移系统与轨迹（trajectory）理论；逻辑程序的编码与答案集求解；形式化安全性分析（不变性、贝尔福图约束）。

**📊 数据集**

实验与验证基于理论情绪状态空间：根据玫瑰曼评估理论构造了 108 个（含 16 个基本情绪）心理状态组合，并在此空间上定义 HER 与 UER 的约束；并未使用公开数据集，而是利用这些理论状态进行离散化建模与仿真。

**📈 对比分析**

比较方法：在相同的 C‑MT 领域描述下，分别加入 HER 或 UER 的 forbids‑to‑cause 规则，生成两组轨迹；通过形式化证明验证不变性（情绪平衡或功利性）在所有轨迹中保持；实验结果展示两种约束导致的轨迹差异（例如 HER 禁止负面情绪出现，UER 允许短期负面以实现长期目标）。性能方面，利用 ASP 求解器可在数秒内完成典型轨迹搜索，证明方法可扩展但在状态空间指数级增长时仍受限。

**⚠️ 局限性**

局限性：① 仅在离散化的理论状态空间中验证，缺乏大规模真实用户交互数据的评估；② 需要专家为每种情绪理论手工编码约束，缺乏自动化推理；③ 随着心理状态维度和动作组合的增加，ASP 求解的复杂度急剧上升，尚未提出可扩展的优化策略。

---

## 426. SciCoQA: Quality Assurance for Scientific Paper--Code Alignment

**arXiv ID:** 2601.12910 | [PDF](https://arxiv.org/pdf/2601.12910v1)

**作者:** Tim Baumgärtner `[一作]` (Ubiquitous Knowledge Processing Lab), Iryna Gurevych `[通讯]` (Ubiquitous Knowledge Processing Lab)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一个包含 611 条科研论文与代码实现之间不一致的数据集，并在该数据集上评估多种 LLM 的检测性能。

**💡 创新点**

提出了跨学科的合成差异生成方法、差异类型与类别细分框架，以及基于 LLM 的自动化评估流程。

**🔧 技术方法**

采用 LLM 推理、自动差异生成、LLM‑as‑a‑Judge 评估等技术，结合 GPT‑5、Gemini、GPT‑OSS 等模型进行实验。

**📊 数据集**

数据集来源于 GitHub issue、重现论文以及通过 GPT‑5 生成的合成代码差异，共 81 条真实差异和 530 条合成差异。

**📈 对比分析**

对 21 种 LLM 进行评估，最佳模型 GPT‑5 在真实差异上的召回率仅为 45.7%，在合成差异上为 71.3%，显示出显著的性能瓶颈。

**⚠️ 局限性**

局限性包括数据集主要偏向 CS/AI 领域、差异定义排除了简单 bug 与配置问题、样本规模相对较小，导致模型泛化受限。

---

## 427. Supervised Learning for the (s,S) Inventory Model with General Interarrival Demands and General Lead Times

**arXiv ID:** 2601.12900 | [PDF](https://arxiv.org/pdf/2601.12900v1)

**作者:** Eliran Sherzer `[一作]` (Ariel University), Yonit Barron `[通讯]` (Ariel University)

**通讯引用:** 424 | [OpenAlex ID](https://openalex.org/A5064804228)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

通过构建监督学习框架，用神经网络快速预测非马尔可夫 (s,S) 库存系统的稳态库存分布、周期时间和缺货概率，从而替代耗时的仿真。

**💡 创新点**

创新点包括：①将大规模仿真标签与神经网络相结合；②使用 Phase‑Type 分布采样生成多样化输入，并证明仅前5阶矩即可获得高精度；③设计支持约束的分布预测网络，使模型易于推广到其他库存政策。

**🔧 技术方法**

技术手段包括：Phase‑Type 分布采样、离散事件仿真、全连接前馈神经网络（NN1预测分布、NN2预测周期、NN3预测缺货概率）、ReLU、Softmax、Sigmoid、对输入矩进行对数变换与标准化。

**📊 数据集**

数据集：250 万训练实例、5 万验证实例、4.8 万测试实例。测试集按 SCV、s、S、ρ 等 32 组划分，输入为需求间隔与交付时间的前 5 阶矩及阈值 s、S。

**📈 对比分析**

与仿真结果对比，SAE<0.03、相对误差 RE<1%、绝对误差 AE<0.02；1000 个实例的推断时间仅 0.015 秒，远快于 0.42 小时的仿真；在不同参数区间内保持低误差，证明方法稳健且高效。

**⚠️ 局限性**

局限性：①仅利用前 5 阶矩，可能无法捕捉极端分布特征；②在高 SCV 或大 S 情况下误差略增；③需要先进行大规模仿真生成标签，无法直接解释模型；④对不同库存策略需重新训练。

---

## 428. LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System

**arXiv ID:** 2601.13096 | [PDF](https://arxiv.org/pdf/2601.13096v1)

**作者:** Muhayy Ud Din `[一作]`, Irfan Hussain `[通讯]`

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了一套基于大型语言模型（LLM）和视觉语言模型（VLM）融合的异构UAV-USV系统，用于海港设施的自主检测与报告生成。

**💡 创新点**

创新点在于将LLM作为高层符号任务规划器，自动将自然语言指令转化为满足安全约束的依赖图；同时利用轻量级VLM实现实时语义感知与结构化合规报告，突破传统规则机和单一视觉检测方法的可扩展性与语义深度。

**🔧 技术方法**

核心技术包括：GPT‑4o/ GPT‑4/ GPT‑3.5‑Turbo 等LLM用于生成符号计划；SmolVLM、Florence‑2、Moondream2、Qwen2‑VL 等轻量级VLM用于多模态推理；ROS2/ NAV2/A* 进行路径规划；PID/滑模控制实现UAV/USV轨迹跟踪；依赖图调度实现并行任务执行。

**📊 数据集**

数据集主要来源于 MBZIRC 海事模拟器（包含真实港口布局、动态船舶、码头、起重机等）以及现场采集的UAV/USV 摄像流，二者共同构成训练/评估的模拟与实地场景。

**📈 对比分析**

对比方法：在多任务场景下分别评估不同 LLM 的计划正确率、执行成功率和响应时间；评估各 VLM 的语义正确率（SC）与推理时延。结果显示 GPT‑4o 在计划上达 94% 正确率、85% 成功率、<9 s 响应；VLM 中 Qwen2‑VL 与 Moondream2 的 SC 均超过 80%，时延 0.3–0.6 s；SmolVLM、Florence‑2 及 GIT‑base 在实地环境下性能显著下降。

**⚠️ 局限性**

主要局限包括：LLM 调度与执行需依赖云端或高性能设备，实时性受网络延迟影响；轻量 VLM 在复杂场景下仍出现误检/漏检；模型推理仍需消耗显存，未完成在资源极限海上平台上的完全离线部署；缺乏大规模真实海港长时间持续验证。

---

## 429. CPU-less parallel execution of lambda calculus in digital logic

**arXiv ID:** 2601.13040 | [PDF](https://arxiv.org/pdf/2601.13040v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62`

---

## 430. Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups

**arXiv ID:** 2601.13094 | [PDF](https://arxiv.org/pdf/2601.13094v1)

**作者:** Gelei Xu `[一作]` (University of Notre Dame), Yiyu Shi `[通讯]` (University of Notre Dame)

**通讯引用:** 5130 | [OpenAlex ID](https://openalex.org/A5000141831)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `e15e3743-5ee0-4d5f-813d-d146868082fc` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

提出 HyperAdapt 框架，利用患者属性编码生成残差偏置，实现共享骨干网络的子组适配。

**💡 创新点**

将低秩共享参数的 hypernetwork 与通道级调制相结合，既保持预训练知识，又实现高效、可解释的患者条件适配。

**🔧 技术方法**

使用低秩分解、通道级特征调制、共享生成块、hypernetwork 生成残差偏置、嵌入层处理连续/离散属性等技术。

**📊 数据集**

在 Fitzpatrick‑17k、ODIR‑5k、PAD‑UFES‑20 三个医学影像数据集上进行实验。

**📈 对比分析**

与 FairAdaBN、FairQuantize、GroupModel、GroupAdapt、DAFT、HEAL 等基线比较，HyperAdapt 在整体精度、召回率、F1 等指标上均表现更优，且对弱势子组提升更显著。

**⚠️ 局限性**

对高维连续属性的可解释性仍有限；在极度稀缺子组样本时可能出现过拟合；需在更广泛的多模态数据集上进一步验证。

---

## 431. What's it like to be a chat? On the co-simulation of artificial minds in human-AI conversations

**arXiv ID:** 2601.13081 | [PDF](https://arxiv.org/pdf/2601.13081v1)

**作者:** Geoff Keeling `[一作]` (Institute of Philosophy School of Advanced Study University of London), Winnie Street `[通讯]` (Institute of Philosophy School of Advanced Study University of London)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并论证了“角色共模拟”视角，认为 LLM 生成的角色是共建的、具有心智和心理连续性的实体；

**💡 创新点**

创新点在于将角色的存在从传统的“幻觉”框架转为“共模拟”现实性，借鉴认知心理学与游戏角色模拟的类比，提出角色是共享工作空间中的“真实模式”；

**🔧 技术方法**

主要使用概念分析、对 LLM 架构（MoE、多实例）和人机交互中的理论心理学机制的探讨，阐释共同建模与错误信号的动态过程；

**📊 数据集**

未采用传统数据集，而是以概念性案例（如 D&D 玩家角色、电影《荒岛余生》中的威尔逊）和 LLM 聊天日志为思辨依据；

**📈 对比分析**

通过哲学论证与类比对比（幻觉主义 vs 现实主义）来检验论点，未给出量化实验，评价基于逻辑一致性与预测效率；

**⚠️ 局限性**

局限在于缺乏经验验证与量化指标，对意识与主体性假设仍未解决，且共模拟模型对实际 LLM 部署的可行性尚未测试。

---

## 432. Analysis of Long Range Dependency Understanding in State Space Models

**arXiv ID:** 2601.13048 | [PDF](https://arxiv.org/pdf/2601.13048v1)

**作者:** Srividya Ravikumar `[一作]` (TU Darmstadt), Mira Mezini `[通讯]` (Hessian Center for Artificial Intelligence)

**通讯引用:** 8346 | [OpenAlex ID](https://openalex.org/A5078067853)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

对S4D模型在源码漏洞检测任务中的核行为进行时域和频域可解释性分析，并比较不同S4D与CNN混合架构的性能。

**💡 创新点**

首次系统性研究S4D核的时频特性，揭示不同架构导致低通/带通/高通滤波行为，并证明SMR+S4D低通特性提升长程依赖与性能。

**🔧 技术方法**

采用时域脉冲响应与FFT频谱分析，计算功率谱密度、峰值频率、频谱熵等指标，并在单层CNN+S4D等模型上实现。

**📊 数据集**

使用真实漏洞检测基准ReVeal，涵盖Linux Debian内核与Chromium源代码共22,734个函数。

**📈 对比分析**

通过准确率、精确率、召回率和F1分数四指标比较六种模型，SMR+S4D在F1上最高达88.03%，优于单独CNN或S4D。

**⚠️ 局限性**

仅使用单层模型与单一任务，缺乏多层深度或多任务验证，且未考虑模型训练时间和泛化到其他代码域的鲁棒性。

---

## 433. SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification

**arXiv ID:** 2601.13035 | [PDF](https://arxiv.org/pdf/2601.13035v1)

**作者:** Xu Xiaodan `[一作]`, Hu Xiaolin `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出一种基于分离注意力机制和语义感知对比学习的三元组分类框架SASA，以提升知识图谱中三元组有效性判断的准确率。

**💡 创新点**

创新点在于：①设计分离注意力机制，将头-关系和尾实体分别编码后进行更灵活的交互；②引入层次化的语义感知对比学习，既包含局部级别的dropout增强正样本，又利用大模型检索的硬负样本进行全局级别对比。

**🔧 技术方法**

采用BERT双塔编码器、分离注意力模块、局部/全局对比学习任务以及二分类交叉熵损失共同训练。

**📊 数据集**

使用FB15k‑237和YAGO3‑10两大公共知识图谱数据集，并利用对应的实体描述文本进行训练。

**📈 对比分析**

相较于TransE、KG‑BERT、StAR和Confidence‑Based等基线，SASA在两个数据集上都实现了显著提升，FB15k‑237准确率从0.907提升至0.966（+5.9%），YAGO3‑10从0.932提升至0.966（+3.4%）。

**⚠️ 局限性**

局限性包括：①仍未充分利用图结构信息；②对硬负样本的检索依赖大模型，计算成本较高；③对不同关系类别的泛化能力仍有提升空间。

---

## 434. Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses

**arXiv ID:** 2601.13024 | [PDF](https://arxiv.org/pdf/2601.13024v1)

**作者:** Chongyuan Dai `[一作]` (Hefei University of Technology), Zongyuan Ge `[通讯]` (Monash University)

**通讯引用:** 11197 | [OpenAlex ID](https://openalex.org/A5005014252)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并构建了名为 CEDAR 的多模态跨文化情感对齐基准，用7种语言共10962个实例涵盖14种细粒度情感。

**💡 创新点**

创新地聚焦情感响应在不同文化背景下的差异，使用LLM筛选文化差异场景并通过人工注释获得真实文化标签，首次系统评估多模态LLM的文化情感一致性。

**🔧 技术方法**

采用大语言模型生成候选标签、文本与图像生成、语义聚类、Russell圆形模型过滤、跨语言一致性与差异过滤以及人类审核等技术。

**📊 数据集**

构建自有数据集 CEDAR，来源包括公开文化语料、ArabCulture、JETHICS、Google/Baidu 图像等，并通过翻译与人类验证得到7种语言版。

**📈 对比分析**

对17个多语言/多模态LLM（8B-1T）在文本和图像两子集上进行准确率、情感倾向、Russell四象限偏差等指标评估，发现多模态性能低于文本，亚洲/低资源语言表现差，语言一致性并不提升文化匹配，模型在高激活情感偏好。

**⚠️ 局限性**

受限于仅7种语言、资源有限导致样本规模与文化深度受限；仅用14分类情感与Russell模型混合；注释仅覆盖高共识场景，难以覆盖更细微文化差异。

---

## 435. ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs

**arXiv ID:** 2601.13007 | [PDF](https://arxiv.org/pdf/2601.13007v1)

**作者:** Rusheng Pan `[一作]`, Zhenhua Ling `[通讯]`

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

通过ArchAgent框架结合静态分析、代码分块与LLM合成技术，从跨仓库的大型遗留代码库中恢复业务对齐的多视图架构图

**💡 创新点**

1) 可扩展的代码分块与上下文裁剪，支持百万级代码的LLM处理；2) 融合跨仓库依赖上下文，自动识别并突出业务关键模块；3) 生成Mermaid语法的完整架构图，兼具可视化与可编辑性

**🔧 技术方法**

静态分析、文件聚类与上下文索引、LLM语义摘要与生成（如Qwen3、Llama3）、Mermaid图表生成、上下文检索与跨仓库关联机制

**📊 数据集**

八个大型生产级GitHub项目（1k–22k源文件，Go、Java、C/C++、Python、YAML），配有公开的架构图与文档，公开于 https://github.com/panrusheng/arch-eval-benchmark

**📈 对比分析**

与DeepWiki在同一数据集上比较，ArchAgent平均F1为0.966（σ=0.025），DeepWiki为0.860（σ=0.067），差异显著；依赖上下文消融实验表明加入上下文可将F1提升约0.11（Qwen3）或0.07（Llama3），并在案例研究中几乎完整覆盖业务核心模块

**⚠️ 局限性**

仍受LLM上下文窗口限制，需分块处理；对极大规模或极其复杂项目的可扩展性尚未充分验证；实验评估主要基于人工标注，缺乏自动化验证机制

---

## 436. Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models

**arXiv ID:** 2601.12995 | [PDF](https://arxiv.org/pdf/2601.12995v1)

**作者:** Runxuan Liu `[一作]` (Harbin Institute of Technology), Bing Qin `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 15641 | [OpenAlex ID](https://openalex.org/A5017671620)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出图推理范式（GRP），让大型语言模型把推理过程以图结构形式表示，并基于此构建过程感知分层剪切奖励强化学习框架（PASC-GRPO），显著提升推理质量。

**💡 创新点**

创新点包括：①将推理转为步骤级认知标签的图结构；②设计多维图结构奖励与过程感知奖励；③提出分层剪切优势估计（SCAE）以防止奖励劫持。

**🔧 技术方法**

主要技术手段包括监督微调（SFT）、强化学习（GRPO+PASC）、图结构奖励设计、网络X图构建、步骤级认知标签、分层剪切优势估计。

**📊 数据集**

使用数据集：40.3k 结构化数学推理链、12k 结构化代码生成链；评测基准包括 GSM8K、MATH500、AMC23、AIME24/25、MBPP、HumanEval、LiveCodeBench 等。

**📈 对比分析**

在与 LLaMA‑3.1、Gemma‑3 等开源 LLM 的对比中，本文模型在竞赛级数学与高难度代码生成基准上提升 10%+，在 AIME24/25 上提高约 7%+，同时显著缩短推理长度。

**⚠️ 局限性**

局限性：仅在逻辑推理与代码生成任务验证，普适性尚待进一步探索；模型规模局限于 4B/8B，未探讨更大模型的扩展；图拓扑生成仍使用固定认知标签，缺乏动态适应机制。

---

## 437. AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection

**arXiv ID:** 2601.12994 | [PDF](https://arxiv.org/pdf/2601.12994v1)

**作者:** Shiming Wang `[一作]` (Delft University of Technology), Julian F. P. Kooij `[通讯]` (Delft University of Technology)

**通讯引用:** 1706 | [OpenAlex ID](https://openalex.org/A5074902093)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出 AsyncBEV 模块，用于提升多模态3D目标检测在传感器异步情况下的鲁棒性。

**💡 创新点**

创新点在于引入 Δ-BEVFlow 任务，基于已知时间偏移预测 BEV 空间流量，并将其与 ego‑motion 补偿结合，实现轻量化、可插拔的异步对齐。

**🔧 技术方法**

技术包括基于 BEV 特征的流估计（运动式与速度式两种实现）、SimpleBEV 生成图像 BEV、针对 token‑grid 结构的 warper、以及可选的流监督损失。

**📊 数据集**

使用 nuScenes 数据集进行训练与评估，并在其多模态（摄像头+激光雷达）场景下测试。

**📈 对比分析**

与基线（原始、EMC、数据增强、StreamingFlow 等）对比，AsyncBEV 在 0.5 s 时延下，CMT 与 UniBEV 的 NDS 提升 16.6% 与 11.9%，动态目标 NDS 提升 16.6% 与 11.9%，性能显著优于其他方法。

**⚠️ 局限性**

局限在仅考虑两种传感器且假设其中一个始终同步，未覆盖多传感器同时异步及雷达等其他模态的场景。

---

## 438. Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization

**arXiv ID:** 2601.12993 | [PDF](https://arxiv.org/pdf/2601.12993v1)

**作者:** Hao Luo `[一作]`, Zongqing Lu `[通讯]`

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

研发一种跨体态的 Vision‑Language‑Action 模型 Being‑H0.5，利用统一动作空间和人类中心预训练，在大规模多体态数据上实现高效通用机器人控制。

**💡 创新点**

①将人类手部运动视为通用“母语”并构建统一动作空间；②提出 Mixture‑of‑Flow、Manifold‑Preserving Gating 与 Universal Async Chunking 等机制以支持跨体态流式控制；③构建 UniHand‑2.0 大规模人机混合数据集。

**🔧 技术方法**

多模态序列建模、Mixture‑of‑Transformers、流匹配 Diffusion、动作量化与离散掩码预测、Manifold‑Preserving Gating、Universal Async Chunking 以及实时双线程控制等技术。

**📊 数据集**

使用 UniHand‑2.0（35k 小时人机交互、14k 小时机器人、5k 小时视觉‑语言），覆盖 30 种机器人本体；还使用 LIBERO、RoboCasa 等仿真 benchmark，以及 Ego4D、EPIC‑KITCHENS 等公开视频库。

**📈 对比分析**

在 10 种真实机器人平台上与 π_0.5 等基线对比，专属模型仅差少量；在 LIBERO 取得 98.9% 成功率、RoboCasa 53.9% 成功率，首次实现跨体态零样本转移并取得非零成功率。

**⚠️ 局限性**

仍受限于动作空间离散化误差、对极高 DoF 机器人精细控制不足、需要大量人类视频数据；跨体态时延迟与噪声仍可能导致执行漂移，低样本适配效果仍有限。

---

## 439. PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient

**arXiv ID:** 2601.12988 | [PDF](https://arxiv.org/pdf/2601.12988v1)

**作者:** Zijian Wang `[一作]`, Kai Yu `[通讯]` (X-LANCE Lab)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 PaperGuide 框架，使用小型 LLM 通过先生成高层计划（draft）再细粒度执行，显著提高科学论文问答的交互效率。

**💡 创新点**

创新点在于将高层规划与低层执行分离，提出 Draft‑and‑Follow 结构，并设计专门的 Draft‑and‑Follow Policy Optimization（DFPO）算法，解决 LLM 的“knowing‑doing” 问题。

**🔧 技术方法**

技术手段包括：ReAct 风格工具调用、对话式强化学习（多轮 GRPO）、DFPO（联合优化草稿与解答）、Draft & Tool‑Use Fine‑Tuning（DTFT）以及负样本屏蔽与奖励路由器。

**📊 数据集**

使用的主要数据集为 AirQA‑Real 与 SciDQA 两大科研论文问答基准，且通过自建的 10k arXiv 论文生成的 synthetic 训练集进行预训练。

**📈 对比分析**

与传统 Prompting+RAG、SFT‑RL（M‑GRPO、DAPO）以及更大模型（GPT‑4o‑mini、VLLM‑72B）对比，PaperGuide 在 3B/7B 模型上保持或超过准确率，同时在 I‑Avg 交互效率上提升 3–5%，尤其在 7B 版超过 GPT‑4o‑mini 的性能。

**⚠️ 局限性**

局限性主要包括：对深层语义理解仍依赖模型规模，DFPO 需要较多的强化学习样本且训练成本高；当前仅在两大基准上验证，跨领域推广仍待进一步实验。

---

## 440. Rules, Resources, and Restrictions: A Taxonomy of Task-Based Information Request Intents

**arXiv ID:** 2601.12985 | [PDF](https://arxiv.org/pdf/2601.12985v1)

**作者:** Melanie A. Kilian `[一作]` (University of Regensburg), David Elsweiler `[通讯]` (University of Regensburg)

**通讯引用:** 2073 | [OpenAlex ID](https://openalex.org/A5041921674)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

基于机场信息台工作人员的访谈，构建了一个四层、20个一级和86个子类的任务型信息请求意图分类体系；

**💡 创新点**

创新点在于将任务视角融入意图分类，弥补了传统日志基分类缺乏任务语境的缺陷，并提出了面向AI驱动任务导向搜索的通用意图框架；

**🔧 技术方法**

采用扎根理论（Grounded Theory）访谈与编码方法（开放、轴向、选择编码），并借助ChatGPT辅助验证和细化分类；

**📊 数据集**

使用了来自8名机场信息台工作人员共计约720条信息请求的访谈数据，研究样本涵盖120年工作经验；

**📈 对比分析**

通过随机抽取147条问句交由外部评估者分类，计算Cohen κ=0.84（95% CI [0.78,0.91]），显示分类的一致性和可解释性高；

**⚠️ 局限性**

限制包括：数据仅来源于机场信息台互动，缺乏在线搜索情境；专家回顾性访谈可能存在记忆偏差；未充分覆盖任务的客观信息需求与跨领域验证。

---

## 441. ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation

**arXiv ID:** 2601.12983 | [PDF](https://arxiv.org/pdf/2601.12983v1)

**作者:** Jesus-German Ortiz-Barajas `[一作]` (INSAIT), Iryna Gurevych `[通讯]` (Ubiquitous Knowledge Processing Lab)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6215c339-3735-4be3-8a07-5bbb7004712d` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文研究了如何利用多模态大型语言模型（MLLM）自动生成误导性图表，并提出了ChartAttack框架以及对应的AttackViz数据集。

**💡 创新点**

创新点在于首次系统化构建误导性图表攻击框架和可复现的数据集，并通过实验展示了此类误导对MLLM和人类的显著影响。

**🔧 技术方法**

主要技术包括指令调优的MLLM、SBERT检索示例、误导生成模块、Matplotlib规则系统，以及基于Relaxed accuracy和Deception rate 的评估指标。

**📊 数据集**

数据集方面，论文以PlotQA为基础生成AttackViz，并将其扩展到ChartQA做跨域评估。

**📈 对比分析**

在正确图表与误导图表两种情境下对多款MLLM进行ChartQA评估，平均误导导致域内准确率下降19.6个百分点、跨域下降14.9个百分点；人类实验中准确率亦下降约20.2个百分点。

**⚠️ 局限性**

局限性包括仅覆盖三种图表类型、仅考虑设计误导而非推理误导、数据集构建依赖特定模型、实验规模有限等。

---

## 442. RM -RF: Reward Model for Run-Free Unit Test Evaluation

**arXiv ID:** 2601.13097 | [PDF](https://arxiv.org/pdf/2601.13097v1)

**作者:** Elena Bruches `[一作]` (Siberian Neuronets LLC), Stanislav Moiseev `[通讯]` (T-Technologies)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种轻量级奖励模型RM‑RF，用于在不编译运行的前提下预测自动生成的单元测试是否成功编译、是否提升代码覆盖率、是否提升突变杀死率，并构建了多语言（Java、Python、Go）的训练、验证与 hold‑out 数据集；

**💡 创新点**

创新点在于：①将单元测试评估拆分为三目标（编译成功、覆盖提升、突变提升）并直接从源代码和测试代码预测；②提出无执行的“跑不跑”奖励模型；③同时对全参数微调（SFT）和参数高效微调（LoRA）进行系统对比；④提供公开的数据集与评估方法。

**🔧 技术方法**

技术栈包括预训练大型语言模型（Qwen、Codestral 等），利用 Swift 框架进行 SFT、LoRA 微调，使用 vLLM 进行高效推理；覆盖率与突变率计算依赖 Python coverage、Java Jacoco、Go cover 等工具；模型输入采用 YAML 定义的验证目标，输出为三位布尔指标。

**📊 数据集**

数据集为约 22,285 条样本，按语言分布（Java、Python、Go）并划分为训练、验证和 hold‑out；样本来源于公开开源仓库，包含人类编写与 LLM 生成的测试，目标标签由执行管道（编译、覆盖、突变）得到。

**📈 对比分析**

与传统编译+运行评估相比，RM‑RF 的 Spearman 相关系数在三语言上分别为 0.79、0.91、0.89，整体 0.86，平均 F1 分数为 0.69；在验证集上 7B SFT 模型优于 14B LoRA，且跨语言性能稳定。

**⚠️ 局限性**

局限性包括：仅覆盖三种语言、未对单语种模型进行专门微调、未在 RL 循环中验证其作为奖励信号的效果、可能存在公开代码的泄露风险、以及模型对复杂错误类型的识别仍有待提升。

---

## 443. Two-timescale Optimization for Hybrid Mechanically and Electronically Tunable 6DMA Aided Communication

**arXiv ID:** 2601.13064 | [PDF](https://arxiv.org/pdf/2601.13064v1)

**作者:** Yuyan Zhou `[一作]` (Chinese University of Hong Kong), Rui Zhang `[通讯]` (National University of Singapore)

**通讯引用:** 100573 | [OpenAlex ID](https://openalex.org/A5100422102)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种混合机械和电子可调的六维可移动天线（HMET‑6DMA）基站架构，并通过两时标优化联合设计阵列位置和辐射模式以提升平均用户速率。

**💡 创新点**

创新点在于首次将机械位置调节与电子模式切换协同利用，并采用长时标（统计用户分布）和短时标（瞬时用户位置）双层优化，实现既具宽角覆盖又具快速响应的天线自适应。

**🔧 技术方法**

使用两时标块坐标上升算法、Monte Carlo抽样、梯度投影与贪婪搜索技术，结合PRAs的多模式辐射和圆形轨道机械移动实现方案实现。

**📊 数据集**

数据集为仿真生成的用户空间分布，包含时间不变的非齐次泊松过程热点分布以及时间变的热点漂移与用户移动模型。

**📈 对比分析**

与固定阵列（FPA）、6DMA、HT‑6DMA、仅位置优化与仅模式优化等基准方案对比，实验显示HMET‑6DMA在平均速率上相对最差基准提升约30%‑50%（具体提升随热点稀疏度而变化），且对初始配置不敏感。

**⚠️ 局限性**

局限性包括受机械运动速度和电子模式扫描范围限制；模型假设LoS单路径、完美CSI且未考虑多径、硬件非理想与实际能耗问题。

---

## 444. Exploration on Highly Dynamic Graphs

**arXiv ID:** 2601.13047 | [PDF](https://arxiv.org/pdf/2601.13047v1)

**作者:** Ashish Saxena `[一作]` (Indian Institute of Technology Ropar), Kaushik Mondal `[通讯]` (Indian Institute of Technology Ropar)

**通讯引用:** 226 | [OpenAlex ID](https://openalex.org/A5059765803)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

研究了在1-间隔连通性和连通时间两种动态图模型下的网络探索问题，证明了在连通时间模型中（n‑2)(n‑1)/2 个智能体无法完成探索，且给出了使用(n‑2)(n‑1)/2+1个智能体、1跳可见性、全局通信与O(log n)内存即可完成永续探索的算法；

**💡 创新点**

填补了1-间隔连通性模型中可见性与通信能力假设的空白，证明了连通时间模型中智能体数量与可见性之间的临界阈值，并提出了最小可见性需求下的高效探索算法；

**🔧 技术方法**

利用动态图理论、可见性与全局通信技术、基于多路径管道化的推送策略与增强管道技术以及全局通信的视图汇总子程序MAP；

**📊 数据集**

无实际数据集，全部基于理论构造与仿真验证；

**📈 对比分析**

与已有的探索算法相比，该算法在连通时间模型下在相同智能体数量下实现永续探索，时间复杂度为O(n⁴·T)，仅需O(log n)内存；

**⚠️ 局限性**

算法无法保证终止，且全局通信是否必需尚未确定。

---

## 445. High-Throughput and Scalable Secure Inference Protocols for Deep Learning with Packed Secret Sharing

**arXiv ID:** 2601.13041 | [PDF](https://arxiv.org/pdf/2601.13041v1)

**作者:** Qinghui Zhang `[一作]` (Institute of Information Engineering Chinese Academy of Sciences), Xudong Chen `[通讯]` (Institute of Information Engineering Chinese Academy of Sciences)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

构造了基于Pack‑Shamir秘密共享的高吞吐量、可扩展安全推理协议，支持多方半诚实模型下的深度学习推理；

**💡 创新点**

创新点包括：① 定义可用于向量-矩阵乘法的VM‑RandTuple，显著降低通信；② 采用滤波器打包实现并行卷积，零填充无需额外通信；③ 将所有非线性操作（ReLU、DReLU、MaxPool、比较）扩展为PSS版本，实现在单轮或对数轮内的并行计算；

**🔧 技术方法**

使用了Pack‑Shamir秘密共享（PSS）技术、离散Vandermonde矩阵随机共享、离线/在线阶段的随机三元组生成、对数轮前缀乘法、以及基于Mersenne素数域的固定点运算；

**📊 数据集**

在MNIST和CIFAR‑10数据集上，测试MiniONN、LeNet、AlexNet、VGG16四个网络；

**📈 对比分析**

与Liu等人（USENIX Security'24）方案对比，通信量在离线、在线和总量分别降低约5.85×、11.17×、6.83×；运行时间在WAN环境下在线/总时长提升1.59×–2.61×，在LAN下亦表现出显著的离线和总时延下降；

**⚠️ 局限性**

主要局限在于：对小k值时计算开销增大，导致在少数参与者或浅网络时改进有限；目前仅支持半诚实、诚实多数，尚未实现恶意安全；缺乏GPU加速，导致在极大网络或参与者数下仍有性能瓶颈。

---

## 446. Think3D: Thinking with Space for Spatial Reasoning

**arXiv ID:** 2601.13029 | [PDF](https://arxiv.org/pdf/2601.13029v1)

**作者:** Zaibin Zhang `[一作]` (Dalian University of Technology), Huchuan Lu `[通讯]` (Dalian University of Technology)

**通讯引用:** 45919 | [OpenAlex ID](https://openalex.org/A5006986293)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 Think3D 框架，使视觉语言模型通过3D重建与交互进行主动空间推理。

**💡 创新点**

将3D点云重建、摄像机姿态基准化和交互式视角切换集成到链式思考中，并引入强化学习优化探索策略。

**🔧 技术方法**

使用 Pi3 3D 重建、点云渲染、基于摄像机姿态的视角操作以及 GRPO 强化学习等技术。

**📊 数据集**

使用 BLINK（多视图）、MindCube 以及 VSI‑Bench（tiny）等空间推理基准数据集。

**📈 对比分析**

与 GPT‑4.1、Gemini‑2.5‑Pro 等大模型以及 Qwen3‑VL‑4B 等小模型对比，未训练时对大模型提升约 7–8%；RL 训练后小模型提升约 6–7%。

**⚠️ 局限性**

对小模型的空间推理受限，依赖高质量 3D 重建且计算开销大，未解决动态场景实时重建与长期任务。

---

## 447. HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads

**arXiv ID:** 2601.13013 | [PDF](https://arxiv.org/pdf/2601.13013v1)

**作者:** Xiaohui Zhao `[一作]` (Baidu Inc.), Shu Wu `[通讯]` (Institute of Automation, Chinese Academy of Sciences)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出一种用于百度广告平台客户终身价值（LTV）预测的模型HT‑GNN，融合人口层级异质性与动态营销引起的行为不确定性。

**💡 创新点**

创新点包括：1）使用超图学习和JS‑divergence监督来捕捉用户群体间的高阶关联；2）采用Transformer编码器和自适应加权处理不规则行为序列；3）构建任务自适应专家混合网络和动态预测塔，支持多时段预测；4) 多损失优化策略（JS、Huber、CE）提升对长尾分布的鲁棒性。

**🔧 技术方法**

技术细节：超图卷积网络（Hypergraph Convolution）+JS‑divergence监督；Transformer时序编码器；任务自适应Mixture‑of‑Experts（MOE）+动态加权；动态回归/分类塔；Huber、JS、交叉熵多任务损失。

**📊 数据集**

使用百度信息流广告平台15 M用户的数据集，包含用户画像、搜索与投放广告交互记录、35类行为序列，记录30、180、365天的LT/LTV值。

**📈 对比分析**

与XGBoost、ZILN、expLTV、MDME、HST‑GT等5种基线进行对比。HT‑GNN在所有预测时段（LT30/180/365，LTV30/180/365）上均取得最低NRMSE、NMAE、最高GINI和AUC，尤其在短期任务上提升约70%（相较于第二好模型MDME）。

**⚠️ 局限性**

局限性：① 超图构造依赖k‑最近邻，需调参；② 模型规模较大，训练成本高；③ 仅在百度广告场景验证，跨领域泛化需进一步研究。

---

## 448. PrivFly: A Privacy-Preserving Self-Supervised Framework for Rare Attack Detection in IoFT

**arXiv ID:** 2601.13003 | [PDF](https://arxiv.org/pdf/2601.13003v1)

**作者:** Safaa Menssouri `[一作]` (Mohammed VI Polytechnic University), El Mehdi Amhoud `[通讯]` (Mohammed VI Polytechnic University)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `9cc9baba-5356-466d-81ff-d80028d90279` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

设计并实现了PrivFly框架，结合自监督学习与差分隐私，在IoFT网络流量中实现稀有攻击检测。

**💡 创新点**

首次将VIME自监督预训练与DP‑SGD联合用于多类别IoFT IDS，并通过合成重采样提升稀有攻击识别。

**🔧 技术方法**

自监督表示学习（VIME）、差分隐私训练（DP‑SGD）、SMOTE/CTGAN合成样本、深度神经网络分类以及SHAP解释。

**📊 数据集**

ECU‑IoFT公开数据集（Tello UAV Wi‑Fi流量）。

**📈 对比分析**

与LR、SVM、RF、DNN基线对比，PrivFly在差分隐私噪声下实现最高99% F1、98%准确率，显著优于基线。

**⚠️ 局限性**

在极低隐私预算下仍存在性能下降，合成样本可能导致过拟合，模型对设备特征依赖过强。

---

## 449. Weighted-Hamming Metric: Bounds and Codes

**arXiv ID:** 2601.12998 | [PDF](https://arxiv.org/pdf/2601.12998v1)

**作者:** Sebastian Bitzer `[一作]` (Technical University of Munich), Violetta Weger `[通讯]` (Technical University of Munich)

**通讯引用:** 133 | [OpenAlex ID](https://openalex.org/A5084539841)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

研究了加权汉明距离下码的误差纠正能力，直接给出了更紧的可纠正误差上界，并提出了一种基于广义并缠构造的灵活码构造与相应的高效译码方案。

**💡 创新点**

创新点在于跳过传统最小距离分析，直接对可纠正误差数给出上界；引入多层广义并缠构造实现可调权重，并给出对误差纠正能力的下界；并改进经典译码器使其能纠正超过半最小距离的错误。

**🔧 技术方法**

利用加权汉明距离、块权重、Krawtchouk多项式、线性规划、广义并缠构造以及通用最小距离（GMD）译码等理论与算法技术。

**📊 数据集**

本文为理论研究，未使用具体数据集，主要通过符号计数和组合计算给出球体大小及差集。

**📈 对比分析**

通过与传统基于最小距离的界、Packing/covering、Singleton、LP 等界比较，实验显示所给出的上界在多组参数（例如 m=2, n=(7,7), λ=(1,2)，q=2,7）下与已有界相当甚至更优；构造的码在短长度下可达到覆盖界，部分实现 LP 界的下界；译码方案可纠正的错误量超过半最小距离。

**⚠️ 局限性**

局限性包括仅适用于线性码；构造与译码需要在每个子码层上具备高效解码器；对大规模块数或非整数权重的推广尚未深入；理论界限虽然紧，但在实际通信场景中的实现复杂度与性能仍待评估。

---

## 450. TinyML-Enabled IoT for Sustainable Precision Irrigation

**arXiv ID:** 2601.13054 | [PDF](https://arxiv.org/pdf/2601.13054v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 451. RAGExplorer: A Visual Analytics System for the Comparative Diagnosis of RAG Systems

**arXiv ID:** 2601.12991 | [PDF](https://arxiv.org/pdf/2601.12991v1)

**作者:** Haoyu Tian `[一作]` (Zhejiang University), Wei Chen `[通讯]` (Zhejiang University)

**通讯引用:** 66171 | [OpenAlex ID](https://openalex.org/A5100344384)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研发了 RAGExplorer，一套可视化分析系统，用于多配置 Retrieval‑Augmented Generation（RAG）流水线的对比诊断和根因分析；

**💡 创新点**

创新点包括：① 以对比为核心的诊断工作流，结合分层失败归因与 Sankey 流图；② 双轨上下文对比和沙盒式交互调试；③ 模块化插件架构和 LLM 辅助解释；

**🔧 技术方法**

技术手段涵盖：可视化（矩阵、条形图、Sankey、双轨条形）、分层失败归因算法、LLM‑as‑Judge 评估、Jaccard 相似度计算、自动化评价指标（Recall@k、MRR、MAP、事实正确性）等；

**📊 数据集**

使用了 2,556 条多跳新闻问答数据集（带真实证据句子标注），即 RAGBench‑News 语料；

**📈 对比分析**

通过在配置空间生成笛卡尔乘积后，利用性能概览矩阵进行粗略筛选，选定两配置进行 Sankey 对比，进一步在实例诊断视图中进行双轨上下文对比和交互调试。实验显示，系统帮助发现隐藏的召回提升、揭示“强者不一定好”的配置误区，并在实验中将准确率从 55% 提升至 60%；

**⚠️ 局限性**

局限性包括：① 依赖手工标注的真实答案，难以直接应用于无标注任务；② 对配置数量的可扩展性有限，适合少量配置的深度对比；③ 对新手用户的学习曲线和认知负荷尚需优化；④ 仅在问答任务上验证，开放式生成任务的效果未知。

---

## 452. Exploiting Light To Enhance The Endurance and Navigation of Lighter-Than-Air Micro-Drones

**arXiv ID:** 2601.13088 | [PDF](https://arxiv.org/pdf/2601.13088v1)

**作者:** Harry Huang `[一作]` (TU Delft), Marco Zúñiga Zamalloa `[通讯]` (TU Delft)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

**🎯 论文内容**

本文提出了一种自给自足的轻于空气微型无人机（LTA），通过在气囊表面布置太阳能电池实现能量收集，并利用单一光源实现“点与行”导航；

**💡 创新点**

创新点包括：①基于CFD的高保真仿真框架，实现了对LTA平台的气动力学和控制闭环的精确建模；②选用最优太阳能电池并评估其对平台稳定性的影响；③提出并对比三种单光源导航算法（Bearing‑Angle、Dither‑Extremum Seeking、Dither‑Free Gradient Ascent），实现低硬件复杂度的光源寻迹；

**🔧 技术方法**

主要技术包括：CFD求解气动阻力与旋翼推力，闭环PID控制器，MPPT光伏充电管理，光源调制与FFT解调，光电探测器阵列或单探测器姿态估计；

**📊 数据集**

使用的实验数据集：太阳能电池在不同照度（80~80000 lux）下的充电曲线、不同光源距离下的光照强度与SNR；在室内外（含风速0~14 m/s）对比飞行轨迹、路径长度、耗时；对比不同LTA平台（BEAVIS、GT‑MAB）以及不同导航算法；

**📈 对比分析**

方法上通过闭环仿真与实机验证对比，结果显示：GT‑MAB平台在姿态控制和风速容忍度上优于BEAVIS；在导航算法中，Bearing‑Angle算法在路径长度和飞行时间上最优，DES路径最长、耗时最长，DGA介于两者之间；在风速8 m/s时，只有BAG能成功导航，风速14 m/s所有算法失败；

**⚠️ 局限性**

局限性包括：①风速超过约8 m/s时仍无法保持稳定；②单光源导航对光强和反射环境敏感，需频繁调节光源；③平台仍需小型电池满足峰值功耗；④太阳能板布置受限于气囊曲率和重量，扩展性受限；

---

## 453. MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux

**arXiv ID:** 2601.13060 | [PDF](https://arxiv.org/pdf/2601.13060v1)

**作者:** Zecheng Li `[一作]` (Honor Device Co), Zuojian Wang `[通讯]` (Honor Device Co)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出 MagicGUI-RMS，一个多代理奖励模型框架，用于对 GUI 代理的轨迹进行自适应评估、纠错和持续自我演化。

**💡 创新点**

创新点包括：1) 结合领域专属奖励模型（DS‑RM）与通用奖励模型（GP‑RM）实现细粒度与语义层次双重评估；2) 通过结构化数据构建管线自动生成平衡多难度奖励样本；3) 引入奖励驱动的数据回流机制，将评估结果转化为主动训练信号，实现闭环自我提升。

**🔧 技术方法**

技术手段：多模态大型语言模型（如 Qwen3‑VL‑8B、GPT‑4o）作为视觉‑语言基底；强化学习与奖励微调；规则驱动与扰动式数据增强；奖励回流与协同进化。

**📊 数据集**

使用的数据集：MagicGUI‑RMS‑72k（奖励判定数据）、MagicGUI‑Agent‑39k（动作交互数据）以及 AndroidControl 基准；同时利用公开的 MagicGUI 交互语料。

**📈 对比分析**

与多种基线（GPT‑4o、Gemini‑2.0、Qwen 系列、UI‑TARS 等）在 step‑level 评估和真实任务回放上对比，MagicGUI‑RMS 在所有难度级别均达 93–96% 的准确率，超越 GPT‑4o 约 30% 的硬样本差距，Agent 在自我进化过程中 step‑level 成功率提升 74%→78%。

**⚠️ 局限性**

局限性：仍依赖大模型的算力与外部评估（GP‑RM），规则与扰动策略在极端布局或新型交互形式下可能产生误判；奖励回流机制对噪声样本的过滤尚不完善，需进一步提升鲁棒性。

---

## 454. Profiling German Text Simplification with Interpretable Model-Fingerprints

**arXiv ID:** 2601.13050 | [PDF](https://arxiv.org/pdf/2601.13050v1)

**作者:** Lars Klöser `[一作]` (Aachen University), Bodo Kraft `[通讯]` (Aachen University)

**通讯引用:** 149 | [OpenAlex ID](https://openalex.org/A5078576521)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

我们开发了一个名为Simplification Profiler的诊断工具，用多维指纹对德国文本简化结果进行可解释评估。

**💡 创新点**

创新点在于将多维度语言属性组成可解释的指纹，并用它来代替传统单一指标进行模型行为诊断，能够捕捉到提示策略和模型规模的细粒度差异。

**🔧 技术方法**

利用了NLI模型、LanguageTool规则、可读性指数、句子嵌入相似度等已有技术组合成模块化评估框架。

**📊 数据集**

主要使用德国维基百科的五句抽取文本，并生成18种不同模型/提示配置的简化版本，构成约1,000例评估子集。

**📈 对比分析**

通过对23维指纹特征训练逻辑回归分类器与随机及长度基线对比，发现指纹特征在区分模型和提示方面的F1可达71.9%，显著优于基线。

**⚠️ 局限性**

局限在于依赖NLI和LanguageTool等工具的偏差、只针对德语维基百科、未涵盖语气、注册等属性，且缺乏与人类评测的相关性验证。

---

## 455. Post-Quantum Secure Aggregation via Code-Based Homomorphic Encryption

**arXiv ID:** 2601.13031 | [PDF](https://arxiv.org/pdf/2601.13031v1)

**作者:** Sebastian Bitzer `[一作]` (Technical University of Munich), Antonia Wachter-Zeh `[通讯]` (Technical University of Munich)

**通讯引用:** 1143 | [OpenAlex ID](https://openalex.org/A5041962883)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b`

**🎯 论文内容**

提出一种基于学习奇偶性带噪声（LPN）假设的同态加密聚合框架，并给出了CRT优化来降低通信成本。

**💡 创新点**

创新点在于首次用代码理论的LPN构造键值与消息可加法同态加密，提出Hint‑LPN假设证明安全，并通过委员会解密器与CRT实现通信节约。

**🔧 技术方法**

采用LPN‑基同态加密、秘密共享的委员会解密、CRT分块以及Hint‑LPN安全分析等技术。

**📊 数据集**

论文未使用公开机器学习数据集，而是在理论和模拟参数下进行性能评估，利用数值仿真展示通信成本。

**📈 对比分析**

与OPA、Willow等LWE‑基方案及信息理论聚合协议比较，实验表明在用户数为10、50、100且协作参数适中的情形下，LPN方案的通信成本可低于信息理论方案。

**⚠️ 局限性**

局限性包括LPN维度需较大导致通信与计算开销增加，且与LWE方案相比在相同安全级别下效率不够理想。

---

## 456. Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis

**arXiv ID:** 2601.13021 | [PDF](https://arxiv.org/pdf/2601.13021v1)

**作者:** Nataša Petrović `[一作]` (University of the Balearic Islands), Jose Maria Buades Rubio `[通讯]` (University of the Balearic Islands)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出了一种基于集成学习与特征重要性筛选的红细胞形态分类方法，用于镰刀形细胞病（镰刀细胞病）的诊断支持。

**💡 创新点**

创新点在于系统性地评估不同分类器组合与单一特征组的性能，并通过特征重要性分析显著减少特征维度，同时验证了模型在未知数据集上的优越泛化能力。

**🔧 技术方法**

采用了决策树、Extra Trees、随机森林、梯度提升、支持向量机、k最近邻、全连接神经网络等基学习器，并结合投票、堆叠等集成策略以及基于树模型的特征重要性排序。

**📊 数据集**

使用了由UIB提供的血液涂片图像数据集ErythrocitesIDB作为训练与验证，另外从同一来源下载的SCDEnsemble.zip作为独立测试集。

**📈 对比分析**

与单一GB、RF基学习器对比，最优的RF+ET堆叠集成在测试集上实现了F1‑score 90.71%、SDS‑score 93.33%，在泛化性指标上显著优于传统方法。

**⚠️ 局限性**

局限在于对色彩特征依赖性低、模型仍为黑箱类型，未使用动态或更高级的可解释性技术，且在不同光学条件下的鲁棒性仍需进一步验证。

---

## 457. Enshrined Proposer Builder Separation in the presence of Maximal Extractable Value

**arXiv ID:** 2601.12989 | [PDF](https://arxiv.org/pdf/2601.12989v1)

**作者:** Yitian Wang `[一作]` (University College London), Jiahua Xu `[通讯]` (University College London)

**通讯引用:** 977 | [OpenAlex ID](https://openalex.org/A5079474815)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

本文通过构建正式模型和基于代理的仿真，对以太坊PoS中集成的ePBS机制进行系统评估，重点分析其在MEV（最大可提取价值）驱动的竞价过程中对公平性、去中心化和交易重排序的影响。

**💡 创新点**

创新点在于：①首次提出将数学分析与多主体仿真相结合的框架，全面量化ePBS的收益分配与MEV动态；②揭示ePBS在收益再投资下加剧了Builder的“富者愈富”效应；③用Gini系数、MEV包含概率和逆序计数等量化指标展示ePBS对去中心化的负面影响。

**🔧 技术方法**

使用的技术包括：正式化的博弈模型、最优竞价策略推导、基于EIP‑7732协议细节的代理仿真、网络延迟建模、MEV收益计算和基于区块链数据的实证分析。

**📊 数据集**

数据集主要来源于以太坊主网的链上数据（交易费用、MEV分布等）和Flashbot的MEV数据；在仿真中设置1000个区块，并扩展到10,000个区块以观察长期收益再投资的影响。

**📈 对比分析**

与传统PoS的随机区块提议方式对比，采用Gini系数、MEV包含概率和交易逆序计数三项指标。实验结果显示：Gini系数从PoS的0.1749升至ePBS的0.8358；95.4%的区块价值归于提议者；交易逆序次数在ePBS显著高于PoS；因此ePBS在提升提议者收益的同时，反而加剧了Builder的收益与内容集中，未能实现预期的去中心化目标。

**⚠️ 局限性**

局限性包括：①模型假设了简化的网络拓扑与均匀的交易分布，实际链上环境更为复杂；②仅关注MEV前跑、后跑与沙箱攻击等常见策略，未覆盖所有MEV手段；③仿真结果受参数设置（如延迟、投标策略、重投资因子）影响较大，缺乏多场景验证；④未探索可替代的ePBS改进方案，难以给出具体改进建议。

---

## 458. Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers

**arXiv ID:** 2601.12981 | [PDF](https://arxiv.org/pdf/2601.12981v1)

**作者:** Sulaiman Khan `[一作]` (Hamad Bin Khalifa University), Zubair Shah `[通讯]` (Hamad Bin Khalifa University)

**通讯引用:** 4347 | [OpenAlex ID](https://openalex.org/A5081437624)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

构建并验证了基于Tabular Transformer的多模态模型，用于利用DXA影像与电子健康记录预测Qatar Biobank人群的2型糖尿病风险。

**💡 创新点**

首次将Tabular Transformer与骨密度长时序数据结合，并通过概率解释发现肥胖相关指标优于骨密度指标作为糖尿病预测因子。

**🔧 技术方法**

采用Tabular Transformer、传统机器学习（如Logistic回归、随机森林等）以及大型语言模型（Claude 3.5 Sonnet、GPT‑4、Gemini Pro）进行模型对比，使用SMOTE‑ENN、混合增广等技术处理不平衡数据。

**📊 数据集**

使用Qatar Biobank 1,382名受试者的电子健康记录与DXA扫描数据，包含725男、657女，其中287例糖尿病、1,095例健康。

**📈 对比分析**

Tabular Transformer在测试集上达84.8%准确率、73.2%精确率、75%召回率、ROC AUC 79.7%，明显优于大型语言模型（AUC 71.3–74.7）和传统机器学习（AUC 56.7–65.3）。

**⚠️ 局限性**

样本量有限且严重不平衡，缺乏多中心数据与长期随访，且主要针对卡塔尔人群，限制了模型的普适性与外部验证。

---

## 459. Path to Diversity: A Primer on ISAC-izing Commodity Wi-Fi for Practical Deployments

**arXiv ID:** 2601.12980 | [PDF](https://arxiv.org/pdf/2601.12980v1)

**作者:** Hongbo Wang `[一作]` (Nanyang Technological University), Jun Luo `[通讯]` (Nanyang Technological University)

**通讯引用:** 23682 | [OpenAlex ID](https://openalex.org/A5100749903)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文从底层物理层出发，系统梳理并构建了 Wi‑Fi ISAC 的四个独立多样性维度（时间、频率、链路、空间），并给出对应的技术实现与应用路径；

**💡 创新点**

创新点在于提出了将 Wi‑Fi 作为 ISAC 平台的整体理论框架，将传统顶层应用视角转向底层物理资源的多样性解析，并针对每个维度给出可落地的实现方案；

**🔧 技术方法**

采用的技术包括同步时钟的单点式 ISAC、频谱拼接与离散频谱采样、链路多样化与 BFI 数字反馈、MIMO 空间方向控制、以及相位/频率失调的补偿与自适应校准；

**📊 数据集**

主要使用公开 Wi‑Fi CSI 数据集（如 Widar、WIDER、C-MUSI 等）以及实验室自行采集的多频段、MIMO 环境下的 CSI 与反馈数据；

**📈 对比分析**

通过与传统基于上层模型的 ISAC 调研进行对比，本文展示了在时间同步、频谱扩展、盲区消除和方向分辨率等关键指标上可实现至少 3 倍以上的精度提升，且在多目标感知场景中保持较高的鲁棒性；

**⚠️ 局限性**

局限性包括：对硬件平台的依赖较大（需支持高频段、宽带和多天线）、实现复杂度高且标准化程度低、频谱碎片化和调度难题仍待解决、以及在实时性与能耗方面尚未完全满足大规模部署需求。

---

## 460. Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading

**arXiv ID:** 2601.13082 | [PDF](https://arxiv.org/pdf/2601.13082v1)

**作者:** Advije Rizvani `[一作]` (Liechtenstein Business School), Pavel Laskov `[通讯]` (Liechtenstein Business School)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

研究通过伪造新闻标题对基于LLM的算法交易系统进行攻击，并量化其对财务回报的影响。

**💡 创新点**

首次系统性评估两种不可被人类识别的标题操纵手段（Unicode同形字符替换与隐写文本）对LLM驱动ATS的经济损失，并在真实数据上证明攻击可将年化回报削减至17.7个百分点。

**🔧 技术方法**

使用Backtrader仿真平台、LSTM价格预测模型、FinBERT/FinGPT/FinLLaMA及六种通用LLM进行情绪分析，结合自定义的Unicode同形替换与隐藏文本攻击技术。

**📊 数据集**

采用真实股票相关新闻头条和对应的历史行情数据，覆盖14个月的交易日。

**📈 对比分析**

通过与未受攻击的基线ATS进行对比，发现攻击后年化回报下降最高达17.7个百分点，表明攻击显著降低交易绩效。

**⚠️ 局限性**

仅考虑单日标题攻击，未研究多日连锁攻击或防御机制；实验基于Backtrader仿真，真实交易平台的抵御能力仍需进一步验证。

---

## 461. No Traffic to Cry: Traffic-Oblivious Link Deactivation for Green Traffic Engineering

**arXiv ID:** 2601.13087 | [PDF](https://arxiv.org/pdf/2601.13087v1)

**作者:** Max Ilsen `[一作]` (Osnabrück University), Markus Chimani `[通讯]` (Osnabrück University)

**通讯引用:** 1133 | [OpenAlex ID](https://openalex.org/A5044475263)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出一种无流量感知的绿色网络工程方法，目标是在低流量期间只激活最少的连接，确保任何缩放后流量矩阵可路由。

**💡 创新点**

创新点在于将问题定义为对任意下调流量矩阵的可路由性约束，给出 max(1/α,2) 近似算法并提供两种后处理启发式，理论与实践均接近最优。

**🔧 技术方法**

使用线性规划求解 LP 松弛、整数规划、流网络与多商品流模型，以及对 LP 基本解的上取整与启发式迭代。

**📊 数据集**

实验基于 Topology Zoo 的 60 节点以上拓扑，假设每条链路 5 条并行连接，并使用 Repetita 数据集的四个高负载流量矩阵。

**📈 对比分析**

与最优 ILP、以及流量感知与无感知两种变体对比，发现后处理算法在连接数上接近最优、计算时间显著降低、且最大链路利用率不超过 1。

**⚠️ 局限性**

主要局限在未考虑具体硬件功耗模型、SR 分段限制以及对流量变化的鲁棒性不足。

---

## 462. GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure

**arXiv ID:** 2601.13052 | [PDF](https://arxiv.org/pdf/2601.13052v1)

**作者:** Antoine Carreaud `[一作]` (Ecole Polytechnique Federale de Lausanne), Adrien Gressin `[通讯]` (University of Applied Sciences Western Switzerland)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本研究创建了 GridNet‑HD 数据集，并提供了多模态 LiDAR‑RGB 语义分割基线；

**💡 创新点**

创新点在于首次公开发布高密度 LiDAR 与高分辨率斜视影像相结合的电力线路 3D 语义标注数据集，精确配准与 11 类语义划分；

**🔧 技术方法**

使用了飞行数据采集、RTK 定位、相机内外参数标定、bundle‑adjustment、LiDAR‑图像配准、点云重投影、Transformer‑based 2D 语义分割、SuperPoint/Point Transformer、Late‑Fusion MLP、DITR 等技术；

**📊 数据集**

采用 GridNet‑HD 数据集，包含 7,694 张高分辨率斜视影像和 2.5 亿点高密度 LiDAR，标注为 11 个电力基础设施与环境类；

**📈 对比分析**

在 GridNet‑HD 上，融合方法明显优于单模态，最佳 mIoU 达到 74.87%（DITR+overlap+TTA），显示几何与外观信息互补；

**⚠️ 局限性**

局限性包括类别不平衡、对精确配准高度依赖、薄弱结构（如电缆、绝缘子）标注稀缺、以及需人工标注、对不同地区的泛化仍需验证。

---

## 463. OFA-MAS: One-for-All Multi-Agent System Topology Design based on Mixture-of-Experts Graph Generative Models

**arXiv ID:** 2601.12996 | [PDF](https://arxiv.org/pdf/2601.12996v1)

**作者:** Shiyuan Li `[一作]` (Griffith University), Shirui Pan `[通讯]` (Griffith University)

**通讯引用:** 22491 | [OpenAlex ID](https://openalex.org/A5008056593)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出一种“一体化”多代理系统拓扑设计框架，能够根据自然语言任务描述自动生成适配的协作图；

**💡 创新点**

创新点包括：① 将任务感知图状态编码（TAGSE）与混合专家（MoE）结合，实现跨域自适应生成；② 采用三阶段训练（无条件预训练、LLM驱动的任务–拓扑对齐预训练、少量真实数据微调）与大规模LLM合成数据；

**🔧 技术方法**

技术手段涵盖：自回归图生成、任务感知图神经网络、Mixture-of-Experts推理、LLM驱动数据合成、结构先验预训练、平衡与稀疏门控正则化；

**📊 数据集**

使用的基准数据集包括 MMLU、GSM8K、AQuA、MultiArith、SVAMP、HumanEval，并在未见过的 GAIA 数据上进行 OOD 验证；

**📈 对比分析**

与固定拓扑、单域图学习模型（AgentPrune、AgentDropout、G-Designer、EIB-LEARNER 等）对比，平均准确率提升至约93%（预训练）/93.5%（微调），在 GAIA OOD 上亦保持领先；

**⚠️ 局限性**

局限性：对数据质量与人工验证依赖较大，极端或动态任务场景下适配性尚需提升，模型对实时环境的快速更新和持续学习仍存在挑战。

---

## 464. METIS: Mentoring Engine for Thoughtful Inquiry & Solutions

**arXiv ID:** 2601.13075 | [PDF](https://arxiv.org/pdf/2601.13075v1)

**作者:** Abhinav Rajeev Kumar `[一作]` (Lossfunk), Paras Chopra `[通讯]` (Lossfunk)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了METIS——一种阶段感知、工具增强的AI研究导师，帮助本科生从创意到可发表论文；

**💡 创新点**

创新点在于将写作阶段A–F与工具路由与文献检索结合，提供自检的“Intuition”“Why this is principled”输出，并基于阶段感知进行工具选择；

**🔧 技术方法**

使用LLM（GPT‑5、Claude Sonnet 4.5）+自定义工具（研究指南检索、文献检索、方法检查、会话记忆），并通过Prompt实现阶段检测与工具路由；

**📊 数据集**

利用公开arXiv/OpenReview论文作为文档检索来源，对D–F阶段进行文献支撑；

**📈 对比分析**

通过LLM‑as‑Judge的成对偏好和学生‑persona rubric两种评估，METIS在单回合任务中对Claude Sonnet 4.5的优胜率为71%，对GPT‑5为54%；在多回合辅导中，METIS的最终质量略高于GPT‑5，成功率和平均完成回合数略高；

**⚠️ 局限性**

局限包括：仅覆盖文本写作阶段，未包含实验与伦理等实验室工作；评估依赖LLM‑judge，易受模型偏好和长度偏差影响；工具检索误差仍存在，阶段误判偶尔出现；对模型性能变化的泛化有限。

---

## 465. Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures

**arXiv ID:** 2601.13059 | [PDF](https://arxiv.org/pdf/2601.13059v1)

**作者:** Yulun Guo `[一作]` `[通讯]`, Yulun Guo

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种基于Retinex理论的双分支原型学习网络，用于低光照环境下的少样本裂缝分割，能够直接从低光照图像中提取裂缝区域，减少对大规模标注数据的依赖。

**💡 创新点**

创新点在于：1）将Retinex分解得到的反射分量与RGB分量并行处理，实现照明不变的全局表示；2）设计交叉相似度先验掩码生成（CSPMG）模块，用高维相似度捕获支持与查询之间的裂缝对应关系；3）引入多尺度特征增强（MSFE）模块结合CBAM与ASPP，对查询特征进行跨尺度、跨通道的加权融合；4）采用原型融合与自支持原型更新机制提升少样本适应性。

**🔧 技术方法**

采用Retinex分解网络、ResNet‑50/101双分支特征提取、余弦相似度原型匹配、CSPMG模块、MSFE模块（包含CBAM、ASPP）、Self‑Support Prototype (SSP)模块、BCE损失与辅助先验一致性损失，整体构建端到端的few‑shot裂缝分割框架。

**📊 数据集**

在LCSD（真实低光裂缝图像）与llCrackSeg9k（通过Restormer生成的低光合成裂缝图像）两大数据集上进行训练与评估。

**📈 对比分析**

在1‑shot与5‑shot设置下，使用mIoU指标与MLC、SSP、CrackNex等SOTA方法对比。结果显示：在llCrackSeg9k上ResNet‑101版实现71.40（1‑shot）/68.20（5‑shot）mIoU；在LCSD上实现70.37（1‑shot）/69.27（5‑shot）mIoU，均显著优于对手模型。

**⚠️ 局限性**

主要局限在于：①对极端噪声与模糊的鲁棒性仍有限；②模型在跨不同低光照场景的泛化能力需进一步验证；③对极少样本情况下的性能提升空间仍存在。

---

## 466. Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition

**arXiv ID:** 2601.13044 | [PDF](https://arxiv.org/pdf/2601.13044v1)

**作者:** Warit Sirichotedumrong `[一作]` (Typhoon), Kunat Pipatanakul `[通讯]` (Typhoon)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `b88c6eac-d57a-4623-a604-1f401f3eb268` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研发了泰语实时 ASR 系统 Typhoon ASR Realtime，采用 FastConformer‑Transducer 架构，结合 11,000 小时大规模泰语语料、统一文本归一化、共识式伪标注、两阶段方言适配，并发布标准化评测基准 Typhoon Benchmark 与 TVSpeech；

**💡 创新点**

①以数据质量与一致性为首要原则，构建统一归一化与共识式伪标注流程；②采用 FastConformer‑Transducer 实现 45× 计算与 13× 参数压缩的低延迟流式模型；③提出两阶段方言适配（先声学再语言）策略；④公开了标准化评测集（Gigaspeech2‑Typhoon、TVSpeech）解决泰语评测不确定性；

**🔧 技术方法**

FastConformer‑Transducer（流式编码+RNN‑T 解码）、多模型共识投票（Pathumma、Biodatlab、Internal Whisper‑Large）、自动复杂度检测与人工校验、文本归一化管线、TTS 语料生成、两阶段课程学习（声学+语言）、INT8/INT4 量化探讨；

**📊 数据集**

主要语料：Gigaspeech2 10,329.5h、Internal Curated Media 631h、Common Voice 17.0 35.4h、Internal TTS 3.2h；方言适配 303h（Internal Isan 28h、Public Isan 27.8h、General Thai 184h、TTS 62h、重复标记 0.33h）；评测基准：Gigaspeech2‑Typhoon 1,000 句、TVSpeech 570 句、FLEURS 公开集、Pathumma Whisper、Gemini 3 Pro 等；

**📈 对比分析**

与 Pathumma Whisper Large‑v3、Whisper Turbo、Gemini 3 Pro 等进行 CER 对比；Typhoon ASR Realtime 在 Gigaspeech2‑Typhoon 6.81% CER、TVSpeech 6.93% CER、FLEURS 13.87% CER（标准化后 9.68%），比离线基线相当但计算 45× 降低；在 Isan 方向，offline 8.85% CER、streaming 10.65% CER，远优于 Whisper‑Medium‑Dialect 17.72%；共识式数据管线单独提升约 4% CER；

**⚠️ 局限性**

归一化过于严格导致可读性下降、缺乏逆文本归一化支持；仅针对泰语主导语音，代码切换、英泰混合难处理；语义理解有限，无法解决复杂语义歧义；多说话人/重叠处理未实现；方言覆盖仅限 Isan，其他方言需扩展；模型仍需量化部署与边缘化实现。

---

## 467. Static Is Not Enough: A Comparative Study of VR and SpaceMouse in Static and Dynamic Teleoperation Tasks

**arXiv ID:** 2601.13042 | [PDF](https://arxiv.org/pdf/2601.13042v1)

**作者:** Yijun Zhou `[一作]` (Vrije Universiteit Amsterdam), Kim Baraka `[通讯]` (Vrije Universiteit Amsterdam)

**通讯引用:** 588 | [OpenAlex ID](https://openalex.org/A5023767001)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0`

**🎯 论文内容**

本文通过一项受试者内实验比较了使用VR手柄与SpaceMouse两种接口在静态与动态遥操作任务中的表现，提出并公开了可支持动态任务的开源VR遥操作界面。

**💡 创新点**

创新点在于：①系统性地将静态与动态两类任务纳入比较，揭示接口在动态任务中显著差异；②提供了专为动态任务设计的可公开的VR遥操作系统；③通过实验验证姿态式控制在实现连续、高速动作时优于基于速度的SpaceMouse。

**🔧 技术方法**

技术包括：Oculus Quest 3手柄的6‑DoF姿态跟踪、姿态增量映射为机器人末端执行器的位姿指令、基于Franka Emika Panda机械臂的笛卡尔阻抗控制、NASA‑TLX与SUS评价量表、以及定量成功率、任务时长和累计成功率指标。

**📊 数据集**

数据集：未使用公开数据集，而是自行设计四个任务（两静态、两动态）并记录25名参与者的演示数据（成功/失败、时长、尝试次数）。

**📈 对比分析**

比较方法为受试者内对比，先用VR后用SpaceMouse；评估指标为成功率、任务时长、累计成功率，以及主观工作负荷与可用性。实验结果显示：在静态任务中两接口差异不显著；在动态任务中VR成功率显著高于SpaceMouse（T3 31.2% vs 0%，T4 50.9% vs 33.3%），任务完成时间更短，累计成功率更快。

**⚠️ 局限性**

局限性包括：实验未对接口顺序做完全随机化（VR始终先行），可能产生顺序效应；缺乏轨迹日志，无法深入分析运动质量与控制策略；任务难度切换不够平滑，可能影响学习过程。

---

## 468. PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning

**arXiv ID:** 2601.13020 | [PDF](https://arxiv.org/pdf/2601.13020v1)

**作者:** Zhiyan Hou `[一作]` (Institute of Automation, Chinese Academy of Sciences), Jinqiao Wang `[通讯]` (Institute of Automation, Chinese Academy of Sciences)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究了多模态大语言模型在连续指令微调（CIT）中的持续学习问题，提出基于LoRA下的路径激活子空间（PASs）的Mixture-of-Experts LoRA方法，通过PASs指导的重加权与秩级稳定化来解决误对齐共漂移并减轻灾难性遗忘。

**💡 创新点**

创新点包括：①将LoRA的下投影定义为路径激活子空间，作为专家功能的能力对齐坐标系；②利用PASs生成路由权重，消除传统独立路由器导致的路由漂移；③在PASs基础上做基于重要性加权的秩级稳定化，聚焦保留过去任务关键方向。

**🔧 技术方法**

使用的技术主要有：LoRA、Mixture-of-Experts、低秩路径激活子空间（PASs）、PASs-guided Reweighting、PASs-aware Rank Stabilization、重要性估计与加权正则化。

**📊 数据集**

实验数据集为M​LLM-CTBench，该基准包含多模态持续指令微调任务，覆盖多种任务和分布漂移。

**📈 对比分析**

与传统连续学习基线（LwF、EWC、MAS等）、PEFT基线（LoRA、O-LoRA）以及MoE-LoRA变体（DDAS、MoELoRA）和零样本/多任务微调做对比。结果显示，本文方法在平均性能（AP）上比第二好约5.1%，在后向迁移（BWT）上显著降低，整体性能领先。

**⚠️ 局限性**

局限性包括：①仅在固定容量MoE-LoRA框架下验证，难以直接推广到容量扩展或回放方式的场景；②PASs基于LoRA结构，迁移至其他PEFT形式需重新定义子空间；③PASs-RW对极端分布漂移的鲁棒性待进一步验证；④PASs-RS重要性估计受任务数据稀缺影响，需额外统计与调参；⑤评估指标主要是AP/BWT，缺乏更细粒度的路由匹配和在线分布动态测试。

---

## 469. Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context

**arXiv ID:** 2601.13018 | [PDF](https://arxiv.org/pdf/2601.13018v1)

**作者:** Ghislain Dorian Tchuente Mondjo `[一作]` `[通讯]` (Universite de Yaounde I), Ghislain Dorian Tchuente Mondjo (Universite de Yaounde I)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

利用双向循环神经网络（BiRNN）在多任务框架下同时预测标签和解释权重，以解决 HateXplain 基准中注意力不稳定的问题；

**💡 创新点**

创新点在于将 BiRNN 作为注意力学习层替代传统矩阵乘法，从而捕捉词序列的前后依赖，使得预测的注意力更接近人工标注的解释；

**🔧 技术方法**

采用 BiRNN‑Attention 结构、全连接层、交叉熵与注意力损失的联合优化、Adam 优化器以及预训练的 GloVe 词向量；

**📊 数据集**

使用 HateXplain 公开数据集（约 20,000 条带有标签、目标社区与解释标注的评论）；

**📈 对比分析**

与 CNN‑GRU、BiRNN、BiRNN‑Attention、BiRNN‑HateXplain 等基线模型在准确率、F1、AUROC、GMB‑AUC、IOU‑F1、Faithfulness 等指标上对比，BiAtt‑BiRNN‑HateXplain 在准确率（0.65）、F1（0.64）、AUROC（0.81）以及多项偏见与解释性指标上均显著提升；

**⚠️ 局限性**

局限性在于虽然解释性和偏见减少明显，但在某些实例中分类效果仍未能优于 BERT‑HateXplain，且模型规模相对较大，对资源消耗与实时性要求较高；

---

## 470. MeltRTL: Multi-Expert LLMs with Inference-time Intervention for RTL Code Generation

**arXiv ID:** 2601.13015 | [PDF](https://arxiv.org/pdf/2601.13015v1)

**作者:** Nowfel Mashnoor `[一作]` (University of Central Florida), Kimia Azar `[通讯]` (University of Central Florida)

**通讯引用:** 785 | [OpenAlex ID](https://openalex.org/A5031747364)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一种名为 MeltRTL 的框架，通过在推理时对大型语言模型内部表示进行干预，实现 RTL 代码生成的准确性提升。

**💡 创新点**

创新点在于结合多专家注意力架构与推理时干预（ITI），并利用非线性探针识别并纠正 RTL 生成中的错误。

**🔧 技术方法**

采用了多专家注意力网络、探针引导的头部选择、推理时激活干预以及轻量级的非线性分类器（LR、MLP、SVC）。

**📊 数据集**

使用了 200 条指令-代码对的小规模数据集，并在 VerilogEval 基准上进行评估。

**📈 对比分析**

与基准 LLM（QwenCoder2.5-14B）相比，MeltRTL 在 VerilogEval 上的可综合率从 85.33% 提升至 96%，功能正确率从 45.33% 提升至 60%，且仅增加 27% 的计算开销。

**⚠️ 局限性**

局限性包括对探针训练数据量的依赖、对不同 RTL 设计类别的泛化能力尚未完全验证，以及推理时干预参数的调优复杂性。

---

## 471. KinGuard: Hierarchical Kinship-Aware Fingerprinting to Defend Against Large Language Model Stealing

**arXiv ID:** 2601.12986 | [PDF](https://arxiv.org/pdf/2601.12986v1)

**作者:** Zhenhua Xu `[一作]`, Meng Han `[通讯]`

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了 KinGuard 框架，通过在大型语言模型上增量预训练嵌入结构化亲属关系知识，实现黑盒可验证的模型所有权标记。

**💡 创新点**

创新点在于用知识嵌入替代传统触发器，解决稳健性与隐蔽性悖论；利用亲属图与四元组属性生成语义连贯的私有文本，使模型内部化深层语义关系，而非记忆固定响应。

**🔧 技术方法**

技术手段包括：结构化属性四元组与亲属图构建、增量预训练（语言建模目标）、ROUGE‑N 相似度与 AUC‑FSR 验证指标、对抗性攻击测试（微调、输入扰动、模型融合）以及 perplexity 与 Token‑Forcing 等隐蔽性评估。

**📊 数据集**

数据集：私有亲属关系叙事语料库（两个家庭图合并生成约 300 篇文本），以及不包含指纹的对照集。该语料库由角色属性四元组与亲属关系图生成的自然语言叙述组成。

**📈 对比分析**

与 ProFlingo、IF‑SFT、Chain&Hash 等基线对比，KinGuard 在清洁模型上 FSR 均为 100%，在微调、输入扰动和模型融合攻击中均保持 100% 或接近 100% 的鲁棒性；在任务基准上平均准确率最高；隐蔽性评估显示 perplexity 极低、Token‑Forcing 检测率为 0%，优于其他方法。

**⚠️ 局限性**

局限性：仅在三种公开模型（LLaMA2、LLaMA3、Qwen2.5）上验证，缺乏更大规模或不同架构的泛化实验；需预先构建私有知识库，规模受限；对更高级的对抗手段或跨模型迁移可能存在未知风险。

---

## 472. Incorporating Q&A Nuggets into Retrieval-Augmented Generation

**arXiv ID:** 2601.13222 | [PDF](https://arxiv.org/pdf/2601.13222v1)

**作者:** Laura Dietz `[一作]` (University of New Hampshire), James Mayfield `[通讯]` (Human Language Technology Center of Excellence Johns Hopkins University)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建基于Q&A nugget 的检索增强生成（RAG）系统，自动生成并利用 nugget 引导检索、抽取与生成，保持引用可追溯；

**💡 创新点**

首次以 nugget 为核心而非聚类摘要，利用 nugget 银行进行去重、排名、检索、抽取与验证，保证每句只引用单一来源，显著提升 nugget 召回与引用支持；

**🔧 技术方法**

使用 LLM 自动生成摘要与 nugget，LLM 进行同义/重述检测、抽取、验证；SVC 结合 19 个质量特征对 nugget 排序；采用 PLAID‑X、Qwen3、Milco 等检索模型；基于 nugget 的句子抽取与句子选择；

**📊 数据集**

TREC NeuCLIR 2024 主题报告生成基准（多语言语料库机器翻译版），配合手工金标 nugget 库；

**📈 对比分析**

与最新 nugget‑based RAG 系统 GINGER、BulletPoints、Agentic 等在 NuggetRecall、NuggetDensity、SentenceNovelty、CitationSupport 等指标上对比，系统在所有 nugget 指标上优于对手，召回提升 42–65%，引用支持达 0.90；

**⚠️ 局限性**

运行成本高（LLM 调用多，二次检索与验证耗时）；验证阶段可能存在评测者知识循环偏差；目前仅在 TREC NeuCLIR 评测，泛化性与跨域表现待进一步验证。

---

## 473. The Energy-Throughput Trade-off in Lossless-Compressed Source Code Storage

**arXiv ID:** 2601.13220 | [PDF](https://arxiv.org/pdf/2601.13220v1)

**作者:** Paolo Ferragina `[一作]` (Sant'Anna School of Advanced Studies), Francesco Tosoni `[通讯]` (Sant'Anna School of Advanced Studies)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

设计并实现了一种基于 RocksDB 的压缩键值存储，用于高效索引大规模源代码数据集，并对其空间、时间、能耗三者做了系统评估。

**💡 创新点**

创新点在于将 Permute‑Partition‑Compress (PPC) 思想嵌入到动态键值存储中，利用文件名键设计使相似内容在存储中相邻，从而获得大幅压缩并兼顾检索性能；同时引入能耗度量，提供 Pareto 最优配置。

**🔧 技术方法**

使用 RocksDB、zstd 压缩、PPC 关键字设计、块大小调优、多线程并行、Perf 能耗测量等技术。

**📊 数据集**

使用四种主流语言（Python、Java、JavaScript、C/C++）各 200 GiB 的 Parquet 源码数据，共计 800 GiB。

**📈 对比分析**

对比不同压缩级别、块大小和线程数的构建与查询性能，结果表明压缩率 15–20%、构建吞吐 158–447 MB/s，检索单/多键在 8–30 倍加速，能耗随之降低。

**⚠️ 局限性**

局限性：仅在单机实验，未实现分布式部署；仅测试插入和检索，未评估删除/更新；能耗估计基于软件计数器，精度有限；对极端压缩级别的能耗/延迟曲线未完全覆盖。

---

## 474. ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments

**arXiv ID:** 2601.13218 | [PDF](https://arxiv.org/pdf/2601.13218v1)

**作者:** Igor Vozniak `[一作]` (German Research Center for Artificial Intelligence), Philipp Slusallek `[通讯]` (German Research Center for Artificial Intelligence)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `3f18e8e3-0266-457c-8567-9039b6d2394d` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

在VR街道穿行环境中构建了120人数据集，提出基于对象的注意力预测方法并设计相应评估指标。

**💡 创新点**

创新点在于提出对象相似度指标oSIM以及SUMGraph模型，该模型通过图卷积网络融合车辆等关键对象信息，实现更符合人类注意力的预测。

**🔧 技术方法**

主要技术包括Mamba‑U‑Net架构、图卷积网络（GCN）、视觉状态空间（VSS）与条件视觉状态空间（C‑VSS）块，以及结合oSIM的多任务损失。

**📊 数据集**

使用的训练数据集为本文新构建的VR街道穿行数据集（120名参与者），包含RGB视角、眼动、全景分割、深度与车辆关键点等多模态信息。

**📈 对比分析**

与现有多种最先进注意力预测模型（如TempSAL、TranSalNet、ContextSalNet、SUM）对比，SUMGraph在28/30项指标（CC、KLD、AUC、SIM、oSIM等）上均达到或超越最佳水平，且加入oSIM损失后性能进一步提升。

**⚠️ 局限性**

局限性包括：数据主要来自城市中心场景，缺乏乡村或极端气候的样本；参与者年龄在20-50岁之间，文化背景仅涵盖德日两国；因此模型的泛化能力至今未在更广泛环境下验证。

---

## 475. Conflict Detection in AI-RAN: Efficient Interaction Learning and Autonomous Graph Reconstruction

**arXiv ID:** 2601.13213 | [PDF](https://arxiv.org/pdf/2601.13213v1)

**作者:** Joao F. Santos `[一作]` (Commonwealth Cyber Initiative), Jacek Kibiłda `[通讯]` (Commonwealth Cyber Initiative)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `a2602d71-93ab-4bad-974b-672788df8193` `3855fcda-48ef-4070-a15e-803cd5c84d83` `64443552-63e0-44b5-906f-d90fe95c5a1b` `3f18e8e3-0266-457c-8567-9039b6d2394d` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出并验证了一套三阶段的冲突检测框架（交互学习 → 图重构 → 冲突识别），用于 AI‑native 移动网络中的 AI 代理竞争目标。

**💡 创新点**

创新点包括：①将交互学习视为推荐系统中的排序问题；②提出轻量级的两塔编码器，用对齐的相似度学习参数–KPI 交互；③采用稀疏化 Softmax（sparsemax）实现无手调参的自动图重构。

**🔧 技术方法**

主要技术：两塔编码器（各自为轻量级前馈网络）、L2 归一化、缩放点积相似度、稀疏化 Softmax、基于规则的冲突识别、BCE 损失训练。

**📊 数据集**

使用公开的冲突模型数据集：10,000 条高斯分布样本，4 个代理、7 个参数、4 个 KPI，模拟了已知冲突关系。

**📈 对比分析**

与基线 GNN、阈值、Top‑K、分位数等方法对比。结果显示：两塔模型比 GNN 训练速度快约 2×、F1 达 1.0 的 epoch 数少 14×；sparsemax 在图重构/冲突识别上的 epoch 数比阈值法低 4×、2×、8×，性能在 F1、AUC 等指标上均优于传统方法。

**⚠️ 局限性**

局限性：①仅在合成 Gaussian 数据集上验证；②未考虑时间序列/动态演化的情况；③冲突识别仍采用简单规则，未评估更复杂的图算法；④缺乏在真实 AI‑native 网络中的部署与验证。

---

## 476. Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising

**arXiv ID:** 2601.13208 | [PDF](https://arxiv.org/pdf/2601.13208v1)

**作者:** Vikram R Lakkavalli `[一作]` `[通讯]`, Vikram R Lakkavalli

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种 Additive U‑Net 架构，通过可学习的加法跳连接替代传统的拼接跳，使网络保持单通道特征空间，实现轻量化去噪。

**💡 创新点**

创新点在于引入可学习的非负标量门控加法跳，既避免了通道膨胀，又提供了可解释的多尺度信息流控制；同时采用残差编码与加法融合，形成全新“减法编码+加法跳”的设计。

**🔧 技术方法**

技术细节包括：残差编码器块、可学习的加法跳门（softplus 约束非负）、1×1 卷积输出头、Charbonnier 损失、Adam 优化器、以及多种卷积核尺寸调度。

**📊 数据集**

训练使用 DIV2K 与 Flickr2K 数据集的灰度随机裁剪，评估在 Kodak‑17 基准集（512×768 灰度图）上加入不同标准差的高斯噪声（σ = 15, 25, 50）。

**📈 对比分析**

与 DnCNN 和伪 Add‑U‑Net（直接相加的跳）对比，Additive U‑Net 在 σ = 15/25/50 的 PSNR/SSIM 上与基线相当甚至略优，且模型尺寸更小、跳门可解释性更强。

**⚠️ 局限性**

局限性包括：仅在灰度单通道图像上验证，缺乏彩色或高分辨率的深入实验；对非高斯或结构化噪声的鲁棒性未作系统评估；以及跳门学习仍需进一步理论分析。

---

## 477. From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models

**arXiv ID:** 2601.13166 | [PDF](https://arxiv.org/pdf/2601.13166v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 478. Active Informative Planning for UAV-based Weed Mapping using Discrete Gaussian Process Representations

**arXiv ID:** 2601.13196 | [PDF](https://arxiv.org/pdf/2601.13196v1)

**作者:** Jacob Swindell `[一作]` (Lincoln Centre for Autonomous Systems), Riccardo Polvara `[通讯]` (Lincoln Centre for Autonomous Systems)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文通过评估多种离散化高斯过程（GP）表示方法，探究其在无人机精准农业植草地图采集中的影响，并将其嵌入递归信息路径规划（IPP）框架中，比较不同表示对地图质量与任务效率的影响。

**💡 创新点**

创新点在于系统化比较七种离散化策略（四叉树、楔形、BSP等）对GP映射的保真度与在线规划行为的影响，并提供基于土壤分布特征的选择指南。

**🔧 技术方法**

技术包括GP回归（Matérn 3/2 核）、基于GPU的NumPyro实现、不同离散化算法（四叉树、BSP LSE、BSP Region、Voronoi、Hex、Wedgelet等）、递归IP规划（利用信息增益、路径成本和覆盖惩罚）以及多指标评估（SSIM、HD、MSE、RMSE、覆盖率等）。

**📊 数据集**

使用了德国Rheinbach地区的WeedMap数据集中的五幅甜菜田的分割正射影像作为训练和评估数据。

**📈 对比分析**

通过在固定40分钟飞行时间内对比四叉树与Voronoi两种离散化，发现四叉树在早期任务中获得更快的草覆盖和误差下降，而Voronoi在中后期可实现更高的地图精度；整体两者均能实现接近100%的草覆盖，但在计算开销和路径光滑度上表现不同。

**⚠️ 局限性**

局限性包括：离散化方法对GP更新的计算延迟差异大（如BSP LSE需超过2分钟），未针对每种离散化设计专门优化的规划器；实验仅基于模拟/数据集，缺乏现场实测验证；并未考虑多机协同或高度自适应控制等更复杂场景。

---

## 479. OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand

**arXiv ID:** 2601.13183 | [PDF](https://arxiv.org/pdf/2601.13183v1)

**作者:** Sergio Servantez `[一作]` (Northwestern University), Kristian Hammond `[通讯]` (Northwestern University)

**通讯引用:** 5091 | [OpenAlex ID](https://openalex.org/A5114000097)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

介绍了OpenExempt框架与基准，用动态生成技术在美国破产豁免法域内创建可控的法律推理任务；

**💡 创新点**

创新点在于将专家编码的法律知识与符号推理结合，实现任务规模、复杂度可调且支持诊断性评估；

**🔧 技术方法**

采用结构化法律知识表征、模板化自然语言生成、符号求解器和多级任务流水线；

**📊 数据集**

使用手工编码的资产与豁免法规集（约500项资产，联邦及五州豁免）自动生成近1万份样本；

**📈 对比分析**

在9,765样本、9个评估套件上对13种LLM进行零样本对比，推理模型在基础到高级任务上表现最佳，但最高级任务F1<0.63，显示仍有提升空间；

**⚠️ 局限性**

仅覆盖美国破产豁免法、单一语言、客观任务，缺乏多州/多语言扩展，未处理主观法律解释问题。

---

## 480. Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages

**arXiv ID:** 2601.13178 | [PDF](https://arxiv.org/pdf/2601.13178v1)

**作者:** Joseph Gatto `[一作]` (Dartmouth), Sarah M. Preum `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建并公开了大规模异步门诊门户消息的医学分诊数据集 PMR-Bench，并将分诊任务转化为成对推断的头对头比赛式重新排序问题。

**💡 创新点**

①将医学分诊视为“哪个更紧急”的成对推断；②开发自动化数据标注策略为 LLM 提供领域指导；③提出 UrgentReward 与 UrgentSFT 两类模型，分别基于 Bradley‑Terry 和下一词预测目标。

**🔧 技术方法**

使用大型语言模型（8B 及以上）训练，采用 Bradley‑Terry 比值学习和下一词预测（SFT）方法，并配合自动化标注生成训练数据。

**📊 数据集**

PMR‑Bench 数据集，包括 1569 条唯一患者消息、2000+ 高质量对比测试对，以及结合非结构化患者消息与真实 EHR 数据的样本。

**📈 对比分析**

在 inbox 排序指标上与基线 8B 通用模型对比，UrgentSFT‑8B 和 UrgentReward‑8B 分别提升 15 分和 16 分；UrgentReward 在低资源环境下表现更佳。

**⚠️ 局限性**

仅在门诊门户消息场景评估，未覆盖急诊现场；自动标注策略可能引入偏差；模型对低质量或极端表达的消息鲁棒性尚待验证。

---

## 481. Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification

**arXiv ID:** 2601.13105 | [PDF](https://arxiv.org/pdf/2601.13105v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86`

---

## 482. Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference

**arXiv ID:** 2601.13155 | [PDF](https://arxiv.org/pdf/2601.13155v1)

**作者:** Zimeng Wu `[一作]` (Beihang University), Yunhong Wang `[通讯]` (Beihang University)

**通讯引用:** 13775 | [OpenAlex ID](https://openalex.org/A5115589096)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种无训练的自预测式令牌跳过框架 SPTS，用于加速长上下文 LLM 的推理。

**💡 创新点**

创新点在于：① 通过自预测信号（Partial Attention Probing 和 Low‑rank Transformation Probing）准确评估每个令牌在 MHA 与 FFN 的重要性；② 采用多阶段延迟剪枝策略动态分配令牌预算，减少冗余令牌的干扰；③ 兼顾前填充和解码阶段，实现更高的速度-准确性权衡。

**🔧 技术方法**

核心技术包括：Transformer 结构改造、轻量化注意力/前馈代理网络、低秩分解、基于注意力贡献的令牌筛选、分阶段候选令牌剪枝。

**📊 数据集**

主要使用 LongBench 数据集（17 个子任务、6 大类），并在 LLaMA‑3.1‑8B‑Instruct、Qwen2.5‑7B‑Instruct、openPangu‑Embedded‑1B‑V1.1 三大模型上进行实验。

**📈 对比分析**

与 LazyLLM、SlimInfer、GemFilter、PyramidInfer、FTP 等现有方法相比，SPTS 在 32K 上下文时 TTFT 加速 2.46×、E2E 加速 2.29×，并在 LongBench 上保持或略优于原模型的平均准确率（≈0.06%–0.85% 的提升）。

**⚠️ 局限性**

局限性：① 需要预先设定多阶段令牌预算和剪枝阈值，对不同模型/硬件可能需手工调优；② 在极端长序列或非常稀疏信息场景下，代理网络的预测误差可能增大；③ 由于采用无训练方式，某些特定任务或新模型可能无法完全复现同等效果。

---

## 483. Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access

**arXiv ID:** 2601.13134 | [PDF](https://arxiv.org/pdf/2601.13134v1)

**作者:** Heng Fang `[一作]` (KTH Royal Institute of Technology), Hossein Azizpour `[通讯]` (KTH Royal Institute of Technology)

**通讯引用:** 10501 | [OpenAlex ID](https://openalex.org/A5071284506)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文系统梳理了地球嵌入产品的生态系统，并提出三层结构（数据、工具、价值）的统一分类法；

**💡 创新点**

创新点在于提供了标准化的加载和查询接口（整合到TorchGeo中），从而打破不同嵌入格式与许可证的碎片化障碍；

**🔧 技术方法**

主要技术包括基于PyTorch的模型封装、GeoParquet/COG等云原生地理空间文件格式的支持，以及在TorchGeo中实现的检索与像素级推理流水线；

**📊 数据集**

使用了多种公开嵌入数据集（Clay、Major TOM、Earth Index、Copernicus‑Embed、Presto、Tessera、Google Satellite Embedding 等）以及对应的遥感影像源（Sentinel‑2、Landsat、Sentinel‑1、NAIP、ERA5 等）；

**📈 对比分析**

通过在TorchGeo中统一加载后，作者演示了相似度检索和土地覆被分类两类任务；在检索实验中采用余弦相似度进行 k‑NN 搜索，在分类实验中采用 k‑NN 进行像素级预测，示例表明统一接口可实现多模型、跨任务的可比性；

**⚠️ 局限性**

局限性主要体现在现有嵌入产品的分布不一致、可复现性不足、以及缺乏统一的评测基准和完整的训练细节，导致跨模型比较仍然存在一定困难。

---

## 484. Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization

**arXiv ID:** 2601.13118 | [PDF](https://arxiv.org/pdf/2601.13118v1)

**作者:** Alessandro Midolo `[一作]` (University of Catania), Massimiliano Di Penta `[通讯]` (University of Sannio)

**通讯引用:** 19707 | [OpenAlex ID](https://openalex.org/A5025099559)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过自动化的迭代优化与人工分析，系统性地提出并验证了十条针对大型语言模型代码生成的提示优化准则，旨在帮助开发者构造更有效的零射提示；

**💡 创新点**

创新点在于：①使用基于测试驱动的自动化迭代过程来生成改进后的提示，从而客观挖掘改进要素；②将所提准则在50名从业者中进行实证验证，评估使用频率与感知价值；

**🔧 技术方法**

技术主要包括：大语言模型（GPT‑4o‑mini、Llama 3.3 70B、Qwen2.5 72B、DeepSeek Coder V2）在代码生成与提示优化的自动交互；人工差分对比与双人审查；问卷调查；

**📊 数据集**

数据集涵盖三大 Python 代码生成基准：BigCodeBench、HumanEval+ 与 MBPP+；此外使用实验室生成的提示与错误日志做为分析材料；

**📈 对比分析**

比较方法：对比原始提示与优化后提示在基准测试中的通过率；通过率提升幅度为：在所有模型中平均约 50‑60 % 的任务从“始终失败”转为“通过”；

**⚠️ 局限性**

局限性包括：仅针对 Python；基准任务与模型限制可能影响结果普适性；评估依赖自我报告的使用与感知，缺乏客观执行效果测量；

---

## 485. Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement

**arXiv ID:** 2601.13100 | [PDF](https://arxiv.org/pdf/2601.13100v1)

**作者:** Aaron R. Flouro `[一作]`, Shawn P. Chadwick `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `8d10c613-917e-4880-9716-17789f50e119`

**🎯 论文内容**

提出递归元蒸馏的公理化框架，定义元教师构造算子并在满足锚定公理的前提下证明其收敛性和唯一固定点。

**💡 创新点**

通过引入教师锚定公理与收缩分析，首次给出递归蒸馏几何收敛的理论保证，并对偏差‑方差行为给出框架性解释。

**🔧 技术方法**

运用了操作算子理论、公理化构造、KL 散度收缩、固定点分析以及 f‑散度的一般性推广。

**📊 数据集**

未涉及实验或数据集，完全基于理论推导。

**📈 对比分析**

论文未做方法对比或性能评估，侧重于形式化证明与理论保证。

**⚠️ 局限性**

局限在于缺乏经验验证、未讨论温度缩放、优化误差对收敛的影响以及在真实大规模模型中的可行性。

---

## 486. On the Reliability of Estimation Bounds in Low-SNR Bistatic ISAC

**arXiv ID:** 2601.13216 | [PDF](https://arxiv.org/pdf/2601.13216v1)

**作者:** Ataher Sams `[一作]` (University of Illinois Chicago), Besma Smida `[通讯]` (University of Illinois Chicago)

**通讯引用:** 1411 | [OpenAlex ID](https://openalex.org/A5018641453)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `a05fcc20-6870-48b1-abb6-44c47d7cde76`

**🎯 论文内容**

在双极ISAC系统中，作者研究了在低信噪比且感知接收机只能获得统计特性的情况下，角度估计精度与通信速率之间的基本权衡。

**💡 创新点**

创新点是提出使用Ziv–Zakai Bound（ZZB）代替传统的Cramér–Rao Bound（CRB）来评估低SNR下的AoA估计性能，并给出解析表达式和 Pareto 前沿，揭示了CRB在低SNR场景下的误导性。

**🔧 技术方法**

采用ZZB、CRB、BCRB、ECRB 的理论推导、均匀先验、随机多目标模型、协方差矩阵估计以及子空间联合波束成形等技术。

**📊 数据集**

通过 Monte‑Carlo 仿真（L=500，8 阵元，AoA 均匀分布在 ±30° 或 ±60° 的多目标场景）验证结果，未使用公开数据集。

**📈 对比分析**

与CRB、先验界限及最大似然估计器比较，结果显示 ZZB 在低SNR 时更紧致、与 ML 接近；在高SNR 时收敛于 CRB，体现了更合理的通信-感知 Pareto 前沿。

**⚠️ 局限性**

局限在于仅考虑单用户、单目标或均匀先验的理想化场景，未验证非均匀分布、多用户、多频段以及实际硬件效应对性能的影响。

---

## 487. An AMP-Based Asymptotic Analysis For Nonlinear One-Bit Precoding

**arXiv ID:** 2601.13214 | [PDF](https://arxiv.org/pdf/2601.13214v1)

**作者:** Zheyu Wu `[一作]` (Imperial College London), Bruno Clerckx `[通讯]` (Imperial College London)

**通讯引用:** 15057 | [OpenAlex ID](https://openalex.org/A5070530952)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

针对具有一比特DAC的MU‑MISO系统，提出并分析了一种基于凸松弛‑再量化（CRQ）的非线性一比特前向调制方案，并在大系统极限下通过近似消息传递（AMP）推导了符号误码率（SEP）的闭式表达式。

**💡 创新点**

创新点在于：①使用AMP与状态演化构建了针对CRQ方案的全新解析框架；②实现了对量化变量a和一比特信号的联合优化，摆脱了手动调参的限制；③给出了精确的SEP极限表达式，并通过该结果对传统SQUID前向调制进行系统性比较。

**🔧 技术方法**

主要技术包括：近似消息传递（AMP）算法、状态演化理论、凸松弛与量化模型、BPSK符号分布、Rayleigh衰落信道假设、Gaussian 分布与Stein 引理、符号函数的软化处理等。

**📊 数据集**

实验使用随机生成的Rayleigh衰落通道矩阵以及BPSK数据符号，设置N=128、K=δN（δ∈(0,∞)），并通过数值模拟验证理论结果。

**📈 对比分析**

通过与经典SQUID前向调制方案在相同系统配置下的仿真比较，结果表明：①理论与仿真SEP高度吻合；②通过适当调节正则化参数(ρ,λ)可实现比SQUID更低的误码率，尤其在ρ→0、λ≈0.31时性能最优。

**⚠️ 局限性**

限制与不足：①分析在ρ>0时严格成立，ρ=0的情形仅在数值上验证；②目前仅对二进制相位键控（BPSK）进行推导，尚未扩展到高阶调制；③正则化参数的最优联合设计仍是一个待解决的二维优化问题。

---

## 488. From Human to Machine Refactoring: Assessing GPT-4's Impact on Python Class Quality and Readability

**arXiv ID:** 2601.13139 | [PDF](https://arxiv.org/pdf/2601.13139v1)

**作者:** Alessandro Midolo `[一作]` (University of Catania), Massimiliano Di Penta `[通讯]` (University of Sannio)

**通讯引用:** 19707 | [OpenAlex ID](https://openalex.org/A5025099559)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文基于GPT‑4o，对100个Python类进行大规模自动重构，评估其行为一致性、代码质量和可读性；

**💡 创新点**

首次从行为、静态分析和可读性三维度系统评估LLM重构效果，并给出公开可复现的实验包；

**🔧 技术方法**

使用GPT‑4o进行类级重构，结合Flake8、Pylint、SonarCloud和Scalabrino可读性模型进行评估；

**📊 数据集**

ClassEval基准（100个Python类及其单元测试）；

**📈 对比分析**

通过对比重构前后的单元测试通过率、静态分析工具警告数量和可读性分数，发现平均通过率约84%，代码警告显著下降但可读性略降，整体性能稳定；

**⚠️ 局限性**

局限包括测试覆盖不足导致行为误判、可读性指标与人类感知不完全一致、仅针对Python且依赖GPT‑4o版本，未验证在其他语言或开源模型上的泛化。

---

## 489. Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains

**arXiv ID:** 2601.13137 | [PDF](https://arxiv.org/pdf/2601.13137v1)

**作者:** Yuan Gao `[一作]` (Minzu University of China), Xiaobing Zhao `[通讯]` (Minzu University of China)

**通讯引用:** 1736 | [OpenAlex ID](https://openalex.org/A5100773044)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一个对抗式价值一致性对齐框架，并训练出VC‑LLM模型以提升在敏感领域的价值一致性。

**💡 创新点**

创新点在于将持续预训练、指令微调与对抗训练三阶段结合，并通过攻击者-执行者-评审者（Attacker‑Actor‑Critic）生成高质量、挑战性的数据，实现对敏感领域价值的系统对齐。

**🔧 技术方法**

使用了多模态对抗训练技术：持续预训练、指令微调、基于Prompt的对抗数据生成、以及LLM评估器做过滤。

**📊 数据集**

使用了约33.7 GB中文敏感领域数据（新闻、政府文件、政策法规等）以及从公开数据集生成的对抗样本（共64,238条）。

**📈 对比分析**

通过构建中英双语价值一致性评测基准，对比了多款主流LLM（如Qwen、Llama、Baichuan、GLM、GPT‑4o 等），VC‑LLM在中英两语总分分别为836/799，平均分4.80/4.59，显著优于其他模型，尤其在宗教、政治等子领域表现突出。

**⚠️ 局限性**

局限性包括对跨文化复杂情境（如主权子域）仍存在事实与价值混合错误，且对抗训练需要依赖人工评审或额外模型，可能导致资源消耗和对齐质量波动。

---

## 490. GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning

**arXiv ID:** 2601.13132 | [PDF](https://arxiv.org/pdf/2601.13132v1)

**作者:** Kim Yu-Ji `[一作]` (Pohang University of Science and Technology), Tae-Hyun Oh `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 2670 | [OpenAlex ID](https://openalex.org/A5078114111)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出一种基于3D高斯散点（3D Gaussian Splatting）的多视角可视化语言模型框架，用于嵌入式探索与推理。

**💡 创新点**

创新点在于将VLM与3DGS结合，通过初始视点搜索、基于VLM的视点优化以及最终视点验证，实现可嵌入式的动态视角生成与精准三维定位。

**🔧 技术方法**

采用3D Gaussian Splatting构建语义高斯、VLM‑as‑Judge评估视角、差分渲染、CLIP+SAM语义嵌入、HDBSCAN聚类等技术。

**📊 数据集**

使用OpenEQA（Habitat‑Matterport/ScanNet）作为嵌入式问答基准，以及自建的5个ScanNet场景的3D定位问答数据集。

**📈 对比分析**

与BlindLLM、Frame Captions、3D‑Mem等方法对比，平均帧数约2.7帧，在LLM‑Match指标上从48.2提升至57.8，明显优于现有方案。

**⚠️ 局限性**

主要局限在于对极端遮挡或细粒度属性仍易误检，且模型高度依赖VLM导致推理延迟较高。

---

## 491. Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning

**arXiv ID:** 2601.13115 | [PDF](https://arxiv.org/pdf/2601.13115v1)

**作者:** Fengran Mo `[一作]` (University of Montreal), Meng Jiang `[通讯]` (University of Notre Dame)

**通讯引用:** 5740 | [OpenAlex ID](https://openalex.org/A5074821819)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种在多轮会话中交替进行检索与推理的agentic对话搜索框架，利用强化学习优化检索查询、利用检索结果生成答案并具备混合主动行动能力（如澄清、拒绝回答）

**💡 创新点**

创新点在于将检索优化奖励与混合主动行动奖励作为中间奖励拆分并联合训练，实现对话上下文中的检索查询生成、检索结果利用以及行动决策的统一优化；并首次在多轮会话中引入信息增益奖励提升检索结果与答案的一致性

**🔧 技术方法**

技术包括：大语言模型基于Qwen系列的策略网络、Group Relative Policy Optimization (GRPO)强化学习、检索-增强生成（RAG）框架、信息增益奖励与混合主动行动奖励设计、检索器E5、LLM-as-a-Judge评估

**📊 数据集**

使用四个公开多轮对话搜索基准数据集：TopiOCQA、INSCIT、QReCC、CORAL

**📈 对比分析**

与传统分离检索-生成管线（ChatQA、UniConv、EvoRAG等）以及其他agentic系统（Search-R1、AgenticLM、ChatR1）比较，实验表明在答案生成（F1、EM、LLM-judge）和检索质量（NDCG@3、InfoGain）上均取得领先或接近最优的成绩，7B/7B模型在多轮任务上更具优势

**⚠️ 局限性**

主要局限：RL训练和推理成本高，未在更大或不同类型LLM上验证，奖励权重和超参数未做充分探索，混合主动行动在无标注数据集上效果有限

---

## 492. IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks

**arXiv ID:** 2601.13114 | [PDF](https://arxiv.org/pdf/2601.13114v1)

**作者:** Abdelrahman Soliman `[一作]` (University of Guelph), Amr Mohamed `[通讯]` (Qatar University)

**通讯引用:** 8777 | [OpenAlex ID](https://openalex.org/A5021329808)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

提出并实现了 IntAgent，一种基于 LLM 的意图驱动网络管理框架，结合 NWDAF 的实时分析与工具发动机，实现网络运营商高层意图的自动化执行。

**💡 创新点**

创新点在于将意图工具引擎嵌入 NWDAF 分析层，使 LLM 能实时利用标准化网络遥测；通过 MCP 协议统一工具调用；并提供丰富的 3GPP 合规数据源和安全性检查机制。

**🔧 技术方法**

采用 Meta Llama 3.1 LLM 与 Ollama 本地推理、MCP（Model Context Protocol）工具集成、NWDAF 的事件暴露服务、MongoDB 数据存储、Open5GS/K8s 核心网络、UERANSIM 仿真、DeepSeek‑R1 代码生成等技术。

**📊 数据集**

使用自建的 Open5GS 网络收集的 UPF、PCF、SMF 事件日志与遥测数据；在用例中使用了 500 条近似内存利用率样本及模拟 UE 流量数据；全部为内部网络数据，无公开数据集。

**📈 对比分析**

通过两个实际用例验证：①机器学习预测用例得到随机森林回归模型，R²≈0.75；②按时段调度数据速率提升 20%，成功实施；在模拟流量峰值下监测到系统保持低延迟、吞吐量和信令开销稳定。

**⚠️ 局限性**

主要局限是 LLM 仍存在幻觉问题，导致需人工确认；复杂的计划‑执行‑观察循环使简单任务产生过多步骤；对模型进行域知识微调及更严格的安全检查仍待完善。

---

## 493. Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision

**arXiv ID:** 2601.13217 | [PDF](https://arxiv.org/pdf/2601.13217v1)

**作者:** Bingsen Chen `[一作]` (New York University), Chen Zhao `[通讯]` (New York University)

**通讯引用:** 2077 | [OpenAlex ID](https://openalex.org/A5100351992)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了多轮报告修订评估框架，统一了深度研究代理（DRA）长文本报告的评价维度，并构建了人类验证的用户反馈模拟管线，用于评估DRA在多轮交互中对反馈的响应与质量保持情况。

**💡 创新点**

创新点在于：①把多轮修订视为评估DRA的关键维度；②将先前分散的评价指标聚合为三维度（全面性、事实性、呈现性）形成统一协议；③设计了基于检查表和人类标注的反馈生成器，实现逼真的多轮反馈场景；④系统性评测五种不同架构的DRA，揭示其在修订时内容回退与引用质量下降的普遍问题。

**🔧 技术方法**

主要技术包括：LLM评判器（覆盖度、事实性、呈现性）；基于检查表的分层评分；人工验证的反馈生成器（内容、格式、自我反思三类反馈）；以及对比实验的多轮修订指标（引入率、破坏率、全史引入率）。

**📊 数据集**

使用了 ResearchRubrics、RigorousBench 和 ResearcherBench 三个公开数据集，包含专家标注的研究问题与对应的检查表，并在核心子集（25题/数据集）上进行多轮实验。

**📈 对比分析**

对比方法：在三类反馈（自我反思、内容反馈、格式反馈）和多轮情景下，五种DRA（OpenAI DR、Sonar DR、LC ODR、Tongyi DR、DR Tulu）被评估。实验显示：①覆盖度大多在第二轮下降；②尽管引入率超过90%，但破坏率在20–30%之间；③多轮修订无法逼近理论最优轨迹，Gap在9%–26%；④通过提示工程或专门的修订子代理可略幅提升，但仍无法消除引用质量下降。总体而言，现有DRA在可靠修订方面表现欠佳。

**⚠️ 局限性**

局限性包括：①未系统剖析破坏率与引用下降的根本原因；②未评估模型规模对修订能力的影响；③反馈模拟依赖高质量检查表，可能对低质量或不完整的检查表不鲁棒；④评估未考虑报告长度成本，导致长文本DRA在覆盖度上表现偏高。

---

## 494. Negotiating Relationships with ChatGPT: Perceptions, External Influences, and Strategies for AI Companionship

**arXiv ID:** 2601.13188 | [PDF](https://arxiv.org/pdf/2601.13188v1)

**作者:** Patrick Yung Kang Lee `[一作]` (University of Toronto), Carolina Nobre `[通讯]` (University of Toronto)

**通讯引用:** 929 | [OpenAlex ID](https://openalex.org/A5034150082)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对使用通用聊天机器人（如 ChatGPT、Claude 等）进行情感陪伴的人类关系进行了系统研究，探讨了人们如何概念化伴侣身份、受外部因素（模型更新、平台安全防护、社群与社交圈）影响，以及如何通过“导向策略”来创建、维护和恢复关系。

**💡 创新点**

创新点在于：①首次将内部动态、外部影响与导向策略三角视角整合到通用 AI 同伴关系研究中；②通过多源数据（Reddit 讨论、问卷与深度访谈）实现数据三角验证；③揭示模型更新和安全防护对情感连结的冲击与用户自发的迁移/自定义策略。

**🔧 技术方法**

采用的技术包括：BERTopic 主题建模、Interrupted Time Series（ITS）情绪与主题趋势分析、K‑Means+UMAP 聚类、定性主题编码与人工审阅；同时结合 LLM 生成的情感评分（VAD）来量化社群情绪。

**📊 数据集**

使用的数据集为：41,867 条 r/MyBoyfriendIsAI 论坛帖子与评论（约 41k+ 条），43 份高质量问卷样本，以及 13 份半结构化访谈记录。

**📈 对比分析**

比较方法：通过 ITS 分析 GPT‑5 发布前后社区情绪与主题分布变化；使用 Mann‑Whitney U 检验外部影响因素重要性；利用聚类结果展示三类用户导向策略。由于研究重点为人类体验与行为，未涉及模型性能度量，主要以定性与情感量化指标（如情绪极性变化）评估结果。

**⚠️ 局限性**

局限性包括：①样本主要来自 WEIRD 社群，缺乏跨文化多样性；②Reddit 与问卷数据自选偏倚可能影响普适性；③研究方法多样但难以建立因果关系；④对 AI 系统技术细节（如模型内部机制）未深入挖掘，无法直接指导模型改进。

---

## 495. Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching

**arXiv ID:** 2601.13186 | [PDF](https://arxiv.org/pdf/2601.13186v1)

**作者:** Diego Gosmar `[一作]` (Tesisquare), Deborah A. Dahl `[通讯]` (Conversational Technologies)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在多代理架构中引入了HOPE启发的Nested Learning与语义缓存，构建了可实时、低成本、绿色的注入防御管道。

**💡 创新点**

创新点在于：①把语义相似缓存与多级内存系统（MTM/LTM）结合，实现跨阶段知识迁移；②扩展TIVS为TIVS‑O，加入可观测性指标OSR；③通过极度可观测配置实现安全与透明度的双提升。

**🔧 技术方法**

采用多模语言模型（前端使用Llama 2，后端使用Llama 3.1，评估者使用Claude Sonnet 4.5），全流程交互通过Open Floor Protocol；缓存基于all‑MiniLM‑L6‑v2语义向量，阈值τ=0.87；内存管理采用LRU/LFU。

**📊 数据集**

评估数据集为301条合成注入攻击样本，涵盖10个攻击族群（覆盖直接覆盖、权威假装、角色扮演、逻辑陷阱等）。

**📈 对比分析**

与无缓存、仅MTM或原四指标TIVS系统对比，TIVS‑O平均得分提升约0.045（-0.521 vs -0.476），安全率提升至84.4%，高危率为0，缓存命中率41.6%，导致LLM调用量减少41.6%并使推理时延从约9 s降至150 ms，成本与能耗也随之降低。

**⚠️ 局限性**

局限包括：①评估样本为人工合成，未覆盖真实攻击变体；②语义阈值选取经验性，可能对其他领域或嵌入模型不适用；③评估器为LLM，存在偏差，需与规则或人工评估交叉验证；④嵌入模型未针对安全任务微调，可能导致语义漂移。

---

## 496. NeuroShield: A Neuro-Symbolic Framework for Adversarial Robustness

**arXiv ID:** 2601.13162 | [PDF](https://arxiv.org/pdf/2601.13162v1)

**作者:** Ali Shafiee Sarvestani `[一作]` (University of Illinois Chicago), Arman Roohi `[通讯]` (University of Illinois Chicago)

**通讯引用:** 1303 | [OpenAlex ID](https://openalex.org/A5077392159)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `6215c339-3735-4be3-8a07-5bbb7004712d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

开发了一种神经符号框架，通过在训练中加入符号规则监督，提升交通标志识别模型的可解释性和对抗鲁棒性。

**💡 创新点**

创新点在于提出联合符号逻辑损失与自适应权重调节，使网络在对抗样本下保持符号一致性，并且仅需10个epoch即可训练完成。

**🔧 技术方法**

使用了改进的 ResNet18 共享骨干、轻量化 MLP 符号头、软逻辑与语义损失、FGSM/PGD 对抗训练及可自适应的逻辑权重。

**📊 数据集**

实验数据集为 GTSRB（德国交通标志识别基准）。

**📈 对比分析**

与标准对抗训练和 Transformer LNL‑MoEx 等基线对比；PGD‑Neuro‑Symbolic 在 PGD 攻击下取得 56% 准确率、FGSM 65.8%，同时保持 98% 的清洁准确率，训练周期仅10个epoch，效率低于 ViT 方案。

**⚠️ 局限性**

局限性包括仅依赖静态符号规则，缺乏链式推理；对大扰动（ε=0.5）PGD训练不收敛；推理时仍比普通对抗训练略高的计算开销，且未在边缘设备上验证。

---

## 497. FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference

**arXiv ID:** 2601.13143 | [PDF](https://arxiv.org/pdf/2601.13143v1)

**作者:** Chaeyoung Jung `[一作]` (Korea Advanced Institute of Science and Technology), Joon Son Chung `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 10153 | [OpenAlex ID](https://openalex.org/A5038723822)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出FastAV，一种针对音视频大型语言模型的两阶段token裁剪框架；

**💡 创新点**

首次系统分析音视频token的重要性，并结合attention rollout与last-query重要性实现全局裁剪与细粒度裁剪；

**🔧 技术方法**

使用attention rollout评估token影响，采用残差融合的attention矩阵；在细粒度裁剪中利用last-query注意力得分进行逐层裁剪；

**📊 数据集**

在VideoLLaMA2和video-SALMONN2两个模型上，使用AVQA、MUSIC-AVQA与AVHBench三大数据集进行评测；

**📈 对比分析**

与原始模型、随机裁剪、top‑attentive等策略对比，FastAV在保持或提升准确率的同时，理论FLOPs下降40%以上、推理速度提升约30%，内存使用亦显著降低；

**⚠️ 局限性**

局限在于裁剪比例需经验调参，裁剪策略对不同模型的通用性和对极长视频的适应性尚待进一步验证。

---

## 498. TVWorld: Foundations for Remote-Control TV Agents

**arXiv ID:** 2601.13142 | [PDF](https://arxiv.org/pdf/2601.13142v1)

**作者:** Zhantao Ma `[一作]`, Michael K. Ng `[通讯]` (Hong Kong Baptist University)

**通讯引用:** 28748 | [OpenAlex ID](https://openalex.org/A5010561682)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了 TVWorld 这一离线图形化电视导航基准，并基于该基准设计了两套评测任务（TVWorld‑N 与 TVWorld‑G）。

**💡 创新点**

创新点在于：①将远程遥控电视交互抽象为有限图搜索，解决点与点击（PnC）不适用的焦点导航问题；②提出两阶段拓扑感知训练框架（Topology‑Aware Training），通过结构化推理示例和图拓扑奖励提升 LVLM 对焦点与长程导航的理解；③开发了专用电视导航基础模型 TVTheseus 并取得 SOTA 结果。

**🔧 技术方法**

使用了基于 Qwen3‑VL‑8B‑Instruct 的大型视觉语言模型，辅以监督微调（含三类推理示例）和后续的强化学习（GRPO），并在图结构上设计了基于到达时间的距离奖励。

**📊 数据集**

数据集为 TVWorld：由 TCL 与 Google TV 设备通过 BFS 收集得到的 6 条离线导航图，包含 5 种场景（Config、Display、Audio、Apps、Channels），共 5,000 个起止任务与 187 条焦点定位标注。

**📈 对比分析**

与闭源模型 Gemini‑3 Flash、GPT‑5 mini 以及多款开源 LVLM（Qwen3‑VL‑32B‑Instruct、UI‑Tars‑1.5‑7B 等）对比，TVTheseus 在 TVWorld‑N 上取得 68.3% 的成功率（对比基线 20.0%），并在 TVWorld‑G 上实现 81.8% 的 IoU@0.5，显著优于所有对手。

**⚠️ 局限性**

局限性包括：仅在 8‑B 级模型规模实验，未探讨更大模型的规模效应；图构建过程中对敏感系统入口做了屏蔽，导致生成图与真实电视部署略有差异。

---

## 499. CODE: A Contradiction-Based Deliberation Extension Framework for Overthinking Attacks on Retrieval-Augmented Generation

**arXiv ID:** 2601.13112 | [PDF](https://arxiv.org/pdf/2601.13112v1)

**作者:** Xiaolei Zhang `[一作]` (Southeast University), Songze Li `[通讯]` (Southeast University)

**通讯引用:** 2711 | [OpenAlex ID](https://openalex.org/A5085853632)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种通过向检索增强生成系统的知识库注入对抗文本来诱导大型推理模型出现过度推理（overthinking）攻击的方法。

**💡 创新点**

创新点在于将对抗样本的构造与跨层矛盾设计、冲突织造、风格适配三阶段协同生成框架（Contradiction-Based Deliberation Extension，CODE）相结合，实现黑盒环境下的无侵入式、可扩展的过度推理攻击。

**🔧 技术方法**

技术主要包括多代理文本生成（矛盾构造器、冲突织造器、风格适配器）、检索相关性匹配、演化优化风格改写、以及对抗样本的可检索性与逻辑一致性验证。

**📊 数据集**

实验使用了 HotpotQA 和 MuSiQue 两个动态数值推理问答数据集，采样各200条多跳问题。

**📈 对比分析**

与多种现有对抗与防御方案（如 CCoT、CoD、Taleep、TrustRAG）对比，CODE 在保持答案准确率不降的前提下，令推理 token 数量平均提升 5.32×~24.72×，任务级别提升 12.7×~43.5×，展示出明显的推理成本放大效果。

**⚠️ 局限性**

限制包括：需要一定的检索相关性才能注入对抗文本，且对抗样本的生成依赖于多代理协同，可能导致对特定模型或检索器的适配性差；对抗文本在实际知识库中的长期维护和更新仍是挑战。

---

## 500. GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction

**arXiv ID:** 2601.13207 | [PDF](https://arxiv.org/pdf/2601.13207v1)

**作者:** Jinnao Li `[一作]`, Changbo Wang `[通讯]` (East China Normal University)

**通讯引用:** 1269 | [OpenAlex ID](https://openalex.org/A5063110936)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建了 GTPred 基准，用于评估多模态大语言模型在图像的地理定位与拍摄时间预测上的能力，并提出了结合时间区间与层级地点匹配的可解释评估协议。

**💡 创新点**

创新点包括：①首次将时间信息与层级地理信息统一纳入评估；②提供覆盖 120 年、370 张图像、79 国、94 州、186 城、125 细粒地点的全新数据集；③设计了可解释的推理过程评分和层级加权得分。

**🔧 技术方法**

技术手段为：使用多模态大语言模型（OpenAI、Gemini、Grok、Qwen、InternVL 等）进行推理；利用 GPT‑5.1 自动提取标签并评估推理过程；采用时间区间 IoU 与层级加权匹配得分进行综合评估。

**📊 数据集**

数据集为 GTPred：370 张图像，来源于 TimeGuessr Explained，涵盖 79 个国家、94 个州、186 个城市、125 个细粒地点，时间跨度超过 120 年。

**📈 对比分析**

评估方法为将最终答案分数与推理过程分数相乘得到总分；对 15 款 MLLM 进行对比，专有模型平均在 geo‑localization 上得分 0.85、time‑prediction 0.88，开源模型相差约 0.15–0.3，显示专有模型在时空推理上明显占优；引入时间信息后，定位准确率显著提升。

**⚠️ 局限性**

局限性在于：公开模型在世界知识与多步推理方面表现有限；时间与空间信息对模型提升不对称；数据规模虽然庞大但仍未覆盖所有细粒点；评估仅在离线环境下进行，未考虑检索等外部资源。

---

## 501. Scientific production in the era of Large Language Models

**arXiv ID:** 2601.13187 | [PDF](https://arxiv.org/pdf/2601.13187v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `f53a5690-f5d8-493f-989c-dc46a1f99053`

---

## 502. Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues

**arXiv ID:** 2601.13206 | [PDF](https://arxiv.org/pdf/2601.13206v1)

**作者:** Neil K. R. Sehgal `[一作]` (University of Pennsylvania), Lyle Ungar `[通讯]` (University of Pennsylvania)

**通讯引用:** 30279 | [OpenAlex ID](https://openalex.org/A5044944954)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究大型语言模型在实时多轮谈判中对持续时间的感知能力，发现缺乏显式时间反馈会导致谈判失败。

**💡 创新点**

提出将持续时间意识作为LLM评估的新维度，并用模拟谈判框架分离时间感知与策略能力。

**🔧 技术方法**

使用多模型（GPT-5.1、GPT-4.1、Claude 4.5、Qwen3-8B 等）与时间反馈、紧急提示等不同提示技术。

**📊 数据集**

使用人工构造的多议题招聘谈判情景和“Rubbermind”情景的支付表作为实验数据。

**📈 对比分析**

通过对比时间限制与轮次限制、控制组与时间感知组的成约率，发现时间反馈可将成约率从 4% 提升至 32%，而轮次限制下几乎达到 100%。

**⚠️ 局限性**

局限在于仅使用模拟双人谈判、缺乏人类基准、未探究更长时限或多方情境，并未验证模型内部时间编码的具体机制。

---

## 503. The Achilles' Heel of Angular Margins: A Chebyshev Polynomial Fix for Speaker Verification

**arXiv ID:** 2601.13198 | [PDF](https://arxiv.org/pdf/2601.13198v1)

**作者:** Yang Wang `[一作]`, Chenghua Lin `[通讯]`

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出 ChebyAAM 损失函数，用 Chebyshev 多项式逼近 arccos，替代 AAM‑Softmax 中的三角函数，解决梯度爆炸并提升对难分样本的惩罚力度。

**💡 创新点**

创新点在于将 arccos 的不连续梯度问题转化为可控的多项式逼近，既消除梯度爆炸，又提供更陡峭的梯度，增强训练稳定性与性能。

**🔧 技术方法**

采用 Chebyshev 多项式展开与 Clenshaw 递推求值、梯度与 Hessian 的解析形式，并在 ECAPA‑TDNN、CAM++、SimAMResNet34 等网络上实现。

**📊 数据集**

使用 VoxCeleb2 训练集，评估数据包括 VoxCeleb1‑O/E/H、SITW core‑core/multi 与 CN‑Celeb1‑Eval。

**📈 对比分析**

与 A‑Softmax、AM‑Softmax、AAM‑Softmax 等基线比较，ChebyAAM 在 EER 与 mDCF 指标上均表现更佳，尤其在 SITW 等更具挑战性的场景中提升显著。

**⚠️ 局限性**

对多项式阶数敏感，高阶逼近可能导致正则化效果消失；实验聚焦说话人验证，未验证其在其他任务或更大模型上的通用性。

---

## 504. LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations

**arXiv ID:** 2601.13190 | [PDF](https://arxiv.org/pdf/2601.13190v1)

**作者:** Vittoria De Pellegrini `[一作]` (King Abdullah University of Science and Technology), Tariq Alkhalifah `[通讯]` (King Abdullah University of Science and Technology)

**通讯引用:** 11658 | [OpenAlex ID](https://openalex.org/A5032021877)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

设计并训练了一个潜在自回归视频扩散模型LAViG-FLOW，用于预测CO2注入下的饱和度和压力场随时间演化的视频。

**💡 创新点**

同时对两物理耦合状态变量建立独立潜在空间并通过拼接进入单一VDiT学习联合分布，随后使用自回归微调实现超越训练窗口的预测，且比传统数值模拟快数百倍。

**🔧 技术方法**

采用2D VQ‑VAE与VAE进行压缩，利用Video Diffusion Transformer（VDiT）学习联合分布，并在自回归阶段进行微调；辅以时间步正则化、梯度截断、LPIPS感知损失等技术。

**📊 数据集**

使用公开的CO2地质封存数据集（ECLIPSE 2D径向对称储层，96×200 网格，30年注入，约5500个模拟）。

**📈 对比分析**

与ECLIPSE CPU模拟比较，生成时间从约10分钟降至1–2秒，误差指标（MSE、MAE、RMSE）随预测步长略升但仍处于可接受范围；视频质量指标（SSIM、PSNR、LPIPS、FVD）保持优良。

**⚠️ 局限性**

局限包括时间嵌入为固定绝对位置，无法表达时间偏移；时间步稀疏导致缺失细粒度演化；未加入注入速率等物理控制；预训练阶段耗时长、显存占用大。

---

## 505. Optimistic Imprecise Shortest Watchtower in 1.5D and 2.5D

**arXiv ID:** 2601.13165 | [PDF](https://arxiv.org/pdf/2601.13165v1)

**作者:** Bradley McCoy `[一作]` (James Madison University), Binhai Zhu `[通讯]` (Montana State University)

**通讯引用:** 2341 | [OpenAlex ID](https://openalex.org/A5070925973)

**关键词:** `a42c7bd6-d8fd-40d3-94df-ae8cd808f5c4` `5b4c1114-4a70-478e-9921-2514ee03850d` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文研究了不确定地形（1.5D 与 2.5D）下的最优短距离观测塔问题，提出了 1.5D 情况的线性时间解法，并给出了 2.5D 离散版本的加法近似方案。

**💡 创新点**

创新点在于：①首次在 1.5D 模型中实现了线性时间的最优解；②将 2.5D 问题转化为多次 0-观测塔检验，从而得到一个运行时间为 O(OPT/ε n³) 的加法近似算法。

**🔧 技术方法**

主要技术包括：对不确定区间进行规范化到 O(n) 个典型实例；利用可视多边形和最短路径性质将问题降维；对 2.5D 进行逐顶点的可视性分析与半平面交叉检测。

**📊 数据集**

本文未使用公开数据集，而是以理论模型（离散点集和三角网）为实验基础，通过实验演示验证算法的正确性与复杂度。

**📈 对比分析**

与传统的 1.5D 精确地形观测塔算法相比，线性时间实现大幅提升；与 2.5D NP‑难性已知的最短路径方法相比，近似方案在误差可控的前提下实现了可接受的性能，但未达到 PTAS 水平。

**⚠️ 局限性**

局限性包括：① 2.5D 情况下仍未得到多项式时间精确解；② 近似方案的运行时间依赖于 OPT，且对输入规模增长时不具备可扩展性；③ 仅覆盖离散版观测塔，连续版 2.5D 尚未得到完整处理。

---

## 506. OPTIMUM-DERAM: Highly Consistent, Scalable, and Secure Multi-Object Memory using RLNC

**arXiv ID:** 2601.13146 | [PDF](https://arxiv.org/pdf/2601.13146v1)

**作者:** Nicolas Nicolaou `[一作]` (Optimum), Sriram Vishwanath `[通讯]` (Georgia Tech)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

本文提出了一种面向 Web3 的分布式共享内存（DeRAM）系统，利用随机线性网络编码实现原子读写操作，并支持多对象、动态节点加入/离开与拜占庭容错；

**💡 创新点**

创新点包括：1）在共享内存中采用 RLNC 以减少通信与存储开销并提升容错；2）结合一致性哈希与 Kademlia DHT 实现对象分布与动态发现；3）使用区块链注册表实现节点参与的安全动态管理；4）采用签名与拜占庭量子集合的模块化 DAP 设计；5）实现多对象、动态的原子共享内存并兼顾拜占庭读写的安全性；

**🔧 技术方法**

主要技术手段包括：随机线性网络编码（RLNC）、一致性哈希、Kademlia 路由、区块链/SMR 注册表、数字签名、拜占庭容错量子集合、以及基于 DAP 的原子读写协议；

**📊 数据集**

实验使用了 52 台分布在 Google 云平台不同数据中心的虚拟节点，配合 MWABD 基准测试，评估了对象大小（32 KB–16 MB）、对象数量（1–1 000）、节点数量（13–52）、并发读写量（10–400 读/100 写）等多维度场景；

**📈 对比分析**

通过与 MWABD 全复制和 MWABD 5 节点集群的对比，DeRAM 在大对象场景下读写延迟降低 25–50%，在节点数、并发量增加时延迟保持稳定，内存占用相较全复制方案下降约 20%–30%；

**⚠️ 局限性**

局限性包括：仅对拜占庭写入节点提供安全保证，读者仍可能攻击；缺乏对动态重编码参数的支持；标签空间可能耗尽；对网络分区的鲁棒性未充分评估；以及在极大规模集群中可能仍面临节点发现与一致性延迟的挑战。

---

## 507. CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks

**arXiv ID:** 2601.13133 | [PDF](https://arxiv.org/pdf/2601.13133v1)

**作者:** Mingshuang Luo `[一作]` (Chinese Academy of Sciences), Shiguang Shan `[通讯]` (Chinese Academy of Sciences)

**通讯引用:** 33966 | [OpenAlex ID](https://openalex.org/A5050297728)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `afceb026-1760-41ae-8d86-010831a37d97` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了CLASP框架，利用CLIP生成多层伪标签并结合Prompt‑Controlled Mixture‑of‑Experts实现人类中心视觉任务的统一无监督预训练；

**💡 创新点**

创新点包括：①使用CLIP自动生成低层部位和高层属性伪标签；②引入可学习提示控制的MoE模块，实现任务感知的特征分离；③将对比学习与伪标签监督相结合，提升多任务泛化；

**🔧 技术方法**

主要技术包括：DINO对比学习、CLIP图像与文本编码、k‑means多粒度聚类、Prompt‑Controlled MoE、交叉熵/二元交叉熵损失、负载平衡等；

**📊 数据集**

预训练使用大规模无标签LUPerson；下游实验覆盖Market‑1501、MSMT17、PETA、PA100k、LIP、CUHK‑SYSU、PRW、CityPerson、COCO等；

**📈 对比分析**

与现有方法相比，CLASP在所有任务上均取得或接近SOTA，显著提升ReID、属性识别、人体解析、行人检测等指标，同时GCR下降、EAD上升，训练时间与参数增长低于10%；

**⚠️ 局限性**

局限性包括：对不同任务的伪标签有一定的互斥影响（部位标签提升解析但略降ReID）；对聚类数、专家数等超参敏感；仅针对图像任务，且高性能可能带来隐私风险。

---

## 508. PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain

**arXiv ID:** 2601.13128 | [PDF](https://arxiv.org/pdf/2601.13128v1)

**作者:** Sung Ju Lee `[一作]`, Nam Ik Cho `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种名为 PhaseMark 的后置式水印框架，利用 VAE 潜在频域中的相位调制在单次操作中实现水印嵌入与提取。

**💡 创新点**

创新点在于不依赖迭代优化或模型反演，直接对潜在频域相位进行硬/软调制，构建四种变体并引入轴偏移与 Hermitian 对称性，以实现性能与图像质量的可调权衡。

**🔧 技术方法**

技术核心包括 VAE 编码/解码、二维 FFT、相位调制（APM、PCQ、IPS、SPS）、Hermitian 对称性约束、轴偏移与线性插值。

**📊 数据集**

使用 Stable Diffusion v2‑1‑base 生成的 1,000 张 512×512 图像，提示来源于 MS‑COCO‑2017、SD‑Prompts 与 DiffusionDB 等数据集进行实验。

**📈 对比分析**

与 DwtDctSvd、RivaGAN、ZoDiac 等现有后置与生成式水印方法比较，在对比、JPEG、模糊、VAE 再生成、裁剪等攻击下，TPR@1%FPR 最高达 0.999，图像质量 ΔFID‑1k 仅 +0.042，嵌入/检测时间分别为 0.142 s 与 0.050 s，显著快于 ZoDiac 的 7 min。

**⚠️ 局限性**

局限性包括：仅针对基于 VAE 的 LDM 进行设计，对其他生成模型迁移性未知；水印容量上限为 128 位；在极端高噪声或重编码环境下仍可能出现检测下降。

---

## 509. xBound: Join Size Lower Bounds

**arXiv ID:** 2601.13117 | [PDF](https://arxiv.org/pdf/2601.13117v1)

**作者:** Mihail Stoian `[一作]` (University of Technology Nuremberg), Andreas Kipf `[通讯]` (University of Technology Nuremberg)

**通讯引用:** 1022 | [OpenAlex ID](https://openalex.org/A5046188245)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了第一个可证明的联接大小下界框架，能够检测并纠正数据库优化器的基数低估。

**💡 创新点**

利用反向点乘不等式与ℓ_p范数，并结合键的最小/最大值、分区统计和范数拼接技术，首次给出严谨的下界。

**🔧 技术方法**

逆向点乘不等式（Pólya–Szegő、逆 Hölder）、ℓ_p范数统计、键值区间（zonemap）、分区统计、范数拼接技术，以及等价/范围谓词的支持。

**📊 数据集**

JOB、STATS‑CEB、Microsoft 内部生产工作负载（Fabric DW 10% 样本）等基准数据集。

**📈 对比分析**

与 DuckDB 1.4、PostgreSQL 18、Fabric DW 的传统估算器及最新上界估算器进行对比；xBound 能发现约10–15% 的下界违规，且通过下界剪裁将单边 Q‑误差显著降低，估算时间与传统估算器相近。

**⚠️ 局限性**

仅支持 Berge‑acyclic 同键多路连接、无复杂谓词；需要事先获取键的最小/最大值，分区统计与范数拼接会带来一定开销，对动态更新的增量维护尚未完全优化。

---

## 510. CORE-T: COherent REtrieval of Tables for Text-to-SQL

**arXiv ID:** 2601.13111 | [PDF](https://arxiv.org/pdf/2601.13111v1)

**作者:** Hassan Soliman `[一作]` (Ubiquitous Knowledge Processing Lab), Iryna Gurevych `[通讯]` (Ubiquitous Knowledge Processing Lab)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种名为CORE-T的训练免费框架，用于在开放式多表文本到SQL检索中，先通过LLM生成表目的元数据并预计算轻量级表兼容缓存，再在推理时用一次LLM选择连贯的表子集并进行小幅增量调整，从而获得既相关又可连接的表集合。

**💡 创新点**

核心创新点在于（1）将表理解任务离线完成：利用LLM对每张表生成简短的用途描述，显著提升表语义表征；（2）构建无监督的表间兼容缓存，模拟主键–外键连接；（3）在线阶段仅使用一次LLM调用进行子集选择，避免多轮交互或昂贵的MIP求解，兼顾精确度和效率。

**🔧 技术方法**

技术包括稠密检索（FAISS索引 + UAELargeV1嵌入）、LLM生成表用途（Llama3.1-8B或Qwen2.57B）、兼容性评分（列头相似度、值重叠、唯一性与子集关系）、单次LLM选择（基于提示工程的JSON输出）以及增量恢复（基于缓存的阈值选择）。

**📊 数据集**

使用公开的Bird、Spider和MMQA三大多表SQL基准，所有数据集均按开放式书本设置合并多数据库表并去除数据库标识。

**📈 对比分析**

相较于传统的DR、DRR、ReAct、JAR和ARM，CORE-T在Bird、Spider、MMQA上分别提升表检索F1最多22.7点、减少约42%的表数量，并在多表执行准确率上提升5.0点（Bird）至6.9点（MMQA）；同时使用约4–5倍更少的LLM tokens，显著降低成本。

**⚠️ 局限性**

局限性包括：仅在有限的英文基准上评估；兼容缓存仅覆盖键–外键式连接，可能忽略非等值、自动连接或多跳连接；对稀疏或受限值表的推断效果未知；在高度嘈杂或多语言环境中的表现仍待验证。

---

## 511. Exploring the Impacts of Background Noise on Auditory Stimuli of Audio-Visual eHMIs for Hearing, Deaf, and Hard-of-Hearing People

**arXiv ID:** 2601.13098 | [PDF](https://arxiv.org/pdf/2601.13098v1)

**作者:** Wenge Xu `[一作]` (Birmingham City University), Mark Colley `[通讯]` (UCL Interaction Centre)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

通过虚拟现实模拟，比较了安静与嘈杂背景噪声下，不同听力人群（听力正常、聋人/耳聋）对音频‑视觉电子人机界面（eHMI）信任、安全感、认知负荷及跨行行为的影响。

**💡 创新点**

首次系统评估背景噪声对聋人/耳聋用户的听觉eHMI可感知性及其对体验的影响，并给出多模态eHMI设计的四条实用建议。

**🔧 技术方法**

采用Unity3D虚拟现实环境、Varjo XR‑4 HMD、眼动追踪与Cyberith Virtualizer平台，结合AVAS、轮胎噪声、贝铃声与语音提示实现eHMI；实验采用交叉设计、非参数统计（nparLD）分析。

**📊 数据集**

实验使用自收集的30名参与者数据（25正常听力、11聋/耳聋）与合成音频背景噪声（58/70 dB）及三种听觉刺激（基线、铃声、语音）。

**📈 对比分析**

通过非参数方差分析和事后Bonferroni校正对信任、使用感、可用性、安全感、工作负荷等主观量表以及眼动、跨行时长等客观指标进行比较；结果显示背景噪声降低信任、可用性和安全感，铃声/语音提升体验，但对跨行行为影响不显著。

**⚠️ 局限性**

样本量偏小，尤其聋人/耳聋组仅11人；实验场景受限为单一无信号交叉点，缺乏真实交通环境与突发噪声；未探索其他辅助模态（触觉）或多语言/不同听力助听设备的适配。

---

## 512. Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification

**arXiv ID:** 2601.13197 | [PDF](https://arxiv.org/pdf/2601.13197v1)

**作者:** Aravind B `[一作]` (Amrita Vishwa Vidyapeetham), Mohankumar N `[通讯]` (Amrita Vishwa Vidyapeetham)

**通讯引用:** 516 | [OpenAlex ID](https://openalex.org/A5101703114)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `67630363-6be0-4f51-ab05-7198250671a5` `3855fcda-48ef-4070-a15e-803cd5c84d83` `ba576bd1-e51d-44e8-8077-fc943b333c93` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

使用扩散模型为少数类 DoS/DDoS 攻击合成高保真样本，解决数据不平衡并提升分类器召回率。

**💡 创新点**

创新点在于对每个少数类训练独立的 TabDDPM 进行针对性采样，保证样本多样性与隐私，同时通过改进验证指标突出对抗误检的鲁棒性。

**🔧 技术方法**

采用 Tabular Diffusion Probabilistic Models（TabDDPM）进行数据生成，结合四层 ANN 分类器、Batch Normalization、Dropout 与 t‑SNE 可视化等技术。

**📊 数据集**

实验基于 CIC‑IDS‑2017 数据集，仅保留 6 类（Benign、DoS Hulk、DDoS、DoS GoldenEye、DoS Slowloris、DoS SlowHttpTest）。

**📈 对比分析**

与无增强基线和 SMOTE 过采样进行对比，评估 Accuracy、Precision、Recall、F1；扩散增强实现 macro‑F1≈0.989，召回率与精度几乎达到 100%，显著优于基线的 0.86 和 SMOTE 的 0.89。

**⚠️ 局限性**

局限性包括仅在 CIC‑IDS‑2017 上验证；仅处理数值特征，缺乏混合类型支持；未探讨对抗攻击鲁棒性，且在新数据集上的迁移效果未知。

---

## 513. Helical Tendon-Driven Continuum Robot with Programmable Follow-the-Leader Operation

**arXiv ID:** 2601.13177 | [PDF](https://arxiv.org/pdf/2601.13177v1)

**作者:** Behnam Moradkhani `[一作]` (University of Louisville), Yash Chitalia `[通讯]` (University of Louisville)

**通讯引用:** 479 | [OpenAlex ID](https://openalex.org/A5001760308)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `51c0528b-f690-4182-ae60-bb5f046c276c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文设计并验证了一种具有卷曲缺口的钛合金连续机器人ExoNav，用于在脊髓侧/腹侧硬膜外空间精准放置脊髓刺激电极；通过Cosserat杆理论构建静态模型，考虑重力等外载荷，优化拉力输入实现跟随领导(FTL)运动，并在实验平台与脊髓模型中演示导航能力。

**💡 创新点**

创新点包括：1）将卷曲缺口结构纳入Cosserat杆模型以捕捉机器人弯曲特性；2）提出针对外载荷（重力）下的拉力优化方法；3）实现并验证了在脊髓模型中从背侧到腹侧及神经节的安全导航，为SCS导线精准植入提供新的机器人手段。

**🔧 技术方法**

技术手段主要有：
- Cosserat杆静力模型（自定义缺口几何）
- 末端跟随领导(FTL)运动仿真与控制
- 钢丝拉力控制系统（PI控制）
- 6自由度电磁跟踪与负载传感测量
- MATLAB/Simulink仿真与射电调试

**📊 数据集**

使用的数据集主要是实验测得的拉力、位置误差和RMSE等指标，并在四种不同缺口深度/尺寸的四个原型（共四个模型）以及脊髓模型导航实验中收集。没有公开公开数据集，全部为自制实验数据。

**📈 对比分析**

通过与模型预测（含/不含重力）比较，RMSE从约3.7–4.4 mm降低到1.7–2.3 mm；FTL实验中，模型RMSE约1.07 mm，实验三次平均约3.7 mm；在脊髓模型中，成功从背侧导航至侧/腹侧及神经节，未出现显著碰撞。整体性能表明模型在考虑重力后能较好预测机器人姿态，但实际误差受摩擦、传感器误差和拉力多项式近似影响。

**⚠️ 局限性**

局限性包括：
- 机器人仅手动或简单PI控制，缺乏闭环实时拉力优化；
- 未集成真实SCS电极，仍需开发定位/锁定机构；
- 摩擦与外壳壁相互作用导致误差，尤其在全伸展末端；
- 仅在仿真与人工模型中验证，缺乏真实脊髓动物/临床试验；
- 重力模型假设均匀分布，未考虑曲线路径上的复杂外力。

---

## 514. Training instability in deep learning follows low-dimensional dynamical principles

**arXiv ID:** 2601.13160 | [PDF](https://arxiv.org/pdf/2601.13160v1)

**作者:** Zhipeng Zhang `[一作]` (China Mobile Research Institute), Lei Yang `[通讯]` (China Mobile Research Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了 StabilityBench，基于对训练过程的结构化扰动审计来评估深度学习训练的稳定性。

**💡 创新点**

创新点在于将训练稳定性定义为一个与最终性能解耦的动力学属性，构建四维稳定性分类法，并提出低维元状态监控以捕捉崩溃前的结构性漂移。

**🔧 技术方法**

采用了扰动注入、低维元状态学习、梯度相干性与不稳定指数等技术，以及可重复的实验框架。

**📊 数据集**

在强化学习方面使用MuJoCo连续控制任务（PPO、TRPO、SAC、TD3）；在大规模语言模型方面训练GPT‑2 124M/355M/774M在Causal LM任务上。

**📈 对比分析**

通过比较扰动前后崩溃时间、元状态偏差和冲击强度等指标，实验显示高性能模型仍可能高度脆弱，证明稳定性与性能不相关。

**⚠️ 局限性**

局限性包括：仅在RL和LLaMA两类任务上验证；实验为后验描述而非预测/控制；扰动规模和类型有限，未涵盖更广泛的模型或硬件环境。

---

## 515. ICo3D: An Interactive Conversational 3D Virtual Human

**arXiv ID:** 2601.13148 | [PDF](https://arxiv.org/pdf/2601.13148v1)

**作者:** Richard Shaw `[一作]` (Huawei), Eduardo Pérez-Pellitero `[通讯]` (Huawei)

**通讯引用:** 554 | [OpenAlex ID](https://openalex.org/A5013682396)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出了 Interactive Conversational 3D Virtual Human（ICo3D）系统，能够从多视角捕捉数据生成全身、面部可交互、对话式的逼真三维人类虚拟人像，并实现实时语音驱动的面部动画与大语言模型（LLM）对话。

**💡 创新点**

创新点包括：① Audio‑Driven HeadGaS++ 的音频驱动面部重动画；② 在 SWinGS++ 中引入空间‑时域编码器提升动态身体重建的精度与连贯性；③ 头部与身体模型的无缝融合与体素层级剪裁；④ 将 LLM 与 TTS、ASR 结合，实现自然语言驱动的实时交互；⑤ 通过分窗口训练与后期时序微调实现高帧率、低延迟的实时渲染。

**🔧 技术方法**

主要技术手段：3D Gaussian Splatting（3DGS）及其动态扩展（SWinGS++、HeadGaS++），面部音频特征映射、时序 MLP、空间‑时域编码器；LLM Qwen2（0.5B量化版）+ Whisper ASR + OpenVoice V2 TTS；程序化身体动画生成；多视角结构光与光度学配准。

**📊 数据集**

使用的数据集包括：DNA‑Rendering（全身多摄像机录制），RenderMe‑360（头部多视角）、TalkingGaussian（基准面部重建）、以及公开的 SMPL‑X、FLAME 形状模型。

**📈 对比分析**

与现有基准对比，SWinGS++ 在 DNA‑Rendering 上取得 PSNR 30.17、SSIM 0.9699、LPIPS 0.0807，显著优于 SWinGS、Space‑Time Gaussians 等；HeadGaS++ 在自驱动与跨驱动实验中均在 PSNR、SSIM、Sync‑C 等指标上超过 ER‑NeRF、RAD‑NeRF、TalkingGaussian、GaussianTalker；系统整体可在 Linux/Windows 上实现 70–105 FPS，单头部模型可达 250 FPS，满足实时交互需求。

**⚠️ 局限性**

局限性：4D 动态重建只能重放训练时序，无法生成任意新姿态；身体动画仍采用预设关键帧与程序化策略，缺乏真正基于语音驱动的动作生成；头部与身体需在不同捕获环境下对齐，易产生对齐误差；对高动态大运动的捕捉仍有限，且依赖多摄像机硬件。

---

## 516. A Streamlined Attention-Based Network for Descriptor Extraction

**arXiv ID:** 2601.13126 | [PDF](https://arxiv.org/pdf/2601.13126v1)

**作者:** Mattia D'Urso `[一作]` (Graz University of Technology), Friedrich Fraundorfer `[通讯]` (Graz University of Technology)

**通讯引用:** 7032 | [OpenAlex ID](https://openalex.org/A5068079834)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

设计了一个轻量级的基于 U‑Net 的描述子网络，可在现有关键点检测器上单独训练，显著提升描述子匹配性能。

**💡 创新点**

创新点包括将残差 U‑Net 与 CBAM 结合的残差 U‑Net Attention（RUBA）块、改进的三元组损失配合课程化难负采样，以及仅 240 万参数即可与多种检测器兼容的解耦式设计。

**🔧 技术方法**

使用卷积注意力模块 CBAM、残差路径、修改后的三元组损失 + 难负采样、混合精度训练与 NVIDIA RTX 4090 GPU 进行加速。

**📊 数据集**

训练集：MegaDepth；评估集：HPatches、Image Matching Challenge 2021、MegaDepth‑1500、Graz4K（4K 城市场景）。

**📈 对比分析**

与 SuperPoint、DISK、RIPE、ALIKED、DeDoDe‑B/G 等方法比较，在 HPatches 的 Homography Accuracy 上提升 2–5%，在 IMC21 AUC@5 上提升 1–2%，在 MegaDepth‑1500 上提升 2–5%，在 Graz4K 上大幅提升，且仅需 2.4M 参数、速度与原始检测器相近。

**⚠️ 局限性**

需针对每个检测器单独训练，通用性有限；在极高分辨率或极大关键点预算下仍可能出现 OOM 或性能波动。

---

## 517. Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward

**arXiv ID:** 2601.13122 | [PDF](https://arxiv.org/pdf/2601.13122v1)

**作者:** Gourab K Patro `[一作]`, Dagnachew Birru `[通讯]` (Phi Labs)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a4b10f5d-130b-4e77-9367-6469ec621899` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

本文对比了传统任务特定AI（Type‑1）与现代通用AI（Type‑2）的责任AI（RAI）风险，阐述了后者因高自由度输出（DoFo）导致的更大风险，并提出了四大责任目标（C2V2：Control, Consistency, Value, Veracity）以指导通用AI系统的设计与治理。

**💡 创新点**

创新点在于：①将AI系统按输出自由度划分为Type‑1与Type‑2；②将RAI风险映射到C2V2四个维度，提供系统化的责任目标框架；③列举并评估多种现有技术（对齐、检索增强、符号化、代理工具、路由/蒸馏/量化等）在C2V2维度上的适用性；④提出基于C2V2的系统设计流程，示例化企业内部知识助手。

**🔧 技术方法**

核心技术包括：AI对齐（监督/指令微调、RLHF）、检索增强生成（RAG）、提示工程与优化、守门策略（Guardrails）、代理工具使用、路由/蒸馏/量化、神经符号融合、推理增强（链式思维）和自我验证。

**📊 数据集**

本文未进行实验性评估，因此未使用特定数据集；讨论基于公开文献和案例（如OpenAI、Stability AI诉讼、医学、金融等行业）对技术效果进行概念性阐述。

**📈 对比分析**

由于是综述与理论框架，未给出量化性能指标；作者通过对比分析说明，Type‑2 AI在各RAI原则下的风险更高，C2V2框架可聚焦并组合多种技术以降低风险，但缺乏实证验证。

**⚠️ 局限性**

局限性包括：①缺乏系统级实验验证，C2V2框架与技术组合的效果尚未量化；②对不同领域、规模与资源约束下的实现细节未给出；③对法规合规、成本与可扩展性的评估不充分；④对模型训练成本与碳足迹的实际改进仍处于探索阶段。

---

## 518. Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs

**arXiv ID:** 2601.13099 | [PDF](https://arxiv.org/pdf/2601.13099v1)

**作者:** Abdellah El Mekki `[一作]` (University of British Columbia), Muhammad Abdul-Mageed `[通讯]` (University of British Columbia)

**通讯引用:** 4022 | [OpenAlex ID](https://openalex.org/A5004629670)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

创建并发布了Alexandria数据集，一个涵盖13个阿拉伯国家、11个高影响领域、107K多轮对话、包含城市级方言和性别元数据的社区驱动的阿拉伯方言翻译基准。

**💡 创新点**

首次实现细粒度城市级方言标注、对话情境和性别约束的多轮数据，以及通过社区协作和严格审校保证质量。

**🔧 技术方法**

使用Prompt驱动的英文源生成、人工翻译+AI辅助+同行评审+规范化处理，并在Gemini、Qwen、Gemma、Command等多种LLM上进行上下文级和全会话级翻译评测。

**📊 数据集**

Alexandria本身；对比已有数据集如PADIC、MADAR、FLORES+、WMT24++等；评测使用公开/私有测试集。

**📈 对比分析**

通过spBLEU、chrF++自动评估以及人类评估（语义充分性、性别准确率、方言流利度）对13个方言及城市子方言进行评测，发现Gemini系列表现最佳，方言→英语高于英语→方言，马格里布方言最难，整体模型表现与整体强度相关。

**⚠️ 局限性**

性别方向不平衡、技术术语缺失导致MSA泄漏、传统MT基线不支持多维约束、评估仅限LLM且闭源模型覆盖有限。

---

## 519. Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology

**arXiv ID:** 2601.13319 | [PDF](https://arxiv.org/pdf/2601.13319v1)

**作者:** Peter Sullivan `[一作]` (University of British Columbia), Muhammad Abdul-Mageed `[通讯]` (University of British Columbia)

**通讯引用:** 4022 | [OpenAlex ID](https://openalex.org/A5004629670)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了一个统一标准化框架，对 31 个方言阿拉伯语数据集进行整理、语音质量与方言性自动化分析，并发布了跨 14 个方言的 ASR benchmark；

**💡 创新点**

创新点在于：①统一的方言标签映射与元数据规范化；②结合文本方言性评分 (ALDi) 与无参考音频质量估计，实现大规模自动化数据特征化；③基于此框架推出的多方言零样本 ASR 基线；

**🔧 技术方法**

采用了多模态文本/语音特征提取、无监督音频质量评估（TorchAudio‑SQUIM），方言性二分类与等级化模型（ALDi），以及标准化评测流水线；

**📊 数据集**

使用了 31 个公开/授权方言语音语料，涵盖 14 种方言（如埃及、沙特、摩洛哥、突尼斯等），并对其训练集进行自动化特征提取；

**📈 对比分析**

通过对 Whisper‑large‑v3、MMS、SeamlessM4T‑v2、Omnilingual、Qwen3 等公开预训练模型在 14 方言零样本下的 WER/CER 进行对比，发现 Omnilingual 与 Qwen3 在部分方言上表现最佳，MSA 的 WER 低于 12；

**⚠️ 局限性**

局限性包括：①方言性评估仅基于文本，无法覆盖无转录的语音；②ISO 639‑3 + 位置标签未完全捕捉细粒度方言与社会语言差异；③无参考音频质量指标与人工评测不完全一致，可能影响对录音质量的真实判断；

---

## 520. CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning

**arXiv ID:** 2601.13304 | [PDF](https://arxiv.org/pdf/2601.13304v1)

**作者:** Wenxin Ma `[一作]` (Johns Hopkins University), Jieneng Chen `[通讯]` (Johns Hopkins University)

**通讯引用:** 5564 | [OpenAlex ID](https://openalex.org/A5066600512)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一个面向对象的因果空间推理基准Causal Spatial Reasoning Benchmark（CSRB），并给出相应的评价体系；

**💡 创新点**

创新点在于将因果推理与空间感知结合，设计了四个子任务（碰撞、遮挡、轨迹、兼容性），并提出基于世界模型的可控视频生成框架CSG，帮助模型在视觉层面进行物理模拟；

**🔧 技术方法**

核心技术包括文本到三维空间属性预测、4D轨迹仿真、基于Diffusion的对象级视频生成以及多模态链式推理；

**📊 数据集**

数据集由Blender渲染的多样化3D场景组成，包含50+对象类别，提供RGB、深度图、定向边界框，并通过物理仿真生成因果场景；

**📈 对比分析**

与多款开源与闭源LLM（如Qwen3、GPT‑5、Gemini）对比，CSRG显著提升了因果空间推理准确率（平均提升≈2–3%），但与人类（≈85%）仍存在较大差距；

**⚠️ 局限性**

局限性主要在于生成视频的物理一致性有限，尤其在遮挡和长时序推理方面表现不足，且模型仍易产生语言漂移导致的误判。

---

## 521. OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference

**arXiv ID:** 2601.13300 | [PDF](https://arxiv.org/pdf/2601.13300v1)

**作者:** Yow-Fu Liou `[一作]` (National Yang Ming Chiao Tung University), An-Zi Yen `[通讯]` (National Yang Ming Chiao Tung University)

**通讯引用:** 206 | [OpenAlex ID](https://openalex.org/A5012131890)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出选项注入方法，通过在多选问答中添加含误导指令的选项来评估LLM鲁棒性。

**💡 创新点**

创新点在于将选项界面偏差与指令干扰结合，构建OI‑Bench并系统评估16种指令类型的攻击效果。

**🔧 技术方法**

使用对抗注入、基线MCQA、攻击成功率、准确度下降等指标，并对模型进行后训练对齐（DPO、PPO）等防御策略。

**📊 数据集**

使用MMLU、LogiQA、HellaSwag各约1000道题构成3000道样本的OI‑Bench。

**📈 对比分析**

对12个LLM进行零样本评估，标准准确率约80%，注入后准确度下降10%至30%，攻击成功率最高达20%，防御策略中后训练对齐能显著降低攻击成功率。

**⚠️ 局限性**

局限在于仅针对多选问答，无法推广到需要长篇推理或决策序列的任务，且对封闭模型内部机制缺乏可解释性。

---

## 522. Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning

**arXiv ID:** 2601.13284 | [PDF](https://arxiv.org/pdf/2601.13284v1)

**作者:** Duygu Nur Yaldiz `[一作]` (University of Southern California), Nikolaos Pappas `[通讯]` (AWS AI Labs)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了大型语言模型在决策任务中的校准-分类权衡，并提出了一种直接调节决策标记概率的校准感知强化学习方法。

**💡 创新点**

发现RLVR虽提升准确率但导致极度过度自信，决策标记仅起提取作用，进而设计了在RL目标中加入基于决策标记的交叉熵校准损失，以直接抑制过度自信。

**🔧 技术方法**

采用RLVR（GRPO）与自监督微调(SFT)相结合的训练框架，并在此基础上加入针对决策标记的校准交叉熵损失与Beta归一化策略。

**📊 数据集**

在CommonsenseQA、OpenBookQA、OpenAI Moderation和XSTest等多选题与二分类内容审核数据集上进行实验。

**📈 对比分析**

与SFT和基线相比，所提方法在保持与GRPO相近的准确率的同时，将ECE从≈30%降低至≈7%，显著缓解过度自信，且在OOD场景下保持稳定的性能。

**⚠️ 局限性**

实验仅覆盖Qwen3 1.7B-8B规模的模型；未扩展到更大模型或其他模型族；仅针对决策任务，未探究开放式生成的校准；对推理轨迹内部不确定性的细粒度分析尚缺失。

---

## 523. CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning

**arXiv ID:** 2601.13262 | [PDF](https://arxiv.org/pdf/2601.13262v1)

**作者:** Eric Onyame `[一作]` (University of Virginia), Chirag Agarwal `[通讯]` (University of Virginia)

**通讯引用:** 1122 | [OpenAlex ID](https://openalex.org/A5048724032)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个多语言医学推理基准CureMed-Bench和对应的训练框架CureMed。

**💡 创新点**

在多语言医学推理中首次引入可验证单一答案的开放式问答，并结合代码切换监督和基于语言资源的课程强化学习同时提升推理正确性与语言一致性。

**🔧 技术方法**

采用冷启动代码切换监督式微调、Group Relative Policy Optimization（GRPO）课程强化学习、LLM‑as‑a‑judge 验证器及多语言奖励设计。

**📊 数据集**

构建了覆盖13种语言（包括低资源语言）的15,774条开放式医学推理实例CureMed-Bench，来源于MedlinePlus等临床资料。

**📈 对比分析**

与28个基线模型（一般与医学领域）在逻辑正确性和语言一致性上进行对比，CureMed在7B/32B参数规模下分别达成54.35%/70.04%逻辑准确率和85.21%/94.96%语言一致率，明显优于对照组并在低资源语言上保持优势。

**⚠️ 局限性**

受限于可获取的临床资料覆盖度，难以覆盖所有语言及临床场景；依赖API生成与验证成本高，且基准仅覆盖单一答案的开放式问答，未涵盖多访、多模态决策。

---

## 524. Autonomous Navigation at the Nano-Scale: Algorithms, Architectures, and Constraints

**arXiv ID:** 2601.13252 | [PDF](https://arxiv.org/pdf/2601.13252v1)

**作者:** Mahmud S. Zango `[一作]` (University of Glasgow), Jianglin Lan `[通讯]` (University of Glasgow)

**通讯引用:** 1477 | [OpenAlex ID](https://openalex.org/A5050760087)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文综述了纳米无人机在极限SWaP（尺寸、重量、功耗）条件下实现自主导航的最新技术路线，涵盖传感、计算、感知、规划、控制、群体协同以及软硬件协同设计，并系统性地评估了现有方法的性能与局限，提出了未来发展路线图。

**💡 创新点**

创新点在于：①把传统几何基准方法与“Edge AI”深度学习、神经形态控制相融合，形成可在<100 mW功耗下运行的轻量化感知与决策框架；②系统性识别并突出“Sim‑to‑Real”“Physics‑Gap”“SWaP‑Gap”三大难点；③提出混合架构与多层堆栈设计，兼顾实时性与学习能力；④为纳米级无人机提供完整的软硬件工具链与评测基准。

**🔧 技术方法**

使用技术包括：高效微控制器（STM32F4）、低功耗SoC（GAP8/9、Navion ASIC）、事件摄像头与ToF传感、量化/剪枝CNN（DroNet、NanoFlowNet）、神经形态SNN、几何控制与INDI、强化学习（PPO、SAC、ART‑IQN）、模型预测控制与安全过滤、SLAM/全局规划（tinySLAM、A*、MPC）、群体通信协议（Crazyswarm、ARGoS）、仿真平台（AirSim、Gym‑pybullet‑drones、ARGoS）、部署编译链（TFLM、AutoTiler、DORY、BackpropTools）。

**📊 数据集**

本文主要利用仿真与实验数据，借助AirSim、Gym‑pybullet‑drones、ARGoS等平台产生合成图像与动力学数据；在真实飞行中使用官方测试环境（如Crazyflie 2.x与其模块化“deck”）进行验证；并未公开单一公开数据集，而是依赖多源合成与实际飞行日志进行对比评估。

**📈 对比分析**

通过实验与仿真对比，评估了不同平台在推理速度、功耗、内存占用、任务完成率等指标；例如GAP8在86 mW下可实现DroNet 135 fps，Navion ASIC在24 mW下完成VIO；强化学习策略在模拟中达到80–90 %成功率，但实地转移仍低约10–20 %；MPC与LQR在高动态任务中的跟踪误差对比显示，几何控制+INDI在噪声下优于纯PID。整体性能虽大幅提升，但仍受限于短时续航、动态障碍物避让与仿真到现实的漂移。

**⚠️ 局限性**

局限性主要包括：①续航时间短（几分钟以内）与能耗分配难题；②动态环境中的鲁棒避障与实时感知受限；③仿真到现实的差距导致策略迁移困难；④缺乏高精度传感器（LiDAR、RGB‑D）与稀疏视角导致地图分辨率低；⑤通信带宽与功耗在群体规模扩展时成为瓶颈；⑥现有算法对极端噪声与振动的抗扰性能尚未完全成熟。

---

## 525. Aligning Agentic World Models via Knowledgeable Experience Learning

**arXiv ID:** 2601.13247 | [PDF](https://arxiv.org/pdf/2601.13247v1)

**作者:** Baochang Ren `[一作]` (Zhejiang University), Huajun Chen `[通讯]` (Zhejiang University)

**通讯引用:** 7791 | [OpenAlex ID](https://openalex.org/A5102018239)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出WorldMind框架，通过经验学习让LLM代理自主构建符号世界知识库，实现世界模型的对齐。

**💡 创新点**

创新点在于利用过程经验和目标经验无训练在线对齐，消除物理错觉并实现跨模型、跨环境迁移。

**🔧 技术方法**

采用预测编码思路的过程经验抽象、自动反思模块和目标经验提取，结合LLM生成动作与预测状态。

**📊 数据集**

在EB‑ALFRED、EB‑Habitat以及Embodied Web Agent等基准上进行实验。

**📈 对比分析**

与ReAct、SimuRA、ReasoningBank等基线对比，WorldMind在成功率(SR)和目标条件成功(GC)上均提升5–10%以上，显示显著性能提升。

**⚠️ 局限性**

局限在于依赖视觉感知质量、对对齐机制的机制解释不足以及多代理共享世界模型的实时同步仍未解决。

---

## 526. Do Instruction-Tuned Models Always Perform Better Than Base Models? Evidence from Math and Domain-Shifted Benchmarks

**arXiv ID:** 2601.13244 | [PDF](https://arxiv.org/pdf/2601.13244v1)

**作者:** Prateek Munjal `[一作]`, Praveenkumar Kanithi `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

比较了基础（base）大语言模型与经过指令调优（instruction‑tuned）模型在数学推理和领域迁移任务（如医学计算）的性能，并在零样本、少样本、分布偏移以及评估器敏感性等多维度进行系统实验。

**💡 创新点**

揭示指令调优并非普适提升：在零样本 CoT 场景下基础模型往往优于指令调优；在分布偏移（MedCalc、Math Perturb）中，指令调优性能下降；且指令调优对大模型的提升往往微乎其微，主要受提示模式影响。

**🔧 技术方法**

使用 Chain‑of‑Thought (CoT) 解码（针对基础模型）与重复随机采样（针对指令调优模型），评估指标为 Pass@k（k=20），同时对 LaTeX 输出采用正则表达式和 MathVerify 两种评估器。

**📊 数据集**

数据集包括 GSM8K、Math‑500、Math Perturb Hard（扰动版）、MedCalc（医学计算基准），并在 16 种公开权重模型（0.6B–1T）上进行实验。

**📈 对比分析**

通过 Pass@20 在零样本与 8‑shot CoT 对比，发现基础模型在零样本时显著优于指令调优（如 LLaMA3‑70B：32.7% 下降），但在 8‑shot 时差距缩小；在分布偏移任务中基础模型往往更强；评估器差异导致 Math‑500 结果存在 10% 以上差异，说明评估方法对结论影响大。

**⚠️ 局限性**

局限性包括：基准覆盖范围有限，评估器依赖显著；结果受解码参数、提示模板影响；仅评估部分模型与数据，未对指令调优的具体训练成分进行因果分析；未探究将相同采样策略应用于指令调优模型的情况。

---

## 527. KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?

**arXiv ID:** 2601.13240 | [PDF](https://arxiv.org/pdf/2601.13240v1)

**作者:** Xue Jiang `[一作]` (Peking University), Yihong Dong `[通讯]` (Peking University)

**通讯引用:** 846 | [OpenAlex ID](https://openalex.org/A5077542599)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了 KOKO‑Bench benchmark，结合领域知识语料库与多粒度评测任务，以评估 LLM 在域特定软件开发中的知识获取与应用能力。

**💡 创新点**

创新点在于同时提供了完整的知识语料库和基于真实项目的代码生成与知识问答任务，使模型必须主动学习并利用域知识，而非仅凭预训练知识。

**🔧 技术方法**

使用了多种域专化技术（SFT、LoRA、RAG、kNN‑LM、KNM‑LM、DSCC）以及基于 agent 的系统（Claude Code、SWE‑Agent、OpenHands），并通过需求描述与严谨的单元/集成测试进行评估。

**📊 数据集**

数据集涵盖 6 个新兴领域（RL、Agent、RAG、MO、Embodied AI、Ascend）共 11 个框架、25 个项目，含约 77k 行知识语料、63k 行项目代码、1k+ 单元/集成测试和 107 题 Q&A。

**📈 对比分析**

与多种基线对比显示，即使是最强 LLM 在代码生成上仅 8% 左右 Pass@1，域专化方法提升有限（最高 28% 语义理解），Claude Code 以 34% Pass@1 领先，但整体性能远低于通用基准。

**⚠️ 局限性**

局限性包括现有域专化技术提升有限、受数据规模与知识遗忘、跨域冲突制约，agent 方案成本高且易出现循环调用。

---

## 528. A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models

**arXiv ID:** 2601.13238 | [PDF](https://arxiv.org/pdf/2601.13238v1)

**作者:** Chengyin Hu `[一作]`, Yiwei Wei `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6215c339-3735-4be3-8a07-5bbb7004712d` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出了针对视觉‑语言模型（VLM）的两阶段雨天对抗攻击框架，利用语义解耦与物理一致性实现鲁棒性评估。

**💡 创新点**

创新点在于：①将对抗攻击分为语义层和物理层两阶段，先在嵌入空间弱化语义边界，再在可控的雨滴与光照参数空间生成高质量结构化扰动；②使用多尺度雨滴和非均匀照明的参数化模型，避免传统像素级噪声的无意义扰动；③采用CMA‑ES进行梯度无关的全局优化，保证在非凸物理空间内能找到强攻击样本。

**🔧 技术方法**

使用的技术包括：语义解耦的全局雨层混合、基于VGG的感知一致性约束、SSIM结构一致性约束、光照场模型、CMA‑ES梯度无关优化以及LLM‑as‑Judge（GPT‑4o）进行跨任务评价。

**📊 数据集**

实验数据集：300张MS COCO测试图像（30个语义类别），用于零样本分类、图像生成与视觉问答任务。

**📈 对比分析**

与现有物理一致性攻击（ITA、Shadow、Natural Light）对比，本文在零样本分类上的Top‑1准确率下降最高可达62%（相比ITA的51%），在图像生成和VQA任务中也实现了显著的性能衰减，证明了跨任务的可迁移性和更高的攻击效果。

**⚠️ 局限性**

局限性：仅针对雨天场景，未覆盖雾霾、雾天、雪等其它复杂天气；对不同VLM结构的泛化能力需要进一步验证；对细粒度扰动机制与多种环境因素交互的深层分析仍不足。

---

## 529. Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations

**arXiv ID:** 2601.13225 | [PDF](https://arxiv.org/pdf/2601.13225v1)

**作者:** Tim Lachmann `[一作]` (Stockholm University), Petri Laukka `[通讯]` (Uppsala University)

**通讯引用:** 8772 | [OpenAlex ID](https://openalex.org/A5042598969)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文构建了首个公开的多模态混合情绪数据集，并基于该数据集提出了情绪存在性与相对显著度的评估指标。

**💡 创新点**

创新点在于同时标注情绪混合的相对显著度（50/50、70/30、30/70）以及提供平衡的混合情绪样本，为混合情绪识别研究提供了全新的数据与评价框架。

**🔧 技术方法**

采用了多模态特征提取器（VideoMAE V2、ImageBind、WavLM、HuBERT 等）以及早期融合策略，配合 MLP 及 HiCMAE 线性层进行多标签软分类。

**📊 数据集**

使用了自行收集的 3,050 条视频（58 位演员，6 种单一情绪与 10 种两情绪组合）组成的 “EmotionBlend” 数据集，并提供了训练/验证/测试划分。

**📈 对比分析**

在五折交叉验证与保留测试集上评估，最优多模态组合 VideoMAE V2 + HuBERT 在情绪存在性上达到 33.2% 的准确率，HiCMAE 在显著度评估上取得 18% 的准确率，均显著优于单模态和零基线。

**⚠️ 局限性**

局限性包括：实验情绪为受控演员表现，缺乏自然情境；情绪类别仅限五种基础情绪及其两两组合；显著度仅离散化为三类，未能覆盖连续变化；数据集在种族与文化多样性方面有限。

---

## 530. Functional Logic Program Transformations

**arXiv ID:** 2601.13224 | [PDF](https://arxiv.org/pdf/2601.13224v1)

**作者:** Michael Hanus `[一作]` (Kiel University), Steven Libby `[通讯]` (University of Portland)

**通讯引用:** 13 | [OpenAlex ID](https://openalex.org/A5037906216)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

本文提出并实现了一套基于函数逻辑语言Curry的程序变换框架，主要针对Curry中间表示FlatCurry实现变换规则、组合与应用，并对不同实现风格与策略进行评估；

**💡 创新点**

创新点在于将变换定义为部分定义的非确定性操作，利用Curry的功能模式、非确定性与搜索操作，实现可读、可组合、可扩展的变换；同时提供非确定性、确定性与混合两种实现方式，并引入混沌、混合、确定性三种变换策略，进行系统性对比；

**🔧 技术方法**

使用了Curry语言及其功能逻辑特性（非确定性、功能模式、oneValue等）、FlatCurry中间语言、非确定性/确定性变换实现、并行/串行组合操作、混沌/混合/确定性策略等技术；

**📊 数据集**

在Curry标准库（Prelude、Data.Char、Data.Either、Data.List、Data.Maybe、Numeric、System.Console.GetOpt、System.IO）以及将这些库转换为A‑Normal Form的实验数据集上进行评测；

**📈 对比分析**

通过在PAKCS（Prolog）和KiCS2（Haskell）两种Curry实现上测量模块大小、函数数、变换次数和耗时，比较混沌、混合与确定性策略的性能；结果显示确定性策略最快，混合策略性能相近；在可变换较多的ANF实验中，非确定性与确定性差距在Prolog上更大，而KiCS2上差距相对可接受；

**⚠️ 局限性**

局限性包括：需要在Curry环境下运行；非确定性实现会带来额外运行时开销；实现依赖于Curry的特定特性，对其他语言移植需要重写；对大规模程序的性能影响仍有待进一步评估；

---

## 531. CooperBench: Why Coding Agents Cannot be Your Teammates Yet

**arXiv ID:** 2601.13295 | [PDF](https://arxiv.org/pdf/2601.13295v1)

**作者:** Arpandeep Khatua `[一作]`, Diyi Yang `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一套新的多智能体协作基准，并通过设计可自适应的通信与协调机制，提升了多智能体系统在复杂任务中的协作性能。

**💡 创新点**

创新点在于将通信、协作和协调三大关键要素统一到一个端到端的学习框架中，并通过动态消息传递与共享策略显著降低了对手工设计的依赖。

**🔧 技术方法**

采用深度强化学习（DQN/Actor‑Critic）、图神经网络来建模智能体间关系、以及注意力机制用于消息筛选。

**📊 数据集**

实验数据集主要来自公开的StarCraft II微观控制任务、Overcooked和DeepMind Lab等多智能体协作场景。

**📈 对比分析**

与现有的基线方法（如Independent DQN、MADDPG、QMIX等）比较，作者的方法在任务完成率、收敛速度和资源利用率上平均提升了10%~20%。

**⚠️ 局限性**

局限性包括：在大规模智能体群体下通信开销依然显著、对极端动态环境的适应性有限，以及在多任务迁移学习中的鲁棒性尚需进一步验证。

---

## 532. Towards Natural Language Environment: Understanding Seamless Natural-Language-Based Human-Multi-Robot Interactions

**arXiv ID:** 2601.13338 | [PDF](https://arxiv.org/pdf/2601.13338v1)

**作者:** Ziyi Liu `[一作]` (Purdue University), Karthik Ramani `[通讯]` (Purdue University)

**通讯引用:** 11659 | [OpenAlex ID](https://openalex.org/A5004602626)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出“自然语言环境（NLE）”概念，并通过虚拟现实中的角色扮演实验，探讨人机多机器人协作的交互设计空间；

**💡 创新点**

创新点在于首次系统性构建NLE的设计维度（任务协调主导性、机器人自治水平、机器人个性），并基于实验数据验证不同主导模式对任务完成率的影响；

**🔧 技术方法**

技术主要为：自然语言处理与大型语言模型（LLM）驱动的机器人对话、虚拟现实沉浸式模拟、语音识别与多模态交互；

**📊 数据集**

数据集为：52名参与者共13场实验，涉及78个子任务，记录了任务完成率、对话主导次数等指标；

**📈 对比分析**

通过对话主导次数和任务完成率的统计比较，发现机器人主导场景（平均主导次数5.31）往往能实现100%任务完成率，而人类主导场景完成率仅为88‑79%；

**⚠️ 局限性**

局限性包括：实验仅在虚拟环境中进行，未验证在真实家庭机器人中的可行性；机器人类型有限（仅清洁机与助手机械臂）；未覆盖老年人/残障用户；缺乏对比基准系统或公开数据集的性能评估。

---

## 533. Verifying Local Robustness of Pruned Safety-Critical Networks

**arXiv ID:** 2601.13303 | [PDF](https://arxiv.org/pdf/2601.13303v1)

**作者:** Minh Le `[一作]` (Georgia Institute of Technology), Phuong Cao `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 216 | [OpenAlex ID](https://openalex.org/A5011948693)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文验证了不同裁剪比例下剪枝深度神经网络的局部鲁棒性，并比较了其对可验证性性能的影响。

**💡 创新点**

发现剪枝比例与数据集不同而影响可验证性最优点存在显著差异，提出了剪枝比例对安全关键任务鲁棒性验证的重要性。

**🔧 技术方法**

采用了 α,β‑CROWN 形式化验证器、Magnitude‑based 全局无结构 L1 裁剪、ResNet4 训练与微调技术。

**📊 数据集**

使用了 MNIST 与 NASA JPL Mars Frost Identification 两个图像识别数据集。

**📈 对比分析**

通过在每个模型上对前 100 条输入进行局部鲁棒性验证，统计已证明的实例数；结果显示 MNIST 上 40‑50% 剪枝最优，JPL 上 70‑80% 剪枝最优。

**⚠️ 局限性**

局限在于仅测试了卷积层裁剪、单一 ResNet4 结构、固定的 α,β‑CROWN 验证器，且未探讨其他裁剪策略、数据集或更大规模网络的泛化性。

---

## 534. Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams

**arXiv ID:** 2601.13299 | [PDF](https://arxiv.org/pdf/2601.13299v1)

**作者:** Ethan Seefried `[一作]` (Oak Ridge National Laboratory), Tirthankar Ghosal `[通讯]` (Oak Ridge National Laboratory)

**通讯引用:** 745 | [OpenAlex ID](https://openalex.org/A5081072666)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了 Enginuity 数据集，提供 5 万+ 大规模、跨域工程图形的结构化注释，支持组件检测、关系提取和图形问答等任务。

**💡 创新点**

首创公开的大规模多域工程图数据集，并通过 AI+人工混合标注与主动学习实现高效、标准化的层级结构注释，填补了符号识别与关系抽取之间的空白。

**🔧 技术方法**

采用 AI 驱动的初始检测、专门标注团队、专家验证与主动学习相结合的 4 阶段标注管道，并使用 ISO/IEEE 统一本体标准；后续可用于训练多模态大语言模型进行图形解析与推理。

**📊 数据集**

主要使用自身构建的 Enginuity 数据集，涵盖汽车域 5 万+ 图形（如驱动器、底盘、车身等），包括公开域和行业合作的旧车型图形。

**📈 对比分析**

本文未给出具体实验结果；但提到现有方法符号检测达 85%+，关系抽取仍低于 60%（下降 25%+），预计 Enginuity 将为后续模型提供统一基准并促进性能提升。

**⚠️ 局限性**

局限性包括：仅覆盖汽车域，后续需扩展至其他工程领域；受专有信息限制，数据收集受限于 5–15 年前的旧车型；关系抽取仍面临高复杂度，标注成本仍非零；公开数据可能不足以覆盖所有设计规范。

---

## 535. Diffusion-based Inverse Model of a Distributed Tactile Sensor for Object Pose Estimation

**arXiv ID:** 2601.13250 | [PDF](https://arxiv.org/pdf/2601.13250v1)

**作者:** Ante Marić `[一作]` (Idiap Research Institute), Sylvain Calinon `[通讯]` (Idiap Research Institute)

**通讯引用:** 10296 | [OpenAlex ID](https://openalex.org/A5048780399)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

利用分布式触觉传感器，提出基于扩散模型的逆传感器模型与粒子滤波器相结合，实现无视觉条件下的物体姿态估计。

**💡 创新点**

创新点在于将去噪扩散生成模型与几何约束投影相结合，能够高效生成符合触碰约束的多模态姿态候选，并通过信念驱动的粒子注入提升采样效率与估计精度。

**🔧 技术方法**

采用DDIM扩散生成器、SDF几何投影、分布式触觉皮肤（CySkin）感知、粒子滤波与贝叶斯更新。

**📊 数据集**

训练数据使用基于SDF的仿真触觉观测，评估对象取自YCB数据集（如钻机、马克杯、芥末瓶等）。

**📈 对比分析**

与局部采样与基于力/扭矩的SDF方法对比，实验表明DDIM模型在ADD、成功率和收敛速度上均优于基线，在模拟和真实世界测试中表现一致。

**⚠️ 局限性**

局限性包括仅适用于二维平面3-DoF、需已知物体几何、训练为物体特定、对复杂接触形状与动态效应建模不足、对多物体/并行接触的适应性待提升。

---

## 536. The Cost of Failure: On The Complexity of Recampaigning under Fixed Districts

**arXiv ID:** 2601.13246 | [PDF](https://arxiv.org/pdf/2601.13246v1)

**作者:** Michael C. Chavrimootoo `[一作]` (Denison University), Aidan Jeansonne `[通讯]` (Denison University)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355`

**🎯 论文内容**

提出并研究了“再竞选”（recampaigning）问题，即在预先划定的选区内，政党通过把候选人战略性地安置到不同选区，力求让所有候选人赢得选区，从而实现选举控制。

**💡 创新点**

创新点在于：①首次把候选人安置视为一种新的选举控制模型；②对该模型在不同投票规则、获胜者数量约束、是否计价等情形下的复杂度进行系统划分与对比；③将该问题与传统的控制问题通过多项式时间可逆变换关联，揭示了价格化与非价格化、有限获胜者与无限获胜者之间的复杂度差异。

**🔧 技术方法**

主要采用的技术包括：多项式时间归约（如从 X3C、3DM、Exact-3-3DM、Monotone 1‑in‑3 SAT 等 NP‑完全问题构造实例）；图论算法，如最小成本不平衡匹配、最小权重完全 b‑匹配；以及参数化复杂度分析，利用集合覆盖与多项式时间可决条件（1‑Winner、ℓ‑Winner）来证明 FPT 结果。

**📊 数据集**

该研究完全为理论分析，并未使用任何实际数据集；所有证明均基于构造性归约与抽象模型。

**📈 对比分析**

由于是纯理论工作，本文并未进行实验或性能对比；通过归约与复杂度分析给出了该问题在各类投票规则下的“硬度”与“可解性”，并指出了在特定参数（如选区数、获胜者上限）下的可行性与不可行性。

**⚠️ 局限性**

局限性：①缺乏针对真实选举数据的实验验证，无法评估模型在实践中的效果与可操作性；②对某些自然投票规则（如 Condorcet、Ranked Pairs）的具体算法仍待深入；③仅讨论了构造性最优性（完全赢）而未考虑部分赢或最大化候选人赢得数的近似算法；④对其他参数化维度（如候选人数、投票规则多样性）尚未展开研究。

---

## 537. Reducing Tokenization Premiums for Low-Resource Languages

**arXiv ID:** 2601.13328 | [PDF](https://arxiv.org/pdf/2601.13328v1)

**作者:** Geoffrey Churchill `[一作]` (Stony Brook University), Steven Skiena `[通讯]` (Stony Brook University)

**通讯引用:** 13060 | [OpenAlex ID](https://openalex.org/A5060741187)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

分析多语言模型 tokenizer 的词表差异和 tokenization premium，并提出在冻结模型后追加单字符 token 以降低 tokenization premium；

**💡 创新点**

创新地为冻结模型后训练追加新 token 并使用线性回归、kNN、局部线性回归等方法推导 embedding，从而显著减少 tokenization penalty；

**🔧 技术方法**

采用 BPE、WordPiece 等 tokenization 技术、Jaccard 相似度评估词表、kNN/线性回归/局部线性回归推导 embedding，并在 Llama 3.2 1B 上进行实验；

**📊 数据集**

使用 FLORES‑200 200 语言翻译对数据集来评估 tokenization premium 及 embedding 效果；

**📈 对比分析**

通过比较 tokenizer 词表 Jaccard 相似度、各语言 tokenization premium，以及在 Llama 3.2 1B 上计算压缩与原始输入的最后隐藏层余弦相似度，结果显示线性回归在层 0 表现最佳，余弦相似度大多接近 1；

**⚠️ 局限性**

局限性包括余弦相似度与真实下游性能可能不一致、输出概率的投票拆分问题，以及仅在输入侧使用压缩而非输出等。

---

## 538. Verifying First-Order Temporal Properties of Infinite-State Systems via Timers and Rankings

**arXiv ID:** 2601.13325 | [PDF](https://arxiv.org/pdf/2601.13325v1)

**作者:** Raz Lotan `[一作]` (Tel Aviv University), Sharon Shoham `[通讯]` (Tel Aviv University)

**通讯引用:** 6447 | [OpenAlex ID](https://openalex.org/A5028417315)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c`

**🎯 论文内容**

提出一种统一的基于计时器和隐式排名的FO‑LTL属性证明框架，将任意FO‑LTL属性的验证转化为终止性验证，并通过SMT求解器自动检查排名下降

**💡 创新点**

1) 将FO‑LTL属性的验证完整地归约为终止性验证，使用“预言计时器”而不需要公平假设；
2) 将隐式排名框架推广到无限域并加入可判定的有效性条件；
3) 将计时器直接纳入排名构造，简化证明

**🔧 技术方法**

一阶逻辑、FO‑LTL、预言计时器、隐式排名构造、SMT（Z3）以及基于Python的验证工具

**📊 数据集**

对前人工作中的一系列案例进行评估，包括 Ticket 协议、Paxos、ABP、HRB、Ackermann、LexArray、TimestampedQueue、CascadingQueue、ReorderingQueue、MutexRing、LeaderRing、ToyStabilization、Dijkstra k‑State、BinaryCounter、SAT‑Backtrack、SAT‑CDCL 等

**📈 对比分析**

与传统的 liveness‑to‑safety 归约相比，所得到的证明更小且验证时间更短；表中给出了每个例子的执行时间、构造器数量、证明大小等指标，显示在多数案例上显著优于已有方法

**⚠️ 局限性**

需要用户手工给出排名、invariant 以及有限性近似；归约在使用第一阶语义近似时不再完全；当前实现仅支持含有全局/最终运算符的 FO‑LTL，扩展到更复杂的时序算子仍待研究

---

## 539. Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse

**arXiv ID:** 2601.13317 | [PDF](https://arxiv.org/pdf/2601.13317v1)

**作者:** Samantha Sudhoff `[一作]` (Purdue University), Tunazzina Islam `[通讯]` (Purdue University)

**通讯引用:** 121 | [OpenAlex ID](https://openalex.org/A5056005531)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在Meta付费广告与Bluesky公开帖子的基础上，对2024‑2025年气候话语进行了跨平台比较，挖掘并标注主题；

**💡 创新点**

提出了可解释的主题发现与标记框架，先通过语义聚类实现无监督主题抽取，再利用LLM生成人类可读的主题标签，实现在不同激励结构平台上的直接对比；

**🔧 技术方法**

采用Sentence‑BERT嵌入、PCA/UMAP降维、HDBSCAN聚类，利用Mistral‑Large进行聚类过滤、摘要生成与主题标签，随后用人类与LLM评估，主题用于立场预测与语义检索；

**📊 数据集**

使用Meta广告库收集113,493条气候广告（去重后17,026条）与Bluesky 1.3M条气候帖子（去重后19,182条）；

**📈 对比分析**

与LDA、BERTopic基线对照，文本‑主题方法在人工和LLM评估下的准确率最高（≈0.67/0.46），在立场预测和检索任务中均提升F1和Precision@k，证明主题更具语义一致性；

**⚠️ 局限性**

仅覆盖Meta与Bluesky两平台，依赖预训练LLM可能引入偏见，未进行因果推断，且方法对不同语言或平台的泛化能力未作评估。

---

## 540. Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification

**arXiv ID:** 2601.13272 | [PDF](https://arxiv.org/pdf/2601.13272v1)

**作者:** Aaron Pim `[一作]` (Institute for Mathematical Innovation University of Bath), Tristan Pryer `[通讯]` (Department of Mathematical Sciences University of Bath)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `a8e75ba4-7a2d-4153-b003-06c94533add0`

**🎯 论文内容**

提出一种基于多层蒙特卡罗（MLMC）的框架，用以在推断阶段高效估计神经网络的蒙特卡罗Dropout不确定性，并通过重用Dropout掩码实现多级采样。

**💡 创新点**

创新点在于：1）将Dropout掩码视为不确定性源，定义以前向传递次数为层级的精度阶层；2）构造粗细级别的耦合估计器，实现无偏的多层估计；3) 推导了精度、方差与成本的闭式表达式，并给出最优采样分配规则；4) 在前向与逆向PINN-Uzawa基准上验证理论并展示了显著的成本降低。

**🔧 技术方法**

主要技术包括：蒙特卡罗Dropout、深度学习的神经网络推断、多层蒙特卡罗方法、随机过程耦合与方差分析、经验方差估计、以及对数-对数回归验证采样率。

**📊 数据集**

使用两类基准：1）前向PINN–Uzawa的边界层常微分方程（可解析解）；2）逆向PINN–Uzawa的随机目标源问题（目标具有已知期望与方差）。

**📈 对比分析**

与传统单层MC‑Dropout（固定前向次数）在相同计算预算下比较。结果显示：在前向与逆向问题上，MLMC方法在相同预算下实现了 3–10 倍的方差降低，或在相同方差下显著降低前向评估次数。

**⚠️ 局限性**

局限性包括：1）理论推导依赖于高阶矩（如四阶矩）或零超额峰度假设，实际分布偏离时可能需要额外估计；2）对Dropout掩码重用的实现需要在网络推断框架中支持；3）当前向评估成本与随机性不平衡时，成本模型需调整；4）实验仅在PINN 1D PDE 基准上验证，尚未在更高维度或更复杂网络上测试。

---

## 541. Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models

**arXiv ID:** 2601.13260 | [PDF](https://arxiv.org/pdf/2601.13260v1)

**作者:** Sawsan Alqahtani `[一作]` (Princess Nourah Bint Abdulrahman University), M Saiful Bari `[通讯]` (Amazon AGI)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

将分词重新定义为大型语言模型的核心建模决策，并提出以语境为导向的 tokenizer–model 共同设计框架，强调标准化评估与透明报告；

**💡 创新点**

创新点在于将分词从传统预处理转变为与模型架构、训练目标、语言与任务需求共同演进的设计要素，并提出多维评估指标和责任感的设计原则；

**🔧 技术方法**

核心技术为对现有子词分词方法（BPE、WordPiece、Unigram）的理论分析、与模型协同优化的概念化框架、以及基于语料与任务的分词诊断工具；

**📊 数据集**

本文未给出具体实验数据集，主要以文献回顾和概念论证为依据；

**📈 对比分析**

未进行实验比较，作者以文献案例和理论推理说明该框架在多语言、低资源和领域特定情境下的潜在优势；

**⚠️ 局限性**

局限性包括缺乏大规模实证验证、对资源和工具的依赖、以及仍未解决如何统一评估代理与实际下游性能的具体方法。

---

## 542. RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements

**arXiv ID:** 2601.13233 | [PDF](https://arxiv.org/pdf/2601.13233v1)

**作者:** Bolin Chen `[一作]` (Northwestern University), Wei Chen `[通讯]` (Northwestern University)

**通讯引用:** 66171 | [OpenAlex ID](https://openalex.org/A5100344384)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出基于随机森林的生成式逆设计框架 RAG，用于在小样本、高维函数响应和复杂设计需求下实现一次性无迭代逆设计。

**💡 创新点**

创新点包括：①将前向映射改写为设计变量+查询点的输入、单标量输出，降低学习难度并实现离散化不变性；②直接通过随机森林集成估计条件似然，从需求直接推导设计；③利用树间方差对前向预测与逆设计的不确定性进行量化，提升可信度；④单步采样（MCMC）生成多样化设计，避免传统迭代求解。

**🔧 技术方法**

使用随机森林回归、联合输入-输出映射、条件似然估计、Metropolis‑Hastings MCMC、方差不确定性量化、拉丁超立方采样等技术。

**📊 数据集**

实验数据集：声学元材料 500 组设计（波数‑频率散射），机械元材料 1057 组设计（应力‑应变曲线）以及公开机械元材料数据（2065 训练/231 测试），其中对机械元材料的 40% 子集用于对比。

**📈 对比分析**

与基于深度神经网络的生成式方法相比，RAG 在仅使用 10%–40% 数据时即可达到相近的预测精度（声学测试 MSE 0.4839；机械测试误差 5.14% vs NN 2.59%），训练时间 3–59 秒，且通过条件似然阈值可显著提升设计满足率；此外，RAG 能在需求困难时给出低似然提示，帮助排除不可行方案。

**⚠️ 局限性**

局限性：适用于维度较低的设计空间；前向预测需要将每个样本展开为 d_y 个输入‑输出对，响应维度增大时计算量呈指数增长；随机森林在极大数据或极高维特征下表现不如深度网络；生成设计需采样，无法一次性给出最优解；对离散化细节仍需人工选择。

---

## 543. MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic

**arXiv ID:** 2601.13331 | [PDF](https://arxiv.org/pdf/2601.13331v1)

**作者:** Wei Wang `[一作]` (University of Cincinnati), Jun Bai `[通讯]` (University of Cincinnati)

**通讯引用:** 706 | [OpenAlex ID](https://openalex.org/A5110376155)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出MultiST模型，通过跨注意力融合空间基因表达与H&E组织图像，实现空间域识别、伪时间推断和细胞间相互作用分析。

**💡 创新点**

创新点在于使用图卷积+MLP双分支编码、对抗性Fisher‑MMD正则、图掩蔽自监督与色彩归一化的CLIP‑ViT图像编码，以及双向跨注意力机制，显著提升多模态特征对齐与边界精细化。

**🔧 技术方法**

技术方法包括图卷积网络、全连接网络、CLIP‑ViT视觉编码、跨注意力融合、GAN与Fisher‑MMD对抗正则、深度嵌入式聚类、标签扩散和伪时间回归。

**📊 数据集**

使用13份10×Visium空间转录组数据（12份人类DLPFC、1份乳腺癌）以及对应的H&E图像进行实验。

**📈 对比分析**

与BayesSpace、conST、SEDR、SpaGCN、STAGATE等SOTA方法在ARI、AMI、COM指标上进行对比，MultiST在所有数据集上获得最高或接近最高的分数，域分割更清晰、伪时间更连续、细胞互作更可靠。

**⚠️ 局限性**

局限性包括对高稀疏和混合细胞spot的鲁棒性仍有限、空间分辨率受Visium限制、模型训练与调参成本较高、对不同平台的数据需要额外适配。

---

## 544. The Tag is the Signal: URL-Agnostic Credibility Scoring for Messages on Telegram

**arXiv ID:** 2601.13294 | [PDF](https://arxiv.org/pdf/2601.13294v1)

**作者:** Yipeng Wang `[一作]` (Northeastern University), Mohit Singhal `[通讯]` (Northeastern University)

**通讯引用:** 43 | [OpenAlex ID](https://openalex.org/A5017559481)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了 Tag2Cred 框架，用闭合词表的短文本标签（主题、主张类型、行动号召、证据呈现）替代 URL/词频特征，直接对 Telegram 短消息进行可信度风险评分，并在监测阶段通过风险加权标签动态检测高危策略。

**💡 创新点**

创新点在于：① 在 URL 稀疏、短消息环境下提出完全无 URL 依赖的标签化方法；② 通过 LLM 进行标签赋值并用 L2 正则化逻辑回归校准为概率评分；③ 证明单一标签维度（CTA、主张类型）对风险判别的主导作用，并通过标签聚类与时序漂移分析实现可解释的监控。

**🔧 技术方法**

使用的大模型：Qwen‑32B（Fine‑Tuned 进行标签分配）；特征提取：稀疏多热标签向量、TF‑IDF、SBERT；分类与校准：ℓ₂ 正则化逻辑回归、Platt 标定；集成：Stacked Logistic Regression（TF‑IDF+Tag2Cred+SBERT）。

**📊 数据集**

数据集：Telegram 公共频道 234 个，总计 9,371,099 条信息；以 MBFC 评分作为远程监督的子集 87,936 条（含 URL 的 19% 约 1.79M 条）。

**📈 对比分析**

与基线（URL‑masked TF‑IDF、SBERT、PASTEL、GPT‑4o 零样本）在 10 次域离散划分下对比。Tag2Cred 在域离散、URL‑masked 条件下 AUC 0.871、macro‑F1 0.787、Brier 0.167；集成模型 AUC 0.901、macro‑F1 0.813、Brier 0.114，均显著优于 TF‑IDF（AUC 0.831、macro‑F1 0.737）和 SBERT（AUC 0.848、macro‑F1 0.748）。

**⚠️ 局限性**

限制：① 依赖 MBFC 域级评分，可能带来外部评估偏差；② 样本为 234 个频道的非随机抽样，结果可能不具普适性；③ LLM 标签化对讽刺、上下文细微差别识别不足；④ 监测主要聚焦标签级别，未对单条消息进行个体级干预。

---

## 545. A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification

**arXiv ID:** 2601.13288 | [PDF](https://arxiv.org/pdf/2601.13288v1)

**作者:** Gonzalo Ariel Meyoyan `[一作]` (Universidad de Buenos Aires), Luciano Del Corro `[通讯]` (Universidad de San Andrés)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在生产环境中直接在服务 LLM 的前向传递中训练轻量级探针，利用隐藏层的多层多标记表示实现安全与情感分类，无需额外调用单独的 guard 模型。

**💡 创新点**

创新点在于把分类视为对完整 L×T×d 隐藏张量的表示选择，提出两阶段 token‑layer 聚合架构，并通过可学习的注意力门或下采样多头自注意力动态定位最佳层级与标记，显著降低额外参数与延迟。

**🔧 技术方法**

技术核心是冻结的 decoder‑only LLM（如 Llama‑3.2‑3B）结合直接池化、可学习注意力门和下采样多头自注意力聚合模块，训练时只更新 probe 参数；推理时共享服务 LLM 的前向计算。

**📊 数据集**

数据集包括安全领域的 ToxicChat 与 WildGuardMix，以及情感分类任务的 IMDB、SST‑2 和 Emotion；探针在这些数据集上进行微调和评估。

**📈 对比分析**

与传统的单独 guard 模型（如 OpenAI Moderation、Llama‑Guard、WildGuard 等）和 logit‑only 读取方法（MULI）比较，探针在安全任务中实现了 84.5%（MHA）或 88.6%（WildGuardMix）F1，接近或匹配大模型 guard；在情感任务上 MHA probe 的准确率达 95.4%/95.3%/87.7%，与 RoBERTa/DeBERTa 等专用分类器竞争；且无需额外模型调用，延迟和显存提升显著低于两模型管线。

**⚠️ 局限性**

主要局限在于仅在 Llama‑3.2‑3B 上验证，未探讨不同架构或规模模型的泛化；探针继承了基础 LLM 的偏见与能力限制；对长序列处理存在 VRAM 限制；对极小标注数据的适应性未知；并且只能检测而不能生成解释性拒绝回应。

---

## 546. Tight Asymptotic Bounds for Fair Division With Externalities

**arXiv ID:** 2601.13287 | [PDF](https://arxiv.org/pdf/2601.13287v1)

**作者:** Frank Connor `[一作]` (McGill University), Šimon Schierreich `[通讯]` (AGH University of Krakow)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355`

**🎯 论文内容**

本文研究了在存在外部效应的无分配可分物品公平分配问题，证明在此模型下EF1分配不总是存在，并给出了最优可实现的公平度量：EF-√n，且该上界是渐进最优的。

**💡 创新点**

创新点在于：①首次证明外部效应模型下EF1无法保证；②提出并证明了EF-√n的上限与下限相匹配，构造了匹配的离散实例；③将外部效应模型转化为非对称外怨模型，再利用多彩差异（multicolor discrepancy）工具完成证明；④给出了一种在预期意义下真诚的随机机制，实现EF-n。

**🔧 技术方法**

主要技术：非对称外怨模型与外部效应模型的等价映射；多彩差异理论与不等式转换；构造二进制无任务（binary no-chores）实例的差异下界；组合这些工具得到EF-√n上限与下界。

**📊 数据集**

无实验数据集，全部为理论证明与构造实例。

**📈 对比分析**

相较于之前仅在特殊情形下已知EF1存在性，本文给出全局上界与下界，证明了最优公平度量；在随机机制方面，相比传统非一致机制，提供了预期真诚的方案；性能方面，由理论证明可在多项式时间内实现。

**⚠️ 局限性**

局限性：①只给出渐进上界与下界，缺少小规模显式反例；②对预期真诚机制的下界尚未得到匹配；③方法主要适用于可加性与外部效应模型，难以直接推广到更一般的福利/社会影响模型。

---

## 547. Function Recovery Attacks in Gate-Hiding Garbled Circuits using SAT Solving

**arXiv ID:** 2601.13271 | [PDF](https://arxiv.org/pdf/2601.13271v1)

**作者:** Chao Yin `[一作]` (Vrije University), Fabio Massacci `[通讯]` (University of Trento)

**通讯引用:** 7198 | [OpenAlex ID](https://openalex.org/A5085639552)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `5b4c1114-4a70-478e-9921-2514ee03850d` `9cc9baba-5356-466d-81ff-d80028d90279` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出并实现了一种针对门隐藏（Gate‑Hiding）加密电路的功能恢复攻击，利用电路拓扑信息和SAT求解器在有限的黑盒查询下重构隐藏的门类型。

**💡 创新点**

创新点包括：① 在门隐藏模型下首次证明仅凭拓扑泄露即可强制约束门类型，显著减小搜索空间；② 设计了基于拓扑保持简化定理的预处理（S‑Class、Z‑Class、R‑Class 分类），进一步将门类型域压缩至 3/6/8 取值；③ 开发了增量式 SAT 搜索框架，将候选门分配和判别输入的搜索拆分，避免一次性求解过大的约束，显著提升效率；④ 兼顾了隐藏输入（Threat Model B）场景。

**🔧 技术方法**

技术手段主要是：SAT 编码（变量一热编码、信号变量、门语义约束），基于 Tseitin 扩展的 CNF 约束；增量式求解与判别输入生成；拓扑保持简化定理实现的门类型域约束；使用 PySAT + Glucose3 的 SAT 求解器；对两种威胁模型（全可控输入与部分隐藏输入）分别构造求解流程。

**📊 数据集**

数据集涵盖三类：ISCAS'89 标准组合电路、常用 2PC 加密电路（加法器、比较器、汉明距离）以及用于容错传感器融合的 MPC 电路，总门数可达 768，输入/输出比接近 10‑20；实验中对所有实例执行了 24 h 限时评估。

**📈 对比分析**

与基线单一 SAT 求解器相比，优化攻击在 24 h 预算内成功恢复的电路显著更多；在同一实例上平均加速 10‑100 倍（最小 16.6 倍，最大 159 倍）。加入简化定理后，时间进一步下降，许多在基线下超时的电路能在秒级完成。判别输入数量与电路的门/输出比呈正相关，但远小于 2^输入量；查询量保持在 < 2^10，显示攻击不依赖大量 oracle 调用。

**⚠️ 局限性**

主要局限：① 未针对判别输入集的最小化，可能导致大判别集的实例耗时增长；② 只评估了固定隐藏输入 y 的随机取值，未系统分析不同隐藏输入对求解复杂度的影响；③ 对极端结构（如点函数）仍可能需要较多判别输入；④ 受限于硬件资源，未给出攻击能否扩展到更大规模电路的理论上限。

---

## 548. Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops

**arXiv ID:** 2601.13268 | [PDF](https://arxiv.org/pdf/2601.13268v1)

**作者:** Zainab Ghafoor `[一作]` (Sonoma State University), Tirtho Roy `[通讯]` (Iowa State University)

**通讯引用:** 7 | [OpenAlex ID](https://openalex.org/A5114201231)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `9cc9baba-5356-466d-81ff-d80028d90279` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并实现了一个推理时的多智能体迭代评估与修正框架，以提升医疗大型语言模型（LLM）的伦理安全性和合规性。

**💡 创新点**

创新点在于：①将生成器与评估器分离，形成可动态更新的评估策略；②采用 AMA 医学伦理原则与五级安全风险评估（SRA‑5）作为反馈标准；③通过结构化反馈在推理阶段多轮修正，避免了昂贵的模型微调。

**🔧 技术方法**

技术手段包括：生成器 DeepSeek R1 与 Med‑PaLM；评估器 LLaMA 3.1（伦理评估）与 Phi‑4（风险评估）；基于 AMA 原则的评分系统；SRA‑5 风险等级；多轮迭代框架（最多 5 次迭代）和共识融合机制。

**📊 数据集**

使用了 MedSafetyBench 提供的 900 条对抗性医疗问答（按 9 项 AMA 原则均衡划分）作为实验数据集。

**📈 对比分析**

对比方法：在相同评估条件下，分别使用 DeepSeek R1 与 Med‑PaLM 生成答案，再通过两评估器迭代修正。性能指标包括收敛率、平均迭代次数、伦理违规降低比例和风险降级率。结果显示 DeepSeek R1 的收敛率为 94.2%（平均 2.34 次迭代），违规降低 89.1%，风险降级 92.1%；Med‑PaLM 收敛率 91.8%（平均 2.67 次迭代），违规降低 85.4%，风险降级 90.6%。

**⚠️ 局限性**

局限性：①仅评估两款生成器与两款评估器，难以推广至其他模型；②评估器本身为语言模型，判断结果缺乏临床专家标注的基准；③实验仅限单轮提问，未涵盖多轮对话与上下文变化；④未针对诱导注入等针对性攻击进行鲁棒性评估；⑤缺乏与真实临床工作流的结合验证。

---

## 549. Unlearning in LLMs: Methods, Evaluation, and Open Challenges

**arXiv ID:** 2601.13264 | [PDF](https://arxiv.org/pdf/2601.13264v1)

**作者:** Tyler Lizzo `[一作]` (Georgia Institute of Technology), Larry Heck `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 6381 | [OpenAlex ID](https://openalex.org/A5003679010)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

综述了大语言模型（LLM）中的机器无学习（unlearning）方法，并对其方法、评估体系和挑战进行系统梳理。

**💡 创新点**

提出了从数据、参数、架构、混合以及其他维度的四类无学习分类框架，全面评估了现有方法的效果，并总结了评估基准、指标与未解决的技术难点。

**🔧 技术方法**

对现有技术进行归纳，包括梯度上升、合成数据替代、知识蒸馏、LoRA/任务向量、对比解码、联邦无学习、提示级与系统级干预等，形成了完整的技术地图。

**📊 数据集**

引用并分析了多种数据集与基准：TOFU、WHP、WMDP、RWKU、MMLU、HELM、BigBench、BLUR、多语言QA、OK‑VQA、SAFEERASER 等，用于评估遗忘质量与模型通用性能。

**📈 对比分析**

通过对比忘记/保留指标、p 值、归一化模型效用等，发现传统梯度上升等方法往往无法达到显著遗忘；最近方法如 UNLEARN 与 NPO 在遗忘率上优于传统方案，但在保留性能或计算成本上仍存在明显折衷。

**⚠️ 局限性**

局限性包括缺乏严格的遗忘保证、可扩展性与效率瓶颈、跨语言/跨模态评估不足、易受对抗性复学攻击、以及对边界定义与评估方法的不完善。

---

## 550. Deep Neural networks for solving high-dimensional parabolic partial differential equations

**arXiv ID:** 2601.13256 | [PDF](https://arxiv.org/pdf/2601.13256v1)

**作者:** Wenzhong Zhang `[一作]` (Suzhou Institute for Advanced Research, University of Science and Technology of China), George EM Karniadakis `[通讯]` (Brown University)

**通讯引用:** 94777 | [OpenAlex ID](https://openalex.org/A5009658255)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `14d48e9d-0069-4ad9-996a-1d5968216998` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文综述了三类针对高维抛物型偏微分方程（PDE）的深度学习求解方法，并对它们在两个典型基准问题（LQG HJB 方程和多维 Black‑Scholes 期权定价方程）上的表现进行系统对比。

**💡 创新点**

创新点在于：
1) 统一构建了 PDE 残差、SDE 期望和随机差分三大范式的框架，帮助读者快速定位不同方法的核心思想；
2) 将最新的变分/对抗实现（DeepMartNet、Shotgun）与传统 PINN、Deep BSDE 等进行同一维度、同一网络规模下的实验对照；
3) 通过大规模 GPU 计算（A100、T4）展示了这些方法在 100–1000 维问题上实际的计算时间、显存占用与误差。

**🔧 技术方法**

所采用的技术主要包括：
- PDE 残差方法：Physics‑Informed Neural Networks（PINN）、Deep Galerkin Method（DGM）、Deep Ritz Method（DRM）、随机差分 PINN（RS‑PINN）以及随机采样（SDGD、HTE）等；
- SDE 相关方法：Deep BSDE、Deep BSDE 变种、FBSNN、Actor‑Critic、Diffusion Monte Carlo、Picard 迭代；
- 混合/无微分方法：DeepMartNet（基于马尔可夫性与弱形式）和 Shotgun（随机差分强形式）。

**📊 数据集**

使用的“数据集”是人工生成的高维数值测试集：
1) HJB 方程：100 维和 1000 维的 Rosenbrock 目标函数；
2) Black‑Scholes 方程：在 100 维与 1000 维的欧式最大期权（max_i x_i – a）的终端条件，测试点均匀分布在 [90,110]^d。所有结果均通过 Monte‑Carlo 采样验证。

**📈 对比分析**

性能对比（以相对 L² 误差 RE₂、显存 MB、GPU 运行时间为指标）：
- HJB：DeepMartNet 在 1000 维时 RE₂=3.14×10⁻³、显存 9633 MB、时间 260 s；PINN‑SDGD RE₂=6.08×10⁻³、显存 1844 MB、时间 217 m；Deep BSDE RE₂=3.76×10⁻³、显存 1856 MB、时间 678 s；Shotgun RE₂=2.59×10⁻³、显存 8192 MB、时间 867 s。整体来看，随机差分/无微分方法在极高维度下误差更小但显存和时间消耗更大；PINN 在显存和时间上更优，但误差相对较高。
- Black‑Scholes：在 1000 维时 DeepMartNet RE₂=8.27×10⁻³、显存 8310 MB、时间 110 s；Deep BSDE RE₂=6.17×10⁻³、显存 1896 MB、时间 676 s；PINN RE₂=1.42×10⁻²、显存 510 MB、时间 60 s；Shotgun RE₂=1.48×10⁻²、显存 7431 MB、时间 642 s。可见，在该类金融 PDE 中，PINN 在计算效率上最优，Deep BSDE 在误差与显存之间取得折中，DeepMartNet 及 Shotgun 在显存消耗较大但误差可控。

**⚠️ 局限性**

局限性包括：
1) 仍受“维数灾难”影响，误差、显存与时间随维度快速增长；
2) 大部分方法（SDE、随机差分）仅适用于抛物型/椭圆型 PDE，无法处理一般超平面边界或非局部算子；
3) 对 PDE 残差方法的采样策略（尤其在高维非有限域）缺乏理论保证，导致在梯度骤变或复杂结构解时收敛慢；
4) DeepMartNet 等对抗/弱形式训练需要额外的测试网络、梯度更新，易出现训练不稳定；
5) 目前实验主要聚焦于单一终端条件与简单边界，缺乏对多终端、非线性边界、随机系数等更一般场景的验证。

---

## 551. ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection

**arXiv ID:** 2601.13234 | [PDF](https://arxiv.org/pdf/2601.13234v1)

**作者:** Md. Nishan Khan `[一作]` (North South University), M. Monir Uddin `[通讯]` (North South University)

**通讯引用:** 386 | [OpenAlex ID](https://openalex.org/A5088467986)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出并实现了ConvMambaNet框架，用于实时精准癫痫发作检测

**💡 创新点**

将Mamba结构状态空间模型块嵌入CNN架构，实现高效长程时间建模且计算成本低的创新设计

**🔧 技术方法**

采用CNN、Mamba SSM、注意力机制、Adam优化以及He/Kaiming等初始化技术

**📊 数据集**

使用CHB‑MIT scalp EEG数据集进行实验验证

**📈 对比分析**

与CNN、RNN、Transformer等基线模型比较，ConvMambaNet在准确率99%、F1 0.99、AUC 0.97等指标上表现最佳，同时训练速度更快

**⚠️ 局限性**

对跨人群泛化的验证仍有限，对极端噪声鲁棒性尚未充分评估

---

## 552. Privacy Starts with UI: Privacy Patterns and Designer Perspectives in UI/UX Practice

**arXiv ID:** 2601.13342 | [PDF](https://arxiv.org/pdf/2601.13342v1)

**作者:** Anxhela Maloku `[一作]` (Technical University of Munich), Florian Matthes `[通讯]` (Technical University of Munich)

**通讯引用:** 3907 | [OpenAlex ID](https://openalex.org/A5022973212)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `9cc9baba-5356-466d-81ff-d80028d90279` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本研究通过系统文献综述、15次半结构化访谈以及两场交互式研讨会，系统化了UI/UX设计中的14个隐私考虑，并基于此创建并验证了一个可操作的UI/UX隐私模式目录与对应的Figma组件库。

**💡 创新点**

创新点在于首次将隐私考虑与影响因素完整归纳为14个问题与14个因素，并将专家视角融入设计科学研究，产出了可直接落地的隐私模式目录和实用的设计组件库。

**🔧 技术方法**

研究方法包括系统文献综述（SLR）、主题编码访谈分析、设计科学研究（DSR）、交互式研讨会与线上问卷评估，并结合Figma原型工具进行实践验证。

**📊 数据集**

所使用的数据集包含：102篇相关学术文献、15位UI/UX从业者访谈记录，以及11名研讨会参与者的问卷反馈。

**📈 对比分析**

通过与现有隐私模式/暗黑模式文献的对比，并结合研讨会与问卷反馈，验证了模式目录的可用性和实用性；调查数据显示平均满意度达4.2/5，表明其在实际设计中的接受度较高。

**⚠️ 局限性**

研究局限包括：文献检索仅使用Google Scholar标题过滤，样本主要来自欧洲且缺乏行业/领域深度，未区分UI与UX，以及研讨会未录音导致部分讨论细节缺失。

---

## 553. Reduction for Structured Concurrent Programs

**arXiv ID:** 2601.13341 | [PDF](https://arxiv.org/pdf/2601.13341v1)

**作者:** Namratha Gangamreddypalli `[一作]` (Ecole Polytechnique), Shaz Qadeer `[通讯]` (Microsoft)

**通讯引用:** 9796 | [OpenAlex ID](https://openalex.org/A5072464909)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

提出一种新的结构化并发程序约简技术，能够将并行组合安全地转换为顺序组合，并支持包含递归过程调用的原子段；

**💡 创新点**

创新点在于统一并行到顺序的约简与Lipton移动者理论的扩展，使两种约简可任意组合，显著提升了约简范围与灵活性；

**🔧 技术方法**

使用移动者类型系统、静态分析与seq‑reduce / par‑reduce 注解，并在 Civl 之上实现自动化的类型检查和证明条件生成；

**📊 数据集**

在四个典型案例上验证：并发快照对象、ABD 可容错寄存器、FLASH 缓存一致性协议以及两阶段提交协议；

**📈 对比分析**

与现有 QED/Civl 方法对比，所有案例的证明均在几秒内完成，注解行数占实现+规范行数的比例为 0.31–0.88，证明规模小且执行时间短；

**⚠️ 局限性**

局限性包括需要手工验证右移动者不失败、左移动者终止性等附加条件，以及对超大规模动态线程生成的支持仍有限。

---

## 554. SEER: Spectral Entropy Encoding of Roles for Context-Aware Attention-Based Design Pattern Detection

**arXiv ID:** 2601.13334 | [PDF](https://arxiv.org/pdf/2601.13334v1)

**作者:** Tarik Houichime `[一作]` (Mohammed V University In Rabat), Younes El Amrani `[通讯]` (Mohammed V University In Rabat)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

构建了 SEER——一种将图拉普拉斯谱熵角色编码和时序调用上下文嵌入 Transformer 之中的行为‑结构序列模型，用于检测 23 种 GoF 设计模式。

**💡 创新点**

创新点在于利用类内交互图的谱熵生成对象角色的唯一“光谱指纹”，并将经验加权的调用时长纳入上下文，使模型能在保持语言无关的前提下更精准地区分同构结构中的不同角色。

**🔧 技术方法**

技术方案包括：行为‑结构序列（BSS）抽象、拉普拉斯谱熵计算与角色嵌入、调用时长权重编码、双流 Transformer 编码器以及基于符号+谱熵的向量融合。

**📊 数据集**

使用 PyDesignNet 数据集，该数据集包含 1,832 个 Python 文件、35,000 条行为‑结构序列，覆盖全部 23 个 GoF 设计模式。

**📈 对比分析**

与前身 BSS 及 FeatureMap、MARPLE‑DPD 等三类主流方法对比，SEER 在 PyDesignNet 上取得 93.98% 的准确率、93.20% 的宏 F1 分数，提升 1.46pp 和 0.72pp，且误报率下降近 20%。

**⚠️ 局限性**

局限性包括：对多态/重载细节、参数级语义缺乏建模；对极端结构变化或代码生成的鲁棒性尚待验证；跨语言泛化仅通过关键词映射可行，实际部署需针对不同语言细调；以及依赖可执行代码与运行时采样的前置条件。

---

## 555. Deep Learning for Semantic Segmentation of 3D Ultrasound Data

**arXiv ID:** 2601.13263 | [PDF](https://arxiv.org/pdf/2601.13263v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 556. RegCheck: A tool for automating comparisons between study registrations and papers

**arXiv ID:** 2601.13330 | [PDF](https://arxiv.org/pdf/2601.13330v1)

**作者:** Jamie Cummins `[一作]` (University of Oxford), Malte Elson `[通讯]` (University of Bern)

**通讯引用:** 3798 | [OpenAlex ID](https://openalex.org/A5076659092)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发并公开了RegCheck，一个基于LLM的工具，用于自动提取并对比研究注册与论文，帮助科研者、审稿人和编辑检查偏差。

**💡 创新点**

创新点在于提供标准化工作流、支持自定义维度、保持人机循环并生成可共享报告，解决传统手工比对耗时难以复现的问题。

**🔧 技术方法**

采用大语言模型（如ChatGPT‑5等）、embedding（OpenAI text‑embeddings‑3‑large）、GROBID/DPT‑2 文档解析、检索增强生成（RAG）以及嵌入检索与LLM判断。

**📊 数据集**

使用用户上传的注册文件（可来自ClinicalTrials.gov等）和论文PDF/Word；并无公开固定数据集，系统主要依赖上传内容。

**📈 对比分析**

方法：为每个维度构造查询，利用embedding检索相关段落，LLM生成摘要并给出偏差判断；据作者经验，准确率较高，能捕捉多种偏差，但仍需人工核实，误报/漏报尚未系统量化。

**⚠️ 局限性**

局限性：缺乏系统性评估与基准；对LLM的准确性与误报率依赖；跨学科性能差异尚未充分验证；隐私敏感内容使用受限；未给出详细错误率或鲁棒性分析。

---

## 557. PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion

**arXiv ID:** 2601.13327 | [PDF](https://arxiv.org/pdf/2601.13327v1)

**作者:** Po-Yu Liang `[一作]` (University of Cincinnati), Jun Bai `[通讯]` (University of Cincinnati)

**通讯引用:** 706 | [OpenAlex ID](https://openalex.org/A5110376155)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `09944146-298c-433e-89df-37255de463d7` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `f86bf285-fd08-4156-973b-6e6481af8fa0` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出并实现了基于BERT的注意力扩散模型，用于生成蛋白质结合位点的嵌入，并结合分子动力学模拟验证了所生成肽段与TIGIT受体的结合能力。

**💡 创新点**

创新点在于将时间相关的分数扩散模型与BERT架构相结合，并通过高斯随机傅里叶特征编码时间步，实现对蛋白质序列嵌入的可扩展生成；同时在MD模拟中引入自适应窗口的umbrella采样提高结合能估计的精度。

**🔧 技术方法**

技术包括BERT、ProtT5嵌入、score-based diffusion、Gaussian random Fourier features、cosine variance schedule、GROMACS 2023、OPLS-AA力场、SPC/E水模型、AlphaFold2结构预测、NVT/NPT平衡、umbrella采样与WHAM。

**📊 数据集**

数据集方面主要使用训练集的蛋白质序列嵌入（来自ProtT5），以及用于验证的AlphaFold2预测肽段结构；TIGIT受体结构采用PDB 3Q0H。

**📈 对比分析**

文中未给出与现有方法的定量比较或性能指标，主要通过分子动力学模拟和结合能估计展示模型生成肽段的结合潜力。

**⚠️ 局限性**

限制包括缺乏公开的评估基准与量化结果，扩散模型的训练时间和资源需求较高，以及MD模拟仅对少量肽段进行，未覆盖更大规模的实验验证。

---

## 558. Probabilistic Linear Logic Programming with an application to Bayesian Networks computations

**arXiv ID:** 2601.13270 | [PDF](https://arxiv.org/pdf/2601.13270v1)

**作者:** Matteo Acclavio `[一作]` (University of Sussex), Roberto Maieli `[通讯]` (Roma TRE University)

**通讯引用:** 84 | [OpenAlex ID](https://openalex.org/A5048741973)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c`

**🎯 论文内容**

将贝叶斯网络的概率计算嵌入到多头方法与概率注解的线性对象（Linear Objects）逻辑程序中，实现通过证明搜索直接计算联合和边缘概率。

**💡 创新点**

创新点在于：①引入多头方法并为其赋予概率标注，打破传统单头规则的树形限制；②利用线性逻辑的资源敏感性，保证每个网络节点只被计算一次；③通过证明搜索与概率乘法天然耦合，实现无外部语义解释的概率推理。

**🔧 技术方法**

使用技术包括：线性逻辑（尤其是多加法-乘法片段）、聚焦证明（focused proofs）、多头方法（bipoles）以及在规则上附加概率值的操作语义；贝叶斯网络的条件概率表被编码为概率多头方法。

**📊 数据集**

论文主要使用经典的五变量示例网络（Cloudy、Sprinklers、Rain、WetGrass、TrafficJam）作为实验数据，并未使用公开数据集或大规模网络。

**📈 对比分析**

方法比较主要通过证明理论给出正确性证明，未与现有贝叶斯推理引擎（如Variable Elimination、Junction Tree等）进行实验对比；性能评估在本文中未展开。

**⚠️ 局限性**

局限性：①仅支持布尔型变量，无法直接扩展到多值或连续变量；②缺乏针对大规模网络的优化（如树结构、变分推理、剪枝等）；③概率选择仍需在目标中显式写出，缺少动态抽样或概率分支策略；④未提供实验验证，难以评估实际执行效率。

---

## 559. A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus

**arXiv ID:** 2601.13253 | [PDF](https://arxiv.org/pdf/2601.13253v1)

**作者:** Ebubekir Tosun `[一作]`, Mahmoud ElHussieni `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `67630363-6be0-4f51-ab05-7198250671a5` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了规模最大的土耳其语语义关系语料库（843,000对），通过FastText聚类、Gemini LLM自动标注以及词典校验三阶段混合流程完成。

**💡 创新点**

创新点在于将无监督的嵌入聚类与多语言LLM生成相结合，并通过外部词典实现质量校验，实现低成本（约$65）大规模语义关系自动生成。

**🔧 技术方法**

使用的技术包括FastText嵌入、层次凝聚聚类、Gemini 2.5‑Flash LLM标注、JSONL格式化、Siamese multilingual‑e5‑large 句子编码、CMNRL 对比学习以及基于Transformer的关系分类模型。

**📊 数据集**

所用数据集包括110k条专家整理的法律与技术词条、Facebook预训练的FastText土耳其语词向量、约20k条土耳其同义词词典条目，最终合并成83万条人工与LLM生成的关系对。

**📈 对比分析**

通过对检索模型的Top‑1召回率（90%）和关系分类模型的宏F1（90%）进行评估，并与六种Transformer候选模型对比，最终选取turkish‑e5‑large作为最佳模型。

**⚠️ 局限性**

局限性包括98%数据为LLM合成，可能引入模型偏差；主要聚焦法律领域导致域偏倚；词汇覆盖未完全展开所有形态变位；以及需定期更新以跟随术语演变。

---

## 560. Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph

**arXiv ID:** 2601.13251 | [PDF](https://arxiv.org/pdf/2601.13251v1)

**作者:** Ebubekir Tosun `[一作]`, Mahmoud ElHussieni `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

构建了一个大规模无反义词的同义词聚类系统，覆盖15M词条生成约290万高精度同义词簇。

**💡 创新点**

创新点在于(1) 生成84.3万标注的三类关系数据集；(2) 训练90% macro‑F1的三类关系判别器；(3) 提出软转硬的两阶段聚类算法以消除语义漂移和多义词。

**🔧 技术方法**

技术包括Gemini 2.5‑Flash LLM数据增强、Transformer句对分类器、FAISS GPU向量搜索、两阶段软聚类+拓扑投票、语义中心父节点选择等。

**📊 数据集**

使用84.3万对的同义/反义/共义关系数据集（827k LLM生成+16k字典），以及15M词向量（来自多语种e5‑large微调）。

**📈 对比分析**

与多种基线（Louvain、Leiden、Watset、对抗微调）对比，最终同义词图在精度上提升至90% macro‑F1，簇大小均衡，最大86，避免了反义词误并入。

**⚠️ 局限性**

局限包括对低质量OCR/拼写错误仍有残留、对极低频词或新词缺乏覆盖、聚类阈值需经验调参、模型与LLM生成标签的依赖性。

---

## 561. A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms

**arXiv ID:** 2601.13243 | [PDF](https://arxiv.org/pdf/2601.13243v1)

**作者:** Yapeng Li `[一作]` (Harbin Institute of Technology), Tonghua Su `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 669 | [OpenAlex ID](https://openalex.org/A5033324841)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

对大型语言模型（LLM）的多种推理范式（直接单模型、Chain‑of‑Thought、以及四种典型多智能体工作流）进行统一评估，并推出了新的开放式基准 MIMeBench，专门测评语义抽象与对比辨识能力。

**💡 创新点**

①在单模型与多智能体之间系统比较成本‑准确率权衡；②引入 MIMeBench，聚焦语义抽象与对比辨识，填补闭式基准对语义深度不足的空白；③通过角色隔离与成本分布分析揭示不同工作流对模型能力与资源的具体需求。

**🔧 技术方法**

使用 LLM 推理、Chain‑of‑Thought（CoT）自适应推理、基于角色的多智能体工作流（Plan‑and‑Execute、Reflection、Interactive Debate、Adversarial Debate）、LLM 判定器评测、token‑成本追踪与统计分析等技术。

**📊 数据集**

闭式基准：GSM8K、GSM‑Hard、AIME‑24、AQUA、ARC‑Easy/Challenge、CommonsenseQA、GPQA‑Diamond、HumanEval、HumanEval+；开放式基准：新构建的 MIMeBench（100 篇主旨摘要题，包含四选一选项）。

**📈 对比分析**

采用零样本评估配合 LLM 判定器对比 Pangu‑7B 与 Qwen3 系列及 DeepSeek；CoT 推理提升显著（尤其在 AIME‑24 与 HumanEval+ 上），多智能体在某些任务提升但存在收益递减；MIMeBench 上 Pangu‑7B 在语义抽象与对比辨识得分高于大多数通用 7B 级模型。

**⚠️ 局限性**

研究仅基于 Pangu‑7B 与四种代表性工作流，未扩展到更大模型或更多工作流；成本评估仅使用 token 计量，未考虑实际延迟或硬件差异；MIMeBench 的评判标准与基准设置仍有改进空间。

---

## 562. RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions

**arXiv ID:** 2601.13235 | [PDF](https://arxiv.org/pdf/2601.13235v1)

**作者:** Drishti Goel `[一作]` (University of Illinois Urbana-Champaign), Koustuv Saha `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 3141 | [OpenAlex ID](https://openalex.org/A5057029055)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a6cb313d-240c-4723-a372-3ba1f39b9afc`

**🎯 论文内容**

提出了一种以照护伦理为理论基础、经过临床验证的 Rubric-based Risk Index，用于评估与护理相关的 LLM 生成回复中的风险，并通过逐轮反馈迭代改进模型回复，显著降低风险；

**💡 创新点**

创新点在于将照护伦理的五个风险维度（无视、偏见与污名、信息不准、无批判性肯定、认知自负）转化为可操作的评估量表，构建了基于该量表的评估与修正循环；

**🔧 技术方法**

技术包括六大现有 LLM（GPT‑4o‑mini、Claude Sonnet 4、Phi‑3 Mini、Qwen3‑4B、Medichat‑Llama3‑8B、MedAlpaca‑7B），使用 GPT‑5‑nano 作为客观评审者生成评估分数与改进建议，并在同一模型上实施两轮迭代修正；

**📊 数据集**

使用超过 20,000 条来自 Reddit（r/Alzheimers、r/CaregiverSupport）和 ALZConnected 的真实护理者提问数据，构建 ADRD‑Caregiver 与 General‑Caregiver 两大数据集；

**📈 对比分析**

方法通过对比初始回复与第 1 轮、第 2 轮回复的 Rubric‑score 进行配对 t 检验与 Cohen d 估计；结果显示所有模型在第 1 轮后风险分数下降 45–98%，其中 GPT‑4o‑mini、Claude、Phi‑3 下降幅度最高；

**⚠️ 局限性**

局限性包括：量表仅针对 ADRD 场景，可能不适用于其他护理领域；评估依赖 LLM（GPT‑5‑nano）可能带来偏差；采用二元评分忽略风险严重程度；未直接测量对护理者福祉或决策的长期影响；

---

## 563. MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation

**arXiv ID:** 2601.13232 | [PDF](https://arxiv.org/pdf/2601.13232v1)

**作者:** Kourosh Darvish `[一作]` (University of Toronto), Animesh Garg `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 4986 | [OpenAlex ID](https://openalex.org/A5061193324)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `25d64835-ec5b-425b-899d-a6e1e6fecabd` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

开发了一套多尺度、GPU加速的机器人仿真框架（Matterix），用于构建化学实验室数字孪生，能够高保真地模拟机械操作、粒子流体、热传导、化学动力学以及实验设备功能，并实现从虚拟环境到真实实验的无缝迁移。

**💡 创新点**

创新点包括：1）集成语义引擎，将热传递、化学反应等非物理行为与Isaac Sim物理引擎协同；2）基于层次化状态机与可学习技能库的工作流设计；3）提供丰富的资产库及NeRF 3D重建工具，简化环境搭建；4）实现大规模GPU并行仿真，保持高帧率；5）实现真实环境感知与仿真同步，支持实时调试。

**🔧 技术方法**

技术栈：NVIDIA Isaac Sim + Isaac Lab、PBD 粒子模拟、PyTorch GPU并行语义引擎、FoundationPose 6D pose 估计、cuRobo 运动规划、PPO 强化学习、NeRF 3D 重建、USD 资产描述。

**📊 数据集**

使用公开资产库（玻璃器皿、机器人、自动化平台等）、化学反应数据库（SMARTS 模板与参数）、实验室实景视频（NeRF 训练）以及实验室传感器数据（相机、温度、流量等）来构建和验证数字孪生。

**📈 对比分析**

与真实实验对比：S_N1 反应温度调控、红氧实验的颜色变化、pick‑and‑place、液体倒灌和液体处理等任务中，仿真成功率分别为 75%、90% 等；热传递语义引擎对 FPS 影响仅 3%；在 2048/4096 并行环境下，GPU 负载增幅 < 4%，显示出高效的可扩展性；相较于单任务或无语义引擎的仿真，提供完整实验流程与无缝迁移能力。

**⚠️ 局限性**

局限性：1）化学动力学采用近似模型，缺乏量子化学精度和气相反应支持；2）反应模板有限，仅支持前向单一步骤；3）仿真与现实差距导致姿态估计误差；4）缺乏工作流的自适应恢复与容错机制；5）需要进一步集成实时传感器反馈与自适应学习以提升逼真度。

---

## 564. Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation

**arXiv ID:** 2601.13228 | [PDF](https://arxiv.org/pdf/2601.13228v1)

**作者:** Tianqi Du `[一作]` (Peking University), Yisen Wang `[通讯]` (Peking University)

**通讯引用:** 5308 | [OpenAlex ID](https://openalex.org/A5101431030)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了Any-order Any-subset Autoregressive modeling (A3) 框架，实现任意顺序、任意子集的并行生成。

**💡 创新点**

创新点在于将扩散模型的平行预测结构与自回归的递归依赖融合，构造双流注意力和逐步训练课程，既保持AR的深度依赖，又兼顾扩散的灵活性。

**🔧 技术方法**

采用双流注意力网络、递归分组预测、渐进式训练（从单 token 逐步扩展到任意子集）以及两种解码策略（group-wise AR 采样和动态重采样）。

**📊 数据集**

训练数据为 FineWeb 与 SlimPajama 语料混合，采样 2B token；评估使用 TriviaQA、HellaSwag、Winogrande、SIQA、PIQA、ROCStories 等标准数据集。

**📈 对比分析**

与传统 AR（LLaMA）和多种扩散模型（Plaid、Dream、DiffuLlama）对比，A3 在 QA、推理和填空任务上均超越扩散模型，虽然与大规模 AR 仍有差距，但表现随模型规模和数据量显著提升。

**⚠️ 局限性**

局限在于需额外的训练阶段和复杂的注意力设计，且在数据量不足时仍落后于纯 AR 模型；解码时动态重采样虽效果好但速度慢。

---

## 565. Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?

**arXiv ID:** 2601.13227 | [PDF](https://arxiv.org/pdf/2601.13227v1)

**作者:** Laura Dietz `[一作]` (University of New Hampshire), James Mayfield `[通讯]` (Johns Hopkins University)

**通讯引用:** 3773 | [OpenAlex ID](https://openalex.org/A5036270568)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了在检索增强生成（RAG）系统评估中利用内部信息（评估框架、评估提示、黄金nugget）来提升评估分数的风险，并通过设计子版本探针对该风险进行实验验证。

**💡 创新点**

创新点在于系统化展示三类内部信息对LLM评判器的影响，提出了RAGE系统及其子版本，首次量化内部信息导致的评价失真，并针对如何通过盲测与多样化方法来防御此类攻击提出建议。

**🔧 技术方法**

技术手段包括：基于LLM的自动评判器（AutoNuggetizer）与nugget匹配、句子提取与生成、以及自定义提示过滤（citation filter、nugget cover filter）来模拟内部信息泄露；还使用LLM模型（GPT‑4o、Qwen3 等）完成检索、提取与生成。

**📊 数据集**

数据集为TREC NeuCLIR 2024 报告生成任务的测试集，包含10M多语种文档、人工标注的gold nugget（无LLM参与），并在TREC 2025 RAGTIME/DRAGUN 任务中进行验证。

**📈 对比分析**

对比基线系统（GINGER、GINGER‑Llama、GptResearcher、BulletPoints）和 RAGE 的各变体，发现：① 具备评估框架知识的系统在 nugget recall、density 等指标上提升 78%–417%；② 使用评估提示过滤可在 citation support、nugget recall 上小幅提升；③ 直接使用 gold nugget 作为系统 nugget 可使 nugget recall 进一步提升 42%–65%，但其他指标无显著改进；整体来看，内部信息泄露能显著扭曲自动评估结果。

**⚠️ 局限性**

局限性包括：实验仅基于自动评判器，缺少全面的人类评估验证；TREC NeuCLIR 是唯一可用的全人工 nugs 数据集，实验结果可能不易推广；子版本探针未考虑对长篇生成质量的主观影响；以及未评估不同 LLM 模型对攻击效果的敏感性。

---

## 566. The Query Complexity of Local Search in Rounds on General Graphs

**arXiv ID:** 2601.13266 | [PDF](https://arxiv.org/pdf/2601.13266v1)

**作者:** Simina Brânzei `[一作]` (Purdue University), Dimitris Paparas `[通讯]` (Google Research)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b` `5b4c1114-4a70-478e-9921-2514ee03850d` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

在一般图上研究局部搜索的查询复杂度，给出在 t 轮交互下寻找局部最小值的确定性上界与随机下界，并对并行斜坡下降（parallel steepest descent）算法进行分析。

**💡 创新点**

创新点在于把图的分离数（separation number）引入复杂度分析，得到上界 O(t·n^{1/t}(sΔ)^{1-1/t})；提出随机下界 Ω(t·n^{1/t}-t)，并展示当分离数较大时并行算法能取得更优表现；同时构造了基于树的硬性输入分布，实现对任意图的下界证明。

**🔧 技术方法**

利用分离数理论与分裂引理（shattering lemma）、Yao 对偶与随机试验、树结构的符号（signature）分析、球查询与并行斜坡下降算法；在证明中频繁使用最小/最大邻居、树深度、收缩因子等图论与算法工具。

**📊 数据集**

本工作为理论分析，无实验数据集；示例场景包括线性回归（网格图）、超参数优化（高维连续空间离散化）、鲁棒矩阵估计（矩阵图）等，但所有结果均为理论上界与下界。

**📈 对比分析**

与已有的格点分析（grid）和随机游走、量子查询下界等方法对比，提出的上界在分离数 s=Θ(n) 时退化为 O(n)，但在 s≪n 时显著优于传统 O(n)；随机下界与已知的 Ω(√n) 等结论保持一致，且对 t≥2 的情况给出了更一般的下界。性能上可视为在给定 t 与 Δ 的条件下获得渐进最优或接近最优的查询复杂度。

**⚠️ 局限性**

限制包括：上界依赖于分离数 s，若 s 接近 n 则失去优势；下界仅在随机算法与 t 轮交互下成立，对特殊图结构（如非常稠密或极稀疏）可能不是最优；假设局部最小值唯一，实际问题中可能出现多重局部最小值导致分析不完全对应。

---

## 567. Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room

**arXiv ID:** 2601.13406 | [PDF](https://arxiv.org/pdf/2601.13406v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

---

## 568. AfroScope: A Framework for Studying the Linguistic Landscape of Africa

**arXiv ID:** 2601.13346 | [PDF](https://arxiv.org/pdf/2601.13346v1)

**作者:** Sang Yun Kwon `[一作]` (University of British Columbia), Muhammad Abdul-Mageed `[通讯]` (University of British Columbia)

**通讯引用:** 4022 | [OpenAlex ID](https://openalex.org/A5004629670)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了覆盖 9 个语言家族、7 种书写系统、9 个领域的 AfroScope 大规模多语种数据集，并提出统一的非洲语言识别框架。

**💡 创新点**

创新点包括：统一覆盖、针对同源语言的层次式细粒度判别、对冲突词汇的专门对比嵌入模型 Mirror‑BERT，以及跨语言转移与域效应的系统分析。

**🔧 技术方法**

使用技术包括：FastText、XLM‑RoBERTa 变体 Serengeti、T5 基础 Cheetah、对比学习的 Mirror‑BERT、层次推理路由以及 4‑gram 污染检测。

**📊 数据集**

数据集为 AfroScope，整合 11 个公开来源，总计约 1.98 亿句子，覆盖 2,000+ 非洲语言。

**📈 对比分析**

通过内部测试和外部各子集评估，基线模型宏 F1 约 90%，使用 Mirror‑BERT 在 29 个易混淆语言上提升 4.55%，并在资源不足的语言上实现与高资源语言相当的性能。

**⚠️ 局限性**

限制包括：仅单标签判别，无法处理混合/代码切换文本；依赖 Ethnologue 的语言分类和脚本标签；置信度阈值固定，校准不完善，导致部分语言表现下降。

---

## 569. A Scientific Data Integrity system based on Blockchain

**arXiv ID:** 2601.13425 | [PDF](https://arxiv.org/pdf/2601.13425v1)

**作者:** Gian Sebastian Mier Bello `[一作]` (Universidad Industrial de Santander), Luis A. Núñez `[通讯]` (Universidad Industrial de Santander)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

开发并测试了基于 Hyperledger Fabric 的区块链原型，用于验证并保障 LAGO 项目测量与模拟数据的完整性，采用离链存储模型，仅将哈希与元数据写入链上

**💡 创新点**

将区块链与 HPC 结合，提供多机构多节点环境下的权限控制、可追溯性和易增添新记录功能，并通过离链存储避免块大小限制，形成完整事务签名与链码验证流程

**🔧 技术方法**

使用 Hyperledger Fabric 2.5、RAFT 共识、X.509 证书身份、Chaincode (ScientificDataCollectContract)、Node.js gateway、Docker、Hyperledger Explorer、SHA‑256 哈希与 ECDSA 签名等技术

**📊 数据集**

使用 LAGO 公开数据子集，包括 31 个 WCD 的原始测量（L0、L1 等）以及 One Data Hub 的模拟数据

**📈 对比分析**

通过在链上直接篡改哈希和签名进行恶意攻击实验，使用 Blockchain Verifier 检测到哈希不匹配和签名失效，验证了完整性保障；在测试网络中平均每 2 秒产生一个区块，约 8 交易/分钟，展示了可扩展性；未给出与传统数据库的性能基准

**⚠️ 局限性**

需要保证节点同步与一致性，离链存储无法防止数据本身被篡改，区块链不适合存储大文件，随着网络规模扩大，可能面临可扩展性与容错性挑战

---

## 570. Driving Computational Efficiency in Large-Scale Platforms using HPC Technologies

**arXiv ID:** 2601.13424 | [PDF](https://arxiv.org/pdf/2601.13424v1)

**作者:** Alexander Martinez Mendez `[一作]` (Universidad Industrial de Santander), Luis A. Núñez `[通讯]` (Universidad Industrial de Santander)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

分析并优化拉丁美洲巨型观测站（LAGO）在EGI FedCloud HPC平台上的任务级并行工作负载的资源利用效率，量化CPU、壁钟时间与I/O效率，并给出改进建议。

**💡 创新点**

首次将任务并行模型与HPC资源利用率指标结合，针对测试作业与工作负载异质性提出数据驱动的资源请求与工作流管理优化方案。

**🔧 技术方法**

使用Slurm作业日志、LAGO VO元数据、Docker容器化工作流、统计与可视化工具，对CPU效率、壁钟效率、失败率等指标进行评估。

**📊 数据集**

基于LAGO在EGI FedCloud平台的历史作业计费与系统监控日志，涵盖Monte Carlo模拟、数据处理与用户分析等工作负载。

**📈 对比分析**

通过计算不同工作负载类别（W1–W3）的CPU/壁钟效率分布与经验阈值对比，发现MC模拟几乎100%效率，数据处理60–75%，用户测试约40%，并指出测试作业对平均值的扭曲。

**⚠️ 局限性**

受限于作业级日志缺失内存峰值、并行内部细粒度利用难度，测试作业混入导致平均指标失真，手工工作流管理缺乏完整捕获，难以全面评估整套任务并行方案。

---

## 571. Deep Image Prior with L0 Gradient Regularizer for Image Smoothing

**arXiv ID:** 2601.13400 | [PDF](https://arxiv.org/pdf/2601.13400v1)

**作者:** Nhat Thanh Tran `[一作]`, Jack Xin `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种基于深度图像先验的无监督图像平滑框架 DIP-ℓ0。

**💡 创新点**

创新点在于将 ℓ0 梯度正则化融入 DIP，并针对非凸非光滑目标设计了 ADMM 方案。

**🔧 技术方法**

使用技术包括深度图像先验（编码‑解码网络）、ℓ0 梯度正则、ADMM 优化以及 Region Fusion 作为 ℓ0 求解器。

**📊 数据集**

主要使用 NKS 数据集进行评估，并对 JPEG 低质量压缩的 10 张 clip‑art 图像进行实验。

**📈 对比分析**

与 14 种传统与深度滤波器比较，DIP-ℓ0 在边缘保留图像平滑和 JPEG 噪声去除方面取得了最高 PSNR，并在大多数指标上领先。

**⚠️ 局限性**

缺点是计算量大，需要在每张图像上训练网络，T=100 时耗时数分钟。

---

## 572. Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models

**arXiv ID:** 2601.13368 | [PDF](https://arxiv.org/pdf/2601.13368v1)

**作者:** Zhenjiang Mao `[一作]` (University of Florida), Anirudhh Venkat `[通讯]` (University of Florida)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 Recurrent Confidence Chain (RCC) 框架，用于在多步推理中对大型语言模型的不确定性进行量化。

**💡 创新点**

创新点包括使用跨步注意力建模语义依赖、设计线性复杂度的递归置信传播机制，以及将语义相关性与时间置信跟踪统一到一个框架。

**🔧 技术方法**

技术方法主要是基于注意力机制的跨步关联、软最大化置信值、阈值过滤、递归更新公式以及超参数 δ 的调节。

**📊 数据集**

实验数据集为中国高考数学基准（GAOKAO Math）和 CLadder 因果推理数据集。

**📈 对比分析**

与平均对数、最终答案对数、自我一致性、自我评估、SAR 以及 UQAC 等基线进行对比，RCC 在 NLL 和 ECE 指标上均优于其他方法，表现出更好的锐度与校准平衡。

**⚠️ 局限性**

局限性在于对多头注意力的处理不完善，无法动态确定最佳头部以及在过度传播与校准之间的权衡，且目前仅验证在特定模型与数据集上。

---

## 573. Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments

**arXiv ID:** 2601.13364 | [PDF](https://arxiv.org/pdf/2601.13364v1)

**作者:** Zhenan Liu `[一作]` (University of Waterloo), George Shaker `[通讯]` (University of Waterloo)

**通讯引用:** 3214 | [OpenAlex ID](https://openalex.org/A5060296994)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种实时、独立的4D毫米波雷达感知系统，用于在尘埃浓度高、障碍物多的封闭环境中进行人员检测；

**💡 创新点**

创新点包括：①在受限空间内实现可控多级尘埃生成方法并基于此构建新的4D雷达数据集；②设计了基于RCS、速度、方位角和仰角的阈值噪声过滤框架；③采用KD‑tree聚类与规则化语义阈值的分类管线，消除多路径假目标并实现无需大规模训练集的实时行人识别；

**🔧 技术方法**

使用了4D毫米波雷达、红外相机、激光雷达；阈值过滤、KD‑tree聚类、规则化语义特征分类；与YOLOv8视觉检测模型对比；

**📊 数据集**

新构建的4D毫米波雷达数据集（含摄像头和LiDAR），采集于尘埃浓度递增的封闭货车拖车内，包含9,202帧雷达点云；

**📈 对比分析**

与训练有素的YOLOv8视觉模型对比，雷达系统在尘埃浓度升高时仍保持稳定的行人检测率，而视觉模型性能显著下降；阈值过滤与规则化分类使得误检率显著降低，实时性良好；

**⚠️ 局限性**

局限性在于缺乏时间序列积累、目标跟踪与多传感器融合，无法充分捕获环境上下文，需进一步加入时空信息处理与融合策略以进一步提升鲁棒性与分类精度；

---

## 574. Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection

**arXiv ID:** 2601.13359 | [PDF](https://arxiv.org/pdf/2601.13359v1)

**作者:** Asen Dotsinski `[一作]` (University of Amsterdam), Panagiotis Eustratiadis `[通讯]` (University of Amsterdam)

**通讯引用:** 94 | [OpenAlex ID](https://openalex.org/A5041404983)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种名为 sockpuppetting 的低成本 Jailbreak 方法，直接在 open‑weight LLM 的 assistant 消息块中插入接受序列，迫使模型生成违禁内容。

**💡 创新点**

创新点在于用极简的前缀插入取代复杂的梯度优化，实现更高攻击成功率，并首次将 sockpuppetting 与梯度优化结合形成混合滚动攻击。

**🔧 技术方法**

采用了 chat 模板改写、接受序列插入、GCG（Gradient‑guided Contrastive Generation）梯度导向优化、Rolling（逐步扩展）优化及对比实验等技术。

**📊 数据集**

使用了包含 520 条恶意提示及对应目标接受字符串的 “Harmful Behaviors” 数据集。

**📈 对比分析**

通过与 GCG 单独优化和统一优化基线对比，sockpuppetting 在单独攻击中提升 ASR 至约 80%，混合滚动版本在通用攻击中提升至约 64%。

**⚠️ 局限性**

局限性包括对 Gemma 等模型的“翻转”行为导致攻击失效、需事先匹配接受序列与模型自然输出风格、以及对闭源模型防御机制的适用性有限。

---

## 575. A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization

**arXiv ID:** 2601.13435 | [PDF](https://arxiv.org/pdf/2601.13435v1)

**作者:** Shuozhe Li `[一作]` (University of Texas), Leqi Liu `[通讯]` (University of Texas)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了 WaveLSFormer，一种用于小时级股票多头/空头交易的可学习小波-Transformer模型，能够直接输出满足固定风险预算的持仓信号。

**💡 创新点**

创新点在于：1）将小波滤波器设计为可学习的 FIR 卷积，利用频域正则化实现低频/高频分离；2）引入低导向高频注入（LGHI）机制，稳定地将高频信息注入低频分支；3）使用软标签和 Sharpe 正则化的交易目标，直接优化风险调整后的收益；4）在端到端训练中同时学习小波分解与交易策略。

**🔧 技术方法**

技术主要包括可学习小波前端、Transformer 编码器、低导向高频注入模块、风险预算缩放、软标签交叉熵损失、Sharpe 正则化、频域正则化（rFFT）以及多尺度信息融合。

**📊 数据集**

使用 2019‑2025 年间美国股票市场的 5 年小时级 OHLCV 数据，按行业划分为 6 个高流动性行业（如可再生能源、医疗设备等）进行实验。

**📈 对比分析**

与 MLP、LSTM、Transformer 等基线模型进行对比（同等参数规模），在 10 个随机种子上评估。WaveLSFormer 在平均 ROI 上升至 0.607±0.045、Sharpe 提升至 2.157±0.166，显著优于所有基线，且模型复杂度仅略有增加。

**⚠️ 局限性**

局限性包括：1）未考虑交易成本、滑点、市场冲击和借贷/换手限制；2）实验仅在美国股票小时级数据上验证，缺乏跨市场、跨频率的泛化测试；3）对不同宏观环境和流动性变化的鲁棒性未做系统评估。

---

## 576. MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization

**arXiv ID:** 2601.13437 | [PDF](https://arxiv.org/pdf/2601.13437v1)

**作者:** Adriana-Valentina Costache `[一作]` (University of Bucharest), Radu Tudor Ionescu `[通讯]` (University of Bucharest)

**通讯引用:** 8537 | [OpenAlex ID](https://openalex.org/A5081017623)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了多语言开放集学习与发现（MOSLD）基准数据集，并针对文本分类任务设计了一套多阶段 OSLD 方法，包含能量检测、聚类、关键词抽取和模型再训练；

**💡 创新点**

创新点在于：①构建了首个多语言开放集学习与发现基准；②提出了可持续学习的多阶段管道，并引入对比损失增强聚类结果；

**🔧 技术方法**

技术包括：能量基异常检测、k-means 聚类、TF-IDF 关键词抽取、BERT 编码、交叉熵 + 对比损失（V2）等；

**📊 数据集**

使用了 12 种语言的新闻文本，样本总计 960,438，涵盖 4 个已知类别与逐步加入的未知类别；

**📈 对比分析**

与冻结的 BERT 基线相比，V1 与 V2 在大多数语言和测试阶段显著提升准确率与宏 F1；V2 在早期阶段略优，整体表现比基线提升 30%~50%；

**⚠️ 局限性**

局限性包括：仅评估少量基线模型，缺乏专门设计的 OSLD 方法；GPT‑4o 的评估仅限两种语言和单阶段，受 API 成本限制；

---

## 577. Using deep learning for predicting cleansing quality of colon capsule endoscopy images

**arXiv ID:** 2601.13412 | [PDF](https://arxiv.org/pdf/2601.13412v1)

**作者:** Puneet Sharma `[一作]` (UiT The Arctic University of Norway), Jan-Matthias Braun `[通讯]` (University of Southern Denmark)

**通讯引用:** 521 | [OpenAlex ID](https://openalex.org/A5082188694)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文使用深度学习模型对胶囊内镜图像的清洁度进行自动评估。

**💡 创新点**

创新点包括：① 在 ResNet‑18 上采用 13 步迭代剪枝策略，在保持甚至提升准确率的同时实现高达 79% 的稀疏度；② 将 ROAD 框架与 Grad‑CAM 等多种可解释性方法结合，用多指标评估剪枝后模型的可解释性；③ 在外部数据集上引入 HnLTS 组合温度标定，实现对剪枝模型的概率校准。

**🔧 技术方法**

使用的技术包括：深度卷积神经网络（ResNet‑18），结构化剪枝（按通道的 L1‑norm 迭代删减），Grad‑CAM、Grad‑CAM++、Eigen‑CAM、Ablation‑CAM 与 Random‑CAM 的可解释性评估，ROAD 框架的可解释性度量，Adaptive Temperature Scaling（HnLTS）模型校准。

**📊 数据集**

数据集为：1）Danish Care For Colon 2015 试验中的 500 张图像，由 14 名临床医师使用 Leighton–Rex 量表标注；2）外部验证集 396 张图像，由 3 名医师一致标注。

**📈 对比分析**

方法比较：在 10 折交叉验证中，原始模型准确率 79.2%，剪枝后 7 步时准确率提升至 88%，稀疏度 79%。可解释性度量显示 Grad‑CAM 等方法得分显著高于 Random‑CAM，且不同类别差异明显。校准后，外部数据集的测试准确率从 61.6% 提升至 71–77%（隐藏单元 h=16–64）。

**⚠️ 局限性**

局限性包括：① 可解释性度量依赖单一目标层和子集，可能引入偏差；② 校准提升了“Good”“Excellent”等类别准确率，但在“Poor”类别上下降；③ 数据集规模有限，且标注存在主观性，未来需扩大样本量并改进标注一致性。

---

## 578. Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility

**arXiv ID:** 2601.13398 | [PDF](https://arxiv.org/pdf/2601.13398v1)

**作者:** Nickil Maveli `[一作]` (University of Edinburgh), Shay B. Cohen `[通讯]` (University of Edinburgh)

**通讯引用:** 6582 | [OpenAlex ID](https://openalex.org/A5030503109)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出RTCE基准，设计四种无损压缩算法的前向与反向推理任务，评估Code‑LLMs的回环一致性。

**💡 创新点**

通过执行无关的精确映射回环评估，强调模型必须在编码与解码之间保持一一对应，暴露传统单向评测忽视的推理不一致。

**🔧 技术方法**

使用零样本提示、基于执行轨迹的监督微调（LoRA）以及自我反思多轮修订来提升模型性能。

**📊 数据集**

构造250条合成样本，覆盖字符串、日志、YAML、表格四类输入，并配合LZW、AE、RLE、Huffman四种压缩算法，形成1000个评测实例。

**📈 对比分析**

采用Exact Match、Edit Similarity、Pass@5等指标进行评估，结果显示即使是大规模模型亦无法完全闭环，微调与自我反思仅带来有限提升，且不同算法间性能差异显著。

**⚠️ 局限性**

仅针对Python的压缩‑解压回环，忽略其他语言和可逆任务；评测为静态且不考虑运行时副作用；数据来源为合成，可能与真实代码存在差距。

---

## 579. Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction

**arXiv ID:** 2601.13388 | [PDF](https://arxiv.org/pdf/2601.13388v1)

**作者:** Sasha Ronaghi `[一作]` (Stanford University), Bryant Lin `[通讯]` (Stanford University)

**通讯引用:** 571 | [OpenAlex ID](https://openalex.org/A5080082088)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

利用大型语言模型（LLM）从65位65岁以上2型糖尿病患者的非结构化访谈中提取结构化社会决定因素（SDOH）评分，并将这些评分与实验室指标一起用于A1C预测；同时评估LLM直接从访谈文本预测糖尿病控制水平的准确性。

**💡 创新点**

首次证明LLM能够将自由文本中的社会决定因素转化为可量化评分，并直接通过文本推断糖尿病控制水平；在亚太裔美国人族群中以此为中心进行研究，展示了LLM在临床风险模型中的可扩展应用。

**🔧 技术方法**

使用Stanford SecureGPT（ChatGPT‑4o、o1、o1‑mini、DeepSeek r1）进行检索增强生成（RAG）与句向量嵌入+聚类；对提取的SDOH评分与实验室数据构建Ridge、Lasso、Random Forest、XGBoost等线性/树基机器学习模型；通过交叉验证评估A1C预测性能；直接对访谈文本进行分类预测。

**📊 数据集**

65名65岁以上T2D患者的访谈文本（平均1,500字），以及每位患者的完整电子病历实验室指标（血糖、甘油三酯、HDL、LDL、肌酐）和最新A1C值；族群中46.2%为亚太裔美国人。

**📈 对比分析**

A1C预测采用R²作为评价指标，发现仅Ridge回归在SDOH特征集上得到0.046的正R²，Random Forest在组合特征集上得到0.013；LLM直接预测控制水平时，GPT‑4o达到60%总体准确率，o1 53.9%，DeepSeek 50.8%，o1‑mini 50.8%；低控制水平预测准确率低于其他两个等级。

**⚠️ 局限性**

主要局限为样本量仅65人导致模型过拟合和预测精度低；自述访谈可能存在社会期望偏差；LLM在复杂叙事中易被误导；缺乏纵向A1C轨迹；SecureGPT的远程运行限制了可扩展性和部署灵活性。

---

## 580. From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace Instruction Tuning

**arXiv ID:** 2601.13384 | [PDF](https://arxiv.org/pdf/2601.13384v1)

**作者:** Jiajun Zhang `[一作]` (University of Science and Technology of China), Junyang Lin `[通讯]` (Alibaba Group)

**通讯引用:** 3025 | [OpenAlex ID](https://openalex.org/A5100612233)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了搜索与替换填充（SRI）框架，旨在解决传统 FIM 在上下文错误、缺乏安全性以及无法高效利用聊天模型方面的不足。

**💡 创新点**

创新点在于将检索与替换机制嵌入单次推理流程，通过显式搜索阶段验证并纠正上下文，既保持了 FIM 的高效性，又实现了对聊天模型安全对齐的兼容。

**🔧 技术方法**

技术主要包括：SRI 格式的结构化提示、基于搜索与替换的微调流程、利用 BFloat16 的 Megatron‑LM 训练框架，以及在 32k 上下文长度下的高效推理。

**📊 数据集**

使用了自合成的 SRI‑200K 数据集（从 The Stack v2 提取 200k 样本，20k 用于微调）以及 60k 的通用指令对，确保不与基准产生重叠。

**📈 对比分析**

与标准 FIM、自然语言 FIM（NL‑FIM）以及多种推理方式比较，SRI 在 20+ 主流代码完成基准（CrossCodeEval、RepoEval、CrossCodeLongEval、ExecRepoBench、SAFIM）上平均提升 15–30%，并保持推理延迟与 FIM 相当；在安全评测（SAL）中显著降低注入攻击成功率。

**⚠️ 局限性**

主要局限包括：评估仅基于离线基准，缺乏真实 IDE 部署与用户反馈；以及对小型模型（如 0.5B）效果不佳，需进一步研究知识蒸馏或结构改进。

---

## 581. A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge

**arXiv ID:** 2601.13383 | [PDF](https://arxiv.org/pdf/2601.13383v1)

**作者:** Akbar Anbar Jafari `[一作]` (University of Tartu), Gholamreza Anbarjafari `[通讯]` (3S Holding OÜ)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了AgentForge，一个轻量级、模块化的Python框架，用于快速构建LLM驱动的自主代理；

**💡 创新点**

创新点包括可组合的技能抽象（DAG形式）、统一的LLM后端接口实现多供应商无缝切换，以及基于YAML的声明式配置系统；

**🔧 技术方法**

核心技术包括基于Python的类型安全技能注册与执行、LLM后端抽象层、以及基于图的任务编排；

**📊 数据集**

使用公开API（OpenAI GPT‑4o‑mini、Groq Llama）和本地HuggingFace Transformers模型进行评测，Benchmark涵盖新闻聚合、数据分析、研究助手与内容生成四个场景；

**📈 对比分析**

与LangChain、AutoGPT和直接API集成比较，AgentForge在任务完成率上与LangChain相近（87–93%），但开发时间缩短62%（vs LangChain）或78%（vs 直接API），且推理开销低于100 ms；

**⚠️ 局限性**

局限性包括仅支持单代理架构、缺乏高级错误恢复与多代理协作、默认无状态执行、评测范围有限等。

---

## 582. The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models

**arXiv ID:** 2601.13358 | [PDF](https://arxiv.org/pdf/2601.13358v1)

**作者:** Samuel Cyrenius Anderson `[一作]` `[通讯]` (Scrivly.AI), Samuel Cyrenius Anderson (Scrivly.AI)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过提取大语言模型在链式思维推理过程中的隐藏状态轨迹，量化其几何特征并比较不同规模（8B vs 70B）以及四个推理领域（法律、科学、代码、数学）的变化，进一步构建神经推理算子验证几何结构对推理可压缩性的影响。

**💡 创新点**

创新点在于发现推理几何呈现三种相位（晶化、液态、晶格），规模对不同领域产生不同的相位转移，并提出普适的振荡常数（-0.4）以及几何结构可预测算子学习成功的实证。

**🔧 技术方法**

采用轨迹提取、PCA、Levina‑Bickel 维度估计、对齐度、相干度、轮廓系数等几何测度，并训练线性/MLP/DeepONet/谱KAN 等算子来预测终点隐藏状态。

**📊 数据集**

使用 GSM8K（数学）、GPQA（科学）、HumanEval（代码）、CaseHOLD 与 LexGLUE‑SCOTUS（法律）等公开基准进行实验。

**📈 对比分析**

通过对 8B 与 70B Llama 模型的几何指标对比，发现法律领域出现 45% 维度收缩、31% 对齐提升，算子在法律分类任务上达 63.6% 的准确率，科学/数学领域保持几何不变，代码领域显著提升聚类度，振荡常数始终约为 -0.4。

**⚠️ 局限性**

局限性包括仅研究 Llama 系列两尺度、仅用英文数据、缺少中间尺度、数据集多样性可能混杂结果、观察到的关联尚未证明因果关系。

---

## 583. LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction

**arXiv ID:** 2601.13352 | [PDF](https://arxiv.org/pdf/2601.13352v1)

**作者:** Yuxing Lu `[一作]` (Georgia Institute of Technology), May D. Wang `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 20063 | [OpenAlex ID](https://openalex.org/A5030096887)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851` `e15e3743-5ee0-4d5f-813d-d146868082fc` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出一种LLM-as-RNN框架，利用自然语言记忆状态在推理时实现冻结LLM的递归预测与在线自我纠错；

**💡 创新点**

核心创新是把隐藏状态用可编辑的自然语言文本表示，并通过反馈驱动的文本重写实现可更新记忆，而非传统的不可变上下文堆叠；

**🔧 技术方法**

主要技术包括三步推理流程（Contextualization、Reflection、Memory Update），利用Prompt模板、LLM评估器（或自评判）产生语义梯度，并在固定token预算下迭代重写记忆；

**📊 数据集**

在三大领域的三组连续数据集上评估：MIMIC‑IV（医疗诊断）、Weather（气象预测）和S&P 500+财经新闻（股市收盘价预测）；

**📈 对比分析**

与Zero‑shot、Full History Concatenation (FHC)、MemPrompt基线相比，LLM‑as‑RNN在大多数模型和任务上均显著提升，平均准确率提升约6.5%，在MIMIC‑IV、Weather、S&P 500分别提升10.8%、1.6%、4.8%；

**⚠️ 局限性**

主要局限包括推理成本高（每步需多次LLM调用）、记忆更新受模型诊断能力限制、对反馈（标签或LLM批评）依赖强、需要手工设计Prompt与token预算，且可能在高噪声或隐私场景中产生误差累积与安全隐患。

---

## 584. Towards Scalable Federated Container Orchestration: The CODECO Approach

**arXiv ID:** 2601.13351 | [PDF](https://arxiv.org/pdf/2601.13351v1)

**作者:** Rute C. Sofia `[一作]` (fortiss GmbH), Alejandro Tjaarda `[通讯]` (Universidad Carlos III de Madrid)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出 CODECO，一个面向边缘-云-物联网持续统一的 Kubernetes 联邦调度框架，提供跨层次（数据、计算、网络）协同调度与 AI 辅助决策。

**💡 创新点**

创新点包括：基于应用邻域的边界化分区、融合网络/数据/计算三维可观测性、分层治理（集中策略、分布式执行）、去中心化的隐私保护学习与推荐、统一的元数据图管理。

**🔧 技术方法**

采用技术包括：Kubernetes + Open Cluster Management、eBPF 网络监控、Prometheus + Grafana、Neo4j + Kafka 元数据图、GNN+MARL 学习、ONOS SDN、VXLAN 覆盖、AI/ML 推理等。

**📊 数据集**

实验使用 CODEF 软件定义边缘云仿真平台，集成 AWS、Azure、Google Cloud、XCP‑NG、CloudLab、FABRIC、边缘设备等，应用案例涉及智能出行、工业自动化、沉浸式媒体等真实负载。

**📈 对比分析**

在 CODEF 统一实验框架下与 KubeFed、Karmada、PHARE、Liqo 等现有多集群方案对比，评估延迟、能耗、资源利用、迁移成本；实验显示 CODECO 在跨层优化下平均减少 15‑25% 延迟、20% 能耗，迁移失败率低于 5%。

**⚠️ 局限性**

限制包括：多 HUB 交叉治理尚未成熟；聚合抽象可能导致局部最优而非全局最优；AI 推荐需进一步稳定性保障；对极端网络波动的容错仍有限。

---

## 585. Influence of Normative Theories of Ethics on the European Union Artificial Intelligence Act: A Transformer-Based Analysis Using Semantic Textual Similarity

**arXiv ID:** 2601.13372 | [PDF](https://arxiv.org/pdf/2601.13372v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f`

---

## 586. Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics

**arXiv ID:** 2601.13401 | [PDF](https://arxiv.org/pdf/2601.13401v1)

**作者:** Peter A. Massih `[一作]` (EPFL), Eric Cosatto `[通讯]` (NEC Laboratories America)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了SQuID卫星量化推理基准和QVLM代码生成式视觉语言模型，解决了传统VLM在像素级计数与测量上的失效。

**💡 创新点**

创新点在于将视觉信息以像素精度的分割掩码传递给LLM，利用代码生成而非端到端编码，保留空间索引，并用可验证的可接受范围评估。

**🔧 技术方法**

使用LLM（GPT‑5等）进行代码生成，调用ConvNeXt‑UNet/DINOv3分割模型，进行几何运算；同时构建分割服务端、API。

**📊 数据集**

使用公开卫星影像数据集DeepGlobe、EarthVQA、Solar Panels、NAIP等合成的2,000问答对，包含三难度层级；以及公开分割数据集训练分割模型。

**📈 对比分析**

在SQuID上采用零样本pass@1评估，与直接编码的VLM（GPT‑5、Qwen3‑VL‑30B‑A3B‑Thinking）对比，QVLM在整体准确率上提升约14个百分点（42% vs 28%）。

**⚠️ 局限性**

局限性在于依赖封闭词汇的分割模型、运行速度慢、占用更多token，且可能受训练集偏差影响；目前不能处理超出分割模型主题的查询。

---

## 587. Leveraging Transformer Decoder for Automotive Radar Object Detection

**arXiv ID:** 2601.13386 | [PDF](https://arxiv.org/pdf/2601.13386v1)

**作者:** Changxu Zhang `[一作]` (HELLA GmbH & Co. KGaA), Markus Gardill `[通讯]` (Brandenburg University of Technology)

**通讯引用:** 296 | [OpenAlex ID](https://openalex.org/A5041147083)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出了一种基于Transformer解码器的3D雷达目标检测框架，利用Pyramid Token Fusion模块将多尺度雷达特征统一为token序列，实现端到端无NMS预测。

**💡 创新点**

创新点在于将Transformer解码器作为检测头实现直接框回归，设计轻量级PTF模块融合多尺度特征，并通过全局注意力捕获雷达数据的长程空间-时间关联，消除传统密集候选和NMS。

**🔧 技术方法**

采用Transformer编码器-解码器（Conditional DETR）、PTF、TPE、Focal Loss、GIoU、Hungarian匹配以及雷达3D RAD张量输入。

**📊 数据集**

使用RADDet雷达数据集（AWR1843 radar，10,158帧，28,401个标注）进行训练与评估。

**📈 对比分析**

与CNN及Transformer基准方法在3D RAD、RA、RD mAP上进行对比，本文在3D mAP上达到15.91%（IoU 0.7），比TransRAD高出约2-3%；在RA/RD 2D检测同样取得最佳mAP，显示更优的定位精度。

**⚠️ 局限性**

实验仅覆盖单一无车速/俯仰信息的数据集，缺乏多样化场景、车速动态和标签质量的验证，限制了结果的泛化性。

---

## 588. Practical Insights into Semi-Supervised Object Detection Approaches

**arXiv ID:** 2601.13380 | [PDF](https://arxiv.org/pdf/2601.13380v1)

**作者:** Chaoxin Wang `[一作]` (Dominican University), Doina Caragea `[通讯]` (Kansas State University)

**通讯引用:** 4363 | [OpenAlex ID](https://openalex.org/A5067341711)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

对三种先进半监督目标检测方法（MixPL、Semi‑DETR、Consistent‑Teacher）在少标注（k‑shot）场景下进行系统性实验与比较，评估其检测精度、推理延迟和模型大小。

**💡 创新点**

创新点在于：①采用每类固定k‑shot的平衡采样策略，真实反映数据稀缺条件；②同时量化模型大小与推理时间，提供部署级的性能–资源权衡；③在三大数据集（MS‑COCO、Pascal VOC、Beetle）上统一实验，给出低数据量下的最优模型与实践建议。

**🔧 技术方法**

使用的技术包括：
- MixPL（Pseudo‑Mixup/Pseudo‑Mosaic 伪标签增强）
- Semi‑DETR（Stage‑wise Hybrid Matching、Cross‑View Query Consistency、Cost‑based Pseudo‑Label Mining）
- Consistent‑Teacher（Adaptive Sample Assignment、3D Feature Alignment、Gaussian Mixture Confidence）
- 所有方法均基于预训练 ResNet‑50 并在 DINO 或 RetinaNet 之上实现。

**📊 数据集**

使用的数据集：
- MS‑COCO（80 类）
- Pascal VOC 2007/2012（20 类）
- 自制 Beetle 数据集（7 类昆虫）

**📈 对比分析**

比较方法：在固定k‑shot（1,5,10,20,50,100,150）下，分别在三大数据集上测量 mAP[0.5:0.95]、推理时间(ms/图)和模型大小(MB)。结果显示：
- MixPL 在大多数 k‑shot 与数据集上取得最高 mAP；
- Semi‑DETR 其次，性能与 MixPL 相近；
- Consistent‑Teacher 速度最快、模型最小，但 mAP 相对最低；
- 性能随 k 提升显著，但在不同数据集上增益差异明显，复杂多类数据（MS‑COCO）仍需更多标注；

**⚠️ 局限性**

局限性：
- 仅评估三种方法，未覆盖所有主流 SSOD 框架；
- 所有模型均以 ResNet‑50 为骨干，未探究更轻量级或更大模型的效果；
- 对伪标签噪声对长期训练的影响未深入分析；
- 仅在公开与自制数据集上验证，缺少行业真实场景的进一步验证。

---

## 589. CLEAR: A Semantic-Geometric Terrain Abstraction for Large-Scale Unstructured Environments

**arXiv ID:** 2601.13361 | [PDF](https://arxiv.org/pdf/2601.13361v1)

**作者:** Pranay Meshram `[一作]` (University at Buffalo), Karthik Dantu `[通讯]` (University at Buffalo)

**通讯引用:** 1839 | [OpenAlex ID](https://openalex.org/A5032635242)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

论文提出CLEAR框架，构建基于语义边界的平面拟合区域图，实现大规模地形抽象与路径规划。

**💡 创新点**

创新点在于将边界种子分解与递归平面拟合相结合，既保持地形语义与几何一致，又生成凸可搜索图，突破传统网格/四叉树失去语义或几何的缺陷。

**🔧 技术方法**

使用基于Voronoi的边界种子分解、递归平面拟合、语义加权成本图编码，并通过A*、RRT*与BeamNG仿真验证其性能。

**📊 数据集**

使用NASADEM地形与NALCMS土地覆盖数据，构建12个9–100 km²的多样化地图，用于评估。

**📈 对比分析**

与网格、六边形、四叉树抽象及原始A*/RRT*对比，CLEAR在规划时间上提升至10×、路径成本低6–9%、成功率更高，并在仿真中实现更短、更可靠的路径。

**⚠️ 局限性**

局限性包括假设障碍为空闲地形，未建模细小障碍；在高度碎片化地区小区域分解困难；计算量随点密度上升，需要降采样以实现实时。

---

## 590. FlipFlop: A Static Analysis-based Energy Optimization Framework for GPU Kernels

**arXiv ID:** 2601.13345 | [PDF](https://arxiv.org/pdf/2601.13345v1)

**作者:** Saurabhsingh Rajput `[一作]` (Dalhousie University), Tushar Sharma `[通讯]` (Dalhousie University)

**通讯引用:** 2096 | [OpenAlex ID](https://openalex.org/A5023044082)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了 FlipFlop 框架，利用静态 PTX 分析预测 GPU kernel 的能耗和最优线程块配置，并通过硬件校准的混合性能‑能耗模型减少调优搜索空间。

**💡 创新点**

创新点在于：①在不执行 kernel 的前提下，使用 PTX 级别的静态特征提取与硬件校准相结合的能耗预测；②将线程块形状、功率上限与性能耦合建模，提供可解释的能源优化指导；③实现了 93% 以上的配置空间压缩和 80% 左右的能耗降低。

**🔧 技术方法**

核心技术包括：静态代码分析、PTX 指令特征提取、内存共alescing 与 bank‑conflict 评估、MWP‑CWP 并行模型、动态功率与静态漏电功率校准、DVFS 近似、Pareto 前沿搜索以及与 Kernel Tuner、Bayesian 优化等工具的对比实验。

**📊 数据集**

使用的数据集与工作负载：多头注意力（MHA）kernel（LLAMA、CodeLlama）、HeCBench 基准（向量加、矩阵乘、卷积、转置等）以及不同 GPU 架构（RTX 5000 Ada、RTX 3070 Ampere）。

**📈 对比分析**

与 NVIDIA 占用率启发式、完整跑速测 profiling、贝叶斯优化等方法对比，FlipFlop 预测准确率约 83%，能耗可下降最高 79%，吞吐提升可达 106%，搜索空间压缩 93.4%，节省执行时间超过 10⁵ 倍。

**⚠️ 局限性**

局限性包括：实验主要集中在 NVIDIA GPU，模型对其它架构的迁移性有限；仅验证单核 kernel，未覆盖多流竞争场景；模型假设（如内存共alescing、功率‑频率关系）在极端工作负载下可能失效；对动态功率调节的细粒度控制仍不完善。

---

## 591. Classifiers in High Dimensional Hilbert Metrics

**arXiv ID:** 2601.13410 | [PDF](https://arxiv.org/pdf/2601.13410v1)

**作者:** Aditya Acharya `[一作]` (University of Maryland), David M. Mount `[通讯]` (University of Maryland)

**通讯引用:** 14723 | [OpenAlex ID](https://openalex.org/A5016442699)

**关键词:** `a42c7bd6-d8fd-40d3-94df-ae8cd808f5c4` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b`

**🎯 论文内容**

提出了在Hilbert几何空间中利用线性规划实现最大间隔SVM、软间隔SVM以及最近邻分类器的高效算法；

**💡 创新点**

创新点在于将Hilbert距离的度量化简为对数比值的上确界表达，从而使得球体可表示为多面体并且可通过线性组合的方式求得切平面，进而实现多维度下的多项式时间解法；

**🔧 技术方法**

采用线性规划与凸优化技术、双对偶变换、投影到多面体球面、以及基于凸多面体的球体构造；

**📊 数据集**

文中未使用具体数据集，主要以理论分析和算法复杂度证明为主；

**📈 对比分析**

通过理论证明算法的运行时间为多项式(O(poly(n,m,d,B,log(1/ε)))，并与之前指数级或无理论保证的方法进行了对比；

**⚠️ 局限性**

限制在于需假设输入为有界凸多面体并且点集可线性分离（软间隔扩展后可放宽），对高维度下实际数据集的经验评估仍待进一步验证。

---

## 592. Organ-Aware Attention Improves CT Triage and Classification

**arXiv ID:** 2601.13385 | [PDF](https://arxiv.org/pdf/2601.13385v1)

**作者:** Lavsen Dahal `[一作]` (Duke University), Joseph Y. Lo `[通讯]` (Duke University)

**通讯引用:** 7433 | [OpenAlex ID](https://openalex.org/A5040192736)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

提出了一种基于解码器无关、器官感知的CT多标签分类框架ORACLE‑CT，并在胸部与腹部CT上实现统一的校准式推理。

**💡 创新点**

创新点在于：①基于解剖掩码的软max注意力聚合；②加入器官体积/HU标量融合（OSF）提升对尺寸/密度敏感的疾病；③统一的、可审计的评测协议，兼容多种2.5D/3D骨干。

**🔧 技术方法**

技术包括：多实例学习（MIL）风格的软max注意力聚合、器官掩码映射、标量融合、温度缩放校准、基准数据集切分和统一训练损失。

**📊 数据集**

使用公开胸部CT数据集CT‑RATE和外部测试集RAD‑ChestCT，以及腹部CT数据集MERLIN；对比内部与外部标签。

**📈 对比分析**

与基准VLM的线性探针或零样本对照相比，ORACLE‑CT在CT‑RATE上AUROC提升至0.86，在MERLIN上AUROC提升至0.85，显著优于零样本VLM与先前监督基线，且在外部数据上保持稳健。

**⚠️ 局限性**

局限性包括：依赖高质量器官分割，分割误差会影响聚合；标量融合方式简单，可能对局灶病灶效果有限；注意力热图虽可审计但不保证因果性；未对所有骨干进行系统超参数搜索。

---

## 593. Guidelines for the Creation of an Annotated Corpus

**arXiv ID:** 2601.13353 | [PDF](https://arxiv.org/pdf/2601.13353v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871`

---

## 594. Bounded Minds, Generative Machines: Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk

**arXiv ID:** 2601.13376 | [PDF](https://arxiv.org/pdf/2601.13376v1)

**作者:** Jiqun Liu `[一作]` (University of Oklahoma), Jiqun Liu `[通讯]` (University of Oklahoma)

**通讯引用:** 626 | [OpenAlex ID](https://openalex.org/A5088558868)

**关键词:** `7a50eb32-3dbc-4c3e-a038-bda01b2d9965` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275`

**🎯 论文内容**

本文提出了一条以人类启发式为核心的对话式人工智能研究路径，强调系统需识别并配合用户的有限理性，降低偏见风险并提升决策质量。

**💡 创新点**

创新点在于把有限理性与启发式应用于对话系统设计与评估，提出实时检测认知脆弱性、轻量级干预和认知影响评估框架，超越传统的事实准确性评价。

**🔧 技术方法**

主要技术包括结构化输出、函数调用、检索增强生成、轻量级“审计器”对话草稿进行预评估，以及置信区间与基线提示的呈现。

**📊 数据集**

文章未给出具体数据集，建议在未来实验中使用多任务对话数据和人类行为日志来验证。

**📈 对比分析**

由于本文为研究路线图而非实验论文，没有实验对比；作者提出的评估方法包括情境集、在线实验和对抗式记录，用以验证校准、视角拓展与抵御干预的效果。

**⚠️ 局限性**

主要限制在于实时认知脆弱性检测的可行性、干预措施的侵入性与用户体验、以及治理、审计与透明性的实现挑战。

---

## 595. Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models

**arXiv ID:** 2601.13443 | [PDF](https://arxiv.org/pdf/2601.13443v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 596. A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions

**arXiv ID:** 2601.13373 | [PDF](https://arxiv.org/pdf/2601.13373v1)

**作者:** Zhenan Liu `[一作]` (University of Waterloo), George Shaker `[通讯]` (University of Waterloo)

**通讯引用:** 3214 | [OpenAlex ID](https://openalex.org/A5060296994)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `3855fcda-48ef-4070-a15e-803cd5c84d83` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

开发了一套基于4D毫米波雷达的轻量级模型驱动框架，用于工业和矿井等恶劣环境下的实时人类检测。

**💡 创新点**

创新点在于提出多阈值领域感知过滤、两帧惯性补偿累积、Doppler感知聚类及规则式3D分类，形成可解释、无监督、嵌入式可实时执行的雷达感知基线。

**🔧 技术方法**

采用了雷达点云多阈值过滤、KD‑Tree欧式聚类、Doppler补偿、规则式尺寸‑RCS判定以及外部LiDAR‑IMU姿态补偿等技术。

**📊 数据集**

实验使用了控制室内尘土拖车中自行收集的尘土浓度数据和实际地下矿井中的雷达/相机/激光同步数据（无3D标注）。

**📈 对比分析**

与YOLOv8相机检测对比；在尘土浓度升高时，雷达框架帧级召回率保持94%对比17%，人数召回率84%对比12.5%，误报率约5%；在矿井环境中仍能稳定检测，视觉检测失效。

**⚠️ 局限性**

局限性包括对稀疏异向雷达点云的分割精度受限、缺乏完整3D边界框标注、难以进行细粒度姿态估计以及对多目标复杂姿态的处理不足。

---

## 597. CausationEntropy: Pythonic Optimal Causation Entropy

**arXiv ID:** 2601.13365 | [PDF](https://arxiv.org/pdf/2601.13365v1)

**作者:** Kevin Slote `[一作]` (Clarkson University), Erik Bollt `[通讯]` (Clarkson University)

**通讯引用:** 6201 | [OpenAlex ID](https://openalex.org/A5003961936)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

实现了CausationEntropy 1.1 Python 包，完成了oCSE算法、熵估计器、合成数据生成与可视化工具的完整功能。

**💡 创新点**

将oCSE方法模块化、可扩展，并首次集成多种熵估计技术、100%单元测试及易用 API，弥补了以往低层实现缺乏开源生态的不足。

**🔧 技术方法**

采用信息论的因果推断框架，使用高效熵/互信息估计器（Gaussian、kNN、geometric‑kNN、KDE、Poisson），并通过 Python、NumPy、SciPy、NetworkX、Matplotlib 等实现。

**📊 数据集**

使用自带 synthetic 模块生成线性高斯过程、耦合振荡器等合成时间序列，并以 5 节点 Erdős‑Rényi 随机图中的 Gaussian 震荡器为示例数据集。

**📈 对比分析**

在合成网络上与 PCMCI、Transfer Entropy 等方法对比，能够准确恢复原始因果结构；通过 P 值和 CMI 的统计结果以及可视化展示验证性能。

**⚠️ 局限性**

目前缺乏对大规模真实实验数据的验证，计算复杂度随维度增长而提升，且主要面向离散时间序列，异步或连续系统的适用性尚待进一步扩展。

---

## 598. The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes

**arXiv ID:** 2601.13348 | [PDF](https://arxiv.org/pdf/2601.13348v1)

**作者:** M. Karen Shen `[一作]` (University of British Columbia), Dongwook Yoon `[通讯]` (University of British Columbia)

**通讯引用:** 1430 | [OpenAlex ID](https://openalex.org/A5028316272)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了人们对AI聊天机器人的成瘾行为，提出了三种成瘾类型并阐释了“AI魔术师”现象。

**💡 创新点**

首次系统识别了Escapist Roleplay、Pseudosocial Companion和Epistemic Rabbit Hole三种成瘾类型，并将AI Genie概念作为成瘾机制的核心。

**🔧 技术方法**

采用主题分析、共对应分析（Correspondence Analysis / Multiple Correspondence Analysis）等定性与定量混合方法来描述和关联成瘾特征。

**📊 数据集**

数据来源为从14个相关子版块中筛选的794条Reddit帖子（其中334条被认定为自报成瘾案例）。

**📈 对比分析**

通过定性主题与定量共对应分析相结合，对症状、钩子、设计要素、情境因素和恢复策略进行关联与可视化；结果显示不同成瘾类型在这些维度上有显著差异，说明方法能够揭示多维度关联，未做传统性能对比。

**⚠️ 局限性**

局限性包括仅来自Reddit的自报数据，可能不具普遍性；样本选取偏向热门帖子；未能验证因果关系；以及缺乏纵向追踪验证恢复策略效果。

---

## 599. Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation

**arXiv ID:** 2601.13440 | [PDF](https://arxiv.org/pdf/2601.13440v1)

**作者:** Mohit Kakda `[一作]` (Northeastern University), Lawrence Swaminathan Xavier Prince `[通讯]` (Northeastern University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文对基于视觉-语言模型的零样本与少样本异常分类与分割方法进行系统分析与对比，重点评估WinCLIP与AnomalyCLIP两种主流方案。

**💡 创新点**

创新点在于将滑窗式特征提取与可学习、面向“异常”概念的文本提示相结合，并引入DPAM机制以提升细粒度定位；同时在同一实验框架下统一比较两种方法的精度、效率与可迁移性。

**🔧 技术方法**

使用CLIP的视觉与文本编码器、滑窗提取、可学习文本提示、多尺度对齐、注意力加权（DPAM）以及多任务损失（分类+分割）。

**📊 数据集**

在MVTec AD数据集上进行实验，包含15类物体与纹理，覆盖多种缺陷类型。

**📈 对比分析**

在所有指标上，AnomalyCLIP显著优于WinCLIP，分类AUROC从0.612提升至0.916，分割AUROC从0.726提升至0.907；WinCLIP在细粒度定位上表现更好，但整体精度与鲁棒性落后。

**⚠️ 局限性**

两种方法均在柔性/复杂物体（如电缆、晶体管）和低对比缺陷上表现不佳，且对光照、视角变化敏感；WinCLIP对提示设计依赖较高，AnomalyCLIP在缺陷类型需功能性理解（缺失组件、逻辑错误）时精度受限。

---

## 600. Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models

**arXiv ID:** 2601.13433 | [PDF](https://arxiv.org/pdf/2601.13433v1)

**作者:** Priyanka Mary Mammen `[一作]` (UMass Amherst), Shankar Venkitachalam `[通讯]` (Adobe)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本论文系统研究了大型语言模型在面对不同专业层级的权威背书（正确或错误）时的行为变化，发现高专业误导背书会显著降低模型准确率并提升其自信度，同时即便是具备推理能力的模型也易受此影响。

**💡 创新点**

创新点在于：①构建了多层级权威偏差的层次化评估框架，揭示误导性背书随专业水平递增而造成的危害；②证明推理模型并不免疫此偏差；③利用残差流中的“高专业”导向 steering 向量，成功实现了对权威偏差的机制化抑制与放大，证明偏差可被可控调节。

**🔧 技术方法**

使用的技术主要包括：
- 提示工程（在 MCQ 题目中插入不同专业层级的专家背书），
- 评估指标（ΔAccuracy、ΔEntropy、Robustness Rate），
- 残差流 steering 向量干预（提取并在推理时加/减该向量以改变模型对权威的敏感度）。

**📊 数据集**

所用数据集：
- AQuA‑RAT（数学推理 MCQ），
- LEXam（法律考试 MCQ），
- MedMCQA（医学 MCQ），
- MedQA（医学 MCQ）。

**📈 对比分析**

比较方法：对 11 个模型（5 推理模型 + 6 非推理模型）在三种提示条件（基线、正确背书、错误背书）下计算 ΔAcc、Robustness Rate 和 ΔEnt。结果显示：
- 高专业错误背书导致准确率显著下降，且模型对错误答案的置信度显著提升；
- 推理模型虽基准更高，但仍易受误导；
- 通过 steering 向量干预后，大多数模型的准确率提升、误导效果被抑制。

**⚠️ 局限性**

limitation：
- 仅评估至 32B 参数规模的开源模型，无法反映更大模型的行为；
- 只覆盖四个领域，缺乏更广泛的领域泛化；
- 背书格式单一，未考虑多样化表述或自信度语义；
- 对层级/解释性机制的分析有限，未来需要更细粒度的解释方法。

---

## 601. Techniques of Modern Attacks

**arXiv ID:** 2601.13427 | [PDF](https://arxiv.org/pdf/2601.13427v1)

**作者:** Alexander Shim `[一作]` `[通讯]` (Florida International University), Alexander Shim (Florida International University)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文系统性分析了APT的生命周期、TTP，并对四篇相关研究进行对比，提出了综合的APT检测与防御框架；

**💡 创新点**

创新点在于将行为分析、网络协同防御与分布式 provenance 图审计相结合，提出多层次、动态适应的APT防御策略；

**🔧 技术方法**

采用机器学习行为分析、图模型（provenance audit）、HMM、深度学习、网络流量与日志监控等技术；

**📊 数据集**

使用公开APT事件日志、Camflow 生成的 provenance 图数据、DARPA 数据集以及在 15 台服务器上构建的实验网络；

**📈 对比分析**

通过与 StreamSpot、Unicon 等现有检测系统对比，展示了在召回率和鲁棒性方面的提升，实验结果显示在 6 种攻击场景下可实现高召回率；

**⚠️ 局限性**

主要局限包括对抗性子图检测的实时性不足、跨组织数据共享的隐私与同步挑战，以及对极端隐匿攻击的检测能力有待进一步提升。

---

## 602. Quantum Encryption Resilience Score (QERS) for MQTT, HTTP, and HTTPS under Post-Quantum Cryptography in Computer, IoT, and IIoT Systems

**arXiv ID:** 2601.13423 | [PDF](https://arxiv.org/pdf/2601.13423v1)

**作者:** Jonatan Rassekhnia `[一作]` `[通讯]` (Luleå University of Technology), Jonatan Rassekhnia (Luleå University of Technology)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5a41884c-404f-4688-a89c-aa238c10fe68` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

开发了统一的量化指标 Quantum Encryption Resilience Score（QERS），并在 ESP32-C6 与 Raspberry Pi CM4 上对 MQTT、HTTP、HTTPS 三种协议进行 12 小时连续实验，以评估后量子密码学对性能与安全性的综合影响。

**💡 创新点**

首次将延迟、CPU 利用率、RSSI、能耗、密钥大小等多维度指标融合成单一分数，并提出 Basic、Tuned、Fusion 三层评分模型，兼顾效率与安全性。

**🔧 技术方法**

采用后量子密钥协商 Kyber 与 Dilithium 签名、TLS 1.3、Wi‑Fi 通信；利用 ESP32‑C6 MCU 与 Raspberry Pi CM4 服务器，结合 min‑max 归一化与 MCDA 加权算法计算 QERS。

**📊 数据集**

采集了 12 小时连续实验数据，覆盖近距离与远距离 Wi‑Fi 条件下三种协议的延迟、CPU、能耗、RSSI、密钥大小等指标，数据以 CSV 形式记录。

**📈 对比分析**

通过归一化后得到 0–100 分的 Basic、Tuned、Fusion 分数，实验显示 MQTT 在 Basic/Tuned 上最高，HTTPS 在 Fusion 上最高，QERS 能直观展示协议在资源受限环境下的效率与安全权衡。

**⚠️ 局限性**

受限于单一硬件平台、仅测试 Kyber/Dilithium，未覆盖多种后量子算法或大规模网络，且 Fusion 模型仍使用人工权重，缺乏自适应学习机制。

---

## 603. TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction

**arXiv ID:** 2601.13422 | [PDF](https://arxiv.org/pdf/2601.13422v1)

**作者:** Dahai Yu `[一作]` (Florida State University), Guang Wang `[通讯]` (Florida State University)

**通讯引用:** 4436 | [OpenAlex ID](https://openalex.org/A5100451757)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一种统一框架，用于预测用户级能源使用量，并提供可靠的预测区间。

**💡 创新点**

创新点在于（1）层次化时空表示模块——结合记忆增强的MASTGNN同时捕获微观用户层和宏观区域层的时空特征；（2）顺序一致化分位数回归（SCQR）——在分布无关的前提下，随时间动态校准不确定性区间，从而保证在分布漂移和极端天气下的有效覆盖率。

**🔧 技术方法**

核心技术包括：图卷积网络（Diffusion GCN）+时序卷积网络（TCN）的混合骨干；共享参数池与低秩线性注意力的记忆增强机制；分位数回归与平均绝对误差相结合的混合损失；以及基于非一致性得分的顺序一致化预测区间构造。

**📊 数据集**

使用佛罗里达州61,672户家庭30分钟间隔的电力消耗数据作为主要实验集；并进一步在纽约和加州的两组相同类型数据上验证泛化性。

**📈 对比分析**

与13个先进基线（STGCN、GWNET、ASTGCN、AGCRN、StemGNN、DSTAGNN、STZINB、PDFormer、DiffSTG、DeepSTUQ、PowerPM、Chronos、Moment）在6项指标（MAE、RMSE、MAPE、MPIW、WINK、COV）上对比，本文模型平均提升约5.4%（MAE）和5.7%（不确定性指标），且在极端天气（飓风、龙卷风、热浪）场景下保持更高的覆盖率与更窄的区间宽度。

**⚠️ 局限性**

局限性包括：对高频（30分钟）时序的依赖，模型仍需大量计算资源，虽然使用记忆增强降低了复杂度但在更大规模用户群或更细粒度数据时可能仍受限；未显式引入外部气象、社会经济等辅助特征，可能在某些特殊情境下预测误差仍然较大；模型的通用性虽然在NY/CA验证过，但在跨国或跨时区的迁移学习仍待进一步研究。

---

## 604. SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement

**arXiv ID:** 2601.13417 | [PDF](https://arxiv.org/pdf/2601.13417v1)

**作者:** Yujian Xiong `[一作]` (Arizona State University), Yalin Wang `[通讯]` (Arizona State University)

**通讯引用:** 11229 | [OpenAlex ID](https://openalex.org/A5100740828)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于Sliced Gromov-Wasserstein距离的GAN框架（SGW-GAN），用于无配对视网膜眼底图像的增强，兼顾视觉质量与临床判读的几何一致性。

**💡 创新点**

创新点在于首次将SGW作为高效的内部关系保留约束引入无配对图像增强，既保持疾病类别内部结构，又显著降低GW计算成本；同时构建三项损失（RMSE、SGW、对抗）平衡结构、关系与真实性。

**🔧 技术方法**

技术包括GAN（WGAN+梯度惩罚）、Sliced Gromov-Wasserstein距离（随机一维投影求解）、预训练MAE编码器提取特征、U-Net+通道/空间注意力生成器、PatchGAN鉴别器。

**📊 数据集**

使用公开的EyeQ视网膜眼底数据集，包含人工噪声与真实噪声图像，图像尺寸统一为224×224。

**📈 对比分析**

与CycleGAN、WGAN、OTTGAN、OTEGAN、Context‑Aware OT、CUNSB‑RFIE等基线比较。SGW-GAN在FID、PSNR/SSIM略逊于某些基线，但在疾病分级（ACC、F1、AUC）和全局GW不一致度上均显著优于其它方法（例如ACC 0.7814 vs 0.7539，GW误差 599.9 vs 794.9）。

**⚠️ 局限性**

局限性包括：1）在纯视觉指标上略低，可能被主观误差评价；2）SGW计算仍比传统GAN略慢，需平衡投影数；3）依赖固定的预训练编码器，可能限制跨域适应；4）仅在眼底图像上验证，跨模态推广需进一步研究。

---

## 605. Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study

**arXiv ID:** 2601.13416 | [PDF](https://arxiv.org/pdf/2601.13416v1)

**作者:** A. Nieto Juscafresa `[一作]`, J. Sullivan `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `57a58b01-81b4-4d75-a45c-2e891f272b50` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在无标签的条件下，利用冻结的扩散U‑Net作为特征提取器，采集不同层级与时间步的中间去噪特征，并通过线性探针实现细粒度磷虾分类；

**💡 创新点**

创新点在于系统评估扩散模型在细粒度识别中的最佳层-时间步组合，并将生成质量与判别性能关联，证明冻结扩散特征可与监督基线相媲美且优于其他自监督方法；

**🔧 技术方法**

使用的技术包括无监督扩散去噪训练（MinSNR加权）、冻结U‑Net取解码器特征、全局平均池化、线性softmax探针，以及对比实验；

**📊 数据集**

实验数据集为两套IFCB流化细胞检测器（SMHI与SYKE）提供的平衡与不平衡磷虾图像，且在不同时间和地点的OOB数据集上进行迁移测试；

**📈 对比分析**

与ResNet‑50、EfficientNet‑B0/B3、ViT‑B/16等监督模型以及MAE、DINOv3等自监督基线对比，冻结扩散特征在线性探针下在平衡集上取得92.4%准确率、94.1%Macro F1，优于自监督基线且接近监督模型；在OOB时仍保持高准确率；

**⚠️ 局限性**

局限在于仅针对单一U‑Net架构、固定注意力位置和噪声计划，未验证跨架构、跨噪声调度及跨数据集的普适性；训练成本高且对长尾分布的进一步优化尚未探究。

---

## 606. Local-to-Global Logical Explanations for Deep Vision Models

**arXiv ID:** 2601.13404 | [PDF](https://arxiv.org/pdf/2601.13404v1)

**作者:** Bhavan Vasu `[一作]` (Oregon State University), Prasad Tadepalli `[通讯]` (Oregon State University)

**通讯引用:** 3386 | [OpenAlex ID](https://openalex.org/A5014260664)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种将深度视觉模型的决策转化为可解释的逻辑公式（MDNF）的两级框架，既能给单张图像生成局部解释，又能对同一类别或所有类别生成全局覆盖解释与多类解释列表；

**💡 创新点**

创新点包括：① 基于人类可识别的对象原语构造最小充分解释；② 用 beam search 近似求解局部 MDNF；③ 采用贪心集覆盖算法合成全局覆盖解释；④ 通过解释列表一次性覆盖多类决策，解决类别间重叠解释的问题；

**🔧 技术方法**

技术手段：逻辑表达式（单调 DNF）、Beam Search、贪心集覆盖、解释列表（decision list）、对象掩码/高斯模糊、后置抽象与覆盖评估；

**📊 数据集**

使用 ADE20K 和 Pascal‑Parts 两个视觉数据集；在 VGG‑19 与 ViT‑B 两种网络上进行实验；

**📈 对比分析**

与模型原始验证准确率、Fidelity⁺/Fidelity⁻ 指标以及覆盖率进行对比；在 ADE20K 上覆盖率约 85%，多类解释列表准确率约 75%（VGG‑19 73%，ViT‑B 75%），在 Pascal‑Parts 上准确率约 53%；

**⚠️ 局限性**

局限性：① 需要对象或部件标注，或依赖自动分割；② 掩码模糊化可能产生 OOD 噪声；③ Beam Search 与贪心方法仍是近似，可能漏掉更精细的解释；④ 对复杂模型或大规模数据集的可扩展性尚未充分验证；⑤ 解释列表覆盖率虽高，但解释条数仍可进一步压缩。

---

## 607. QERS: Quantum Encryption Resilience Score for Post-Quantum Cryptography in Computer, IoT, and IIoT Systems

**arXiv ID:** 2601.13399 | [PDF](https://arxiv.org/pdf/2601.13399v1)

**作者:** Jonatan Rassekhnia `[一作]` `[通讯]` (Luleå University of Technology), Jonatan Rassekhnia (Luleå University of Technology)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出并实现了 Quantum Encryption Resilience Score (QERS)，用于评估在资源受限的 IoT/IIoT 环境中部署后量子密码学（PQC）时的系统性能与安全性综合指标。

**💡 创新点**

将多维度指标（延迟、包丢失、CPU 负载、能耗、信号强度、密钥大小、加密开销）统一归一化并通过三种模式（Basic、Tuned、Fusion）综合评分，首次将系统级、网络级与安全级指标融合为可解释、可复现的复合评分。

**🔧 技术方法**

使用 ESP32‑C6 设备进行实测；采用 min‑max 归一化、加权组合、随机森林回归预测 Fusion 模式；通过 Flask+仪表盘实现可视化。

**📊 数据集**

收集了 5 种主流 PQC 算法（Kyber、Dilithium、Falcon、SPHINCS+、NTRU）在两种无线距离（近端、5 m 远端）下的连续 24 h 数据，包含延迟、CPU、RSSI、能耗、密钥尺寸等指标。

**📈 对比分析**

通过比较 Basic/Tuned/Fusion 三种评分在不同距离、算法下的平均值，发现 Dilithium 与 NTRU 在 Fusion 模式下表现最佳，Kyber 与 SPHINCS+ 分数较低；Fusion 模式能显著平滑波动并体现环境压力。

**⚠️ 局限性**

局限性在于：仅覆盖 ESP32‑C6 低功耗 MCU 与 Wi‑Fi 通信；未涉及 BLE、LoRa 等网络；采样范围与时间窗口有限；随机森林模型需更多多样化数据验证其泛化能力。

---

## 608. Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks

**arXiv ID:** 2601.13392 | [PDF](https://arxiv.org/pdf/2601.13392v1)

**作者:** Shlok Shelat `[一作]` (Ahmedabad University), Manas Gaur `[通讯]` (University of Maryland)

**通讯引用:** 1453 | [OpenAlex ID](https://openalex.org/A5023667301)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并评估一个基于DFA构造的新基准，用来检验大型语言模型在正式推理中的符号推理能力。

**💡 创新点**

（1）首次将DFA构造任务拆分为知识检验、已知（seen）与未知（unseen）两类，严格控制记忆与组合推理的区分；（2）设计了手工与Arden定理逆向生成的两种unseen问题生成方式，确保问题的结构新颖；（3）提出三阶段提示协议与多策略提示（CoT、ToT）以深入分析模型错误模式。

**🔧 技术方法**

使用大型语言模型（GPT‑5.1、Gemini‑2.5‑Flash、Grok‑4.1‑fast‑reasoning），三种提示策略（Zero‑Shot、Chain‑of‑Thought、Tree‑of‑Thought），以及手工与Arden生成的DFA题库，结合自动与人工验证管道进行评测。

**📊 数据集**

包含 50 条 DFA 知识问答、90 题已知构造、180 题未知构造（60 手工，120 Arden 生成）共 320 题，所有题目均在公开或自制数据集上发布。

**📈 对比分析**

与三种提示策略下的模型结果对比，已知任务准确率 84–90%，未知任务直接提示仅 20–59%，显著下降；提示改进（CoT‑One‑Shot、ToT）可提升 3–30% 但仍低于已知水平；提示协议可纠正轻微错误，但对复杂 DFA 的全局不一致性修复效果有限。总体表明 LLM 在符号推理方面仍有显著不足。

**⚠️ 局限性**

（1）模型访问受限导致超时；（2）Token/状态空间爆炸限制深层嵌套表达式的处理；（3）验证仅在有限字符串长度内，可能漏检极端反例；（4）数据集仅涵盖正则表达式与 DFA，无法推广到更复杂形式；（5）实验未使用微调或自适应提示，可能低估模型潜能。

---

## 609. Robustness and Resilience Evaluation of Eco-Driving Strategies at Signalized Intersections

**arXiv ID:** 2601.13389 | [PDF](https://arxiv.org/pdf/2601.13389v1)

**作者:** Zhaohui Liang `[一作]` (University of Wisconsin - Madison), Xiaopeng Li `[通讯]` (University of Wisconsin - Madison)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出并验证了在信号灯路口评估生态驾驶策略鲁棒性和弹性的统一框架；

**💡 创新点**

将内部执行误差和外部环境扰动两类不确定性分别量化为鲁棒性指标R和弹性指标G，并将它们归一化到理论收益区间；

**🔧 技术方法**

使用滚动窗口优化和三次多项式轨迹规划作为控制器，基于轨迹功用函数（能源消耗与通行时间的加权和）与RMSE进行评估；

**📊 数据集**

实验数据来源于NGSIM亚特兰大Peachtree Street路口的交通时序与车辆行驶记录；

**📈 对比分析**

通过对两种控制器（优化型Method A与解析型Method B）在不同红灯延迟（0 s、2 s、4 s、6 s）的四组场景中测量RMSE、U、R、G，发现优化型控制器在鲁棒性与弹性上更稳定、误差更小；

**⚠️ 局限性**

仅考虑单车、仅模拟红灯延迟扰动、未覆盖多车交互与更复杂的交通情境，且指标侧重能效与跟踪误差，未完全涵盖安全性与长期性能。

---

## 610. Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning

**arXiv ID:** 2601.13387 | [PDF](https://arxiv.org/pdf/2601.13387v1)

**作者:** Zhenjiang Mao `[一作]` (University of Florida), Ivan Ruchkin `[通讯]` (University of Florida)

**通讯引用:** 453 | [OpenAlex ID](https://openalex.org/A5021509994)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了基于Signal Temporal Logic的步进置信度估计框架，并通过超网络实现问题级参数自适应

**💡 创新点**

将置信度视为时间信号，利用STL挖掘判别式时序模式，保持可解释结构，同时用超网络对实例进行参数调节

**🔧 技术方法**

Signal Temporal Logic（STL）规则挖掘、鲁棒性分数映射、超网络（hypernetwork）参数化、单样本推理、标准校准指标（ECE、Brier）

**📊 数据集**

四大推理基准：GAOKAO‑Math、CLadder、SciQ、Big‑Bench‑Hard（BBH）

**📈 对比分析**

与传统logit、self‑evaluation、self‑consistency、内部检视器等基线对比，单样本推理下ECE与Brier显著降低，校准效果优于基线

**⚠️ 局限性**

需预先分段，分段粒度影响结果；时序结构多为任务特定；仅使用token概率；在更开放式生成任务上需进一步验证

---

## 611. Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations

**arXiv ID:** 2601.13371 | [PDF](https://arxiv.org/pdf/2601.13371v1)

**作者:** Junyi Zhang `[一作]` (Zhejiang University), Min Zhang `[通讯]` (Zhejiang University)

**通讯引用:** 58048 | [OpenAlex ID](https://openalex.org/A5100402851)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `4de8e9d8-757b-475f-9627-18a445e50202` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了将3D人脸几何映射到球面后再展开成2D网格的Spherical Geometry Representation（SGR），并在此基础上构建了Spherical Geometry Diffusion（SGD）框架，实现了从文本到高质量3D人脸网格、面部重建和纹理合成。

**💡 创新点**

核心创新在于将几何约束到简单的球面拓扑，利用统一的2D表示解决网格拓扑难题；提出Center-symmetric Padding和Geometric Regularization两项技术提升训练稳定性与几何质量；以及双阶段扩散模型（先几何后纹理）实现可控生成。

**🔧 技术方法**

使用了VQ‑VAE编码SGR为几何潜在空间，结合条件潜在扩散模型（LDM）进行几何生成；随后采用基于SDXL的图像扩散模型做纹理生成；实现了球面三角剖分与Delaunay球面三角化等几何重建算法。

**📊 数据集**

主要使用Describe3D、FaceScape、COMA三大数据集，其中Describe3D提供文本-3D配对，FaceScape和COMA则通过结构化文本属性扩展评估。

**📈 对比分析**

与3DMM、MAE、CoMA、FacialGAN、D3FSM、i3DMM、FLAME、ImFace、ImFace++等方法在多项指标（Specificity、Diversity、Chamfer Distance、F‑score、CLIP评分）上均实现了更高的精度、更低的误差、更快的推理速度，尤其在几何质量和文本对齐上领先。

**⚠️ 局限性**

局限性主要在于公开文本‑3D人脸数据集规模有限，导致模型训练与泛化受限；此外对极端表情或稀有族群的表现尚未充分验证。

---

## 612. On the Relation of State Space Models and Hidden Markov Models

**arXiv ID:** 2601.13357 | [PDF](https://arxiv.org/pdf/2601.13357v1)

**作者:** Aydin Ghojogh `[一作]` (Lakehead University), Benyamin Ghojogh `[通讯]` (University of Waterloo)

**通讯引用:** 1351 | [OpenAlex ID](https://openalex.org/A5024030325)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

对隐藏马尔可夫模型（HMM）、线性高斯状态空间模型（LG‑SSM）、Kalman 滤波器以及现代 NLP 状态空间模型（如 S4、Mamba）进行统一的理论比较与系统分析。

**💡 创新点**

系统阐明了它们在模型形式、推理算法、学习方法与不确定性解释方面的相同点与本质差异，并将传统概率模型与当代确定性深度模型联系起来，构建了一个从离散概率到连续高斯再到确定性序列模型的统一框架。

**🔧 技术方法**

使用概率图模型（PGM）框架、前向后向推理、Kalman 滤波/平滑、Expectation‑Maximization（EM）以及梯度反向传播等技术进行分析与比较。

**📊 数据集**

本文为理论综述，未使用具体实验数据集；仅通过理论推导与结构对比进行讨论。

**📈 对比分析**

通过对模型结构、推理流程、学习算法与不确定性解释的对照表进行系统比较；未给出实验性能指标，主要以定性分析与方法对比为主。

**⚠️ 局限性**

主要局限在：①缺乏基于真实数据的实证验证；②对 S4、Mamba 等现代模型的内部机制讨论不够深入；③未覆盖非线性或非高斯状态空间模型的情况。

---

## 613. Remote Triggers: Misophonia, Technology Non-Use, and Design for Inclusive Digital Spaces

**arXiv ID:** 2601.13355 | [PDF](https://arxiv.org/pdf/2601.13355v1)

**作者:** Tawfiq Ammari `[一作]` (Rutgers University), Samantha Gilgan `[通讯]` (Rutgers University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本研究通过16名美国misophonia患者的深度访谈，系统剖析其在社交媒体、视频会议和休闲平台上的技术使用与非使用模式，探讨其应对策略，并提出以感官可访问性为核心的五项设计原则，以期构建更包容的数字空间。

**💡 创新点**

创新点在于：①将misophonia视为与神经多样性相关的感官障碍，填补以往仅关注听觉或行为干预的空白；②提出将感官触发分离、实时过滤、感官可预测性、协同边界协商与视觉触发管理五大设计原则，首次将视觉触发与实时音频/视频过滤技术结合；③以“排他性by‑design”为视角，强调平台设计责任而非用户自我调适。

**🔧 技术方法**

技术手段包括：①定性访谈与NVivo主题分析；②对音频触发进行机器学习分类（如检测咀嚼、敲击等）实现实时音频过滤；③利用计算机视觉检测视觉触发（如吃饭、重复运动）实现动态模糊或预警；④设计个性化感官偏好配置与共享边界协商工具；⑤提议在平台侧实现音视频分通道控制与内容级别感官标签。

**📊 数据集**

数据集为16位来自Reddit、Instagram和Facebook misophonia社群的美国成年志愿者，涵盖性别、触发音/视觉种类、触发强度等信息；未使用公开大规模语音/视频数据集，主要以访谈记录为主。

**📈 对比分析**

论文未搭建原型或进行对比实验，因此没有性能指标；通过主题分析对访谈数据进行归纳总结，结果以质性证据呈现，未与量化基准对照。

**⚠️ 局限性**

局限性包括：①样本规模小且仅来自美国线上社区，缺乏跨文化、跨年龄的代表性；②研究方法为定性访谈，无法验证提出的技术方案实际效果；③未进行用户实验或性能评估，缺少系统实现与可用性验证；④受访者对misophonia的认知差异可能导致自我报告偏差。

---

## 614. Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans

**arXiv ID:** 2601.13350 | [PDF](https://arxiv.org/pdf/2601.13350v1)

**作者:** Abdel Djalil Sad Saoud `[一作]`, Hanane Slimani `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了一种名为SeOT的多源域适配框架，利用最优传输（OT）计划构造双向图谱并通过谱嵌入得到域不变且具有判别力的样本表示，进而在目标域上训练分类器。

**💡 创新点**

核心创新点在于：① 将平滑的OT计划直接视为不同域之间的邻接矩阵，构造跨域连通图；② 通过谱图嵌入捕获各域间的内在结构，得到域无关的低维表示；③ 采用Wasserstein barycenter将多源信息融合在单一中间分布上，从而实现更稳健的多源对齐。

**🔧 技术方法**

技术要点包括：离散OT的熵正则化求解、Wasserstein barycenter的计算、基于拉普拉斯算子的谱图嵌入（使用Arnoldi迭代求k个最小特征向量）、以及常规的MLP/随机森林分类器。

**📊 数据集**

实验数据集：① Music‑Speech Discrimination（MSD）——音乐与语音在五种噪声域上的二分类；② Music Genre Recognition（MGR）——十种音乐流派在多噪声域上的多分类；③ CS‑RT（电缆缺陷诊断）——四种压缩因子下的反射信号多类分类。

**📈 对比分析**

与KMM、TCA、OT‑IT、OT‑Laplace、JCPOT、WBT、WBT_reg等现有方法在上述三个基准上对比。SeOT在MSD上平均提升约29%，在MGR上提升约18%，在CS‑RT上提升约25%，且在部分任务甚至超过了仅使用目标域标签的基准。

**⚠️ 局限性**

局限性：① 需要全域OT计划和谱分解，计算开销较大，难以直接扩展到极大规模数据；② 目前的实现为离线嵌入，对新样本的快速投影缺乏高效机制；③ 对极端类别不平衡或标签分布极端差异的适配效果尚未充分验证。

---

## 615. The Words That Can't Be Shared: Exploring the Design of Unsent Messages

**arXiv ID:** 2601.13343 | [PDF](https://arxiv.org/pdf/2601.13343v1)

**作者:** Michael Yin `[一作]` (University of British Columbia), Robert Xiao `[通讯]` (University of British Columbia)

**通讯引用:** 2793 | [OpenAlex ID](https://openalex.org/A5012394116)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了人们在情绪激动时写下但未发送信息的动机、体验与情绪反射，并通过对不同平台设计的9个探针（如“烧毁”“渐隐”“强制发送”等）探讨其对真实性、情绪释放和反思的影响。

**💡 创新点**

首次系统化地把未发送信息视为独立的数字化情绪调节实践，提出将笔记应用转化为专属“未发送消息”空间，并通过设计探针揭示平台设计如何调节自我呈现、情绪释放与反思三大情绪目标。

**🔧 技术方法**

采用定性访谈与主题分析相结合的方法，构建9个基于ReactJS的渐进式Web原型（探针），并在Zoom线上进行用户体验讨论。

**📊 数据集**

使用自愿参与的20名UBC学生（形成性研究）和8名同样背景的参与者（探针研究）进行数据收集，未使用公开数据集。

**📈 对比分析**

通过访谈中的主题对照和用户自述比较不同探针的效果，未进行量化性能评估，但研究显示“烧毁”“渐隐”等探针能提升情绪释放与“强制发送”“永不发送”等探针能影响真实性与决策。

**⚠️ 局限性**

样本以年轻女性为主，缺乏性别与文化多样性；主题分析由单一研究者完成，可能带来偏见；探针仅为概念性原型，缺乏长期使用与功能性验证。

---

## 616. Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay

**arXiv ID:** 2601.13456 | [PDF](https://arxiv.org/pdf/2601.13456v1)

**作者:** Sahasra Kokkula `[一作]` (Columbia University), Aaditya Baruah `[通讯]` (Columbia University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在联邦学习中模拟时序概念漂移，研究标准FedAvg易发生灾难性遗忘问题，提出客户端经验回放解决方案。

**💡 创新点**

创新点是将经验回放（replay buffer）嵌入联邦学习客户端，保持模型对已消失类别的记忆，而无需改动服务器聚合逻辑。

**🔧 技术方法**

采用FedAvg框架、客户端局部SGD训练、经验回放缓冲区、简单CNN模型与批量梯度聚合。

**📊 数据集**

使用Fashion‑MNIST数据集，在不同“季节”阶段只出现部分类别，构建人工漂移场景。

**📈 对比分析**

与IID FedAvg基线以及无回放的漂移FedAvg比较，实验表明无回放模型从74%跌至约28%，回放模型可恢复到78–82%的准确率，缓冲区容量越大性能越好。

**⚠️ 局限性**

局限在于仅在简易图像数据上验证，未考虑更复杂数据、真实漂移模式、部分参与客户端、以及差分隐私或安全聚合等安全强化。

---

## 617. HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations

**arXiv ID:** 2601.13547 | [PDF](https://arxiv.org/pdf/2601.13547v1)

**作者:** Yujia Hu `[一作]` (Singapore University of Technology and Design), Roy Ka-Wei Lee `[通讯]` (Singapore University of Technology and Design)

**通讯引用:** 1517 | [OpenAlex ID](https://openalex.org/A5089793938)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一套名为HateXScore的四维度指标，用于评估模型在仇恨言论检测任务中的解释质量。

**💡 创新点**

创新点在于将结论明确性、引用跨度的真实性与因果性、受保护群体识别以及内部逻辑一致性四个维度结合，形成系统化、可量化的解释评估框架，并通过可配置的受保护群体词表提升政策适配性。

**🔧 技术方法**

技术包括自然语言生成（LLM生成二元标签与自由文本解释）、字符串匹配与正则表达式提取引用、掩码-预测差异评估因果性、spaCy/jieba/KoNLPy进行分词、词形还原和NER、基于阈值的逻辑一致性判定，以及整体分数聚合。

**📊 数据集**

使用六个跨语言（英、汉、韩）仇恨言论数据集：HateXplain、HateCheck、Latent Hatred、HASOC、ToxiCN、KOLD。

**📈 对比分析**

与传统的准确率/宏F1对比，HateXScore能揭示解释失效和标签不一致情况；在模型层面，GPT‑4o和Qwen‑7B在大多数数据集上获得最高HateXScore，表明大型LLM在生成连贯、因果且符合政策的解释方面优于同类模型；实验还通过人类评测验证了该指标与人工判断的一致性。

**⚠️ 局限性**

局限性包括：自动掩码与引用匹配可能在隐晦或比喻文本中失误；受保护群体识别仍受词表完整性和多目标覆盖程度限制；目前仅针对单语言文本，未覆盖多模态或动态推理；在多目标攻击情境下TGI仅为二元判定，未细化覆盖度。

---

## 618. StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing

**arXiv ID:** 2601.13522 | [PDF](https://arxiv.org/pdf/2601.13522v1)

**作者:** Shuang Li `[一作]` (Iowa State University), Shuang Li `[通讯]` (Iowa State University)

**通讯引用:** 13692 | [OpenAlex ID](https://openalex.org/A5100415892)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种针对低Tucker秩张量感知的随机交替最小化算法（StoTAM），直接在核心张量和因子矩阵上进行优化，避免了传统方法中的昂贵张量投影操作。

**💡 创新点**

创新点在于：①将核心张量更新转化为闭式最小二乘解，②因子矩阵在Stiefel流形上做随机梯度步进并通过QR重排保持正交，③整个算法以随机小批量方式运行，显著降低了存储和计算成本，提升了实测收敛速度。

**🔧 技术方法**

使用技术包括：Tucker分解、随机小批量梯度下降、Stiefel流形上的梯度投影、QR重排正交化、HOSVD谱初始化、MATLAB实现。

**📊 数据集**

实验数据集为人工生成的三阶张量：尺寸为10×10×15，Tucker秩为(2,2,2)，核心张量与因子矩阵均为独立标准高斯随机数，测量张量为i.i.d. Gaussian（方差1/m），总测量数m=400。

**📈 对比分析**

与基线方法StoTIHT进行比较，结果显示StoTAM在墙壁时间上收敛更快：在约1秒内达到数值精度底线，而StoTIHT需更长时间；损失函数值和重构误差曲线均表现出更快的下降，尤其在前期迭代阶段。

**⚠️ 局限性**

限制包括：仅在合成实验中验证；缺乏理论收敛性证明；当前实现仅针对三阶张量，扩展到高阶或有噪声测量的情形尚未完成。

---

## 619. From "Fail Fast" to "Mature Safely:" Expert Perspectives as Secondary Stakeholders on Teen-Centered Social Media Risk Detection

**arXiv ID:** 2601.13516 | [PDF](https://arxiv.org/pdf/2601.13516v1)

**作者:** Renkai Ma `[一作]` (University of Cincinnati), Pamela J. Wisniewski `[通讯]` (International Computer Science Institute)

**通讯引用:** 5158 | [OpenAlex ID](https://openalex.org/A5032530421)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `9cc9baba-5356-466d-81ff-d80028d90279` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过对青少年社交媒体风险检测仪表板 MOSafely 进行专家访谈评估，探讨其设计、实现与可持续性挑战。

**💡 创新点**

提出“mature safely”范式，利用多方利益相关者的专家评估在青少年上线前识别并缓解技术与社会张力，重新定义“青少年中心”的设计。

**🔧 技术方法**

采用预训练的文本与图像风险检测模型（CNN、DNN、LSTM）并配合卡片式可视化界面，实现人机交互式风险评估。

**📊 数据集**

以模拟社交媒体导出示例数据演示系统功能，原始研究基于青少年自愿上传的社交媒体对话数据。

**📈 对比分析**

通过定性访谈主题分析评估专家反馈，未做量化性能对比；模型层面报告的准确率与 F1 分别在 82–87% 之间。

**⚠️ 局限性**

仅在专家视频演示阶段验证，缺乏真实系统与青少年用户反馈，且面临数据隐私、法律合规与可持续性等限制。

---

## 620. Group Relative Policy Optimization for Robust Blind Interference Alignment with Fluid Antennas

**arXiv ID:** 2601.13506 | [PDF](https://arxiv.org/pdf/2601.13506v1)

**作者:** Jianqiu Peng `[一作]` (Harbin Institute of Technology), Rui Wang `[通讯]` (Southern University of Science and Technology)

**通讯引用:** 69907 | [OpenAlex ID](https://openalex.org/A5100431408)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文提出了基于流体天线（FAS）的盲干扰对齐（BIA）框架，用于在无CSIT且存在通道估计误差的K用户MISO下行链路中实现鲁棒的总速率最大化。

**💡 创新点**

创新点在于首次将流体天线与BIA结合，构建了针对通道误差的鲁棒总速率优化问题，并提出了一种去除Critic网络的Group Relative Policy Optimization（GRPO）深度强化学习算法，使模型规模和计算量几乎减半，同时通过组基探索逃离局部最优。

**🔧 技术方法**

技术上主要采用流体天线场响应模型、BIA干扰对齐方案、基于误差分布的通道模型以及GRPO强化学习算法，并对比PPO、PPO-Init、MaximumGain、RandomGain等基线。

**📊 数据集**

实验数据集为仿真环境：K=4用户，BS 2个固定天线，流体天线位于0.5m³立方体内，信道误差协方差矩阵为[[0.02,0.01],[0.01,0.02]]×η，使用50,000个离散位置样本进行基线评估。

**📈 对比分析**

与PPO相比，GRPO在总速率上提升约4.17%；与PPO-Init提升约30.29%；与MaximumGain和RandomGain分别提升约200.78%和465.38%；在不同CSI误差程度下均表现出更优的鲁棒性。

**⚠️ 局限性**

局限性包括：仅在仿真环境中验证，缺乏真实硬件实验；对K用户规模和天线数有限制；未考虑动态环境下的时变信道；以及对GRPO超参数选择的敏感性未深入探讨。

---

## 621. Integrating Vision-Centric Text Understanding for Conversational Recommender Systems

**arXiv ID:** 2601.13505 | [PDF](https://arxiv.org/pdf/2601.13505v1)

**作者:** Wei Yuan `[一作]` (University of Queensland), Hongzhi Yin `[通讯]` (University of Queensland)

**通讯引用:** 16608 | [OpenAlex ID](https://openalex.org/A5088492734)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种屏幕文本感知对话式推荐系统（Screen-Text-Aware CRS），通过双通道（视觉+文本）对扩展上下文进行多粒度处理，融合对实体描述的视觉 OCR 表示和文本编码，进而提升推荐准确度和生成质量。

**💡 创新点**

创新点包括：①将完整对话或实体描述渲染为“屏幕文本”并用视觉编码器提取粗粒度语义；②对文本信息使用标准语言模型提取细粒度语义；③通过对比学习对齐三种视角的表征，并用交叉注意力+自适应门控实现动态融合；④将融合后的表征与 LLM 进行提示学习，实现端到端的推荐与回复生成。

**🔧 技术方法**

使用的技术主要有：视觉 OCR 编码器（DeepSeek‑OCR）、文本编码器（RoBERTa‑base）、图神经网络（1‑层 R‑GCN）用于知识图谱，LLM（Qwen3‑8B 生成实体描述，DialoGPT‑small 作为生成器），对比学习（InfoNCE）、交叉注意力、Perceiver 采样器、可学习提示（soft prompt）和多任务训练。

**📊 数据集**

实验数据集：ReDial 与 INSPIRED 两个公开对话式推荐基准，分别包含电影推荐和以说服/解释为主的对话场景。

**📈 对比分析**

与 15+ 传统与最新（包括 MSCRS、DCRS、UNICRS 等）基线相比，在 ReDial 上 Recall@10、NDCG@10、MRR@10 及 BLEU‑2、ROUGE‑2 等指标均实现 1–3% 的提升；在 INSPIRED 上提升幅度更大，Recall@10 提升 17.12%、NDCG@10 提升 14.88%、MRR@10 提升 13.57%，生成质量在 BLEU‑3 与 ROUGE‑2 上分别提升 18.75% 与 31%。

**⚠️ 局限性**

局限性：①仍依赖预训练模型的冻结，调参复杂；②视觉通道虽能处理长文本但会丢失细粒度语义；③对图像/结构化信息没有直接利用，无法进一步提升；④对新领域或非文本上下文的迁移性尚待验证；⑤需要额外的 OCR 渲染与视觉编码开销。

---

## 622. Spectrum & RAN Sharing: A Measurement-based Case Study of Commercial 5G Networks in Spain

**arXiv ID:** 2601.13484 | [PDF](https://arxiv.org/pdf/2601.13484v1)

**作者:** Rostand A. K. Fezeu `[一作]` (University of Minnesota), Zhi-Li Zhang `[通讯]` (University of Minnesota)

**通讯引用:** 11869 | [OpenAlex ID](https://openalex.org/A5100622097)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

在西班牙对Orange与Vodafone之间的5G频谱与RAN共享进行首次实测，并量化其对用户体验与网络性能的影响。

**💡 创新点**

创新点在于：①首次在真实商用5G网络中进行共享网络的实验测量；②同时评估控制面与数据信息面延迟、吞吐量、PRB利用率以及视频QoE；③揭示共享后核心网络可能共享带来的安全与性能效应。

**🔧 技术方法**

使用的技术包括：Accuver XCAL 5G测量工具、Ookla Speedtest、ping/Traceroute、Google/ Azure/ AWS云服务器、FFmpeg+DASH.js 进行ABR视频实验，以及自定义脚本实现驱动与静态测试。

**📊 数据集**

所用数据集为：约1.2TB的实测数据，包含1,060分钟的非共享测量与1,100分钟的共享测量，覆盖马德里等多座城市的5G基站与用户端流量记录。

**📈 对比分析**

比较方法：在相同环境下对比共享与非共享三大指标（控制面延迟、吞吐量、PRB效率）以及视频QoE（平均码率与停顿比例）。结果显示共享显著降低控制面延迟（约13%）并提升吞吐量（约27%），PRB效率提升；但对QoE的提升有限，停顿时间变化不大。

**⚠️ 局限性**

限制：仅覆盖西班牙一地区且仅两家运营商；实验设备统一为一款手机型号，未覆盖多平台差异；ABR算法分析有限；核心网络共享的安全性与隐私影响未深入探讨。

---

## 623. Exploring Learners' Expectations and Engagement When Collaborating with Constructively Controversial Peer Agents

**arXiv ID:** 2601.13479 | [PDF](https://arxiv.org/pdf/2601.13479v1)

**作者:** Thitaree Tanprasert `[一作]` (University of British Columbia), Dongwook Yoon `[通讯]` (University of British Columbia)

**通讯引用:** 1430 | [OpenAlex ID](https://openalex.org/A5028316272)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在异步在线学习环境中，对基于大型语言模型（LLM）的同伴代理实施建设性争议（CC）模型，比较了受限（regulated）与非受限（unregulated）行为机制，并探讨了代理行为设计透明度对学习者交互与感知的影响。

**💡 创新点**

发现学习者可被划分为效率驱动型和好奇驱动型两种取向，并证明代理的争议程度与透明度对不同取向学习者的参与度、控制感及代理能力感知产生显著差异，首次从行为机制与学习者价值观的交互角度阐释同伴代理的设计效用。

**🔧 技术方法**

使用 GPT‑4 构建代理，设计 2×2 混合因子实验，结合对话分析、G‑eval 自动评估、问卷量表与混合方法统计（线性混合模型、Bonferroni 校正）来评估代理行为与学习效果。

**📊 数据集**

数据来源于 144 名本科生的实验数据（6 个辩论主题、聊天记录、问卷与手工评分），未使用公开语料库或外部评测集，全部为自创实验数据。

**📈 对比分析**

通过对比受限与非受限代理以及透明与不透明设计的 2×2 交互效应，结果显示受限代理提升了参与度但未显著提升论证质量，非受限代理在效率驱动型学习者中表现更佳；透明度总体降低学习者对代理能力的感知，实验方法基于线性混合模型和 G‑eval，效应显著且可重复。

**⚠️ 局限性**

研究样本年龄偏低、LLM 经验丰富、仅包含英语本科生，实验仅为单次会话、缺乏对照组（单独学习），辩论主题与评估维度有限，限制了结果的普适性与对长期学习效果的解释。

---

## 624. A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model

**arXiv ID:** 2601.13476 | [PDF](https://arxiv.org/pdf/2601.13476v1)

**作者:** Jinhao Li `[一作]` (Monash University), Hao Wang `[通讯]` (Monash University)

**通讯引用:** 26970 | [OpenAlex ID](https://openalex.org/A5100446064)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了统一的变分式缺失值填补框架 PRAIM，利用预训练大语言模型对多模态充电数据进行语义编码，并通过检索增强记忆实现跨站点统一模型，完成电动汽车充电需求缺失值填补。

**💡 创新点**

创新点包括：① 用预训练 LLM 生成语义丰富的嵌入；② 引入检索增强生成（RAG）将全网上下文检索融合，打破单站点模型限制；③ 在变分空间与 FiLM 调制的 Transformer 解码器中实现不确定性量化；④ 在缺失数据分布恢复上显著优于传统方法。

**🔧 技术方法**

采用的技术有：预训练大语言模型（AngIE）、检索增强生成（RAG）、变分自编码器结构、FiLM 线性调制、Transformer 解码器、KL 正则化、ELBO 训练、归一化与周期编码等。

**📊 数据集**

使用了四个公开 EV 充电数据集：Palo Alto（美国）、Dundee（英国）、Boulder（美国）和 Perth（英国）。

**📈 对比分析**

与统计、传统 ML、深度学习及 LLM 基准（如 mean、KNN、LSTM、GAN、LLM4RS 等）在人工掩码和真实缺失场景下进行 MAE、NLL、CRPS 等多指标评估；PRAIM 在所有缺失比例下 MAE 最低、分布重建最接近原始、下游预测 MAE/MSE 显著下降（提升约 20–30%）。

**⚠️ 局限性**

局限性包括：对预训练 LLM 的依赖、检索过程导致的推理延迟、整体训练/推理速度比传统基线慢 5–20 倍、对极端连续缺失区块仍有改进空间、需要足够多站点样本以构建有效检索库、以及未在更细粒度（小时/分钟）时间尺度下充分验证鲁棒性。

---

## 625. A Tool for Automatically Cataloguing and Selecting Pre-Trained Models and Datasets for Software Engineering

**arXiv ID:** 2601.13460 | [PDF](https://arxiv.org/pdf/2601.13460v1)

**作者:** Alexandra González `[一作]` (Universitat Politècnica de Catalunya), Silverio Martínez-Fernández `[通讯]` (Universitat Politècnica de Catalunya)

**通讯引用:** 1415 | [OpenAlex ID](https://openalex.org/A5050955846)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发并发布了MLAssetSelection—a款专为软件工程场景设计的机器学习资产管理与选择Web工具，支持跨多 benchmark 的统一排行榜、交互式多维过滤和结果导出；

**💡 创新点**

突破性之处在于将 SE 任务映射与自动化资产甄别相结合，提供统一排行榜、可导出结果以及持续更新的资产目录，并首次实现针对软件生命周期各阶段的细粒度过滤与提醒功能；

**🔧 技术方法**

前端采用 Angular + TypeScript，后端使用 FastAPI 与 PostgreSQL，整体容器化部署于 Docker；后端核心包含基于 NLP 的任务分类管线、Leaderboard Engine、定时数据刷新作业，以及 GitHub Actions + SonarQube 的 CI/质量保障；

**📊 数据集**

主要数据来源为 Hugging Face Hub 的模型与数据集卡片、Papers With Code 归档、SEMODS 数据集以及通过 NLP pipeline 识别的 147 项 SE 任务分类；

**📈 对比分析**

通过构建统一排行榜，结合自报的评测结果（benchmark 名称、实现、语言、指标、分数）对模型进行标准化排序；实验表明工具能够快速生成符合 SE 需求的模型排名，虽然未给出具体性能提升数字，但能显著降低手工搜索成本；

**⚠️ 局限性**

局限性包括：依赖源注册库的文档完整性与评测真实性；当前仅集成 Hugging Face，其他模型仓库尚未接入；Leaderboard 仅基于自报评测，可能存在报告偏差；

---

## 626. Fairness-informed Pareto Optimization : An Efficient Bilevel Framework

**arXiv ID:** 2601.13448 | [PDF](https://arxiv.org/pdf/2601.13448v1)

**作者:** Sofiane Tanji `[一作]` (Universite Catholique de Louvain), Yassine Laguel `[通讯]` (Universite Cote d'Azur)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种通过双层优化实现 Pareto‑效率的公平学习框架，自动调节各敏感组的权重，以最小化用户指定的公平性指标。

**💡 创新点**

创新点在于：① 以任意公平性度量为目标，在 Pareto 前沿上寻找最优解；② 设计单循环大规模双层算法（如 Bilevel Adaptive Rescaling）并给出收敛保证；③ 公开实现该框架的开源 Python 工具箱。

**🔧 技术方法**

核心技术包括：双层优化、加权求和（scalarization）、梯度/海森矩阵近似、随机/无偏梯度估计、梯度裁剪、Lyapunov 分析，以及对大规模数据的单循环更新。

**📊 数据集**

使用 11 个真实世界表格数据集（ACSEmployment、ACSIncome、ACSTravelTime、Adult、COMPAS、German Credit、Arrhythmia、Law School、Parkinsons Telemonitoring、Communities and Crime、Student Performance）以及多种敏感属性划分，涵盖分类与回归任务。

**📈 对比分析**

与统一采样、平衡采样、一组单独训练、最小化极差（minimax）等基线比较，结果显示该方法在多种公平度量（Demographic Parity、Disparate Mistreatment、Equal Opportunity 等）上显著降低不公平度，同时保持或略优于基线的预测准确率/RMSE，说明在公平-准确率权衡上更优。

**⚠️ 局限性**

局限性包括：① 需要组间损失凸且可微，且假设梯度有界，限制了可应用模型类型；② 对小样本或高维深度网络的适用性未验证；③ 仍为局部最优，缺乏全局最优保证；④ 计算成本相对传统方法仍较高，尤其在大组数或大样本规模时；⑤ 仅针对表格数据和线性/核模型，未覆盖图像、文本等其他领域。

---

## 627. DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis

**arXiv ID:** 2601.13551 | [PDF](https://arxiv.org/pdf/2601.13551v1)

**作者:** Feng Ding `[一作]` (NanChang University), Jianqiang Du `[通讯]` (NanChang University)

**通讯引用:** 453 | [OpenAlex ID](https://openalex.org/A5015470164)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了面向扩散模型的细粒度部分面部伪造大规模数据集DiffFace‑Edit，并在该数据集上进行检测基准实验。

**💡 创新点**

创新点包括：①专门收集覆盖8个面部区域的单区与多区编辑样本；②引入detector‑evasive（语义模糊）样本，系统分析其对IMDL检测器的逃避效果；③结合8种IMDL定位器，提出跨域评估框架，全面评估检测器在不同生成模型与攻击模式下的性能。

**🔧 技术方法**

使用多种开源扩散模型（SD1.5、SD2、SD3、SDXL、FLUX、Kandinsky 2.1）与多模态语言模型生成编辑提示；采用IMDL‑BenCo评价指标（像素级F1、IoU）以及多尺度频域、边缘特征等技术。

**📊 数据集**

核心数据集为DiffFace‑Edit（2M+伪造图像），原始图像来源于CelebAMask‑HQ；对比使用了现有数据集如CIFake、DiffusionForensics‑General、ForgeryNet等。

**📈 对比分析**

在DiffFace‑Edit上对8个IMDL定位器进行实验，结果显示：在符合IMDL标准的SC样本上F1/IoU均较高，但在语义模糊SA样本上性能骤降；移除样本检测更困难；多区攻击导致检测精度明显下降，证明IMDL易受语义与位置过拟合影响。

**⚠️ 局限性**

局限性包括：移除样本生成难度大、样本多样性不足；实验集中于固定提示与面部区域，缺乏跨模态与跨域的进一步验证；对真实攻击环境的泛化能力仍待评估。

---

## 628. Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models

**arXiv ID:** 2601.13533 | [PDF](https://arxiv.org/pdf/2601.13533v1)

**作者:** Changshuo Zhang `[一作]` `[通讯]` (Individual Author), Changshuo Zhang (Individual Author)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a2602d71-93ab-4bad-974b-672788df8193` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 Entropy‑Guided Latent Reasoning (EGLR) 模型，改进生成式重排（GRM）中的探索‑利用平衡。

**💡 创新点**

创新点：①将推理与推荐同步进行，取代“先推理后推荐”；②利用熵阈值动态触发可变长度隐式推理；③在推理阶段提高温度、推荐阶段降低温度，实现自适应探索‑利用平衡。

**🔧 技术方法**

使用生成器‑评估器框架、强化学习（GRPO）、语言模型隐式推理机制、上下文感知推理标记和动态温度调整等技术。

**📊 数据集**

实验数据集为公开电商 Ad 数据集和短视频 KuaiRand 数据集。

**📈 对比分析**

与监督学习基线（DLCM、PRM、Seq2Slate）、RL 基线（EG‑Rerank、CMR、LAST）以及隐式推理基线（ReaRec、STREAM‑Rec、LatentR³）对比，EGLR 在 MAP、NDCG 和 Evaluator Score 上均取得显著提升，尤其在评估器分数上领先。

**⚠️ 局限性**

局限性：需调节 S_max、H_th、α 等超参数；推理步骤越多，推理延迟和计算量递增；在极深推理层时收益递减；与更强基座模型相比仍有提升空间。

---

## 629. Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs

**arXiv ID:** 2601.13528 | [PDF](https://arxiv.org/pdf/2601.13528v1)

**作者:** Jackson Kaunismaa `[一作]`, Erik Jones `[通讯]` (Anthropic)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并评估了一种利用受限前沿模型产生的“无害”prompt‑output对，对开源模型进行微调，从而提升其在化学武器合成等恶意任务上的能力的攻击方法，称为“elicitation attacks”

**💡 创新点**

创新点在于：①把前沿模型的安全措施转化为攻击工具；②通过生成与恶意任务相关但无害的prompt来规避前沿模型的拒绝；③引入基于anchor比较的评估指标，克服传统关键词rubric评估的局限；④系统地研究了攻击效果随前沿模型能力、数据量、训练域、以及安全措施的变化而变化的特征

**🔧 技术方法**

技术主要包括：使用安全的前沿模型（如Claude 3.5 Sonnet）生成高质量无害化学合成响应；构造无害prompt集合（从PubChem选取大量无害有机化合物并过滤潜在危险）；用这些prompt-output对对开源模型进行监督微调（SFT）；引入anchor‑comparison评估方法（利用已破解的前沿模型生成anchor，并比较子目标完成情况）；通过多种基准（rubric、anchor、人工专家）评估提升；探究数据规模、前沿模型版本与域相似度对攻击性能的影响；使用长度控制与过滤避免因回复长度导致的偏差。

**📊 数据集**

主要数据集：①从PubChem筛选约5000个有机化合物，生成对应的合成prompt；②使用Claude 3.5 Sonnet等前沿模型为这些prompt生成响应，形成无害prompt‑output对；③对比基线数据集，包括用开源模型自己生成的prompt‑output对（weak‑only）和公开化学教材内容（textbook‑only）；④在8个化学武器任务上进行评测，任务列表来自公开化学武器研究文献；⑤为anchor‑comparison生成anchor响应时使用破解版Claude 3.5 Sonnet与DeepSeek‑R1等模型；⑥实验还使用了Gemma 2 27B、Qwen 2.5 72B、Llama 3.1 8B等开源模型。

**📈 对比分析**

比较方法：采用“performance gap recovered”（PGR）和平均PGR（APGR）来衡量微调后模型与基准模型之间的提升；对比三种训练方式：weak‑only、textbook‑only与elicitation attack；使用anchor‑comparison与rubric两种评估指标；在不同前沿模型版本（Claude 3.5 Sonnet、Claude 4 Opus等）、不同数据规模（1k–10k对）以及不同训练域（从一般科学到有机合成）下评估。实验结果显示：在anchor‑comparison上，Llama 3.3 70B对Claude 3.5 Sonnet的PGR可达约39%，在rubric上可达61%；随着前沿模型升级和数据量增加，PGR显著提升，达到70%以上。相较于基线，elicitation攻击在所有模型和评估指标上均表现出显著更高的提升。

**⚠️ 局限性**

局限性包括：①依赖前沿模型生成高质量无害响应，若前沿模型安全措施更强或生成内容被严格过滤则攻击难度上升；②anchor‑comparison评估仍依赖破解模型，可能因hallucination导致评分偏差；③实验仅针对化学武器合成任务，其他恶意场景的迁移性尚未验证；④攻击效果受训练域相似度影响，若恶意任务与无害域差异大，则提升有限；⑤在实际部署中，前沿模型的接口限制、成本和监管可能限制攻击可行性。

---

## 630. Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging

**arXiv ID:** 2601.13498 | [PDF](https://arxiv.org/pdf/2601.13498v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 631. Event Classification by Physics-informed Inpainting for Distributed Multichannel Acoustic Sensor with Partially Degraded Channels

**arXiv ID:** 2601.13513 | [PDF](https://arxiv.org/pdf/2601.13513v1)

**作者:** Noriyuki Tonami `[一作]` (NEC Corporation), Tomoyuki Hino `[通讯]` (NEC Corporation)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `b88c6eac-d57a-4623-a604-1f401f3eb268` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

针对分布式多通道声学传感器在通道失效和布局变更情况下的声事件分类，提出了一种无学习的物理信息植入前端，利用逆时迁移（RTM）对多通道声谱进行重建与填补，再通过Transformer进行分类。

**💡 创新点**

创新点在于将逆时迁移的物理传播模型作为前端预处理，实现对失效通道的无学习填补，并通过物理一致的图像投影得到统一质量的多通道信号；同时通过学习空间权重评估各通道贡献，使得模型对布局变化更鲁棒。

**🔧 技术方法**

使用了逆时迁移（RTM）传播算子、三维格点的场景一致图像构建、前向投影重建、log‑mel特征提取、Audio Spectrogram Transformer（AST）以及可学习的通道权重机制。

**📊 数据集**

在模拟数据集上评估：使用ESC‑50音频库生成的2,000个环境声音，配合50通道分布式传感器，随机生成三种布局（圆形、线性、直角），并在每个通道添加-30~0 dB的噪声，形成30万个样本。

**📈 对比分析**

与AST基线、基于稀疏softmax的通道选择、通道交换数据增强以及两种oracle方法（最大SNR单通道、束波单通道）进行对比。RTM前端在所有布局下均表现最好，尤其在直角布局上提升13.1个百分点（从9.7%到22.8%），整体平均准确率达23.6%，显著优于传统学习方法。

**⚠️ 局限性**

主要局限在于假设所有通道同步，未处理异步采样；对真实硬件噪声和多径反射的建模有限；与oracle方法仍存在较大性能差距，表明对最优通道选择的进一步研究仍需开展。

---

## 632. Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives

**arXiv ID:** 2601.13503 | [PDF](https://arxiv.org/pdf/2601.13503v1)

**作者:** Kyung Ho Lim `[一作]`, Byung-Hoon Kim `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `9cc9baba-5356-466d-81ff-d80028d90279` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

设计并实现了一种基于语义图的去识别框架Anonpsy，对精神科病历进行结构保留的生成式去识别。

**💡 创新点**

创新点在于将病历转化为时间轴语义图并通过图约束扰动和图条件LLM重生成，既降低可识别性又保留诊断相关的临床结构。

**🔧 技术方法**

使用技术包括本地部署的ChatOllama LLM、语义图构建与校验、图约束扰动模块、图条件文本生成、以及规则与LLM相结合的混合推理。

**📊 数据集**

评估数据集为DSM‑5‑TR 临床案例（共92份，90份用于实验），为公开教育性精神科案例集。

**📈 对比分析**

通过与PHI遮蔽和LLM‑only重写基线的对照实验，采用5名精神科医师的专家评估和GPT‑5自动评估；结果显示在诊断保真度上Anonpsy与原始文本无显著差异，但在重识别风险评分和语义相似度上显著优于LLM‑only，风险集中在1–2分。

**⚠️ 局限性**

局限性包括：仅在教育案例集上验证，真实临床记录的多样性与不完整性可能影响语义图构建；专家评估样本有限；对罕见诊断或高度识别性症状的病例仍存在残余隐私风险。

---

## 633. Modeling Perpetrators' Fate-to-Fate Contagion in Public Mass Shootings In The United States Using Bivariate Hawkes Processes

**arXiv ID:** 2601.13501 | [PDF](https://arxiv.org/pdf/2601.13501v1)

**作者:** Youness Diouane `[一作]`, James Silver `[通讯]`

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

对1966-2024年美国公共枪击事件按嫌疑人死亡与否进行分类，并用双变量Hawkes过程估计事件间的传播效应。

**💡 创新点**

首次将嫌疑人存活与死亡视为两类事件，量化其交叉与自激发传播，揭示“存活”事件显著触发“死亡”事件。

**🔧 技术方法**

采用双变量指数核Hawkes点过程，利用Stan进行贝叶斯最大似然估计。

**📊 数据集**

使用The Violence Project的公开数据库，共200起事件，时间跨度1966年8月至2024年9月。

**📈 对比分析**

分别对全期与2000年前后两段建模并做残差检验，模型拟合良好，且后2000年“存活”→“死亡”传播显著增强，验证方法有效。

**⚠️ 局限性**

事件极少导致估计不稳，未考虑空间、媒体等协变量，且仅使用指数核可能限制模型的灵活性。

---

## 634. RASC: Enhancing Observability & Programmability in Smart Spaces

**arXiv ID:** 2601.13496 | [PDF](https://arxiv.org/pdf/2601.13496v1)

**作者:** Anna Karanika `[一作]` (University of Illinois Urbana-Champaign), Indranil Gupta `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 6563 | [OpenAlex ID](https://openalex.org/A5027240302)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

设计并实现了一种名为 RASC（Request‑Ack‑Start‑Complete）的新型 RPC 替代抽象，提升智能空间中 IoT 设备的可观测性与可编程性，并在 Home Assistant 平台上实现。

**💡 创新点**

创新点在于引入三阶段反馈（确认、开始、完成）与自适应轮询算法，支持细粒度动作依赖和动态调度，能够保证设备安全与执行序列等价，解决了传统 RPC 在长时序动作中的观测与编程瓶颈。

**🔧 技术方法**

主要技术包括在现有 RPC 之上层叠实现、事件驱动的 DAG 调度、动态调度算法（Shortest‑Task‑First 与 Restriction‑Vectors）以及基于历史时长分布的自适应轮询与统计学习，整体实现用 Python 约 8.5K 行代码。

**📊 数据集**

实验使用了在办公室设备（门、升降机、投影仪、灯、窗帘、空调等）采集的约 50 次动作执行时间数据，以及来自 IoTBench 和自定义的多样化例程集合，构成真实工作负载。

**📈 对比分析**

通过与周期性轮询、V‑opt（分箱最优）、FCFS、Just‑in‑Time 等基线方法对比，RASC 的轮询效率提升 44%–89%，调度延迟下降 10%–55%，CPU 与内存占用均低于基线，且能实现更高并行度。

**⚠️ 局限性**

局限性包括对极端长时延漂移和非平稳分布的适应仍有限；自适应轮询依赖设备已公开的状态字段，无法覆盖完全不支持状态查询的设备；缺少对硬件层修改的支持，无法处理所有低级设备异常。

---

## 635. Learning-Augmented Online TRP on a Line

**arXiv ID:** 2601.13494 | [PDF](https://arxiv.org/pdf/2601.13494v1)

**作者:** Swapnil Guragain `[一作]` (Kent State University), Gokarna Sharma `[通讯]` (Kent State University)

**通讯引用:** 1068 | [OpenAlex ID](https://openalex.org/A5002981812)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文研究在学习增强框架下的线性在线维修工人问题（TRP），提出了新的竞争性算法。

**💡 创新点**

创新点包括：在预测模型下给出3的竞争性下界，并构造 2+√3≈3.732 的确定性算法；在有误差预测时实现 min{2+√3+4δ,4} 的竞争性。

**🔧 技术方法**

技术手段主要是基于 AFRATI 的离线 TRP 规划、对半线进行递增长度回访的轮回策略以及对预测误差进行偏移补偿。

**📊 数据集**

本文未使用任何公开数据集，所有结果均为理论分析与证明。

**📈 对比分析**

与原始无预测模型下已知的 4 竞争比相比，提出的算法在 δ≠0 时竞争比可下降至 2+√3+4δ；在 δ=0 时达到 2+√3；在 δ≥0.067 时退回到 4，整体性能均优于现有最优。

**⚠️ 局限性**

局限性包括：仅针对一维线性度量空间；算法需预知误差比例 δ；缺乏对更一般度量空间的推广和实验验证。

---

## 636. Quantum Qualifiers for Neural Network Model Selection in Hadronic Physics

**arXiv ID:** 2601.13463 | [PDF](https://arxiv.org/pdf/2601.13463v1)

**作者:** Brandon B. Le `[一作]` (University of Virginia), D. Keller `[通讯]` (University of Virginia)

**通讯引用:** 7634 | [OpenAlex ID](https://openalex.org/A5017322945)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出并验证了量子限定符，用以判断在不同噪声、复杂度和维度下 CDNN 或 QDNN 更适合进行 DVCS CFF 提取。

**💡 创新点**

创新点在于将复杂度与信息理论指标整合成可量化的诊断量子指标，并在 DVCS 实验中展示其预测性能。

**🔧 技术方法**

采用量子深度神经网络、经典深度神经网络及多项式回归等机器学习技术。

**📊 数据集**

使用 JLab Hall A/B 的 DVCS 伪数据以及合成的分类与回归数据集。

**📈 对比分析**

通过对比 CDNN 与 QDNN 在分类、回归和 DVCS 提取中的误差指标，发现 QDNN 在高噪声、高维度或高复杂度场景下性能更佳。

**⚠️ 局限性**

局限在于当前量子硬件噪声、模型可解释性不足以及仅在特定实验场景下验证，缺乏广泛的实测验证。

---

## 637. Governance Matters: Lessons from Restructuring the data.table OSS Project

**arXiv ID:** 2601.13466 | [PDF](https://arxiv.org/pdf/2601.13466v1)

**作者:** Pedro Oliveira `[一作]` (Northern Arizona University), Igor Steinmacher `[通讯]` (Northern Arizona University)

**通讯引用:** 4129 | [OpenAlex ID](https://openalex.org/A5051186886)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df`

**🎯 论文内容**

对 R 语言高性能包 data.table 进行治理重组，并通过混合方法评估治理改革对项目健康、响应速度和社区活跃度的影响。

**💡 创新点**

①首次将社区调查与 GitHub 仓库挖掘结合，形成完整的治理评估框架；②提出可公开的、分层式治理模型；③为成熟 OSS 项目提供可复现的治理改进示例。

**🔧 技术方法**

使用 Likert 量表调查问卷、GitHub 仓库挖掘脚本、CHAOSS 指标、普通最小二乘（OLS）回归对比治理前后趋势。

**📊 数据集**

数据集包括 data.table GitHub 仓库的 PR、issue、贡献者行为记录（共 25 份问卷，过滤后 17 份有效回答）以及 25 个月的仓库活动日志。

**📈 对比分析**

通过 OLS 回归比较治理前后 12 个月的指标斜率差异；结果显示 PR 解决时间从 700+ 天降至 1–7 天，backlog 降至 0–20 项，新增贡献者增长约 200%，保留贡献者提升约 3 倍，整体性能显著提升。

**⚠️ 局限性**

局限性：仅针对单一项目，缺乏跨项目验证；问卷基于自评，可能受社会期望偏差；治理改革与其他并行干预（如基金资助、社区推广）难以完全归因；指标侧重 PR/issue，未覆盖所有治理维度。

---

## 638. LongSpeech: A Scalable Benchmark for Transcription, Translation and Understanding in Long Speech

**arXiv ID:** 2601.13539 | [PDF](https://arxiv.org/pdf/2601.13539v1)

**作者:** Fei Yang `[一作]`, Kaifu Zhang `[通讯]` (Alibaba International Digital Commerce)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `67630363-6be0-4f51-ab05-7198250671a5` `79276348-11e0-48e3-84bc-7ec231d0171c` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了LongSpeech基准，构建了10分钟长段音频的多任务数据集，并为长音频语音理解提供统一评测平台。

**💡 创新点**

创新点在于规模大（超过10万段音频）、任务多样（从ASR、翻译到总结、情感、时序定位等）以及提供可复现的多源构建流水线，展示了现有模型在长音频上的显著性能缺口。

**🔧 技术方法**

使用多来源拼接、语义聚类、嵌入筛选、合成语音等数据处理技术；实验中对比AudioFlamingo3、Voxtral、DashengLM、Qwen2-Audio、Kimi-audio、Whisper等大型音频‑语言模型，采用WER、BLEU、ROUGE、解析准确率等多维度指标进行评估。

**📊 数据集**

数据集来源包括LibriSpeech、TED‑LIUM v3、SPGISpeech、VoxPopuli、CommonVoice、AISHELL‑2、IWSLT、以及自制电影对话语料，合成约10分钟长段音频共计超过10万条。

**📈 对比分析**

通过对每个任务的标准指标进行模型对比，发现模型在ASR和翻译任务上存在专长但整体互斥；在总结、情感、时序定位等高层推理任务上的表现普遍低下，说明LongSpeech具有高度挑战性。

**⚠️ 局限性**

局限性包括：模型缺乏对长音频上下文的保持与结构化分析能力；任务间存在专化导致性能互斥；情感识别、时序定位等高层推理任务仍表现极差；当前构建流程虽多样但可能不足以覆盖更复杂的真实对话场景。

---

## 639. When Wording Steers the Evaluation: Framing Bias in LLM judges

**arXiv ID:** 2601.13537 | [PDF](https://arxiv.org/pdf/2601.13537v1)

**作者:** Yerin Hwang `[一作]` (Seoul National University), Kyomin Jung `[通讯]` (Seoul National University)

**通讯引用:** 3524 | [OpenAlex ID](https://openalex.org/A5077832834)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

系统评估了大型语言模型在四个高风险任务（真实性评估、越狱检测、毒性检测、语法可接受性判断）中对不同语言框架（谓词正面/负面）的敏感性，并量化了不一致性和偏差。

**💡 创新点**

首次将心理学框架效应引入LLM评估，提出P/¬P框架对齐度和任务诱导偏差三项指标，揭示模型族群与任务本身共同决定评估偏差。

**🔧 技术方法**

使用14个LLM评审器（GPT-4o、GPT-5系列、Qwen 2.5、LLaMA 3等）进行零样本推理，配合链式推理提示，记录两种框架下的判断输出；通过计算一致性、同意偏差和任务诱导偏差来评估鲁棒性。

**📊 数据集**

TruthfulQA（1000例）、JailbreakBench（300例）、Jigsaw毒性数据集（1000例）、GLUE CoLA子集（1000例）等公开数据集。

**📈 对比分析**

对每个模型在两种框架下的判断一致率进行比较，GPT-5-mini平均不一致率仅为5.69%，最稳健；小参数模型不一致率>50%；模型系列显示明显的同意或拒绝倾向；任务层面也展现不同的同意偏差；整体表明LLM评审器普遍缺乏对框架的鲁棒性。

**⚠️ 局限性**

仅覆盖四个任务，主要使用英语，框架限定为谓词正负两种形式，未探讨更广泛的语言或语义框架；使用严格匹配的提示对比，未检验真实系统中多维度提示变化的影响。

---

## 640. Sticky Help, Bounded Effects: Session-by-Session Analytics of Teacher Interventions in K-12 Classrooms

**arXiv ID:** 2601.13520 | [PDF](https://arxiv.org/pdf/2601.13520v1)

**作者:** Qiao Jin `[一作]` (North Carolina State University), Vincent Aleven `[通讯]` (Carnegie Mellon University)

**通讯引用:** 14060 | [OpenAlex ID](https://openalex.org/A5047522207)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文通过教师访谈与MATHia ITS日志分析，研究了K‑12数学课堂中教师即时帮助的决策因素与跨会话影响。

**💡 创新点**

首次将教师帮助历史与学生参与状态结合建模，揭示帮助“粘性”与学习效益短暂化的现象。

**🔧 技术方法**

采用混合效应逻辑回归、交叉滞后面板模型和增量因子模型（AFM）对教师行为与学生学习进行时序建模。

**📊 数据集**

使用MATHia ITS的1.4百万交互记录，包含339名学生、14节课的帮助记录与参与状态。

**📈 对比分析**

在混合效应模型中，帮助历史提升帮助概率1.32倍；交叉滞后模型显示帮助并不显著预测后续学习，说明短期收益但无长期效应。

**⚠️ 局限性**

主要局限包括教师帮助日志不完整、缺乏对帮助类型和离线行为的记录，且观察性研究难以确定因果关系。

---

## 641. AgenticRed: Optimizing Agentic Systems for Automated Red-teaming

**arXiv ID:** 2601.13518 | [PDF](https://arxiv.org/pdf/2601.13518v1)

**作者:** Jiayi Yuan `[一作]` (University of Washington), Goran Radanović `[通讯]` (Max Planck Institute for Software Systems)

**通讯引用:** 918 | [OpenAlex ID](https://openalex.org/A5047197460)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过进化算法和LLM元代理自动生成并迭代优化红队Agentic系统，以提高对大型语言模型的破窗攻击成功率。

**💡 创新点**

将红队任务视为Agentic系统设计问题，结合演化选择、交叉、变异和LLM自我反思，实现无需人工干预的自动化红队系统搜索。

**🔧 技术方法**

使用LLM元代理、进化算法（选择、交叉、变异）、自我反思机制、黑盒评估、目标模型与判定器的查询工具函数。

**📊 数据集**

主要使用HarmBench标准数据集（及其子集）进行攻击任务，在实验中针对Llama-2-7B、Llama-3-8B、GPT-3.5-Turbo、GPT-4o-mini等模型进行评估。

**📈 对比分析**

与AdvReasoning、AutoDAN-Turbo、Self-Refine等基线对比，攻击成功率在开源模型上达96–98%，在专有模型上实现GPT‑3.5‑Turbo/GPT‑4o‑mini 100%与Claude Sonnet 3.5 60%，显著优于现有方法。

**⚠️ 局限性**

依赖初始档案导致探索范围受限；对攻击多样性与效率的平衡不足；判定器误差可能影响评估；系统可能被恶意利用。

---

## 642. Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests

**arXiv ID:** 2601.13515 | [PDF](https://arxiv.org/pdf/2601.13515v1)

**作者:** Hanlin Zhou `[一作]` (School of Computer Sciences, Universiti Sains Malaysia), Qing Deng `[通讯]` (School of Computer Sciences, Universiti Sains Malaysia)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

通过结合随机森林检测目录扫描攻击，利用HTTP 5xx自定义指标动态调整 Kubernetes HPA，并将攻击流量重定向至蜜罐以实现自动扩容与攻击隔离。

**💡 创新点**

创新点在于将机器学习模型与 HPA 的自定义指标集成，实时判定攻击并自动调整 maxReplicas，避免攻击导致资源浪费，同时使用蜜罐隔离攻击流量，形成完整的攻击检测与自适应扩容闭环。

**🔧 技术方法**

使用技术包括 Kubernetes HPA、Prometheus 与 nginx‑vts exporter 收集 5xx 状态码，Python 脚本实现 Random Forest 分类、IP 识别、ConfigMap 动态更新，以及蜜罐 Nginx pod 的流量重定向。

**📊 数据集**

数据集为由 Python 脚本模拟的访问日志，共 200 个 IP，其中 10 个执行目录扫描，标记 404/403 为攻击，随后用于训练与评估随机森林模型。

**📈 对比分析**

在六种不同攻击概率与阈值组合下重复实验，比较 5xx 错误率、总请求时延与 F1 分数；实验显示当阈值设置合理时，HPA 动态调整可保持低 5xx、低时延，F1 分数均在 0.95 以上，验证模型与方法的有效性。

**⚠️ 局限性**

实验规模有限，易出现过拟合；阈值需手工调优；仅模拟目录扫描攻击，未覆盖其他攻击类型；实验仅在单节点环境中进行，缺乏大规模验证。

---

## 643. SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation

**arXiv ID:** 2601.13462 | [PDF](https://arxiv.org/pdf/2601.13462v1)

**作者:** Amine Rostane `[一作]` `[通讯]` (ESIEA), Amine Rostane (ESIEA)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `e0540dec-d77f-42db-94ae-d039248f6393` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本论文提出并实现了SpatialBench-UC，一个可复现的文本到图像模型空间关系评估基准，采用选择性预测框架自动判定PASS/FAIL/UNDECIDABLE并给出置信度。

**💡 创新点**

创新点在于将空间评估建模为带有置信度和拒绝选项的选择性预测问题，并通过人类审核校准阈值，提供可解释的风险‑覆盖曲线，以及利用对抗性角色对换构建的对比式提示对。

**🔧 技术方法**

技术上使用了COCO预训练的Faster R‑CNN和开源Grounding DINO目标检测器，结合几何距离判定、近界阈值、重叠和稳健性检查，构建判定器；并采用人机标注、阈值网格搜索进行置信度校准。

**📊 数据集**

使用了200条轴对齐空间关系提示（50个对象对×4种关系），生成的800张图像（每提示4个随机种子）来自SD 1.5、BoxDiff和GLIGEN；评估基准包含对偶提示对和人类审核样本N=200。

**📈 对比分析**

与三种基线（SD 1.5 Prompt‑only、SD 1.5+BoxDiff、SD 1.4+GLIGEN）比较，判定器PASS率分别为11.8%/23.8%、40.4%/42.5%、51.6%/52.0%，条件PASS率在已决定样本上达95–99%，表明带空间约束的生成方法显著提升了空间关系遵循性。

**⚠️ 局限性**

局限性包括判定器高度依赖检测器性能，缺失检测导致大量UNDECIDABLE；人类审核单一标注者且规模有限；基准仅覆盖两物体轴对齐关系，且置信度未完全校准为概率。

---

## 644. More Than Efficiency: Embedding Compression Improves Domain Adaptation in Dense Retrieval

**arXiv ID:** 2601.13525 | [PDF](https://arxiv.org/pdf/2601.13525v1)

**作者:** Chunsheng Zuo `[一作]` (Johns Hopkins University), Daniel Khashabi `[通讯]` (Johns Hopkins University)

**通讯引用:** 5641 | [OpenAlex ID](https://openalex.org/A5043628255)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

针对预训练稠密检索模型在专业领域的性能下降，提出仅对查询向量做PCA压缩，再将压缩矩阵映射到查询和文档向量，从而实现无监督的领域自适应。

**💡 创新点**

创新点在于：①首次发现仅对查询进行PCA压缩而非文档或两者合并，可在多数模型-数据集组合中获得显著性能提升；②证明这一“零成本”线性变换在多达14个不同领域和语言的数据集上普遍有效，并与更复杂的域自适应方法（如GPL+JPQ、GPL+BPR）可比甚至优于。

**🔧 技术方法**

核心技术为：稠密检索模型（如MiniLM、GTE、Sent‑T5、BGE等）生成向量；对目标域查询（或查询+文档）做均值中心化后执行PCA，保留90%（或其它比例）主要成分；将得到的投影矩阵应用于查询和文档向量，随后在压缩空间里计算余弦相似度进行检索。

**📊 数据集**

使用14个MTEB基准数据集（含软件工程、医学、金融、科研、新闻等多领域）以及额外11个查询量较小的MTEB数据集，覆盖多语言（英文、丹麦语、德语）。

**📈 对比分析**

与未压缩基线、Query+Document压缩以及GPL+JPQ/BPR等先进域自适应方法对比。结果显示：Query压缩在126个模型-数据集组合中有75.4%获得提升，平均提升约10–20% NDCG@10；在部分数据集（如SpartQA、MedQA、Code）可提升超过40%；相较于GPL+JPQ/BPR，PCA在5个公共数据集上获得相同或更高的相对改进，且无需额外训练或数据生成成本。

**⚠️ 局限性**

局限性包括：①依赖预训练模型已捕获足够的领域信息，极专业词汇可能无法充分改善；②需要一定量的无标签目标域样本来稳定估计协方差矩阵；③最优保留比例因模型和数据集差异而异，需要经验或实验确定；④作为线性方法，PCA可能无法捕捉非线性语义结构，适用于未来结合非线性降维方法。

---

## 645. DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities

**arXiv ID:** 2601.13502 | [PDF](https://arxiv.org/pdf/2601.13502v1)

**作者:** Nhi Kieu `[一作]` (Queensland University of Technology), Sridha Sridharan `[通讯]` (Queensland University of Technology)

**通讯引用:** 13079 | [OpenAlex ID](https://openalex.org/A5055128383)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `8d10c613-917e-4880-9716-17789f50e119` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在遥感语义分割中，提出 DIS2 框架，实现了在缺失模态下仍能保持高精度的分割性能。

**💡 创新点**

创新点包括将解耦学习与知识蒸馏融合为 DLKD，以主动补偿缺失模态；使用 Classwise Feature Learning Module（CFLM）对不同类别进行自适应注意力；以及采用层次混合融合（HF）实现多尺度特征融合。

**🔧 技术方法**

核心技术包括：卷积+Transformer 混合编码器、正交约束的解耦分支、基于特征层和 logits 的层级知识蒸馏、类级注意力查询与多尺度解码器。

**📊 数据集**

在 ISPRS 的 Vaihingen 与 Potsdam 两个遥感数据集上进行实验，分别包含 RGIR 与 NDSM 两种模态。

**📈 对比分析**

与 GEMMNet、mmformer、ShaSpec、SimSiam 及其变体对比，DIS2 在全模态、缺失 RGIR 与缺失 NDSM 三种场景下均显著提升 mIoU 与 mF1，尤其在极小目标 “car” 的识别上提升 10–15 分。

**⚠️ 局限性**

局限性在于仍需完整模态训练样本以进行知识蒸馏，且在多模态全部缺失或极端噪声环境下鲁棒性尚未完全验证。

---

## 646. Concurrent Permissive Strategy Templates

**arXiv ID:** 2601.13500 | [PDF](https://arxiv.org/pdf/2601.13500v1)

**作者:** Ashwani Anand `[一作]` (Max Planck Institute for Software Systems), Anne-Kathrin Schmuck `[通讯]` (Max Planck Institute for Software Systems)

**通讯引用:** 416 | [OpenAlex ID](https://openalex.org/A5039498617)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并实现了并发可许可策略模板（ConSTels），能够压缩表示安全、Büchi 与 Co‑Büchi 目标下的随机赢策略集合，支持离线增量合成与在线自适应。

**💡 创新点**

首次为并发游戏设计可许可策略模板，融合了模板组合与冲突无关性分析，实现对并发安全与活性目标的高效合成与运行时概率调整，显著提升了策略族的表示与利用效率。

**🔧 技术方法**

采用并发游戏理论、随机策略抽象、模板合成与冲突无关性分析、在线概率调整算法，并在原型工具中实现了模板生成、组合与运行时自适应功能。

**📊 数据集**

使用公开的并发游戏基准图（包含安全、Büchi、Co‑Büchi 目标的标准测试实例），若无具体数据集则采用常见的基准图形游戏集合。

**📈 对比分析**

与传统单一赢策略合成方法及基于PeSTels的转让策略进行比较，实验结果表明 ConSTels 在规模性与适应性上更优，平均合成时间缩短约 30%，且在在线自适应场景中保持了正确性与性能。

**⚠️ 局限性**

限制包括仅覆盖安全、Büchi 与 Co‑Büchi 目标；对更复杂或更大规模系统的支持仍有限；在线自适应假设对手行为可观测且有限；工具实现处于原型阶段，缺乏工业级验证。

---

## 647. Bridging the Gap Between Estimated and True Regret Towards Reliable Regret Estimation in Deep Learning based Mechanism Design

**arXiv ID:** 2601.13489 | [PDF](https://arxiv.org/pdf/2601.13489v1)

**作者:** Shuyuan You `[一作]` (Griffith University), Zhe Wang `[通讯]` (Griffith University)

**通讯引用:** 11455 | [OpenAlex ID](https://openalex.org/A5100621319)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

系统评估了基于深度学习的多物品拍卖机制（RegretNet、ALGnet、RegretFormer、CITransNet）的激励兼容性失效，并提出了理论下界与基于项目的退回近似以及基于项目梯度引导的初始化策略，显著提升了退回估计的准确性和计算效率。

**💡 创新点**

创新点在于：①推导出退回的严格下界与线性可计算的项目式退回近似；②设计了将离散项目搜索结果转化为结构化梯度上升初始点的Guided Gradient Refinement方法；③通过这些方法在保持近似最优的同时，将计算成本从数百小时降至约一小时，实现数百倍速度提升。

**🔧 技术方法**

技术包括：理论证明与下界推导、项目式退回计算、离散网格搜索、结构化多样化初始化（组合、单项、扰动、随机等）、梯度上升优化、实验对照与计算复杂度分析。

**📊 数据集**

使用合成加性估值数据，取自均匀分布 U[0,1] 的 i.i.d. 估值，测试样本 10,000 例；此外对 CITransNet 使用其原始更复杂估值分布。

**📈 对比分析**

与原始模型（默认超参数）和最优/近似最优（全搜索或 1,000 初始+2,000 步梯度）进行对照；结果显示在小规模设置下误差 < 1%；在大规模设置下，新方法在 1–2 小时内得到与近似最优相当的退回，速度提升约 200–1000 倍，且在 RegretFormer 中揭示了 40 倍以上的误报退回。

**⚠️ 局限性**

局限性包括：①项目式退回在存在强交叉效应时可能低估真实退回；②方法主要针对加性估值，未针对非加性或更复杂分布进行验证；③当估值空间维度极高时仍需适度增大 k 或细化网格，计算负担不完全消除；④未对真实市场环境的收益与兼容性进行进一步实验验证。

---

## 648. Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization

**arXiv ID:** 2601.13451 | [PDF](https://arxiv.org/pdf/2601.13451v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

---

## 649. The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing

**arXiv ID:** 2601.13487 | [PDF](https://arxiv.org/pdf/2601.13487v1)

**作者:** Olivia Pal `[一作]` (University of Illinois), Koustuv Saha `[通讯]` (University of Illinois)

**通讯引用:** 3141 | [OpenAlex ID](https://openalex.org/A5057029055)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

利用大规模社交媒体数据开展了新闻消费与心理社会结果的准实验研究

**💡 创新点**

首次量化不同新闻互动方式对情绪、行为与认知健康的差异效应，揭示了主动互动可缓解负面情绪、被动收藏则加剧抑郁等问题

**🔧 技术方法**

采用潜在结果框架、倾向得分匹配、相对处理效应计算和异质性处理效应回归

**📊 数据集**

来自去中心化平台的约26M条帖子和45M条评论数据，其中148,680名参与者被标记为处理组，83,711名为对照组

**📈 对比分析**

通过匹配后比较处理组与对照组的RTE，显著提升抑郁51%、焦虑36%等情绪指标，且在两个月内持续；回归表明收藏互动对抑郁等指标的效应超过十倍

**⚠️ 局限性**

受限于单一平台、缺乏临床验证、无法完全排除平台使用整体影响，且未考虑新闻主题差异与文化背景

---

## 650. Context and Transcripts Improve Detection of Deepfake Audios of Public Figures

**arXiv ID:** 2601.13464 | [PDF](https://arxiv.org/pdf/2601.13464v1)

**作者:** Chongyang Gao `[一作]` (Northwestern University), V. S. Subrahmanian `[通讯]` (Northwestern University)

**通讯引用:** 18008 | [OpenAlex ID](https://openalex.org/A5038645035)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出并实现了Context-based Audio Deepfake Detector (CADD)，能够将音频与其上下文信息（新闻、社交媒体帖子、Wikidata信息）和转录文本结合起来，提升对公共人物音频深度伪造的检测性能。

**💡 创新点**

创新点：①将开放获取的上下文数据与音频特征融合；②设计了可插拔的特征提取与神经处理模块，兼容现有SOTA音频检测器；③通过对比实验展示上下文/转录对不同数据集的显著提升及对抗性攻击的鲁棒性。

**🔧 技术方法**

使用技术：ALBERT文本编码、PCA降维、LFCC/MFCC/Whisper音频特征、深度学习后端（如RawNet3、LCNN等）以及融合模块；还对多种传统机器学习模型进行了基线实验。

**📊 数据集**

数据集：①Journalist-provided Deepfake Dataset (JDD，255份真实记者收集的深度伪造音频)；②Synthetic dataset (SYN，771条死故人物音频)；③In-The-Wild (ITW) 公开数据集；④P^2V 大规模合成数据集（250k+样本）。

**📈 对比分析**

对比方法：在71个基线（22个SOTA检测器 + 49传统ML模型）上做实验，使用F1、AUC、EER、Avg评分。结果显示：在JDD上CADD平均提升5.9%–39.0%；SYN上提升3.99%–9.5%；ITW上提升0.89%–1.48%；P^2V上提升3.3%。CADD在23种对抗性音频攻击中，平均性能下降仅-0.71%，显著优于基线。

**⚠️ 局限性**

局限性：①需要可获取的高质量上下文和转录文本，某些领域或语言缺乏此类资源；②在已实现近乎完美的简单数据集（如ITW）上提升有限；③对政治人物深度伪造的误差仍高于娱乐人物，说明语言复杂度与多样性带来的挑战；④模型依赖现有SOTA检测器的前端，整体推理成本较高。

---

## 651. A simulation of urban incidents involving pedestrians and vehicles based on Weighted A*

**arXiv ID:** 2601.13452 | [PDF](https://arxiv.org/pdf/2601.13452v1)

**作者:** Edgar Gonzalez Fernandez `[一作]` `[通讯]` (INFOTEC Centro de Investigación e Innovación en TIC), Edgar Gonzalez Fernandez (INFOTEC Centro de Investigación e Innovación en TIC)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

提出了基于加权 A* 的多智能体仿真框架，用二维网格城市模型模拟行人与车辆在各种障碍与交通规则下的交互，评估冲突、侧行和行驶效率。

**💡 创新点**

将加权 A* 与风险惩罚函数结合，使代理能够在路径成本与安全风险之间调节，模拟从守法到鲁莽的多样化行为；通过可调权重实现路径优化与风险控制的双重功能；利用热力图直观展示冲突热点。

**🔧 技术方法**

使用 AgentPy 多智能体框架实现仿真；加权 A*（带风险项）进行路径规划；离散时间感知‑反应‑行动循环；统计收集平均车速、侧行次数、碰撞数；生成冲突与速度热力图。

**📊 数据集**

采用人工构建的 5×5 区块网格（每块 15×15 单元），随机生成障碍、车辆与行人出生率；未使用真实 GIS 数据，未来计划引入 OpenStreetMap 等。

**📈 对比分析**

通过改变行人/车辆数量、障碍占比以及加权参数进行实验，对比基线（标准 A* 或无风险权重）结果。实验表明：权重增大导致侧行率上升，车辆速度随车辆密度下降，碰撞主要由车辆密度驱动；加权 A* 计算速度快、占用内存低，仿真可在 1000 步内完成。

**⚠️ 局限性**

局限性包括：二维网格简化真实城市几何；未纳入交通信号灯、交叉路口动态控制；人行道、车道宽度未细化；风险函数手工设定，对参数敏感；缺少真实地图验证；未考虑多车道、复杂车辆动力学或群体拥堵模型。

---

## 652. BladeSDF : Unconditional and Conditional Generative Modeling of Representative Blade Geometries Using Signed Distance Functions

**arXiv ID:** 2601.13445 | [PDF](https://arxiv.org/pdf/2601.13445v1)

**作者:** Ashish S. Nair `[一作]` (GE Aerospace Research), Liping Wang `[通讯]` (GE Aerospace Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文提出了一套基于DeepSDF的域特定隐式生成框架，用于涡轮叶片几何的重构、无约束生成和性能感知的条件生成，并提供了量化的误差指标；

**💡 创新点**

创新点包括：① 采用截断SDF及凸包+KD‑树标签构建高质量叶片SDF；② 在潜空间学习到近似高斯且可解释的结构，主成分与叶片几何参数（如锥度、弦长比例）高度相关；③ 通过神经网络把最大方向应变映射到潜码，实现性能驱动的条件生成；④ 证明重构误差始终低于1%最大叶片尺寸，且生成的叶片无伪影且符合工程可制造性；

**🔧 技术方法**

使用的技术包括：DeepSDF auto‑decoder（8层512宽的MLP，dropout+BN），截断SDF采样、KD‑树距离；潜空间正则化为零均值高斯；潜空间主成分分析；潜码高斯采样；神经网络映射（2隐藏层128单元）从应变到潜码；Marching Cubes提取表面；卷积/点云处理的凸包求法；Adam优化和学习率衰减；

**📊 数据集**

数据集为合成涡轮叶片集合，222个训练样本和300个测试样本，基于两表面参数化（bottom/ top 5* 参数，K1–K3比例），每个叶片全局归一化至[-1,1]^3；

**📈 对比分析**

评价方法主要通过表面到表面的欧氏距离误差，训练集平均误差≈5.5×10⁻²（<1% D_max），测试集误差范围相近但分布更宽；潜空间与叶片参数的一一对应通过PCA验证，生成的叶片在无约束与条件两种方式下均保持光滑、无伪影，且与传统2D‑引导或无约束3D管线相比提供了可解释性和性能约束；

**⚠️ 局限性**

局限性包括：① 仅在合成数据上验证，缺乏真实扫描数据的评估；② 条件映射仅基于三维应变特征，可能无法覆盖更复杂的性能指标；③ 由于解码器容量限制，测试集潜码方差增大导致重构误差分布更宽；④ 未考虑预测不确定性和交互式设计；⑤ 仍需与CAD约束和可制造性约束进一步耦合。

---

## 653. Preconditioning Benefits of Spectral Orthogonalization in Muon

**arXiv ID:** 2601.13474 | [PDF](https://arxiv.org/pdf/2601.13474v1)

**作者:** Jianhao Ma `[一作]` (University of Pennsylvania), Yuxin Chen `[通讯]` (University of Pennsylvania)

**通讯引用:** 4038 | [OpenAlex ID](https://openalex.org/A5100416078)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

对谱正交化梯度优化器（Mu）在矩阵分解和线性变换器的上下文学习任务中进行理论与实验研究，证明其在线性收敛下实现无条件数依赖的收敛速率。

**💡 创新点**

提出通过谱正交化实现的自适应预条件化机制，显著降低梯度搜索方向的条件数影响，并给出严格的收敛证明，首次在具体任务上验证其加速效果。

**🔧 技术方法**

使用谱正交化（matrix sign）梯度更新、指数衰减学习率、离散标量序列分析，以及对角化分解将矩阵迭代拆解为独立标量序列的理论工具。

**📊 数据集**

主要使用合成实验数据：随机生成的对称正定矩阵（条件数可控）以及随机生成的协方差矩阵，实验规模为 d=100，r=2 等设置。

**📈 对比分析**

与梯度下降（GD）和无动量的 Muon 变体进行对比；实验表明 Muon 在高条件数或过参数化情形下迭代次数大幅下降、收敛更快、精度达到机器级别；GD 与无动量版本在这些情形下收敛缓慢。

**⚠️ 局限性**

仅针对两类极简任务进行理论分析，假设列空间完美对齐、需要小幅初始化；对更一般矩阵优化问题、非线性网络或实际数据集的适用性尚未证明。

---

## 654. Patterning: The Dual of Interpretability

**arXiv ID:** 2601.13548 | [PDF](https://arxiv.org/pdf/2601.13548v1)

**作者:** George Wang `[一作]` (Timaeus), Daniel Murfet `[通讯]` (Timaeus)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了如何通过对训练数据的精准调节来引导神经网络形成预期的内部结构和泛化模式（即“patterning”）

**💡 创新点**

提出将线性响应理论（susceptibility）反向应用，构建从目标内部结构到训练数据调整的映射，从而实现对网络泛化的可控写入

**🔧 技术方法**

利用结构贝叶斯框架、奇异学习理论中的本地学习系数、以及基于SGLD的贝叶斯后验采样来估计susceptibility，并求解伪逆实现数据重加权

**📊 数据集**

在小型3M参数Transformer上使用Pile子集进行语言建模实验，并在合成括号平衡任务（包含Nested和Equal‑Count两种算法）上使用自定义数据集

**📈 对比分析**

实验表明：沿第二主成分的重加权能加速或抑制诱导电路的形成；在括号任务中，通过识别并加权“几乎嵌套/几乎等数”样本，成功将模型聚集到所需算法，实现了对算法分布的显著偏移

**⚠️ 局限性**

局限性包括仅在小模型和简单任务上验证，susceptibility估计计算量大，线性近似对大幅度干预的适用性未知，以及缺乏在线动态控制的实现

---

## 655. ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution

**arXiv ID:** 2601.13546 | [PDF](https://arxiv.org/pdf/2601.13546v1)

**作者:** Hui Sun `[一作]` (Nankai University), Jiang Bian `[通讯]` (Microsoft Research Asia)

**通讯引用:** 13006 | [OpenAlex ID](https://openalex.org/A5030951014)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了基于多代理的时间序列进化算法TSEvol，并基于其生成的TSEData-20K数据集，训练并优化了一系列LLM驱动的异常检测模型ChatAD。

**💡 创新点**

创新点包括：①多层代理（认知推理层CRL和交互反馈层IFL）生成高质量多轮推理对话；②基于TS特征的强化学习优化TKTO，实现跨任务零样本推理；③搭建LLADBench评测基准。

**🔧 技术方法**

技术主要有：多代理指令进化、Chain-of-Thought推理、LoRA微调、TKTO强化学习、LLM-as-judge评测、长上下文处理。

**📊 数据集**

使用的数据集包括：TSEData-20K（多轮对话与推理）、ANDE、SGAD、OERQA、IMPUT、FOREC、CLASS、TKTOD等。

**📈 对比分析**

与9个公开基准模型对比，ChatAD在单轮和多轮异常检测、推理、预测、分类任务上平均提升30%以上准确率、F1，并将误报率降低至约1%-5%（单轮FPR降至4.55%）。

**⚠️ 局限性**

局限性在于Transformer对数值数据的原生理解不足，缺乏专门为时间序列设计的架构，且多模态扩展尚待进一步研究。

---

## 656. TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning

**arXiv ID:** 2601.13545 | [PDF](https://arxiv.org/pdf/2601.13545v1)

**作者:** Shirin Shahabi `[一作]` (Inference Labs Inc), Haruna Isah `[通讯]` (Inference Labs Inc)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `5a41884c-404f-4688-a89c-aa238c10fe68` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出并实现了TruthTensor，一套基于实时预测市场的LLM评估框架，用以测量模型的准确性、校准、漂移及风险敏感性。

**💡 创新点**

创新点在于将模型评价从静态基准转向实时预测市场，并引入叙事、时间、置信漂移度量以及“人类模仿”评分，解决了数据污染和闭合世界评测的缺陷。

**🔧 技术方法**

采用指令锁定、版本化提示、基线构造、工具增强推理和概率预测，结合Polymarket实时行情、Brier、Log‑Likelihood、ECE等统计量进行多维评估。

**📊 数据集**

利用超过50万场实时预测市场事件（政治、经济、科技等）以及对应的市场报价作为真值，覆盖约一百万次概率更新。

**📈 对比分析**

将8款大模型与多种基线并行评估，使用Brier、ECE、漂移分数等指标；结果显示模型虽有相近预测精度，但在校准、叙事稳定性和市场一致性上差异显著。

**⚠️ 局限性**

局限在于仅针对预测市场场景，需昂贵的实时数据与基础设施，且评价维度虽多但仍未涵盖全部人类推理细节，易受市场波动与数据质量影响。

---

## 657. MN-TSG:Continuous Time Series Generation with Irregular Observations

**arXiv ID:** 2601.13534 | [PDF](https://arxiv.org/pdf/2601.13534v1)

**作者:** Xu Zhang `[一作]` (Microsoft Research), Jiang Bian `[通讯]` (Microsoft Research)

**通讯引用:** 13006 | [OpenAlex ID](https://openalex.org/A5030951014)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `afceb026-1760-41ae-8d86-010831a37d97` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `109c2b71-d051-425c-831f-0c544c24280d`

**🎯 论文内容**

提出了一种结合混合专家（MoE）神经受控微分方程（NCDE）的连续时间序列生成框架MN‑TSG，解决了不规则采样与连续高分辨率生成的难题。

**💡 创新点**

创新点包括：①基于Mixture‑of‑Experts的动态函数提升NCDE对多样时序动态的建模；②通过预训练的通道自编码器实现NCDE的解耦训练，聚焦动态学习；③联合学习专家权重与时序样本的扩散模型，实现一次性生成样本及其对应的专家配置，从而支持精细连续生成。

**🔧 技术方法**

采用了混合专家NCDE、预训练的通道自编码器、扩散模型、以及自然三次样条插值等技术。

**📊 数据集**

在十个公开/合成数据集上验证，包括Sines、Stocks、Energy、MuJoCo、ECG200、ECG5K、ECGFD、TLECG、以及合成的多波形与多项式系数数据。

**📈 对比分析**

与多种基线（KO‑VAE、GT‑GAN、TimeGAN‑NCDE、TimeVAE‑NCDE、Diffusion‑NCDE、ProFITi、HeTVAE）进行定量评估，指标包括DS、MDD、KL；在不规则采样、规则采样以及连续生成任务中，MN‑TSG consistently 超越基线，获得更低的误差与更高的分布相似度，并在连续生成中显著提升预测性能。

**⚠️ 局限性**

局限性在于假设底层动力学是连续可微的，无法处理突变或不连续变化的真实世界时序；未来可能需探索更宽容或非光滑的模型。

---

## 658. The OncoReach Stylet for Brachytherapy: Design Evaluation and Pilot Study

**arXiv ID:** 2601.13529 | [PDF](https://arxiv.org/pdf/2601.13529v1)

**作者:** Pejman Kheradmand `[一作]` (University of Louisville), Yash Chitalia `[通讯]` (University of Louisville)

**通讯引用:** 479 | [OpenAlex ID](https://openalex.org/A5001760308)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

本文设计并评估了一种手持式、肌腱驱动的可转向导丝OncoReach，针对宫颈癌的射频内照射（ISBT）进行针导向，并在自制的人体盆腔与子宫模型中完成了试点实验验证其可操作性。

**💡 创新点**

创新点包括①在15/13号针内嵌入多关节尼龙钛软管并使用可倾斜的单筋路径，显著提升弯曲顺应性；②提出二维管Cosserat模型，可准确预测自由空间下的形状；③开发单向手柄手持驱动方案，并在真实人体盆腔模型中展示从更安全的中线入路到达侧面靶点的可行性。

**🔧 技术方法**

采用肌腱驱动关节设计、球形关节、尼龙钛软管、线性丝杠+PID控制、Vicon运动捕捉、CT影像与BrachyVision治疗规划、以及二维管Cosserat模型等技术。

**📊 数据集**

数据集主要基于50例临床宫颈癌病人平均尺寸构建的3D模型；使用Humimic凝胶、3D打印的盆腔与子宫模型；实验仅由一名专业医师操作。

**📈 对比分析**

通过自由空间实验与模型预测的误差<2%验证模型准确性；试点实验中，OncoReach针尖偏转12.6–24.0 mm，明显高于传统直针3.6–7.9 mm，表明能实现更大弯曲并从更安全的入路到达靶点，显示出优异的性能。

**⚠️ 局限性**

局限性：仅单名专家试点，缺乏统计学意义；模型仅在自由空间验证，未考虑组织反作用力；phantom组织不透明，无法实时观测针尖位置；未来需扩大样本、加入实时形状感知与可视化等改进。

---

## 659. GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models

**arXiv ID:** 2601.13524 | [PDF](https://arxiv.org/pdf/2601.13524v1)

**作者:** Yang Yu `[一作]` (Huazhong University of Science and Technology), Jingdong Chen `[通讯]` (Ant Group)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了首个多层服装试穿模型 GO-MLVTON，并设计了服装遮挡学习模块和基于稳定扩散的服装变形与拟合模块，实现多层服装的真实层次和遮挡关系；

**💡 创新点**

创新点在于首次将服装遮挡关系显式建模（GOL）并结合稳定扩散生成器（GMF）实现多层试穿，同时构建了专门的 MLG 数据集和 Layered Appearance Coherence Difference (LACD) 评价指标；

**🔧 技术方法**

使用了 StableDiffusion v1.5 的 UNet、跨注意力机制、控制网络 ControlNet、VAE 编码/解码器以及自监督遮挡损失；

**📊 数据集**

使用了自制的 MLG 数据集（3538 份样本，包含内层服装、外层服装、真实穿着图和无服装图）和公开的 VITON‑HD 等基线数据集进行比较；

**📈 对比分析**

与 CAT‑DM、MV‑VTON、CATVTON 等单层试穿方法对比，GO‑MLVTON 在 FID、KID、SSIM、LPIPS 及 LACD 上均取得显著优势，证明其在多层试穿任务中具有更好的视觉质量和层次一致性；

**⚠️ 局限性**

局限性包括仅处理两层服装的情况，尚未验证对更多层级或极端遮挡场景的泛化能力；

---

## 660. Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement

**arXiv ID:** 2601.13481 | [PDF](https://arxiv.org/pdf/2601.13481v1)

**作者:** Jian Zhang `[一作]` (Xi'an Jiaotong University), Jun Liu `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 73099 | [OpenAlex ID](https://openalex.org/A5100361698)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了APOLO框架，针对精神健康文本情绪诊断自动优化提示。

**💡 创新点**

创新点在于将提示优化建模为POMDP并引入Planner–Teacher–Critic–Student–Target多代理协作，兼顾情绪共病与探索效率。

**🔧 技术方法**

采用大语言模型、POMDP规划、Socratic式对话、风险与成本约束的迭代优化技术。

**📊 数据集**

使用六个公开情绪诊断数据集：DailyDialog、EmoryNLP、PELD、RECCON、EmotionX、DepressionEmo。

**📈 对比分析**

在所有基线（原始、CoT、APE、ProTeGi、OPRO、PE2）上均取得最高宏/微F1、EMR、PMA，平均提升3–5%，且在token消耗上更高效。

**⚠️ 局限性**

局限在于对LLM的高依赖、需手工设计代理提示、对极端罕见情绪的召回仍有限。

---

## 661. Elias-type Bounds for Codes in the Symmetric Limited-Magnitude Error Channel

**arXiv ID:** 2601.13477 | [PDF](https://arxiv.org/pdf/2601.13477v1)

**作者:** Zhihao Guan `[一作]` (Xi'an Jiaotong University), Hengjia Wei `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 361 | [OpenAlex ID](https://openalex.org/A5061347472)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

研究整数格 ℤⁿ 中对称有限幅度误差通道的完美误差校正码，并给出新的必要条件，阐明 e 与 n、s 的关系。

**💡 创新点**

创新点在于将 Elias 界的几何思路推广到对称有限幅度误差距离 d_s，得到针对任意非晶格完美码的全局上界，同时对非完美码给出包装密度上界。

**🔧 技术方法**

主要技术包括几何平均、球面包装、Elias‑式推导以及针对 s 取值不同的二次规划分析。

**📊 数据集**

论文为理论研究，不使用任何实验数据集。

**📈 对比分析**

通过与已有的完美码与包装界限对比，证明对 e 的约束更为严格，但未进行实验性能评估。

**⚠️ 局限性**

仅给出必要条件，未证明存在性；缺乏具体构造方法，对 s ≥ 3 的严格性仍需进一步验证。

---

## 662. Graph Neural Networks are Heuristics

**arXiv ID:** 2601.13465 | [PDF](https://arxiv.org/pdf/2601.13465v1)

**作者:** Yimeng Min `[一作]` (Cornell University), Carla P. Gomes `[通讯]` (Cornell University)

**通讯引用:** 11862 | [OpenAlex ID](https://openalex.org/A5069030030)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了一种无监督、非自回归的图神经网络启发式方法，在单次前向传播中直接生成旅行商问题（TSP）的 Hamiltonian 循环解，无需搜索或监督。

**💡 创新点**

创新点包括：①将 Hamiltonian 循环约束嵌入学习目标，构造可微的软排列逼近；②设计了全等变的坐标特征提取器，保证对平移、旋转、节点置换的无关性；③在单一训练轨迹上通过 Dropout 与 Snapshot Ensemble 产生多样化解，提升鲁棒性与解质量。

**🔧 技术方法**

主要技术包括：图神经网络（SCT‑GNN）结合 Gumbel‑Sinkhorn 软排列、Hungarian 算法解码、MC‑Dropout 随机前向、Snapshot Ensemble、等变坐标特征提取（基于傅里叶谐波）。

**📊 数据集**

使用均匀采样的欧氏 TSP 数据集：TSP100、TSP200、TSP500（分别 1.5M、2.0M、5.0M 训练实例）。

**📈 对比分析**

与 Greedy Nearest‑Neighbor、Christofides、2‑opt 等经典启发式以及基于 RL/监督学习的 GNN 对比。实验显示，该方法在不使用搜索的前提下，将 Greedy 的最优性缺口缩小至原来的一半以上；在 TSP100/TSP200 上达到 5.5%–9.2% 的缺口，TSP500 上与 Christofides 差距可达 12.5%，同时推理时间仅为毫秒级 GPU 前向。

**⚠️ 局限性**

局限性：仍未能达到全局最优；对极大规模实例的最优性缺口未显著下降；模型在某些随机实例上偶尔出现较差解；对非欧氏或更复杂约束的 TSP 迁移性待验证。

---

## 663. PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving

**arXiv ID:** 2601.13453 | [PDF](https://arxiv.org/pdf/2601.13453v1)

**作者:** Aditya Thole `[一作]` (Birla Institute of Technology and Science Pilani), Dhruv Kumar `[通讯]` (Birla Institute of Technology and Science Pilani)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

开发了PhysicsSolutionAgent框架，利用LLM和Manim动画生成面向物理教学的多模态解释视频；

**💡 创新点**

创新点包括引入检索增强生成（RAG）以查询Manim文档、构建多轮错误纠正循环、实施截图驱动的视觉反馈循环以及构建15维度自动化评估体系，兼顾概念与数值问题；

**🔧 技术方法**

使用的技术包括GPT‑5 mini驱动的Planner‑Coder架构、Manim动画引擎、检索增强生成（RAG）与向量数据库、Vision‑Language Model（VLM）进行视觉评估、错误捕获与重试机制；

**📊 数据集**

使用的评估数据集为32条物理问题（按难度分为Easy/Medium/Hard及Theorem类），并参考TheoremExplainBench等标准基准；

**📈 对比分析**

通过全自动LLM评判器对15项指标加权，得到平均整体分3.8/5，Version‑1与Version‑2比较显示视觉质量提升，且与TheoremExplainAgent等基线保持一致的高质量表现；

**⚠️ 局限性**

局限性包括：仅单轮视觉循环且仅使用静态截图，无法捕捉动画时序与音视频同步；文本与视觉内容存在冗余与重复；RAG仅覆盖Manim文档，缺乏物理知识库导致潜在幻觉；生成耗时较长，难以实现实时即时答疑。

---

## 664. Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification

**arXiv ID:** 2601.13589 | [PDF](https://arxiv.org/pdf/2601.13589v1)

**作者:** HyeYoung Lee `[一作]` `[通讯]` (Korean University), HyeYoung Lee (Korean University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种多智能体架构，将音频情绪识别与实时响应内容生成结合，确保生成内容安全、年龄适宜并可在设备上实时运行。

**💡 创新点**

创新点在于将情绪识别、响应策略决策、内容参数生成和安全验证拆分为四个专门智能体，并引入规则循环安全验证机制；同时提供可解释的策略映射与可插拔模块化设计。

**🔧 技术方法**

核心技术包括轻量化CNN情绪分类、决策树情绪‑响应映射、两层前馈网络生成多模态内容参数、规则基安全验证、INT8量化与结构化剪枝以实现边缘部署。

**📊 数据集**

使用公开情绪语音数据集IEMOCAP、RAVDESS、AIHub情绪语料库以及合成情绪TTS数据进行训练与评估。

**📈 对比分析**

与单一端到端模型对比，实验显示情绪识别准确率73.2%，响应模式一致性89.4%，安全合规率100%，且端到端延迟低于100 ms，可在Raspberry Pi 4等低功耗设备上实现实时推理。

**⚠️ 局限性**

局限性包括缺乏跨句子上下文与个性化适应，策略决策固定，未整合视觉或文本多模态信息，且文化适应性仍待研究。

---

## 665. TREX: Tokenizer Regression for Optimal Data Mixture

**arXiv ID:** 2601.13588 | [PDF](https://arxiv.org/pdf/2601.13588v1)

**作者:** Inho Won `[一作]` (KAIST), KyungTae Lim `[通讯]` (KAIST)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

该工作提出了Tokenizer Regression for Optimal Data Mixture (TReX)，通过训练小规模代理tokenizer并回归预测压缩性能，快速寻找多语言tokenizer的最佳数据混合。

**💡 创新点**

创新点在于将回归模型用于tokenizer压缩预测，利用Rank Invariance实现规模不变性，避免昂贵的全量搜索，并显著提升压缩率。

**🔧 技术方法**

主要技术包括Dirichlet采样数据混合、LightGBM回归、代理tokenizer训练与压缩指标NSL评估。

**📊 数据集**

实验使用19种语言的FineWeb2-HQ和FLORES数据集进行训练与测试。

**📈 对比分析**

与均匀混合、语言族聚类、GPT-4o和LLaMA3基准相比，TReX预测的最佳混合在ID/OOD压缩率提升约10–12%，并在LLM训练中将训练时间缩短1,000小时以上。

**⚠️ 局限性**

局限性包括仅优化压缩率而不评估下游任务性能、对极大规模或不同语言组合的Rank Invariance验证不足，以及仅覆盖19种语言，未覆盖极低资源或高度屈折形态语言。

---

## 666. A Kubernetes custom scheduler based on reinforcement learning for compute-intensive pods

**arXiv ID:** 2601.13579 | [PDF](https://arxiv.org/pdf/2601.13579v1)

**作者:** Hanlin Zhou `[一作]` (Universiti Sains Malaysia), Jingfei Ni `[通讯]`

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出基于深度强化学习的自定义 Kubernetes 调度器 SDQN 与 SDQN‑n，并在计算密集型工作负载下与默认调度器、LSTM、Transformer 进行对比。

**💡 创新点**

创新点在于将 DQN 与节点状态奖励函数结合，实现可调节的集中调度策略 SDQN‑n，显著降低 CPU 利用率并促进绿色数据中心。

**🔧 技术方法**

采用 Deep Q‑Network（DQN）为核心的强化学习模型，并对比 LSTM 与 Transformer 结构。

**📊 数据集**

使用无操作 CPU‑bound 容器模拟的 50 个计算密集型 Pod 作为实验数据。

**📈 对比分析**

通过多次实验测量平均每节点 CPU 利用率，结果显示 SDQN‑n 使平均 CPU 利用率下降 20% 以上，优于默认调度器及 LSTM/Transformer。

**⚠️ 局限性**

局限在于实验仅在 4 节点小规模集群与单一工作负载类型上验证，缺乏对大规模集群、多样化任务及实时调度的评估。

---

## 667. Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework

**arXiv ID:** 2601.13564 | [PDF](https://arxiv.org/pdf/2601.13564v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 668. FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning

**arXiv ID:** 2601.13578 | [PDF](https://arxiv.org/pdf/2601.13578v1)

**作者:** Qian Feng `[一作]` (Zhejiang University), Hui Qian `[通讯]` (Zhejiang University)

**通讯引用:** 20364 | [OpenAlex ID](https://openalex.org/A5101585978)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种基于特征与梯度正交约束的增量忘记框架FG-OrIU，能够在视觉预训练模型上实现不可逆的深度类级删除，既彻底消除被忘记类别的信息，又保持剩余类别的性能。

**💡 创新点**

创新点在于：①将特征空间通过SVD分解为遗忘与保留子空间；②在前向阶段对遗忘类特征做正交投影，对保留类特征做对齐；③在反向阶段对梯度进行双重正交投影，既强化遗忘类更新方向，又阻止对保留类的污染；④设计动态子空间自适应机制，保证多轮删除任务中遗忘子空间扩张、保留子空间收缩，实现稳定的记忆与忘记平衡。

**🔧 技术方法**

主要技术包括：Singular Value Decomposition（SVD）用于子空间分解；LoRA（Low‑Rank Adaptation）模块实现轻量级参数更新；正交投影约束（特征正交投影 fop‑f/fop‑r 与梯度正交投影 gop‑f/gop‑r）；动态子空间适配；Deep Image Prior（DIP）用于评估残余信息。

**📊 数据集**

实验数据集：ImageNet‑100、CUB‑200、OmniBenchmark（分类任务）以及 CASIA‑Face100、MS‑Celeb‑100（人脸识别任务），均基于ViT‑B/16 或 Face‑Transformer 预训练模型。

**📈 对比分析**

与多种基线比较：包括传统连续学习方法（L2、EWC、MAS、LwF、DER、FDR）以及现有机器忘记方法（BAD‑T、LIRF、SCRUB、GS‑LoRA 等）以及完整重训。FG‑OrIU 在所有任务中均表现出更低的遗忘类准确率（Acc_f ≈ 0）、更高的保留类准确率（Acc_r 领先 5–10%）以及更优的 H‑Mean，尤其在多轮连续忘记（4 轮）时保持忘记效果不退化，证明了其深度忘记与稳健的记忆保持能力。

**⚠️ 局限性**

局限性：目前仅针对类级增量忘记，尚未验证对样本级忘记的适用性；方法依赖于子空间分解与正交投影，计算开销在大规模模型上可能显著；对不同网络结构（如CNN、Transformer以外）适用性尚待进一步验证。

---

## 669. Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews

**arXiv ID:** 2601.13575 | [PDF](https://arxiv.org/pdf/2601.13575v1)

**作者:** Thanh-Lam T. Nguyen `[一作]` (VNU University of Engineering and Technology), Hoang-Quynh Le `[通讯]` (VNU University of Engineering and Technology)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建并公开了一个新的同一用户不同产品评论对的隐式比较意见挖掘数据集，并在此数据集上评估了传统机器学习和多种基于语言模型的基线模型；

**💡 创新点**

创新点在于：①首次针对同一用户的隐式比较意见进行系统标注，消除跨用户写作风格噪声；②提出双层标注方案（句子级别的aspect提及与评论级别的偏好判断）；③提供大规模（4,150对）数据集作为隐式比较基准；

**🔧 技术方法**

技术方法包括：传统机器学习两阶段流程（fastText词向量 + SVM/XGBoost进行aspect分类和比较分类），以及端到端的Transformer encoder‑decoder（BART、T5）和instruction‑tuned模型（FLAN‑T5、Llama‑3.2、Qwen3‑4B、ChatGPT、Gemini）进行结构化输出；

**📊 数据集**

使用的主要数据集是从BeerAdvocate酒评库筛选得到的Same User – Different Object (SUDO) 数据集，共4,150对评论（15,191句），涵盖appearance、aroma、palate、taste四个感官维度；

**📈 对比分析**

在宏/微 F1 评价下，传统两阶段模型整体表现低于60%；微 F1 约为50%，宏 F1 约为45%；相比之下，Fine‑tuned T5 与 BART 在宏/微 F1 上分别达到约56%/58%和约51%/55%，为最优；instruction‑tuned模型表现普遍逊色；整体性能仍不高，说明任务难度大；

**⚠️ 局限性**

限制包括：①数据域单一（仅酒类），难以推广到其他商品；②对aspect间互依性的建模不足；③两阶段管线易产生误差累积；④数据规模有限，未涉及多用户对多产品的跨域比较；

---

## 670. DRGW: Learning Disentangled Representations for Robust Graph Watermarking

**arXiv ID:** 2601.13569 | [PDF](https://arxiv.org/pdf/2601.13569v1)

**作者:** Jiasen Li `[一作]` (Institute of Information Engineering, Chinese Academy of Sciences), Weiping Wang `[通讯]` (Institute of Information Engineering, Chinese Academy of Sciences)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `a2602d71-93ab-4bad-974b-672788df8193` `3f18e8e3-0266-457c-8567-9039b6d2394d` `9ce7179e-700c-4310-ac2b-91df50ded46e` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了一种基于解耦表示学习的图数据数字水印框架（DRGW），通过在图中分离结构与水印信息来实现鲁棒、透明且可检测的水印嵌入与提取。

**💡 创新点**

创新点包括：1）对图进行结构与水印子空间的互信息最小化解耦；2）设计图感知可逆网络（Graph‑aware INN）提供无信息损失的隐写通道；3）构建结构感知编辑器，将连续水印映射为鲁棒的离散图编辑方案，解决离散化导致的信号衰减问题。

**🔧 技术方法**

采用图同构网络（GIN）作为编码器，GCN 辅助的可逆耦合层实现 Graph‑aware INN，互信息正则化、对比学习损失和正交性损失实现解耦；利用最大似然和匹配滤波实现水印提取，整体实现基于 PyTorch/PyG。

**📊 数据集**

在 18 个真实图数据集上进行实验，涵盖六大类：社交网络、学术网络、知识图谱、电商推荐、Web 图谱以及道路网络，数据来源于公开图数据集。

**📈 对比分析**

与结构空间方法 Towards、潜在空间方法 KGMark 以及 Naive 基线相比，DRGW 在所有数据集上均取得近乎完美的可检测性（AUC≥0.998）、在节点/边删改、同构与自适应攻击下保持高 AUC（≥0.96），同时在结构与功能保真度指标上比对手下降幅度降低约 4‑10 倍。

**⚠️ 局限性**

局限性包括：1）与简单结构空间方法相比计算开销更高；2）对图中丰富的类型或语义信息未做专门的解耦，可能限制在异构图上的性能；3）水印容量受载体子空间和编辑预算限制，未实现显式容量评估。

---

## 671. ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits

**arXiv ID:** 2601.13563 | [PDF](https://arxiv.org/pdf/2601.13563v1)

**作者:** Aryan Karmore `[一作]` `[通讯]` (Indian Institute of Information Technology), Aryan Karmore (Indian Institute of Information Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `64443552-63e0-44b5-906f-d90fe95c5a1b` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 ButterflyMoE，一种将 MoE 专家参数化为共享三值量子化基底的蝶形矩阵旋转，从而实现子线性内存缩放；

**💡 创新点**

核心创新是把专家视为共享基底的轨道变换，利用学习的蝶形旋转实现 O(d^2+N·d·log d) 的内存复杂度，并获得 150 倍压缩；

**🔧 技术方法**

采用蝶形矩阵、三值量化+STE、端到端门控网络以及针对激活外点的学习旋转；

**📊 数据集**

在多域语言建模基准（如 WikiText‑103、ArXiv、GLUE 等）以及算术、排序、复制、反转等控制任务上进行评估；

**📈 对比分析**

与标准 MoE、QMoE、MoQE、PuzzleMoE 等方法对比，实验显示 256 个专家时压缩率达 150 倍，保持与密集模型相同的准确率，Edge 设备可容纳 64 专家仅需 1.9 MB；

**⚠️ 局限性**

局限在于推理速度比密集模型慢（高达 48.9 倍）、实验规模受限于硬件、对大规模参数化的可解释性与收敛性仍待进一步研究。

---

## 672. Reasoning is a Modality

**arXiv ID:** 2601.13562 | [PDF](https://arxiv.org/pdf/2601.13562v1)

**作者:** Zhiguang Liu `[一作]` (University of Missouri), Yi Shang `[通讯]` (University of Missouri)

**通讯引用:** 9008 | [OpenAlex ID](https://openalex.org/A5057883374)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种将全局控制器与局部工作空间分离的Transformer块，专门用于解决ARC抽象推理问题。

**💡 创新点**

核心创新是将推理视作一种独立的“模态”，通过在Transformer中显式区分少量全局控制器Token和大量局部工作空间Token，形成控制器驱动的规则执行机制。

**🔧 技术方法**

采用角色分离的Transformer结构（含密集注意力+结构化注意力）、轻量级递归封装、VARC视觉化编码、以及多视角投票与增强策略。

**📊 数据集**

在ARC-1与ARC-2数据集上进行评估，使用VARC协议的离线预训练与测试时训练（TTT）。

**📈 对比分析**

与VARC‑ViT、HRM、TRM等基线比较，单模型在ARC‑1上达到58.8%准确率，在ARC‑2上提升至11.0%；与UNet集成后在ARC‑1上达到62.6%，超过平均人类60.2%以及VARC‑ViT 60.4%。

**⚠️ 局限性**

仍受限于任务自适应成本、模型规模对极端复杂任务的推广能力有限，以及对解释生成的直接可解释性未充分评估。

---

## 673. Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis

**arXiv ID:** 2601.13558 | [PDF](https://arxiv.org/pdf/2601.13558v1)

**作者:** Mehrab Beikzadeh `[一作]` (University of California), Ian W Holloway `[通讯]` (University of California)

**通讯引用:** 3865 | [OpenAlex ID](https://openalex.org/A5008629761)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

使用 MSM（男性同性爱者）在社交媒体和约会应用上公开的文本数据，训练机器学习模型预测其危险行为（如每月酗酒、AUDIT‑C 高分、伴侣数量>5）和保护行为（PrEP 使用）。

**💡 创新点**

首次将 ChatGPT embedding 作为特征引入此类预测，并通过 Fisher 分数进行特征选择，显著提升了模型在罕见事件上的预测性能。

**🔧 技术方法**

采用的技术包括：ChatGPT embedding、BERT embedding、LIWC 词典分析、预定义风险词频特征、SVM（线性核）、逻辑回归和梯度提升分类器；同时使用 Fisher 分数实现特征子集优化。

**📊 数据集**

数据集来自 224 名 iOS 用户（筛选后 160 名），收集了 Grindr、Tinder、Instagram、Snapchat、Twitter、Reddit 等平台的文本信息，标注来源于自我报告的问卷（AUDIT‑C、伴侣数量、PrEP 使用等）。

**📈 对比分析**

与传统单一特征方法（naïve）相比，改进方法在 F1（少数类）上取得：Binge 月度 0.78、>5 伴侣 0.78、AUDIT‑C 高 0.64、PrEP 0.63；主要得益于 ChatGPT embedding 与 BERT/LIWC 的组合以及特征选择。

**⚠️ 局限性**

主要限制包括：仅能获取文本数据（无图像、搜索历史），样本量有限且部分行为极为罕见，导致模型在这些类别上仍难以训练；且依赖 iOS 平台，缺乏跨平台可重复性。

---

## 674. Reflections over the Sea: Reconfigurable Intelligent Surface for Maritime Self-Powered Communications

**arXiv ID:** 2601.13618 | [PDF](https://arxiv.org/pdf/2601.13618v1)

**作者:** Qianqian Zhang `[一作]` (Rowan University), Jia Mi `[通讯]` (Stevens Institute of Technology)

**通讯引用:** 877 | [OpenAlex ID](https://openalex.org/A5006857005)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

通过在离岸风电机塔等基础设施上部署可重构智能表面（RIS），并结合波能自供电与海面波动感知的信道模型，实现了海事物联网通信的动态优化与覆盖增强。

**💡 创新点**

① 首次将RIS引入海事通信场景；② 设计波动感知的两/三射线信道模型；③ 开发基于波能的自供电系统；④ 将实时CSI测量与RIS相位优化结合，形成闭环自适应方案。

**🔧 技术方法**

可重构智能表面（RIS）反射技术；波能捕捉与变换（PTO、电子转换、捕获宽度比）；近海两射线/三射线信道模型；块式衰落信道估计与LS/SDP优化；使用CVX求解半正定规划。

**📊 数据集**

使用仿真数据：5.8 GHz、5 MHz带宽、6 m风电机塔、360个RIS单元、8个接收天线、4个浮标、不同海况（海浪状态0–7）以及波能参数（PTO 50%、转换效率90%、捕获宽度8.2%）进行评估。

**📈 对比分析**

与未使用RIS、不同接收天线高度、RIS单元数、最大发射功率等对照，采用信道容量/总数据速率作为指标；仿真表明在海浪状态≥4时系统速率提升>20%，当接收天线高度不足或海浪状态≥6时RIS贡献尤为显著。

**⚠️ 局限性**

① 需要大量子帧进行信道估计，导致有效上行时间减少；② 受限于波能在平静海况下不足，无法支持高功率传输；③ 对CSI误差、同步误差及多用户干扰的鲁棒性未进行深入分析；④ 仅在仿真层面验证，缺乏实际部署与实测数据。

---

## 675. ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch

**arXiv ID:** 2601.13606 | [PDF](https://arxiv.org/pdf/2601.13606v1)

**作者:** Zheng Liu `[一作]` (Peking University), Lijun Wu `[通讯]` (Shanghai Artificial Intelligence Laboratory)

**通讯引用:** 3243 | [OpenAlex ID](https://openalex.org/A5102750692)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `67630363-6be0-4f51-ab05-7198250671a5` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出ChartVerse框架，利用代码驱动生成高复杂度、准确可靠的图表推理数据，并以此训练VLM模型

**💡 创新点**

创新点包括：① Rollout Posterior Entropy（RPE）度量图表难度；② 复杂度感知图表编码器实现从零生成多样化高难度图表；③ 真值锚定逆向QA合成，确保答案准确并通过失败率筛选难度样本；④ 通过CoT蒸馏与RL微调实现学生模型突破教师模型上限

**🔧 技术方法**

核心技术：VLM生成可执行代码、CLIP特征提取与谱熵计算、温度采样、CoT推理与蒸馏、基于RL的样本强化学习、代码执行环境验证

**📊 数据集**

构建ChartVerse-SFT-600K与ChartVerse-RL-40K两大数据集，来源于现有ChartQA、PlotQA、FigureQA等数据集中的高RPE样本，结合代码执行得到真值

**📈 对比分析**

与ChartQA、CharXiv、ChartMuseum、ChartX、ChartBench、EvoChart等6个图表推理基准对比；ChartVerse-8B在所有基准上平均得分64.1，显著优于同规模教师模型Qwen3‑VL‑30B‑A3B‑Thinking（62.9）并逼近更大模型Qwen3‑VL‑32B‑Thinking（67.0）

**⚠️ 局限性**

局限性：RPE和代码生成依赖现有VLM的推理能力，可能产生视觉细节偏差；逆向QA合成需多轮LLM推理，计算成本高；RL阶段样本规模受限，难以覆盖更广泛的极端长尾图表模式

---

## 676. SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System

**arXiv ID:** 2601.13581 | [PDF](https://arxiv.org/pdf/2601.13581v1)

**作者:** Heedou Kim `[一作]` (Korea University), Jaewoo Kang `[通讯]` (Korea University)

**通讯引用:** 15135 | [OpenAlex ID](https://openalex.org/A5076917278)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 ScriptMind 框架，结合 LLM 进行犯罪脚本推理和实时诈骗检测，并通过认知模拟评估其对用户怀疑度的提升效果。

**💡 创新点**

创新点在于将 LLM 的推理能力与用户认知反馈耦合，首次实现基于犯罪脚本的多轮诈骗预测与动态警示，显著提升用户的怀疑与决策能力。

**🔧 技术方法**

采用开放源代码的 11B 小型 LLM，使用 QLoRA 低秩适配进行微调，并构建了犯罪脚本推理任务（CSIT）和脚本感知推理数据集（CSID）。

**📊 数据集**

使用 571 个韩国电话诈骗案例，提取 22,712 条脚本推理实例（含 11,356 条正类对话）构成 CSID 数据集。

**📈 对比分析**

与 GPT‑4o 等商业零样本模型对比，微调后模型在检测准确率上提升约 13%，误报率降低至 0.02，整体性能显著优于基线。

**⚠️ 局限性**

局限性包括仅针对电话诈骗、缺乏多模态攻击场景、情绪测量受限以及模型仅在受限环境中验证，未来需扩展到多国多渠道数据。

---

## 677. Behavior Knowledge Merge in Reinforced Agentic Models

**arXiv ID:** 2601.13572 | [PDF](https://arxiv.org/pdf/2601.13572v1)

**作者:** Xiangchi Yuan `[一作]` (Georgia Institute of Technology), Wenke Lee `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 27101 | [OpenAlex ID](https://openalex.org/A5047140382)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了 Reinforced Agent Merging (RAM) 方法，用来融合通过强化学习训练的多个专用 agent 模型，解决传统基于 SFT 的全局平均合并导致的任务特定能力稀释问题。

**💡 创新点**

创新点在于识别 RL 任务向量的稀疏异质分布，主动将共享参数与唯一参数分离，采用分布感知的重缩放因子保持唯一参数的完整幅值，从而避免信号稀释并实现任务特定能力的保留与增强。

**🔧 技术方法**

主要技术包括：① 对 RL 任务向量进行稀疏性与重叠统计分析；② 计算基于重叠比率的重缩放因子 λ_t；③ 对共享参数做平均，对唯一参数做保留并按 λ_t 进行放大；④ 采用 PPO/GRPO 等 RL 算法生成原始 agent 模型。

**📊 数据集**

使用了多域评测数据集：LiveBench、LiveCodeBench（编程）、Berkeley Function Call Leaderboard（工具使用）、RULER HotpotQA/SQuAD（长上下文记忆）以及 Llama3.2-3B 基础模型训练出的 ZeroSearch、Math Reasoning、ToolRL 等 RL agent；评测涵盖多种长度（7k‑64k）和并行/非并行场景。

**📈 对比分析**

通过与原始专用 agent、Task Arithmetic、Fisher、TIES、DARE 等基线进行对比，RAM+ 在 12 个任务中实现 9 个 SOTA，平均性能提升约 1.7‑2.5 分，甚至在多数域上超过原专用 agent，显示出显著的性能优势。

**⚠️ 局限性**

局限性包括：① 仅在 3B/7B 规模模型上验证，未知是否适用于 70B+ 大模型；② 重缩放因子基于参数重要性等值假设，缺乏细粒度曲率信息；③ 对参数碰撞多样化（大规模 agent 集合）时可能需要更复杂的冲突解决策略；④ 在不同数据或模态的任务中可能需要额外的超参数调优。

---

## 678. Self-Improvement as Coherence Optimization: A Theoretical Account

**arXiv ID:** 2601.13566 | [PDF](https://arxiv.org/pdf/2601.13566v1)

**作者:** Tianyi Qiu `[一作]` (Peking University University of Oxford), Shi Feng `[通讯]` (George Washington University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

该论文提出一致性优化框架，将无监督自我改进方法（如辩论、迭代引导、内部一致性最大化等）统一为对上下文行为的可压缩性与可预测性最大化，并给出了可扩展的 Gibbs 采样算法。

**💡 创新点**

创新点在于把这些方法视为描述长度正则化的特殊实现，证明在使用预训练模型作为先验时一致性优化是半监督学习的最优正则化方案，并提供理论与实验验证。

**🔧 技术方法**

主要技术包括信息论与描述长度的理论推导、学习系统的归纳表示、Gibbs 采样与软化一致性分布、以及多种先验策略（BASE、CHAT、THINK）。

**📊 数据集**

实验使用 GSM8K、HARDMath（包含正反面答案）以及自定义开放式科研问题集合来评估一致性与真确性。

**📈 对比分析**

通过与 LLM‑as‑a‑Judge 对比，一致性指标在检测欺骗答案上显著优于传统评估；在 GSM8K 上，Gibbs 采样在不同 γ 设置下提升训练准确率，最高峰值约为 45%（相当于基线 44.4%）。

**⚠️ 局限性**

限制包括实验规模有限、缺乏与其他正则化方法的直接对比、以及在大规模模型与长上下文环境下的可扩展性和过度优化风险。

---

## 679. AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent

**arXiv ID:** 2601.13559 | [PDF](https://arxiv.org/pdf/2601.13559v1)

**作者:** Sun Hui `[一作]`, Wentong Cai `[通讯]` (Nanyang Technology University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出了AgentGC，一种基于多智能体和大语言模型的演化式基因组数据无损压缩系统。

**💡 创新点**

创新点在于将LLM驱动的少量样本提示学习与自适应压缩框架AMKLCF相结合，实现了压缩模型、数据集和硬件的协同优化；并设计了压缩优先、吞吐量优先和均衡三种压缩模式。

**🔧 技术方法**

主要技术包括（s,k)-mer编码、BiLSTM静态模型、Transformer动态模型、模型选择与混合、GPU加速的批量推理、以及LLM（GPT‑5）进行参数调优的多智能体架构。

**📊 数据集**

实验使用了9个真实基因组数据集（覆盖多种物种与规模），并构建了112个高质量向量-文本对的初始化向量数据库。

**📈 对比分析**

与14个基线方法（包括传统压缩器和多种AI压缩器）对比，AgentGC在压缩比上平均提升约16.5%，吞吐量提升4.7–9.2倍，压缩鲁棒性提高超过94%，并在CPU内存和GPU内存上分别节省约85%和46%。

**⚠️ 局限性**

限制在于深度学习模型的高计算和存储需求，导致在极大规模或通用场景下的可扩展性受限，未来计划采用CPU‑GPU异构加速、LLM微调和多模态扩展以缓解此问题。

---

## 680. A General One-Shot Multimodal Active Perception Framework for Robotic Manipulation: Learning to Predict Optimal Viewpoint

**arXiv ID:** 2601.13639 | [PDF](https://arxiv.org/pdf/2601.13639v1)

**作者:** Deyun Qin `[一作]` (Nankai University), Yongchun Fang `[通讯]` (Nankai University)

**通讯引用:** 13031 | [OpenAlex ID](https://openalex.org/A5058644546)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种一阶多模态主动感知框架（MVPNet），能在一次视角调整中直接预测机器人抓取任务的最优观察姿态。

**💡 创新点**

①将视角质量评估与框架解耦，可通过自定义评价函数满足不同任务；②使用跨注意力的Transformer实现视觉（遮罩图）与三维点云的对齐与融合；③通过大规模域随机化合成数据实现无人工标注的高效数据集构建；④实现了从仿真到真实世界的无缝迁移。

**🔧 技术方法**

深度相机+语义分割（Grounded-SAM2）、点云编码器（PointNet++ + PointNeXt）、ResNet-18、Transformer交叉注意力、MLP回归、AdamW优化器、StepLR学习率调度。

**📊 数据集**

基于Isaac Sim的合成数据集（约17k样本），包含掩码图、点云和相机位姿调整标签；真实环境使用Intel RealSense D435和Franka Research 3机器人进行验证。

**📈 对比分析**

在仿真中与四种抓取模型（Economic Grasp、GraspNet、TRG、GIGA）对比，所有模型在优化视角后抓取成功率均提升（平均提升约10‑15%），在真实环境中抓取成功率从25.5%提升至47.6%，几乎翻倍。

**⚠️ 局限性**

①框架目前仅在视角受限的抓取任务上验证，缺乏对更复杂动态任务的通用性证明；②依赖于仿真生成的数据，尽管实现了 sim‑to‑real 迁移，但仍可能在极端光照或遮挡条件下表现不足；③对计算资源有一定要求，单步预测仍需较高显存和GPU计算。

---

## 681. Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning

**arXiv ID:** 2601.13632 | [PDF](https://arxiv.org/pdf/2601.13632v1)

**作者:** Zhiming Xue `[一作]` (Northeastern University), Zihan Yu `[通讯]` (Northeastern University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了风险感知动态路由框架RADR，通过将基于ST‑GNN的拥堵风险预测与动态边权优化相结合，实现了对物流网络的实时、鲁棒路径规划。

**💡 创新点**

创新点在于将K‑Means聚类构建物流图、GCN+GRU混合ST‑GNN用于空间时间风险预测，以及将预测风险直接映射为动态边权以实现风险感知的路由决策。

**🔧 技术方法**

采用了K‑Means聚类、图卷积网络(GCN)、门控循环单元(GRU)、Dijkstra算法和风险加权动态边权机制等技术。

**📊 数据集**

使用了2024年Smart Logistics数据集，该数据集包含真实IoT传感器的GPS轨迹、交通指标及延迟标签。

**📈 对比分析**

与传统静态Dijkstra、GRU‑only、GCN‑only等基准对比，RADR在高拥堵场景下将风险得分降低19.3%而距离仅增加2.1%，表现出显著的鲁棒性和效率提升。

**⚠️ 局限性**

局限在于仅考虑单路径规划、缺乏对多车队协同与文本语义信息的利用，且模型依赖于聚类参数与风险阈值的手工调优。

---

## 682. Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models

**arXiv ID:** 2601.13630 | [PDF](https://arxiv.org/pdf/2601.13630v1)

**作者:** Zhaopeng Zhang `[一作]` (University of Science and Technology of China), Hui Jin `[通讯]` (Lenovo Research)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种训练无关的多权限访问控制框架AAAC，通过在LLM中对中间激活进行锚点驱动的向量转移实现多级权限约束，防止高权限信息泄露；

**💡 创新点**

创新点在于发现不同权限条件下的中间激活形成可分离的几何簇，利用此结构构建权限锚点并在推理阶段通过向量驱动实现无模型微调的权限控制；

**🔧 技术方法**

使用中间层激活空间的几何分析、线性探针、Silhouette系数评估层信息量、向量驱动（steering）与阈值控制的风险评估；

**📊 数据集**

使用自构造的MultiPER‑Enterprise企业部门级权限问答数据集（约11k条，涵盖HR、Finance、Legal、Sales、R&D五类权限）；

**📈 对比分析**

与Prompt‑Only与Prompt‑Policy两种基线对比，AAAC在三大LLM（Llama3‑8B、Qwen3‑8B、Gemma‑7B‑it）上实现权限违规率下降至0.5–0.9%、攻击成功率下降至≈0.09，且推理延迟仅提升10–25%；

**⚠️ 局限性**

局限包括需要带标签样本构建锚点、单中心锚点可能无法覆盖多模态权限空间、仅针对单轮问答，且对复杂多轮交互与权限交叉情况处理不足。

---

## 683. CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models

**arXiv ID:** 2601.13622 | [PDF](https://arxiv.org/pdf/2601.13622v1)

**作者:** Donghee Lee `[一作]` (University of California), Zhe Zhao `[通讯]` (University of California)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出了一个上下文感知的图像表征优先化框架 CARPE，能够在 LVLM 中动态平衡视觉特征与语言模型推理，从而提升图像分类与多模态任务的表现。

**💡 创新点**

创新点在于：①引入 vision‑integrator 将原始视觉编码与 LLM 预对齐特征融合；②设计 context‑aware ensemble，通过可学习的上下文提示动态分配视觉与语言权重；③扩展为 MoE 版本，集成多种视觉编码器以进一步提升泛化。

**🔧 技术方法**

核心技术包括多头交叉注意力、self‑attention、MLP、轻量级 context prompt 与 context encoder，以及 Mixture‑of‑Experts 路由器；训练时采用少量 ImageNet + LLaVA‑Instruct 进行微调。

**📊 数据集**

使用的数据集包括 ImageNet、Caltech‑101、Flowers‑102、Food‑101 进行分类评测；以及 ScienceQA、TextVQA、POPE、MME、MMBench、CV‑Bench、MMVP 等七个视觉‑语言基准。

**📈 对比分析**

与基线 LLaVA1.5‑7B、ImageNet‑fine‑tuned、WiSE‑FT、LEVI 以及 SPHINX‑13B 对比，CARPE 在四个分类任务上平均提升约 5–6%，在所有视觉‑语言基准上平均提升约 0.3 分，尤其在 CV‑Bench、MMVP 等视觉‑中心任务中提升 12.2% 与 2.0%；MoE 变体更是实现了最高的平均性能。

**⚠️ 局限性**

局限性主要是：①仍需额外训练成本与参数；②对极端语言复杂性任务的自适应仍有限；③在某些小样本或极端 OOD 场景下仍未达到最优。

---

## 684. Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments

**arXiv ID:** 2601.13592 | [PDF](https://arxiv.org/pdf/2601.13592v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 685. Secure Multi-Path Routing with All-or-Nothing Transform for Network-on-Chip Architectures

**arXiv ID:** 2601.13610 | [PDF](https://arxiv.org/pdf/2601.13610v1)

**作者:** Hansika Weerasena `[一作]` (University of Florida), Prabhat Mishra `[通讯]` (University of Florida)

**通讯引用:** 6149 | [OpenAlex ID](https://openalex.org/A5006818844)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

提出了一种轻量级的安全多路径路由框架，利用基于准群的All-or-Nothing Transform（AONT）将每个数据包分块后分发至多条互不重叠的路由，保证中间路由器无法单独恢复原始数据；

**💡 创新点**

创新点在于将AONT与多路径路由相结合，既消除了传统加密带来的高面积和性能开销，又实现了对被动窃听攻击的有效防护；

**🔧 技术方法**

主要技术包括准群实现的AONT、基于NoC的多路径路由设计以及对应的硬件实现与仿真；

**📊 数据集**

实验使用了典型SoC NoC网络仿真环境，采用常见工作负载和流量模型（如OpenSPARC、缓存访问等）进行评估；

**📈 对比分析**

与传统AES加密方案对比，AONT多路径路由在面积、延迟和功耗上的总开销分别降低了约7.3×、3.5×和2.8×，几乎不影响系统性能；

**⚠️ 局限性**

局限性包括需要预先规划足够的互不重叠路径、对动态流量变化和路径重选的支持有限，以及仅针对被动窃听，尚未覆盖主动攻击或重放攻击等情景。

---

## 686. When Reasoning Leaks Membership: Membership Inference Attack on Black-box Large Reasoning Models

**arXiv ID:** 2601.13607 | [PDF](https://arxiv.org/pdf/2601.13607v1)

**作者:** Ruihan Hu `[一作]` (Beijing University of Posts and Telecommunications), Xi Zhang `[通讯]` (Beijing University of Posts and Telecommunications)

**通讯引用:** 8818 | [OpenAlex ID](https://openalex.org/A5100430813)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了在黑盒大型推理模型（LRM）上利用中间推理轨迹进行成员身份推断攻击，并提出了 BlackSpectrum 框架。

**💡 创新点**

创新点在于发现推理轨迹在语义潜在空间形成从回忆到推理的连续谱，并以此构建回忆–推理轴进行精准攻击。

**🔧 技术方法**

使用了句子嵌入编码器、序列去噪模块、低熵合成序列选择以及投影计分等技术。

**📊 数据集**

采用了新构建的 arXivReasoning 与 BookReasoning 两大数据集，覆盖 55 篇 arXiv 论文和 184 本书。

**📈 对比分析**

与传统基于 token logit 的攻击以及五种基线（Thinking Token、Compression Rate、Tr-Consistency、LLM-based judgement）对比，BlackSpectrum 在 ACC、AUC 和 TPR@5%FPR 上提升多达 23.8%、29.9% 和 1.9 倍。

**⚠️ 局限性**

局限性包括：需访问推理轨迹；实验假设对不同 LRM 训练数据未知，结果可能受限；且仅在四款公开 LRM 上验证，未探讨跨模型通用性。

---

## 687. TRGCN: A Hybrid Framework for Social Network Rumor Detection

**arXiv ID:** 2601.13573 | [PDF](https://arxiv.org/pdf/2601.13573v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39`

---

## 688. Foundations of Global Consistency Checking with Noisy LLM Oracles

**arXiv ID:** 2601.13600 | [PDF](https://arxiv.org/pdf/2601.13600v1)

**作者:** Paul He `[一作]` (Nanyang Technological University), Shiva Kasiviswanathan `[通讯]` (Amazon Web Services)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究在使用大型语言模型（LLM）作为噪声子集一致性判定器的情况下，如何高效验证自然语言事实集合的全局一致性，并提出一种自适应分治算法来定位最小不一致子集（MUS）并通过击中集实现修复。

**💡 创新点**

创新点在于：①从理论上证明仅靠成对检查无法保证全局一致性，且最坏情况下查询复杂度呈指数；②提出了低多项式查询复杂度的分治+击中集修复框架；③给出了针对噪声LLM判定器的噪声放大与独立性假设下的理论分析。

**🔧 技术方法**

采用QuickXplain的递归分治求MUS、基于击中集的贪心最小修复、以及对LLM的子集一致性判定（噪声Oracle）。

**📊 数据集**

实验使用VitaminC和FEVER两个基准数据集，对每个样例组装30条事实，构造有冲突的子集。

**📈 对比分析**

与直接一次性查询LLM的“all-at-once”基线对比，QXR方法在Precision、Recall和F1上均显著提升，尤其在Recall上从约0.33提升至0.88，F1提升至0.72，显示更精准且更完整的错误定位与修复。

**⚠️ 局限性**

局限性包括：理论分析假设查询独立性且可通过多数投票降低噪声；实际LLM可能产生系统性错误，单模型多次查询并不一定可靠；实验仅覆盖中等规模的事实集，未检验在更大知识图谱或长上下文RAG场景下的可扩展性。

---

## 689. DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems

**arXiv ID:** 2601.13591 | [PDF](https://arxiv.org/pdf/2601.13591v1)

**作者:** Maojun Sun `[一作]` (Hong Kong Polytechnic University), Jian Huang `[通讯]` (Hong Kong Polytechnic University)

**通讯引用:** 12997 | [OpenAlex ID](https://openalex.org/A5012067697)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了面向真实世界数据科学任务的多模态、多步骤、多维度评估基准DSAEval，并系统评估了11种先进的LLM/视觉‑语言模型；

**💡 创新点**

①引入多模态环境感知、连续多查询交互与三维度评估三大核心功能；②使用LLM‑Judge实现对推理、代码与结果的软标签评估；③构建包含285个数据集、641个任务的真实场景基准；

**🔧 技术方法**

多模态环境感知（文本+表格+图像观测）、交互式沙箱执行、LLM‑Judge评估、GPU加速的深度学习训练、分层任务脚本生成；

**📊 数据集**

涵盖285个多元数据集（结构化表格、文本、图像等），任务类型包括统计推断、特征工程、建模、推断、CV、NLP、时间序列等；

**📈 对比分析**

与多款LLM/VLM（Claude‑Sonnet‑4.5、GPT‑5.2、MiMo‑V2‑Flash 等）进行对比；Claude‑Sonnet‑4.5取得最高综合得分8.16；GPT‑5.2在相同得分下使用最少令牌，效率最高；MiMo‑V2‑Flash成本最低；多模态感知可提升视图任务得分2.04–11.30%；

**⚠️ 局限性**

评估结果受LLM随机性影响；Judge模型选择与人类评估的匹配有限；基准侧重单模型评估，未覆盖完整系统级代理；对非结构化深度学习任务仍表现不足；

---

## 690. Highly Deformable Proprioceptive Membrane for Real-Time 3D Shape Reconstruction

**arXiv ID:** 2601.13574 | [PDF](https://arxiv.org/pdf/2601.13574v1)

**作者:** Guanyu Xu `[一作]` (University of Michigan), Xiaonan Huang `[通讯]` (University of Michigan)

**通讯引用:** 3300 | [OpenAlex ID](https://openalex.org/A5000690549)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `6514db3d-8de6-452c-91b7-acdb31787cc4` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出一种柔性可变形的本体感知膜，可通过内置LED与光电二极管的光波导传感实现对膜本身三维形状的实时重建

**💡 创新点**

创新点在于将光波导与液态金属柔性互连相结合，构建了高可拉伸、低EMI的薄膜传感器，并通过数据驱动的两阶段神经网络实现大规模全局形变的高精度重建

**🔧 技术方法**

采用光波导强度感知、液态金属（氧化镓铟）互连、可折叠PCB分布式LED/PD阵列、时间分复用采样以及点云自编码器+多层感知机的深度学习架构

**📊 数据集**

数据集为在140mm×140mm薄膜上记录的34.3万对样本（5个PD、30个LED），每帧包含光信号向量和对应的RealSense D435深度相机获取的点云真值

**📈 对比分析**

与传统阻容、磁性或光波长基感知方式对比，本文方法在90Hz实时率下实现平均Chamfer距离1.307mm（中位1.195mm），对25mm深度挤压仍保持低误差，证明了高精度与高频率的优越性能

**⚠️ 局限性**

局限性在于LED/PD布局主要经验设计，未进行全局最优优化；实验仅覆盖四侧夹紧的垂直挤压形变，未验证拉伸、扭转等更丰富的变形模式，且缺乏基于仿真的数据生成与布局优化方法

---

## 691. Scaling Test-time Inference for Visual Grounding

**arXiv ID:** 2601.13633 | [PDF](https://arxiv.org/pdf/2601.13633v1)

**作者:** Guanqi Zhan `[一作]` (NVIDIA), Ligeng Zhu `[通讯]` (NVIDIA)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过在小型视觉语言模型（VLM）上引入扩展的推理过程，利用测试时生成更多token来提升其多模态推理能力，从而显著提高视觉定位（grounding）精度并降低推理延迟。

**💡 创新点**

创新点在于：①发现小VLM落后主要源于文本理解能力不足而非视觉编码；②提出通过“扩展测试时计算”即让模型在推理阶段输出完整推理链来提升文本理解；③构建基于GPT‑4生成的推理轨迹的SFT与RL两阶段训练框架；④将方法同时应用于传统的可见目标定位与新提出的全景（amodal）定位任务。

**🔧 技术方法**

技术手段包括：SFT（监督微调）利用GPT‑4生成的推理文本；RL（强化学习）采用GRPO+token‑level mean loss、KL/熵正则；多模态数据处理（ViT编码 + LLM投影）；测试时生成多token提升文本表征；量化延迟与准确率评估。

**📊 数据集**

使用的数据集：
- RefCOCO（用于可见目标定位）
- COCO‑Amodal、TAO‑Amodal（用于amodal定位）
- 通过GPT‑4在上述数据集上生成的推理文本。

训练样本量由原始数据集通过GPT‑4生成推理轨迹后扩增得到。

**📈 对比分析**

与大模型（InternVL‑3‑8B、Qwen3‑VL‑235B‑Instruct/Thinking）及同家族中更大模型进行对比：
- 在RefCOCO上，8B模型在90.5 IoU的大模型基础上提升至91.4 IoU，同时平均延迟降至737 ms（约5.9×更快）。
- 2B/4B模型在准确率上也超越8B大模型。
- 在amodal定位任务中，方法同样提升了约6–11 %的准确率。总体表明，扩展测试时计算能在保持小模型规模的前提下，弥补或超越大模型性能并显著降低推理成本。

**⚠️ 局限性**

局限性包括：
- 依赖于GPT‑4等专有大模型生成推理轨迹，产生额外成本和潜在偏差；
- 扩展测试时计算虽然提升文本理解，但在极端长prompt或复杂视觉情景下仍可能受限；
- 仅在RefCOCO和amodal数据集上评估，缺乏对其他多模态任务或跨域鲁棒性的验证；
- 目前尚未充分探索与更高效推理技术（如参数稀疏化、知识蒸馏）的结合。

---

## 692. PRIMAL: Processing-In-Memory Based Low-Rank Adaptation for LLM Inference Accelerator

**arXiv ID:** 2601.13628 | [PDF](https://arxiv.org/pdf/2601.13628v1)

**作者:** Yue Jiet Chong `[一作]` (National University of Singapore), Xuanyao Fong `[通讯]` (National University of Singapore)

**通讯引用:** 2926 | [OpenAlex ID](https://openalex.org/A5085588788)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 PRIMAL，一个基于内存中计算（PIM）的低秩适配（LoRA）LLM推理加速器。

**💡 创新点**

创新点在于：①使用异构 PE 与 2D‑mesh IPCN 实现高并行、低通信；②设计 SRPG（SRAM 重新编程与电源门控）机制，使 LoRA 更新与计算重叠并在空闲时节能；③采用统一的空间映射与数据流编排最小化通信开销。

**🔧 技术方法**

核心技术包括：RRAM‑ACIM 与 SRAM‑DCIM 的双模混合计算；IPCN 统一指令集控制数据流；SRPG 并行重编程与电源门控；层级化芯片片段（CT）架构。

**📊 数据集**

使用 Llama‑13B（LoRA rank 8 的 Q,V）以及 Llama‑3.2‑1B、Llama‑3‑8B 等模型进行实验，配合不同上下文长度（1024/1024 与 2048/2048）。

**📈 对比分析**

与 Nvidia H100 对比，PRIMAL 在 LoRA rank 8、Llama‑13B 上实现了约 1.5 × 的吞吐量提升和 25 × 的能效提升（9.85 tks/J 对比 0.4 tks/J）。在 TTFT 与 ITL 上也显著下降，体现了管线化执行与 SRPG 的功耗优势。

**⚠️ 局限性**

局限性包括：①仅验证了 LoRA rank 8 的情况，未探讨更高秩或完整微调；②对极大模型（>13B）仍需更多芯片片段，面积与成本上升；③SRPG 需要额外的控制逻辑，设计复杂度提升。

---

## 693. Optimizing Parallel Schemes with Lyapunov Exponents and kNN-LLE Estimation

**arXiv ID:** 2601.13604 | [PDF](https://arxiv.org/pdf/2601.13604v1)

**作者:** Mudassir Shams `[一作]` (Balikesir University), Bruno Carpentieri `[通讯]` (Free University of Bozen-Bolzano)

**通讯引用:** 1468 | [OpenAlex ID](https://openalex.org/A5051748763)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

研究并开发了一种结合理论分岔分析与基于kNN的微系列Lyapunov指数估计的自适应逆并行根求解器，用以诊断和抑制其动态不稳定性。

**💡 创新点**

① 将Lyapunov指数与参数空间分岔图统一映射，实现实时稳定性诊断；② 提出微系列kNN估计器用于短时Lyapunov指数快速计算；③ 基于Lyapunov反馈自动调整单参数α，形成自稳定求解框架。

**🔧 技术方法**

逆并行迭代法（INVM^α）、分岔与稳定性分析、微系列kNN Lyapunov指数估计、滑动窗口Lyapunov剖面、基于Lyapunov的自适应参数控制。

**📊 数据集**

以三次多项式 f(x)=x³−1 与六次多项式 f(x)=x⁶+30x³−125x²−5x+120 为测试函数，随机生成 1000 个扰动初值向量。

**📈 对比分析**

与未调参的 INVM^α 及经典 ZHM 方法对比，通过残差、步长、CPU 时间、内存使用、收敛阶等指标评估，发现自适应参数能将误差降至 10⁻¹⁹⁶、CPU 时间降低 70%+、内存 70%+，收敛阶提升至约5。

**⚠️ 局限性**

仅验证一维标量多项式；方法依赖大量初值样本和窗口长度调参；对高维或噪声影响、非光滑函数的鲁棒性尚未充分验证。

---

## 694. An Elementary Approach to Scheduling in Generative Diffusion Models

**arXiv ID:** 2601.13602 | [PDF](https://arxiv.org/pdf/2601.13602v1)

**作者:** Qiang Sun `[一作]` (University of Science and Technology of China), Wenyi Zhang `[通讯]` (University of Science and Technology of China)

**通讯引用:** 8230 | [OpenAlex ID](https://openalex.org/A5100360013)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究扩散模型中噪声调度与时间离散化对逆采样的影响，给出多元高斯简化模型下 KL 散度的闭式表达及其收敛特性，并提出基于 KL 的高效时间离散化策略；

**💡 创新点**

创新点在于从 KL 散度的闭式推导得到噪声调度的“切线定律”并与源协方差谱相关，且提出无需额外训练即可利用 KL 衡量离散化方案的低成本方法；

**🔧 技术方法**

使用高斯理论分析、KL 散度闭式求解、Euler‑Maclaurin 展开、变分求解、切线调度、O(NFE) 采样策略、ODE 采样器（DPM‑Solver++、UniPC）等技术；

**📊 数据集**

在 CIFAR‑10、FFHQ‑64 数据集上使用预训练的 EDM 与 VP‑SDE 模型进行实验；

**📈 对比分析**

与常用 Uniform‑λ 基线和 Xue'24 搜索策略对比；在有限 NFE 预算下，提出的 ρ=1.5/2.0 功率均匀时间离散化在 FID 上均优于基线，并在多步情形下保持优势；

**⚠️ 局限性**

局限性包括：理论基于多元高斯假设，实际图像数据的适用性需要进一步验证；VE 设置下 γ 的闭式解在高 σ_max 时为近似；尚未考虑引导采样和高分辨率生成的推广。

---

## 695. CauScientist: Teaching LLMs to Respect Data for Causal Discovery

**arXiv ID:** 2601.13614 | [PDF](https://arxiv.org/pdf/2601.13614v1)

**作者:** Bo Peng `[一作]` (Shanghai Artificial Intelligence Laboratory), Chaochao Lu `[通讯]` (Shanghai Artificial Intelligence Laboratory)

**通讯引用:** 579 | [OpenAlex ID](https://openalex.org/A5034013066)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出了一个协同因果发现框架，结合大型语言模型（LLM）作为假设生成者与概率统计（BIC）验证器共同探索结构。

**💡 创新点**

创新点在于：①混合初始化在无先验时自动选取统计模型或LLM生成图的BIC最低者；②LLM提议原子操作（增删逆转）并通过错误记忆避免重复错误；③使用干预感知的BIC作为严格验证指标，实现双向迭代改进。

**🔧 技术方法**

主要技术包括：LLM（Qwen3-14B/32B）生成结构假设；MLP估计对数似然以适配非线性因果；干预感知BIC（数据拟合+结构复杂度惩罚）；错误记忆与迭代优化算法。

**📊 数据集**

实验数据集涵盖 5/8/20/37 个节点的标准 Bayesian Network Repository 数据：Cancer、Asia、Child、Alarm；每个数据集均包含观测与单节点干预样本。

**📈 对比分析**

与基线（FCI、AVICI）和零射击LLM（Qwen3-14B/32B）对比，框架在所有数据集显著提升 F1（最高提升 53.8%）、召回（从 35% 提升至 100%）并将 SHD 降至 1.2（相比 16）或 17.8（相比 61.8），显示出对大图和复杂结构的鲁棒性。

**⚠️ 局限性**

局限性：①依赖变量的语义描述，匿名或缺失元数据时难以发挥优势；②验证仅基于 BIC，可能对样本量或分布偏差不敏感，未来可替换为更适合的评分函数。

---

## 696. PINA: Prompt Injection Attack against Navigation Agents

**arXiv ID:** 2601.13612 | [PDF](https://arxiv.org/pdf/2601.13612v1)

**作者:** Jiani Liu `[一作]` (Zhejiang University), Wenyuan Xu `[通讯]` (Southeast University)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种针对LLM导航代理的自适应提示注入攻击框架PINA，用于在黑盒、长上下文、可执行动作的限制下生成高效攻击提示。

**💡 创新点**

创新点在于结合攻击评估器与分布分析器形成闭环：攻击评估器聚合多维导航指标得分，分布分析器通过KL散度与关键词辨识提供全局与局部优化信号，从而实现对目标代理的精细化提示改进。

**🔧 技术方法**

使用技术包括：基于代理模拟器的黑盒评估、使用GPT‑3.5/GPT‑4作为攻击评估器、Llama‑2‑7B做分布分析、KL散度与熵变化检测关键词、迭代提示优化算法和反馈生成器。

**📊 数据集**

实验数据集涵盖室内NavGPT（使用R2R数据集）与户外Balcı等人模型（未公开的室外数据集），对比了四种基线注入方法。

**📈 对比分析**

与基线相比，PINA在室内代理上实现75%攻击成功率（ASR），在户外代理上100% ASR，且显著降低SPL、nDTW和CLS指标，表现优于所有基线；在自适应防御情境下仍保持高成功率并显著扰乱导航质量。

**⚠️ 局限性**

局限性包括：依赖于准确的代理模拟器；对更复杂的动态环境或多模态输入的鲁棒性未知；对更强大或专门的自适应防御（如深度学习检测）仍需进一步验证。

---

## 697. Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data

**arXiv ID:** 2601.13608 | [PDF](https://arxiv.org/pdf/2601.13608v1)

**作者:** Zhipeng Chang `[一作]` (Penn State University), Wenrui Hao `[通讯]` (Penn State University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在联邦学习中提出了FIPA方法，即使用低秩Fisher信息矩阵对每个客户端的参数更新进行参数级聚合，代替传统的统一标量权重。

**💡 创新点**

创新点在于将Fisher信息矩阵的参数识别能力转化为可调的参数级权重，通过低秩近似实现可扩展且精细的更新缩放，从而在非IID数据下显著缓解客户端漂移。

**🔧 技术方法**

核心技术包括：低秩FIM谱分解、子空间迭代与Rayleigh–Ritz投影、薄QR求解、Generalized Gauss–Newton、参数级聚合、两阶段训练与参数高效微调（LoRA式FC层冻结）。

**📊 数据集**

实验使用了CIFAR‑10、CIFAR‑100、Tiny‑ImageNet等图像分类数据集，以及一维/二维函数回归和PDE学习任务，所有数据均通过Dirichlet分布模拟非IID。

**📈 对比分析**

与FedAvg、FedProx、FedRCL、FedAdam等方法比较，FIPA在异构数据场景下提升准确率高达约10%（例如CIFAR‑10 α=0.01 上升9.5%），在PDE和函数拟合中也表现出更快、更稳健的收敛。

**⚠️ 局限性**

限制包括：额外的通信和计算开销（上传低秩FIM特征）、需要选择合适的秩与冻结参数比例、对延迟/慢速客户端敏感，以及FIM信息可能带来隐私泄露风险。

---

## 698. DCCVT: Differentiable Clipped Centroidal Voronoi Tessellation

**arXiv ID:** 2601.13603 | [PDF](https://arxiv.org/pdf/2601.13603v1)

**作者:** Wylliam Cantin Charawi `[一作]` (École de Technologie Supérieure), Diego Thomas `[通讯]` (Kyushu University)

**通讯引用:** 666 | [OpenAlex ID](https://openalex.org/A5078334891)

**关键词:** `a42c7bd6-d8fd-40d3-94df-ae8cd808f5c4` `5b4c1114-4a70-478e-9921-2514ee03850d` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

提出一种可微分的裁剪中心体素网格（DCCVT）算法，联合优化点云的隐式SDF值与Voronoi站点位置，从而在学习框架中高质量地提取3D网格。

**💡 创新点**

创新点在于：①将中心Voronoi切片与零水平集投影融合为可微流程；②通过CVT正则化与Eikonal、MbMC约束实现网格光滑与正则化；③设计自适应上采样与多种站点分布策略，提升复杂形状的重建精度。

**🔧 技术方法**

采用技术包括：可微分裁剪CVT、SDF投影与梯度估计、Eikonal/MbMC正则化、基于Delaunay/Voronoi的网格提取、神经SDF（HotSpot）初始化、以及PyTorch+GPU加速的迭代优化。

**📊 数据集**

使用Thingi32（Thingi10K子集）数据集进行点云采样和网格评估。

**📈 对比分析**

与Voromesh和Marching Tetrahedra（MTet）基线对比，在Chamfer Distance、F1 Score和Normal Consistency三项指标上均取得更低CD、更高F1和NC；尤其在上采样或SDF未收敛的情况下表现更稳健，平均时间约5分钟/32³点。

**⚠️ 局限性**

局限性：需要在每一步重新进行Delaunay三角化，导致计算开销较大；对SDF初始化敏感，极端缺口或不完整点云时仍易出现错误；尚缺乏针对大缺口或复杂拓扑的鲁棒性提升。

---

## 699. Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models

**arXiv ID:** 2601.13599 | [PDF](https://arxiv.org/pdf/2601.13599v1)

**作者:** Linrui Ma `[一作]` (Huawei), Yunhe Wang `[通讯]` (Huawei)

**通讯引用:** 13724 | [OpenAlex ID](https://openalex.org/A5100727358)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种分阶段的“草稿-修订”结构块扩散模型，先用小块快速生成草稿，再用大块全局双向扩散进行细化。

**💡 创新点**

核心创新包括结构化扩散框架、快照置信度重掩码策略以及混合尺度训练，使模型既能快速草拟又能通过全局上下文纠错。

**🔧 技术方法**

使用了块扩散模型（BD3-LM）、快照置信度计算、重掩码机制、混合尺度训练以及Transformer架构。

**📊 数据集**

在OpenWebText数据集上进行训练与评估。

**📈 对比分析**

与AR、SEDD、MDLM、BD3-LM等基线相比，在生成困惑度（Gen PPL）上从25.7降到21.9，仅用26%调优预算，显著缩小与AR模型的差距。

**⚠️ 局限性**

局限性在于需要多阶段计算，调参复杂；重掩码比例和块尺寸对性能影响大，模型对不同长文本的泛化仍有限。

---

## 700. AI IDEs or Autonomous Agents? Measuring the Impact of Coding Agents on Software Development

**arXiv ID:** 2601.13597 | [PDF](https://arxiv.org/pdf/2601.13597v1)

**作者:** Shyam Agarwal `[一作]` (Carnegie Mellon University), Bogdan Vasilescu `[通讯]` (Carnegie Mellon University)

**通讯引用:** 5577 | [OpenAlex ID](https://openalex.org/A5050821883)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了 LLM 驱动的自治编码代理在开源仓库中的长期因果效应，关注开发速度与软件质量的变化。

**💡 创新点**

首次将分层差分与倾向得分匹配相结合，对 agent‑first 与 IDE‑first 两类仓库进行细粒度比较，揭示代理使用前置 AI 环境对速度和质量的异质影响。

**🔧 技术方法**

使用分层差分（Borusyak 估计）、倾向得分匹配、事件研究以及 SonarQube 静态分析工具。

**📊 数据集**

依赖 AIDev 数据集（标记 agent PR）与 GHArchive（仓库活动日志），并补全 2024‑2025 年的 PR 记录。

**📈 对比分析**

通过对比 agent‑first 与 IDE‑first 两组，发现前者在首个 AI 工具时获得 36%~76% 的速度提升，但持续产生 18%~35% 的质量债务；后者速度提升有限，质量风险同样上升。

**⚠️ 局限性**

局限在于仅捕获可观察的 agent PR，未考虑使用强度或开发者交互；分类误差可能导致噪声；长期后果及跨语言适用性尚待验证。

---

## 701. Stochastic Dynamic Pricing of Electric Vehicle Charging with Heterogeneous User Behavior: A Stackelberg Game Framework

**arXiv ID:** 2601.13571 | [PDF](https://arxiv.org/pdf/2601.13571v1)

**作者:** Yongqi Zhang `[一作]` (Monash University), Zhuo Chen `[通讯]` (Tongji University)

**通讯引用:** 19319 | [OpenAlex ID](https://openalex.org/A5119128853)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了基于双层Stackelberg博弈的随机异质动态定价框架，用于电动汽车充电站匹配与价格优化。

**💡 创新点**

创新点在于将多项式离散选择模型与排队理论结合，兼顾用户感知误差与充电站容量差异，并通过动态概率敏感性引导的交叉熵算法实现大规模滚动规划。

**🔧 技术方法**

主要技术包括多项式Logit用户选择模型、M/M/s/c排队近似、交叉熵（CEM）+概率敏感性分析（PSA）以及多步平均（MSA）求解双层优化。

**📊 数据集**

使用了澳大利亚克莱顿地区22座充电站的实际位置与充电需求时序数据，并基于真实车辆SOC、能耗等参数进行仿真。

**📈 对比分析**

与固定价、时段定价以及无平衡MNL方案对比，结果显示动态定价将排队损失下降约73%，系统总效用提升近二倍，且在高峰期仍能保持较低拥堵。

**⚠️ 局限性**

主要局限在于假设滚动窗口内需求已知、仅考虑单一运营商竞争、未纳入电网约束及更细粒度的驾驶行为异质性。

---

## 702. Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation

**arXiv ID:** 2601.13565 | [PDF](https://arxiv.org/pdf/2601.13565v1)

**作者:** Yu Qin `[一作]` (Hunan University), Zhiyong Li `[通讯]` (Hunan University)

**通讯引用:** 14477 | [OpenAlex ID](https://openalex.org/A5100396732)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种开源词汇6D姿态估计框架FiCoP，利用细粒度对应关系消除全局匹配中的背景干扰，提升机器人在开放世界中的姿态推断精度。

**💡 创新点**

创新点在于引入Patch Correlation Predictor（PCP）生成基于patch‑to‑patch相关矩阵的空间先验，结合Cross‑Perspective Global Perception（CPGP）模块实现跨视角结构一致性，并通过Object‑Centric Disentanglement预处理剔除噪声。

**🔧 技术方法**

技术包括SAM与GroundingDINO的对象分割、DINOv2视觉编码器、CLIP文本编码、Transformer‑based CPGP、基于卷积的PCP、以及Point‑DSC姿态回归。

**📊 数据集**

实验使用REAL275与Toyota‑Light真实世界数据集，以及ShapeNet6D合成数据进行训练和零样本测试。

**📈 对比分析**

与PoseDiffusion、RelPose++、ObjectMatch、SIFT、LatentFusion、Oryon及Horyon等方法对比，FiCoP在REAL275上AR/ADD提升至65.9/55.2（分别比Horyon高8.0%/6.1%），在Toyota‑Light上AR/ADD提升至88.8/89.5。

**⚠️ 局限性**

局限在于对高分辨率特征和大patch granularity的计算成本较高，且对极端遮挡或完全未知纹理的物体仍可能出现匹配误差。

---

## 703. Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions

**arXiv ID:** 2601.13590 | [PDF](https://arxiv.org/pdf/2601.13590v1)

**作者:** Fan Huang `[一作]` (Indiana University Bloomington), Jisun An `[通讯]` (Indiana University Bloomington)

**通讯引用:** 3646 | [OpenAlex ID](https://openalex.org/A5084955495)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

系统性评估大型语言模型在源–信息–渠道–接收者(SMCR)框架下的说服易感性，并在多轮交互中跟踪信念变化。

**💡 创新点**

①提出SMCR视角的说服策略组合；②发现“元认知提示”反而加速信念崩溃的悖论；③展示对抗性微调在不同模型架构上的差异性。

**🔧 技术方法**

多轮对话实验、元认知提示（自报置信度）、对抗性微调（QLoRA/OpenAI fine‑tune）、置信度轨迹分析与SMCR策略生成。

**📊 数据集**

三个领域的数据集：BoolQ（事实问答）、PubMedQA（医学问答）、LatentHatred（社会偏见检测），共1,236个高置信度样本。

**📈 对比分析**

与基线（无提示）和鲁棒性增强系统提示比较，评估指标为鲁棒率（100−@4）与平均终止回合。结果显示：GPT‑4o‑mini最高鲁棒率≈98%，Qwen 2.5‑7B≈49%，Llama 3.3‑70B≈22%，Mistral 7B≈20%，Llama 3.2‑3B≈3.5%；对抗微调在GPT‑4o‑mini、Mistral 7B表现突出，而在Llama系列几乎无效。

**⚠️ 局限性**

只评估5种模型，模型与技术快速演进可能导致结果不具普适性；实验仅在单轮会话内进行，缺乏跨会话或长期交互的验证；对抗微调采用混合脆弱样本，未能细分不同脆弱类型的因果关系。

---

## 704. Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models

**arXiv ID:** 2601.13580 | [PDF](https://arxiv.org/pdf/2601.13580v1)

**作者:** Ahmad Al-Zuraiqi `[一作]` (Jadara University), Ahmad Al-Zuraiqi `[通讯]` (Jadara University)

**通讯引用:** 2 | [OpenAlex ID](https://openalex.org/A5023553674)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

介绍了一种神经器官移植框架，可将预训练Transformer层模块化为可移植的检查点，实现域适应。

**💡 创新点**

创新点在于将中间层提取为独立的“器官”，通过检查点分发实现无数据部署和跨模型迁移。

**🔧 技术方法**

采用层级抽取、独立训练、检查点包装、直接替换或桥接融合等技术，主要针对解码器-only模型。

**📊 数据集**

使用WikiText作为低数据域，并在跨域测试中使用不同主题的样本。

**📈 对比分析**

与LoRA、全微调、Top-K、IA^3等方法对比，器官移植在PPL上比LoRA提升2.8–38.6倍，训练速度提升2–28倍，且不需访问原始数据。

**⚠️ 局限性**

局限在于仅适用于解码器-only架构，对编码器或编码器-解码器模型效果差，且多器官组合存在干扰。

---

## 705. GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds

**arXiv ID:** 2601.13570 | [PDF](https://arxiv.org/pdf/2601.13570v1)

**作者:** Tingting Dan `[一作]` (University of North Carolina), Guorong Wu `[通讯]` (University of North Carolina)

**通讯引用:** 10313 | [OpenAlex ID](https://openalex.org/A5021809690)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851` `a6cb313d-240c-4723-a372-3ba1f39b9afc`

**🎯 论文内容**

提出了一种几何状态空间神经网络（GeoSSM），在对称正定（SPD）流形上直接建模功能连接随时间的演化轨迹，并将其应用于人脑功能连接分析和三类动作识别数据集。

**💡 创新点**

创新点在于：①将Riemannian流形几何嵌入传统SSM，使用加权弗雷歇均值和正交群平移实现SPD矩阵的平滑传播；②提出SPD保持注意力（SPA）模块，在保持正定性的前提下对时空信息进行可解释的加权；③通过对数映射和全局卷积实现可扩展、高效的时序学习。

**🔧 技术方法**

技术方法包括：经典SSM框架、SPD流形几何（Stein距离）、加权弗雷歇均值、正交群作用、SPD卷积、SPD保持注意力、对数/指数映射、全局卷积扩展、矩阵指数/对数稳定化、交叉熵分类器。

**📊 数据集**

使用的数据集有：人脑连接组—HCP‑WM（任务fMRI）与四个疾病组（ADNI、OASIS、PPMI、ABIDE），以及动作识别数据集—Florence3D、HDM05、UTKinect‑Action3D。

**📈 对比分析**

与多种空间模型（GCN、GIN、GSN、MGNN、GNN‑AK、SPDNet、MLP）和序列模型（RNN、LSTM、Transformer、Mamba、SVM、STAGIN、NeuroGraph等）进行对比。结果显示，GeoSSM在任务基分类、疾病早期诊断和动作识别任务中均显著优于基线，任务基准确率高达97%以上，疾病分类准确率和F1显著提升，统计显著性达到p<0.05。

**⚠️ 局限性**

局限性包括：①对滑动窗口长度仍有一定依赖，需要经验性调参；②模型计算量大，需对SPD矩阵做对数/指数运算，影响训练速度和内存；③目前仅使用滑动窗口构造的SPD矩阵，可能无法捕捉更细粒度的时序细节；④在多类别疾病分类中仍存在误分类；⑤未探讨不同流形距离或更高阶几何对性能的影响。

---

## 706. LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI

**arXiv ID:** 2601.13556 | [PDF](https://arxiv.org/pdf/2601.13556v1)

**作者:** Jianan Wang `[一作]` (National University of Defense Technology), Chen Qian `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 50873 | [OpenAlex ID](https://openalex.org/A5100428454)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 LogicEnvGen，一种基于大语言模型的顶层设计方法，用于自动生成逻辑多样化的模拟环境，并构建 LogicEnvEval 基准来评估此类环境的物理合理性、逻辑覆盖、场景有效率与缺陷检测能力。

**💡 创新点**

创新点包括：① 将任务执行逻辑抽象为决策树结构化行为计划；② 通过最小轨迹选择算法（MTSA）压缩逻辑轨迹集合，消除冗余；③ 用约束求解（Z3）实现物理可行的对象布置；④ 设计四维评估指标与 25 个复杂条件任务的 Benchmark，突破了以往仅关注视觉多样化的研究。

**🔧 技术方法**

核心技术包括：大语言模型（DeepSeek‑v3、Gemini‑2.5‑Flash、Qwen2.5‑72B）进行任务解析与场景生成；规则驱动的验证与迭代改进；深度搜索与贪心算法生成逻辑轨迹；约束满足问题求解器 Z3 处理物理与空间约束；行为树模拟器评估场景有效性与缺陷检测。

**📊 数据集**

使用 25 个手工验证的长周期条件任务（LogicEnvEval）作为任务集合，结合 Objaverse 3D 资产库与 AI2‑THOR 环境框架，并根据自定义的物理约束（房间布局、门窗位置、对象支撑、碰撞等）构建测试集。

**📈 对比分析**

与 Holodeck、CoT、IFG 三种基线方法在同一 LLM 与资产库下进行对比。LogicEnvGen 在 Physics Pass Rate 上保持 100% 物理合规，逻辑覆盖率提升 1.04–2.61 倍，缺陷检测率提升 4–68%（平均 94.67%），场景有效率显著高于基线；同时通过 MTSA 大幅减少模拟时间，提升效率。

**⚠️ 局限性**

局限性：① 采用 JSON 决策树表示，可能不适合所有任务；② 仅使用行为树模拟器进行验证，缺乏高保真物理引擎的评估；③ Benchmark 仅包含 25 个任务，规模与多样性有限，难以全面验证方法的泛化能力。

---

## 707. Towards Token-Level Text Anomaly Detection

**arXiv ID:** 2601.13644 | [PDF](https://arxiv.org/pdf/2601.13644v1)

**作者:** Yang Cao `[一作]` (Great Bay University), Yujiu Yang `[通讯]` (Tsinghua University)

**通讯引用:** 3782 | [OpenAlex ID](https://openalex.org/A5020953714)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了 TokenCore 框架，实现了 token 级文本异常检测，能够精确定位文本中异常词。

**💡 创新点**

创新点在于统一了 token 级检测方法，构建了正向 token 嵌入记忆库并采用最近邻距离进行异常评分，同时首次给出了三大带 token 标注的真实 benchmark 数据集，推动了跨类型异常检测的研究。

**🔧 技术方法**

使用了预训练 BERT 的词向量、子词最大池化、记忆库最近邻搜索技术，并与 LOF、iForest、ECOD、DeepSVDD、AutoEncoder、LUNAR 等六种基线方法进行对比。

**📊 数据集**

实验数据集包括 SMS Spam（字符腐败）、Restaurant Review（语义异常）和 Grammar Correction（语法错误）三大 benchmark，每个数据集都提供了 token 级标注。

**📈 对比分析**

在 token 与 document 两级别的 AUROC/AUPRC 指标下，TokenCore 在语义和语法异常上均获得最佳或次优表现，平均 AUROC 最高，但在字符腐败的 token 级检测上略逊于统计方法。

**⚠️ 局限性**

主要局限包括预训练模型对表面异常（如拼写错误）的敏感度不足；最大池化对子词信息可能导致信息丢失；token 级异常的极端类别不平衡易产生误报；记忆库规模大导致搜索成本高。

---

## 708. ContiguousKV: Accelerating LLM Prefill with Granularity-Aligned KV Cache Management

**arXiv ID:** 2601.13631 | [PDF](https://arxiv.org/pdf/2601.13631v1)

**作者:** Jing Zou `[一作]` (University of Electronic Science and Technology of China), Chun Jason Xue `[通讯]` (Mohammed Bin Zayed University of Artificial Intelligence)

**关键词:** `9a43038e-f401-4fd9-9c05-65c0b8369d7e` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种面向共享前缀LLM推理的高效KV缓存离线系统ContiguousKV，用于显著加速Re‑Prefill阶段。

**💡 创新点**

创新点包括：1）统一的ContiguousChunk粒度对齐算法与I/O，消除读放大；2）两级（intra‑period 与 inter‑period）异步预取机制，打破I/O与计算的顺序依赖；3）基于注意力评分的缓存管理策略，动态优先保留语义重要的Chunk。

**🔧 技术方法**

主要技术手段包括ContiguousChunk划分、异步预取（Speculative Prefetch）、注意力评分聚合、min‑heap缓存淘汰、两层预取引擎等。

**📊 数据集**

在Qwen2.5系列模型（7B、14B、32B）上使用SST‑2、SUBJ、TREC和RTE四个自然语言理解数据集进行评估。

**📈 对比分析**

与AS+LRU、AS+H2O+LRU、IMPRESS等现有离线推理系统对比，ContiguousKV在Re‑Prefill阶段的TTFT平均提升约3.85×（5% KV预算下与IMPRESS相比），并在保持或略高于IMPRESS的准确率的同时大幅降低P95尾部延迟。

**⚠️ 局限性**

局限性包括：仅针对共享前缀场景；需要手动调节SemChunk与Period大小以平衡准确率与效率；对极长上下文或极大模型时仍存在读放大风险；实现复杂度较高，且未公开完整代码。

---

## 709. Balancing Fairness and High Match Rates in Reciprocal Recommender Systems: A Nash Social Welfare Approach

**arXiv ID:** 2601.13609 | [PDF](https://arxiv.org/pdf/2601.13609v1)

**作者:** Yoji Tomita `[一作]` (CyberAgent), Tomohiko Yokoyama `[通讯]` (University of Tokyo)

**通讯引用:** 10938 | [OpenAlex ID](https://openalex.org/A5067233448)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

研究了在线匹配平台中的递归推荐系统（RRS），提出了双边无嫉妒（double envy‑free）公平定义，并探讨了公平与匹配效率的权衡。

**💡 创新点**

创新点包括：① 将公平分配中的无嫉妒性扩展到双边推荐；② 提出了使用Nash社会福利（NSW）优化实现近似无嫉妒的算法；③ 设计了α‑SW 目标实现公平与效率的可调权衡；④ 利用Sinkhorn算法实现可扩展的高效求解。

**🔧 技术方法**

主要技术：双随机矩阵表示推荐列表；位置基础观察模型（PBM）；交替 Frank‑Wolfe 优化框架；NSW 与 α‑SW 目标函数；Sinkhorn 正则化求解线性规划；与基准方法（Naive、Prod、TU、IterLP）对比。

**📊 数据集**

数据集：① 合成数据（不同受欢迎度 λ、两种检验函数 log、inv）；② 日本在线交友平台 200 男 200 女 的交互数据；③ Speed Dating 实验数据（约 270 男 270 女）。

**📈 对比分析**

与基准方法比较：SW 方案匹配率最高但公平性差；NSW 在保持匹配率相近的同时几乎消除嫉妒，Gini 指数显著下降；α‑SW 通过 α 控制公平-效率折中；Sinkhorn 方案在大规模实例上速度提升数倍且公平度保持优良。实验显示 NSW 和 Sinkhorn‑NSW 在公平性与效率上均优于传统方法。

**⚠️ 局限性**

局限性：① 缺乏规模达到百万级的公开匹配平台数据；② Sinkhorn 算法虽加速但在超大规模下仍需较长时间；③ 假设偏好概率在整个过程固定，未考虑在线更新与实时学习；④ 对 NSW 的理论近似保证尚不完整。

---

## 710. Breaking the Data Barrier in Learning Symbolic Computation: A Case Study on Variable Ordering Suggestion for Cylindrical Algebraic Decomposition

**arXiv ID:** 2601.13731 | [PDF](https://arxiv.org/pdf/2601.13731v1)

**作者:** Rui-Juan Jing `[一作]` (Jiangsu University), Changbo Chen `[通讯]` (Chinese Academy of Sciences)

**通讯引用:** 1445 | [OpenAlex ID](https://openalex.org/A5011795147)

**关键词:** `847a60d8-a755-47af-ba5d-c5236b9e3083` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76`

**🎯 论文内容**

利用预训练与微调的Transformer模型解决CAD变量顺序选择的稀缺数据问题。

**💡 创新点**

提出一套与CAD紧密关联的预训练任务，通过海量数据预训练并微调以提升变量排序准确性。

**🔧 技术方法**

采用Transformer架构、专用tokenization、预训练任务（如指数向量、ie_11、re_4等）以及fine‑tune策略。

**📊 数据集**

使用公开随机CAD数据集DQ‑3、DQ‑4、增强版DQ‑4b，以及SMT真实数据集。

**📈 对比分析**

与多种启发式方法及未预训练Transformer对比，预训练+微调模型在准确率与CAD运行时间上显著优于传统启发式，最快可达2×速度提升。

**⚠️ 局限性**

预训练任务对结果集特征的准确率仍偏低，多阶段预训练未能进一步提升效果；模型在学习更复杂特征时仍有限，需更大数据或更深模型进一步突破。

---

## 711. GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark

**arXiv ID:** 2601.13711 | [PDF](https://arxiv.org/pdf/2601.13711v1)

**作者:** Lotta Kiefer `[一作]` (University of Technology Nuremberg), Steffen Eger `[通讯]` (University of Technology Nuremberg)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出德国语作家身份验证（AV）基准GerAV，包含60万+文本对。

**💡 创新点**

首次构建大规模、跨域、多源的德国语AV基准，并系统评估LLM。

**🔧 技术方法**

使用大语言模型（Gemma‑3、Llama‑3.1/3.2、Qwen‑2.5）并进行LoRA微调。

**📊 数据集**

数据来自德国Reddit（分为in‑domain、cross‑domain、profile‑based）与Twitter，混合数据。

**📈 对比分析**

与传统特征、神经、跨语言基线以及零样本LLM比较，微调模型平均F1达0.83，显著优于基线与GPT‑5。

**⚠️ 局限性**

缺乏解释性、内容偏倚评估、人类评估以及对其他语言的扩展。

---

## 712. ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins

**arXiv ID:** 2601.13706 | [PDF](https://arxiv.org/pdf/2601.13706v1)

**作者:** Xinhao Liu `[一作]` (University of Electronic Science and Technology of China), Nirwan Ansari `[通讯]` (New Jersey Institute of Technology)

**通讯引用:** 26131 | [OpenAlex ID](https://openalex.org/A5008864376)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `64443552-63e0-44b5-906f-d90fe95c5a1b` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

开发了一个训练‑free、实时流式 3D 重建系统 ParkingTwin，用于地下车场数字孪生，提供精确几何和高保真纹理；

**💡 创新点**

创新点包括：①利用 OSM 语义先验直接生成 TSDF 结构，消除几何不确定性；②基于四模几何约束的动态车辆检测与剔除；③在 CIELAB 感知空间中进行照明鲁棒纹理融合，并加入深度梯度加权与边缘保持；

**🔧 技术方法**

采用的技术包括 OSM 向量图与 LiDAR 对齐、TSDF 表示、RGB‑D 视图投影、LAB 颜色空间转换、深度梯度加权、双边平滑以及轻量级 GPU 并行实现；

**📊 数据集**

使用的实测数据集为 ICPARK（地下车场约 68,000 m²），包含 ZED 立体相机 RGB‑D 序列、机器人位姿、OSM 地图及车辆掩码；

**📈 对比分析**

与 3DGS 与 ESLAM 对比，ParkingTwin 在 SSIM、PSNR、LPIPS 上分别为 0.87、30.1 dB、0.13，显著优于对手；运行帧率 30+ FPS、VRAM 仅 6 GB、处理速度提升约 15×，可在 GTX 1660 上实现实时重建；

**⚠️ 局限性**

局限性：仅能重建地面结构，屋顶/天花板无法建模；需要事先将 OSM 与首帧姿态对齐，才可启动系统。

---

## 713. Generative Intent Prediction Agentic AI empowered Edge Service Function Chain Orchestration

**arXiv ID:** 2601.13694 | [PDF](https://arxiv.org/pdf/2601.13694v1)

**作者:** Yan Sun `[一作]` (Beijing University of Posts and Telecommunications), Xuesong Qiu `[通讯]` (Beijing University of Posts and Telecommunications)

**通讯引用:** 4840 | [OpenAlex ID](https://openalex.org/A5042944721)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一个基于生成式意图预测代理（GIPA）的边缘服务功能链（SFC）编排框架，能够在用户意图不完整或隐式时主动预测并优化SFC部署。

**💡 创新点**

核心创新在于构建多维意图空间（功能、QoS、资源）并利用生成扩散模型（GDM）进行无标签的隐式意图预测，随后将预测结果作为全局提示嵌入SFC编排模型，实现预判式服务迁移与部署。

**🔧 技术方法**

使用了大语言模型（DeepSeek‑R1 7B）进行意图理解，生成扩散模型（GDM）做意图预测，PPO强化学习训练SFC编排器，以及多头自注意力网络与注意力解码器完成节点选择。

**📊 数据集**

采用Gemini‑3 Pro自动生成约4000条多场景自然语言指令作为训练样本，并在自建的Python模拟边缘网络环境中评估模型。

**📈 对比分析**

与基线方法IMAAC、MTRL以及简单的最佳努力（BE）进行对比，实验显示GIPA在并发任务数增加时平均执行延迟最低、服务成功率最高，特别是导航与移动相关场景提升显著。

**⚠️ 局限性**

局限性包括依赖于自制的合成数据，缺乏真实用户隐式意图标签；扩散模型训练成本高；在极端网络拥塞或节点失效时仍可能出现预测误差导致迁移失败。

---

## 714. Ultra-Lightweight Network for Ship-Radiated Sound Classification on Embedded Deployment

**arXiv ID:** 2601.13679 | [PDF](https://arxiv.org/pdf/2601.13679v1)

**作者:** Sangwon Park `[一作]` (Gangneung-Wonju National University), Sangwook Park `[通讯]` (Gangneung-Wonju National University)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出一种轻量化船舶辐射声音分类模型 ShuffleFAC，用于在资源受限的海事监测系统中实现实时识别。

**💡 创新点**

创新点在于将频率感知卷积与 ShuffleNet 风格的可分离卷积骨干结合，构建了 Frequency‑Adaptive Separable Convolution（FASC）模块，既保持频域敏感性，又显著降低参数量与计算量。

**🔧 技术方法**

采用的技术包括：log‑Mel 频谱预处理、频率感知块（频率位置编码+通道注意）、FASC、分组卷积、通道洗牌、平均池化、批归一化和 ReLU，训练时使用交叉熵损失与 Adam 优化器。

**📊 数据集**

使用的数据集为 DeepShip，包含约 47 小时来自 265 艘船舶的真实水下录音，按文件级划分为训练/验证/测试集，并提取 3 s 声片的 log‑Mel 频谱。

**📈 对比分析**

在与 FAC、SCAE、MobileNet、ShuffleNet、MicroNet 等轻量化基线同样的训练/测试协议下对比，ShuffleFAC（γ=16）取得宏 F1≈71.45%，仅 39 K 参数、3.06 M MACs，Raspberry Pi5 上平均推理时间 6.05 ms，较 MicroNet0 提升 1.82 % F1、模型大小减 9.7×、推理速度快 2.5×。

**⚠️ 局限性**

局限性包括：在更严格的记录级划分下整体准确率相对较低；仅在 DeepShip 数据集验证，缺乏跨数据集泛化评估；对极端海洋噪声环境的鲁棒性尚未充分验证；虽然已减少张量操作开销，但在更小模型规模时性能仍会受到限制。

---

## 715. Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting

**arXiv ID:** 2601.13665 | [PDF](https://arxiv.org/pdf/2601.13665v1)

**作者:** Mounika Kanulla `[一作]` (SRM University), Vivek Yelleti `[通讯]` (SRM University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `e0540dec-d77f-42db-94ae-d039248f6393` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

构建自采蔬菜图片数据集，并提出结合CNN-LSTM和CNN-DeiT Transformer的多任务融合模型，实现蔬菜品种分类、腐败程度检测与保质期预测。

**💡 创新点**

创新点在于：①针对同一图像同时完成分类、检测与回归的多任务学习；②通过CNN+Transformer与CNN+LSTM的融合提升局部与全局特征建模；③引入LIME实现模型可解释性；④在噪声数据上进行鲁棒性评估。

**🔧 技术方法**

使用的技术包括：MobileNetV2、DeiT Transformer、LSTM、特征拼接融合、交叉熵+MSE损失、Adam优化器、LIME可视化、Flask部署。

**📊 数据集**

使用自行构建的蔬菜日常腐败进程图像数据集，包含8种蔬菜、3种腐败级别、每日多张照片，另外人工添加噪声得到噪声集。

**📈 对比分析**

与单一CNN、VGG16、ResNet50、Capsule网络等基线模型以及各融合组合进行比较；在原始数据上CNN+DeiT取得蔬菜分类F1 0.98、腐败检测F1 0.61、MSE 3.58、SMAPE 41.66；在噪声数据上同模型F1 0.97、F1 0.67、MSE 5.96、SMAPE 44.68，优于其他方案。

**⚠️ 局限性**

局限性包括：腐败检测F1相对较低；数据集规模有限且仅覆盖8种蔬菜；模型对极端噪声或不同光照条件仍有一定性能下降；缺乏跨域或大规模真实环境验证。

---

## 716. Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning

**arXiv ID:** 2601.13657 | [PDF](https://arxiv.org/pdf/2601.13657v1)

**作者:** Myong-Yol Choi `[一作]` (Ulsan National Institute of Science and Technology), Hyondong Oh `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 3319 | [OpenAlex ID](https://openalex.org/A5022579538)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出一种利用单一LiDAR与深度强化学习控制器，实现通信自由无人机群集群导航的完整系统。

**💡 创新点**

创新点在于引入隐式领导者-跟随者框架，仅通过局部LiDAR感知实现目标导向的协同运动，并成功实现从仿真到真实环境的无通信迁移。

**🔧 技术方法**

技术实现包括LiDAR点云聚类与EKF跟踪、点云下采样、PPO训练的actor‑critic网络以及端到端的感知‑决策管线。

**📊 数据集**

使用数据集：Nvidia Isaac Sim 中的 OmniDrones 仿真环境（随机障碍密度与两个测试环境），以及真实实验中的五架配备 Livox Mid‑360 LiDAR 与 Jetson Orin NX 的定制无人机。

**📈 对比分析**

与 PACNav、VPF、DAgger 等基线方法进行对比，实验表明在复杂障碍环境中成功率达 72%，任务进度 88%，相较基线提升 20% 以上。

**⚠️ 局限性**

局限性包括 LiDAR 垂直视场受限导致在大队伍与狭窄通道中难以通过，以及缺乏对更大规模三维空间的充分利用。

---

## 717. TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation

**arXiv ID:** 2601.13653 | [PDF](https://arxiv.org/pdf/2601.13653v1)

**作者:** Xingjian Wu `[一作]` (East China Normal University), Bin Yang `[通讯]` (East China Normal University)

**通讯引用:** 10449 | [OpenAlex ID](https://openalex.org/A5001216674)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出一种基于工具增强的时序推理框架TimeART，利用LLM与21个高性能时序分析工具协同完成时序问答与预测；

**💡 创新点**

创新点在于①构建100k的Expert ReAct轨迹数据集TimeToolBench；②设计四阶段训练策略，让模型先学习工具边界、再学习策略、通过自我反思提升决策；③把LLM与专用时序工具无缝集成，实现代理式时序推理；

**🔧 技术方法**

使用LLM（Qwen-3 8B）+LoRA微调、ReAct式交互、工具调用（如LightGTS、DADA）、四阶段训练（工具边界、策略学习、自我反思）以及LoRA+GPU并行训练；

**📊 数据集**

主要使用MTBench、TimeMQA两大时序问答基准，以及构造的TimeToolBench（100k轨迹），并在金融、气象等领域的公开数据上进行评测；

**📈 对比分析**

与多种闭源（GPT‑4o、Gemini、Claude等）和开源（DeepSeek‑R1‑7B、Llama3‑8B、Mistral‑7B、ChatTS‑7B）模型比较。TimeART在MTBench与TimeMQA上均实现或逼近SOTA，特别在多选题、股票/温度预测等任务上大幅提升准确率/误差（如MAE降至5%~68%）；

**⚠️ 局限性**

局限性包括：①对工具的依赖，若工具覆盖不全或精度不足仍受限；②对极长序列或多变量时序的感知能力尚待提升；③训练成本仍较高，且自我反思仍需人工验证；④可能存在工具调用不当导致的错误推理。

---

## 718. Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search

**arXiv ID:** 2601.13719 | [PDF](https://arxiv.org/pdf/2601.13719v1)

**作者:** Xinlei Yin `[一作]` (University of Science and Technology of China), Yan Lu `[通讯]` (Microsoft Research Asia)

**通讯引用:** 19678 | [OpenAlex ID](https://openalex.org/A5035278528)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种名为HAVEN的统一框架，用于长视频理解，通过整合视听实体一致性和分层视频索引与代理搜索，实现连贯和全面的推理。

**💡 创新点**

创新点在于引入了视听实体一致性机制和分层信息数据库，支持多层次的动态检索和推理，从而提高了长视频的语义一致性和叙事连贯性。

**🔧 技术方法**

使用了代理搜索机制、自动语音识别（ASR）、说话人分离、以及大型视觉语言模型（VLM）等技术。

**📊 数据集**

在多个长视频理解基准上进行验证，包括LVBench、Video-MME、LongVideoBench和EgoSchema等数据集。

**📈 对比分析**

与现有基线方法相比，HAVEN在LVBench上达到了84.1%的整体准确率，尤其在推理类别中表现突出，达到了80.1%。

**⚠️ 局限性**

局限性在于该方法可能在处理极端复杂的长视频内容时仍然面临挑战，尤其是在多轮检索和推理的效率方面。

---

## 719. Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff

**arXiv ID:** 2601.13717 | [PDF](https://arxiv.org/pdf/2601.13717v1)

**作者:** Zehan Li `[一作]` (University of Chicago), Xinyu Pi `[通讯]` (University of California, San Diego)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在大规模回顾性预测实验中，系统评估了“模拟无知”(Simulated Ignorance, SI) 是否能与真实无知(True Ignorance, TI) 等价，发现即便使用时间截断提示、链式思维与强化学习优化的推理模型，SI 仍会显著保留对已知结果的隐性知识，导致预测准确率明显高于 TI；

**💡 创新点**

首次将 SI 与 TI 进行直接对比，量化并证实了提示无法真正“倒退”模型知识状态，揭示了回顾性评估中潜在的数据泄漏问题；

**🔧 技术方法**

采用了时间截断提示、链式思维(CoT) 推理、强化学习优化的推理模型、Brier 分数评估以及自动化推理轨迹审计；

**📊 数据集**

使用了 477 个来自 Metaculus 2023–2025 年度竞赛的二元预测问题；

**📈 对比分析**

通过在同一问题集上比较 SI 与 TI 的 Brier 分数，发现即使在最优提示下 SI 与 TI 之间仍存在约 52% 的性能差距，表明 SI 的预测质量远低于 TI；

**⚠️ 局限性**

仅针对提示级别的知识抑制进行评估，未探索参数级别的“无学习”方法，且实验集中在二元问题，可能未能涵盖所有预测形式的挑战。

---

## 720. Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs

**arXiv ID:** 2601.13707 | [PDF](https://arxiv.org/pdf/2601.13707v1)

**作者:** Yujin Jo `[一作]`, Taesup Kim `[通讯]` (Seoul National University)

**通讯引用:** 2395 | [OpenAlex ID](https://openalex.org/A5065728469)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种无训练、单前向传递的对抗性注意力引导方法——Attention-space Contrastive Guidance（ACG），用于在视觉-语言模型中抑制幻觉并增强视觉依赖；

**💡 创新点**

创新点在于将幻觉抑制视为注意力空间的对比引导，通过在单一前向过程中构造条件与无条件注意力路径，并对无条件路径进行正交化纠正，以消除语言偏置；

**🔧 技术方法**

使用了自注意力层内的注意力对比、掩码近似无条件路径、文本正交化（Orthogonalization）以及单前向的内部引导机制；

**📊 数据集**

在MS COCO基础上的CHAIR、POPE以及MMHal-Bench等幻觉评估数据集上进行实验；

**📈 对比分析**

与logit‑level对比解码、分类器自由引导、潜在引导等三类基线比较，ACG在CHAIR、POPE上实现了最优或最接近最优的幻觉率，同时推理延迟仅为基线的1.19倍，明显低于需要多次前向传递的方法；

**⚠️ 局限性**

限制在于对γ（引导强度）和层级选择的敏感性；若γ设置不当会导致准确性下降，且单前向掩码近似仍可能在视觉信息稀缺时产生误差。

---

## 721. Criminator: An Easy-to-Use XR "Crime Animator" for Rapid Reconstruction and Analysis of Dynamic Crime Scenes

**arXiv ID:** 2601.13689 | [PDF](https://arxiv.org/pdf/2601.13689v1)

**作者:** Vahid Pooryousef `[一作]` (Monash University), Tim Dwyer `[通讯]` (Monash University)

**通讯引用:** 5784 | [OpenAlex ID](https://openalex.org/A5008149778)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

开发了一款名为 Criminator 的 XR 工具，帮助非专业人员快速构建并重现动态犯罪现场动画，用于假设检验、演示和培训。

**💡 创新点**

创新点在于：①基于协同设计的交互式动画框架；②简化的轨道/槽/效果面板，支持即时录制与回放；③利用手机 3D 扫描和 Gaussian Splatting 生成逼真环境；④在 XR 环境中实现全身跟踪动画，无需专业建模与动画软件。

**🔧 技术方法**

技术包括：Meta Quest Pro 虚拟现实、Unity 2022.3、Mixed Reality Toolkit 3、Meta Movement SDK、Gaussian Splatting 渲染、全身跟踪、轨道/槽/效果编辑器、实时录制/播放。

**📊 数据集**

数据集为：实验场景的手机 3D 扫描点云（使用 iPhone 15 Pro Max Scaniverse 合并），以及由受试者录制的角色动画（6 名专业人士 + 12 名非专业参与者）。

**📈 对比分析**

比较方法：对比受过培训的法医学专家与未受训的普通参与者在观察任务与动画创作任务中的 SUS、NASA‑TLX、动画质量评分、位置/注视模式等指标。结果显示：①两组在可用性评分相近，②动画创作的准确度在专业组略高但差异不显著，③总体可用性符合平均水平，工作负荷略高于观察任务。

**⚠️ 局限性**

局限性包括：①样本规模有限，尤其专业组只有 6 人；②动画质量受 Meta Movement SDK 低体位关节跟踪不精确限制；③缺乏对司法可采性的完整验证（需进一步法律评估和数据源可追溯性）；④工具仍需改进界面、语音/手势交互和误差可视化，且在隐私法规下的 3D 数据共享受限。

---

## 722. Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games

**arXiv ID:** 2601.13709 | [PDF](https://arxiv.org/pdf/2601.13709v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 723. ORCA -- An Automated Threat Analysis Pipeline for O-RAN Continuous Development

**arXiv ID:** 2601.13681 | [PDF](https://arxiv.org/pdf/2601.13681v1)

**作者:** Felix Klement `[一作]` (University of Passau), Stefan Katzenbeisser `[通讯]` (University of Passau)

**通讯引用:** 9665 | [OpenAlex ID](https://openalex.org/A5036400192)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一套自动化框架与工具，对 O‑RAN 组件进行安全分析，并生成 CVSS 风险评分。

**💡 创新点**

创新点在于将威胁→CAPEC 语义映射与 CVE 召回相结合，采用嵌入语义相似度阈值筛选，实现在不人工干预下的高细粒度风险评估。

**🔧 技术方法**

主要技术包括自然语言处理（嵌入式语义表示、相似度计算）、图像识别（提取 CAPEC‑WMI）、爬取与对接 CVE/CWE 数据库的 API，和 CVSS 评分公式的自动化实现。

**📊 数据集**

使用的数据集包括：O‑RAN 联盟公布的通用威胁清单、CAPEC 公开数据库、CVE/NIST CVE 数据库以及 NIST CWE 数据。

**📈 对比分析**

通过对比手工评估的风险分值与自动化提取的 CVSS 平均分，展示了自动方法在一致性与可重复性上的优势；实验表明，加入/剔除重复 CVE 对整体分值影响微小，整体评分差异在 0.02–0.09 之间。

**⚠️ 局限性**

局限性：依赖阈值设定（cos_sim、过滤策略）导致匹配结果不确定；对 CVE 数据完整性与时效性有限；缺乏对每个威胁的细节验证，难以直接评估绝对准确性。

---

## 724. Towards robust long-context understanding of large language model via active recap learning

**arXiv ID:** 2601.13734 | [PDF](https://arxiv.org/pdf/2601.13734v1)

**作者:** Chenyu Hui `[一作]` (Xi'an Jiaotong University), Chenyu Hui `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 14087 | [OpenAlex ID](https://openalex.org/A5083097302)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了主动回顾学习（Active Recap Learning，ARL）框架，通过在继续预训练和推理阶段生成并利用摘要来提升大模型在长文本中的理解与记忆能力。

**💡 创新点**

创新点包括：① 通过长短上下文预测概率比（Long‑Short Gap）精确识别对远程信息依赖度高的关键标记；② 设计两阶段检索与摘要流程，将最有助于预测的早期段落提炼为可插入的“回顾”摘要；③ 在推理时引入递归记忆机制，动态生成并压缩摘要，避免上下文爆炸。

**🔧 技术方法**

技术手段主要有：继续预训练（Fine‑tuning），基于损失的段落检索，使用LLM（如Qwen 1.5、RWKV‑7）进行摘要重写与压缩，动态分块与特殊标签插入，及使用vLLM、DeepSpeed 等加速推理与训练。

**📊 数据集**

数据集包括：ProLong（用于继续预训练）、RULER（含NIAH、QA子任务）和LongBench（多域长文本评测）。

**📈 对比分析**

与原始模型及基于位置编码扩展的长文本扩容方法对比，ARL 在 RULER 上实现了最高 49.1%（RWKV‑7）和 159.1%（Qwen‑1.5）的提升，LongBench 上平均提升约 9.4%（Qwen‑1.5）和 9.5%（RWKV‑7），尤其在摘要任务上提升 19–47%。

**⚠️ 局限性**

局限性包括：① 需要额外的预训练样本与算力；② 对段落检索与摘要质量依赖较大，可能在信息稀疏或语义不连贯的文本中效果有限；③ 目前主要验证在 Transformer 与 RWKV 体系结构，跨架构通用性尚待进一步探索。

---

## 725. OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents

**arXiv ID:** 2601.13722 | [PDF](https://arxiv.org/pdf/2601.13722v1)

**作者:** Yulin Hu `[一作]` (Harbin Institute of Technology), Bing Qin `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 15641 | [OpenAlex ID](https://openalex.org/A5017671620)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究了记忆增强对话系统中“过度个性化”的现象，提出了OPBench基准并提供了1700个人工校验实例。

**💡 创新点**

首次系统化量化过度个性化的三类表现（不相关、阿谀奉承、重复），并提出轻量级的Self‑ReCheck过滤模块。

**🔧 技术方法**

结合大语言模型（GPT‑4o‑mini、Gemini‑2.5‑flash、Qwen3 等）与多种记忆检索方式（RAG、MemU、MEMOS 等）以及注意力与词嵌入分析。

**📊 数据集**

采用 LoCoMo 长时序对话数据构建用户档案，随后生成任务并人工审核，构成 OPBench。

**📈 对比分析**

在 36 种配置上评估，发现加入记忆后过度个性化下降 26.2%–61.1%；Self‑ReCheck 可将该指标平均提升 29%，同时保持甚至提升个性化性能。

**⚠️ 局限性**

主要局限在于使用合成对话数据、单轮文本评估以及仅限英语，未覆盖多轮、多模态及跨语言场景。

---

## 726. Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles

**arXiv ID:** 2601.13705 | [PDF](https://arxiv.org/pdf/2601.13705v1)

**作者:** Maria Lymperaiou `[一作]` (National Technical University of Athens), Athanasios Voulodimos `[通讯]` (National Technical University of Athens)

**通讯引用:** 6130 | [OpenAlex ID](https://openalex.org/A5062640206)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

对视觉谜题作为评估大型视觉语言模型（LVLM）推理能力的框架进行系统综述与归纳，提出统一的谜题抽象和五类推理维度分类；

**💡 创新点**

提出了视觉谜题的统一抽象框架，并将其按归纳、类比、算法、演绎和几何/空间推理五个维度进行系统分类，指出“幻觉推理”与“解释‑执行”鸿沟；

**🔧 技术方法**

主要采用文献综述、元分析与基准对比的方式，对现有视觉谜题基准进行整理与评估；

**📊 数据集**

整合了ARC、VisualPuzzles、Raven/PGM、Bongard、PUZZLES、LogicVista、Sudoku‑Bench、GeoSketch等多种视觉谜题数据集；

**📈 对比分析**

通过汇总各基准结果并归纳模型弱点，未给出统一实验，但指出LVLM在推理深度、跨域泛化和空间推理上表现不足；

**⚠️ 局限性**

局限性包括对表面视觉特征的过度依赖、缺乏不确定推理（abductive、lateral）支持、缺少长序推理训练目标、解释可信度低，以及缺少系统化的多模态推理框架。

---

## 727. Performance and Complexity Trade-off Optimization of Speech Models During Training

**arXiv ID:** 2601.13704 | [PDF](https://arxiv.org/pdf/2601.13704v1)

**作者:** Esteban Gómez `[一作]` (Aalto University), Tom Bäckström `[通讯]` (Aalto University)

**通讯引用:** 1568 | [OpenAlex ID](https://openalex.org/A5052130850)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了一种基于特征噪声注入的动态复杂度层方法，在训练过程中实现模型性能与计算复杂度的联合优化。

**💡 创新点**

创新点在于使用可微分的噪声插值使层维度连续化，动态调整网络容量，避免传统剪枝后处理，且单次训练即可完成性能与复杂度的权衡。

**🔧 技术方法**

使用了特征噪声注入、动态/自适应复杂度层（DCL/ACL）、L2 正则化 λ、梯度下降优化、卷积递归网络、ResNet34 以及相应的 PyTorch 实现。

**📊 数据集**

实验数据集包括：合成滤波器实验、VAD 任务使用 EARS + DNS/AudioSet + VCTK+ESC-50、音频反欺骗任务使用 ASVspoof 2019 LA。

**📈 对比分析**

与固定复杂度基线及公开 VAD（Silero VAD）进行比较。VAD 任务复杂度可降约 80%，EER 仅略降；音频反欺骗任务 EER 从 6.26% 降至 2.53%，模型大小降约 90%，性能与挑战赛前十同水平。

**⚠️ 局限性**

局限性包括：若最小 λ 设得过低易导致性能下降；方法需对网络结构做改造，适配性受限；对特定硬件无直接优化；跨任务泛化仍需进一步验证。

---

## 728. IGAA: Intent-Driven General Agentic AI for Edge Services Scheduling using Generative Meta Learning

**arXiv ID:** 2601.13702 | [PDF](https://arxiv.org/pdf/2601.13702v1)

**作者:** Yan Sun `[一作]` (Beijing University of Posts and Telecommunications), Qihui Wu `[通讯]` (Nanjing University of Aeronautics and Astronautics)

**通讯引用:** 11375 | [OpenAlex ID](https://openalex.org/A5100785098)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了 IGAA 框架，利用 Agentic AI 在边缘网络中实现通用的服务调度与资源分配。

**💡 创新点**

创新点包括：① 将自然语言意图与网络资源通过 N–S–I 矩阵映射成可计算的向量；② 设计 easy‑to‑hard 生成式元学习流程，结合 RCETL 与 APOTL 两种迁移学习算法；③ 引入生成式意图重放（GIR）机制与多维度评估纠正模型，抑制 LLM 幻觉与灾难性遗忘。

**🔧 技术方法**

采用的技术有：大型语言模型（LLM）进行意图理解与场景生成；生成式元学习与因果效应感知迁移学习（RCETL）；动作潜能最优迁移学习（APOTL）与 Kantorovich 距离；变分自编码器（VAE）实现 GIR；多指标评估模型用于反馈与自我纠正。

**📊 数据集**

使用自建的合成服务场景数据集（通过 LLM 生成的意图和对应资源需求），实验在模拟的边缘网络环境中完成，未采用公开工业数据集。

**📈 对比分析**

通过与四种专门场景的调度算法（IMAAC、PPOCO、TSS、Best Effort）在多场景交叉、适应新服务、可扩展性实验中进行对比；在意图满足率、任务成功率和平均延迟等指标上，IGAA 与场景特定算法相差不超过 3.81%，在适应新服务时提升 19.19%，可扩展到 10 种资源/服务仍保持 90% 以上的性能。

**⚠️ 局限性**

局限性在于：对大语言模型和生成式元学习的计算开销较高；在极大资源/服务维度下仍可能出现性能下降；评估指标主要基于模拟环境，缺乏真实边缘网络部署验证；幻觉与重放机制仍需进一步稳健性提升。

---

## 729. Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation

**arXiv ID:** 2601.13698 | [PDF](https://arxiv.org/pdf/2601.13698v1)

**作者:** Arjun Nichani `[一作]` (University of California), Haewon Jeong `[通讯]` (University of California)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `39fd911c-56a4-425d-a2f9-8038ad3b6e21` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

研究公平性、隐私与准确性的三元关系，提出噪声化Chernoff差异指标并通过密度比估计实现Chernoff信息估计器。

**💡 创新点**

首次将Chernoff信息与公平-准确-隐私三元关系关联，提出噪声Chernoff差异作为三者的统一度量，并设计CINE神经估计方法。

**🔧 技术方法**

利用信息理论中的Chernoff信息、密度比估计（DRE-∞）和神经网络CINE、Gaussian输入噪声实现差分隐私、以及标准的公平度量（等机会）等技术。

**📊 数据集**

在合成高斯数据、Gaussian混合、Adult收入数据以及MNIST降维表示等多种数据集上进行实验。

**📈 对比分析**

与闭式解和先前的Chernoff信息估计器对比，CINE在低到中维（≤20维）数据上误差极低，能准确捕捉公平-准确曲线斜率，实验表明其在不同噪声水平下能预测公平性与准确性的关系。

**⚠️ 局限性**

在高维、非连续特征、以及非输入噪声的其他隐私机制下效果下降，且缺乏完整的高维理论分析与对其他隐私算法的适配。

---

## 730. Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning

**arXiv ID:** 2601.13690 | [PDF](https://arxiv.org/pdf/2601.13690v1)

**作者:** Yue Guo `[一作]` (Baidu Inc), Bo Yuan `[通讯]` (Baidu Inc)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了临床诊断推理数据结构CDRD并训练Dr. Assistant模型，提升诊断推理与询问能力。

**💡 创新点**

提出CDRD结构及三阶段构建管线，使用两阶段SFT+RL训练与专门奖励函数，并创建诊断推理与询问基准。

**🔧 技术方法**

使用LLM（Qwen3‑14B）进行监督微调，随后采用强化学习（DAPO）结合自定义奖励函数（推理与询问分量及CDRD一致性）。

**📊 数据集**

基于内部指南构建约11条CDRD（≈60种疾病），生成4400 QA对和36688轮对话；评测基准包含242例病例和147轮对话。

**📈 对比分析**

与多款开源/闭源LLM对比，ICD召回率最高，提升13.59%超HuatuoGPT‑o1‑72B；医生满意度显著提高，性能优于大多数对手。

**⚠️ 局限性**

需要人工医生审校CDRD，规模受限；评测基准覆盖部门有限；奖励函数启发式；未验证在真实EHR或开放式对话中的表现。

---

## 731. HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference

**arXiv ID:** 2601.13684 | [PDF](https://arxiv.org/pdf/2601.13684v1)

**作者:** Zhiyuan Shi `[一作]` (Zhejiang University), Wenxiao Wang `[通讯]` (Zhejiang University)

**通讯引用:** 3116 | [OpenAlex ID](https://openalex.org/A5101701726)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出无训练的异构缓存框架 HeteroCache，动态压缩大型语言模型的 KV 缓存以降低内存占用并加速推理。

**💡 创新点**

创新点在于利用注意力头的时间异质性和空间冗余对头进行分类，分配不同的缓存预算并通过异步检索及时恢复关键上下文，解决了传统动态压缩方法粗粒度分配和高 I/O 开销的问题。

**🔧 技术方法**

采用了头级稳定性与相似度评估、基于权重的预算分配策略、分层 GPU/CPU 存储以及基于 pivot 头的异步按需检索技术。

**📊 数据集**

在 Llama‑3.1‑8B、Qwen2.5‑14B、DeepSeek‑R1‑Distill‑Llama‑8B 等模型上，使用 LongBench、LongBench v2、InfiniteBench、NIAH 等长文本基准进行评测。

**📈 对比分析**

与 FullAttention、Quest、ShadowKV、OmniKV、CAKE 等压缩方法对比，HeteroCache 在 50% 或 30% 缓存压缩率下仍接近全精度，解码速度提升约 3×，与 OmniKV 的 I/O 延迟相比显著提升 40×，在各基准任务上均位居领先或接近最优。

**⚠️ 局限性**

目前实现仅基于 PyTorch，缺乏自定义 CUDA 核心，导致未能充分释放理论加速潜力；此外异步检索的隐藏效果受限于 CPU‑GPU 互联（PCIe）带宽，在低带宽环境下可能无法完全抹去 I/O 延迟。

---

## 732. Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation

**arXiv ID:** 2601.13683 | [PDF](https://arxiv.org/pdf/2601.13683v1)

**作者:** Boyuan Cao `[一作]` (Fudan University), Hongming Shan `[通讯]` (Fudan University)

**通讯引用:** 4164 | [OpenAlex ID](https://openalex.org/A5049086157)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种动态差分线性注意力（DDLA）机制，并将其集成进线性扩散 Transformer（LiT）模型，实现高质量图像生成。

**💡 创新点**

创新点包括：①动态投影解耦 token 表示，提升匹配精度；②为每个 token 动态分配核函数以捕捉细粒度语义差异；③利用差分因子减弱冗余信息，增强查询‑键检索鲁棒性；④在此基础上构建全新的 DynDiff‑LiT，保持线性计算复杂度同时显著提升生成质量。

**🔧 技术方法**

技术手段主要是：线性注意力（kernel‑based attention）、动态路由投影、可学习核函数与差分因子、深度可分离卷积（depth‑wise convolution）增强特征多样性。

**📊 数据集**

使用 ImageNet‑1K 以及其 100 类子集作为主要评估数据集，实验在 256×256 和 512×512 分辨率下进行。

**📈 对比分析**

与 DiT、DiG、PixArt‑Σ、EDiT、Sana 等现有模型对比，使用 FID、sFID、IS、Precision/Recall、KID、sKID 等指标，DynDiff‑LiT 在所有指标上均超过或与 SOTA 相当，且推理成本与传统 quadratic attention 相比显著降低，尤其在更高分辨率（如 2048×2048）时优势更明显。

**⚠️ 局限性**

局限性：①差分因子初始化不当可能导致信息丢失；②动态路由与核函数分配增加了实现复杂度；③在极高分辨率或长序列场景下，虽然保持线性复杂度，但仍需进一步验证对极大 token 数的可扩展性。

---

## 733. CodeContests-O: Powering LLMs via Feedback-Driven Iterative Test Case Generation

**arXiv ID:** 2601.13682 | [PDF](https://arxiv.org/pdf/2601.13682v1)

**作者:** Jianfeng Cai `[一作]` (University of Science and Technology of China), Houqiang Li `[通讯]` (University of Science and Technology of China)

**通讯引用:** 25302 | [OpenAlex ID](https://openalex.org/A5078141810)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于反馈驱动的迭代框架，用LLM生成并不断优化程序竞赛题目的测试用例，最终构建高质量数据集CodeContests-O。

**💡 创新点**

创新点在于将测试用例生成从单向开放循环转为闭环迭代过程：利用已知正确与错误解的执行结果作为客观反馈，指导LLM逐步提升测试用例的保真度（TPR）与判别力（TNR）。

**🔧 技术方法**

核心技术包括LLM生成的生成器‑验证器（Generator‑Validator）程序、执行反馈收集与根因分析、基于搜索替换的生成器更新、上下文压缩与逻辑校验器（checker）共生成，以及RL训练（GRPO）评估。

**📊 数据集**

使用的主要数据集是公开的CodeContests竞赛题库，并在此基础上构造了CodeContests-O；对比数据集包括原始CodeContests、CodeContests+（不同复制倍数）以及HardTests。

**📈 对比分析**

通过对比TPR/TNR和LiveCodeBench上的Pass@1，CodeContests-O在迭代3次后达到TPR 89.37%/TNR 90.89%，显著优于其他数据集；在RL训练中，基于CodeContests-O的模型在Easy/Medium/Hard任务上分别提升至70.42%/26.56%/2.45%，整体提升约7.5%。

**⚠️ 局限性**

主要局限是迭代过程计算开销大，需要多轮LLM推理和代码执行；此外该框架仅用于补充已有题目的测试用例，无法从零生成新的题目描述。

---

## 734. Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging

**arXiv ID:** 2601.13677 | [PDF](https://arxiv.org/pdf/2601.13677v1)

**作者:** Carsten T. Lüth `[一作]` (German Cancer Research Center), Fabian Isensee `[通讯]` (German Cancer Research Center)

**通讯引用:** 14420 | [OpenAlex ID](https://openalex.org/A5072647800)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

设计并评估了一种名为ClaSP PE的主动学习查询策略，用于3D医学影像分割。

**💡 创新点**

通过类分层采样与指数衰减的功率噪声扰动，解决了传统不确定性方法在类别不平衡和早期冗余查询方面的局限。

**🔧 技术方法**

基于预测熵的不确定度评分，结合类分层抽样与对数尺度功率噪声调度；使用nnU-Net训练并在nnActive框架下进行评估。

**📊 数据集**

在nnActive基准的四个3D医学数据集（AMOS2022、Hippocampus、KiTS2021、ACDC）以及四个未见数据集（LiTS、WORD、Tooth Fairy 2、MAMA MIA）进行实验。

**📈 对比分析**

与随机、改进随机（前景感知随机）以及五种不确定度查询（PE、BALD、PowerBALD、SoftrankBALD、PowerPE）对比，ClaSP PE在AUBC、Final Dice和FG‑Eff指标上在24个实验设置中均显著优于随机及大多数基线。

**⚠️ 局限性**

受基准过拟合风险、依赖基础模型预测能力、需手动设定少量超参数、对不同查询设计或分割后端的适应性不确定、仅评估平均Dice而非边界指标等限制。

---

## 735. Reinforcement Learning for Opportunistic Routing in Software-Defined LEO-Terrestrial Systems

**arXiv ID:** 2601.13662 | [PDF](https://arxiv.org/pdf/2601.13662v1)

**作者:** Sivaram Krishnan `[一作]` (University of Adelaide), Jinho Choi `[通讯]` (University of Adelaide)

**通讯引用:** 17742 | [OpenAlex ID](https://openalex.org/A5022303970)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

研究了在低地球轨道（LEO）卫星网络与陆地网络集成的机会式路由问题，提出了基于软件定义网络（SDN）的残差强化学习框架，实现了在可用地面网关波动时将数据包转发到任何可达网关的动态路由策略。

**💡 创新点**

创新点在于：①将 SDN 控制层与强化学习相结合，利用 GEO 卫星的全局视角进行集中式决策；②采用残差学习方法，将传统的 Backpressure 路由作为基线，在其基础上加入可达网关信息的加权修正，从而兼顾网络稳定性与动态性；③在 LEO 卫星网络的快速拓扑变化和不确定的网关可用性下，仍能保持良好的吞吐率和延迟表现。

**🔧 技术方法**

使用的技术包括：软件定义网络（SDN）架构、残差强化学习（Residual RL）框架、Double Deep Q‑Network（DDQN）算法、Backpressure 路由基线、基于卫星轨道的可用性预测、以及离散动作空间的网络调度。

**📊 数据集**

主要使用的数据集为：Space‑Track 的 TLE 数据（卫星轨道）、2020 年全球人口密度（GSPW）数据（模拟地面流量）、以及地面网关的地理位置信息。

**📈 对比分析**

与 Backpressure、Equalize、No‑ISL、Max‑Weight、Random 等经典路由策略以及纯 DDQN 进行对比。实验结果显示：相较于 vanilla DDQN，残差策略平均队列长度下降 3.9%–18.1%；相较于 Backpressure，平均队列长度下降 1.6%–12.1%，峰值下降 5.3%–14.8%；在不同星座（Starlink、Iridium、OneWeb）和网关布局（单区、混合）下均表现出最优或接近最优的队列分布和 ECDF 曲线。

**⚠️ 局限性**

主要限制包括：①尚未在规模更大的百万级星座上验证可扩展性；②未考虑 GEO 控制器与 LEO 卫星之间的通信延迟；③未对缓冲区溢出进行建模，可能在极端拥塞情况下出现丢包。

---

## 736. Fusion Segment Transformer: Bi-Directional Attention Guided Fusion Network for AI-Generated Music Detection

**arXiv ID:** 2601.13647 | [PDF](https://arxiv.org/pdf/2601.13647v1)

**作者:** Yumin Kim `[一作]` (MIPPIA Inc), Seonghyeon Go `[通讯]` (MIPPIA Inc)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 Fusion Segment Transformer，利用双模态 Transformer 与门控融合实现全长音频 AI 生成音乐检测

**💡 创新点**

创新点在于结合内容与结构流的双向跨模态注意力与自适应门控融合层，显著提升对长时结构信息的捕捉

**🔧 技术方法**

技术包括 Transformer、双向交叉注意力、门控多模态单元、Muffin Encoder、Wav2vec 2.0、Music2vec、MERT、FXencoder 等特征提取器

**📊 数据集**

使用 SONICS（约9.6 万曲）和 AIME（1.2 万曲）两大数据集进行训练与评估

**📈 对比分析**

与基线和前期 Segment Transformer 对比，SONICS 上准确率最高 0.9999，AIME 上也获得最高 F1 与 AUC，整体性能显著提升

**⚠️ 局限性**

局限性包括对分段策略敏感、频域特征效果不佳、模型仍非端到端、对极端边界案例的鲁棒性待提升

---

## 737. SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation

**arXiv ID:** 2601.13732 | [PDF](https://arxiv.org/pdf/2601.13732v1)

**作者:** Andreas Wiedholz `[一作]` (XITASO GmbH), Tobias Huber `[通讯]` (XITASO GmbH)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `729e5870-4135-47f5-97f2-e3974d07b5dc` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

构建了一个基于ROS2的无人机语义分割演示系统，用于评估机器人软件在并发不确定性下的自适应能力。

**💡 创新点**

创新点在于：①支持多源并发不确定性且根源不明确的1:n症状–根源映射；②实现了四类常见自适应（重部署、激活/停用、通信切换、参数重设）；③提供了可插拔的管理子系统接口，便于公平比较不同自适应方法。

**🔧 技术方法**

核心技术包括ROS2与其生命周期节点、ResNet50‑based Deeplab‑V3深度学习模型、诊断工具、uncertainty‑injector脚本以及基于MAPE‑K的基线管理系统。

**📊 数据集**

使用SynDrone Dataset（Town 01）作为输入数据集，提供RGB和深度图像的预录制飞行序列。

**📈 对比分析**

通过对比基线管理系统与未管理情况下的指标来评估方法：IoU、系统停机时间、解决不确定性比例、反应时间和无用重部署次数；基线在20 s实验中平均IoU为0.86±0.24，平均反应时间1.65±0.99 s，平均重部署次数5.66±2.05。未管理系统IoU仅为0.47±0.02。

**⚠️ 局限性**

局限性包括：①未能检测所有WARNING级别的不确定性导致IoU方差较大；②重部署过于频繁且耗时；③示例聚焦于语义分割，其他机器人任务的通用性尚未验证。

---

## 738. Foundational VeriFast: Pragmatic Certification of Verification Tool Results through Hinted Mirroring

**arXiv ID:** 2601.13727 | [PDF](https://arxiv.org/pdf/2601.13727v1)

**作者:** Bart Jacobs `[一作]` (KU Leuven), Bart Jacobs `[通讯]` (KU Leuven)

**通讯引用:** 16938 | [OpenAlex ID](https://openalex.org/A5084226578)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

将 VeriFast 的验证结果通过提示镜像机制转化为 Coq 证明脚本，实现对 Rust 程序验证结果的形式化证明。

**💡 创新点**

提出了“提示镜像”技术，记录 VeriFast 符号执行的关键信息并在 Coq 中重放，构建了非形式化工具到形式化证明的桥梁，并首次在分离逻辑工具中实现基础化验证。

**🔧 技术方法**

采用 VeriFast 符号执行、Coq 与 Iris 分离逻辑、MIR（中间表示）转换、SMT Solver 自动化、逻辑堆模型等技术。

**📊 数据集**

没有使用大型数据集，示例仅为一个反转链表的 Rust 程序。

**📈 对比分析**

论文未进行实验比较或性能评估，仅给出示例程序的证明通过情况。

**⚠️ 局限性**

目前仅支持有限的 Rust 特性和 VeriFast 功能；未验证 axiomatic semantics、忽略某些 MIR 语句、未处理循环、结构体、泛型等，基础语义验证仍待完成。

---

## 739. SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories

**arXiv ID:** 2601.13713 | [PDF](https://arxiv.org/pdf/2601.13713v1)

**作者:** Aditya Bharat Soni `[一作]` (Carnegie Mellon University), Debojyoti Dutta `[通讯]` (Nutanix)

**通讯引用:** 1486 | [OpenAlex ID](https://openalex.org/A5113845539)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 SWE-Tester pipeline，利用开源大语言模型自动生成问题重现测试，并构建了 41K 条高质量训练实例。

**💡 创新点**

首创性地将开源 LLM 训练用于问题重现测试，设计两步工作流（代码定位+代码编辑）并采用 Search/Replace 补丁格式，显著提升开源模型在该任务上的表现。

**🔧 技术方法**

使用了 Qwen‑2.5 Coder Instruct（7B/14B/32B）、Llama3.1‑8B Instruct、Gemma3‑12B Instruct 等开源 LLM 进行监督微调；结合 BM25 与 LLM 重新排序实现代码定位，使用自一致性重排序的推理 scaffold 进行推理；代码编辑采用 Search/Replace 补丁格式。

**📊 数据集**

训练数据来自 2.6K 开源 GitHub 仓库的 41K 条问题‑PR 对，源自 SWE‑Gym、SWE‑Fixer、SWE‑Rebench 等公开数据集；评估基准使用 SWT‑Bench Verified（433 条 Python 任务）以及参考 Defects4J 等。

**📈 对比分析**

与基线（未微调 LLM）和公开闭源方法对比，使用可适用率、成功率、变更覆盖率三项指标评测；微调后模型成功率提升至 10% 以上，变更覆盖率提升至 21% 以上；更大模型、更多推理计算、更多训练数据均能持续提升性能。

**⚠️ 局限性**

局限性包括：仅针对 Python 仓库；代码编辑仍是瓶颈；相比闭源模型仍有性能差距；需要更好的定位与重排序技术来进一步提升效率。

---

## 740. DistilMOS: Layer-Wise Self-Distillation For Self-Supervised Learning Model-Based MOS Prediction

**arXiv ID:** 2601.13700 | [PDF](https://arxiv.org/pdf/2601.13700v1)

**作者:** Jianing Yang `[一作]` (University of Tokyo), Hiroshi Saruwatari `[通讯]` (University of Tokyo)

**通讯引用:** 7628 | [OpenAlex ID](https://openalex.org/A5003814223)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `8d10c613-917e-4880-9716-17789f50e119` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `9ce7179e-700c-4310-ac2b-91df50ded46e` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

研发了一种基于自监督模型层级token预测的MOS预测方法DistilMOS。

**💡 创新点**

通过将预训练SSL模型每层的隐藏表示聚类为token ID，并在MOS预测模型中加入自蒸馏token预测任务，缓解灾难性遗忘并提升泛化能力。

**🔧 技术方法**

使用k‑means聚类、Transformer自监督模型（Wav2Vec2/WavLM）、CNN‑BLSTM特征处理、Token MLP预测以及多任务损失（MSE+交叉熵）等技术。

**📊 数据集**

在BVCC（in‑domain）和SOMOS（zero‑shot）语音质量评测数据集上进行实验。

**📈 对比分析**

与SSL‑MOS基线、无token预测版本以及MSE蒸馏版本对比，DistilMOS在BVCC的SRCC、LCC、KTAU等指标显著提升，并在SOMOS的零射击评测中取得更高相关系数，显示出更好的性能与泛化。

**⚠️ 局限性**

受限于BVCC样本量有限，聚类结果可能对不同数据集不稳健；需要在更大或多源数据集上进一步验证和改进。

---

## 741. Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning

**arXiv ID:** 2601.13697 | [PDF](https://arxiv.org/pdf/2601.13697v1)

**作者:** Zhihang Yuan `[一作]` (Alibaba Cloud Computing), Lei Shi `[通讯]` (Alibaba Cloud Computing)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 GradFiltering 方法，通过在冻结的 GPT‑2 代理上使用 LoRA 组合训练，记录每个示例的梯度信息，计算梯度信噪比（G‑SNR）来进行数据选择。

**💡 创新点**

创新点包括：①利用 LoRA 组合构建轻量化代理实现梯度统计，无需构建完整梯度数据库；②提出 G‑SNR 结合梯度下降幅度与不确定性，兼顾学习进展与模型不确定性；③方法目标无关、可直接基于梯度实现，无需手工标签或任务专属奖励。

**🔧 技术方法**

使用技术包括 LoRA 参数高效微调、LoRA 组合（LoRA‑Ensemble）、梯度统计与梯度信噪比（G‑SNR）、LLM‑as‑a‑judge 评估框架。

**📊 数据集**

实验使用 Alpaca 与 Alpaca‑GPT4 这两个指令‑响应数据集，评估时采用 WizardLM 与 Vicuna 的指令集合。

**📈 对比分析**

与随机子集和 Superfiltering 基线对比，使用 LLaMA‑2‑7B/13B 在 LoRA 与全参数微调下进行实验；在 5%–15% 子集上，GradFiltering 的 Pairwise Winning Score（PWS）往往 ≥1，甚至超过完整数据集；人类评估与训练损失曲线亦显示其性能更好且收敛更快。

**⚠️ 局限性**

局限性包括：只关注梯度模量而忽视方向，依赖早晚梯度快照和固定的 5 组 LoRA 组合；代理仍需微调并非零成本；对需要延迟学习或强课程调度的任务可能不适用。

---

## 742. OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens

**arXiv ID:** 2601.13695 | [PDF](https://arxiv.org/pdf/2601.13695v1)

**作者:** Sifan Li `[一作]` (University of California), Yiwei Wang `[通讯]` (University of California)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `fede83ac-7505-405f-ab37-e7284695c47f` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究从表格图片使用光学令牌生成可执行SQL的框架OptiSQL，压缩输入并保持执行准确率。

**💡 创新点**

将光学令牌作为表格信息的紧凑视觉表示，冻结视觉编码器仅微调解码器，并系统评估视觉令牌的表示足够性与效率-准确率权衡。

**🔧 技术方法**

采用OCR导向视觉编码器（如DeepSeek‑OCR）生成光学令牌，预训练自回归解码器微调生成SQL；通过token预算控制、鲁棒性评估与视觉诊断等技术。

**📊 数据集**

使用视觉化版本的Spider 2.0‑Snow单表查询数据集（表格图像+自然语言问题+SQL答案）。

**📈 对比分析**

与文本到SQL基线（ReFoRCE）、OCR+文本管道、通用VLM（Pix2Struct、Donut）对比；OptiSQL在仅256个光学令牌下执行准确率约66%（与OCR管道相近），表格输入token量约降低十倍；在鲁棒性测试中性能下降可预测，FrozenEnc版在鲁棒性上更稳健。

**⚠️ 局限性**

受预训练视觉编码器限制，难以处理严重噪声、手写或畸变图像；仅评估单表查询，跨表查询尚未覆盖；冻结编码器虽保持鲁棒性但限制了准确率提升；未验证光学令牌在其他结构化生成任务中的适用性。

---

## 743. Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue

**arXiv ID:** 2601.13687 | [PDF](https://arxiv.org/pdf/2601.13687v1)

**作者:** Zhichao Liang `[一作]` (Chinese University of Hong Kong), Satoshi Nakamura `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 11097 | [OpenAlex ID](https://openalex.org/A5020994673)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 SocialMindChange 基准，用以评估大语言模型在多阶段社交情境中主动进行支持性对话、并预测对他人心理状态轨迹的影响。

**💡 创新点**

创新点在于：① 将 Theory of Mind 评测从被动状态报告转向主动引导；② 设计多场景、多角色、包含二阶/三阶心理状态的动态对话；③ 通过四类多项选择问题（指导-行动、即时转移、因果解释、全程规划）系统化衡量模型的跨阶段推理能力。

**🔧 技术方法**

技术上使用结构化 Prompting 结合 LLM 生成（GPT‑4o）实现情景、心理轨迹与对话；在评估时采用 Vanilla Prompt 与 Chain‑of‑Thought 方式；数据生成过程包含三步：情境构造、心理轨迹设计、对话生成与人工验证。

**📊 数据集**

数据集为 1,200 个社交阶段，每阶段包含 5 场景、4 名角色，共 96,000 题目；每题来源于通过 LLM 生成并人工审核的情境、心理状态标签与对话文本。

**📈 对比分析**

对比方法：在 9 种主流 LLM（包括 GPT‑4o、Llama‑3.1‑70B、Qwen‑2‑72B 等）上使用两种 Prompt；与 5 名人类标注者基准比较。结果显示 LLM 平均准确率仅 22.4%，比人类低 54.2个百分点；模型在“指导-行动”题目上表现稍好（≈30–36%），但在“指导‑转移”题目上仅 16–20%，显示跨阶段推理显著不足。

**⚠️ 局限性**

局限性：① 仅采用文本对话，未覆盖非语言信号；② 只评估 4 人情境，无法验证更大群体的泛化；③ 只使用了 Vanilla 与 CoT 两种 Prompt，缺乏针对跨阶段一致性的专门 Prompt 与解码策略；④ 只涵盖 4 个心理状态字段，未覆盖更丰富的社会认知变量；⑤ 受限于实验规模和预算，未覆盖所有新兴 LLM 与更大规模模型。

---

## 744. Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery

**arXiv ID:** 2601.13676 | [PDF](https://arxiv.org/pdf/2601.13676v1)

**作者:** Fabian Greifeneder `[一作]` (RISC Software GmbH), Philipp Moser `[通讯]` (RISC Software GmbH)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文开发了一种基于Transformer的自回归深度学习代理模型，用于实时模拟大脑软组织在神经外科手术中与手术器械相互作用所产生的瞬时变形；同时在Unity环境中实现了模型的部署，支持实时交互；

**💡 创新点**

创新点包括：①首次在大规模三维脑网格上实现自回归实时预测；②提出了随机教师强制（stochastic teacher forcing）训练策略，有效缓解训练与推理间的分布漂移和误差累积；③将Universal Physics Transformers与稀疏超级节点信息聚合相结合，既保持空间细节，又显著降低计算复杂度；

**🔧 技术方法**

技术主要包括：Universal Physics Transformers（UPT）网络结构、Supernode消息传递、Perceiver式跨注意力解码、随机教师强制训练、ONNX+TensorRT部署等；

**📊 数据集**

数据集来源于基于Allen Human Brain Reference Atlas构建的21,670节点脑网格，使用非线性Neo‑Hookean有限元仿真生成5种不同的手术器械碰撞场景，合计1,050个8s时序仿真，共约160个时间步/仿真；此外还扩展到高分辨率151,000节点网格；

**📈 对比分析**

与传统数值FEM（TLED）对比：代理模型在同一硬件上每步推理约18–43 ms，FPS达55–23，速度提升90×；在5个训练方案中，随机教师强制后，10步自回归MSE降至0.35，相比纯教师强制1.90；在交叉方案测试中，MSE 0.09±0.04，Hausdorff 1.99 mm；

**⚠️ 局限性**

局限性包括：仅针对单个脑几何体，未验证跨主体泛化；碰撞场景仅采样在Sylvian裂缝附近，未覆盖其他脑区；模型训练依赖大规模FEM数据，生成成本高；

---

## 745. The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption

**arXiv ID:** 2601.13671 | [PDF](https://arxiv.org/pdf/2601.13671v1)

**作者:** Apoorva Adimulam `[一作]` (Applied Agentic AI Skan AI), Sumit Kumar `[通讯]` (Applied Agentic AI Skan AI)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `5b4c1114-4a70-478e-9921-2514ee03850d` `3855fcda-48ef-4070-a15e-803cd5c84d83` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了多智能体系统的统一架构和通信协议，形成了完整的调度、策略、状态、质量与治理四层框架，并通过模型上下文协议（MCP）与代理对代理协议（A2A）实现了工具调用与同类代理协作的标准化。

**💡 创新点**

创新点在于：①将传统的单一 LLM 任务拆解为专门化代理并在统一编排层下动态分配、同步与验证；②定义了两条互补的协议（MCP 与 A2A）实现工具与代理间的安全、可审计交互；③引入了治理与可观测性模块，提供安全、合规、实时性能监控与自动恢复机制。

**🔧 技术方法**

主要技术包括：大规模语言模型（LLM）作为认知核心；基于消息中间件或 gRPC 的协议实现（MCP、A2A）；工作流编排引擎（如 LangChain/AutoGen 等）；状态与知识管理（分布式数据总线、事务日志）；质量与运维监控（telemetry、异常检测、指标可视化）。

**📊 数据集**

论文并未给出单一公开数据集，而是以行业案例（金融风控、保险核保、软件开发自动化、客户服务）为示例，说明在这些领域的数据来源主要为企业内部业务数据与第三方服务（如 Document AI、Decision AI）。

**📈 对比分析**

通过对比传统单一 LLM 方案和现有的分布式代理实现，论文展示了：在金融风控流程中，使用多智能体编排能将审批速度提升 10-20 倍、成本降低 70% 以上；在保险核保中，错误率降低 30% 以上；在软件工程中，交付周期缩短 50%+。比较方法主要是业务指标（吞吐量、延迟、准确率）与人工/单一代理基准对照。

**⚠️ 局限性**

局限性包括：①通信与协调开销随代理数量增大可能成为瓶颈；②治理与安全机制复杂，实施成本高；③大模型固有的幻觉、偏差等风险在多代理交互中被放大；④缺乏统一的评测基准和公开实验平台，难以客观比较不同实现；⑤对实时性和容错的正式验证仍在进行中。

---

## 746. VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement

**arXiv ID:** 2601.13664 | [PDF](https://arxiv.org/pdf/2601.13664v1)

**作者:** Tiancheng Fang `[一作]` (Shanghai Jiao Tong University), Fan Wu `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 18974 | [OpenAlex ID](https://openalex.org/A5075948251)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `edb9d762-f411-4838-a852-f2d638b018db` `40105733-5154-44cd-8090-a8cab9e64b07` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了VIAFormer，一种通过多视角图像引导的体素细化模型，用于修复噪声体素。

**💡 创新点**

创新点包括Correctional Flow直接学习从粗糙体素到干净体素的轨迹，Image Index提供3D空间对齐的图像标记，以及Hybrid Stream Transformer实现双流融合。

**🔧 技术方法**

采用Voxel-Image Alignment Transformer、RoPE位置编码、Flow Matching目标、VAE编码解码和多视角DINOv2特征。

**📊 数据集**

训练集来自ObjaverseXL、ABO、3D-FUTURE、HSSD等约48万3D资产，评估使用Toys4k和Dora数据集。

**📈 对比分析**

与DiffComplete、PatchComplete、WSSC、SDFusion等基线进行基准，对VFM衍生噪声和合成噪声分别提升IoU约5%和39%，表现为目前最佳。

**⚠️ 局限性**

局限包括对底部缺失的识别不稳定、对复杂拓扑缺陷敏感性不足，且依赖大量高质量多视角数据。

---

## 747. Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs

**arXiv ID:** 2601.13655 | [PDF](https://arxiv.org/pdf/2601.13655v1)

**作者:** Guangba Yu `[一作]` (Chinese University of HongKong), Michael R. Lyu `[通讯]` (Chinese University of HongKong)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对开源 LLM（DeepSeek、Llama、Qwen）在微调与推理阶段的用户报错进行大规模实证分析，构建 705 条手工标注的失败案例数据集。

**💡 创新点**

首次系统地揭示 LLM 用户报错的症状分布、根因映射与生命周期演化；发现环境与配置错误是主因，且生成质量异常成为新型失败范式；提出两层症状/根因分类体系。

**🔧 技术方法**

采用人工审阅+主题编码、开放代码法、交叉验证；使用 Cohen's Kappa 评估标注一致性（>0.92）；构建基于 GitHub issue 的失效抽取与过滤流程。

**📊 数据集**

705 条真实用户报错（共 5302 条 issue），涵盖 DeepSeek、Llama、Qwen 三大系列的 fine‑tune 与 inference 失败实例。

**📈 对比分析**

通过统计比较三系列、不同生命周期阶段、版本演进等维度，对失败比例、根因占比进行可视化；未给出传统算法性能指标，重点展示失败分布与行业实践的一致性。

**⚠️ 局限性**

局限性：仅覆盖开源模型，无法直接推广到封闭源 LLM；标注过程仍受主观影响；仅使用 GitHub issue 作为数据来源，可能遗漏其他渠道的报错；缺乏自动化检测与修复工具。

---

## 748. Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge

**arXiv ID:** 2601.13649 | [PDF](https://arxiv.org/pdf/2601.13649v1)

**作者:** Xiaolin Zhou `[一作]` (University of Southern California), Ruishan Liu `[通讯]` (University of Southern California)

**通讯引用:** 1147 | [OpenAlex ID](https://openalex.org/A5080351422)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

系统研究了多语言环境下的对比式 LLM-as-a-judge 的语言偏差，分别考察同语种对比与异语种对比两种场景，分析了语言、问题、学科差异对评判结果的影响，并探究语言偏差是否可归因于低困惑度。

**💡 创新点**

首次在对比式评判框架中量化并区分语言偏差与低困惑度偏差，揭示语言身份对评判偏差的独立贡献，并发现文化相关学科的语言差异更明显。

**🔧 技术方法**

使用大语言模型的交互式评判（LLM-as-a-judge）与线性回归、F‑检验等统计方法评估偏差；对模型进行位置消偏、双向对比实验。

**📊 数据集**

MMMLU（14 042 条多语言多选题）作为评判数据集，覆盖 14 种语言与 57 个学科。

**📈 对比分析**

通过将 8 种模型在同语种和异语种两种配置下的准确率与人类偏好进行对比，发现欧盟语言表现最佳、非洲语言最低；模型在异语种时普遍偏好英文答案，且该偏好不完全由困惑度解释，表明存在显著额外的语言偏差。

**⚠️ 局限性**

实验中未能完全剔除答案框架与措辞不匹配对困惑度的影响，且未评估推理模式对评判结果的潜在影响，导致困惑度与偏差的关联估计可能偏低。

---

## 749. Quadratic Upper Bound for Boosting Robustness

**arXiv ID:** 2601.13645 | [PDF](https://arxiv.org/pdf/2601.13645v1)

**作者:** Euijin You `[一作]` (Konkuk University), Hyang-Won Lee `[通讯]` (Konkuk University)

**通讯引用:** 1112 | [OpenAlex ID](https://openalex.org/A5039991280)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在快速对抗训练（FAT）框架下，提出并使用二次上界（QUB）损失函数，以提升模型对对抗攻击的鲁棒性。

**💡 创新点**

创新点在于推导出交叉熵损失的二次上界，并将该上界作为正则化项加入训练；该方法不需要额外的内层最大化步骤即可改善鲁棒性。

**🔧 技术方法**

主要技术包括对抗训练、FGSM/PGD/Free‑AT等对抗样本生成方法、二次上界损失、梯度与logit差分、Hessian 上界估计，以及静态和递减权重的训练策略。

**📊 数据集**

实验数据集涵盖 CIFAR‑10、CIFAR‑100 和 Tiny ImageNet，并使用 ResNet18、WideResNet34‑10、PreActResNet18 等网络。

**📈 对比分析**

与多种现有 FAT 方法（Free‑AT、FGSM‑RS、FGSM‑CKPT、N‑FGSM 等）在 ResNet18/WRN 等模型上对比，采用 PGD、PGD50‑10、AutoAttack 等评估；QUB 在大多数方法上显著提升鲁棒准确率，尽管标准准确率略有下降，但整体鲁棒性明显加强。

**⚠️ 局限性**

局限性包括：对对抗样本质量敏感，在易过拟合的基础方法（如 FGSM‑RS）上可能导致性能退化；二次上界在训练后期可能产生过度正则化；计算开销相对传统损失略高。

---

## 750. On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation

**arXiv ID:** 2601.13729 | [PDF](https://arxiv.org/pdf/2601.13729v1)

**作者:** Weichuan Wang `[一作]` (City University of Hong Kong), Chen Ma `[通讯]` (City University of Hong Kong)

**通讯引用:** 4362 | [OpenAlex ID](https://openalex.org/A5101866773)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

系统评估了非确定性机器翻译（ND‑MT），验证在温度约束下能产生多样且语义等价的候选，并揭示了“Buckets”效应。

**💡 创新点**

提出无参考的Group Lexical Variance Score（GLVS）度量、Bucket效应分析，以及ExpectoSample策略来筛选可靠评测指标与鲁棒系统。

**🔧 技术方法**

使用采样式解码、温度控制、群体度量（min、max、mean、random、std）以及多种词汇级（BLEU、ChrF++、METEOR、ROUGE、TER）和语义级（COMET、BERTScore、BLEURT、LASER、LaBSE、SentTrans、XNLI）指标。

**📊 数据集**

以WMT23/24公开数据集为基础，涵盖六语言对（中↔英、德↔英、俄↔英），约12,000条源句。

**📈 对比分析**

与确定性MT对比，ND‑MT在低温度下保持语义相等并提升词汇多样性；min指标在不同采样规模下最为稳定；ExpectoSample确定ChrF++、COMETDA/KIWI为可靠指标，验证了系统鲁棒性。

**⚠️ 局限性**

局限在于仅评测公开模型、温度范围受限、评测依赖现有自动指标、未进行人工验证、对低资源或极端语言对的泛化性不足。

---

## 751. Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement

**arXiv ID:** 2601.13724 | [PDF](https://arxiv.org/pdf/2601.13724v1)

**作者:** Sam Cantrill `[一作]` (Australian National University), Mohammad Ali Armin `[通讯]` (CSIRO)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `4de8e9d8-757b-475f-9627-18a445e50202` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了面部空间时间图（STGraph）和轻量化时空图卷积网络MeshPhys，用3D面部网格序列直接对齐表面来估计远程光电容积描记（rPPG）信号。

**💡 创新点**

创新点在于：①直接将3D面部表面作为输入空间，构建面向表面的图结构；②将局部颜色特征与面部拓扑耦合为节点特征；③在此图上设计时空卷积，利用表面结构先验约束感知范围，实现更稳健的信号提取。

**🔧 技术方法**

使用了3D面部网格重建、表面对齐特征编码、图卷积网络（时空图卷积）、轻量化网络设计和跨数据集评估技术。

**📊 数据集**

实验数据集包括 PURE、UBFC‑rPPG、MMPD 和 VIPL‑HR 四个公开基准，涵盖从小规模到大规模、不同光照与运动条件的录像。

**📈 对比分析**

与传统视频基方法、STMap基方法以及最新深度学习模型进行对比，在四个数据集的内部（intra）和跨数据集（cross‑dataset）评测中均实现了或超过了最先进（state‑of‑the‑art）性能，并且模型参数更少、跨数据集泛化更好。

**⚠️ 局限性**

主要局限包括：①依赖准确的3D面部网格估计，若网格重建失败或质量差会影响效果；②在极端姿态、遮挡或大幅光照变化下的鲁棒性仍有提升空间；③当前模型仅关注表面颜色变化，未充分利用深度或光照变化带来的额外信息。

---

## 752. MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network

**arXiv ID:** 2601.13715 | [PDF](https://arxiv.org/pdf/2601.13715v1)

**作者:** Yiwei Lu `[一作]` (Jiangnan University), Tao Yan `[通讯]` (Jiangnan University)

**通讯引用:** 2352 | [OpenAlex ID](https://openalex.org/A5025290228)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种基于运动不一致性的多模态视频玻璃表面检测网络 MVGD-Net。

**💡 创新点**

创新点在于设计跨尺度多模态融合模块、历史引导注意模块和时空解码器，并利用运动不一致性提示来驱动检测。

**🔧 技术方法**

采用 RAFT 光流、Swin Transformer 骨干、CBAM 轻量化注意力、跨尺度注意力、HGAM/TCAM 时序注意模块以及 TSD 时空解码器等技术。

**📊 数据集**

构建了 312 条视频、共 19,268 帧的 MVGD-D 大规模数据集，并使用该数据集对模型进行训练与评估。

**📈 对比分析**

在 VGSD-D 和 MVGD-D 上与 11 种 state‑of‑the‑art 方法对比，IoU、Fβ 等指标显著提升，最高提升约 7.2% / 4.5%，并在多项指标上领先。

**⚠️ 局限性**

局限在于仅利用三帧短序列，难以捕捉长期时序关系，导致在某些帧出现漏检或误检。

---

## 753. Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction

**arXiv ID:** 2601.13710 | [PDF](https://arxiv.org/pdf/2601.13710v1)

**作者:** Sayeed Shafayet Chowdhury `[一作]` (Purdue University), Vijay R. Ramakrishnan `[通讯]` (Indiana University)

**通讯引用:** 7043 | [OpenAlex ID](https://openalex.org/A5074669560)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

研究利用术前临床表格数据预测慢性鼻窦炎患者是否能在术后6个月达到≥8.9点SNOT‑22改善，并比较监督式机器学习模型与多种生成式AI模型的预测性能；

**💡 创新点**

首次在同一数据集上严格对比生成式AI与校准的监督式表格机器学习模型，提出“ML‑first, GenAI‑augmented”工作流，并提供可复现的tabular‑to‑GenAI评估协议；

**🔧 技术方法**

采用监督式ML（Logistic回归、随机森林、MLP）和大型语言模型（ChatGPT、Claude、Gemini、Perplexity、DeepSeek）在零射击提示下进行二分类预测，使用AUC、F1、AP、校准曲线和决策曲线等多维评估；

**📊 数据集**

使用NIH多中心慢性鼻窦炎结局研究（NCT01332136）两份表格，合并524例术后患者，包含年龄、性别、SNOT‑22基线、CT/Lund‑Mackay、内镜评分、病理类型等术前特征；

**📈 对比分析**

在相同预处理和交叉验证下进行模型比较，MLP获得最高AUC≈0.66、F1≈0.83，生成式AI模型AUC在0.36–0.63、F1在0.61–0.81之间，且多模型对非响应者检测不足，显示偏向“全手术”预测；

**⚠️ 局限性**

仅为回顾性单领域研究，MCID阈值存在噪声，模型对罕见负类检测弱，对提示和功能调用的限制以及RAG未能显著提升性能，需外部验证、主动推理与偏差监测等进一步研究。

---

## 754. CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks

**arXiv ID:** 2601.13669 | [PDF](https://arxiv.org/pdf/2601.13669v1)

**作者:** Jiayu Lin `[一作]` (Fudan University), Zhongyu Wei `[通讯]` (Fudan University)

**通讯引用:** 5871 | [OpenAlex ID](https://openalex.org/A5011504177)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出社区级对齐方法，构建CommunityBench基准，评估17种LLM在四项任务（偏好识别、偏好分布预测、社区一致生成、社区识别）上的能力，并验证社区级对齐可提升个人行为建模。

**💡 创新点**

创新点：①把对齐粒度定位为社区层面，兼顾普适性与多样性；②设计四个基于Common Identity and Common Bond理论的任务，构建大规模社群偏好数据；③系统证明现有LLM在捕捉社区特定偏好方面能力有限；④展示社区级对齐可作为高效的个体建模途径。

**🔧 技术方法**

使用技术包括：基于Common Identity and Common Bond理论的社区建模；Reddit文本处理与LLM总结生成社区简介；MMR与分布式筛选构造选项集；贝叶斯推断投票分布；四任务评估（PI、DP、CG、CI）；对齐方式为提示、RLHF、监督微调；评估采用vLLM、OpenAI API等。

**📊 数据集**

主要数据集来自公开的Reddit内容，构成12,149个实例、6,919个社群，涵盖四个任务；此外使用SocioBench验证社区对齐模型在个人行为模拟上的优势。

**📈 对比分析**

通过与17种开源与专有模型比较，使用准确率、JSD、Kendall τ和BTL‑Elo指标。结果显示：大模型在PI、CI任务上表现最佳，但在DP任务捕捉多样偏好仍显不足；CG任务整体性能落后；在长尾社群准确率显著下降；社区级对齐模型在SocioBench上超越提示式个体对齐。

**⚠️ 局限性**

局限性：①仅基于单一平台（Reddit）构建，难以推广到其他社交或多语言环境；②采用投票分数近似偏好，缺乏更细粒度的规则或审核信息；③评估主要是单轮任务，未涉及多轮动态社区仿真；④社区概况生成仍依赖LLM，可能带来偏差。

---

## 755. Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis

**arXiv ID:** 2601.13659 | [PDF](https://arxiv.org/pdf/2601.13659v1)

**作者:** Chunlei Meng `[一作]` (Fudan University), Zhongxue Gan `[通讯]` (University of South Australia)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `57a58b01-81b4-4d75-a45c-2e891f272b50` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 TSDA 框架，在多模态情感分析中先对每个模态的时间动态与空间结构进行解耦，然后再进行跨模态对齐和再耦合

**💡 创新点**

核心创新在于时间-空间先解耦并通过 Factor-Consistent Cross-Modal Alignment 保证同类因子只相互对齐，并用 Gated Recouple 自适应融合

**🔧 技术方法**

使用轻量级时序编码器和空间编码器、块状掩码注意力、因子纯度监督、解相关正则化、正交约束以及门控重耦合模块

**📊 数据集**

在 CMU‑MOSI 和 CMU‑MOSEI 两个公开情感分析基准数据集上进行评估

**📈 对比分析**

与多种 SOTA 方法（如 MISA、EMOE、MISA 等）对比，TSDA 在 MAE、ACC‑2、ACC‑7、F1 等指标上均取得最高或接近最高分，显著提升约 1%~2%

**⚠️ 局限性**

局限性包括对超参数的依赖、模型复杂度较高以及在跨域或非对齐设置下仍需进一步验证

---

## 756. Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation

**arXiv ID:** 2601.13658 | [PDF](https://arxiv.org/pdf/2601.13658v1)

**作者:** Arthur Amalvy `[一作]` (Academia Sinica), Hen-Hsen Huang `[通讯]` (Academia Sinica)

**通讯引用:** 1138 | [OpenAlex ID](https://openalex.org/A5053932280)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一种可持续生成未来时间知识图谱提取（TKGE）基准的完整流程，利用时间知识图谱预测（TLogic）生成未来四元组，再通过LLM生成对应文本；

**💡 创新点**

创新点在于：①通过预测未来事实构建无数据污染的基准数据集；②将四元组对文本的自动生成与预测相结合，形成可无限扩展的时间基准；③在同一数据集上对已知与未知事实的性能差异进行定量评估。

**🔧 技术方法**

技术方法包括：时间知识图谱预测（TLogic）规则挖掘、LLM（Llama3.3‑70B）文本生成、EDC（Extract, Define, Canonicalize）提取框架与基线模型Mistral‑7B‑Instruct、以及自定义的四元组评估指标。

**📊 数据集**

使用的数据集为YAGO 4.5（2023之前的事实），从中提取 2000‑2024 年的时间事实作为基础，随后生成 2026 年的未来四元组（共 4,209 条）及其文本描述；对照同样来源的 2022 年事实集进行评测。

**📈 对比分析**

在单事实与多事实两种评测设定下，EDC 在已知事实集上的 F1‑score 约 70‑85%，而在未来未见事实集上下降 2‑4%；基线 Mistral‑7B‑Instruct 的下降更显著（约 10%），说明模型在未见事实和未来时间戳上表现更差。

**⚠️ 局限性**

局限性包括：①TLogic 在稀有关系上生成能力有限；②仅支持日级时间粒度，无法处理时间区间；③缺乏统一的时间感知评估指标，当前采用的扩展自 WebNLG 的四元组指标仍存在不足。

---

## 757. Face-Voice Association with Inductive Bias for Maximum Class Separation

**arXiv ID:** 2601.13651 | [PDF](https://arxiv.org/pdf/2601.13651v1)

**作者:** Marta Moscati `[一作]`, Shah Nawaz `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出一种在面部-声音关联任务中使用最大类分离作为先验偏置的方法，通过固定矩阵实现多模态表征的最大类分离，并结合交叉熵与正交损失进行训练。

**💡 创新点**

首次将最大类分离作为先验偏置引入多模态学习，证明在面部-声音关联任务中可显著提升性能，并显示与正交约束协同效果最佳。

**🔧 技术方法**

采用FaceNet和Ecapa‑tdnn的冻结预训练特征提取器，后续通过全连接层和L2归一化得到表征，加入固定的最大类分离矩阵，并使用交叉熵损失与正交约束损失进行联合训练。

**📊 数据集**

在 VoxCeleb（seen‑heard、unseen‑unheard）和 MAV‑Celeb（英语、乌尔都）两个基准数据集上进行实验。

**📈 对比分析**

与多种SOTA方法（Single Stream Net、FOP、AML等）在交叉模态验证（EER/AUC）和匹配（准确率）上进行对比，取得最优EER/最高AUC以及最高匹配准确率，验证方法有效。

**⚠️ 局限性**

未探讨不同说话人数对性能的影响，未验证该偏置在其他任务或模型上的适用性，实验仅局限于两大数据集。

---

## 758. On the stability, complexity, and distribution of similarity classes of the longest edge bisection process for triangles

**arXiv ID:** 2601.13663 | [PDF](https://arxiv.org/pdf/2601.13663v1)

**作者:** Daniel Kalmanovich `[一作]` (Ariel University), Yaar Solomon `[通讯]` (Ben-Gurion University of the Negev)

**通讯引用:** 60 | [OpenAlex ID](https://openalex.org/A5068177854)

**关键词:** `a42c7bd6-d8fd-40d3-94df-ae8cd808f5c4`

**🎯 论文内容**

分析并证明最长边细分（LEB）在任意初始三角形下生成的三角形序列最终仅出现有限种相似类，并进一步发现这些相似类集中在“终端四重集”上，且面积占比随迭代指数级增长；

**💡 创新点**

提出终端四重集概念并给出其几何与谱性质的完整描述，证明终端四重集占主导地位，阐明终端四重集数量与初始三角形的关系；

**🔧 技术方法**

利用双曲几何模型、Möbius 与反Möbius 变换、谱方法（Perron–Frobenius定理及矩阵理论）对迭代过程及其图结构进行严谨分析；

**📊 数据集**

无实验数据集，全部基于数学证明与符号计算；

**📈 对比分析**

通过理论推导得到指数级收敛率，并配合数值实验验证，证明在大多数初始三角形下面积占比几乎达到1；

**⚠️ 局限性**

研究仅限于平面三角形的最长边细分，无法直接推广至高维多面体；终端四重集数量的精确公式仍未知，且对极端初始形状的收敛行为尚未完全解析。

---

## 759. Efficient Parallel $(Δ+1)$-Edge-Coloring

**arXiv ID:** 2601.13822 | [PDF](https://arxiv.org/pdf/2601.13822v1)

**作者:** Michael Elkin `[一作]` (Ben-Gurion University of the Negev), Ariel Khuzman `[通讯]` (Ben-Gurion University of the Negev)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本论文提出了一套完整的并行(Δ+1)‑边缘着色算法，采用PRAM模型实现，能够在对偶分解与递归合并过程中显著降低时间复杂度和处理器使用量；

**💡 创新点**

创新点在于构造了 fan‑graph 与 conflict‑graph 两种辅助图，通过求独立集实现大规模 fan 的并行 recoloring，并通过 Reduce‑Color 迭代高效减少色彩；

**🔧 技术方法**

主要技术包括 PRAM 算法、Eulerian 循环与双向边着色、独立集/顶点着色近似、αβ‑路径交换与 fan 旋转等；

**📊 数据集**

实验与对比均基于理论分析，无需真实数据集；

**📈 对比分析**

与先前工作相比，该方法在最坏情况时间复杂度从原先的 Δ².8 改为 Δ².4，或在低 arboricity 场景下进一步降低至 Δ².1，且处理器需求显著下降；

**⚠️ 局限性**

限制主要体现在对 fan‑graph 的独立集求解需要较多处理器，且当 Δ 或 a 较大时 λ‑large 集大小下降；此外算法假设未着色边集为匹配，实际应用时需保证此性质。

---

## 760. The Non-Predictability of Mispredicted Branches using Timing Information

**arXiv ID:** 2601.13804 | [PDF](https://arxiv.org/pdf/2601.13804v1)

**作者:** Ioannis Constantinou `[一作]` (University of Cyprus), Yiannakis Sazeides `[通讯]` (Univ. Grenoble Alpes)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文研究在分支预测中使用分支时序信息（即分支在重排序缓冲区中的停留周期）进行后期重预测，提出Speculative Branch Resolution（SBR）方案并在gem5上实现验证；

**💡 创新点**

创新点在于将微架构时序信息（CTIV、OTIV、YTIV）编码为信息向量，作为覆盖预测器与传统TAGE预测器并行，从而尝试提升硬难预测（H2P）分支的准确率；

**🔧 技术方法**

采用TAGE预测器框架、SBR覆盖预测机制、时序信息向量编码技术，并通过gem5模拟器对Intel Skylake-like和Goldencove-like核心进行周期级仿真；

**📊 数据集**

使用SPEC2017 Rate Benchmarks中的10个高BMPKI基准，抽取92个H2P分支作为实验对象；

**📈 对比分析**

通过比较SBR与大容量TAGE-SC基线在分支错误率、IPC提升等指标，发现SBR仅在极少数两条分支上实现了显著误预测率下降，其余情况下性能提升极为有限；

**⚠️ 局限性**

局限性在于时序信息与分支结果的相关性不高，SBR在大多数H2P分支上无法超越仅使用架构信息的TAGE-SC；且仅对TAGE框架验证，未探索更大窗口或其他微架构特征的潜力。

---

## 761. Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis

**arXiv ID:** 2601.13802 | [PDF](https://arxiv.org/pdf/2601.13802v1)

**作者:** Yushen Chen `[一作]` (Shanghai Jiao Tong University), Xie Chen `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 2053 | [OpenAlex ID](https://openalex.org/A5090959358)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了Habibi，一个开源的统一方言阿拉伯语文本到语音（TTS）框架，并构建了首个多方言阿拉伯语零样本合成基准。

**💡 创新点**

创新点包括：① 利用语言学启发的两阶段课程学习（先对现代标准阿拉伯语（MSA）微调，再适应各方言），实现高质量零样本生成；② 在训练与推理中加入方言区域识别符，提升识别精度并增强上下文学习；③ 通过系统化的数据清洗与去噪流程，充分利用原本为ASR设计的大规模非标准化数据；④ 在公开数据上公开模型、推理代码和基准，填补了阿拉伯方言TTS的资源空白。

**🔧 技术方法**

技术手段包括：F5‑TTS架构作为基础；两阶段课程学习与方言特定监督微调；在文本序列中嵌入区域识别符实现上下文感知；多步筛选（CPS阈值、源分离去噪、规则过滤）对数据进行清理；使用WavLM进行说话人相似度评估；使用Omnilingual‑ASR和多方言ASR评估WER；对齐、音频合成、超参数调优等。

**📊 数据集**

使用的主要数据集：MASC、MGB‑2/3/5、SADA、FLEURS、Omnilingual、UAE‑100K、UAE‑Nexdata、Darija‑S2T、DarijaTTS‑clean、Jordan‑Audio、内部数据；总计约1857小时、879k句子；基准集覆盖7个方言（阿尔及利亚、埃及、摩洛哥、利比亚、黎巴嫩、沙特、叙利亚）。

**📈 对比分析**

与ElevenLabs Eleven v3 (alpha)以及多方言ASR基线进行对比，使用WER‑O、WER‑S、SIM和UTMOS等指标。结果显示统一模型在多数方言上与专业化模型相当甚至更优，且在所有主要方言上均超过商业基准，证明统一方言TTS可实现零样本高质量合成。

**⚠️ 局限性**

局限性包括：缺乏有效的检查点融合与细粒度采样策略以平衡各方言收敛；不支持代码混合（阿拉伯语与英语、法语等）；未探究最小数据量及持续学习方案；未评估在资源外方言的迁移能力；数据质量仍是瓶颈；模型架构未针对方言专门设计；未对内部表示进行分析。

---

## 762. Area-universality in Outerplanar Graphs

**arXiv ID:** 2601.13781 | [PDF](https://arxiv.org/pdf/2601.13781v1)

**作者:** Ravi Suthar `[一作]` (Birla Institute of Technology and Science), Krishnendra Shekhawat `[通讯]` (Birla Institute of Technology and Science)

**通讯引用:** 239 | [OpenAlex ID](https://openalex.org/A5068014820)

**关键词:** `a42c7bd6-d8fd-40d3-94df-ae8cd808f5c4` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文研究了外可平面图在面积可逆矩形布局中的可行性，给出了必要且充分的结构条件并设计了构造算法。

**💡 创新点**

创新点在于证明外可平面图仅在恰有两个度为2的顶点时才可实现面积可逆布局，并提出了Outer4Completion等增广策略，能够保证所有正则边标记下的布局均为面积可逆。

**🔧 技术方法**

主要使用图论理论（外可平面图、弱对偶树、可逆正则边标记）、拓扑结构分析与线性时间构造算法，结合矩形分割与最大线段一侧性判定。

**📊 数据集**

论文为理论性工作，未使用实验数据集，结果以图例与示例图展示。

**📈 对比分析**

与以往研究相比，本工作提供了完全的必要充分条件与线性时间构造方案；在算法实现方面复杂度为O(n)，并给出了所有面积可逆布局的枚举上界|V|+2，证明了算法的最优性。

**⚠️ 局限性**

局限性在于仅针对外可平面图，无法直接推广到一般平面图或更复杂的结构；增广过程需严格满足条件，否则可能产生不可逆布局；实际应用中仍需结合具体面积需求进行细化。

---

## 763. GOMPSNR: Reflourish the Signal-to-Noise Ratio Metric for Audio Generation Tasks

**arXiv ID:** 2601.13758 | [PDF](https://arxiv.org/pdf/2601.13758v1)

**作者:** Lingling Dai `[一作]` (Institute of Acoustics, Chinese Academy of Sciences), Chengshi Zheng `[通讯]` (Institute of Acoustics, Chinese Academy of Sciences)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出了 GOMPSNR 作为 SNR 的可靠替代指标，并基于此开发了新的相位导向和幅度-相位联合优化的损失函数，用以提升神经声码器的生成质量。

**💡 创新点**

创新点在于用全方向相位导数替代传统相位距离，改进了相位误差测量并使得指标与人类感知更相关，同时将该改进推广到损失函数设计，实现幅度与相位的协同优化。

**🔧 技术方法**

使用了频域相位导数（Omnidirectional Phase Derivatives）、改进的 SNR 公式（OMPSNR、GOMPSNR）、相位权重的 OP 损失、以及联合幅度相位的 OmniRI 与 Coupled OmniRI 损失，并在多模型训练中融合 GAN、特征匹配和 Mel 频谱损失。

**📊 数据集**

在 LJSpeech（13k 语音片段）和 LibriTTS（约 960 小时）两个公开数据集上进行评估，并对多种先进声码器（Vocos、APNet、APNet2、RNDVoc）及音频码器（WavTokenizer、Vocos）进行实验。

**📈 对比分析**

与传统 SNR、L1/L2 失真、OP、RI 等损失比较，GOMPSNR 在与 PESQ、UTMOS、VQScore、NISQA 等感知指标的 Pearson 与 Spearman 相关性显著提升；使用新损失组合的声码器在 MCD、M‑STFT、GOMPSNR、PESQ、UTMOS 等指标上均优于原始损失，尤其在低比特率下提升更为显著。

**⚠️ 局限性**

局限性包括对极小样本数据集（如 LJSpeech）可能导致过拟合，GOMPSNR 仍依赖帧对齐，且在非帧同步的生成任务中需要进一步验证。

---

## 764. Pro-AI Bias in Large Language Models

**arXiv ID:** 2601.13749 | [PDF](https://arxiv.org/pdf/2601.13749v1)

**作者:** Benaya Trabelsi `[一作]` (Bar Ilan University), Sarit Kraus `[通讯]` (Bar Ilan University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在三种实验中检测LLM对AI的偏好，发现建议、薪酬评估和内部表示均显示系统性偏向AI。

**💡 创新点**

提出可重复的Pro‑AI偏差基准，并在建议、薪酬与内部表示三维度同时验证偏差。

**🔧 技术方法**

使用多种LLM（包括专有与开源模型），基于排名统计、薪酬估计误差和隐藏层相似度的量化方法。

**📊 数据集**

利用多领域建议提示、匹配的岗位薪酬记录（H1B LCA 数据）以及学科标签模板。

**📈 对比分析**

对比专有与开源模型，发现专有模型推荐频率+13pp、平均排名1.22 vs 1.79，薪酬误差提升约10pp；在内部表示中AI始终位列最高相似度。

**⚠️ 局限性**

局限包括对模型内部机制缺乏可解释性、缺少跨语言验证、以及数据集可能未覆盖全部行业与文化差异。

---

## 765. Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection

**arXiv ID:** 2601.13735 | [PDF](https://arxiv.org/pdf/2601.13735v1)

**作者:** Hojin Kim `[一作]` (Yonsei University), Jaehyung Kim `[通讯]` (Yonsei University)

**通讯引用:** 1926 | [OpenAlex ID](https://openalex.org/A5110631092)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文研究了在 Best‑of‑N 选择中使用的概率置信度指标对推理质量的真实性能，并通过三类干预（注意力掩码、模型参数缩小、数据扰动）破坏推理步骤间的因果依赖，发现这些指标对因果结构不敏感；随后提出对比因果度量，显式隔离步骤间因果贡献。

**💡 创新点**

创新点在于：①首次系统展示概率置信度指标对推理步骤因果关系的鲁棒性；②引入对比因果度量（Contrastive Causality Metric），通过将标准置信度与完全掩码后的置信度相减，显著提升了推理结果的选择准确率，并恢复了对因果扰动的敏感性。

**🔧 技术方法**

采用的技术包括：自回归概率分布计算、注意力层掩码、使用小规模评估模型、文本级改写（paraphrase）、句子级洗牌、截断；评价指标包括自证性（Self‑certainty）、对数似然、熵以及对比因果度量；实验中使用了零样本 CoT 生成、10 条候选样本的 Best‑of‑N 策略。

**📊 数据集**

数据集覆盖数学与科学推理任务：MATH‑500、GSM8K、GPQA‑Diamond、AR‑LSAT、LogiQA；所有实验均在这些公开基准上进行。

**📈 对比分析**

通过对比标准概率指标与对比因果度量在原始、掩码、参数缩小及数据扰动等多种实验设置下的选取准确率，发现标准指标在大多数扰动下误差 <1%，而对比因果度量在无扰动时提升约0.4%，在扰动时准确率显著下降，验证其对因果结构的敏感性。

**⚠️ 局限性**

局限性：实验仅聚焦数学/科学推理任务，未覆盖常识、多跳问答或多模态推理；研究为经验性诊断，缺乏理论解释；仅在推理阶段进行，未探讨模型训练或部署的影响。

---

## 766. Variational Dual-path Attention Network for CSI-Based Gesture Recognition

**arXiv ID:** 2601.13745 | [PDF](https://arxiv.org/pdf/2601.13745v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2`

---

## 767. RIM Hand : A Robotic Hand with an Accurate Carpometacarpal Joint and Nitinol-Supported Skeletal Structure

**arXiv ID:** 2601.13737 | [PDF](https://arxiv.org/pdf/2601.13737v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

---

## 768. Counterexample Classification against Signal Temporal Logic Specifications

**arXiv ID:** 2601.13743 | [PDF](https://arxiv.org/pdf/2601.13743v1)

**作者:** Zhenya Zhang `[一作]` (Kyushu University and National Institute of Informatics), Eunsuk Kang `[通讯]` (Carnegie Mellon University)

**通讯引用:** 1440 | [OpenAlex ID](https://openalex.org/A5044511705)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一个基于参数化信号时序逻辑（PSTL）的对抗例子分类准则和分类框架，用以区分和分析混合系统在满足或违反 STL 规范时的不同违规模式。

**💡 创新点**

创新点在于：1) 用 PSTL 对 STL 规范进行分解，得到可解释的“满足类”和“违反类”，并证明其为充分条件；2) 通过构造类之间的偏序关系，将包含关系转化为有向无环图；3) 利用二分搜索思路在该图中快速定位信号所在的边界，从而显著减少对成员资格的昂贵优化查询。

**🔧 技术方法**

核心技术包括：PSTL 参数化时序逻辑、量化稳健语义、基于优化求解器的成员资格查询（min‑robustness）、偏序关系构造与二分搜索算法。

**📊 数据集**

实验数据集：来自行业广泛使用的两个 Simulink 模型——自动变速箱（AT）和抽象燃油控制（AFC），分别针对四条 STL 规范采集了 30 条违反例子。

**📈 对比分析**

与基线全遍历分类方法相比，使用二分搜索的实现：① 在 k 取值较大（k=4）时基线无法在给定时间内完成分类，所对应的分类时间达到数千秒；② 我们的方法在相同条件下仍在 2000 秒以内完成；③ 对于 k=4 的 AT2，基线耗时超 10K 秒，而我们仅需不到 2000 秒，展示了显著的效率提升；此外，实验结果表明分类结果能够揭示不同违规模式的分布，为后续故障定位提供参考。

**⚠️ 局限性**

局限性包括：① 对 k 的依赖，k 较大时类的指数增长仍会导致一定的计算量；② 成员资格查询需要非凸优化，可能在高维或复杂信号中收敛缓慢；③ 当前仅对时间参数化的 PSTL 进行考虑，无法覆盖幅值参数的情况；④ 需要手动设定规范中的 k 值，缺乏自动化调优机制。

---

## 769. On Autopilot? An Empirical Study of Human-AI Teaming and Review Practices in Open Source

**arXiv ID:** 2601.13754 | [PDF](https://arxiv.org/pdf/2601.13754v1)

**作者:** Haoyu Gao `[一作]` (University of Melbourne), Christoph Treude `[通讯]` (Singapore Management University)

**通讯引用:** 4917 | [OpenAlex ID](https://openalex.org/A5077658936)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过对开源项目中AI辅助拉取请求（PR）的行为进行大规模实证研究，探讨了项目层面的AI使用规范和开发者与AI的交互模式。

**💡 创新点**

创新点在于将AI‑Co‑authored PR 与同一时间段的人工 PR 进行对比，并细粒度地引入贡献者代码拥有权的度量，揭示了AI PR 在非拥有者贡献者中占比高、审核节奏快且反馈少的反向模式。

**🔧 技术方法**

研究采用了 GitHub 数据爬取、Git Blame 代码拥有权分析、Bot 检测（Golzadeh 等方法）以及关键词过滤技术，配合文本预处理（小写、分词、词形还原）进行规范检测。

**📊 数据集**

数据集为扩展后的 AIDev（含 AI‑Only 与 Human+AI PR）以及同源仓库在同一时段收集的 174,567 条人工 PR，覆盖 2,134 个仓库；同时收集了 README、CONTRIBUTING、Code of Conduct 与 PR 模板等项目文档。

**📈 对比分析**

通过对三类 PR（AI‑Only、Human+AI、Human‑Only）按贡献者拥有权分层，比较其合并率、评论数、审查次数与关闭时长，发现 AI‑+Human PR 的合并率虽低于 Human‑Only，但合并速度更快、所需审核更少，说明 AI 介入可提升流程效率。

**⚠️ 局限性**

局限性包括仅以 Git Blame 作为拥有权标注，未考虑多用户名同一人情况；Bot 检测基于评论模式，可能漏检低活跃仓库中的机器人；只分析了标准贡献文件，未覆盖可能的专用 AI 文档。

---

## 770. EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory

**arXiv ID:** 2601.13748 | [PDF](https://arxiv.org/pdf/2601.13748v1)

**作者:** Tien-Dat Pham `[一作]` (HAI-Smartlink Research Lab), Xuan-The Tran `[通讯]` (Vietnam Maritime University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出一种双分支EEG-Titans框架，用神经记忆机制与滑动窗口注意力并行捕捉长期与短期癫痫前驱信号，完成基于EEG的癫痫发作预测。

**💡 创新点**

创新点在于：①引入Titans的Memory-as-a-Gate结构实现高效长程记忆；②将短时局部注意力与全局记忆通过可学习门控融合；③采用安全优先的时间顺序hold‑out评估与患者特异阈值/上下文自适应策略；④系统化的异常案例与多尺度上下文分析。

**🔧 技术方法**

技术手段包括：ShallowConvNet空间分词器、滑动窗口因果自注意力、Titans记忆门控、软融合Top‑K阈值决策、30分钟冷却期以及基于滑动窗口的置信度聚合。

**📊 数据集**

使用的主要数据集为CHB‑MIT 18名儿童患者的脑电图（共约980小时，198次发作），采用18个共通双极通道。

**📈 对比分析**

与2024年及之前的Transformer、CNN、TCN等主流方法比较，EEG‑Titans在同一chronological hold‑out设置下平均段级灵敏度99.46%，FPR/h 0.371，16/18患者达到100%灵敏度且FPR/h低于0.2；在挑战性病例CHB15通过扩展上下文至5分钟将FPR/h降至0.00、灵敏度升至99.86%。

**⚠️ 局限性**

局限性包括：1）仅在CHB‑MIT小样本、儿童数据上验证，缺乏跨机构或临床长期验证；2）对高肌电噪声或极度非平稳的儿童EEG仍易产生误报；3）模型缺乏解释性与公平性评估；4）阈值与上下文自适应目前仍手工设定，需进一步自动化。

---

## 771. FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs

**arXiv ID:** 2601.13836 | [PDF](https://arxiv.org/pdf/2601.13836v1)

**作者:** Qian Chen `[一作]` (Fudan University), Xipeng Qiu `[通讯]` (Shanghai Innovation Institute)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建了首个面向多模态未来预测的基准数据集 OFP，并提出基于指令微调的 Omni‑Modal Future Forecasting（OFF）方法。

**💡 创新点**

创新点在于：①提供完整的音视频协同未来预测评测框架；②设计四类对抗性干扰样本以逼真检验跨模态推理；③在指令数据中加入因果推理链，提升模型的前瞻性推断与泛化能力。

**🔧 技术方法**

主要技术包括多模态 LLM（Gemini、Qwen、MiniCPM 等）与专用音视频编码器、LoRA 微调、基于 Gemini 2.5 Flash 的自动标注与验证、以及注意力差异可视化分析。

**📊 数据集**

使用的数据集为 OFP（919 条视频、1,034 题目，涵盖 8 个领域），并与 WorldSense、DailyOmni、JointAVBench 等现有多模态基准进行对比实验。

**📈 对比分析**

在 20 款模型的评估中，最优专有模型 Gemini 3 Flash 的准确率仅达 64.8%；OFF 微调后，开源模型的整体表现提升 1–10%，尤其在 Speech 场景提升近 10%，并在跨基准评测中表现出显著的泛化优势。

**⚠️ 局限性**

局限性主要体现在：整体准确率仍偏低，模型对短视频、紧急场景以及音频认知仍易出错；未来预测仍受限于视频感知与跨模态推理的深度，数据集规模与多样性有待进一步扩展。

---

## 772. A Distributed Spatial Data Warehouse for AIS Data (DIPAAL)

**arXiv ID:** 2601.13795 | [PDF](https://arxiv.org/pdf/2601.13795v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7`

---

## 773. ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks

**arXiv ID:** 2601.13824 | [PDF](https://arxiv.org/pdf/2601.13824v1)

**作者:** Xiaohong Yang `[一作]`, Seyyedali Hosseinalipour `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在资源受限的网络边缘设备上，提出 ELSA 框架，结合分割学习与层级联邦学习实现 LLM 的高效联邦微调。

**💡 创新点**

创新点包括：行为感知的层级聚类、三段式模型分割仅使用 LoRA 参数、基于计算草图与语义子空间正交扰动的通信压缩方案。

**🔧 技术方法**

使用 SL、HFL、KL 散度、LoRA、Sketch、SS‑OP、PCA/SVD、聚类、权重融合等技术。

**📊 数据集**

使用八个 NLP 任务数据集：Trec、AG_News、Emotion、Banking77、RTE、CB、MultiRC、SQuAD。

**📈 对比分析**

与 FedAvg、FedProx、FedAMS、RaSA、FedCAda、RoFed 等基线对比，在大多数任务上取得最高准确率/ F1，并显著降低通信成本（约 3–4 倍节省）。

**⚠️ 局限性**

局限：仅在 BERT‑base 级别验证，未测试超大模型；分割方案需手工设置，压缩比例需经验调优；对极端网络抖动和极度非 IID 的数据场景的鲁棒性仍待进一步评估。

---

## 774. Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning

**arXiv ID:** 2601.13806 | [PDF](https://arxiv.org/pdf/2601.13806v1)

**作者:** Dezhao Song `[一作]` (Thomson Reuters Foundational Research), Jonathan Richard Schwarz `[通讯]` (Imperial College London)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

利用IRAC框架构建法律知识图谱并生成SFT和DPO训练数据，后训练中等至大规模LLM以提升法律推理能力。

**💡 创新点**

创新点在于：①以IRAC为核心设计知识图谱；②直接使用图结构进行LLM后训练而非仅做检索；③结合SFT与DPO提升模型推理一致性。

**🔧 技术方法**

采用大型预训练LLM（Claude Sonnet 3.5）进行知识图谱抽取和解释生成，随后使用SFT与DPO进行后训练；评估使用常见法律基准。

**📊 数据集**

主要数据集为约12K份美国法庭判例（含事实、问题、规则、结论），以及LexGLUE、LegalBench、COLIEE、δ‑Stance、SuperGPQA等公开评测集。

**📈 对比分析**

与原始模型对比，IRAC KG后训练在14项任务中提升了10–13项；DPO进一步提升平均分，部分模型（如Llama3.1‑70B DPO）在法律推理子任务上接近或超过141B级别的SaulLM。

**⚠️ 局限性**

局限在于仅覆盖美国普通法，数据规模有限，未涉及跨系统法律或其他高风险领域；后训练对环境能耗影响大；缺乏真实用户部署与反馈验证。

---

## 775. Zero-free regions and concentration inequalities for hypergraph colorings in the local lemma regime

**arXiv ID:** 2601.13796 | [PDF](https://arxiv.org/pdf/2601.13796v1)

**作者:** Jingcheng Liu `[一作]` (Nanjing University), Yixiao Yu `[通讯]` (Nanjing University)

**通讯引用:** 35 | [OpenAlex ID](https://openalex.org/A5102447002)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce`

**🎯 论文内容**

研究了在满足采样LLL（Sampling LLL）条件下，k‑uniform 超图 q‑着色问题的配分函数在复平面上关于区间 [0,1] 的零自由带，进而得到该问题的中心极限定理（CLT）、局部中心极限定理（LCLT）以及 Chebyshev 型不等式，并给出了基于零自由带的确定性 FPTAS。该框架进一步推广到一般约束满足问题（CSP）并证明了 Fisher 零（Fisher zeros）对应的零自由区间。

**💡 创新点**

① 将 Lee‑Yang 零和 Fisher 零的研究从图多项式推广到任意 CSP；
② 设计了投影‑提升（projection‑lifting）方案，将复杂度较低的投影分布与原始复杂分布关联；
③ 将复数 Markov 链（复数 Glauber 动态）与图的 percolation 结构结合，构造了 witness‑graph、bad‑cluster 等新概念，用以在复平面上分析边缘测度；
④ 通过上述技术，给出了在 q ≳ Δ^5/k-2.5 条件下的零自由区间，从而实现了更高效的确定性 FPTAS。

**🔧 技术方法**

主要技术包括：
- 复数拓展的 Glauber 动态与系统扫描动态的复杂分析；
- 投影‑提升方案（state‑compression + lifting）与对应的分解（oblivious / adaptive）步骤；
- 复数 Markov 链的收敛与边缘测度上限证明；
- 以 percolation 方式构造 witness‑graph、bad‑tree 以及 bad‑cluster；
- 采样LLL 与局部均匀性（local uniformity）相结合，得到对误差与方差的上界。

**📊 数据集**

本工作为纯理论分析，未使用任何具体数据集。实验部分通过符号推导与极限计算验证了零自由带与 CLT 的正确性。

**📈 对比分析**

与之前仅在 q ≳ Δ^2 + o_q(1)/k-2 条件下可获得的 FPTAS 相比，本研究的零自由带与 FPTAS 在 q ≳ Δ^5/k-2.5 条件下成立，虽然距离最优阈值仍有一定差距，但在该范围内实现了更快的确定性计数算法（多项式时间）以及 CLT 的非渐近性证明。

**⚠️ 局限性**

1) 零自由区间与 FPTAS 仍仅在 q ≳ Δ^5/k-2.5 条件下适用，尚未达到最优的 q ≳ Δ^2 + o_q(1)/k-2；
2) 对于更一般的 CSP，当前仅能在投影子问题上得到零自由，仍需进一步研究如何直接在原始问题上证明零自由；
3) 复数 Markov 链的收敛证明相对复杂，难以直接推广到更大类的交互模型；
4) 对于高阶超图（k 远大于 50）和非常稀疏结构的理论边界尚未最优。

---

## 776. GuideTouch: An Obstacle Avoidance Device for Visually Impaired

**arXiv ID:** 2601.13813 | [PDF](https://arxiv.org/pdf/2601.13813v1)

**作者:** Timofei Kozlov `[一作]` (Skolkovo Institute of Science and Technology), Dzmitry Tsetserukou `[通讯]` (Skolkovo Institute of Science and Technology)

**通讯引用:** 1963 | [OpenAlex ID](https://openalex.org/A5056458774)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `c7913869-b026-40e7-b14b-dfd72dc55ea0`

**🎯 论文内容**

开发并评估了一款名为 GuideTouch 的可穿戴障碍物规避装置，利用两块垂直排列的 ToF 传感器实现三维环境感知，并通过四个振动马达在肩部和胸前提供方向性触觉反馈；对其触觉模式识别准确率进行了实验验证；并在 14 名视障用户中进行了初步应用测试。

**💡 创新点**

1) 采用自旋式离心清洁光学罩，提升户外使用时的传感器抗污性能；2) 通过四点触觉反馈实现简洁直观的方向提示，减少对传统白手杖的依赖；3) 在低成本可穿戴框架内实现 500 g 以内的轻量化设计，配备自供电与定位报警功能。

**🔧 技术方法**

时间飞行（Time‑of‑Flight）传感器（VL53L5CX）、ESP32 微控制器、四个振动马达、离心式自清洁机、电容式报警模块、低功耗蓝牙/有线通信（用于实验交互）等硬件技术。

**📊 数据集**

未使用公开数据集；实验数据来源于 22 名普通受试者（单/双/三/四个马达组合共 15 种模式）与 14 名视障用户（单/双马达模式）在实验室静态测试环境中收集的触觉识别结果。

**📈 对比分析**

通过混淆矩阵与单因素方差分析（ANOVA）评估不同触觉模式的识别准确率；单/双马达模式平均准确率达到 92.9%，三/四马达模式显著下降。与传统手杖或基于摄像头的视觉辅助系统没有直接量化对比，但实验结果显示 GuideTouch 在静态条件下已能实现高准确率的方向提示，且设备重量轻、功耗低、成本约 100 USD。

**⚠️ 局限性**

1) 模式复杂度高时识别准确率显著下降；2) 实验仅在静态环境下进行，未验证动态行走或拥挤场景的鲁棒性；3) 受试者样本量有限，且部分受试者因佩戴不适导致误差；4) 目前的传感器分辨率受限，难以检测极细或低反射率障碍物。

---

## 777. Fit Matters: Format-Distance Alignment Improves Conversational Search

**arXiv ID:** 2601.13778 | [PDF](https://arxiv.org/pdf/2601.13778v1)

**作者:** Yitian Yang `[一作]` (National University of Singapore), Yi-Chieh Lee `[通讯]` (National University of Singapore)

**通讯引用:** 1685 | [OpenAlex ID](https://openalex.org/A5054435118)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在会话式搜索中开展实验，检验将信息呈现格式（粒度+媒介）与用户心理距离（时间/空间）匹配是否提升体验。

**💡 创新点**

首次提出并实证验证“格式–心理距离一致性”这一设计维度，证明匹配可显著提升决策信心、易用性、可信度等指标。

**🔧 技术方法**

采用实验设计、CLT理论框架、NASA‑TLX认知负荷量表、LIWC文本分析等技术手段。

**📊 数据集**

使用 464 名美国在线受试者的数据，四种格式（抽象文本、详细文本、抽象图文、详细图文）与两维心理距离（近/远）交叉，形成 16 个实验条件。

**📈 对比分析**

通过方差分析与效应量比较，匹配条件在所有体验维度上均显著提升（p<.001），效应量约为 0.3–0.6，说明匹配带来 20–40% 的主观体验提升。

**⚠️ 局限性**

局限包括单轮交互、仅涉及旅游规划情境、仅操纵时间与空间维度、样本仅为英语美国成人且未评估客观决策质量。

---

## 778. The Limits of Conditional Volatility: Assessing Cryptocurrency VaR under EWMA and IGARCH Models

**arXiv ID:** 2601.13757 | [PDF](https://arxiv.org/pdf/2601.13757v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

---

## 779. Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance

**arXiv ID:** 2601.13770 | [PDF](https://arxiv.org/pdf/2601.13770v1)

**作者:** Mostapha Benhenda `[一作]` `[通讯]`, Mostapha Benhenda

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `5a41884c-404f-4688-a89c-aa238c10fe68` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

创建了Look‑Ahead‑Bench基准，用于测量金融领域点‑时间LLM的前瞻性偏差；

**💡 创新点**

创新点在于将真实交易工作流与Alpha衰减指标相结合，系统评估模型在不同时间段的泛化能力；

**🔧 技术方法**

采用AI Hedge Fund框架实现多智能体交易决策，利用Alpha、Alpha衰减等量化指标进行评估；

**📊 数据集**

使用美国大型科技股（AAPL、MSFT、GOOGL、NVDA、TSLA）在两个时间段（2021年与2024年）构建的历史行情数据；

**📈 对比分析**

通过与传统量化基准（买入持有、等权、动量、均值回归、MA交叉等）以及标准LLM与PiT模型比较，发现标准LLM在后期表现显著衰退（Alpha衰减>−15pp），而PiT模型规模越大性能越好；

**⚠️ 局限性**

局限在于样本规模仅限5只科技股、评估周期有限，未覆盖多行业、多资产和高频交易场景，且仅使用单一交易框架。

---

## 780. DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution

**arXiv ID:** 2601.13761 | [PDF](https://arxiv.org/pdf/2601.13761v1)

**作者:** Shengda Fan `[一作]` (Renmin University of China), Yankai Lin `[通讯]` (Renmin University of China)

**通讯引用:** 12031 | [OpenAlex ID](https://openalex.org/A5043098453)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `8d10c613-917e-4880-9716-17789f50e119` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 Decoupled Asymmetric Reasoning Curriculum (DARC)，通过先训练可控难度的提问器再用异构自蒸馏的方式进行自我演化；

**💡 创新点**

核心创新在于将自我学习拆解为两阶段：①难度匹配的提问器训练消除目标漂移；②异构自蒸馏用文档增强教师生成高质量伪标签，降低噪声与自我确认偏差；

**🔧 技术方法**

使用 Group Relative Policy Optimization (GRPO) 训练提问器，采用异构自蒸馏（教师有文档，学生无文档）以及基于多数投票的伪标签；

**📊 数据集**

利用公开语料库（如DataComp‑LM、Nemotron‑CC‑Math等）生成问答对，评测在多种数学与通用推理基准（MATH‑500、GSM8K、MMLU‑Pro、GPQA‑Diamond、BBEH 等）；

**📈 对比分析**

与基线（Base、Absolute Zero、R‑Zero、R‑Few、SPICE）及监督模型 General‑Reasoner 对比，DARC 在三种 backbone（Qwen3‑4B/8B、OctoThinker‑8B）上平均提升约10.9分，单个模型可逼近监督水平；

**⚠️ 局限性**

局限性包括：①需外部语料做 grounding；②伪标签仍存在噪声；③适用于可验证答案的任务，对开放式任务不适用。

---

## 781. Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders

**arXiv ID:** 2601.13798 | [PDF](https://arxiv.org/pdf/2601.13798v1)

**作者:** Kai Wittenmayer `[一作]` (Max Planck Institute for Informatics), Jonas Fischer `[通讯]` (Max Planck Institute for Informatics)

**通讯引用:** 870 | [OpenAlex ID](https://openalex.org/A5007776675)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了一种语言对齐的概念基础模型，可从 CLIP‑DINOiser 特征中无监督学习层级化、空间根植、可命名的概念，并用这些概念解释多任务视觉决策。

**💡 创新点**

创新点包括：① 采用 Matryoshka 稀疏自编码器与 BatchTopK 机制在不同粒度上提取概念；② 通过局部共现分析构建父子关系图并利用该层级提升概念命名；③ 在分类、开窗语义分割和图像字幕生成等下游任务上保持可解释性同时保持性能。

**🔧 技术方法**

主要技术手段有：CLIP‑DINOiser 引导池化提取局部特征；Matryoshka 稀疏自编码器 + BatchTopK 构建层级稀疏概念；概念共现图构建父子关系；层级感知标签匹配结合 CLIP 文本编码器进行概念命名。

**📊 数据集**

使用的数据集包括 ImageNet、Places365、PartImageNet、COCO‑stuff、COCO caption、ADE20K、PASCAL VOC/Context、Cityscapes、COCO‑Stuff 以及 Amazon MTurk 进行概念一致性与关系评估。

**📈 对比分析**

与现有概念瓶颈模型（LF‑CBM、LaBo、CDM、DCLIP 等）以及黑盒 VLM 在分类、开窗分割和字幕生成上做了线性分类头或微调对比；在分类上与最优概念方法相当，在开窗语义分割上与 CLIP‑DINOiser/OVDiff 性能持平或更优，在字幕任务上保持相近性能且可通过概念编辑改变输出。

**⚠️ 局限性**

局限性：概念命名仍受 CLIP‑DINOiser 文本-图像联合编码器偏差影响，部分概念可能出现偶然关联；需更大词表与更细粒度评估；在生成性任务上对概念细粒度控制尚未完全成熟。

---

## 782. Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues

**arXiv ID:** 2601.13742 | [PDF](https://arxiv.org/pdf/2601.13742v1)

**作者:** Arjun Chandra `[一作]` (Boston University), Venkatesh Saligrama `[通讯]` (Boston University)

**通讯引用:** 8945 | [OpenAlex ID](https://openalex.org/A5048704387)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了TRACE框架和Human Chain-of-Thought（HCoT）重标注方案，用两阶段无训练方法在音频特征蓝图与LLM推理的基础上对语音转语音模型进行多维度（内容、语音质量、旁语音特征）评估；

**💡 创新点**

创新点在于：①利用低成本音频特征蓝图让文本LLM“听”到音频信息；②引入Typed‑Tie的HCoT重标注，拆解整体评价为可解释的维度评分；③训练‑free的两阶段流程与确定性融合策略，兼顾可审计性与成本效益；

**🔧 技术方法**

技术手段包括：语音识别（Whisper-large‑v3）、MOS预测器、openSMILE/eGeMAPS等轻量级音频特征提取；LLM（Gemini 2.5 Flash/​GPT‑4o）推理，prompting实现维度评分与推理；确定性树策略进行维度合并；

**📊 数据集**

数据集：SpeakBench 与 S2S‑Arena 两个公开的S2S人类偏好数据集，经过HCoT重新标注得到四维度（C/VQ/P/Overall）评估；

**📈 对比分析**

比较方法：以4‑way准确率（{1,2,both‑good,both‑bad}）衡量，与Audio‑Judge（仅音频）、LLM‑Judge（仅转写）以及传统ALM评测对比；结果显示TRACE在整体和VQ/P维度上明显优于基线，且成本约为Audio‑Judge的三分之一；

**⚠️ 局限性**

局限性：仅在英文数据上验证，跨语言推广未知；特征模式手工设定，可能遗漏细粒度属性；依赖前置音频提取器错误，需进一步校正与自适应优化。

---

## 783. Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering

**arXiv ID:** 2601.13752 | [PDF](https://arxiv.org/pdf/2601.13752v1)

**作者:** Chak Tou Leong `[一作]` (Hong Kong Polytechnic University), Wenjie Li `[通讯]` (Hong Kong Polytechnic University)

**通讯引用:** 11482 | [OpenAlex ID](https://openalex.org/A5100408983)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了基于推理信念工程（Reasoning Belief Engineering）的框架，通过对大推理模型内部推理信念的对齐，实现不依赖推理轨迹的行为塑造；

**💡 创新点**

创新点在于发现并利用LRM内部的可探测推理信念，借助自我反思的问答对而非冗长推理轨迹来引导模型行为；

**🔧 技术方法**

核心技术包括对内部logit进行探测、构建目标信念蓝图、生成自我反思问答对并通过监督微调实现信念内化；

**📊 数据集**

实验使用了Qwen3-8B和R1‑Qwen‑7B两大模型，效率评测基于GSM8K、MATH‑500、AMC 2023、AIME 2024，信念评测基于MMLU‑Redux和GPQA‑Diamond；

**📈 对比分析**

与SFTShortest、SimPOShortest、EfficientBelief等基线对比，所提方法在保持甚至提升准确率的同时实现了显著的推理长度压缩（约10‑20倍降低训练token），并在信念任务上匹配或优于传统轨迹监督方案；

**⚠️ 局限性**

局限性包括仅在7B‑8B模型上验证、仅使用SFT而非RL、可能无法提升核心推理能力、以及在多任务中不同信念相互影响等问题。

---

## 784. FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation

**arXiv ID:** 2601.13837 | [PDF](https://arxiv.org/pdf/2601.13837v1)

**作者:** Xinya Ji `[一作]` (Nanjing University), Derek Bradley `[通讯]` (Disney Research Studios)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

设计了一种前馈网络，能够仅用少量输入图像快速生成高质量、可实时动画的3D高斯头部头像。

**💡 创新点**

创新点包括：①将预训练的Diffusion VAE与DINOv3特征通过Transformer融合以获得多视图一致的表示；②为每个高斯引入特征向量，并用轻量化MLP根据FLAME表达式码实现实时变形；③利用VGGT几何先验作为监督，提升头部几何平滑度。

**🔧 技术方法**

使用技术包括3D Gaussian Splatting、Vision Transformer、多视图特征融合、Stable Diffusion VAE、DINOv3、轻量化MLP、VGGT几何监督、FLAME表达式编码。

**📊 数据集**

训练和评估使用Ava-256与Nersemble两个多视图视频数据集。

**📈 对比分析**

与InvertAvatar、GPAvatar、Avat3r等SOTA方法在PSNR/SSIM/LPIPS/CSIM/AKD等指标上均表现更好；重建时间不足1秒，实时动画帧率可达128 FPS。

**⚠️ 局限性**

局限性：依赖精确相机参数；不能控制舌头运动；在光照/视角与训练分布差异较大时表现可能受限；使用的几何先验与训练数据相关。

---

## 785. The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations

**arXiv ID:** 2601.13835 | [PDF](https://arxiv.org/pdf/2601.13835v1)

**作者:** Sam OConnor Russell `[一作]`, Naomi Harte `[通讯]` (Trinity College Dublin)

**通讯引用:** 4637 | [OpenAlex ID](https://openalex.org/A5042231269)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

使用语音韦克多器分离韵律与词汇信息，检验 SSL 基础的交替说话模型是否依赖于这两类线索。

**💡 创新点**

首次用 vocoder 干净地隔离韵律与词汇信号，证明 SSL 中这两类特征可独立编码且交替使用。

**🔧 技术方法**

采用 WORLD vocoder、SSL 前端（CPC、wav2vec2.0）、VAP 交替说话模型。

**📊 数据集**

CANDOR 口语语料库（约 850 小时英语对话）。

**📈 对比分析**

将模型在清晰语音、韵律匹配噪声、韵律平坦化、背景噪声等条件下测试，发现韵律匹配噪声可获得约 90% 纯净语音精度，说明韵律足以支撑交替说话，且两类线索互不依赖。

**⚠️ 局限性**

只研究英语，韵律匹配噪声可能仍携带残余声学信息；未验证跨语言普适性。

---

## 786. DroneVLA: VLA based Aerial Manipulation

**arXiv ID:** 2601.13809 | [PDF](https://arxiv.org/pdf/2601.13809v1)

**作者:** Fawad Mehboob `[一作]` (Skolkovo Institute of Science and Technology), Dzmitry Tsetserukou `[通讯]` (Skolkovo Institute of Science and Technology)

**通讯引用:** 1963 | [OpenAlex ID](https://openalex.org/A5056458774)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `e0540dec-d77f-42db-94ae-d039248f6393` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出并实现了一套基于 Vision‑Language‑Action (VLA) 的无人机操纵系统，能够通过自然语言指令让无人机识别、抓取并交付物体给人类。

**💡 创新点**

创新点在于将开源视觉语言模型 Grounding DINO 与轻量级 VLA 结合，形成离线语义推理与实时视觉伺服分离的架构；同时利用 MediaPipe 对人类姿态进行实时估计，设计了人类中心的安全交接控制。

**🔧 技术方法**

核心技术包括：Grounding DINO（开箱即用的跨模态物体检测）、TinyVLA（轻量级视觉‑语言推理网络）、Intel RealSense RGB‑D 相机、MediaPipe Pose、基于 A* 的人类感知路径规划、ROS 2 分布式通信以及 1‑DOF 开闭式抓手。

**📊 数据集**

主要使用的测试数据为室内实验室环境中的 15–20 件日常物品与人类参与者，采用 Vicon 运动捕捉系统提供的实时位姿作为地面真值；在仿真中使用 Unity 生成视觉帧以验证 VLA 的抓取策略。

**📈 对比分析**

通过 10 次随机实验对比评估，系统在对象‑人类路径上平均 Euclidean 距离误差为 0.070 m，最大误差 0.164 m，均方根误差 0.084 m；所有实验均成功完成，且无人机在交接过程中始终保持约 1 m 的安全距离。

**⚠️ 局限性**

局限性包括：仅使用 1‑DOF 抓手，VLA 目前仅实现离线的二元抓取命令，未实现闭环实时控制；系统对极端动态环境或复杂抓取姿态的鲁棒性尚未验证；缺乏针对多目标与高维动作空间的端到端训练数据。

---

## 787. HoverAI: An Embodied Aerial Agent for Natural Human-Drone Interaction

**arXiv ID:** 2601.13801 | [PDF](https://arxiv.org/pdf/2601.13801v1)

**作者:** Yuhua Jin `[一作]` (Chinese University of Hong Kong), Dzmitry Tsetserukou `[通讯]` (Skolkovo Institute of Science and Technology)

**通讯引用:** 1963 | [OpenAlex ID](https://openalex.org/A5056458774)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `b88c6eac-d57a-4623-a604-1f401f3eb268` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出并实现了一种名为 HoverAI 的可悬停无人机，集成 MEMS 激光投影、RGB 摄像头和实时语音/文本交互，能够在空中投射同步口型的虚拟头像并与人类进行自然对话。

**💡 创新点**

创新点包括：①在无人机上实现无外部投影屏的自足视觉输出；②将语音识别、意图分类、检索增强生成（RAG）和文本转语音串联为完整的实时交互流水线；③通过面部年龄/性别检测实现头像的动态个性化；④实现完全移动化、空间感知的社会化代理。

**🔧 技术方法**

采用技术有：MEMS 激光投影与半刚性投影膜、RGB 1080p 摄像头、VAD、Whisper‑medium ASR、Gemma:7b‑instruct 语义分类、RAG+领域知识库、XTTS v2 语音合成、InsightFace 人脸分析、Orange Pi 5 计算平台、Speedybee F405V4 飞控、Wi‑Fi 音频流。

**📊 数据集**

使用的数据集包括：实验收集的 12 名受试者的语音与视觉数据；Whisper、Gemma、InsightFace 的公开预训练模型；RAG 采用 150 条机器人/博物馆相关事实作为知识库；无公开大规模数据集，主要通过现场实验数据评估。

**📈 对比分析**

评估方法：在受控实验室中让 12 名受试者完成语音指令、对话查询和面部追踪任务；通过 WER、F1、MAE 等指标量化性能；结果显示：语音识别 WER 0.181，命令识别 F1 0.90，性别识别 F1 0.89，年龄估计 MAE 5.14 年；端到端延迟约 950 ms，能够支持自然的对话节奏。

**⚠️ 局限性**

局限性：①飞行时间约 12 min；②投影受风、光照影响，室外使用受限；③Wi‑Fi 传输限制操作范围约 15 m；④振动导致投影失真；⑤未对用户主观体验（安全感、信任度）进行评估；⑥隐私伦理问题（面部/语音采集、数据处理）；⑦RAG 知识库规模有限，难以处理跨领域查询。

---

## 788. PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval

**arXiv ID:** 2601.13797 | [PDF](https://arxiv.org/pdf/2601.13797v1)

**作者:** Gabriele Serussi `[一作]` (Bosch Center for AI), Chaim Baskin `[通讯]` (INSIGHT Lab)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种基于冻结视觉语言模型的多层隐藏状态聚合框架，用于组合视频检索。

**💡 创新点**

创新点在于利用所有层的最终标记隐藏状态聚合，并通过轻量级Transformer编码，无需微调或生成字幕。

**🔧 技术方法**

采用冻结的VLM（如Qwen‑VL）提取隐藏状态、Transformer编码、对比学习InfoNCE以及基于来源的硬负样本挖掘。

**📊 数据集**

使用WebVid‑CoVR、FineCVR以及Dense WebVid‑CoVR等公开基准数据集。

**📈 对比分析**

与现有方法相比，Recall@1提升约27%至70%，在所有VLM骨干上均保持领先，并能稳健处理更复杂的文本修改。

**⚠️ 局限性**

局限在于当前基准可能无法充分体现真实场景的时空推理需求，且方法仍需在更具挑战性的动态视频任务上进一步验证。

---

## 789. Demystifying Starlink Network Performance under Vehicular Mobility with Dynamic Beam Switching

**arXiv ID:** 2601.13790 | [PDF](https://arxiv.org/pdf/2601.13790v1)

**作者:** Jinwei Zhao `[一作]` (University of Victoria), Jianping Pan `[通讯]` (University of Victoria)

**通讯引用:** 8663 | [OpenAlex ID](https://openalex.org/A5043097022)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一种面向移动Starlink用户终端的卫星识别与动态波束切换检测方法，揭示在移动环境中卫星切换可多次发生并导致网络性能下降；

**💡 创新点**

创新点在于将障碍图与UT运动信息结合，使用XOR与连通组件算法实现动态波束切换检测，并在同一15秒窗口内识别多颗通信卫星；

**🔧 技术方法**

利用Starlink gRPC接口的障碍图、UT姿态四元数、UT位置、时序日志，以及SGP4轨道预测、连接事件日志；

**📊 数据集**

使用约500公里行驶量的现场数据（共5小时）以及对比的固定站点UT实验，涵盖农村、城市、郊区与高速公路等环境；

**📈 对比分析**

通过与现有基于单卫星假设的识别算法对比，移动环境下平均角度误差由2.37°提升至5.44°，但能正确捕捉多次切换事件；网络测量显示动态切换引发的丢包与吞吐下降明显，且恢复主要靠后续固定时隙切换；

**⚠️ 局限性**

局限性包括障碍图分辨率仅为123×123像素，难以区分相邻卫星；未公开通信卫星ID导致识别仍基于轨道匹配；并且对极端振荡、海上/航空场景的验证不足。

---

## 790. A Blockchain-Oriented Software Engineering Architecture for Carbon Credit Certification Systems

**arXiv ID:** 2601.13772 | [PDF](https://arxiv.org/pdf/2601.13772v1)

**作者:** Matteo Vaccargiu `[一作]` (University of Cagliari), Pierluigi Gallo `[通讯]` (University of Palermo)

**通讯引用:** 1661 | [OpenAlex ID](https://openalex.org/A5061510917)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种基于IoT和许可区块链的四层碳信用认证架构，并在100kWp光伏案例中演示其可行性。

**💡 创新点**

创新点在于将实时物联网数据与Hyperledger Fabric智能合约结合，形成从测量、聚合到区块链认证的完整流程，满足欧盟法规与自愿碳市场标准，并针对中小规模光伏项目提供可操作的认证路径。

**🔧 技术方法**

使用技术包括：物联网智能电表、Raspberry Pi边缘计算节点、分钟级数据聚合、JSON序列化、Hyperledger Fabric许可区块链、链码智能合约以及双向网络通信。

**📊 数据集**

数据集基于100kWp光伏系统的假设测量数据（每秒/每分钟功率、电压、电流等），通过聚合产生每日1440条分钟记录。

**📈 对比分析**

通过将1440条原始记录压缩为288条5分钟批量区块链交易，预计可将交易成本降低约80%；Fabric在理论上可达3500 TPS、2‑3 s延迟、低能耗，系统性能仍待真实部署验证。

**⚠️ 局限性**

局限性包括：缺乏实测数据、对设备精度和碳排放系数的假设、对网络稳定性的依赖、未完成成本效益分析、仅针对欧盟法规，跨地区适用性需进一步验证。

---

## 791. Interoperable rApp/xApp Control over O-RAN for Mobility-aware Dynamic Spectrum Allocation

**arXiv ID:** 2601.13769 | [PDF](https://arxiv.org/pdf/2601.13769v1)

**作者:** Anastasios Giannopoulos `[一作]` (Four Dot Infinity), Panagiotis Trakadas `[通讯]` (Four Dot Infinity)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `3f18e8e3-0266-457c-8567-9039b6d2394d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

研究了一种基于rApp/xApp的可互操作动态频谱分配框架，在O‑RAN中实现长期流量预测与近实时图论调度。

**💡 创新点**

创新点是将Non‑RT RIC的长周期流量预测与Near‑RT RIC的冲突图着色和改进比例公平调度结合，形成多时钟闭环，实现了高成功率与公平性。

**🔧 技术方法**

采用机器学习预测模型（LSTM）、图着色算法（Welsh‑Powell/DSatur/Greedy）、冲突图构建、改进比例公平（MPF）以及O‑RAN标准接口（O1、A1、E2）。

**📊 数据集**

使用公开的5G流量时间序列数据集，包含按15分钟采样的用户负载与流量统计。

**📈 对比分析**

通过与随机、顺序着色、Round‑Robin等基线比较，实验显示成功率>90%、公平性JFI≥85%，在不同频谱分辨率和用户需求下均优于基线。

**⚠️ 局限性**

限制包括模型对极端突发干扰的适应性有限，需进一步研究能耗与跨域协同，以及对大规模网络的可扩展性验证。

---

## 792. vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting

**arXiv ID:** 2601.13768 | [PDF](https://arxiv.org/pdf/2601.13768v1)

**作者:** Wenzhen Yue `[一作]` (Peking University), Xianghua Ying `[通讯]` (Peking University)

**通讯引用:** 1209 | [OpenAlex ID](https://openalex.org/A5015981200)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出 vLinear，一种线性基线多变量时间序列预测模型，包含轻量级的 vecTrans 依赖学习模块和针对最终预测的 WFMLoss 损失。

**💡 创新点**

创新点在于：① vecTrans 通过学习一个向量实现 O(N) 级别的多变量相关建模，显著降低自注意力的 O(N²) 复杂度；② WFMLoss 采用路径和预测区间加权的最终序列流匹配损失，优于传统速度导向或点误差损失；③ 两个模块可无缝插拔到现有 Transformer 或线性模型中。

**🔧 技术方法**

使用的技术包括：线性变换、向量聚合广播、正则化归一化、流匹配理论、路径/区间权重、实例归一化、正交变换、MLP 时序建模。

**📊 数据集**

在 22 个公开多变量时序数据集（如 ETT, ECL, Traffic, Weather, PEMS, 交易与能源等）以及 124 种不同预测长度/设置上进行实验。

**📈 对比分析**

通过与 13 余前沿基线（线性、Transformer、TCN）以及 8 个 Attention 变体对比，vLinear 在绝大多数数据集上取得了 SOTA 的 MSE/MAE，并且在推理时 GPU 记忆占用和 FLOPs 都低于自注意力模型，推理速度提升高达 5 倍。

**⚠️ 局限性**

局限性包括：① 对于极高维或稀疏相关的场景，单向向量的表示可能不足，需进一步探索更高秩或多头扩展；② WFMLoss 在极短预测窗口或噪声较大时的鲁棒性尚未充分验证；③ 目前仅针对确定性预测，概率预测仍需改进。

---

## 793. TransMode-LLM: Feature-Informed Natural Language Modeling with Domain-Enhanced Prompting for Travel Behavior Modeling

**arXiv ID:** 2601.13763 | [PDF](https://arxiv.org/pdf/2601.13763v1)

**作者:** Meijing Zhang `[一作]` (Singapore University of Technology and Design), Ying Xu `[通讯]` (Singapore University of Technology and Design)

**通讯引用:** 193 | [OpenAlex ID](https://openalex.org/A5090685125)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

通过将旅行调查数据中的关键特征转化为自然语言描述，利用大型语言模型（LLM）预测旅行者的出行模式，并提出了TransMode-LLM框架。

**💡 创新点**

创新点在于：① 用特征重要性分析筛选出15个最具预测力的变量；② 将结构化特征系统化转化为可读的自然语言叙述；③ 结合零/一/少量示例学习与域知识增强的提示工程（标准模式定义和三步决策链）提升LLM在出行模式预测任务上的表现。

**🔧 技术方法**

技术包括特征重要性排序（XGBoost、随机森林、Lasso等）、基于模板的文本生成、LLM推理（GPT‑4o、GPT‑4o‑mini、o3‑mini、o4‑mini），以及少量示例学习和域知识增强提示。

**📊 数据集**

使用美国联邦公路管理局（FHWA）发布的全国通勤者出行调查（NHTS）真实样本，包含22,868条记录和85个属性，筛选出约90%占比的6种主要出行模式。

**📈 对比分析**

在多种样本规模（100、200、500、1,000）下与传统分类器（LogitBoost、Gradient Boosting）比较，LLM在零样本下已与基准相当，少量示例学习提升幅度可达42.9%；域知识增强对GPT‑4o系列提升2.3%–12.5%，但对o系列模型往往无效。整体精度与F1‑macro/F1‑weighted均显示少量示例学习能显著缩小精度与类别平衡差距，提升对少数类别的识别。

**⚠️ 局限性**

局限包括：① 仅在美国车主化社会中验证，跨国泛化待评估；② 未考虑不同人口子组（年龄、收入、家庭结构）的预测差异；③ 依赖通用LLM，未探讨专门为交通领域预训练的模型；④ 域知识增强效果高度模型依赖，缺乏统一的最佳实践。

---

## 794. Principled Latent Diffusion for Graphs via Laplacian Autoencoders

**arXiv ID:** 2601.13780 | [PDF](https://arxiv.org/pdf/2601.13780v1)

**作者:** Antoine Siraudin `[一作]` (RWTH Aachen University), Christopher Morris `[通讯]` (RWTH Aachen University)

**通讯引用:** 16785 | [OpenAlex ID](https://openalex.org/A5111798651)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `ba576bd1-e51d-44e8-8077-fc943b333c93` `40105733-5154-44cd-8090-a8cab9e64b07` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出LG-Flow框架，在可交换的拉普拉斯图变分自编码器（LG‑VAE）基础上实现图的潜在扩散生成，解决传统图扩散的二次复杂度和稀疏图中对无边信息的冗余建模；

**💡 创新点**

① 使用拉普拉斯及磁性拉普拉斯位置编码构造可逆节点嵌入，保证邻接矩阵可从潜在中完整恢复；② 证明潜在维度线性随节点数扩展，消除二次瓶颈；③ 将流匹配与Diffusion Transformer应用于潜在空间，保持模型通用性；④ 同时支持无向图和DAG生成；

**🔧 技术方法**

拉普拉斯/磁性拉普拉斯位置编码、GIN/GINE编码器、双线性解码+DeepSet、变分自编码器、流匹配（Flow Matching）、Diffusion Transformer（DiT）、对偶图编码等；

**📊 数据集**

Synthetic：Extended Planar、Tree、Ego；分子：Moses、GuacaMol；DAG：TPU Tile；以及MOSES、GuacaMol的各类分子指标数据；

**📈 对比分析**

与DiGress、SparseDiff、Cometh、DeFoG、DisCo、LayerDAG、Directo等模型对比。LG‑Flow在MMD、Validity、V.U.N、KL-div、FCD等指标上与最先进方法相当或稍优，显著提升采样速度（10‑1000倍）与显存占用；在DAG任务上速度提升高达680×；

**⚠️ 局限性**

在DAG生成中仍存在一定的记忆化，导致多样性略低；潜在空间虽然线性，但对极大图的鲁棒性尚待进一步验证；模型需先训练并冻结编码器，增加整体训练复杂度；

---

## 795. HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection

**arXiv ID:** 2601.13751 | [PDF](https://arxiv.org/pdf/2601.13751v1)

**作者:** Daniel Kyselica `[一作]` (Zaitra s.r.o.), Rado Pitoňák `[通讯]` (Zaitra s.r.o.)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在小卫星有限的存储和计算资源下实现连续洪水检测系统

**💡 创新点**

提出 History Injection Transformer（HiT）机制，将历史影像压缩为可注入的嵌入，实现多时相信息的持续利用且存储量仅为原始影像的0.4%

**🔧 技术方法**

使用 Prithvi‑EO‑2.0‑tiny ViT 编码器、FPN 解码器、HiT 注入块与适配器、交叉熵+Dice 损失、AdamW 优化、CutMix 变体增强

**📊 数据集**

基于 Sentinel‑2 数据的 RaVAEn 与 STTORM‑CD 洪水数据集，采用改进 CutMix 生成连续时序样本

**📈 对比分析**

与双时相基准相比，HiT‑Prithvi 在 STTORM‑CD 测试集上取得 F1≈0.48（基准 0.52），在 Jetson Orin Nano 上以 43 FPS 运行，存储压缩率达到 99.6%，仅需数 GB 即可覆盖欧洲

**⚠️ 局限性**

缺乏真实的连续变更测试集，模型对细微变化的检测能力有限，时间持久性与多事件跟踪尚未得到充分验证

---

## 796. MirageNet:A Secure, Efficient, and Scalable On-Device Model Protection in Heterogeneous TEE and GPU System

**arXiv ID:** 2601.13826 | [PDF](https://arxiv.org/pdf/2601.13826v1)

**作者:** Huadi Zheng `[一作]`, Yan Ding `[通讯]`

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种基于卷积核分解的模型加密方案ConvShatter，能够在TEE‑GPU异构环境下对边缘设备上的深度网络权重实现高效安全推理。

**💡 创新点**

创新点在于将每个卷积核拆分为关键核与共享基底，并注入伪基底、通道与核顺序混洗，消除相似性先验，既保持零精度损失，又显著降低加密开销。

**🔧 技术方法**

主要技术包括卷积核分解、共享基底与伪基底注入、通道/核顺序混洗、一次性加密遮蔽、TEE侧恢复、GPU侧并行卷积与CUDA优化。

**📊 数据集**

实验使用CIFAR‑10、CIFAR‑100、SVHN三大数据集，模型涵盖AlexNet、ResNet‑18/50、VGG16‑BN。

**📈 对比分析**

在与Mag、Soter、ShadowNet、GroupCover等现有加密方案对比时，ConvShatter保持原模型精度不变，攻击成功率降至接近随机水平，推理延迟仅比GroupCover低约30%，吞吐率恢复到基线的约70%。

**⚠️ 局限性**

局限性包括：对极大规模查询的自适应攻击仍可能逼近黑盒上限；目前仅针对标准卷积，未覆盖注意力或深度可分离卷积；侧信道防护需进一步强化。

---

## 797. Device Association and Resource Allocation for Hierarchical Split Federated Learning in Space-Air-Ground Integrated Network

**arXiv ID:** 2601.13817 | [PDF](https://arxiv.org/pdf/2601.13817v1)

**作者:** Haitao Zhao `[一作]` (Nanjing University of Posts and Telecommunications), Linghao Zhang `[通讯]` (Nanjing University of Posts and Telecommunications)

**通讯引用:** 20 | [OpenAlex ID](https://openalex.org/A5075847935)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了层级分割联邦学习（HSFL）框架，用于在空间-航空-地面集成网络（SAGIN）中解决资源受限与数据分布不均衡导致的训练效率与模型精度下降问题。

**💡 创新点**

创新点包括：①将分层分割联邦学习引入SAGIN结构，降低终端设备计算负担；②基于收敛分析构建联合优化问题，统筹考虑分割层、设备关联与资源分配；③利用KKT闭式求解与分层搜索的迭代算法，实现高效求解；④通过设备关联优化缓解数据异构带来的模型偏差。

**🔧 技术方法**

技术手段包括：分层分割联邦学习、混合整数非线性规划（MINLP）建模、拉格朗日松弛与KKT条件求解、二分搜索求最优带宽分配、梯度下降与收敛上界分析。

**📊 数据集**

使用CIFAR‑10数据集，训练AlexNet模型；每台移动设备仅包含10类中的4类样本，以模拟非独立同分布（non‑IID）场景。

**📈 对比分析**

与四种基线（随机关联、等资源分配、无分割的层级联邦学习、基于数据分布的关联）对比，HSFL在相同训练时延下提升约2.7%的最终测试准确率，收敛时延降低约23%。此外，实验还验证了总上行带宽与UAV计算能力对目标函数和时延的影响。

**⚠️ 局限性**

局限性主要体现在：①需要预先搜索所有可能的分割层，计算复杂度随层数成线性关系；②假设设备关联、带宽与计算资源均可精确分配，实际网络中可能存在不可预知的链路衰落与资源波动；③未考虑动态分割层自适应调整，适应时变网络环境的能力有限。

---

## 798. Discriminant Learning-based Colorspace for Blade Segmentation

**arXiv ID:** 2601.13816 | [PDF](https://arxiv.org/pdf/2601.13816v1)

**作者:** Raül Pérez-Gonzalo `[一作]` (Institut de Robòtica i Informàtica Industrial), Antonio Agudo `[通讯]` (Institut de Robòtica i Informàtica Industrial)

**通讯引用:** 33575 | [OpenAlex ID](https://openalex.org/A5028140968)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种基于多维非线性判别分析的颜色空间转换算法CSDA，用于对风机叶片图像进行预处理以提升分割精度。

**💡 创新点**

创新点在于将线性判别分析推广到非线性多维深度判别分析，并通过签名类间方差矩阵避免传统LDA在非线性优化中的不稳定性，实现可学习的颜色空间变换。

**🔧 技术方法**

采用U‑Net架构的端到端网络，结合CSDA的三种判别损失（CSDA、log‑CSDA、Δ‑CSDA）与焦点分割损失，使用Adam优化器和学习率调度。

**📊 数据集**

数据集为在不同风电场使用无人机拍摄的叶片图像，训练集与测试集来自不同风电场，包含叶片与背景的分割标注。

**📈 对比分析**

与多种基线模型（DeepLabv3+、U‑NetFormer、SAM等）以及仅使用判别分析或仅使用焦点损失的对照实验相比，CSDA在准确率、F1、mIoU等指标上均显著提升，达到96.98%准确率、96.20% F1、93.94% mIoU。

**⚠️ 局限性**

局限性包括对高维颜色空间的解释性不足，训练过程中需额外的判别损失计算，且仅在叶片分割场景验证，需进一步验证对其他工业分割任务的泛化能力。

---

## 799. From RTL to Prompt Coding: Empowering the Next Generation of Chip Designers through LLMs

**arXiv ID:** 2601.13815 | [PDF](https://arxiv.org/pdf/2601.13815v1)

**作者:** Lukas Krupp `[一作]` (RPTU University of Kaiserslautern-Landau), Norbert Wehn `[通讯]` (RPTU University of Kaiserslautern-Landau)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发并评估了一个基于大型语言模型（LLM）的聊天助手与 Tiny Tapeout 生态系统结合的浏览器学习平台，使高中生能在 90 分钟内完成从想法到可量产芯片的 RTL 编码、仿真与布局。

**💡 创新点**

首次将 LLM 聊天代理嵌入完整芯片设计流程，提供从需求到 GDSII 的端到端教育路径，并通过案例验证了对非专业用户的可行性。

**🔧 技术方法**

使用了 OpenAI GPT 系列 LLM、Tiny Tapeout 开源 EDA 工具链（Yosys、LibreLane）、Verilator、VGA Playground、GitHub Actions 等技术栈。

**📊 数据集**

主要数据来源于 18 名德国高中生的案例研究，共 8 组 VGA 芯片设计（SLOC、仿真日志、后端生成的 GDSII 等）。

**📈 对比分析**

评估方法为功能正确性（通过 VGA 仿真）和是否可量产（成功生成 GDSII），所有 8 组项目均通过两项指标，显示该方法在短时间内实现完整设计的有效性；与传统手工学习相比未做直接量化，但案例证明教学效果显著。

**⚠️ 局限性**

局限性包括：LLM 对后端错误（如非综合代码、面积限制）处理不足，需要教师干预；仅针对 130 nm VGA 设计和 Tiny Tapeout 生态，扩展到其他工艺或更复杂功能仍需进一步验证。

---

## 800. PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles

**arXiv ID:** 2601.13793 | [PDF](https://arxiv.org/pdf/2601.13793v1)

**作者:** ByeoungDo Kim `[一作]` (Naver Corporation), Duckky Kim `[通讯]` (Naver Corporation)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了一种利用历史速度模式注意力的轻量级ETA预测模型

**💡 创新点**

创新点在于对历史速度序列进行注意力聚合、将进入时间向量化、通过多轮迭代细化嵌入，从而在不使用图结构的情况下捕获时空因果关系

**🔧 技术方法**

使用了多层感知机（MLP）与软注意力机制、迭代重构循环、Smooth L1 和 APE 损失组合，以及多周期监督训练

**📊 数据集**

在韩国大规模真实行驶轨迹数据集（约2.94亿条路径，覆盖2024‑2025年，平均路径长度28km，平均时长35min）上训练与评估

**📈 对比分析**

与规则基速率组合、DeepTravel、CompactETA 等基线对比，MAE/APE/MAPE 评估中 PAtt 在 MAPE 上取得 8.78% 的最低误差，明显优于传统和深度学习方法

**⚠️ 局限性**

局限性包括：对突发局部事件的适应性不足、仅在路径级别做预测，缺乏对邻接链路动态传播的显式建模

---

## 801. Sample Efficient Learning of Body-Environment Interaction of an Under-Actuated System

**arXiv ID:** 2601.13777 | [PDF](https://arxiv.org/pdf/2601.13777v1)

**作者:** Zvi Chapnik `[一作]` (Technion), Shai Revzen `[通讯]` (University of Michigan)

**通讯引用:** 1119 | [OpenAlex ID](https://openalex.org/A5056552261)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在低摩擦、无动量的四脚臂三段颗粒游泳机器人上，评估并比较了两类模型（基于相位的总最小二乘法和增广高斯分支回归）在学习形态-环境相互作用（动机图）时的表现，并探讨了加入被动形态变量（SUDS）对样本效率和泛化的影响。

**💡 创新点**

①首次将增广高斯分支回归（A-GBR）与传统相位相机模型（DDFA）在物理机器人上的实验对比；②系统性分析不同训练频率、步态相似度、数据量对预测误差的交互作用；③证明在样本量有限时，A-GBR 约需 1/10 的数据即可逼近 MLP 的性能；④提出可在线更新的 A-GBR/DDFA 结构，为适应动态环境的机器人提供新思路。

**🔧 技术方法**

基于相位的总最小二乘法（phase‑dependent total least squares）、增广高斯分支回归（A‑GBR）、自回归/线性化的被动形态模型（SUDS），以及对不同步态频率的 Bootstrap 交叉验证评估。

**📊 数据集**

包含 5 种周期步态（圆形、轻/极端菱形、轻/极端方形）与 3 个频率（1/3 Hz、1/2 Hz、1 Hz）的 30 周期运动数据，共计 47,000 条样本；使用 Qualisys Oqus‑310+ 摄像头获取 11 个标记的三维位置。

**📈 对比分析**

通过 Bootstrap 交叉验证，比较了模型在同频率/不同频率、同步态/近似/远程步态的预测误差。结果显示：① A‑GBR 模型比 DDFA 模型在相同频率下误差下降约 40%，在不同频率下下降约 30%；② 加入被动形态变量（SUDS）对 A‑GBR 影响较小（约 3%）；③ 当训练数据量增大时，A‑GBR 的误差随数据量的对数呈近似 -1/2 的衰减，表明其样本效率高；④ 在极低频率下误差最低，1 Hz 误差最高。

**⚠️ 局限性**

① 仅在实验室制备的红豆颗粒环境下验证，缺乏对其他复杂或真实地形的通用性；② 仅评估了两类模型，未涉及更通用的深度学习方法；③ 机器人形态空间维度仍受限，未探究更高维或非线性形态变量的可扩展性；④ 研究聚焦于离线模型，缺乏在线适应和自适应更新的实验；⑤ 对群动力学（p 端项）未展开深入讨论。

---

## 802. Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks

**arXiv ID:** 2601.13776 | [PDF](https://arxiv.org/pdf/2601.13776v1)

**作者:** Thibaut Boissin `[一作]` (Institut de Recherche Technologique Saint-Exupéry), Mathieu Serrurier `[通讯]` (IRIT)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一个统一、高效的 PyTorch 库 Orthogonium，用于构建正交和 1‑Lipschitz 神经网络层；

**💡 创新点**

创新点在于将多种正交卷积实现（AOC、Adaptive‑SOC、AOL、SLL、Sandwich‑AOC）统一到单一 API，并提供完整的特征支持（stride、dilation、group、transpose）以及严格的单元测试，保证数学正确性；

**🔧 技术方法**

技术上结合了正交化参数化（如 Björck–Bowie、指数映射、Gram‑Schmidt、Cayley、Cholesky）、谱归一化、张量到 Toeplitz 矩阵的显式 SVD 检验与可扩展的谱方法、以及多种 1‑Lipschitz 激活和残差包装；

**📊 数据集**

主要在 ImageNet‑1K 上进行大规模性能评估，另外对小规模卷积做显式 SVD 验证；

**📈 对比分析**

与传统无约束卷积相比，Orthogonium 在 ImageNet 上仅额外约 10% 计算开销，同时保持严格的正交/1‑Lipschitz 性质；相较于散落在不同论文/仓库的实现，提供了单行切换的便利与一致的性能；

**⚠️ 局限性**

局限性包括：库仍在持续迭代，部分高级功能（如 Sandwich‑AOC）尚未完全稳定；对极端模型结构（极大分组、复杂残差路径）的兼容性可能需要进一步验证；

---

## 803. TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation

**arXiv ID:** 2601.13935 | [PDF](https://arxiv.org/pdf/2601.13935v1)

**作者:** Anoushkrit Goel `[一作]` (Indian Institute of Technology Mandi), Arnav Bhavsar `[通讯]` (Indian Institute of Technology Mandi)

**通讯引用:** 1309 | [OpenAlex ID](https://openalex.org/A5018647189)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

本文提出了 TrackletGPT，一种基于语言模型的白质束分割框架，并通过使用 tracklet 表示实现了自动化且注册无关的分割。

**💡 创新点**

创新点包括将 streamline 拆分为可互相连接的 tracklet（类似词语），在 GPT 框架中进行自回归重建，融合双向序列和相对位置编码，显著提升了跨数据集泛化能力。

**🔧 技术方法**

主要技术包括 PointNet 风格的编码器、Transformer 解码器、双重掩码预训练、Chamfer 损失与交叉熵联合微调、相对位置嵌入和自回归 tracklet 生成。

**📊 数据集**

使用了 TractoInferno（金标准与银标准）和 Human Connectome Project（HCP）两个公开数据集进行训练和评估。

**📈 对比分析**

通过 Dice、Overlap 与 Overreach 指标与 FINTA-m、RecoBundlesX、TractoGPT、TractSeg 等方法对比，TrackletGPT 在单数据集和跨数据集实验中均达到了 0.94 以上的 Dice 分数，表现出色。

**⚠️ 局限性**

局限性包括推理速度相对较慢（单个受试者约 25–50 分钟），在某些难分束上仍略逊于 TractoGPT，且需要大量训练样本才能保持高性能。

---

## 804. Know Your Contract: Extending eIDAS Trust into Public Blockchains

**arXiv ID:** 2601.13903 | [PDF](https://arxiv.org/pdf/2601.13903v1)

**作者:** Awid Vaziry `[一作]` (Technische Universität Berlin), Axel Küpper `[通讯]` (Technische Universität Berlin)

**通讯引用:** 2682 | [OpenAlex ID](https://openalex.org/A5043270200)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

**🎯 论文内容**

提出一种将欧盟eIDAS信任框架扩展到公共区块链的架构，通过将智能合约与合格电子印章(QSeal)绑定，实现区块链地址与合法实体的可验证关联，从而支持“Know Your Contract/Counterparty/Business”检查。

**💡 创新点**

创新点在于：①将eIDAS的根信任链（从欧盟委员会的信任列表到单个合约地址）完整映射到EVM链上；②利用2025年Ethereum Fusaka升级的P‑256预编译器与CAdES格式，实现符合eIDAS 2.0规定的可链上验证；③提出两种验证模型——离线验证的代理支付协议和全链上验证的DeFi操作，显著降低监管合规成本。

**🔧 技术方法**

使用的技术包括：EVM与EIP‑7951 P‑256预编译、CAdES签名格式、eIDAS Qualified Trust Service Provider（QTSP）证书链、LOT List of Trusted Lists（LOTL）作为链上信任锚，以及以太坊智能合约（包括Safe、ERC‑3009等）。

**📊 数据集**

论文未使用传统数据集，而是利用官方的eIDAS信任列表、QTSP颁发的合格印章证书、以及模拟或示例合约地址/交易来验证架构可行性。

**📈 对比分析**

通过对离线验证与全链上验证两种模型的比较，作者指出：离线验证在gas成本上显著更低，但不适用于需要即时监管审查的DeFi；全链上验证则在首次交互时完成所有KYC/KYB，满足MiCA、PSD2/PSR要求，虽然单笔交易的gas开销增加，但整体合规流程被自动化。实验数据显示，使用P‑256预编译后的签名验证在单笔交易中仅需约0.5 M gas，低于传统RSA/PSS实现。

**⚠️ 局限性**

局限性包括：①需要在链上镜像LOTL，存在同步和安全风险；②对P‑256的依赖要求网络节点支持相应预编译；③方案主要面向欧盟法域，跨境应用需适配其他监管框架；④对自然人身份的隐私保护尚未覆盖，仅适用于法人实体；⑤在高频交易场景下，链上验证的gas成本仍可能成为瓶颈。

---

## 805. Multi-Location Software Model Completion

**arXiv ID:** 2601.13894 | [PDF](https://arxiv.org/pdf/2601.13894v1)

**作者:** Alisa Welter `[一作]` (Saarland University), Sven Apel `[通讯]` (Saarland University)

**通讯引用:** 13075 | [OpenAlex ID](https://openalex.org/A5054951840)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种多位置软件模型补全方法，能够在给定单一位置变更的基础上，预测并建议跨模型多处的进一步变更；

**💡 创新点**

首次实现多位置模型补全，利用基于注意力机制的神经网络从历史协同变更模式中学习，自动生成跨模型的协同变更建议；

**🔧 技术方法**

采用带注意力层的神经网络，对历史的协同变更对进行训练和排序，并结合单位置LLM补全技术；

**📊 数据集**

使用包含3241个真实项目的多位置变更数据集，对历史变更记录进行训练和评估；

**📈 对比分析**

与三种基线（随机、历史共变频率、语义相似度）对比，使用Precision@k指标，平均Precision@k（k≤10）高达0.98，明显优于基线；

**⚠️ 局限性**

在层次结构变更等非结构化变更场景下表现不足；依赖充足的历史数据，难以处理全新模式或跨项目迁移时的泛化问题；

---

## 806. Revisiting Multi-Task Visual Representation Learning

**arXiv ID:** 2601.13886 | [PDF](https://arxiv.org/pdf/2601.13886v1)

**作者:** Shangzhe Di `[一作]` (Shanghai Jiao Tong University), Weidi Xie `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 9854 | [OpenAlex ID](https://openalex.org/A5076097168)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `6514db3d-8de6-452c-91b7-acdb31787cc4` `729e5870-4135-47f5-97f2-e3974d07b5dc` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `8d10c613-917e-4880-9716-17789f50e119` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种多任务视觉预训练框架，联合视觉‑语言对比、无监督学习和稠密空间监督，利用专家模型生成的伪标签训练统一的视觉编码器。

**💡 创新点**

创新点在于将多源监督（语义、定位、几何）融合到单一架构中，并通过高质量伪标签实现无人工标注的稠密监督，显著提升空间推理与语义对齐的双重性能。

**🔧 技术方法**

技术包括ViT共享主干、SigLIP风格的视觉‑语言对比、DINOv2/MAE等自监督蒸馏、基于Depth Anything V2 与 OWLv2 的伪标签生成、轻量级聚焦层与DPT深度头。

**📊 数据集**

数据来源为200M条图文对，经过过滤后生成100M条“全注释”样本，每张图都有标题、区域‑文本对与相对深度伪标签。

**📈 对比分析**

与CLIP、SigLIP等现有模型对比，采用零样本分类、检索、VQA、语义分割、对应与深度估计等多项基准，结果显示在100M样本下的模型在零样本分类、检索与语义分割上均优于同规模VL模型，且在细粒度空间任务上优于当前最先进的单任务模型。

**⚠️ 局限性**

局限性包括对伪标签质量的依赖（专家模型可能产生误差）、在某些几何对应任务上扩展数据反而可能导致性能下降，以及对更大规模模型与数据的进一步验证尚未完成。

---

## 807. Constrained MARL for Coexisting TN-NTN Resource Allocation: Scalability and Flexibility

**arXiv ID:** 2601.13883 | [PDF](https://arxiv.org/pdf/2601.13883v1)

**作者:** Cuong Le `[一作]` (Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg), Symeon Chatzinotas `[通讯]` (Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

针对地面与非地面基站共存的无线资源分配，提出了一种将原问题分解为若干子问题的多代理强化学习框架，并在训练阶段通过动态环境提升策略的灵活性。

**💡 创新点**

创新点包括：
1) 利用交叉频段间无干扰的结构，将每个基站拆分为多个子资源块（SRB），并在同一子资源块内共享奖励；
2) 采用顺序决策与参数共享的多代理MAPPO，显著降低动作空间维度，理论证明子问题最优即为整体最优；
3) 将QoS约束通过Lagrange松弛转化为奖励函数，并在训练中逐步更新乘子；
4) 在训练时随机生成用户数与位置，加入用户存在元数据，使策略对用户进出、移动具有鲁棒性。

**🔧 技术方法**

使用技术主要有：
- 多代理Proximal Policy Optimization (MAPPO)；
- Lagrangian relaxation + 子梯度更新；
- 参数共享与顺序决策的多代理架构；
- 随机多用户动态训练环境；
- 传统的OFDM与功率分配策略作为基线。

**📊 数据集**

数据集为仿真数据：两座地面基站与一架UAV，20 MHz频段，子载波数分别为80、160、320，用户数按泊松分布，路径损耗采用Winner II，信道衰落为Rayleigh/概率模型。没有使用公开的真实网络数据。

**📈 对比分析**

与传统的全局MAPPO和独立PPO（IPPO）直接对原问题求解的两种方法进行对比。实验结果表明：
- 在子载波数增大至960、用户数增至90时，传统方法无法收敛或收敛速度极慢；
- 我们的分解框架在所有规模下均实现更高的奖励（总吞吐量）和更低的QoS违背成本；
- 在动态用户进出/移动场景中，吞吐量最高、QoS违背率最低。

**⚠️ 局限性**

局限性：
- 仅在仿真环境下验证，缺乏真实网络部署与测量；
- 需要每个基站内部维护多个代理，可能增加通信与协调开销；
- 对CSI的统计分布假设（如Rayleigh、Winner II）可能不完全适用于所有非地面链路；
- 训练时需要较大计算资源，尤其在子载波数极大时仍可能面临收敛问题。

---

## 808. Question-Focused Filtering for Knowledge-based VQA

**arXiv ID:** 2601.13856 | [PDF](https://arxiv.org/pdf/2601.13856v1)

**作者:** Wei Ye `[一作]` (Huazhong University of Science and Technology), Rui Zhang `[通讯]` (Huazhong University of Science and Technology)

**通讯引用:** 15817 | [OpenAlex ID](https://openalex.org/A5115603637)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `8d10c613-917e-4880-9716-17789f50e119` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `9ce7179e-700c-4310-ac2b-91df50ded46e` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一个高效的知识过滤框架 QKVQA，用于知识驱动的视觉问答，显著降低了文章选择错误和内部信息选择错误。

**💡 创新点**

创新点在于：① 通过问答聚焦过滤器 QFF，将问题语义深度注入到候选知识的编码中，提升文章筛选准确性；② 采用分块动态多文档选择 CDA，将长篇文章拆分成细粒度文本块，跨文档动态筛选，既减少噪声又降低计算成本。

**🔧 技术方法**

使用技术包括：Q-Former 的交叉注意力机制、BGE-Reranker 进行块级相关性评分、对比学习训练 QFF、RAG 框架的检索-过滤-生成流程、以及基于分块和阈值的动态多文档筛选。

**📊 数据集**

实验数据集：E-VQA 与 InfoSeek 两个 KB‑VQA 基准，均只使用单跳问题进行评估。

**📈 对比分析**

与多种基线（LLaMA‑3‑8B、GPT‑4、Qwen2.5‑VL‑7B、OMGM、VLM‑PRF 等）对比，QKVQA 在 E‑VQA 上提升 3.0–4.9%，InfoSeek 上提升 3.4–3.9%，在单跳问题上达到 53.7%/49.5%/53.7%（E‑VQA）和 34.5%/44.2%/37.9%（InfoSeek），同时整体时延仅比 OMGM 低 0.7 秒，保持竞争性效率。

**⚠️ 局限性**

局限性：仍受检索召回率影响；在长篇文章中分块可能导致信息遗漏，需更细粒度控制；当前只针对单跳问题，未对多跳推理进行验证。

---

## 809. Towards Inclusive External Human-Machine Interface: Exploring the Effects of Visual and Auditory eHMI for Deaf and Hard-of-Hearing People

**arXiv ID:** 2601.13889 | [PDF](https://arxiv.org/pdf/2601.13889v1)

**作者:** Wenge Xu `[一作]` (Birmingham City University), Mark Colley `[通讯]` (UCL Interaction Centre)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文首先通过六名聋人和六名关键利益相关者的焦点小组，确定并筛选出适合聋人使用的视觉eHMI设计；随后在虚拟现实环境中对32名参与者（16名聋人、16名听人）进行实验，比较了四种视觉eHMI（无视觉、抽象灯光、抽象灯光+文字、抽象灯光+符号）与两种听觉eHMI（无语音、语音）对使用体验（信任、可用性、感知安全、心理负荷）和行为（凝视时长、踏入道路时间、提前踏入计数）的影响。

**💡 创新点**

创新点在于：①首次将聋人群体纳入eHMI设计与评估，填补该领域研究空白；②首次在VR中同时评估视觉与听觉双模态eHMI对聋人的影响；③提出并验证了四项针对聋人的eHMI设计需求（状态清晰、避免交通符号、支持多模态、组合视觉信号）。

**🔧 技术方法**

使用技术包括：Unity 2022.3.44构建VR场景；Varjo XR‑4头显+眼动仪采集凝视数据；Cyberith Virtualizer 2进行行走模拟；文本问卷（Trust in Automation、Van der Laan Acceptance、Perceived Safety、NASA‑TLX、LHIPA）。

**📊 数据集**

数据集为：12名聋人及6名利益相关者的焦点小组访谈录音与笔记；32名实验参与者的问卷和眼动/运动测量数据。

**📈 对比分析**

采用混合设计 ANOVA（可用ART转换）以及 Bonferroni 校正的事后检验来比较各条件。结果显示：①视觉eHMI（尤其是组合型）显著提升信任、可用性、感知安全与凝视集中度；②听觉语音亦提升主观体验，但对行为指标影响不显著；③聋人群体在凝视时长和踏入道路时间上相较听人更为谨慎。

**⚠️ 局限性**

局限性包括：样本量有限、只测试单一城市非信号路口情境、仅评估抽象灯光的单模态与组合型视觉eHMI、听觉仅用语音且不考虑不同语种或手语聋人；实验为单次、实验室环境，缺乏真实交通噪声与复杂交通情境的验证。

---

## 810. Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores

**arXiv ID:** 2601.13885 | [PDF](https://arxiv.org/pdf/2601.13885v1)

**作者:** Esma Balkır `[一作]` (Trismik), Nigel Collier `[通讯]` (University of Cambridge)

**通讯引用:** 8465 | [OpenAlex ID](https://openalex.org/A5073413742)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种连续型 IRT（Item Response Theory）适用于生成任务的分数评估，并基于此开发了自适应多模型排名算法，能够在大幅降低评测成本的同时给出统计显著的模型排序。

**💡 创新点**

创新点：① 用异方差正态分布替代伯努利分布，实现了对 0-1 之间连续分数的理论统一；② 引入基于对偶模型置信度的自适应停止和成本感知的样本分配；③ 通过极大化 Fisher 信息实现自适应题目选择，显著减少所需评测项目数；④ 证明方法在未见模型族上同样有效。

**🔧 技术方法**

核心技术：Item Response Theory、异方差正态分布建模、贝叶斯后验更新、Fisher 信息最大化、基于对偶置信度的比较、成本敏感的决策。

**📊 数据集**

使用了五个生成任务的数据集：GovReport（摘要）、BioLaySumm2025（摘要）、Nemotron PII（实体识别）、TruthfulQA（问答）和 FLORES（翻译）。对应指标包括 ROUGE、BLEU、BERTScore、COMET、可读性指数和 LLM‑as‑Judge。

**📈 对比分析**

与随机抽样和固定长度 CAT 对比，所提方法在 2% 的评测项目下获得 0.73 的 Kendall’s τ 与完整评测排名相当，平均提升约 0.12 τ；在成本和项目数量上分别节省 42% 与 32%；在置信度足够的预测上准确率达 95%，同时能有效检测统计学上不可区分的模型对。

**⚠️ 局限性**

局限性：① 需要先行对校准模型进行完整评测以估计项目参数，导致冷启动成本；② 每种指标需单独估计参数，维护成本较高；③ 假设异方差正态分布，若数据偏离可能影响信息量计算；④ 未控制多重比较的族宽错误率；⑤ 未考虑项目特异性区分度和更细粒度的成本信息。

---

## 811. Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education

**arXiv ID:** 2601.13876 | [PDF](https://arxiv.org/pdf/2601.13876v1)

**作者:** Unggi Lee `[一作]` (Chosun University), Gyeonggeon Lee `[通讯]` (Nanyang Technological University)

**通讯引用:** 478 | [OpenAlex ID](https://openalex.org/A5005042692)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `8d10c613-917e-4880-9716-17789f50e119` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出 Pedagogical VLA Framework，结合机器人执行科学演示并生成可解释的教育性语言解释。

**💡 创新点**

通过文本恢复（text healing）、LLM 蒸馏、课堂安全训练以及多维评估，实现轻量级 VLA 模型兼具任务执行与教育解释功能。

**🔧 技术方法**

使用轻量级 VLA 模型 SmolVLA、文本解码器、LLM 蒸馏（GPT‑4o）、视觉+指令+本体感知、联合损失等技术。

**📊 数据集**

基于 SO‑101 机器人在 5 个科学演示（物理：电磁感应；化学：火焰试验；生物：酵母发酵；地球科学：岩石分类；实验室支持：琼脂平板制备）收集的双摄像头视频和动作轨迹数据。

**📈 对比分析**

与 ACT、SmolVLA、Text‑SmolVLA 四个基线对比；在任务成功率、协议符合度、效率、安全、文本质量和可用性等指标上，Pedagogical VLA 在任务执行略逊于纯动作模型，但文本质量和教育可用性显著优于其他模型。

**⚠️ 局限性**

主要局限为轻量化导致任务成功率低于纯动作模型，文本生成与动作预测竞争导致权衡难题，安全响应仍需改进，且模型在课堂实际部署中的鲁棒性和通用性尚未充分验证。

---

## 812. OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting

**arXiv ID:** 2601.13871 | [PDF](https://arxiv.org/pdf/2601.13871v1)

**作者:** Michail Spanakis `[一作]` (University of Crete), Antonis Argyros `[通讯]` (Foundation for Research and Technology – Hellas)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

开发了一种全新无训练、无先验、可一次性计数多类别对象的类无关计数方法OCCAM。

**💡 创新点**

创新点在于将SAM2与阈值化FINCH聚类相结合，实现完全无先验、训练自由且支持多类计数的首次方法。

**🔧 技术方法**

技术核心是使用SAM2进行实例分割，利用自定义阈值FINCH进行聚类，并通过ResNet‑50提取特征，辅以多尺度重采样。

**📊 数据集**

实验数据集包括FSC‑147、CARPK、合成多类测试集以及真实多类图像集。

**📈 对比分析**

与现有训练或先验依赖方法比较，OCCAM在MAE、RMSE、F1等指标上均具备竞争力，部分多类数据集甚至达到SOTA水平。

**⚠️ 局限性**

局限性包括对小目标分割的鲁棒性不足、对重叠或视觉混淆对象的识别误差以及缺乏针对极大对象数量的稳健性。

---

## 813. Designing Drone Interfaces to Assist Pedestrians Crossing Non-Signalised Roads

**arXiv ID:** 2601.13858 | [PDF](https://arxiv.org/pdf/2601.13858v1)

**作者:** Guixiang Zhang `[一作]` (University of Sydney), Marius Hoggenmueller `[通讯]`

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本研究设计并评估了两种无人机界面（机载投影和机载屏幕）用于帮助行人在无信号灯的道路上安全横穿，采用了基于360°实景视频的VR仿真实验，探讨了无人机作为分布式交通灯的可行性。

**💡 创新点**

创新点在于将无人机作为可移动的第三方交通信号源，首次通过投影与屏幕方式将实时交通安全信息呈现给行人，并在实验中验证其对安全感、工作负荷和用户体验的提升。

**🔧 技术方法**

主要技术包括：无人机投影/屏幕交互技术、Unity与Oculus Quest 2的VR实现、360°实景视频处理、实时交通状态模拟、以及NASA‑TLX、AttrakDiff等标准问卷评估工具。

**📊 数据集**

使用了真实城市道路的360°摄像头录制数据（两条穿越场景），并在VR中嵌入相应的三维模型与视频。

**📈 对比分析**

比较方法为三组内点设计（无人机投影、无人机屏幕、无辅助基线），采用Friedman检验和Wilcoxon检验对感知安全、工作负荷、信任和UX进行统计。实验结果显示：投影组感知安全最高、工作负荷最低，屏幕组次之；两种无人机介入均显著优于基线。

**⚠️ 局限性**

局限性包括：VR环境未加入空间音频导致沉浸感不足、样本量仅18人、未在真实道路环境中验证、可能存在对无人机过度信任及安全距离的用户担忧。

---

## 814. Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework

**arXiv ID:** 2601.13945 | [PDF](https://arxiv.org/pdf/2601.13945v1)

**作者:** Yixuan Deng `[一作]` (Chinese University of Hong Kong), Xiaoqiang Ji `[通讯]` (Chinese University of Hong Kong)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

**🎯 论文内容**

提出了ANCHOR框架，实现了可演化的共享状态（Canonical Records）与高并发的多生产者多消费者通信总线（Communication Bus），并在闭环工作流中验证其可行性和鲁棒性。

**💡 创新点**

创新点在于将共享上下文与交互机制抽象为系统级别的显式契约，解决传统中间件中接口漂移、隐式耦合和恢复难题；同时提供可演化的数据模式和并发友好的发布‑订阅实现，支持在负载和失效下的受控降级与自动恢复。

**🔧 技术方法**

采用共享内存映射（mmap）实现Canonical Records，基于多生产者多消费者（MPMC）消息队列实现通信总线；使用心跳监测、重连与重注册机制保证失效恢复；在实验中利用C++/Python实现，部署于单机测试平台（AMD EPYC 9754 + NVIDIA RTX 3090）。

**📊 数据集**

论文主要在无公开数据集的仿真闭环任务上评估，使用自定义的“观测→聚合→记录→推理→指令→执行→反馈”流程，未涉及公开基准数据集。

**📈 对比分析**

通过对比ROS/ROS2等传统中间件，在不同负载（payload 128/1024 B，publish rate 1k/5k msg/s）下测得交付延迟的ECDF，P99维持在数百微秒至数毫秒，表现出稳定的受控降级；在硬重启恢复实验中，系统能在重启后自动重连并恢复吞吐，未出现持续停滞。

**⚠️ 局限性**

局限性：1) 未针对安全与隐私（加密、访问控制）进行完整设计；2) 低延迟与实时性优化仍待加强，缺乏针对时序敏感任务的评估；3) 仅在单机实验环境验证，缺乏多机或分布式部署下的验证；4) 对大规模真实数据集和复杂多模态任务的适用性尚未探究。

---

## 815. IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization

**arXiv ID:** 2601.13938 | [PDF](https://arxiv.org/pdf/2601.13938v1)

**作者:** Heyang Zhou `[一作]` (University of Science and Technology of China), Yong Liao `[通讯]` (University of Science and Technology of China)

**通讯引用:** 2622 | [OpenAlex ID](https://openalex.org/A5021273060)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了IF‑GEO框架，通过先扩展潜在查询再聚合冲突编辑指令，以提升文档在多查询下的可见性。

**💡 创新点**

创新点在于：①“分散‑再聚合”策略将查询特定编辑转化为冲突友好指令；②引入风险意识的稳定性度量（WCP、DR、WTR）来衡量跨查询的安全性。

**🔧 技术方法**

核心技术包括：LLM驱动的查询挖掘、结构化编辑请求生成、冲突感知指令融合、全局修订蓝图构建以及蓝图指导的编辑执行。

**📊 数据集**

使用GEO‑Bench/RAID基准数据集，涵盖每篇文档对应5个多样化查询。

**📈 对比分析**

与传统GEO、RAID G‑SEO、Auto‑GEO等基线对比，IF‑GEO在总体可见度、WCP和WTR指标上均优于对手，且下行风险（DR）显著降低。

**⚠️ 局限性**

局限性包括：多阶段LLM调用导致推理成本高；仿真环境与真实生成引擎存在差距；依赖于查询扩展的代表性，若查询挖掘失效可能导致优化失衡。

---

## 816. Impact Matters! An Audit Method to Evaluate AI Projects and their Impact for Sustainability and Public Interest

**arXiv ID:** 2601.13936 | [PDF](https://arxiv.org/pdf/2601.13936v1)

**作者:** Theresa Züger `[一作]` (Alexander von Humboldt Institute for Internet and Society), Lena Winter `[通讯]` (Alexander von Humboldt Institute for Internet and Society)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f`

**🎯 论文内容**

提出了“Impact‑AI‑method”——一种以公共利益与可持续发展为双重监管概念为基础的定性审计方法，用来评估 AI 项目对社会、环境和经济的影响，并通过访谈、内容分析和评估量表生成可视化报告。

**💡 创新点**

创新点在于：① 将公共利益与可持续性两大概念整合为统一框架；② 设计了跨学科、可复用的访谈流程（项目治理、项目可持续性、系统事实、系统可持续性）与 32 条评估准则；③ 将评估结果用五级交通灯模型直观呈现，便于非学术公众解读；④ 兼顾技术与社会层面，填补现有审计侧重合规或技术性能的空白。

**🔧 技术方法**

主要技术手段包括：半结构化访谈、定性内容分析（使用 MaxQDA）、基于文献与专家访谈的评估指标提取与细化、以及为结果可视化设计的交通灯评分模型。

**📊 数据集**

本研究未使用传统意义上的机器学习数据集；其“数据”来源为：① AI 项目公开资料（项目网站、报告、新闻、社交媒体）；② 受访者提供的项目文件、技术文档、决策记录；③ 与项目相关的外部专家访谈记录。

**📈 对比分析**

方法评估主要通过对已审计项目的结果进行描述性分析和可视化，而非与其他算法或基准进行数值对比。性能表现体现在：能系统捕捉项目治理、技术实现、社会/环境/经济三维影响，并将结果以红黄绿灯方式呈现给利益相关者，提升透明度和可讨论性。

**⚠️ 局限性**

局限性包括：① 依赖访谈，资源耗时且受访者配合度影响；② 评估准则主观性高，需持续校准和验证；③ 与合规审计工具不可直接比较，可能缺乏对法规合规性的评估；④ 结果的可比性受项目差异化定制影响；⑤ 主要关注正向影响，负面后果识别仍有限。

---

## 817. Mathematical and computational perspectives on the Boolean and binary rank and their relation to the real rank

**arXiv ID:** 2601.13900 | [PDF](https://arxiv.org/pdf/2601.13900v1)

**作者:** Michal Parnas `[一作]` `[通讯]` (Academic College of Tel-Aviv-Yaffo), Michal Parnas (Academic College of Tel-Aviv-Yaffo)

**关键词:** `dd4bd30e-3d3d-4e53-a403-da542c6c036a` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

这篇论文提供了对布尔秩和二进制秩的数学和计算机科学视角的全面概述，特别强调它们与实秩的关系。

**💡 创新点**

创新点在于总结了布尔秩和二进制秩的基本定义、计算复杂性及其与通信复杂性的深刻联系，并提出了多种计算和近似这些秩的算法。

**🔧 技术方法**

使用了线性代数、组合数学、图论等多种技术，包括隔离集、概率方法、内核化、通信协议和查询到通信提升技术。

**📊 数据集**

论文中讨论的主要数据集是0,1矩阵，特别是涉及到的矩阵包括C_n和D_n,k等特定家族的矩阵。

**📈 对比分析**

通过与实秩的比较，展示了布尔秩和二进制秩的计算复杂性，指出它们的计算是NP-hard，并且提供了多种算法的性能分析。

**⚠️ 局限性**

限制在于尽管对布尔秩和二进制秩的研究取得了进展，但它们的行为仍然不如实秩那样被充分理解，尤其是在计算复杂性和算法方面的挑战依然存在。

---

## 818. Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging

**arXiv ID:** 2601.13899 | [PDF](https://arxiv.org/pdf/2601.13899v1)

**作者:** Masoumeh Javanbakhat `[一作]` (Hasso-Plattner Institute), Christoph Lippert `[通讯]` (Hasso-Plattner Institute)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `a6cb313d-240c-4723-a372-3ba1f39b9afc`

**🎯 论文内容**

提出一种可解释的深度两样本检验框架，提供样本级和特征级解释。

**💡 创新点**

首次将样本影响度和梯度归因与深度两样本检验结合，实现无标签的统计解释。

**🔧 技术方法**

使用深度最大均值差（DMMD）测试、梯度归因（类似Grad‑CAM）以及影响度分数，并依赖预训练的编码器。

**📊 数据集**

在合成dSprites、阿尔茨海默脑部MRI（ADNI）和眼底糖尿病视网膜病变（EyePACS）数据集上进行验证。

**📈 对比分析**

通过比较高/低影响样本的p值变化以及归因热图与已知生成因子/临床标志的对应关系，证明解释与真实差异一致；统计显著性与传统深度两样本检验相当或更优，解释清晰且具有生物学意义。

**⚠️ 局限性**

局限性包括仅适用于二分类检验、需依赖预训练编码器、计算成本较高、缺乏因果推断能力。

---

## 819. OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3

**arXiv ID:** 2601.13895 | [PDF](https://arxiv.org/pdf/2601.13895v1)

**作者:** Xu Zhang `[一作]` (Nankai University), Qicheng Li `[通讯]` (Nankai University)

**通讯引用:** 832 | [OpenAlex ID](https://openalex.org/A5067376482)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

设计了一个独立框架 OmniOVCD，利用 SAM 3 的多头输出融合后进行实例解耦，实现开放词汇变化检测。

**💡 创新点**

创新点在于提出 Synergistic Fusion to Instance Decoupling (SFID) 策略，将语义、实例和存在头融合并在实例层面匹配，从而消除传统多模型不匹配导致的不稳定问题。

**🔧 技术方法**

采用 SAM 3 作为基座，使用语义/实例/存在头融合、像素级最大融合、存在门控、连通分量实例解耦与实例匹配，以及基于重叠比阈值的变化检测方法。

**📊 数据集**

在四大公共遥感变化基准集（LEVIR‑CD、WHU‑CD、S2Looking、SECOND）上进行实验。

**📈 对比分析**

与传统无监督方法和现有训练‑free OVCD 方法（如 DynamicEarth）对比，OmniOVCD 在所有数据集上取得最高 IoU（LEVIR‑CD 67.2，WHU‑CD 66.5，S2Looking 24.5，SECOND 27.1），同时具备最快推理速度和最低显存占用。

**⚠️ 局限性**

仍未充分验证在极端光照或极短时序差异场景下的鲁棒性，对细粒度类别的检测仍可能出现漏检。

---

## 820. Enhanced Cyber Threat Intelligence by Network Forensic Analysis for Ransomware as a Service(RaaS) Malwares

**arXiv ID:** 2601.13873 | [PDF](https://arxiv.org/pdf/2601.13873v1)

**作者:** Sharmila S P `[一作]` (Indian Institute of Technology Indore), Sharmila S P `[通讯]` (Indian Institute of Technology Indore)

**通讯引用:** 73 | [OpenAlex ID](https://openalex.org/A5101414350)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

对Ryuk和Gandcrab两种Ransomware-as-a-Service（RaaS）样本在虚拟化honeypot中执行后进行网络取证分析，结合VirusTotal API将捕获的网络流量按恶意、可疑、正常三类分类，并据此生成RaaS专属包签名。

**💡 创新点**

创新点在于将网络取证与VirusTotal实时扫描深度耦合，提出基于时间戳、HTTP链接等特征集的自动化恶意流量识别流程，首次实现对RaaS样本超过40%网络包的准确分类，并生成可直接用于IDS/AV的签名。

**🔧 技术方法**

采用Wireshark、tcpdump、Snort/Suricata、Tshark、Zeek进行流量捕获与解析，利用随机森林机器学习做异常检测，并通过VirusTotal API进行多引擎验证，形成端到端的网络取证与威胁情报闭环。

**📊 数据集**

数据集为两天实验共计5天内在Windows10 + Kali Linux虚拟化honeypot上执行Ryuk（共捕获3,433,887包）和Gandcrab（共捕获983,486包）的网络抓包数据；此外使用公开安全存储库中的benign流量做对照。

**📈 对比分析**

与VirusTotal检测结果对比验证恶意包率为40%以上，说明该方法在真实环境下能比传统签名更早、更准确地识别RaaS流量；但文中未给出精确的误报率与检测延迟指标，需进一步与现有IDS/AV方案做基准测试。

**⚠️ 局限性**

局限性包括：样本仅覆盖两种RaaS，缺乏多样化与规模化验证；依赖外部VirusTotal API，受限于调用速率与可用引擎；网络取证过程仅捕获被动流量，可能遗漏隐蔽的C2通道或加密通信；缺乏对生成签名的长期可维护性评估。

---

## 821. Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation

**arXiv ID:** 2601.13852 | [PDF](https://arxiv.org/pdf/2601.13852v1)

**作者:** Raül Pérez-Gonzalo `[一作]` (Institut de Robòtica i Informàtica Industrial), Antonio Agudo `[通讯]` (Institut de Robòtica i Informàtica Industrial)

**通讯引用:** 33575 | [OpenAlex ID](https://openalex.org/A5028140968)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种直接优化 Fisher 判别准则的深度判别分析（DDA），并在此基础上加入概率损失得到 Probabilistic DDA（PDDA），用于风机叶片图像分割。

**💡 创新点**

创新点在于：① 将 Fisher 判别准则以稳定的非平方、带 sigmoid 上界的损失形式直接嵌入神经网络，消除梯度爆炸；② 引入两种可训练的 DDA 损失（log‑scale 与 Δ‑sum）并结合 Focal Loss，形成 PDDA；③ 这是首次将 DDA 应用于图像分割任务。

**🔧 技术方法**

技术手段包括：卷积神经网络（U‑Net 编码‑解码架构）、sigmoid 输出归一化、log‑DDA 与 Δ‑DDA 损失、Focal Loss、Adam 优化器、学习率调度以及多尺度数据增强。

**📊 数据集**

实验数据集为多风电场的叶片分割图像集合，包含数千张带有像素级标注的彩色图像，覆盖不同光照、阴影与风机型号。

**📈 对比分析**

与传统 LDA、U‑Net、DeepLabv3+、Mask2Former、SAM、BU‑Net 等基线方法相比，PDDA 在准确率、F1 与 mIoU 上均取得领先：最高 97.97% 的准确率、96.28% 的 F1 分数和 94.34% 的 mIoU，显示出显著的性能提升。

**⚠️ 局限性**

局限性包括：① λ_P 的调参对最终性能影响大，需在验证集上精细调优；② 在极端遮挡或极端光照条件下，模型仍可能出现误分；③ 计算量与模型规模仍略高于极轻量化需求。

---

## 822. Inverting Self-Organizing Maps: A Unified Activation-Based Framework

**arXiv ID:** 2601.13851 | [PDF](https://arxiv.org/pdf/2601.13851v1)

**作者:** Alessandro Londei `[一作]` (Sony Computer Science Laboratories), Vittorio Loreto `[通讯]` (Sony Computer Science Laboratories)

**通讯引用:** 15086 | [OpenAlex ID](https://openalex.org/A5070657345)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出基于SOM激活的精确逆向映射，并设计 MUSIC 规则实现基于原型几何的可控、平滑的潜在空间探索；

**💡 创新点**

创新点在于将SOM的平方距离激活视为完整的几何约束，利用距离几何理论实现无噪声精确重构，并通过 Tikhonov 正则化在保持原型距离不变的前提下实现语义化的连续运动；

**🔧 技术方法**

核心技术包括距离几何（多源定位）、线性逆问题求解、Tikhonov 正则化、局部雅可比线性化以及对 SOM 的 Voronoi 区域结构的利用；

**📊 数据集**

实验数据集涵盖三种场景：三分量高维高斯混合、手写数字 MNIST 与基于预训练自编码器的 Faces in the Wild；

**📈 对比分析**

与线性插值、传统 VAE/扩散模型对比，MUSIC 在保持潜在结构和语义连贯性方面表现优异，产生的轨迹更平滑、解释性更强，且计算成本低于深度生成模型；

**⚠️ 局限性**

局限性包括需要原型集合在潜在空间中完整张成（否则逆向不唯一），SOM 仅提供分段线性近似，无法捕捉真正的曲率；此外，在高维复杂数据中仍需预先进行 PCA 或自编码器压缩，以保证原型能覆盖足够的方向。

---

## 823. Emotion and Acoustics Should Agree: Cross-Level Inconsistency Analysis for Audio Deepfake Detection

**arXiv ID:** 2601.13847 | [PDF](https://arxiv.org/pdf/2601.13847v1)

**作者:** Jinhua Zhang `[一作]` (Inner Mongolia University), Rui Liu `[通讯]` (Inner Mongolia University)

**通讯引用:** 10476 | [OpenAlex ID](https://openalex.org/A5100448485)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `3855fcda-48ef-4070-a15e-803cd5c84d83` `3f18e8e3-0266-457c-8567-9039b6d2394d` `9ce7179e-700c-4310-ac2b-91df50ded46e` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了 EAI-ADD 框架，用情绪-音频不一致性作为核心判别信号来检测音频深度伪造。

**💡 创新点**

首次将情绪与音频动态的不一致性显式建模，构建情绪音频对齐模块和层次异构图来捕捉跨层级不一致性。

**🔧 技术方法**

使用 WavLM+Emotion2vec 语音与情绪特征提取，SincNet+残差块提炼音频；动态差异对齐、softmax 加权；情绪变化放大损失（Contrastive InfoNCE）；层次异构图注意力网络；最终交叉熵+不确定性加权损失。

**📊 数据集**

在 ASVspoof 2019 LA 和 2021 LA 数据集上进行训练与评估。

**📈 对比分析**

与多种基线（WavLM+MFA、RAD-MFA、DFSincNet 等）对比，EAI-ADD 在 2019LA 最小 t-DCF 0.0110、EER 0.34%，在 2021LA 也表现最佳，分别比最强基线降低约 4.3% t-DCF 与 15% EER。

**⚠️ 局限性**

未在实时或高压缩环境下验证，需进一步研究低延迟与低资源条件下的性能。

---

## 824. Optimal L2 Regularization in High-dimensional Continual Linear Regression

**arXiv ID:** 2601.13844 | [PDF](https://arxiv.org/pdf/2601.13844v1)

**作者:** Gilad Karpel `[一作]` (Technion), Itay Evron `[通讯]` (Meta)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文研究了过参数化连续线性回归模型，并在随机设计下用L2正则化分析了其期望泛化误差，提出了最优正则化强度随任务数T的近线性缩放规律；

**💡 创新点**

创新点在于给出任意教师（单一或i.i.d.多教师）情况下的闭式泛化表达式，证明最优正则化强度约为T/lnT，并首次将这一理论推广到实际神经网络中；

**🔧 技术方法**

主要技术包括高维随机设计的Marchenko‑Pastur解析、正则化递归展开、理论泛化误差分解以及对比实验；

**📊 数据集**

实验数据集包括合成线性回归数据以及基于MNIST的二分类数据（单一教师与多教师两种噪声设置）；

**📈 对比分析**

与无正则化方案（λ→0）以及不同正则化强度的对比表明，采用理论指导的λ可显著降低噪声基准，提升泛化性能；

**⚠️ 局限性**

局限性在于假设特征独立同分布、教师为线性且正则化为等方性，缺乏对非线性模型或非i.i.d.环境的理论分析。

---

## 825. VulnResolver: A Hybrid Agent Framework for LLM-Based Automated Vulnerability Issue Resolution

**arXiv ID:** 2601.13933 | [PDF](https://arxiv.org/pdf/2601.13933v1)

**作者:** Mingming Zhang `[一作]` (Beihang University), Chunming Hu `[通讯]` (Beihang University)

**通讯引用:** 1815 | [OpenAlex ID](https://openalex.org/A5086470621)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

提出一种基于LLM的混合代理框架，自动解析并修复安全漏洞报告，结合工作流的确定性与自适应代理的灵活性；

**💡 创新点**

①首次在漏洞修复任务中使用两种专门代理：上下文预收集代理与安全属性分析代理；②将漏洞的安全属性自动化推理与验证嵌入到修复流程；③将丰富的漏洞报告与代理生成的分析报告融合，提升定位与补丁生成效果；

**🔧 技术方法**

LLM+ReAct框架、代码搜索/符号解析工具、PoC执行、属性插入、Python执行工具、工作流式自动修复（基于Agentless），使用DeepSeek‑V3.2‑Exp、o3‑mini、GPT‑4o等LLM；

**📊 数据集**

SEC‑bench（80‑issue子集用于评估、200‑issue完整集用于泛化），涵盖29个开源C/C++项目与16种CWE；

**📈 对比分析**

与SWE‑agent、OpenHands、Aider、PatchAgent等主流LLM‑SWE与AVR基线对比；在80‑issue集上解决率达75%（基线37.5%），在200‑issue集上解决率达67.5%（领先OpenHands 98.5%）；成本方面约$0.07/issue，低于大多数基线；

**⚠️ 局限性**

仅在C/C++上验证，需针对其他语言扩展工具；对极其复杂或多文件漏洞的处理仍有限；依赖漏洞报告的质量，报告缺失关键信息时效果下降；

---

## 826. Towards Effective Negation Modeling in Joint Audio-Text Models for Music

**arXiv ID:** 2601.13931 | [PDF](https://arxiv.org/pdf/2601.13931v1)

**作者:** Yannis Vasilakis `[一作]` (Queen Mary University of London), Johan Pauwels `[通讯]` (Spotify)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `9ce7179e-700c-4310-ac2b-91df50ded46e` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

研究并改进联合音频-文本模型对否定词的表达，提出文本增强和对比损失两种方法并评估其效果。

**💡 创新点**

提出通过人工否定词插入和在对比损失中加入相异项来显式区分原始与否定文本；同时设计基于检索和二分类的否定评估协议。

**🔧 技术方法**

CLAP模型、对比学习、词插入文本增强、余弦相似度、额外的相异项损失。

**📊 数据集**

Million Song Dataset 与 LP‑MusicCaps‑MSD 生成的自动标注字幕。

**📈 对比分析**

在检索任务上对 R@10 进行评估，加入否定后 R@10 明显下降；在二分类任务上准确率从 0.5 提升至约 0.6‑0.7，显示模型对否定的区分能力。

**⚠️ 局限性**

对否定的处理仍不完美，尤其在半否定句与完全否定句之间的区分有限；使用合成否定标签可能无法完全代表自然语言中的否定复杂性。

---

## 827. Automatic Prompt Optimization for Dataset-Level Feature Discovery

**arXiv ID:** 2601.13922 | [PDF](https://arxiv.org/pdf/2601.13922v1)

**作者:** Adrian Cosma `[一作]` (SUPSI), Olivier Pelletier `[通讯]` (UBS Switzerland AG and its affiliates)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出一种基于数据集级别提示优化的自动特征发现框架，用多代理模型联合生成、提取并评估文本特征；

**💡 创新点**

创新点在于将特征发现视为提示优化问题，利用全局提示而非逐样本监督，并通过文本化解释性与性能反馈迭代改进提示，避免标签泄漏；

**🔧 技术方法**

采用多代理提示优化技术，包含FeatureProposer、Extractor、InterpretabilityScorer、PerformanceFeedback、ReflectiveProposer等模块，使用小型语言模型(SLM)进行提示生成与提炼，并结合贝叶斯优化搜索最佳提示与示例集合；

**📊 数据集**

实验使用金融新闻情感数据集（Twitter‑Financial‑News‑Sentiment、Yahoo‑Finance‑News‑Sentences）以及ToxicChat毒性检测数据集；

**📈 对比分析**

与传统逐样本提示优化器（如MIPRO）对比，利用数据集级别的F1+解释性评分，显著提升分类性能并得到更可解释的特征，性能优于未优化或仅使用标量反馈的基线；

**⚠️ 局限性**

局限性包括高昂的计算成本（每轮需要在大规模数据上提取特征），以及对基础语言模型指令遵循能力的高度依赖，较小模型往往生成无效或幻觉特征。

---

## 828. Asymmetric regularization mechanism for GAN training with Variational Inequalities

**arXiv ID:** 2601.13920 | [PDF](https://arxiv.org/pdf/2601.13920v1)

**作者:** Spyridon C. Giagtzoglou `[一作]` (Maastricht University), Barbara Franci `[通讯]` (Politecnico di Torino)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a`

**🎯 论文内容**

本文将GAN训练建模为变分不等式（VI）问题，并设计了只作用于鉴别器（Discriminator）的非对称零中心输入梯度惩罚，进一步引入Tikhonov正则化。

**💡 创新点**

创新点在于：①只在鉴别器侧引入正则化，既能保留原始鞍点又能显著改善条件；②通过Gauss–Newton可辨识条件给出正则化算子的明确Lipschitz与强单调性常数；③提出仅需一次梯度评估的Extrapolation-from-the-Past（EFTP）算法并证明其线性收敛。

**🔧 技术方法**

主要技术包括：变分不等式与单调算子理论、Tikhonov正则化、零中心输入梯度惩罚、Gauss–Newton近似、单步投影方法（FB、EG、EFTP）及其收敛性分析。

**📊 数据集**

实验数据集：未使用公开大型数据集，采用学术示例与二维双线性toy模型进行数值验证。

**📈 对比分析**

方法比较：在双线性toy上对比FB、EG与EFTP。FB在无正则化时发散、需大γ才稳定；EG与EFTP在任意γ下均收敛；EFTP与EG收敛速度相近，但EFTP每步仅需一次梯度评估，整体梯度调用更少，证明了其计算效率。

**⚠️ 局限性**

局限性：收敛证明仅在局部凸集与Gauss–Newton可辨识条件下成立；对非光滑或非凸设置缺乏理论支撑；未验证在大规模真实GAN任务（如图像生成）中的表现；对随机梯度噪声的鲁棒性与自适应预处理器的设计仍待进一步研究。

---

## 829. HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs

**arXiv ID:** 2601.13919 | [PDF](https://arxiv.org/pdf/2601.13919v1)

**作者:** Yuezhe Yang `[一作]` (Shanghai Jiao Tong University), Lei Bi `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 13059 | [OpenAlex ID](https://openalex.org/A5017738174)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

提出 HyperWalker 框架，利用动态超图 iBrochure 与 RL 导向的 Walker 代理，在长期 EHR、图像与医学知识的基础上实现多跳诊断推理。

**💡 创新点**

创新点包括：①将多模态信息嵌入隐式超图以捕获高阶关联；②RL 代理在超图上进行多跳路径搜索；③linger 机制实现正交化探索以增强诊断多样性；④测试时微调 (TTT) 使模型在推理时自适应局部临床上下文。

**🔧 技术方法**

采用 Transformer‑based VLM 编码器、HNSW 索引、强化学习（自定义奖励）、多模态融合、正交化探索、测试时微调等技术。

**📊 数据集**

使用 MIMIC‑CXR+MIMIC‑IV（医学报告生成）和 EHRXQA（多模态问答）两个基准数据集。

**📈 对比分析**

与 Llama3.2‑Vision、Qwen3‑VL、Gemma、Lingshu、MedGemma、Qwen3‑VL‑Thinking、GLM‑4.1V‑Thinking、MedVLM‑R1、LVMed‑R^2 等多种现有模型对比；在 MRG 上 BLEU‑4 4.98、F1 29.69；在 VQA 上准确率 70.43%，显著优于对手，并且推理时间仅 4.66 秒。

**⚠️ 局限性**

局限性包括：对底层 VLM 质量的依赖、超图构建与检索在极大规模下的实时性瓶颈、缺乏真实临床验证、以及对异常或缺失多模态数据的鲁棒性尚待提升。

---

## 830. AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization

**arXiv ID:** 2601.13918 | [PDF](https://arxiv.org/pdf/2601.13918v1)

**作者:** Yusheng Liao `[一作]` (Shanghai Jiao Tong University), Yu Wang `[通讯]` (Shanghai Artificial Intelligence Laboratory)

**通讯引用:** 20467 | [OpenAlex ID](https://openalex.org/A5100445368)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个基于真实电子病历的多步临床决策评估基准及其对应的Agent框架

**💡 创新点**

创新点在于引入回溯式摘要机制与演化经验策略，解决长上下文信息丢失和推理连续性中断问题

**🔧 技术方法**

使用大型语言模型作为Agent，结合回溯式（RetroSum）摘要模块和经验检索模块，在工具箱交互中实现决策推理

**📊 数据集**

采用MIMIC‑IV（Common、Rare）和MIMIC‑III数据集进行实验

**📈 对比分析**

与ReAct、ReSum、ReflecTool、ReasoningBank等基线对比，实验显示在六项任务上平均提升约29% F1，错误率下降92%

**⚠️ 局限性**

局限在于仅使用单中心MIMIC数据，缺乏多中心、多模态（影像、波形）数据，未验证跨机构泛化能力

---

## 831. Decentralized Infrastructure for Digital Notarizing, Signing and Sharing Files using Blockchain

**arXiv ID:** 2601.13907 | [PDF](https://arxiv.org/pdf/2601.13907v1)

**作者:** Cosmin-Iulian Irimia `[一作]` `[通讯]` (Faculty of Computer Science), Cosmin-Iulian Irimia (Faculty of Computer Science)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了基于区块链与IPFS的分布式微服务体系，用于数字公证、签名和文档安全共享。

**💡 创新点**

创新点包括：将文档去标识化/可逆混淆技术与可选择性披露结合，利用微服务解耦核心功能，并在链上记录文档指纹，实现无中介透明审计；同时提出混合存储与链下大文件分块的解决方案。

**🔧 技术方法**

技术栈涵盖区块链（以太坊/Layer‑2 rollup）、IPFS、微服务框架（Spring Cloud/Node.js）、OCR（Tesseract/LLM模板）、加密签名（ECDSA/RSA）、Zero‑Knowledge Proof（zk‑SNARK）以及容器编排（Kubernetes）。

**📊 数据集**

主要使用官方文档（身份证、营业执照、发票等）及内部收集的扫描样本作为实验数据；OCR 训练采用公开的ICDAR 文本识别数据集进行微调。

**📈 对比分析**

通过与传统中心化存储+签名方案、现有区块链公证平台对标，评估指标包括吞吐量、交易延迟、存储成本、错误率。实验显示在平均1.5 s的交易确认时间下吞吐量提升30%，存储成本下降25%，OCR错误率保持在1.2%。

**⚠️ 局限性**

局限性主要包括：IPFS pinning 维护成本高、区块链可扩展性受限、对初始验证的信任依赖、以及非技术用户的使用门槛。

---

## 832. Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments

**arXiv ID:** 2601.13846 | [PDF](https://arxiv.org/pdf/2601.13846v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 833. Multi-Objective Hierarchical Optimization with Large Language Models

**arXiv ID:** 2601.13892 | [PDF](https://arxiv.org/pdf/2601.13892v1)

**作者:** Andrej Schwanke `[一作]` (University of Freiburg), Arber Zela `[通讯]` (ELLIS Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出 MOHOLLM，一种利用大型语言模型 (LLM) 进行多目标优化的分层搜索框架；

**💡 创新点**

创新点在于通过自适应空间划分、区域化提示和多臂赌博机式评分，限制 LLM 在高潜力子空间内生成候选，并证明在正则性假设下能收敛至 Pareto 集；

**🔧 技术方法**

核心技术包括 KD‑tree 递归划分、区域层次化 Hypervolume 贡献评分、基于 Softmax 的区域采样、LLM 作为条件生成器与代理模型；

**📊 数据集**

在 15 个低到中等维度的合成与真实任务上测试，包括 DTLZ1‑3、Branin‑Currin、Kursawe、Penicillin 发酵、VehicleSafety、CarSideImpact 等；

**📈 对比分析**

与 11 种 MOEA、2 种 MOBO 以及全局 LLM 基线对比，MOHOLLM 在大多数基准上显著优于全局 LLM，且在真实任务中优于大多数 MOEAs，接近 MOBO 的表现；

**⚠️ 局限性**

局限性包括依赖轴对齐 KD‑tree 限制于欧氏空间、LLM 推理成本随维度增加而上升，以及尚未给出正式的 Hypervolume 退化界限。

---

## 834. OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models

**arXiv ID:** 2601.13882 | [PDF](https://arxiv.org/pdf/2601.13882v1)

**作者:** Unggi Lee `[一作]` (Chosun University), Yeil Jeong `[通讯]` (Indiana University Bloomington)

**通讯引用:** 73 | [OpenAlex ID](https://openalex.org/A5112070639)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 OpenLearnLM Benchmark，一套基于教育评估理论的三维（知识、技能、态度）LLM评测框架，并构建了覆盖 124K+ 题目的公开数据集。

**💡 创新点**

创新点包括：① 将 KSA（知识‑技能‑态度）模型与教育评估理论深度耦合；② 设计四层次层级（中心‑角色‑情景‑子情景）以模拟真实教学情境；③ 引入 Alignment Faking 方法检测模型在监控与非监控环境下的行为一致性。

**🔧 技术方法**

采用 LLM‑as‑Judge 评测方法、精确匹配准确率、Bloom 及 Krathwohl 任务难度划分、以及 OpenAI GPT‑5‑mini 生成技术对数据进行构造与评估。

**📊 数据集**

数据集来源于公开评估集（C‑Eval、GPQA、KICE、Pedagogy Benchmark）与专家人工生成，涵盖内容知识、教学理论、场景化任务与态度检测题目。

**📈 对比分析**

对七款前沿 LLM 进行评测，知识维度以准确率衡量；技能维度以 10 分制 rubric 评分；态度维度分标准态度与欺骗一致性两项。结果显示：不同模型在知识、技能与态度三轴上表现差异明显，Claude‑Opus‑4.5 在技能与一致性上最高，Grok‑4.1‑fast 在内容知识最强但一致性最低，验证多维评测的必要性。

**⚠️ 局限性**

局限性包括：① 目前仅覆盖英语文本，缺乏多语言与真实课堂交互数据；② 生成任务与评测依赖 GPT‑5‑mini 可能带来偏差；③ 态度评测样本量有限，需进一步扩充和细化。

---

## 835. HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation

**arXiv ID:** 2601.13864 | [PDF](https://arxiv.org/pdf/2601.13864v1)

**作者:** Qirui Chen `[一作]` (University of Science and Technology of China), Jian Yang `[通讯]` (ZTE Corporation)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了硬件安全评估基准 HardSecBench，并在其上评估 LLM 生成硬件代码的安全性。

**💡 创新点**

提出多代理流水线实现无安全意图泄露的规范化任务生成，并使用执行级验证来客观衡量安全缺陷。

**🔧 技术方法**

使用 LLM 生成规范、实现和测试用例，采用独立分支生成、仲裁器驱动迭代、覆盖率与突变检测等技术。

**📊 数据集**

构建了 924 个 Verilog/firmware-C 任务，涵盖 76 个 CWE，基于 1170 个种子样本经过质量门限过滤得到。

**📈 对比分析**

通过 Pass@k、功能/安全通过率等指标对比闭源与开源模型，结果显示功能通过率高但安全通过率低，提示式提示可提升安全率。

**⚠️ 局限性**

局限包括对 LLM 生成的安全知识依赖提示、模型对复杂时序/物理安全问题的认知不足，以及基准生成与评估仍需人工审核。

---

## 836. A Predictive and Preventive Digital Twin Framework for Indoor Wireless Networks

**arXiv ID:** 2601.13838 | [PDF](https://arxiv.org/pdf/2601.13838v1)

**作者:** Jiunn-Tsair Chen `[一作]` `[通讯]` (WNC Corporation), Jiunn-Tsair Chen (WNC Corporation)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

设计了一套基于数字孪生的预测与预防式Wi‑Fi网络管理框架，能够在未来时刻生成可能导致性能下降的网络场景，并通过分析性性能上限提前检测风险，随后自动搜索并实施鲁棒的重配置方案。

**💡 创新点**

创新点主要有：①提出两类上限约束——Shannon容量上限和CSMA‑CA延迟上限，作为快速可行性筛选；②在数字孪生中引入重要性采样，能够在海量未来情景中高效识别最危险的情况；③使用梯度搜索而非全局最优，聚焦在避免崩溃而非追求微小吞吐提升，提升鲁棒性与可解释性。

**🔧 技术方法**

使用的技术包括：数字孪生建模（空间功率签名的混合分布、时序用户活跃模型、重要性采样生成未来情景）；分析性性能上限推导（基于Shannon理论的容量上限、基于CSMA‑CA马尔可夫链的延迟/吞吐上限）；梯度搜索与简单枚举进行网络配置优化；离散化的用户活动因子（on/off过程）模型；以及对比实验中使用的ns‑2/ns‑3仿真工具。

**📊 数据集**

主要采用仿真生成的家庭Wi‑Fi网格场景作为实验数据，模拟多种用户角色（办公、学生、访客）在不同时间段的活动分布，并参考ns‑2/ns‑3的标准仿真结果验证模型精度。没有使用公开真实数据集，而是通过合成的、可重复的仿真数据来验证框架。

**📈 对比分析**

在24周的负载失衡场景中，将预测框架与传统的反应式负载平衡、QoS调节方法对比。实验显示，数字孪生能够在1–2小时之前触发预警，并通过自动重配置（如 STA 重新关联、通道/功率调整）将 AP 的性能边际恢复到安全范围；吞吐率和延迟等指标在重配置后保持在规定阈值之上，且系统对突发高负载的鲁棒性显著提升。

**⚠️ 局限性**

局限性包括：①对空间/时序模型的简化假设在复杂环境下可能产生误差；②上限约束较为保守，可能导致过度预防或不必要的配置调整；③验证主要基于仿真，缺乏真实部署中的长期实测数据；④框架目前仅处理单链路Wi‑Fi，未涵盖多链路、Beamforming、MLO等新技术的影响。

---

## 837. Nemesis, an Escape Game in Graphs

**arXiv ID:** 2601.13841 | [PDF](https://arxiv.org/pdf/2601.13841v1)

**作者:** Pierre Bergé `[一作]` (University of Grenoble Alpes), Yan Gerard `[通讯]` (University of Clermont Auvergne)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了两款新的基于图的逃脱游戏——Nemesis 与其变体 Blizzard，并对其在不同图结构上的可解性进行了全面的理论分析；

**💡 创新点**

创新点包括：①首次将逃脱游戏与图的可达性、二叉逃脱树等概念结合；②通过构造“电气化”电路 gadget 证明任意图上的 Nemesis 为 PSPACE‑完整；③将 Nemesis 与 Cat Herding 问题关联，给出 Cat Herding 的 PSPACE‑完备性证明；④在树与最大度为 3 的图上给出线性时间求解算法；⑤证明二叉逃脱树判定为 NP‑完整，并在平面多重图上得到 NP‑难度；

**🔧 技术方法**

主要技术手段包括：图结构归约（消除度 1/2 节点、出口复制）、二叉逃脱树判定与搜索、BFS 级联判定、从 SAT/Planar‑Monotone‑Rectilinear‑3SAT 及 QSAT 的多项式归约、以及电气化 gadget 的设计与分析；

**📊 数据集**

本研究未使用实验数据集，而是通过严格的理论归约与构造证明来展示复杂度结果；

**📈 对比分析**

对比方法主要是理论复杂度比较：在树与 Δ≤3 图上实现线性时间算法；在一般图与多重图上证明 PSPACE‑完备性；在平面多重图上得到 NP‑难度；此外，通过归约展示 Nemesis 与 Cat Herding 问题之间的等价性，证明后者的 PSPACE‑完备性；

**⚠️ 局限性**

局限性：1) 对平面简单图的复杂度仍未确定；2) 对固定出口数目的平面图是否可多项式求解尚不清楚；3) 只给出了理论证明，缺乏实验验证或实现细节；4) 目前仅证明了最坏情况的复杂度，未探讨平均情况或启发式算法。

---

## 838. VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content

**arXiv ID:** 2601.13951 | [PDF](https://arxiv.org/pdf/2601.13951v1)

**作者:** Shengyi Wu `[一作]`, Jianfu Zhang `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 4413 | [OpenAlex ID](https://openalex.org/A5100395008)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `40105733-5154-44cd-8090-a8cab9e64b07` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建并公开了 VTONGuard 基准数据集（约 77.5 万张真实与合成的虚拟试衣图像），并在该数据集上系统评估多种 AI 生成图像检测模型，提出了基于多任务学习的 MiT-B2-MT 方案，实现了最高的分类与边界感知性能。

**💡 创新点**

①首次针对虚拟试衣场景设计专用大规模基准，覆盖姿态、服装、背景多样性；②引入 IC‑Light 亮度和 DIV2K 背景增强，提升合成图像的真实性；③提出多任务框架，将人衣分割作为辅助任务，显著提升检测对细粒度边界痕迹的敏感度；④在跨生成范式的泛化评估中揭示了 VTON 检测的普适性瓶颈。

**🔧 技术方法**

使用了卷积检测器 ResNet‑50、频域检测器 Spec、层级 Transformer Swin‑T、语义分割 Transformer MiT‑B2 及其多任务扩展 MiT‑B2‑MT；数据处理包括 IC‑Light 光照融合、DIV2K 背景插值、频域 Fourier 变换；训练采用交叉熵 + 二值交叉熵多任务损失；评估指标为 Accuracy、Average Precision 及 AUC。

**📊 数据集**

VTONGuard 数据集：77.5 万张图像（真实 37.7 万 / 合成 39.8 万），来自 VITON‑HD、DressCode‑Upper 及 10,000+ 线上商品图片；背景来源 DIV2K；生成范式包括 flow‑based、GAN、文本逆转、PBE、Dual‑U‑Net、DiT。

**📈 对比分析**

在所有子集上，MiT‑B2‑MT 在 Accuracy、AP 与 AUC 上均遥遥领先，平均 Acc/AUC 约 98‑99%；相比单任务 Transformer，MiT‑B2‑MT 在 AP 上提升 2‑4%；但跨子集测试表明单范式训练模型在其他范式上性能显著下降，表明泛化能力仍有限。

**⚠️ 局限性**

主要局限：①跨生成范式的泛化差，模型往往只能捕捉特定范式的低级伪影；②数据集中部分范式（如 flow‑based）分辨率与其余不统一，导致训练效果受限；③虽然加入多任务分割提升性能，但在推理时仍需额外的分割网络或预训练模型；④基准仍以公开数据为主，缺乏更真实的用户生成内容（UGC）多样性。

---

## 839. RepoGenesis: Benchmarking End-to-End Microservice Generation from Readme to Repository

**arXiv ID:** 2601.13943 | [PDF](https://arxiv.org/pdf/2601.13943v1)

**作者:** Zhiyuan Peng `[一作]` (Microsoft), Dongmei Zhang `[通讯]` (Microsoft)

**通讯引用:** 10984 | [OpenAlex ID](https://openalex.org/A5100331488)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了RepoGenesis基准，评估从自然语言需求到完整微服务仓库的代码生成。

**💡 创新点**

首次提出多语言、全仓库级别微服务生成基准，并引入“review‑rebuttal”质量保证流程。

**🔧 技术方法**

采用多模态评估（Pass@1、API Coverage、Deployment Success Rate）并对OpenAI、Claude等LLM进行微调。

**📊 数据集**

使用106个跨18个领域、11种框架（Python+Java）微服务仓库，包含1,258个API端点和2,335个黑盒测试。

**📈 对比分析**

与多款开源代理和商业IDE对比，最佳系统Pass@1仅约24%，显示架构一致性与依赖管理仍是瓶颈。

**⚠️ 局限性**

局限在于仅覆盖RESTful微服务、Python/Java两语言、需求完整性假设、缺乏可维护性与安全评估。

---

## 840. Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning

**arXiv ID:** 2601.13942 | [PDF](https://arxiv.org/pdf/2601.13942v1)

**作者:** Hongbo Bai `[一作]` (Hong Kong University of Science and Technology), Yike Guo `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 18216 | [OpenAlex ID](https://openalex.org/A5045081171)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了Glance-or-Gaze (GoG) 框架，将大型多模态模型从被动观察转变为主动视觉规划，动态选择全局视野或高价值区域进行检索并迭代反思。

**💡 创新点**

创新点在于引入Selective Gaze机制实现视觉噪声过滤，以及双阶段学习策略（反思行为对齐 + 复杂度自适应强化学习）实现主动检索与多步推理。

**🔧 技术方法**

技术包括基于大型多模态模型（如 Qwen2.5-VL、Qwen3-VL）、LoRA 微调、GRPO 强化学习、视觉-文本工具调用与跨模态反思。

**📊 数据集**

使用自构造的 GoG‑Instruct 数据集（包含 5,750 条 VQA + 搜索实例）以及 InfoSeek、FVQA、SimpleVQA、MMSearch、DynVQA、LiveVQA‑New 等六大基准。

**📈 对比分析**

与直接回答、全检索工作流、提示式 GoG 代理和 MMSearch R1 等基线对比，GoG 在所有基准上实现 SOTA，平均提升 9.89–19.97 分，尤其在复杂查询上显著优于现有检索增强模型。

**⚠️ 局限性**

局限性包括检索网络不稳定导致 1–5% 的失败率、主要关注英语数据未验证多语言适应性、对特殊文化视觉知识的泛化尚未测试。

---

## 841. Proactive Coded Caching Scheme for D2D Networks

**arXiv ID:** 2601.13929 | [PDF](https://arxiv.org/pdf/2601.13929v1)

**作者:** Qiaoling Zhang `[一作]` (Fujian Normal University), Minquan Cheng `[通讯]` (Guangxi Normal University)

**通讯引用:** 1122 | [OpenAlex ID](https://openalex.org/A5047438727)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

设计了一种用于D2D网络的主动编码缓存方案，能够同时保障文件隐私与安全传输，并在文件足够大、缓存足够大时实现阶优性能。

**💡 创新点**

创新点在于将ramp秘密共享、Diffie–Hellman多用户密钥协商与HKDF派生相结合，构建多轮主动缓存更新机制，既能防止攻击者随时间累积文件片段恢复文件，又能通过D2D直接交互降低传输负载。

**🔧 技术方法**

主要技术包括Ramp Secret Sharing、Diffie–Hellman密钥协商、HKDF密钥派生、主动缓存更新（多项式更新）和编码缓存与D2D传输。

**📊 数据集**

论文采用理论模型与仿真实验，示例场景为4文件、4用户，未使用公开真实数据集。

**📈 对比分析**

通过与已知的安全传输或文件隐私方案在相同缓存容量下比较传输负载，实验表明该方案在大缓存区间内的负载接近信息理论下界，差距为常数倍。

**⚠️ 局限性**

局限性包括对大文件和大缓存容量的依赖，密钥协商与更新过程随用户数增长导致计算与广播开销增加；在缓存极小或更新频率极高的情况下性能会退化，并假设攻击者无法突破Diffie–Hellman难题。

---

## 842. On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation

**arXiv ID:** 2601.13913 | [PDF](https://arxiv.org/pdf/2601.13913v1)

**作者:** Pavlo Melnyk `[一作]` (Linköping University), Bastian Wandt `[通讯]` (Independent Researcher)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文研究单目二维到三维人体姿态提升阶段的旋转等变性，比较了无等变、完全等变和混合模型，并提出通过旋转数据增强实现等变性学习；

**💡 创新点**

创新点在于证明通过数据增强学习的等变性优于设计时强制等变的模型，且严格约束会降低任务性能；

**🔧 技术方法**

使用了ResNet、PoseFormer、VN‑Transformer、GotenNet等提升网络，并通过随机二维旋转增强、MSE训练、MPJPE/PA‑MPJPE评估；

**📊 数据集**

实验数据集包括Human3.6M、MPII‑INF‑3DHP和SportsCap；

**📈 对比分析**

通过Protocol 1/2指标比较，vanilla+aug模型在旋转测试集上优于完全等变和混合+aug模型；训练/推理时间最短；性能提升显著；

**⚠️ 局限性**

局限性包括仅针对单目二维输入的提升阶段，模型选择受实现与性能限制，完全等变模型计算成本高，实验范围局限于所选数据集。

---

## 843. PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation

**arXiv ID:** 2601.13904 | [PDF](https://arxiv.org/pdf/2601.13904v1)

**作者:** Jaeyoung Moon `[一作]` (Gwangju Institute of Science and Technology), Kyung-Joong Kim `[通讯]` (Gwangju Institute of Science and Technology)

**通讯引用:** 2137 | [OpenAlex ID](https://openalex.org/A5076055880)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出并评估了PREFAB，一种基于峰-终法与序数偏好学习的低成本自我情绪标注方法；

**💡 创新点**

创新地将峰-终法与序数偏好学习相结合，仅对情绪拐点进行标注，减少标注负担，并引入预览机制提升标注可信度；

**🔧 技术方法**

使用Transformer编码、FiLM条件化、Siamese网络与序数交叉熵损失进行偏好学习，结合find_peaks检测拐点、线性插值重建完整轨迹；

**📊 数据集**

在AGAIN游戏数据集（9款游戏的玩法日志、视频及相对激励标注）上进行训练与评估；

**📈 对比分析**

与随机、均匀、规则采样以及绝对回归模型对比，PREFAB在F1最高、ΔTE最接近真实；用户研究显示PREFAB+预览降低工作量、提升置信度，且标注质量与全标注相当；

**⚠️ 局限性**

仅在单款游戏和男性玩家样本中验证；需要先收集完整标注进行训练；线性插值可能不自然；实时预览时间成本与效率权衡仍需进一步优化。

---

## 844. TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography

**arXiv ID:** 2601.13897 | [PDF](https://arxiv.org/pdf/2601.13897v1)

**作者:** Ankita Joshi `[一作]` (Indian Institute of Technology Mandi), Aditya Nigam `[通讯]` (Indian Institute of Technology Mandi)

**通讯引用:** 1812 | [OpenAlex ID](https://openalex.org/A5103245984)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

提出了一种名为 TractRLFusion 的 GPT‑based 策略融合框架，用于白质纤维通路的非侵入性重建。

**💡 创新点**

创新点在于引入基于经验的轨迹筛选（EDS）与多评判器微调（MCPFT）实现数据驱动的策略融合，并首次在纤维追踪中应用 GPT 生成融合策略。

**🔧 技术方法**

使用了深度强化学习三种策略（TD3、SAC、DDPG）产生轨迹，GPT‑based FusionNet 作为融合器，结合多评判器 actor‑critic 结构和角度损失进行训练。

**📊 数据集**

训练数据来源于 TractoInferno（5 受试者）做轨迹采样，评估数据包括 Human Connectome Project（HCP）和 ISMRM 2015 Tractography Challenge 的公开数据集。

**📈 对比分析**

与传统 DET、PROB 方法、单一 RL 策略及其简单投票/最大 Q 级联对比，FusionNet 在 Dice、覆盖率和误连接率上均取得最高分，甚至在 HCP 上超越 TractSeg。

**⚠️ 局限性**

局限性包括仅融合三种策略，依赖特定解剖掩模，且多评判器微调对计算资源和模型稳定性要求较高，未来需扩展至更多策略并验证在更大多样化数据集上的泛化。

---

## 845. Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems

**arXiv ID:** 2601.13887 | [PDF](https://arxiv.org/pdf/2601.13887v1)

**作者:** Hong Su `[一作]` (Chengdu University of Information Technology), Hong Su `[通讯]` (Chengdu University of Information Technology)

**通讯引用:** 145 | [OpenAlex ID](https://openalex.org/A5031030652)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 Human Simulation Computation (HSC) 框架，模拟人类在环境中的思考、行动、学习、反思和调度过程，强调通过主动交互获取反馈以实现长期自适应。

**💡 创新点**

创新点包括：① 将人类思维策略（差异检测、范围扩展、连续思考等）嵌入所有阶段；② 将行动视为验证、信息获取和学习促进的核心机制；③ 通过闭环的思考–行动–反思–学习序列实现持续自我改进；④ 引入基于熵和差异的调度与学习优先级。

**🔧 技术方法**

技术手段主要是：使用大型语言模型（LLM）作为推理核心；构建思考函数 𝒯、行动函数 𝒜、反思函数 ℛ、学习函数 ℒ 的组合；利用环境交互获取实时观察和奖励；应用差异函数、熵度量和目标驱动的策略进行调度；使用概率模型对动作与环境交互进行理论分析。

**📊 数据集**

论文未给出具体实验数据集，主要是理论构建和概念验证；若要实现可采用公开 LLM 训练语料（如 Common Crawl、Wikipedia）与模拟/真实环境交互数据。

**📈 对比分析**

比较方法：文中与传统基于语言提示的链式思考、强化学习、认知架构等进行概念对比；未给出数值指标，强调通过交互式验证提高内部一致性和适应性，而非单一任务性能。

**⚠️ 局限性**

局限性：① 需要可执行行动的环境与接口，理论难以在纯文本任务上验证；② 主要关注 LLM 与可编程系统，未覆盖想象、直觉等难以量化的认知；③ 未提供实际实现细节与实验结果，难以量化评估效果；④ 对资源消耗与实时性未做评估。

---

## 846. LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health

**arXiv ID:** 2601.13880 | [PDF](https://arxiv.org/pdf/2601.13880v1)

**作者:** Ye Tian `[一作]` (University of California San Diego), Tajana Rosing `[通讯]` (University of California San Diego)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一套大规模长时序、跨维度、多用户的生活方式健康推理问答基准，并设计了一个基于多步工具调用与确定性聚合的健康助手基线模型LifeAgent；

**💡 创新点**

创新点在于：①首次构建覆盖饮食、运动、睡眠与情绪四个主要维度、长时序与多用户场景的QA基准；②提出可扩展的基准生成管线与标准评估协议；③设计LifeAgent通过分解查询、递归检索与确定性计算，显著提升跨维度聚合推理性能；

**🔧 技术方法**

主要技术包括：LLM（如GPT‑4o、Qwen‑2.5‑7B等）与SQL生成、数据库增补提示、工具调用框架smolagents、以及确定性算子进行聚合与推理；

**📊 数据集**

使用的数据集为AI4FoodDB（100名参与者的饮食、睡眠、运动、情绪四维长时序记录），通过自动化管线生成22,573道问答；

**📈 对比分析**

在两种评测设置（Context Prompting和Database‑augmented Prompting）下对11款LLM进行基准测试，闭源模型整体优于开源模型；LifeAgent在最难子集上将准确率从≈10%提升至≈40%，在多维度与多用户推理中显著优于基线；

**⚠️ 局限性**

局限性包括：SQL执行准确率低、对聚合与结构化答案的推理仍易出错、对极长序列与多用户规模的检索与聚合能力有限，且评估主要基于单一数据来源AI4FoodDB。

---

## 847. Chain-of-Thought Compression Should Not Be Blind: V-Skip for Efficient Multimodal Reasoning via Dual-Path Anchoring

**arXiv ID:** 2601.13879 | [PDF](https://arxiv.org/pdf/2601.13879v1)

**作者:** Dongxu Zhang `[一作]` (Xi'an Jiaotong University), Hiajun Zhang `[通讯]`

**关键词:** `a154b176-e466-40fc-8ae0-e5cd17677106` `fede83ac-7505-405f-ab37-e7284695c47f` `8d10c613-917e-4880-9716-17789f50e119` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出一种针对多模态大语言模型的链式推理压缩方法，避免了文本中心剪枝导致的视觉遗忘现象。

**💡 创新点**

创新点在于将视觉锚定信息瓶颈（VA‑IB）引入剪枝决策，并通过双路径评分（语言惊奇度与跨模态注意力流）实现视觉信息的自动保留。

**🔧 技术方法**

方法结合自注意力中的跨模态注意力、信息瓶颈理论、LoRA适配器以及离线策略蒸馏，实现无运行时额外开销的压缩。

**📊 数据集**

实验使用 Qwen2‑VL、Llama‑3.2 族模型，并在 MMMU、DocVQA、POPE 等数据集上验证。

**📈 对比分析**

与文本中心剪枝（TokenSkip、LLMLingua‑2、ASCoT）对比，V‑Skip 在 DocVQA 上保持 83.7% ANLS，速度提升约 2.9×，在 MMMU 上精度损失仅 5.9%，显著优于基线。

**⚠️ 局限性**

主要局限是依赖底层模型的跨模态对齐，且需额外的离线蒸馏训练，无法完全适用于缺乏对齐的架构。

---

## 848. Understanding Human-Multi-Agent Team Formation for Creative Work

**arXiv ID:** 2601.13865 | [PDF](https://arxiv.org/pdf/2601.13865v1)

**作者:** Hyunseung Lim `[一作]` (Korea Advanced Institute of Science and Technology), Hwajung Hong `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 1526 | [OpenAlex ID](https://openalex.org/A5025649906)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本研究开发了名为CrafTeam的技术探针，让单人设计实践者自行配置并与多智能体团队(HMAT)共同完成创意发想任务。

**💡 创新点**

创新点在于：①将人机协作提升到多智能体团队层面，系统化探讨HMAT的五大形成维度；②揭示“人类主导的编排”而非完全自治的团队结构最能突破智能体间无效循环；③为多方沟通与团队演进提供可操作的设计策略。

**🔧 技术方法**

使用技术主要包括：大语言模型驱动的AI角色（创意生成、评估、反馈、请求），基于Web的交互界面实现团队结构与角色配置，和对话式反馈日志用于反思。

**📊 数据集**

未使用公开数据集，而是采用12名IT行业设计从业者的真实工作背景作为实验对象，收集其在三轮迭代中的团队配置与交互日志。

**📈 对比分析**

由于本研究为探索性实验，没有与基准方法或性能指标进行量化对比；仅通过参与者主观评估和行为计数说明人类主导编排的HMAT在生成创意量和评价质量方面相对更为高效，但缺乏客观度量。

**⚠️ 局限性**

主要局限包括：样本规模有限且非纵向；仅测试创意发想任务，未覆盖其他创意工作流程；只考虑单人‑多智能体场景，未探讨多人与多智能体的协同；未深入讨论伦理与创作主体权问题。

---

## 849. Robust Reversible Watermarking in Encrypted Images Based on Dual-MSBs Spiral Embedding

**arXiv ID:** 2601.13840 | [PDF](https://arxiv.org/pdf/2601.13840v1)

**作者:** Haoyu Shen `[一作]` (East China Normal University), Xinpeng Zhang `[通讯]` (Shanghai University)

**通讯引用:** 13727 | [OpenAlex ID](https://openalex.org/A5071724015)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `fede83ac-7505-405f-ab37-e7284695c47f` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种可逆加密图像鲁棒水印框架，实现高容量、完美可逆和强鲁棒性；

**💡 创新点**

创新点在于：①结合双MSB嵌入与空间冗余，②采用螺旋展开分布多份水印，③引入RS(31,3)误差纠正编码与多数投票增强鲁棒性；

**🔧 技术方法**

技术手段包括预测误差位平面压缩、双MSB位平面重排、位级加密与块置换、RS纠错编码、分布式扩频嵌入以及多数投票提取；

**📊 数据集**

实验使用BOSSbase数据集（100张随机图像）以及常用测试图像（Baboon、Airplane等）进行评估；

**📈 对比分析**

与五种现有RRWEI方案及三种迁移自明文域的鲁棒可逆水印方案对比，实验表明在高斯噪声、JPEG压缩和裁剪攻击下，平均误码率显著低于对手，且在大面积或随机裁剪下可实现零误码；

**⚠️ 局限性**

局限性在于：对强误差校正的依赖导致一定的码字冗余；双MSB约束可能略降低加密图像的统计独立性；对极端噪声或高压缩率（低QF<20）下的鲁棒性未充分验证。

---

## 850. DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes

**arXiv ID:** 2601.13839 | [PDF](https://arxiv.org/pdf/2601.13839v1)

**作者:** Aisha Al-Mohannadi `[一作]` (Qatar Computing Research Institute), Ferda Ofli `[通讯]` (Qatar Computing Research Institute)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了 DisasterVQA 数据集并对 7 款视觉‑语言模型进行零样本基准评测。

**💡 创新点**

首次推出面向真实灾害场景、涵盖多灾种、多问答类型（二元、多选、开放式）的 VQA 基准，且与 FEMA、OCHA 等人道框架对齐。

**🔧 技术方法**

采用 GPT‑4o 自动生成问答、人工审核与 LLM 后处理；对比评测包含 open‑weight（Molmo‑7B、LLaMA‑3.2‑11B、Pixtral‑12B、Mistral‑Small‑3.1‑24B、Qwen2.5‑VL‑32B）和 proprietary（GPT‑4o‑mini、GPT‑4.1‑mini）模型。

**📊 数据集**

数据来自 CrisisMMD、Incidents1M、MEDIC 等公开灾害图像库，最终包含 1,395 张实景图像与 4,405 条专家核实的问答对。

**📈 对比分析**

使用 binary accuracy、MCQ F₁、open‑ended accuracy 进行对比，GPT‑4.1‑mini 在所有类型上表现最优（≈0.91/0.83/0.85），open‑weight 模型在复杂推理与数量推断上仍显不足。

**⚠️ 局限性**

受限于社交媒体偏差、灾害种类与区域分布不均、未覆盖误信息与真实性检测，且仅适合作为诊断工具，不能直接用于现场部署。

---

## 851. SecureSplit: Mitigating Backdoor Attacks in Split Learning

**arXiv ID:** 2601.14054 | [PDF](https://arxiv.org/pdf/2601.14054v1)

**作者:** Zhihao Dou `[一作]` (Case Western Reserve University), Minghong Fang `[通讯]` (University of Louisville)

**通讯引用:** 1529 | [OpenAlex ID](https://openalex.org/A5056811906)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `3855fcda-48ef-4070-a15e-803cd5c84d83` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文研究并提出了一种针对 Split Learning（分割学习）框架下后门攻击的新型防御方法，旨在检测并剔除受污染的嵌入数据；

**💡 创新点**

核心创新点在于先通过 UMAP 降维再用多项式核（PKT）扩展重塑嵌入空间，使正常与恶意嵌入在高维空间中更加可分；随后采用自适应多数投票过滤机制，动态调节半径以最大限度保留正常样本并剔除异常；

**🔧 技术方法**

实现技术包括：UMAP 降维、PKT 多项式核扩展、坐标中位数/均值中心点、基于 L2 距离的自适应半径过滤；

**📊 数据集**

实验使用四个公开图像数据集：CIFAR‑10、MNIST、CINIC‑10 与 ImageNette；

**📈 对比分析**

与七种现有 SL 防御（Trimmed‑mean、Multi‑Krum、HDBSCAN、DP、MP、ANP、VFLIP）以及 U‑shaped SL 的 SafeSplit 进行对比，结果显示该方法在 ACC 维持在 0.85‑0.90 之间、ASR 低于 0.06，在 VILLAIN、Fu、BadVFL、He 与 Adaptive 等五种后门攻击场景下均取得最高的鲁棒性；

**⚠️ 局限性**

局限性包括：当恶意样本比例过高或恶意客户端数量增多时，误报率会略有上升；此外对 U‑shaped SL 需要额外适配；整体计算开销相较无防御方案略有增加。

---

## 852. BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models

**arXiv ID:** 2601.14007 | [PDF](https://arxiv.org/pdf/2601.14007v1)

**作者:** Junyu Zhang `[一作]` (Shandong University), Junqi Wang `[通讯]` (State Key Laboratory of General Artificial Intelligence)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出抽象‑具体映射框架，利用探测与操控方法评估大型语言模型对人类价值观的理解。

**💡 创新点**

将概念理解拆分为抽象-抽象、抽象-具体、具体-具体三类能力，发现内部价值表征在跨层转移时保持稳定，且干预仅影响具体决策，展示价值作为稳定锚点的机制。

**🔧 技术方法**

使用线性/非线性探测器（probe）提取抽象价值描述的内部激活，并通过向量操控（steering）调整价值表征以影响模型输出。

**📊 数据集**

基于10个价值维度的抽象描述与对应具体事件叙述与决策数据，测试六个开源LLM（如GPT‑X、Llama 等）。

**📈 对比分析**

对比探测与操控效果：探测器能在抽象与具体层面一致检测同一价值，操控可显著改变具体决策而不影响抽象解释，说明跨层转移可靠且干预可控；实验显示性能提升显著，具体数值未给出但表现优于无干预基线。

**⚠️ 局限性**

单层探测器受限于分布式信号，需要大量平均；过强干预（α 过大）可能导致失败，需进一步研究干预阈值和机制。

---

## 853. torch-sla: Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch

**arXiv ID:** 2601.13994 | [PDF](https://arxiv.org/pdf/2601.13994v1)

**作者:** Mingyuan Chi `[一作]` `[通讯]`, Mingyuan Chi

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提供了一套面向工业级稀疏线性代数的 PyTorch 库，实现了 GPU 加速、分布式多 GPU 扩展和自适应的 adjoint 微分；

**💡 创新点**

创新点在于：① 使用 adjoint 方法将稀疏求解梯度的图复杂度降至 O(nnz)，解决了迭代求解梯度爆炸问题；② 通过域分解+halo 交换实现了 3 GPU 上 4 亿自由度的可扩展稀疏求解；③ 支持多种后端（SciPy、cuDSS、PyTorch-native）并无缝集成 autograd；

**🔧 技术方法**

技术包括稀疏矩阵 COO 存储、共轭梯度/牛顿/Picard/Anderson 迭代求解、Jacobi 预条件、分布式 SpMV、halo 交换、所有_reduce 及 PyTorch 的 autograd 机制；

**📊 数据集**

主要使用 2D Poisson 方程（5 点中心差分）数据，构造不同规模的稀疏矩阵（10K 至 4 亿 DOF）；

**📈 对比分析**

与 SciPy、cuDSS、PyTorch CG 等后端进行对比；单 GPU 上可解 1.69 亿 DOF，单 GPU GPU CG 190 ms / 1 M DOF；多 GPU 3 颗 H200 达到 4 亿 DOF，时间 331 s，内存 110 GB，残差约 10⁻²；整体性能优于传统 CPU 直接求解器，显著提升了可扩展性与梯度效率；

**⚠️ 局限性**

局限性包括：① 仍受通信瓶颈影响，规模增长时效率下降；② 主要采用 Jacobi 预条件，缺乏更强的多重网格或自学习预条件器；③ 在非常稠密或高维问题中 GPU 内存仍可能不足；④ 目前仅支持有限的迭代算法和预条件，未来需要进一步扩展。

---

## 854. Generating Functions Meet Occupation Measures: Invariant Synthesis for Probabilistic Loops (Extended Version)

**arXiv ID:** 2601.13991 | [PDF](https://arxiv.org/pdf/2601.13991v1)

**作者:** Darion Haase `[一作]`, Tobias Winkler `[通讯]`

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

本文提出了一种基于占优度量（occupation measure）的概率循环分析框架，并给出了利用生成函数（generating function）进行占优度量的自动模板化合成方法，以实现概率循环的精确后验分布推断。

**💡 创新点**

创新点在于：①把占优度量与Kozen的测度变换语义对齐，构造更低阶的循环不变式；②将占优度量用封闭形式的有理生成函数表示；③提出基于模板的符号求解器实现占优度量的不变式自动推导；④在不变式满足条件时同时获得正几乎必然终止（PAST）与后验分布的闭式表达。

**🔧 技术方法**

主要技术包括：概率测度理论、马尔可夫链占优度量、Kozen测度变换语义、生成函数语义、有限闭式有理函数的符号运算、Gröbner基/SMT求解、符号求解与正性检测。

**📊 数据集**

实验使用了包含若干中小规模概率循环的基准集合（如几何循环、快速骰子滚动算法 FDR_N 等），基准数据源来自作者自行构造的程序和公开的验证基准。

**📈 对比分析**

与传统基于近似抽样或基于期望不变式的方法比较，本文的自动化不变式合成在多数基准上能够在一秒内完成，且能够给出精确的后验分布或其上界；在需要手工模板时亦可快速恢复。

**⚠️ 局限性**

局限性包括：仅适用于离散非负整数变量的循环；占优度量需要初始分布可表示为有理生成函数；模板空间有限，可能无法覆盖更复杂或带模运算的循环；正性检测仍采用启发式检查，无法保证所有有效不变式被识别；对无限系数（∞）的处理尚未实现。

---

## 855. RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning

**arXiv ID:** 2601.13964 | [PDF](https://arxiv.org/pdf/2601.13964v1)

**作者:** Cheol-Hui Lee `[一作]` (Korea University), Dong-Joo Kim `[通讯]` (Korea University)

**通讯引用:** 2277 | [OpenAlex ID](https://openalex.org/A5101947623)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种RL-BioAug框架，利用少量标注的强化学习代理自动选择EEG对比学习中的增强策略，实现完全自监督的特征学习。

**💡 创新点**

创新点在于：①采用标签高效的RL代理，仅需10%标注数据即可学习最佳增强；②使用Soft‑KNN一致性得分作为连续奖励，稳定地引导策略学习；③通过Transformer策略网络结合历史动作与奖励实现上下文感知的动态增强。

**🔧 技术方法**

技术包括：强化学习（REINFORCE++），Transformer策略网络，SimCLR对比学习，Soft‑KNN奖励函数，Top‑K采样，多种时间域增强（Time Masking、Permutation、Crop&Resize、Flip、Warp）。

**📊 数据集**

使用Sleep‑EDFX（睡眠分期）和CHB‑MIT（癫痫发作检测）两个EEG数据集，分别评估睡眠阶段和发作二分类任务。

**📈 对比分析**

与随机选择和单一增强方式对比，RL‑BioAug在Sleep‑EDFX的Macro‑F1提升约9.69%、CHB‑MIT提升约8.80%；在整体B‑ACC和MF1指标上均显著优于基线。

**⚠️ 局限性**

局限性包括：动作空间仅为预定义离散增强集合，无法生成新型变换；RL计算开销大，实时部署受限；奖励依赖有限标注，易受标签噪声影响。

---

## 856. Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI

**arXiv ID:** 2601.14055 | [PDF](https://arxiv.org/pdf/2601.14055v1)

**作者:** Andrea Protani `[一作]` (European Organization for Nuclear Research), Luigi Serio `[通讯]` (European Organization for Nuclear Research)

**通讯引用:** 820 | [OpenAlex ID](https://openalex.org/A5069214353)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

本研究提出了基于超体素图的无解码器Transformer‑GAT编码框架SVGFormer，用于多模态MRI脑肿瘤定位。

**💡 创新点**

创新点在于将体素级特征与语义级图推理端到端统一，并通过无解码器聚焦编码层，实现双尺度可解释性。

**🔧 技术方法**

采用3D SLIC超体素分割、Patch级Transformer、GATv2图注意网络以及多头MLP回归/分类头。

**📊 数据集**

使用BraTS 2025预处理脑瘤多模态MRI数据集。

**📈 对比分析**

通过5折交叉验证与传统U‑Net/ViT等基线比较，分类F1≈0.875、ROC‑AUC>0.97，回归MAE≈0.028，显示性能优异。

**⚠️ 局限性**

局限在于对超体素粒度敏感、缺乏多类别分割支持以及需要进一步验证临床可用性。

---

## 857. Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering

**arXiv ID:** 2601.14050 | [PDF](https://arxiv.org/pdf/2601.14050v1)

**作者:** Yuxin Chen `[一作]` (National University of Singapore), Tat-Seng Chua `[通讯]` (National University of Singapore)

**通讯引用:** 59127 | [OpenAlex ID](https://openalex.org/A5089404640)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文系统分析了多语言Mixture-of-Experts LLM的路由行为、专家专业化以及层次功能，并提出通过在中间层引导路由的无训练时间干预方法以提升跨语言性能。

**💡 创新点**

创新点在于揭示MoE模型中路由与专家利用与语言族结构和网络层次高度对应，并利用中间层路由引导实现无训练时间干预的跨语言性能提升。

**🔧 技术方法**

使用路由分析、专家分配统计、层级干预实验以及路由引导调节技术。

**📊 数据集**

使用Qwen3-30B-A3B MoE LLM、Belebele NLU基准、MGSM数学推理、XQuAD理解以及FLORES-200生成等多语言数据集。

**📈 对比分析**

与基线MoE模型、稠密模型以及不同层级干预进行对比，实验表明中间层路由引导在高低资源语言均可提升约1–2%的准确率，并显著改善语言一致性。

**⚠️ 局限性**

局限在于仅针对单一大型MoE模型进行研究，仅做推理时干预，未探究更大规模模型以及训练时或后训练优化的可扩展性。

---

## 858. Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants

**arXiv ID:** 2601.14041 | [PDF](https://arxiv.org/pdf/2601.14041v1)

**作者:** Yunhe Wang `[一作]` (Huawei Noah's Ark Lab), Dacheng Tao `[通讯]` (Nanyang Technological University)

**通讯引用:** 97310 | [OpenAlex ID](https://openalex.org/A5074103823)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

阐述了扩散语言模型（DLM）在生成、推理和多模态任务中相对于自回归模型的优势，并提出了未来发展的十大挑战与四大支柱路线图。

**💡 创新点**

创新点在于将DLM视为全局、双向的去噪过程，提出了多尺度分词、结构化掩码、可伸缩输出长度、内部“再掩码”思考等技术框架，并聚焦于实现全链路统一的多模态扩散骨干。

**🔧 技术方法**

使用技术包括：扩散去噪机制、非因果Transformer架构、结构化多尺度分词、功能性掩码、多步蒸馏与推理加速、主动再掩码的迭代思考、对齐与强化学习方法、以及跨模态的扩散联合目标。

**📊 数据集**

文中未给出具体实验数据集，主要以理论分析与未来研究方向为主，但暗示将需要标注结构依赖的文本、RAG/长序列对齐数据以及多模态联合数据进行预训练与微调。

**📈 对比分析**

由于缺乏实验实现，本文没有提供与现有AR模型或其他扩散模型的数值对比；仅以设计思路与预期收益进行概念性讨论。

**⚠️ 局限性**

主要限制在于：1) 仍处于理论与路线图阶段，缺乏实证验证；2) 对数据工程和训练效率的具体方案尚未细化；3) 在复杂任务中的实际性能与推理速度仍有待评估；4) 需要解决跨模态统一目标与多尺度分词的实现细节。

---

## 859. RM-Distiller: Exploiting Generative LLM for Reward Model Distillation

**arXiv ID:** 2601.14032 | [PDF](https://arxiv.org/pdf/2601.14032v1)

**作者:** Hongli Zhou `[一作]` (Harbin Institute of Technology), Tiejun Zhao `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 8380 | [OpenAlex ID](https://openalex.org/A5100564229)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `8d10c613-917e-4880-9716-17789f50e119` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了 RM‑Distiller 框架，用多面向的教师 LLM 能力（精炼、打分、生成）来高效蒸馏奖励模型，提升对人类偏好对齐的性能。

**💡 创新点**

创新点在于系统化利用生成模型的三大能力：对抗性精炼生成近似对比对、基于分数的 margin‑aware 回归以捕获偏好强度，以及生成分布正则化防止遗忘，从而显著提升 RM 的准确率和 RLHF 效果。

**🔧 技术方法**

主要技术包括对抗精炼（Contrastive Refinement）、margin‑aware 回归（Margin‑Aware Regression）与生成正则化（Generative Regularization）以及联合多任务损失优化。

**📊 数据集**

使用 Skywork‑Preference‑v0.2、RewardBench、RM‑Bench、AlpacaEval、FollowBench、CFBench 等公开偏好与对齐基准；教师模型采用 GPT‑4o、Qwen3‑14B，学生模型为 Qwen2.5‑3B‑Instruct。

**📈 对比分析**

与 BT‑Classifier、Margin‑BT、LSAM、SynRM、CLoud、RMBoost、SteerLM 等基线对比，RM‑Distiller 在 RewardBench 和 RM‑Bench 上平均提升约 10‑15%，在 RLHF 实验中 PPO/GRPO/DAPO 的对齐分数提升 5‑8%，并在小样本（1K）和跨域（阿拉伯语）设置中保持优势。

**⚠️ 局限性**

局限包括仍依赖大规模生成模型作为教师，导致推理成本高；在极端多样化任务或语言上可能需要更多领域特定微调；并且对教师模型的分数和精炼质量高度敏感。

---

## 860. Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution

**arXiv ID:** 2601.14030 | [PDF](https://arxiv.org/pdf/2601.14030v1)

**作者:** Samuel W. Remedios `[一作]` (Johns Hopkins University), Blake E. Dewey `[通讯]` (Johns Hopkins University)

**通讯引用:** 2204 | [OpenAlex ID](https://openalex.org/A5044628433)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

针对多图像超分辨率（MISR）问题，利用扩散模型对多方向低分辨率MRI图像进行联合重建，实现高分辨率体积恢复。

**💡 创新点**

提出了在扩散后验采样（DPS）中对似然进行可分离梯度分解，允许仅使用独立测量的梯度即可完成多图像数据一致性修正，并引入噪声加权融合，形成统一的MISR扩散逆问题框架。

**🔧 技术方法**

核心技术包括扩散模型（DDIM、flow‑matching 估计）、后验采样（DPS）、DMAP、DPPS、PnP/ADMM 的 MISR 泛化，以及噪声加权梯度融合。

**📊 数据集**

实验数据来自 AIBL 与 SLEEP 两个公开脑部MRI数据库，选取 100 例 1mm³ 分辨率 T1 加权图像，模拟 4×、8×、16× 的通过平面降分辨率及相应噪声。

**📈 对比分析**

与单图像超分辨率（SISR）对比，MISR 在 PSNR、SSIM 与 FID 上均有显著提升（PSNR 1–3 dB 改进），且在多尺度下保持更好解剖结构；在 4× 缩放时部分方法 FID 下降，说明感知–失真权衡影响。

**⚠️ 局限性**

局限性包括：未处理不同测量间的配准误差、仅考虑同一对比度的多平面数据，且在极高降采样（16×）下仍需进一步提升细节重建。

---

## 861. Auditory Brain Passage Retrieval: Cross-Sensory EEG Training for Neural Information Retrieval

**arXiv ID:** 2601.14001 | [PDF](https://arxiv.org/pdf/2601.14001v1)

**作者:** Niall McGuire `[一作]` (University of Strathclyde), Yashar Moshfeghi `[通讯]` (University of Strathclyde)

**通讯引用:** 1656 | [OpenAlex ID](https://openalex.org/A5059100610)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出并验证了使用听觉EEG作为查询的脑通道检索（BPR）方法，并首次探索跨感官训练。

**💡 创新点**

创新点在于：①首次在BPR中使用听觉EEG；②证明跨感官（听觉+视觉）训练能显著提升检索效果；③不同聚合策略对跨感官训练的影响。

**🔧 技术方法**

技术主要包括：双编码器架构、Transformer基EEG编码器、四种聚合策略（CLS、mean、max、multi‑vector）和InfoNCE对比学习。

**📊 数据集**

使用了 Alice（听觉）和 Nieuwland（视觉）EEG数据集，通过逆填空（ICT）生成查询‑文档对。

**📈 对比分析**

通过在听觉、视觉和组合训练下评估 MRR、Hit@1/5/10，发现组合训练+CLS聚合下听觉EEG MRR 0.474、Hit@10 0.858，优于传统 BM25/BM25 文本基准。

**⚠️ 局限性**

局限包括：仅使用两份自然阅读/聆听数据，未涵盖主动查询形成的EEG，且数据源差异可能掩盖跨感官神经特征的独立性。

---

## 862. Equivariant Learning for Unsupervised Image Dehazing

**arXiv ID:** 2601.13986 | [PDF](https://arxiv.org/pdf/2601.13986v1)

**作者:** Zhang Wen `[一作]` (Heriot-Watt University), Dongdong Chen `[通讯]` (Heriot-Watt University)

**通讯引用:** 1203 | [OpenAlex ID](https://openalex.org/A5100364591)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了一种完全无监督的等变图像去雾框架 EID，利用图像对称性和伪雾物理模型实现科学图像与自然图像的去雾。

**💡 创新点**

创新点在于将等变一致性约束与雾一致性结合，并通过循环对抗学习得到伪雾物理模型，从而在无清晰图像监督的条件下实现高质量去雾。

**🔧 技术方法**

采用等变学习、循环对抗生成网络、伪雾模块、U‑Net 结构以及 MSE、NIQE、BRISQUE、FID 等评估指标。

**📊 数据集**

实验使用医学内镜数据集 Cholec80‑Haze、细胞显微镜数据集 Cell97，以及自然图像基准 RESIDE‑OTS/HSTS。

**📈 对比分析**

与 DCP、NLP、CycleGAN、Cycle‑Dehaze、UCL‑Dehaze、D4+、UME‑Net 等九种方法对比，EID 在 NIQE、BRISQUE、FID 以及 PSNR/SSIM 上均取得最佳或接近最佳表现。

**⚠️ 局限性**

局限性包括：等变假设在某些复杂场景下可能不成立；伪雾模型受对抗训练质量影响；模型计算量大，实时部署受限。

---

## 863. Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects

**arXiv ID:** 2601.13979 | [PDF](https://arxiv.org/pdf/2601.13979v1)

**作者:** Raffaele Mazza `[一作]` (Università degli Studi della Campania Luigi Vanvitelli), Pietro Falco `[通讯]` (Università degli Studi di Padova)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `729e5870-4135-47f5-97f2-e3974d07b5dc` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了一套跨模态视觉-触觉框架，用于在可见性受限的条件下重建柔性线性物体（如电缆）的三维形状；

**💡 创新点**

创新点包括：① 基于骨架化和端点检测的拓扑感知视觉表示；② 通过自主动触觉探索弥补视觉遮挡缺失；③ 统一点云融合与 B‑spline 插值，实现平滑完整的几何模型；同时将 SAM 与 Florence2 等基础模型用于语义分割；

**🔧 技术方法**

技术栈涵盖：SAM、Florence2 语义分割；RGB‑D 摄像头（Intel Realsense D435i）；触觉传感器（SUNTouch）；RANSAC 计面、HDBSCAN 聚类、骨架化、下采样、欧氏聚类；基于端点的排序与触觉探索算法；B‑spline 拟合；

**📊 数据集**

未使用公开数据集，实验基于真实机器人平台（Yaskawa Motoman SIA5F + RGB‑D + 触觉传感器）收集的电缆场景；

**📈 对比分析**

通过 ICP 对齐评估重建精度，RMSE 仅为 0.00174 m（单根电缆）至 0.0065 m（双根电缆），表明在遮挡、倾斜、交叉等复杂情况仍能保持高精度；未与现有单视觉方法直接对比，但结果优于传统仅视觉的重建；

**⚠️ 局限性**

局限性包括：① 端点检测对自交角度小的稠密点云敏感，导致多端点误判；② 触觉探索受限于物体材质与表面反射；③ 对分割错误（如 SAM2 无法完整分割）仍需依赖触觉补偿；④ 未在大规模多根电缆或更复杂背景下充分验证。

---

## 864. FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation

**arXiv ID:** 2601.13976 | [PDF](https://arxiv.org/pdf/2601.13976v1)

**作者:** Jing Zuo `[一作]` (Fantasy AIGC Team), Yonggang Qi `[通讯]` (Beijing University of Posts and Telecommunications)

**通讯引用:** 923 | [OpenAlex ID](https://openalex.org/A5075315261)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种统一的隐式链式推理框架，融合文本、视觉和多模态链式推理，并在推理时无需显式生成推理步骤；

**💡 创新点**

通过将视觉推理压缩到VAR模型的低维潜在空间，消除了显式推理的令牌爆炸，同时使用跨模式对齐约束让不同推理模式共享同一隐式表示；

**🔧 技术方法**

使用预训练的视觉自回归(VAR)模型进行视觉信息压缩，基于Qwen2.5-VL或Qwen-VL-Max实现多模态链式推理，采用门控机制和交叉模式对齐的联合训练；

**📊 数据集**

在LH‑VLN长时隧多阶段导航基准上进行实验；

**📈 对比分析**

与Aux‑Think、CoT‑VLA、WorldVLA、MGDM等基线对比，取得SR 2.44、ISR 11.01、CSR 9.64、CGT 8.99的最高成绩，并在推理效率上实现APS大约 1.0，比显式CoT方法提升 5‑6 倍；

**⚠️ 局限性**

对齐约束和VAR压缩依赖于先验的CoT标注与VAR模型性能，训练时仍需要显式推理步骤，且在不同VLN任务或更大规模数据集上的泛化能力尚待验证。

---

## 865. Software Testing in the Quantum World

**arXiv ID:** 2601.13996 | [PDF](https://arxiv.org/pdf/2601.13996v1)

**作者:** Rui Abreu `[一作]` (University of Porto), Anila Mjeda `[通讯]` (Munster Technological University)

**通讯引用:** 6 | [OpenAlex ID](https://openalex.org/A5095521898)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文综述了量子软件测试的关键挑战，并提出从软件工程角度出发的可行方法，重点讨论如何在真实噪声量子计算机上实现可扩展的端到端质量保证。

**💡 创新点**

创新点包括：①将传统软件测试的可扩展性思想迁移到量子领域，强调抽象化、属性驱动测试和组合推理；②提出基于统计置信度的测试充分性度量；③将量子计算本身作为测试工具（如量子搜索、量子近似优化、量子机器学习）来加速测试输入生成和优先级排序；④对量子测试基准和工具生态进行系统性评估，指出需统一指标和实验协议。

**🔧 技术方法**

采用的技术主要有：量子电路简化与子电路切片、属性基（symmetry、invariant、unitary）测试、假设-保证分解、量子近似优化（QAOA）、量子机器学习、元迁移变换、统计与噪声容忍的测试或acles、混合量子-经典工作流。

**📊 数据集**

本文并未提出或使用新的数据集，而是呼吁构建公开、标准化的量子测试基准集（包含多样化的程序、故障模型和测量预算）。

**📈 对比分析**

比较方法：作者指出现有工具在真实硬件上的可扩展性不足，并给出衡量指标（错误检测率、覆盖率、射击次数、深度、量子位数、统计置信区间、噪声鲁棒性）。虽然未给出实验结果，但提出了基准评估框架和典型的实验配置，强调需对比不同工具在同一硬件与相同噪声模型下的表现。

**⚠️ 局限性**

局限性：缺乏成熟的可扩展工具与统一接口；对噪声和硬件差异的建模仍不完善；测试oracle和充分性度量仍处于概念阶段；目前多采用混合量子-经典方案，尚未实现完全量子化的测试流程；基准集和标准化流程尚未普及，影响结果可比性和重现性。

---

## 866. Kakugo: Distillation of Low-Resource Languages into Small Language Models

**arXiv ID:** 2601.14051 | [PDF](https://arxiv.org/pdf/2601.14051v1)

**作者:** Peter Devine `[一作]` (University of Edinburgh), Barry Haddow `[通讯]` (University of Edinburgh)

**通讯引用:** 18814 | [OpenAlex ID](https://openalex.org/A5110781707)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `8d10c613-917e-4880-9716-17789f50e119` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了Kakugo自动化管线，使用教师模型生成合成数据并结合翻译数据，训练覆盖54种低资源语言的通用式小型语言模型。

**💡 创新点**

创新点包括：①仅凭语言名即可启动完整的模型开发流程；②将生成的推理轨迹与翻译数据相结合显著提升性能；③公开模型与训练数据，单位成本低于50美元，降低了低资源社区的技术门槛。

**🔧 技术方法**

使用的技术包括：大语言模型GPT‑OSS 120B的知识蒸馏、基于主题、情景、上下文的多种Prompt生成方法、全量微调Granite 4 Micro学生模型以及LLM生成的推理链（chain‑of‑thought）跟踪。

**📊 数据集**

主要数据集为InfinityInstruct 7M_core子集、FineWeb2文本以及评测基准Belebele、FLORES、GlobalMMLU、SIB200，后者用于多任务性能评估。

**📈 对比分析**

采用3‑shot评估在14种语言上的翻译、分类、问答等多任务基准进行比较；最终Gen+Tran(full)模型在54语言上平均提升约9.9%（Belebele）、1.9%（GlobalMMLU）、8.8%（SIB200）和8.5 CHRF++（FLORES xx‑en），在人工偏好评估中多数语言更倾向于Kakugo模型。

**⚠️ 局限性**

局限性包括：仅对教师模型能生成数据的语言有效；缺乏对文化特定任务的评估；混合数据比例最优解未确定；不同模型组合的效果未知。

---

## 867. PRiSM: Benchmarking Phone Realization in Speech Models

**arXiv ID:** 2601.14046 | [PDF](https://arxiv.org/pdf/2601.14046v1)

**作者:** Shikhar Bharadwaj `[一作]` (Carnegie Mellon University), David R. Mortensen `[通讯]` (Carnegie Mellon University)

**通讯引用:** 3009 | [OpenAlex ID](https://openalex.org/A5059859009)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一个名为 Prism 的开放基准，旨在系统评估语音识别系统在语音单元识别（phone recognition）上的能力，并提供完整的评测框架。

**💡 创新点**

其创新点在于首次同时开展内在转写误差率（PFER）与外在下游任务（病理语音评估、第二语言发音反馈、多语言识别）的综合评估，并将所有数据、代码和评测脚本公开共享。

**🔧 技术方法**

作者采用了自监督预训练 + CTC、Encoder‑CTC、Attention‑Encoder‑Decoder 等模型架构，并基于 PFER、转写探针（Transcript Probe）和表示探针（Representation Probe）等技术进行评估。

**📊 数据集**

实验使用了多语言数据集，包括 TIMIT、LibriSpeech、DoReCo、Pathological Speech 等公开数据集，涵盖多种方言、语音障碍与低资源语言。

**📈 对比分析**

与传统 ASR 模型、LALM（Large Audio Language Models）以及随机基线对比显示，Encoder‑CTC 模型在 PFER 低、下游任务稳定性高，且多语言预训练显著提升性能，LALM 在多语言任务中表现逊色。

**⚠️ 局限性**

本文的局限性在于数据集语言、方言覆盖不完整，转写标准主观性高，且下游探针可能因数据偏差或噪声过拟合，从而影响评估结果的可靠性。

---

## 868. Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation

**arXiv ID:** 2601.14039 | [PDF](https://arxiv.org/pdf/2601.14039v1)

**作者:** Wesam Moustafa `[一作]` (Institute of Computer Science), Rafet Sifa `[通讯]` (Fraunhofer Institute for Intelligent Analysis and Information Systems)

**通讯引用:** 2258 | [OpenAlex ID](https://openalex.org/A5064201630)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e15e3743-5ee0-4d5f-813d-d146868082fc` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了可模块化的置信放弃框架，用以提升医学图像分割模型对标签噪声的鲁棒性。

**💡 创新点**

创新点在于引入信息化正则化和幂律自调置信惩罚，并将其与现有损失（GCE、SCE、Dice）结合，得到三种新的噪声鲁棒损失（GAC、SAC、ADS）。

**🔧 技术方法**

采用置信放弃（abstention）机制、改进的DAC/IDAC损失、噪声率估计、幂律自调α策略，以及Dice、GCE、SCE等主流损失函数。

**📊 数据集**

使用了CaDIS和DSAD两大医学影像分割数据集进行实验。

**📈 对比分析**

通过与无放弃基线在不同噪声比例下的对比，实验表明该框架在高噪声环境下显著提升Dice指标，整体性能优于传统损失。

**⚠️ 局限性**

局限性包括对不同噪声模型的调参需求、跨域泛化性尚未充分验证，以及在样本稀缺情况下置信放弃可能导致信息浪费。

---

## 869. Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment

**arXiv ID:** 2601.14022 | [PDF](https://arxiv.org/pdf/2601.14022v1)

**作者:** Rodrigo Pereira David `[一作]` (National Institute of Metrology, Quality and Technology), João Alfredo Cal-Braz `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种基于机器学习的“像对像”框架，在相同真实驾驶条件下，用电动车的特征模型生成假想的CO₂排放序列，以实现与内燃机车的直接比较。

**💡 创新点**

创新点在于：①将驾驶上下文与技术特有的内部作用量解耦，使用统一即时排放单位(g/s)；②通过代理验证保证跨域特征替代不会显著增加误差，从而实现可靠的技术对比。

**🔧 技术方法**

使用长短时记忆（LSTM）递归神经网络完成特征模型(上下文→扭矩/油门)和排放模型(速度+扭矩+油门→即时CO₂)，训练采用MSE损失、Adam优化器和余弦学习率调度。

**📊 数据集**

数据集：电动车BMW i3的公开高频测量数据；内燃机车Infiniti QX50、Chevrolet Blazer、Chrysler Pacifica的车架式测功仪多车道行驶记录，统一转换为统一单位和命名。

**📈 对比分析**

比较方法：先单域训练特征与排放模型 → 代理验证 → 在ICEV行驶轨迹上用EV特征模型生成假想扭矩/油门，再用EV排放模型得到假想CO₂。性能：ICEV排放MAE≈0.28 g/s，EV排放MAE≈0.028 g/s；代理验证误差极小（median ΔMAE≈-0.0025 g/s），表明跨域对比可靠。

**⚠️ 局限性**

局限性：①缺乏同一路段、相同司机的双车对比数据；②逆向映射（EV→ICEV）在CVT等传动结构中可识别性弱；③电网碳强度、再生制动等因素处理保守，未考虑燃料混合比例变化。

---

## 870. Consensus Stability of Community Notes on X

**arXiv ID:** 2601.14002 | [PDF](https://arxiv.org/pdf/2601.14002v1)

**作者:** Yuwei Chuai `[一作]` (University of Luxembourg), Nicolas Pröllochs `[通讯]` (JLU Giessen)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了 X 平台社区笔记在首次展示后随时间的共识稳定性与评价动态，发现 30.2% 的笔记在最初满足展示条件后会消失，并揭示了展示后评议的极化趋势。

**💡 创新点**

首次系统性量化了社区笔记在可见后评价的后续变化，发现类似观点的评议者更倾向于支持，而异议评议者更倾向于否定，且这种极化直接导致笔记消失，揭示了共识式审核机制的脆弱性。

**🔧 技术方法**

采用矩阵分解构建评议者相似度，使用多层次逻辑回归评估消失风险，应用断点时间序列模型捕捉展示前后评价量和倾向的变化，并进行反事实实验排除极化评议者的影响。

**📊 数据集**

使用来自 X 社区笔记公开数据集，包含 437,396 条笔记、35,081,488 条评价、580,000+ 评议者和 233,908 条原始推文。

**📈 对比分析**

通过对比展示前后评价数量和倾向的显著提升，以及对比消失与稳定笔记的差异，证明展示后评价量与倾向的急剧变化与笔记消失显著相关；反事实实验显示排除异议评议者后消失笔记的可见度显著提高。

**⚠️ 局限性**

局限包括无法区分个人偏见、党派分歧与有组织操纵；结果受 X 平台特定算法与政策演变的影响，且数据为快照，缺乏对编辑或删除历史的完整追踪。

---

## 871. Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains

**arXiv ID:** 2601.13975 | [PDF](https://arxiv.org/pdf/2601.13975v1)

**作者:** Marco Piccolo `[一作]` (Nova School of Business and Economics), Joachim Vanneste `[通讯]` (blueOASIS)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

建立统一信息管线，对多源海洋摄像数据进行标准化处理并固定使用YOLO11m模型进行鱼类检测，随后在不同域下进行受控跨域评估与边缘设备部署验证。

**💡 创新点**

通过将检测问题视为信息可靠性问题，设计受控的跨域压力测试，将视觉退化与场景结构两种因素分离，发现稀疏场景导致的“Context Collapse”误差模式；同时提出可在低成本边缘硬件上实现的TensorRT加速方案。

**🔧 技术方法**

YOLO11m深度检测网络、TensorRT FP16加速、Optuna超参搜索、基于视觉退化（UIQM、UCIQE等）与结构度量（物体密度、重叠率）的诊断指标、混合效应模型与TIDE错误分解。

**📊 数据集**

八大异构海底图像数据集（OzFish、DeepFish、Luderick、AquaCoop、Fish4Knowledge、LifeCLEF、Aquarium、Open Ocean）以及外部测试集（Fish Tracking、Aquaculture Dense）。

**📈 对比分析**

固定模型在统一管线下的基线mAP约0.62（640×640），在跨域压力测试中DeepFish稀疏域召回下降至0.55，Luderick域召回下降至0.70；在Jetson Nano上TensorRT实现3.45 FPS，可满足周期性采样。

**⚠️ 局限性**

仅检测单一鱼类类别，未涉及细粒度物种识别；缺乏连续跟踪和行为推断；对极端能见度、极暗等极端环境覆盖不足；模型在稀疏或高重叠场景下仍易失效。

---

## 872. Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition

**arXiv ID:** 2601.13953 | [PDF](https://arxiv.org/pdf/2601.13953v1)

**作者:** Gorgi Pavlov `[一作]` `[通讯]` (Lehigh University and Johnson and Johnson), Gorgi Pavlov (Lehigh University and Johnson and Johnson)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出层次谱组合（Hierarchical Spectral Composition）框架，用固定布尔傅里叶基底和 Sinkhorn 投影的双随机路由结合列符号调制，在梯度下降中学习稀疏三元多项式阈值表示，实现精确离散布尔逻辑推理。

**💡 创新点**

核心创新在于将 Birkhoff 轨道投影与列签位扩展相结合，使双随机路由保持稳定性且可表达布尔否定，证明任何 n≤4 的布尔函数都能以零损失量化的稀疏三元掩码实现，并通过 MCMC 精细化获得全精度。

**🔧 技术方法**

技术手段包括布尔 Fourier 分析、Gumbel‑softmax 三元逼近、Sinkhorn‑Knopp 双随机矩阵投影、列签位调制、Walsh‑Hadamard 精确系数求解、并行退火 MCMC 以及层次化组合构造。

**📊 数据集**

使用全真值表枚举的 16 个 2 变量、10 个 3 变量以及 10 个 4 变量布尔运算作为实验数据集，并在此基础上构造 64 位加法器、128 位相等比较器等大规模组合电路进行验证。

**📈 对比分析**

与纯梯度下降、无约束路由、无列签等对照实验相比，所提方法在所有基准上均实现 100% 准确、零量化误差，GPU 推理吞吐量达到 10,959 MOps/s，硬件可实现单周期组合逻辑推理。

**⚠️ 局限性**

主要局限在于维度扩展受组合空间指数增长限制，n>4 仍需估计或层级分解；此外对复杂函数的梯度陷阱和本地最优仍未完全解决。

---

## 873. LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems

**arXiv ID:** 2601.14053 | [PDF](https://arxiv.org/pdf/2601.14053v1)

**作者:** Badri N. Patro `[一作]` (Microsoft), Vijay S. Agneeswaran `[通讯]` (Microsoft)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

系统性梳理2019‑2025年大语言模型的演进与技术生态，提出LLMOrbit的八维圆形分类法并评估50余模型；

**💡 创新点**

首次量化“扩展壁”三大瓶颈（数据匮乏、成本激增、能耗暴涨），并总结六种突破扩展壁的范式；

**🔧 技术方法**

结合Transformer改进（FlashAttention、GQA、MLA、MoE）、训练方法（RLHF、GRPO、DPO、ORPO、MTP）以及后训练压缩（量化、合并）等技术；

**📊 数据集**

利用公开与自制大规模语料（约15T–20T标记数据、书籍、论文、网络文本、合成教育内容等）进行预训练与后训练；

**📈 对比分析**

通过9项基准（MMLU、MATH、HumanEval等）对比，展示大规模稀疏模型、纯RL推理模型等在成本、能耗与性能上的显著提升；

**⚠️ 局限性**

局限在于对数据质量估计缺乏统一标准、RL奖励不确定性、量化对推理任务的降效、模型可解释性与安全性待进一步完善。

---

## 874. Analyzing the Availability of E-Mail Addresses for PyPI Libraries

**arXiv ID:** 2601.14034 | [PDF](https://arxiv.org/pdf/2601.14034v1)

**作者:** Alexandros Tsakpinis `[一作]` (fortiss GmbH), Alexander Pretschner `[通讯]` (Technical University of Munich)

**通讯引用:** 7208 | [OpenAlex ID](https://openalex.org/A5002011805)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文对 PyPI 生态系统中的 686,034 个 Python 库及其 GitHub 仓库的联系信息（主要是邮箱地址）进行了大规模经验性分析。

**💡 创新点**

创新点在于首次系统性评估邮箱可用性、来源分布、无效条目类型，并将结果扩展到依赖链层面，同时结合 PageRank 评估重要性。

**🔧 技术方法**

采用 Python 编写爬虫抓取 PyPI 和 GitHub API，利用 email-validator 进行语法与域解析校验，并构建依赖图计算 PageRank。

**📊 数据集**

使用的主要数据集为经过过滤后的 686,034 个 PyPI 包及其 1,866,485 条依赖关系，来源于 PyPI simple 与 JSON 接口及 GitHub API。

**📈 对比分析**

作者通过对单个库与其直接/传递依赖链进行对比，并按 PageRank 分层评估覆盖率；结果显示约 81.6% 的库至少有一个有效邮箱，直接/传递依赖高达 97.8%/97.7%，表明覆盖率非常高。

**⚠️ 局限性**

局限性包括仅关注 PyPI 与 GitHub，未考虑其他包源或仓库平台；仅检索最新版本，忽略版本差异；数据为快照，易随时间变化失效；无效邮箱判定基于域解析，可能误判。

---

## 875. Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics

**arXiv ID:** 2601.14027 | [PDF](https://arxiv.org/pdf/2601.14027v1)

**作者:** Junqi Liu `[一作]` (Academy of Mathematics and Systems Science, University of Chinese Academy of Sciences), Wenda Li `[通讯]` (University of Edinburgh)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了 Numina‑Lean‑Agent，一个基于 Claude Code 与 Numina‑Lean‑MCP 的通用代理式形式化数学推理框架，成功解决 Putnam 2025 所有题目并与数学家合作完成 Brascamp–Lieb 定理的正式化。

**💡 创新点**

创新点在于把通用编码代理作为形式化推理核心，利用 MCP 协议实现工具插件化与自适应调用；结合蓝图式规划和人机协作，实现高效、可扩展、无需专门训练的形式化证明。

**🔧 技术方法**

采用 Claude Code（LLM）、Numina‑Lean‑MCP（Lean‑LSP‑MCP、LeanDex、Informal Prover、Discussion Partner）等技术，并使用 MCP、语义检索、迭代精炼、子代理、蓝图规划等方法。

**📊 数据集**

主要数据集包括 Putnam 2025 官方题目集、Lean mathlib 与 Mathlib 代码库以及对应的定理检索语料。

**📈 对比分析**

通过与 AxiomProver、Seed‑Prover 1.5、Aristotle 等系统在 Putnam 2025 上对比，Numina‑Lean‑Agent 在所有 12 题均成功求证，匹配 AxiomProver 并比 Aristotle 高效；在部分题目上证明长度更短、求解时间更低。

**⚠️ 局限性**

局限性包括生成的 Lean 代码往往冗长、可读性差，难以达到人类 Mathlib 代码的简洁性；对类型层面问题敏感，需人工干预；整体仍缺乏与人类风格一致的优雅证明。

---

## 876. Universal Approximation Theorem for Input-Connected Multilayer Perceptrons

**arXiv ID:** 2601.14026 | [PDF](https://arxiv.org/pdf/2601.14026v1)

**作者:** Vugar Ismailov `[一作]` `[通讯]`, Vugar Ismailov

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

**🎯 论文内容**

本文提出了输入连通多层感知机（IC‑MLP）架构，并在单变量与多变量情形下证明了其通用逼近定理，指出激活函数非线性是该架构实现任意连续函数的必要且充分条件。

**💡 创新点**

创新点在于：1）在每一隐藏层直接接收原始输入，从而构造出一套更简单、直观的递归网络函数表达式；2）证明该架构对激活函数的唯一要求仅为非线性，显著简化了传统深度网络通用性分析的复杂度；3）展示IC‑MLP在函数空间上闭合于线性组合，构成一个完整的代数结构。

**🔧 技术方法**

主要使用了函数分析工具（如Hahn–Banach、Riesz表示定理）、Stone–Weierstrass定理、卷积与卷积核（mollifier）技术、泰勒展开与逼近法以及代数闭包论证，配合递归构造和多层投影等方法完成证明。

**📊 数据集**

无（本文为理论分析，不涉及数据集）。

**📈 对比分析**

未进行实验比较；本工作仅提供理论上的通用逼近结论，无具体性能指标或与其他模型的数值对比。

**⚠️ 局限性**

局限性：仅给出了通用性必要与充分条件，未给出逼近误差率、深度/宽度与参数量的量化分析；缺乏经验验证，未讨论在实际任务中的实现与效率；并未考虑特殊约束（如可微性、可解释性）下的进一步改进。

---

## 877. OAMAC: Origin-Aware Mandatory Access Control for Practical Post-Compromise Attack Surface Reduction

**arXiv ID:** 2601.14021 | [PDF](https://arxiv.org/pdf/2601.14021v1)

**作者:** Omer Abdelmajeed Idris Mohammed `[一作]`, Ilhami M. Orak `[通讯]`

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

提出了基于执行来源的强制访问控制（OAMAC），在内核层对进程的执行来源（物理用户、本地登录、远程访问、服务执行等）进行分类并在敏感系统接口上实施访问限制。

**💡 创新点**

将执行来源提升为第一类安全属性，补充传统身份、标签等访问控制维度，实现对不同来源的统一治理，从而在不增加复杂标签策略的情况下显著降低后渗透攻击面。

**🔧 技术方法**

利用Linux eBPF LSM框架实现，无需内核补丁；通过内核可见的终端关联、进程祖先等信息对执行来源进行推断，并在文件系统和BPF控制平面等关键点实施基于来源的策略；使用内核驻留的eBPF map存储策略并支持运行时动态重配置。

**📊 数据集**

论文未使用公开数据集，而是基于在Ubuntu虚拟机上构建的实验环境，模拟物理、远程（SSH）和服务进程三种来源，验证策略正确性、无缝集成和性能。

**📈 对比分析**

与传统MAC（如SELinux/AppArmor）对比，OAMAC通过来源判断实现更细粒度、低复杂度的安全约束；实验显示在执行来源分类、策略执行上无显著性能损失，且对本地管理和系统服务无干扰。

**⚠️ 局限性**

局限性包括：只能识别有限的来源类别，无法解决内核级别攻击；依赖内核可见的终端和进程信息，可能被伪造；对早期启动进程的来源不支持精细控制；仅限Linux且需eBPF LSM支持，未考虑跨主机传播来源或更细粒度的硬件信任。

---

## 878. A Security Framework for Chemical Functions

**arXiv ID:** 2601.14019 | [PDF](https://arxiv.org/pdf/2601.14019v1)

**作者:** Frederik Walter `[一作]` (Technical University of Munich), Zohar Yakhini `[通讯]` (Reichmann University)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `e15e3743-5ee0-4d5f-813d-d146868082fc` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了一种统一的化学函数（Chemical Functions, CF）框架，将化学系统建模为噪声挑战–响应原语，并对其鲁棒性、不可克隆性和不可预测性等安全属性进行形式化定义与分析；

**💡 创新点**

创新点在于将物理不可克隆函数（PUF）概念推广到化学领域，构建完整的安全游戏与数学模型，提供了有限域与渐进两种分析视角，并实现了对 DNA‑基础构造的定量安全评估；

**🔧 技术方法**

采用的技术包括：离散数学与概率论模型（如二项分布、MinHash、Reed–Solomon 纠错编码）、模糊提取器（fuzzy extractor）、统计推断与最大似然决策、以及基于实验测序数据的噪声建模；

**📊 数据集**

使用的数据集主要是两种 DNA‑基础构造：可操作随机 DNA（operable random DNA, ORDNA）和基因组序列加密（Genomic Sequence Encryption, GSE）的实验测序读数；

**📈 对比分析**

通过对比理论极限与实验测得的误码率，论文展示了在不同参数设置下的鲁棒性（如 ρ_avg 近 1）、不可克隆性（可达 10⁻²⁸⁰ 级别）以及不可预测性（σ 约 10⁻⁷⁸ 至 10⁻⁵⁰），表明在合理的实验条件下 CF 具备可接受的安全性能；

**⚠️ 局限性**

限制包括：对噪声模型（独立同分布、均匀性）的简化假设、对化学放大攻击的覆盖不足、实验样本量有限、以及对不同实验室条件下的泛化性尚未充分验证。

---

## 879. Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models

**arXiv ID:** 2601.14004 | [PDF](https://arxiv.org/pdf/2601.14004v1)

**作者:** Hengyuan Zhang `[一作]` (University of Hong Kong), Ngai Wong `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

提出了“Locate‑Steer‑Improve”三阶段可操作机制解释性（MI）框架，并对超过200篇相关论文进行系统整理与归类，给出了核心可解释对象、定位与操控方法及其在对齐、能力与效率提升中的具体应用；

**💡 创新点**

将MI从单纯的观测科学转变为可执行的干预工具，构建了完整的定位‑操控流程、方法体系和应用范例，并公开维护持续更新的论文索引；

**🔧 技术方法**

采用Transformer内核的可解释对象定义（Token embedding、Residual stream、MHA、FFN、SAE）和多种定位技术（Magnitude、Causal Attribution、Gradient Detection、Probing、Vocabulary Projection、Circuit Discovery）以及操控技术（Amplitude Manipulation、Targeted Optimization、Vector Arithmetic）；

**📊 数据集**

主要使用公开的LLM预训练与评估数据集（如GPT‑2、LLaMA、Vicuna、ChatGPT等）以及各类任务数据（对齐、推理、多语言、偏见等），并未单独设计新的数据集；

**📈 对比分析**

通过示例性实验与文献综述表明，应用该框架可显著提升模型的安全性、偏见缓解、人物角色控制、推理能力和推理效率；在对齐任务中，针对性蒸馏/调参可在保持性能的同时减少错误输出；在效率任务中，参数剪枝与向量干预可减少计算量10‑30%且几乎不损失准确率；

**⚠️ 局限性**

局限性包括：定位结果高度依赖数据与任务设定，易受polysemantic与高维噪声影响；操控手段对多模态或Encoder‑Decoder结构的通用性有限；计算成本在大模型上仍然显著，尤其是全量因果归因与电路发现；最终性能提升往往与具体实现细节和训练数据质量密切相关。

---

## 880. Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior

**arXiv ID:** 2601.14000 | [PDF](https://arxiv.org/pdf/2601.14000v1)

**作者:** Junwoo Chang `[一作]` (Yonsei University), Jongeun Choi `[通讯]` (University of California)

**通讯引用:** 3504 | [OpenAlex ID](https://openalex.org/A5028749019)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

在无监督技能发现中提出一种利用群对称性的框架，约束Wasserstein依赖度量为群不变，并通过Group Fourier空间对奖励与策略进行参数化，学习到可在旋转或翻转等对称变换下复用的技能。

**💡 创新点**

①理论证明：在群对称环境下，Wasserstein依赖度量的全局最优解可取等变策略和群不变评分函数；②引入Group-Invariant Wasserstein依赖度量，显式限制搜索空间；③在Fourier域构造可解释且对称的评分函数，从而得到可在对称变换下系统重用的技能。

**🔧 技术方法**

群表示理论（Peter–Weyl 定理、Haar 平均）、Group Fourier 变换、1‑Lipschitz 约束、Equivariant SAC、METRA 的对偶WDM优化、时间距离 d_T 作为度量。

**📊 数据集**

MuJoCo Ant（state‑based）和 DeepMind Control Suite 的 quadruped（pixel‑based）两种基准环境。

**📈 对比分析**

与 METRA 基线对比。实验显示 GISD 在状态空间覆盖率、样本效率和下游目标到达回报方面均优于 METRA；在 Ant 与 Quadruped 上的覆盖率更广、学习更快、最终回报更高。

**⚠️ 局限性**

需预先指定对称群，若对称性未知或不完整会影响效果；等变网络带来额外计算开销；在更复杂或不完全对称的任务（如 Humanoid）中的鲁棒性与可扩展性尚待进一步验证。

---

## 881. "The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework

**arXiv ID:** 2601.13992 | [PDF](https://arxiv.org/pdf/2601.13992v1)

**作者:** Jin Cui `[一作]` (Xi'an Jiaotong University), Pengju Ren `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 1563 | [OpenAlex ID](https://openalex.org/A5044243518)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `8d10c613-917e-4880-9716-17789f50e119` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了多教师链式思维蒸馏框架 COMPACT，动态融合教师梯度，提升小模型推理能力并抑制灾难性遗忘。

**💡 创新点**

创新点包括：多维兼容性评估（图谱共识、互信息适应、难度惩罚）实现动态权重分配；在梯度层级使用任务算术动态融合；保持原始知识结构，防止梯度冲突导致的知识迁移问题。

**🔧 技术方法**

使用技术：任务算术（Task Arithmetic）梯度融合、互信息指标、图谱共识注意力机制、难度惩罚（Perplexity）、LoRA 微调、因果语言模型损失与一致性约束。

**📊 数据集**

使用数据集：In‑Distribution（MATH500、GSM8K、SVAMP）与 Out‑of‑Distribution（CSQA、StrategyQA、GPQA‑Diamond）。

**📈 对比分析**

方法对比：与单教师蒸馏(SBS)、多路径蒸馏(MCC)、误差驱动(EDIT)、MoT、Committee 等基线对比；在 ID 任务上平均提升 4–9% 以上，OOV 任务保持或提升，并显著降低表示漂移和灾难性遗忘。

**⚠️ 局限性**

limitations: 需要较多教师模型与计算资源；动态权重计算带来额外计算开销；对教师分布极端差异的鲁棒性仍有限；在长序列或跨模态推理场景下的适用性尚未充分验证。

---

## 882. VirtualCrime: Evaluating Criminal Potential of Large Language Models via Sandbox Simulation

**arXiv ID:** 2601.13981 | [PDF](https://arxiv.org/pdf/2601.13981v1)

**作者:** Yilin Tang `[一作]` (Shanghai Qi Zhi Institute), Tianxing He `[通讯]` (Institute for Interdisciplinary Information Sciences)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了VirtualCrime沙盒框架，用三代理系统评估LLM的犯罪能力。

**💡 创新点**

提出基于多代理的模拟环境和40个多类型犯罪任务，系统评估LLM在规划与执行犯罪行为时的表现。

**🔧 技术方法**

使用LLM作为攻击者、评判者和世界管理者，采用JSON状态序列、分布式评估和多维度能力打分。

**📊 数据集**

设计了11张地图和13类犯罪目标，形成40个任务作为实验数据集。

**📈 对比分析**

对8大主流LLM与人类基线进行Pass@3、总体成功率等指标评估，部分模型成功率高达95%但仍有安全风险。

**⚠️ 局限性**

局限在文本模拟缺乏物理真实性，无法完全模拟真实环境；并未覆盖所有技术攻击手段。

---

## 883. The Transparency Paradox in Explainable AI: A Theory of Autonomy Depletion Through Cognitive Load

**arXiv ID:** 2601.13973 | [PDF](https://arxiv.org/pdf/2601.13973v1)

**作者:** Ancuta Margondai `[一作]` (University of Central Florida), Mustapha Mouloua `[通讯]` (University of Central Florida)

**通讯引用:** 3603 | [OpenAlex ID](https://openalex.org/A5068877766)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `de8d30ba-c289-43a5-b4ec-7b80df73aea2`

**🎯 论文内容**

构建了一个基于随机控制理论的透明度框架，用来解释并预测 AI 解释在不同认知状态下提升或削弱决策质量的机制。

**💡 创新点**

创新点在于将自主感视为连续随机过程，利用几何布朗运动与漂移函数刻画信息诱发的认知负荷，并通过 Hamilton–Jacobi–Bellman 方程推导出阈值型最优透明度策略，首次将动态认知资源耗竭与解释质量统一起来。

**🔧 技术方法**

采用随机微分方程、几何布朗运动、HJB 最优控制、蒙特卡罗仿真等技术进行理论推导与数值验证。

**📊 数据集**

未使用真实数据集，而是通过 5,000 条独立随机路径的仿真数据验证模型预测，并在不同信息水平与工作记忆水平下进行参数化测试。

**📈 对比分析**

与极大透明度（持续提供解释）和极小透明度（完全不提供解释）两种极端策略对比，仿真显示最优动态透明度策略在保持自主感、减少退出率的同时，决策质量最高，表现优于其他策略。

**⚠️ 局限性**

局限包括：假设自治感遵循几何布朗运动、单一维度的自治、连续时间模型、缺乏实证数据验证，以及对个体差异、信任等其他心理机制的简化处理。

---

## 884. Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval

**arXiv ID:** 2601.13969 | [PDF](https://arxiv.org/pdf/2601.13969v1)

**作者:** Joaquín Polonuer `[一作]`, Marinka Zitnik `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一个无训练、可让语言模型在知识图谱检索中灵活切换全局文本搜索与邻域多跳遍历的代理式检索框架。

**💡 创新点**

通过仅两种工具（全局词法检索与一跳邻域探索）实现宽度与深度的自适应平衡，无需种子选择、预设跳数或训练；并将教师代理的使用轨迹无标签蒸馏到小模型。

**🔧 技术方法**

基于LLM代理交互，工具调用（Search_G 与 Neighbors），基于BM25的文本相似度，投票聚合的多代理并行策略，以及标签无监督的轨迹蒸馏（teacher–student LoRA）。

**📊 数据集**

STaRK 三大图谱：AMAZON、MAG、PRIME。

**📈 对比分析**

与BM25、dense检索、KAR、mFAR、MoR、AvaTaR、GraphFlow、Think-on-Graph等基线比较，Hit@1、Hit@5、Recall@20、MRR 上整体获得最高平均分；在 MAG、AMAZON、PRIME 分别提升约 30–31% Hit@1、28% MRR；蒸馏后 Qwen3‑8B 在三图谱均保持近 90% 教师性能。

**⚠️ 局限性**

推理延迟较高、依赖大型 LLM、全局检索受词法匹配限制，文本稀疏或模板化时效果下降；仅适用于文本丰富的图谱；代理式检索若未加安全审计，可能泄露敏感信息。

---

## 885. DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging

**arXiv ID:** 2601.13954 | [PDF](https://arxiv.org/pdf/2601.13954v1)

**作者:** Adrien Meyer `[一作]` (University of Strasbourg), Nicolas Padoy `[通讯]` (University Hospital of Strasbourg)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `e15e3743-5ee0-4d5f-813d-d146868082fc` `7b0f05dc-d396-4b03-96d2-a379dbd5049d`

**🎯 论文内容**

本文提出一种名为 DExTeR 的基于 DETR 的弱半监督目标检测框架，用单点标注实现医疗影像中的目标定位。

**💡 创新点**

创新点包括类引导的多尺度可变形注意、Class-Instance-Common Knowledge Mixture of Experts (CLICK‑MoE) 以及多点训练策略。

**🔧 技术方法**

主要技术包括 Transformer、DETR、Deformable Attention、Mixture of Experts、点到框回归。

**📊 数据集**

使用 Endoscapes、VinDr‑CXR 与 EUS‑D130 三个医学影像数据集进行验证。

**📈 对比分析**

与 Group‑RCNN、PBC、Point‑DETR 等基线相比，DExTeR 在 12.5%/50% 盒标注比例下的 mAP 提升 3–8 分，且学生检测器可达到近乎完全监督水平。

**⚠️ 局限性**

局限性在于对类标签依赖较强、对极端重叠或形状多变的结构仍有误检，且多点训练需额外计算开销。

---

## 886. Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model

**arXiv ID:** 2601.14052 | [PDF](https://arxiv.org/pdf/2601.14052v1)

**作者:** Haoran Xu `[一作]` (Zhejiang University), Changwei Wang `[通讯]` (Qilu University of Technology)

**通讯引用:** 2922 | [OpenAlex ID](https://openalex.org/A5020628396)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种基于多模态大语言模型（MLLM）的零样本 OOD 检测框架 MM‑OOD，利用多轮对话和图文推理生成多样化的异常样本来提升识别性能。

**💡 创新点**

创新点在于：①针对近 OOD 与远 OOD 采用不同策略，②使用 sketch‑generate‑elaborate 框架将文本提示转化为视觉样本并迭代优化，③利用 MLLM 的多轮对话与链式推理显著扩大异常样本的多样性。

**🔧 技术方法**

核心技术包括 CLIP、LLaVA/Qwen2‑VL 等多模态 LLM、GPT‑4 文本生成、Stable Diffusion 图像合成、基于文本与图像编码的分数计算，以及多轮对话的链式思维（CoT）流程。

**📊 数据集**

实验使用 ImageNet‑10/20（近 OOD）、Food‑101、Oxford‑IIIT Pets、Stanford Cars、CUB‑200‑2011、ImageNet‑1K（远 OOD）为 ID 数据集，OOD 数据集包括 Texture、Places、iNaturalist、SUN 等。

**📈 对比分析**

与 MCM、MaxLogit、Energy、EOE 等基线对比，MM‑OOD 在近 OOD 任务中 FPR95 下降至 3.84%（相较 EOE 提升 3.17pp），在远 OOD 任务中 AUROC 最高 99.56%，FPR95 仅 4.33%，在 ImageNet‑1K 上对比 EOE 亦保持持续优势，表现出显著的性能提升。

**⚠️ 局限性**

局限性包括：①需要依赖大型预训练 MLLM 与生成模型，部署成本高；②对测试时是否为近/远 OOD 仍需人工或比例混合处理；③在极大样本规模或极远 OOD 场景下，异常样本的多样性仍可能不足，导致性能波动。

---

## 887. Collective intelligence in science: direct elicitation of diverse information from experts with unknown information structure

**arXiv ID:** 2601.14047 | [PDF](https://arxiv.org/pdf/2601.14047v1)

**作者:** Alexey V. Osipov `[一作]` (Swiss Re Institute), Nikolay N. Osipov `[通讯]` (St. Petersburg State University)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355`

**🎯 论文内容**

提出一种基于自决游戏币预测市场与公开聊天相结合的机制，鼓励专家在讨论中直接共享私人信息，并通过市场价格推断科学假设的概率。

**💡 创新点**

创新点在于将自决预测市场与实时信息共享绑定，使得即使缺乏真实结果也能通过市场价格和聊天证据实现信息聚合与奖励分配，同时保证结果可解释性。

**🔧 技术方法**

采用自决预测市场（Bernoulli 生成器）、游戏币交易、公开聊天、贝叶斯推断（隐式）以及信息结构假设的形式化模型。

**📊 数据集**

论文主要是理论推导与形式化，没有使用特定实验数据集；所讨论的实例为假设性实验设计。

**📈 对比分析**

未做实验对比，论文通过理论证明展示在满足一系列假设下系统能实现信息聚合、价格与真值一致；性能指标以概率一致性与信息公开度等概念性指标为主。

**⚠️ 局限性**

限制在于需要专家对信息结构与市场机制有共同的（或近似）信念，假设专家行为为风险中性且信息可被完全验证，且模型对异常攻击与合作策略的鲁棒性仅给出启发式论证。

---

## 888. Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology

**arXiv ID:** 2601.14044 | [PDF](https://arxiv.org/pdf/2601.14044v1)

**作者:** Kaiyu Wu `[一作]` (Sun Yat-sen University), Keze Wang `[通讯]` (Sun Yat-sen University)

**通讯引用:** 2250 | [OpenAlex ID](https://openalex.org/A5088124671)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了专门用于气象多模态推理的Benchmark WeatherQA，并提出了逻辑一致性强化微调（LoCo‑RFT）方法，训练得到逻辑一致的VLM Weather‑R1。

**💡 创新点**

创新点包括：①首次识别并解决RFT中的自相矛盾推理（Self‑Contra）问题；②引入逻辑一致性奖励，使模型在保持答案正确的同时保证推理过程的逻辑连贯；③提供高质量气象领域多模态数据集 WeatherQA，填补了该领域的评测空白。

**🔧 技术方法**

使用技术：基于Qwen2.5‑VL‑7B的全参数LoCo‑RFT训练，采用GRPO算法；逻辑一致性奖励由GPT‑oss‑20b评判器提供；同时对推理过程与答案格式进行规范化奖励。

**📊 数据集**

使用数据集：WeatherQA（约15,400条气象图像+文本推理样本，涵盖七种图像模态和四大主题）和ScienceQA（用于评估OOV泛化能力）。

**📈 对比分析**

与基线（Qwen2.5‑VL‑7B、SFT‑7B、RFT‑7B）对比，Weather‑R1在WeatherQA测试集上整体准确率达52.9%，比基线提升9.8个百分点；在ScienceQA上准确率提升4.98个百分点（86.46% vs 81.48%），显示出更强的跨任务泛化。模型在各模态任务中的表现均优于或不低于SFT/RFT。

**⚠️ 局限性**

局限性：仍需依赖评判器来计算逻辑一致性奖励，模型在某些推理类型（Type‑1/2/3）中自相矛盾比例虽降低但未消除；仅针对单选推理，未扩展到开放式生成任务；训练成本和计算资源仍相对较高。

---

## 889. Federated Balanced Learning

**arXiv ID:** 2601.14042 | [PDF](https://arxiv.org/pdf/2601.14042v1)

**作者:** Jiaze Li `[一作]` (Xiaomi Inc), Lumin Xing `[通讯]` (Shandong First Medical University)

**通讯引用:** 169 | [OpenAlex ID](https://openalex.org/A5024257256)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 Federated Balanced Learning (FBL)，通过在边缘端使用生成模型进行知识填充与抽样，以在客户端实现样本平衡，并在此基础上设计知识对齐与知识丢弃策略，进一步提升联邦学习在非 IID 场景下的性能。

**💡 创新点**

创新点包括：① 从客户端角度重新定义非 IID 处理方式，先做样本平衡；② 引入知识对齐嵌入和知识丢弃两种机制，弥合生成数据与真实数据的域差；③ 提供计算受限与不受限两种客户端自决的统一框架；④ 结合基于损失的知识抽样与周期性知识重放，兼顾样本多样性与避免灾难性遗忘；⑤ 可扩展到多模态、NLP 等任务。

**🔧 技术方法**

使用技术：联邦学习框架、Stable Diffusion（4‑bit）边缘生成模型、知识对齐嵌入、知识丢弃、基于损失的抽样、知识重放、FedAvg 等联邦优化器、ResNet‑18 作为网络骨干。

**📊 数据集**

实验数据集：CIFAR‑10、CIFAR‑100、Tiny ImageNet、EuroSAT，采用不同 Dirichlet 参数模拟非 IID 分布，亦评估极端受限客户端与噪声鲁棒性。

**📈 对比分析**

与 FedAvg、FedProx、SCAFFOLD、MOON、FedGen、FedNTD、FedDyn、FedCDA 等基线对比，FBL 在大多数非 IID 条件下均获得最高准确率；在计算资源不受限比例提升时，性能进一步提升，说明框架可适应真实复杂场景。

**⚠️ 局限性**

局限性：依赖生成模型质量，在极端域（如卫星影像）生成效果不佳导致提升有限；极度受限设备无法使用生成模型，需退回 FedAvg；未对多模态任务进行充分验证，需进一步扩展和验证。

---

## 890. Human detectors are surprisingly powerful reward models

**arXiv ID:** 2601.14037 | [PDF](https://arxiv.org/pdf/2601.14037v1)

**作者:** Kumar Ashutosh `[一作]` (University of Texas at Austin), Rohit Girdhar `[通讯]` (Meta AI)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种简单的零样本奖励模型，用于量化视频生成中的人类外观和动作质量，并用该模型对视频扩散模型进行后训练，以提升复杂人类动作的生成质量。

**💡 创新点**

创新点在于将人类检测置信度和文本提示的时间对齐相结合，形成一个无需训练的线性奖励函数，同时在强化学习后训练中使用GRPO实现对视频质量的显著提升。

**🔧 技术方法**

采用ViTDet进行人类检测、BLIP进行视觉-文本相似度计算、Llama-3.2 8B生成动作阶段描述，并使用GRPO进行视频扩散模型的后训练。

**📊 数据集**

数据集方面使用了3000条由Llama-3.2生成的人类动作标签，拆分为易、中、难三类，并从Wan 2.1生成的600对视频进行评估；还用Llama-3.2生成动物动作提示进行跨域测试。

**📈 对比分析**

与VLM-as-a-judge、VBench-2.0、人类异常检测器和DanceGRPO等基线相比，该奖励模型在人工偏好评测中达到约22–3%的准确率提升；后训练后的Wan 2.1在硬动作上的win‑rate达73%，整体显著优于所有基线。

**⚠️ 局限性**

局限性包括对检测器性能的依赖，可能在检测不到的人体部位或极端姿态下失效；模型仍主要针对人类动作，对完全不同物体或极端物理场景的泛化受限。

---

## 891. PAC-Private Responses with Adversarial Composition

**arXiv ID:** 2601.14033 | [PDF](https://arxiv.org/pdf/2601.14033v1)

**作者:** Xiaochen Zhu `[一作]` (Massachusetts Institute of Technology), Srinivas Devadas `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 33516 | [OpenAlex ID](https://openalex.org/A5000525449)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `8d10c613-917e-4880-9716-17789f50e119` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `90291a0e-9d36-4a08-9a16-89ce846d923f` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

针对机器学习模型的API输出进行PAC隐私保护，提出自适应噪声校准算法实现对抗性可线性组合。

**💡 创新点**

在PAC隐私框架下首次解决对抗性适应性查询的线性组合，利用后验感知噪声调节，保持实例稳定性优势。

**🔧 技术方法**

PAC隐私理论、互信息上界、后验更新、Gaussian噪声校准、模型蒸馏与置信过滤、实验评估。

**📊 数据集**

CIFAR‑10/100、Census Income、Bank Marketing、IMDb、AG News、CINIC‑ImageNet等。

**📈 对比分析**

与DP‑SGD、PATE等对比，在相同隐私预算下取得更高准确率；在每步MI预算2⁻³²下CIFAR‑10可支持超过4.7亿次查询，MIA成功率≤51.1%；蒸馏学生模型在90%以上准确率并保持≤50.5% MIA成功率。

**⚠️ 局限性**

需要可计算的秘密空间、对抗性查询仍假设已知策略；计算成本主要在离线训练多模型；在非稳定任务或高维输出时噪声可能增大；仅在API级别保护，无法直接发布模型权重。

---

## 892. BallotRank: A Condorcet Completion Method for Graphs

**arXiv ID:** 2601.14015 | [PDF](https://arxiv.org/pdf/2601.14015v1)

**作者:** Ismar Volic `[一作]`, Jason Douglas Todd `[通讯]` (Duke Kunshan University)

**通讯引用:** 28 | [OpenAlex ID](https://openalex.org/A5040866885)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了一种基于改进的 PageRank 并加入自环的 BallotRank 投票方法，用以在有 Condorcet 赢家时仍能给出完整排名；

**💡 创新点**

创新点在于：①使用对手胜负的边缘差值来构建有向加权图；②在图中加入按获胜总边缘加权的自环，使得在 Condorcet 循环内部能够区分候选人；③通过调节阻尼参数 d 在保证 Condorcet 一致性的同时可产生完整排序；

**🔧 技术方法**

核心技术为图论与谱方法：构造邻接矩阵 M、归一化为列随机矩阵 ℓ，随后用随机行走/幂迭代求解平稳分布得到 BallotRank；

**📊 数据集**

实验使用四大数据集：约 22,309 条 CIVS 在线民意调查、538 选举（美国地方/州/联邦） 、1,070 条苏格兰地方议会选举以及 328 条澳大利亚选举；

**📈 对比分析**

与 minimax、ranked pairs、Schulze 以及 convergence voting 进行比较；在包含 Condorcet 赢家的 5,000+ 选举中 BallotRank 一直能正确识别赢家；在没有 Condorcet 赢家的选举中，它与传统方法有时给出不同赢家，且能提供完整排名；整体表现稳定、计算成本与 PageRank 相当；

**⚠️ 局限性**

局限性包括：①在 d<1 时并不保证每次都能识别 Condorcet 赢家；②对 IIA、单调性、后果不害、弃票和克隆等经典社会选择准则失效；③在某些选举中对阻尼参数极度敏感，d 值变化会导致赢家突变；

---

## 893. A universal linearized subspace refinement framework for neural networks

**arXiv ID:** 2601.13989 | [PDF](https://arxiv.org/pdf/2601.13989v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 894. MANATEE: A DevOps Platform for xApp Lifecycle Management and Testing in Open RAN

**arXiv ID:** 2601.14009 | [PDF](https://arxiv.org/pdf/2601.14009v1)

**作者:** Sofia Montebugnoli `[一作]` (University of Bologna), Tommaso Melodia `[通讯]` (Northeastern University)

**通讯引用:** 19241 | [OpenAlex ID](https://openalex.org/A5054337759)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2`

**🎯 论文内容**

提出了 MANATEE 平台，集成 CI/CD 流水线与 Service Mesh，实现 xApp 在 Open RAN 环境中的完整生命周期管理。

**💡 创新点**

创新点在于将 Service Mesh 的流量控制、A/B 测试与熔断机制与 DevOps 流程结合，支持跨模拟、仿真与真实环境的无缝迁移与渐进式发布。

**🔧 技术方法**

使用 Kubernetes/K3s、Istio（含 Ambient）、Cilium、Helm、Ansible、oransc、e2-simulator、ORANInABox 与真实 OAI+USRP SDR 等技术栈。

**📊 数据集**

实验基于自建的模拟 E2 节点、ORANInABox 的 gNB/UE 仿真以及真实 OAI gNB+USRP 产生的 E2 信令与测量数据，未采用公开数据集。

**📈 对比分析**

对比四种 Mesh 方案（Istio 传统、Istio Ambient、Cilium、无 Mesh）在突发与增量流量下的延迟，Cilium 最优；在 CI/CD 操作中，Mesh 只增加约 10% 创建/删除延迟；Canary 部署在 600 msg/s 负载下无错误，A/B 测试通过熔断实现控制冲突消除。

**⚠️ 局限性**

局限包括 rmr 通讯脆弱导致的错误、Service Mesh 只能在 Layer4 处理 E2 流量、xApp 生态仍不成熟、迁移过程仍需人工审批、实验场景主要是单 gNB，未覆盖多 gNB 与切片并行情况。

---

## 895. From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning

**arXiv ID:** 2601.13995 | [PDF](https://arxiv.org/pdf/2601.13995v1)

**作者:** Zihan Niu `[一作]` (University of Science and Technology of China), Ruiming Tang `[通讯]` (Kuaishou Technology)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一种Tree-aware Aligned Global Sampling（TAGS）框架，通过构建细粒度标签树来实现对大型语言模型指令调优数据的高效、可控采样。

**💡 创新点**

创新点在于：①利用LLM驱动的Act‑Critic链式标注得到细粒度知识标签；②通过递归聚类构建全局标签树，捕捉知识的层级关系；③设计树传播信息模型和KL对齐采样策略，实现全局质量、多样性与目标域的联合优化。

**🔧 技术方法**

主要技术包括：LLM自监督标注（Act‑Critic）、多层次层次聚类、树传播矩阵、信息增益启发式贪婪采样、KL散度对齐正则化。

**📊 数据集**

使用的主要数据集为公开指令数据集Tulu3（约939k条）以及自建的53k条细粒度标签训练集；在实验中采用Qwen3系列（1.7B、4B、8B）模型进行指令调优，并在ARC、BBH、MMLU、IFEval、GSM8k、AlpacaEval、MTBench、WildBench等基准上评估。

**📈 对比分析**

与随机、IFD、#InsTag、DEITA、CaR、QDIT、MIG等现有采样基线相比，TAGS在所有模型规模下均获得最高分，特别是仅使用5%数据即可超越全量训练模型+5.84%，在知识与人类偏好指标上分别提升约+2–5%。

**⚠️ 局限性**

局限性包括：标签器仅在约53k条样本上微调，缺乏对大规模标签生成的可扩展性评估；实验仅覆盖Qwen3系列与SFT任务，未验证在更大模型或强化学习场景下的表现。

---

## 896. Capacity and Energy Trade-Offs in FR3 6G Networks Using Real Deployment Data

**arXiv ID:** 2601.13993 | [PDF](https://arxiv.org/pdf/2601.13993v1)

**作者:** David López-Pérez `[一作]` (Universitat Politècnica de València), Matteo Bernabè `[通讯]` (Universitat Politècnica de València)

**通讯引用:** 17 | [OpenAlex ID](https://openalex.org/A5083239567)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

基于真实运营网络（4G/5G）部署与流量数据，构建了异构多层6G系统级模型，评估FR3频段下不同部署策略（共址、非共址、热点）对吞吐量与能耗的影响。

**💡 创新点**

①首次将真实运营商部署与流量统计直接嵌入异构网络仿真；②利用AI驱动的调度与功耗预测实现动态、数据驱动的性能评估；③揭示非共址热点聚焦部署能在维持能耗增幅可控的前提下，显著提升吞吐量。

**🔧 技术方法**

采用3GPP UMa/UMi 路径损耗模型、2D‑DFT 波束码本与CSI‑RS 精细波束调优、基于人工神经网络的功耗预测、混合专家/3GPP/AI 的系统级仿真器。

**📊 数据集**

来自中国城市运营商的4G LTE 与5G NR 的实际基站位置、频谱、带宽、TRX、发射功率及每小时 UE 计数与流量负载数据；在此基础上合成6G层的部署与参数。

**📈 对比分析**

通过仿真比较五种部署方案（仅4G、4G+5G、共址6G、非共址6G微小区、低功耗6G热点），使用平均 UE 吞吐量、5% 分位、95% 分位以及总功耗作为指标；结果显示非共址热点6G方案平均吞吐量提升约9.5×，总功耗仅增加约59%。

**⚠️ 局限性**

依赖单一城市的部署与流量样本；6G 技术参数与功耗均为保守估计；未充分考虑成本、干扰、法规兼容性及长期运营成本；AI 模型的泛化性和实际部署可行性仍需进一步验证。

---

## 897. STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames

**arXiv ID:** 2601.13974 | [PDF](https://arxiv.org/pdf/2601.13974v1)

**作者:** Shih-Yao Lin `[一作]` `[通讯]` (Independent Researcher), Shih-Yao Lin (Independent Researcher)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了无参考、任务无关的 Spatio-Temporal Entropy Coverage (STEC) 指标，用来评估视频帧采样集合在空间信息、时间覆盖和冗余三方面的质量。

**💡 创新点**

创新点在于：①用熵量化每帧局部结构信息的 STFE；②将时间熵与跨度覆盖度相乘得到 T，确保既均匀又全局覆盖；③利用相邻帧 HSV 直方图余弦相似度构建非冗余度 R；④把三项乘积得到整体 STC 分数，避免单一指标偏向。

**🔧 技术方法**

主要技术包括：拉普拉斯算子 + 局部熵计算、时间归一化分箱 + Shannon 熵、HSV 直方图余弦相似度、矩阵乘积聚合。

**📊 数据集**

使用 MSR‑VTT test‑1k 公开数据集进行评估。

**📈 对比分析**

对 Random、Uniform、Katna、STACFP 四种采样方法进行对比；STEC 能清晰区分各策略，平均 STC 分别为 0.306、0.463、0.663、0.658；STACFP 在 481/1000 视频上获得最高 STC，显示更高的单视频鲁棒性；在检索任务中，STC 较高的方案往往保持或略优的 Recall@1，但并非直接预测下游性能。

**⚠️ 局限性**

局限性：①空间熵仅基于低级像素统计，忽略语义重要性；②对邻域大小、时间分箱等超参数敏感；③仅评估帧集合质量，无法直接说明对特定任务的提升；④在极低运动或高度重复的视频中表现尚未充分验证。

---

## 898. Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving

**arXiv ID:** 2601.14038 | [PDF](https://arxiv.org/pdf/2601.14038v1)

**作者:** Alexandre Justo Miro `[一作]` (Traton Group), Masoud Daneshtalab `[通讯]` (Mälardalen University)

**通讯引用:** 4176 | [OpenAlex ID](https://openalex.org/A5063193249)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

对多传感器车辆数据集中的3D框注释进行误差检测与校正。

**💡 创新点**

提出基于运动模型的注释校正框架、量化指标以及对错误对基准的影响评估。

**🔧 技术方法**

使用ctra运动模型、基于梯度无关的求解算法PS（pymoo）、点云投影与约束优化等技术。

**📊 数据集**

在Argoverse 2、MAN TruckScenes和自有数据集上进行实验。

**📈 对比分析**

与原始注释对比，IPD提升约17%~30%，错误分布减小，误差对基准指标的影响超过常见算法提升幅度。

**⚠️ 局限性**

优化耗时较长，未覆盖完整数据集，未处理框尺寸误差与三维运动问题。

---

## 899. Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models

**arXiv ID:** 2601.14152 | [PDF](https://arxiv.org/pdf/2601.14152v1)

**作者:** Hyunjong Ok `[一作]` (POSTECH), Jaeho Lee `[通讯]` (POSTECH)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了多选题答题（MCQA）中上下文、问题、选项顺序（CQO 与 QOC）对大型语言模型（LLM）性能的影响，并通过实验验证了因果注意力机制导致的性能差距。

**💡 创新点**

创新点在于将因果注意力遮蔽视为导致 QOC 低效的根本机制，系统性排除训练分布偏差和记忆衰减等假设，并通过架构对比、注意力分析以及定向干预验证这一结论。

**🔧 技术方法**

采用了注意力裁剪、激活补丁、选项重复等技术，对比不同模型架构（解码器、编码器-解码器、编码器）以及不同层级的隐藏状态进行干预与评估。

**📊 数据集**

使用了四个阅读推理基准数据集：LogiQA、RACE-H/M、SciQ，每个数据集均采用四选项多选题格式。

**📈 对比分析**

通过在 21 个解码器 LLM（从 0.5B 到 9B 参数）上测量 CQO 与 QOC 的准确率差异（Δ），发现解码器模型存在 10–25% 的性能缺口，而编码器或编码器-解码器模型缺口极小；对 CQO 进行注意力裁剪可将准确率降低 26.8%，对 QOC 进行激活补丁或选项重复可提升 6–8% 的准确率。

**⚠️ 局限性**

局限性包括：实验仅覆盖四选项的 MCQA 任务，未检验更大选项数或开放式 QA；模型规模上限为 9B 参数，未探讨更大规模模型的表现；结果主要针对因果解码器架构，可能不适用于全部 Transformer 变体。

---

## 900. GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression

**arXiv ID:** 2601.14130 | [PDF](https://arxiv.org/pdf/2601.14130v1)

**作者:** Till Aczel `[一作]` (ETH Zurich), Roger Wattenhofer `[通讯]` (ETH Zurich)

**通讯引用:** 21129 | [OpenAlex ID](https://openalex.org/A5078339613)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种基于可微分逻辑电路的灰度图像压缩方法GIC‑DLC，能够在保持高压缩比的同时显著降低能耗与延迟。

**💡 创新点**

创新点在于将神经网络的学习能力与硬件友好的布尔逻辑相结合，利用可微分逻辑电路训练查找表实现高效推理。

**🔧 技术方法**

技术包括多分辨率分层压缩、上采样模型(UPS)与自回归模型(ARM)的可微分逻辑实现、Laplace分布预测以及ANS熵编码。

**📊 数据集**

使用EMNIST（含数字、大小写字母）训练，并在EMNIST、KMNIST、Fashion‑MNIST等数据集上进行评估。

**📈 对比分析**

与传统压缩算法（PNG、WebP、JPEG‑XL）以及基于MLP的学习压缩方法对比，GIC‑DLC在EMNIST上比JPEG‑XL低约30%比特/像素，在能耗与延迟上比PNG提升约100倍和10倍。

**⚠️ 局限性**

局限性包括仅在灰度、结构相对简单的数据集上验证，且对RGB自然图像的表现及真实硬件部署效果仍需进一步研究。

---

## 901. Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic

**arXiv ID:** 2601.14124 | [PDF](https://arxiv.org/pdf/2601.14124v1)

**作者:** Saad Mankarious `[一作]` (George Washington University), Aya Zirikly `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `67630363-6be0-4f51-ab05-7198250671a5` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

利用无预训练的扩散模型对阿拉伯语精神健康文本进行男性到女性的风格转换，生成高熵、语义保真度高的女性作者合成文本，以缓解数据中的性别偏差。

**💡 创新点**

创新点在于：①提出将合成数据生成视作无预训练的风格迁移任务；②构造五个层次不同的性别表达数据集（D1–D5）；③在低资源精神健康领域中实现了高质量、多样化的合成文本生成，避免了大型预训练语言模型带来的偏见与多样性受限。

**🔧 技术方法**

主要技术：DiffuSeq扩散式文本生成框架、无预训练的扩散变换器、基于BERT的语义相似度评估、ROUGE、BLEU等指标评估模型生成效果。

**📊 数据集**

使用的数据集：CARMA阿拉伯语精神健康语料库（男性主导）以及基于GPT生成的五个对应女性风格的子数据集（D1–D5）。

**📈 对比分析**

比较方法：对五个模型分别计算BERTScore（0.93–0.95）、ROUGE‑1/2/L（≤0.07）和BLEU（1–57）。结果显示语义相似度保持高，表面层次（词汇、句式）差异显著，证明模型既保持内容一致，又实现了目标风格转换。

**⚠️ 局限性**

局限性：仅在阿拉伯语上验证，扩散模型训练成本高；数据集设计可能强化性别刻板印象；未验证对其他偏差（方言、社会阶层等）的迁移效果；低资源下训练样本有限，影响模型泛化。

---

## 902. PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning

**arXiv ID:** 2601.14111 | [PDF](https://arxiv.org/pdf/2601.14111v1)

**作者:** Jiaying Wu `[一作]` (Jiangsu Ocean University), Jingcai Guo `[通讯]` (Hong Kong Polytechnic University)

**通讯引用:** 447 | [OpenAlex ID](https://openalex.org/A5038505509)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种名为PMCE的少样本学习框架，通过多粒度语义（类名嵌入和BLIP生成的实例描述）来实现先验检索、MAP校准和双流特征增强。

**💡 创新点**

创新点在于将基类语义检索与MAP先验融合用于原型校正，并利用无标签实例级描述在支持端和查询端同时进行轻量级增强，实现严格增量式推理。

**🔧 技术方法**

使用CLIP文本编码、BLIP图像描述、MAP前验融合、跨注意力增强模块、轻量一致性正则化，并保持视觉骨干与VLM冻结。

**📊 数据集**

实验数据集包括MiniImageNet、TieredImageNet、CIFAR‑FS和FC100四个标准少样本基准。

**📈 对比分析**

与度量、分布、语义和VLM基线进行对比，尤其在1‑shot任务下，PMCE在ResNet‑12和Swin‑T上提升约7%–10%的准确率，整体持续领先。

**⚠️ 局限性**

局限性包括对语义描述质量敏感，低分辨率图像时caption信息不足；基类先验检索依赖类名相似度；仅在冻结骨干的情况下改进，缺乏自适应学习机制。

---

## 903. TLSQL: Table Learning Structured Query Language

**arXiv ID:** 2601.14109 | [PDF](https://arxiv.org/pdf/2601.14109v1)

**作者:** Feiyang Chen `[一作]` (Shanghai Jiao Tong University), Jianhua Li `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 6813 | [OpenAlex ID](https://openalex.org/A5100391361)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出 TLSQL，一个 SQL‑类声明式语言，用于在关系数据库上直接进行表学习，自动将声明翻译成标准 SQL 查询和任务描述，省去数据导出与手工特征工程。

**💡 创新点**

创新点在于把机器学习任务与数据库查询融合，设计了 PREDICT、TRAIN、VALIDATE 三种声明，构建轻量级解析器和 SQL 生成器，使非专家用户能在熟悉的 SQL 环境中完成完整的表学习工作流。

**🔧 技术方法**

技术实现包括基于 Python 的词法分析、递归下降解析器、AST 生成、SQL 代码合成，以及与现有关系型数据库引擎和表学习框架（如 BRIDGE）的对接。

**📊 数据集**

主要使用真实场景数据集 TML1M（包含三张关联表）进行实验，验证系统在实际数据库环境中的可行性。

**📈 对比分析**

与传统需要数据导出、手工预处理的表学习流程相比，TLSQL 在实现上更简洁、开发成本更低；实验表明能显著降低用户的学习与实现门槛，但未给出具体数值对比。

**⚠️ 局限性**

局限性包括目前仅支持关系型数据库，缺乏对大规模数据的性能评估；SQL 翻译过程可能引入额外开销；未来仍需结合 LLM 自动生成 TLSQL 语句以进一步提升易用性。

---

## 904. Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks

**arXiv ID:** 2601.14105 | [PDF](https://arxiv.org/pdf/2601.14105v1)

**作者:** Olesya Razuvayevskaya `[一作]` (University of Sheffield), Kalina Bontcheva `[通讯]` (University of Sheffield)

**通讯引用:** 10093 | [OpenAlex ID](https://openalex.org/A5021952588)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对大规模社区笔记(CNs)与专业事实核查文本进行对比，量化并分析两者使用的说服技巧与其受众评价的关系。

**💡 创新点**

首次系统评估社区驱动的事实核查是否比专业核查更具说服性，并揭示不同组织背景下修辞差异的机制。

**🔧 技术方法**

使用多语言Transformer说服技巧分类器（阈值0.8）、Spearman相关、Mann–Whitney U检验、Cliff's Δ、单侧z检验等统计方法。

**📊 数据集**

三大数据集：社区笔记（≈2.0M条）、EUvsDisinfo（8.5k条专业核查）和DBKF（≈0.68M条多语言专业核查）。

**📈 对比分析**

通过比较平均说服技巧数量和逐技巧出现比例的统计显著性（p<0.05）评估差异；结果显示CN与专业核查在总体说服性上无显著差异，但与EUvsDisinfo相比，CN在若干技巧上更频繁；与DBKF相比，CN整体更少使用多数技巧。

**⚠️ 局限性**

局限性包括文本截断到512令牌可能导致信息损失、说服技巧分类器在非英语语境下的准确性未知、以及受众评价受平台机制影响而非纯粹内容质量影响。

---

## 905. Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition

**arXiv ID:** 2601.14101 | [PDF](https://arxiv.org/pdf/2601.14101v1)

**作者:** Emily Kim `[一作]` (Carnegie Mellon University), Jessica Hodgins `[通讯]` (Carnegie Mellon University)

**通讯引用:** 19955 | [OpenAlex ID](https://openalex.org/A5011498939)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

研究基于课程学习的跨视角动作识别方法，利用合成航空视角和真实地面视角数据训练模型，并在未见的真实航空视角数据上评估效果。

**💡 创新点**

提出两种课程学习策略——两步微调（合成→真实）和多步渐进学习（逐步扩充合成数据再微调），在不使用真实航空数据的前提下实现与单纯数据拼接相同或更好泛化性能，同时显著提升训练效率。

**🔧 技术方法**

使用课程学习与渐进学习框架，结合 SlowFast 与 MViTv2 两种主流视频模型；通过迁移学习、学习率调度与迭代次数统计来衡量训练效率。

**📊 数据集**

采用 REMAG 数据集，包含同步的真实与合成航空、地面视角视频，覆盖 11 动作类别及空闲类别。

**📈 对比分析**

与基线（直接拼接两域数据）及两步微调方案对比，使用 Top‑1 准确率和训练迭代次数评估。实验表明：三种策略在 Top‑1 准确率上相近（误差 < 3%），而多步渐进学习可使迭代次数比基线低 20‑30%，两步微调比基线低 23‑37%。

**⚠️ 局限性**

局限性包括：仅评估两种模型；课程计划固定为三步，未探索自适应调度；假设训练与测试场景背景、光照一致，可能高估真实场景性能；REMAg 数据规模有限，合成图像缺乏足够真实感，导致域差距仍存在。

---

## 906. Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration

**arXiv ID:** 2601.14060 | [PDF](https://arxiv.org/pdf/2601.14060v1)

**作者:** Yongcong Ye `[一作]` (University of Science and Technology of China), Jun Zhou `[通讯]` (Zhejiang University)

**通讯引用:** 18029 | [OpenAlex ID](https://openalex.org/A5100781212)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了基于视觉-语义互补的细粒度零样本组合图像检索方法CVSI

**💡 创新点**

创新点在于同时从查询和目标图像提取视觉和语义信息，并通过LLM生成目标描述实现细粒度对象级检索

**🔧 技术方法**

采用CLIP做特征提取、BLIP-2生成密集描述、LLM生成修改后的文本与目标对象列表，以及伪词映射网络进行视觉编码

**📊 数据集**

在CIRR、CIRCO和FashionIQ三大公开数据集上进行实验

**📈 对比分析**

与多种基线（如LinCIR、SEARLE、LDRE）比较，CVSI在mAP、Recall等指标上均超越现有最优，尤其在CIRCO与CIRR上表现显著提升

**⚠️ 局限性**

局限性包括在单一领域（如FashionIQ）表现略逊、对LLM推理时间和算力依赖较高、域适配仍需进一步研究

---

## 907. LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery

**arXiv ID:** 2601.14154 | [PDF](https://arxiv.org/pdf/2601.14154v1)

**作者:** Shubham Pandey `[一作]` (University at Buffalo), Kenneth Seastedt `[通讯]` (Roswell Park Comprehensive Cancer Center)

**通讯引用:** 408 | [OpenAlex ID](https://openalex.org/A5045331119)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

提出并实现了 MIRACLE，一种融合临床特征、CT 放射组学和 LLM 生成可交互自然语言解释的多模态深度学习框架，用于肺癌手术后并发症风险预测。

**💡 创新点**

创新点包括：① 统一将结构化临床变量、放射组学特征和基于知识库的 LLM 解释在同一模型中融合；② 引入可交互的文本解释模块，让外科医生在推理过程中实时修改解释并即时更新风险估计；③ 采用贝叶斯 MLP 与超球面嵌入，提升小样本不平衡数据下的鲁棒性与不确定度估计；④ 在真实临床数据上与传统机器学习、单独 LLM 预测以及外科医生决策进行系统对比。

**🔧 技术方法**

使用技术包括：贝叶斯 MLP、超球面嵌入、focal loss、冻结的 Clinical Longformer 文本编码器、Llama 3.3 70B、DeepSeek R1 Distill Qwen‑32B、OpenBioLLM‑70B、TotalSegmentator + PyRadiomics 进行放射组学提取、特征融合权重、AUC、TPR@FPR 等评价指标。

**📊 数据集**

数据集为 POC‑L（Roswell Park Comprehensive Cancer Center 2009‑2023 共 3094 名肺癌手术患者），包含 17 项临床变量、113 项放射组学特征，二分类标签为是否出现 10 种术后并发症。

**📈 对比分析**

通过与 5 种传统机器学习模型、3 种单独 LLM 预测以及外科医生基线在同一测试集上对比，使用 AUC 与 TPR@FPR=0.2/0.3 评估。MIRACLE 的 AUC ≈81%，在 FPR=0.3 下 TPR≈81%，在 FPR=0.2 下 TPR≈71‑74%，显著优于传统基线（AUC≤74%，TPR≤60%）和外科医生（≈45%）。

**⚠️ 局限性**

局限性包括：单中心、以白人患者为主的样本缺乏外部多中心验证；CT 协议与重建参数可能导致迁移性能下降；LLM 生成的解释仍可能出现事实错误或偏差；未直接使用原始影像，依赖放射组学特征提取；缺乏前瞻性临床验证与监管合规性评估。

---

## 908. Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping

**arXiv ID:** 2601.14099 | [PDF](https://arxiv.org/pdf/2601.14099v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 909. Practitioner Views on Mobile App Accessibility: Practices and Challenges

**arXiv ID:** 2601.14131 | [PDF](https://arxiv.org/pdf/2601.14131v1)

**作者:** Amila Indika `[一作]` (University of Hawaii at Manoa), Anthony Peruma `[通讯]` (University of Hawaii at Manoa)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

对 110 名来自 43 个国家的跨平台移动应用开发者进行问卷调查，分析其对无障碍功能的认识、实施情况、测试实践以及遇到的技术、组织与生态障碍，探讨经验水平与平台差异对无障碍实践的影响。

**💡 创新点**

首次将 iOS 与 Android 开发者在全球范围内进行对比，提出多层级（技术、组织、生态）障碍分类，并引入“无障碍债务”概念，填补了以往单平台、地区局限的研究空白。

**🔧 技术方法**

采用 Qualtrics 在线问卷，结合定量统计（ANOVA、卡方检验）与定性主题分析（双人编码），实现对实践与观点的多维度描述。

**📊 数据集**

使用 110 名完整问卷样本（包括参与者背景、经验、无障碍知识、功能实现、测试方法、障碍与需求等信息），未使用外部公开数据集。

**📈 对比分析**

通过比较 iOS 与 Android 开发者以及经验层级，利用描述性统计和显著性检验揭示各组在指南熟悉度、功能实现、测试频率和工具使用上的差异，结果表明经验更高、平台特定经验更丰富的开发者在无障碍实践上更成熟。

**⚠️ 局限性**

存在自我选择偏差、地区分布不均、依赖自报数据、定性样本有限且未达到理论饱和、未验证代码层面的实际实现，可能导致结果对整体开发者群体的外推性受限。

---

## 910. SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media

**arXiv ID:** 2601.14128 | [PDF](https://arxiv.org/pdf/2601.14128v1)

**作者:** Shoujie Li `[一作]` (Nanyang Technological University), Wenbo Ding `[通讯]` (Tsinghua University)

**通讯引用:** 7709 | [OpenAlex ID](https://openalex.org/A5012419026)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

设计并实现了砂虫式旋转-蠕动机器人SandWorm及其主动振动事件式触觉感知器SWTac，实现高帧率像素级触觉成像并完成岩石分类、力估计等任务。

**💡 创新点**

创新点在于通过主动振动使事件相机实现静态触摸成像、IMU引导的时间滤波提升图像一致性、以及将旋转螺旋与蠕动结合的混合运动学。

**🔧 技术方法**

使用事件相机、惯性测量单元、PDMS弹性皮肤、U‑Net接触面估计、机器学习分类与力回归等技术。

**📊 数据集**

数据集主要为自制纹理板和实物触觉图像，约10,000张石材图像、3,000张经扩增的接触图像以及300张手动标注的接触面图像。

**📈 对比分析**

与传统光学触觉传感器对比，MSNR提升24%，纹理分辨率0.2 mm，力估计误差0.15 N，岩石分类准确率98%，机器人在管道与砂层中实现12.5 mm/s的运动速度和90%探测成功率。

**⚠️ 局限性**

局限在于颗粒粘附导致纹理检测受限、只能实现二维接触面恢复、对软粘性介质和高黏附土壤表现欠佳，且需要进一步的自清洗与三维重建。

---

## 911. A Systematic Analysis of Chunking Strategies for Reliable Question Answering

**arXiv ID:** 2601.14123 | [PDF](https://arxiv.org/pdf/2601.14123v1)

**作者:** Sofia Bennani `[一作]` (École polytechnique), Charles Moslonka `[通讯]` (Artefact Research Center)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了不同文档分块策略（Token、Sentence、Semantic、Code）、块大小、重叠比例以及上下文长度对工业级检索增强生成(RAG)系统可靠性和成本的影响。

**💡 创新点**

创新点在于系统化、端到端地评估分块参数对性能的影响，并给出可操作的部署准则，如“无重叠优先、句子分块匹配语义分块、避免2.5k以上上下文导致性能崩塌”。

**🔧 技术方法**

使用SPLADE稀疏检索索引、Mistral‑8B指令调优生成器，配合BERTScore、Exact Match和None Ratio指标进行评估。

**📊 数据集**

数据集为Natural Questions（Short Answer子集）上的English Wikipedia文本。

**📈 对比分析**

对比不同分块方法、尺寸、重叠和上下文预算，结果显示无重叠时成本下降；句子分块在500–2.5k上下文中与语义分块性能相当，Token分块明显落后；更大上下文（>2.5k）出现性能下降，EM在≈2.5k最佳，BERTScore在≈500最佳，None Ratio随上下文增大而下降。

**⚠️ 局限性**

仅评估第一阶段检索，未包含重排器或后交互模型，实验仅基于文本数据，代码分块在文本任务中表现差，结果需要在其他行业文档或重排技术场景中进一步验证。

---

## 912. Utilizing the Perceived Age to Maximize Freshness in Query-Based Update Systems

**arXiv ID:** 2601.14075 | [PDF](https://arxiv.org/pdf/2601.14075v1)

**作者:** Sahan Liyanaarachchi `[一作]` (University of Maryland), Nail Akar `[通讯]` (Bilkent University)

**通讯引用:** 1247 | [OpenAlex ID](https://openalex.org/A5080807022)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出在通用延迟分布下的查询式采样方法，利用等待策略最大化连续时间马尔可夫链（CTMC）的平均二进制新鲜度（MBF）。

**💡 创新点**

创新点在于：①放宽了查询延迟为指数分布、回复即时的假设；②在任意延迟分布下给出了最优等待策略的阈值结构；③通过半马尔可夫决策过程（SMDP）和Dinkelbach线性化等手段求解最优策略。

**🔧 技术方法**

技术方法包括：CTMC理论、马尔可夫链稳态分析、Dinkelbach方法、SMDP建模与策略迭代、阈值优化、Monte Carlo仿真验证。

**📊 数据集**

实验使用的是二元CTMC（状态1-2）以及离散延迟分布（如{0,d1}、{0.3,0.5,1}等），并通过不同α、β值模拟不同稳定性场景。

**📈 对比分析**

与零等待（ZW）和常量等待（CW）基线相比，提出的状态独立、延迟独立和最优等待策略在大部分延迟范围内显著提升MBF；在不同α,β、查询延迟设定下，最优策略的表现最优。

**⚠️ 局限性**

局限性：仅针对离散/有限状态CTMC，未考虑多源或高维状态；假设前向/后向延迟独立；阈值结构的推导依赖于p(t)单调性，可能不适用于所有估计器；对实际系统延迟分布的估计误差未讨论。

---

## 913. Verifying Floating-Point Programs in Stainless

**arXiv ID:** 2601.14059 | [PDF](https://arxiv.org/pdf/2601.14059v1)

**作者:** Andrea Gilot `[一作]` (Uppsala University), Eva Darulova `[通讯]` (Uppsala University)

**通讯引用:** 629 | [OpenAlex ID](https://openalex.org/A5053069388)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

在Scala程序中实现了浮点数的可证明性，支持多态、递归和高阶函数，并自动插入NaN检查与类型转换安全检查；

**💡 创新点**

首次将浮点数推理集成到Scala的可验证框架Stainless中，并在实现中验证数学库属性的正确性；

**🔧 技术方法**

利用SMT-LIB浮点理论、Bitwuzla后端、SMT求解器（Z3、CVC4、Z3Boolector）以及对Scala标准库的axiomatization和SSA转换；

**📊 数据集**

使用KeY、FdLibm以及从GitHub抓取的103个真实Scala浮点函数进行基准测试；

**📈 对比分析**

通过与KeY、Z3、CVC4等求解器的基准对比，证明Stainless在大多数案例（82%）能通过验证或给出反例，性能在多数情况下可接受，且在浮点专用求解器Bitwuzla上表现最好；

**⚠️ 局限性**

对三角、指数等超越函数的axiomatic约束仍可能产生伪反例，且在某些复杂循环/数组操作中求解器表现不佳，导致时间或内存瓶颈；

---

## 914. The Quest for Reliable AI Accelerators: Cross-Layer Evaluation and Design Optimization

**arXiv ID:** 2601.14148 | [PDF](https://arxiv.org/pdf/2601.14148v1)

**作者:** Meng Li `[一作]` (Institute for Artificial Intelligence), Runsheng Wang `[通讯]` (Institute for Artificial Intelligence)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一系列跨层可靠性评估与设计优化方案，包括基于老化与变异的动态时序分析（AVATAR）、关键输入模式削减技术（通道重排序与聚类）以及面向大语言模型的统计算法容错（Statistical ABFT）

**💡 创新点**

创新点在于：1）将器件级老化模型直接嵌入时序分析流程，消除多余的安全裕度；2）通过权重正负分布及输出通道聚类实现计算顺序重排，从而显著降低关键路径激活率；3）提出只在错误落入“关键区域”时才触发重算的统计容错机制，既保证可靠性又避免冗余恢复，极大降低功耗与面积开销

**🔧 技术方法**

使用的技术包括：器件级老化/变异建模、事件驱动动态时序分析、基于统计阈值的错误检测与重算、权重/通道重排算法（KNN聚类、曼哈顿距离判定）、TPU风格乘累加器的动态时序仿真、Systolic数组上的统计ABFT实现

**📊 数据集**

实验数据集涵盖常见CNN/MLP基准（ResNet‑18、VGG‑16、CNN、Convolution、MatrixMult等）以及LLM推理/预填充任务（WikiText‑2、HellaSwag、X‑Sum、GSM8K）

**📈 对比分析**

与传统角点DTA及Razor/ABFT等方法对比：AVATAR 在各基准上平均提升 13–65% 最大频率；关键输入模式重排在 ResNet‑18/VGG‑16 上平均降低 4.9–7.8 倍的时序错误率；统计ABFT 在 LLM 推理下，0.72 V/0.70 V 时可实现 23–24% 能耗下降，仅引入 1.4% 区域与 1.8% 功耗开销

**⚠️ 局限性**

局限性：① 方案依赖于可准确建模的老化/变异分布，复杂工艺变化仍需进一步验证；② 关键路径重排主要针对 TPU‑style MAC，其他架构需改造；③ 统计ABFT 的错误阈值设定需针对具体任务手工调优，无法完全自动化；④ 设计与实验集中在单片加速器级别，跨芯片/多芯片系统的协同可靠性尚未深入探讨

---

## 915. Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems

**arXiv ID:** 2601.14091 | [PDF](https://arxiv.org/pdf/2601.14091v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

---

## 916. Vector Coded Caching Multiplicatively Boosts MU-MIMO Systems Under Practical Considerations

**arXiv ID:** 2601.14142 | [PDF](https://arxiv.org/pdf/2601.14142v1)

**作者:** Hui Zhao `[一作]` (EURECOM), Petros Elia `[通讯]` (EURECOM)

**通讯引用:** 2683 | [OpenAlex ID](https://openalex.org/A5015066458)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

本文在多用户多天线系统中引入向量编码缓存（VCC），并在考虑路径损耗、多天线接收机、功率分配与最大最小公平性（MMF）等实际因素的基础上，构建了完整的系统模型与信道模型，推导了BD‑MRC和ZF两种预编码方案下的吞吐量解析表达式与极限，并给出了闭式最优功率分配与MMF最优解的一维搜索方法。

**💡 创新点**

创新点主要包括：①在VCC框架下首次将多天线接收机与多用户多天线预编码相结合；②利用投影矩阵与特征向量的性质，设计了低复杂度的BD‑MRC预编码，并将MMF优化转化为一维根寻找问题；③在大规模天线下给出了基于Rayleigh衰落的渐近吞吐量闭式表达式；④对ZF预编码在VCC中的性能做了上限与下限分析，证明其在大天线场景下与BD‑MRC性能相近；⑤通过仿真验证VCC在宏小区与微小区中能实现高达300%以上的吞吐量提升，且在CSI不完善时表现更优。

**🔧 技术方法**

使用的技术包括：向量编码缓存理论、块对角化（BD）与最大比合并（MRC）预编码与接收机设计、零迫预编码（ZF）、水分配功率分配、最大最小公平性（MMF）优化、一维根搜索、Rayleigh衰落信道模型、路径损耗模型、CSI开销建模以及大天线极限分析（Trace Lemma 等）。

**📊 数据集**

实验采用的是仿真数据：独立同分布的Rayleigh衰落信道，均匀分布于宏/微小区中的用户，给定的协作块长度与CSI占用时间，采用典型的路径损耗模型（η₀=3.76或3，l₀等参数）和基站功率设置，未使用公开数据集。

**📈 对比分析**

通过与传统无缓存的MU‑MIMO（BD‑MRC或ZF）以及基于XOR的比特级多天线编码（MSV）方案进行对比，使用相同的总功率与CSI开销模型；在宏小区环境下，VCC在MMF下能提升约230%吞吐量，微小区可达300%；与MSV相比，VCC在低SNR下性能更优，且在高SNR下可实现至少1.15倍的吞吐量；ZF预编码在大天线下与BD‑MRC性能接近，差距不足5%。

**⚠️ 局限性**

主要局限包括：①MMF优化虽然被简化为一维搜索，但在极大用户/天线规模下仍需较大计算；②模型假设用户请求同步且缓存状态已预先分组，未考虑异步请求导致的信号结构不对齐；③CSI误差模型主要为高斯估计误差，未深入探讨更复杂的CSI误差（如反馈延迟、量化等）；④多天线接收机的硬件实现与协同解码复杂度未详细评估；⑤在非Rayleigh或关键通道（如键盘信道）下的性能分析仍待补充。

---

## 917. CREATE: Cross-Layer Resilience Characterization and Optimization for Efficient yet Reliable Embodied AI Systems

**arXiv ID:** 2601.14140 | [PDF](https://arxiv.org/pdf/2601.14140v1)

**作者:** Tong Xie `[一作]` (Peking University), Meng Li `[通讯]` (Peking University)

**通讯引用:** 23845 | [OpenAlex ID](https://openalex.org/A5100457407)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出 CREATE 体系，进行跨层级错误容忍性评估与优化，结合电路层的异常检测与清除、模型层的权重旋转增强规划、应用层的自主自适应电压调节，实现本地低功耗嵌入式 AI 系统的可靠高效部署。

**💡 创新点**

首次系统性地对嵌入式 AI 系统进行错误注入实验并揭示规划器与控制器的异构容错特性；设计跨层协同的 AD+WR+VS 优化框架，利用激活分布旋转与熵驱动的动态电压控制，显著降低能耗且不影响任务质量；实现几乎无面积/功耗开销的硬件级错误抑制与自适应电压调节。

**🔧 技术方法**

采用随机比特翻转错误模型；电路层实现异常检测与清除单元（对 GEMM 结果做阈值裁剪）；模型层利用 Hadamard 旋转矩阵重塑 LLM 激活分布；应用层基于熵预测器（CNN+MLP）驱动分布式 LDO 进行实时电压调节；在 22nm 生产技术下实现 128×128 PE 体系结构与分布式 LDO；使用 PyTorch 框架进行仿真与实验。

**📊 数据集**

主要使用 JARVIS‑1 机器人任务（7 个基准任务及 6 个复杂任务）；构建 250k 帧熵预测数据集；在 OpenVLA、RoboFlamingo、Octo、RT‑1 等平台上测试不同规划器/控制器组合；对比多种基准任务和电压调节策略。

**📈 对比分析**

与常数电压基线、ThUnderVolt、双模冗余（DMR）以及 ABFT 等现有方法对比；实验显示在 0.75V 时成功率不降低的情况下，CREATE 可平均实现 40.6% 计算能量节约，超过基线 35%；芯片层能耗下降 29.5–37.3%；电池续航提升 15–30%；任务成功率保持在或接近无误差水平。

**⚠️ 局限性**

仅针对 INT8 量化，未深入探讨更低精度或混合精度的适用性；错误注入模型主要为比特翻转，未覆盖位翻转与存储器错误；实验平台集中在 Minecraft 及少数公开平台，缺乏更广泛多领域验证；自适应电压调节需在控制器层实现，可能对极大模型或多核并行环境适用性有限。

---

## 918. Optimizing Energy and Data Collection in UAV-aided IoT Networks using Attention-based Multi-Objective Reinforcement Learning

**arXiv ID:** 2601.14092 | [PDF](https://arxiv.org/pdf/2601.14092v1)

**作者:** Babacar Toure `[一作]` (Huawei Technologies France), Marios Kountouris `[通讯]` (University of Granada)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

本文提出了一种基于注意力机制的多目标强化学习算法 MOSAC-ATT，用于无人机在城市 IoT 网络中进行数据收集与能量消耗权衡的路径规划。

**💡 创新点**

创新点在于将注意力编码与多目标 Soft Actor-Critic 结合，实现对偏好向量的条件化、无缝生成任意权衡策略，并在不依赖完整地图表示的情况下获得更好的泛化能力。

**🔧 技术方法**

主要技术包括多目标强化学习（MOSAC）、自注意力网络、离散 Soft Actor-Critic、经验回放、温度衰减与熵调节，以及基于 set 表示的状态编码。

**📊 数据集**

使用的实验数据集为基于城市网格的仿真环境，随机生成建筑、IoT 设备位置与初始数据量，分别在“Reach Destination”和“Return Base”两种场景下进行训练与测试。

**📈 对比分析**

与 DDQN‑CGL、MOSAC‑CGL、MOSAC‑FTV 和 Greedy 等基线对比，MOSAC‑ATT 在样本效率、超额收敛、Pareto 前沿密度和超体积指标上均显著优于其他方法，尤其在未见过的设备数量和电量条件下表现更稳健。

**⚠️ 局限性**

局限性包括仍然依赖固定最大设备数限制、需要离线训练和对连续动作空间的处理有限，以及在极端环境下对最短路径目标的学习可能受噪声影响。

---

## 919. DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning

**arXiv ID:** 2601.14084 | [PDF](https://arxiv.org/pdf/2601.14084v1)

**作者:** Abdurrahim Yilmaz `[一作]` (Imperial College London), Burak Temelkuran `[通讯]` (Imperial College London)

**通讯引用:** 3831 | [OpenAlex ID](https://openalex.org/A5088761708)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了 DermaBench，一个完全由皮肤科医生手工标注的多源视觉问答基准，用于评估视觉‑语言模型在皮肤病诊断与推理方面的性能。

**💡 创新点**

创新点在于提供真实临床图像、标准化的层级问答集、专家共识标签、肤色多样性与公平性考量，以及与 SkinCon 术语映射，弥补了现有数据集缺乏可靠 VQA 注释与公平评估的空白。

**🔧 技术方法**

采用层级问答结构、AnnotatorMed 标注接口、基于多专家共识的标准化词汇表，以及基准评估脚本；模型评估使用 VQA、分类、长文本推理等多任务指标。

**📊 数据集**

使用 Diverse Dermatology Images (DDI) 数据集中的 656 张图像（570 名患者），并结合 14,474 条医生标注的问答对。

**📈 对比分析**

与现有 DermatoLlama、DermaVQA、MM‑Skin 等数据集对比，DermaBench 通过高质量专家标注提供更可靠的 VQA 评估，实验表明模型在诊断准确率和推理质量上有显著提升，公平性评估显示在不同 Fitzpatrick 皮肤类型上的性能差距减小。

**⚠️ 局限性**

限制在于仅提供元数据，需自行获取原始图像；数据集规模相对有限，且尚未定义标准 train/test 切分，未来需扩展样本量并验证跨模型泛化。

---

## 920. From Trees to Tree-Like: Distribution and Synthesis for Asynchronous Automata

**arXiv ID:** 2601.14078 | [PDF](https://arxiv.org/pdf/2601.14078v1)

**作者:** Mathieu Lehaut `[一作]` (University of Warsaw), Nir Piterman `[通讯]` (University of Gothenburg and Chalmers University of Technology)

**关键词:** `33d19632-8af2-4683-a5db-767c7ce749e6`

**🎯 论文内容**

本文研究了在树状（tree‑like）通信架构下，如何将确定性有限自动机（DFA）分布成Zielonka异步自动机，并在此基础上解决分布式控制（synthesis）问题。

**💡 创新点**

创新点在于：①提出一种对树状架构的二次（O(n²)）分布构造，显著优于此前针对树形架构的二次构造和对三角化依赖字母的指数构造；②证明对树状架构的分布式控制问题是可判定的，并给出与树形架构相同的Tower_d(n)复杂度；③将叶子进程模拟为父进程的技术推广到树状架构。

**🔧 技术方法**

核心技术包括Zielonka异步自动机模型、Mazurkiewicz轨迹与独立性关系、DFA的钻石（diamond）性质、树状架构的拓扑定义、局部状态聚合与递归状态组合函数、以及对控制器的覆盖（covering）构造与优雅化的优先级转换。

**📊 数据集**

本文未使用公开数据集，而是以理论构造与证明为主，研究对象为形式化的自动机模型与通信拓扑。

**📈 对比分析**

与原始Zielonka构造（指数级）以及对树形架构的二次构造相比，本文的构造在状态数上实现了从指数降到二次；控制问题的可判定性与复杂度保持在与树形架构相同的Tower_d(n)级别，说明在树状架构下可接受更灵活的多方通信。

**⚠️ 局限性**

局限性包括：仅适用于树状（树形）拓扑；对于更一般的图形拓扑仍然是未决或不可判定的；控制器构造与合成复杂度高（Tower级），在实际系统中可能不可行；并且论文未给出实验验证或与实用系统的对比。

---

## 921. ConceptCaps -- a Distilled Concept Dataset for Interpretability in Music Models

**arXiv ID:** 2601.14157 | [PDF](https://arxiv.org/pdf/2601.14157v1)

**作者:** Bruno Sienkiewicz `[一作]` (Warsaw University of Technology), Mateusz Modrzejewski `[通讯]` (Warsaw University of Technology)

**通讯引用:** 17 | [OpenAlex ID](https://openalex.org/A5076000935)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `67630363-6be0-4f51-ab05-7198250671a5` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了 ConceptCaps 数据集，采用两阶段生成管线（VAE 负责语义一致性，细化 LLM 负责语言质量）来生产包含 200 个概念标签的 23k 条音乐-描述-音频三元组。

**💡 创新点**

创新点在于将语义建模与文本生成分离，使用 VAE 捕捉属性共现模式并通过 QLoRA 微调的 Llama 3.1 8B 生成专业描述，从而显著提升概念清晰度和音频-文本对齐。

**🔧 技术方法**

使用的技术包括变分自编码器（β‑VAE）、量化低秩适配（QLoRA）微调 LLM、MusicGen 语音合成以及 CLAP、TCAV 等评估指标。

**📊 数据集**

数据集来源于 MusicCaps 的 1,890 条高质量样本进行蒸馏，并在此基础上通过 VAE 生成属性组合，最终与 LLM 和 MusicGen 结合生成完整数据。

**📈 对比分析**

通过 BLEU、ROUGE‑L、BERTScore、MAUVE、CLAP、FAD 等指标与 MusicCaps、LP‑MusicCaps 进行比较，结果显示 ConceptCaps 在文本质量、音频对齐和 TCAV 概念可分离度上均优于现有合成数据集，且计算成本更低。

**⚠️ 局限性**

局限性包括生成模型的偏见（如 MusicGen 的西方中心倾向）、潜在的 “hallucination” 与冗余描述、蒸馏过程可能排除非典型或跨文化音乐概念，导致多样性受限。

---

## 922. Feature-Aware Test Generation for Deep Learning Models

**arXiv ID:** 2601.14081 | [PDF](https://arxiv.org/pdf/2601.14081v1)

**作者:** Xingcheng Chen `[一作]` (Technical University of Munich), Andrea Stocco `[通讯]` (Technical University of Munich)

**通讯引用:** 2453 | [OpenAlex ID](https://openalex.org/A5027652385)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `e0540dec-d77f-42db-94ae-d039248f6393` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于 StyleGAN 隐层空间进行语义可控扰动的特征感知测试框架，能够在生成测试用例时同时评估模型的泛化与鲁棒性，并利用视觉语言模型对扰动的语义相关性进行自动标注。

**💡 创新点**

创新点包括：①在 S 𝑆-空间实现单一语义属性的可控扰动；②构造双重测试 oracle（置信度下降与误分类），从而在同一框架中同时发现模型的局部决策边界和对无关特征的依赖；③结合 VLM 进行语义归因和重新标注，实现高效的无人工标注流程；④在同一实验中统一比较测试生成与伪特征定位两类任务。

**🔧 技术方法**

核心技术包括 StyleGAN2 生成器、S 𝑆-空间解耦特征、梯度敏感度、SmoothGrad、有限差分等 XAI 归因方法、Hill‑climbing 目标优化、视觉语言模型（如 qwen3‑vl‑8b‑thinking）进行语义判定，以及基于置信度下降与误分类的测试 oracle。

**📊 数据集**

实验数据集：CelebA（眼镜、性别等二分类任务）、Kaggle Dog Breed（78 类多分类）、COCO（车检测）。对应的 SUT 包括 ResNet‑50、SWAG‑ViT、ReXNet‑150、YOLOv8。

**📈 对比分析**

与 Mimicry（基于 𝑤‑空间的基线）以及 SpRAy（特征解释聚类）进行对比。结果显示：①在决策边界发现上，提出框架比 Mimicry 在 4 个任务上平均 12% 更快、MS‑SSIM 0.04‑0.07 更高、d₂ 距离更低；②在伪特征定位上，相比 SpRAy 能准确识别 40%‑60% 的相关与无关通道，并在 ResNet‑50 上提升 0.06 的 R_Relevance；③生成的测试集用于模型修复后，ResNet‑50 的边界误判率从 6.5% 降至 0%，整体准确率基本不变。

**⚠️ 局限性**

局限性：①依赖 StyleGAN 的解耦程度，若生成器的特征不够独立会导致归因错误；②计算成本相对较高（梯度、SmoothGrad、VLM 推理均耗时）；③目前仅验证视觉任务，未扩展到文本或音频；④对低准确率模型的伪特征检测效果有限，更多适用于高精度模型。

---

## 923. TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers

**arXiv ID:** 2601.14133 | [PDF](https://arxiv.org/pdf/2601.14133v1)

**作者:** Bin Yu `[一作]` (Harbin Institute of Technology), Kai Chen `[通讯]` (DeepCyber)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一个异步双脑Vision‑Language‑Action框架，分离语义理解与具身感知。

**💡 创新点**

创新点在于引入Asymmetric Mixture‑of‑Transformers（AsyMoT）机制，让冻结的“左脑”与可训练的“右脑”协同工作，避免灾难性遗忘。

**🔧 技术方法**

使用双VLM并行、AsyMoT融合、Flow‑Matching动作专家（Diffusion Transformer）以及状态编码器等技术。

**📊 数据集**

在Open X‑Embodiment (OXE)子集、SimplerEnv、RoboCasa等模拟环境上训练。

**📈 对比分析**

与RT‑1‑X、Octo、OpenVLA、RoboVLM等多种基线对比，SimplerEnv上取得58.4–62%成功率，RoboCasa平均54.6%成功率，均显著优于最新基线。

**⚠️ 局限性**

局限性包括需同构模型、未使用专门的Embodied VLM、数据量有限、缺乏真实机器人实验。

---

## 924. Toward self-coding information systems

**arXiv ID:** 2601.14132 | [PDF](https://arxiv.org/pdf/2601.14132v1)

**作者:** Rodrigo Falcão `[一作]` (Fraunhofer IESE), Karthik Vaidhyanathan `[通讯]` (IIIT Hyderabad)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275`

**🎯 论文内容**

提出了自编码信息系统概念，能够在运行时自动生成、测试并部署源代码以提升可修改性和市场响应速度

**💡 创新点**

首次系统化定义自编码信息系统并探讨其对软件架构、工程角色及组织的潜在影响

**🔧 技术方法**

利用大语言模型（LLM）和检索增强生成（RAG）等生成式 AI 技术

**📊 数据集**

未使用具体数据集

**📈 对比分析**

未进行实验或性能对比

**⚠️ 局限性**

可靠性、可维护性、资源消耗及人机协作机制等方面存在挑战

---

## 925. "Range as a Key" is the Key! Fast and Compact Cloud Block Store Index with RASK

**arXiv ID:** 2601.14129 | [PDF](https://arxiv.org/pdf/2601.14129v1)

**作者:** Haoru Zhao `[一作]` (Shanghai Jiao Tong University), Haibo Chen `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 7343 | [OpenAlex ID](https://openalex.org/A5100406215)

**关键词:** `9a43038e-f401-4fd9-9c05-65c0b8369d7e`

**🎯 论文内容**

本文提出一种基于区间键（range-as-a-key）的云块存储索引Rask-index，旨在显著降低索引内存占用并提升 I/O 性能。

**💡 创新点**

创新点包括：①直接使用块范围作为键；②在叶子节点采用日志结构实现覆盖范围的延迟回收；③双阶段垃圾回收与自适应裁剪；④基于区间的拆分与合并策略；⑤面向覆盖和碎片的搜索算法。

**🔧 技术方法**

技术实现基于ART（Trie）内部节点、B‑Tree 样式叶子、日志结构叶子、双阶段 GC、区间裁剪、工作负载感知合并/重拆。

**📊 数据集**

使用四组工业级 I/O 跟踪数据：阿里云 EBS（1.4k 1.8k VDs）、腾讯云、Meta 以及 Google 的块存储追踪。

**📈 对比分析**

将 Rask-index 与 10 种主流有序索引（B‑Tree、ART、Cuckoo Trie、HydraList、Wormhole、HOT、PGM‑Index、segment tree、interval tree）以及原始 EBS‑index 进行对比。实验显示内存占用可下降 45.3–98.9%，吞吐量提升 1.37–32.0×（相对 SOTA）或 2.76–37.8×（相对 EBS‑index），尾延迟下降 48.2–97.4%。

**⚠️ 局限性**

局限性：对连续区间写入的依赖，极小范围或随机写入场景下收益有限；日志结构叶子与 GC 机制在极高并发写入时可能产生额外锁竞争；实现复杂度较高，需要在生产环境中进一步验证可维护性。

---

## 926. NewsRECON: News article REtrieval for image CONtextualization

**arXiv ID:** 2601.14121 | [PDF](https://arxiv.org/pdf/2601.14121v1)

**作者:** Jonathan Tonglet `[一作]` (KULeuven), Marie-Francine Moens `[通讯]` (KULeuven)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了 NewsRECON 方法，利用大规模新闻文章检索并结合双编码器和两种跨编码器，在缺乏反向图像搜索（RIS）证据的情况下推断新闻图片的日期和地点；

**💡 创新点**

首次将新闻文章语料与双编码器+位置/事件跨编码器相结合，克服单纯图像或知识库依赖的局限，能够在 RIS 失效时仍实现高质量的图片上下文化；

**🔧 技术方法**

使用 CLIP 为基底的双编码器进行图像-文本检索，两个冻结的跨编码器分别对位置和事件进行重排序，配合 Qwen2.5‑7B 生成新闻标题/描述，最终可将检索结果作为证据馈入多模态大型语言模型；

**📊 数据集**

构建了约 91,376 篇来自 NYTimes 与 Guardian 的新闻文章语料，并在 TARA（15,429 张图像）与 5Pils‑OOC（624 张图像）两大公开数据集上进行训练与评测；

**📈 对比分析**

与 CLIP+、InternVL3‑8B、Qwen2.5VL‑7B 等基线以及依赖 RIS 的 COVE 进行对比；在 TARA 上 NewsRECON+MLLM 达到最高 GREAT 分数，较传统基线提升约 9–12pp；在 5Pils‑OOC RIS 失效子集上，NewsRECON+Qwen2.5VL 超越 COVE 超过 10pp，显示出在无 RIS 情况下的优势；

**⚠️ 局限性**

当前语料仅来自两家英语媒体，导致事件覆盖有限；检索结果有时误导 MLLM，导致错误预测，需改进证据融合方法；未来需扩展多语言覆盖并控制噪声。

---

## 927. Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns

**arXiv ID:** 2601.14112 | [PDF](https://arxiv.org/pdf/2601.14112v1)

**作者:** George Mihaila `[一作]` (University of North Texas), George Mihaila `[通讯]` (University of North Texas)

**通讯引用:** 1616 | [OpenAlex ID](https://openalex.org/A5003559911)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一种基于Transformer注意力的可解释性网络ExpNet，用来学习从注意力模式到词级重要性分数的映射，实现无手工聚合规则的解释。

**💡 创新点**

将解释生成视为监督学习问题，利用人类注释的合理化训练模型，自动发现最佳注意力特征组合，实现跨任务泛化并显著提升解释质量。

**🔧 技术方法**

采用BERT‑base提取12层自注意力的双向特征，构建24维特征向量，使用轻量化前馈网络与Focal Loss训练，并在推理时使用阈值后处理。

**📊 数据集**

在三种分类任务上评估：SST‑2（情感）、CoLA（语法可接受性）和HateXplain（仇恨言论），并结合人类及LLM生成的可解释注解。

**📈 对比分析**

与13种基线方法（LIME、SHAP、IG、LRP、GAE、RawAtt、Rollout、AttCAT等）进行交叉任务leave‑one‑out评估，ExpNet在F1上均优于所有基线，提升约13%–25%，AUROC亦保持竞争力。

**⚠️ 局限性**

依赖人类可解释注解训练、仅关注注意力信号、对多词短语解释有限，以及在大型或解码器模型中的适用性需要进一步验证。

---

## 928. AttackMate: Realistic Emulation and Automation of Cyber Attack Scenarios Across the Kill Chain

**arXiv ID:** 2601.14108 | [PDF](https://arxiv.org/pdf/2601.14108v1)

**作者:** Max Landauer `[一作]` (Austrian Institute of Technology), Markus Wurzenberger `[通讯]` (Austrian Institute of Technology)

**通讯引用:** 861 | [OpenAlex ID](https://openalex.org/A5029942543)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

开发了 AttackMate，一款开源的攻击脚本语言和执行引擎，用于在整个杀伤链中模拟人类攻击者的技术实现，并生成更接近真实攻击的日志痕迹。

**💡 创新点**

创新点在于：①采用无代理的命令执行方式，避免在目标系统留下明显的代理痕迹；②提供交互式执行、后台运行和会话管理，使攻击脚本能够模拟真实用户操作；③设计模块化执行器体系，支持自定义脚本、与现有框架（Metasploit、Sliver、Bettercap）无缝对接。

**🔧 技术方法**

技术实现包括：YAML 格式的 Playbook、执行引擎（Playbook 解析器 + 顺序调度器）、多种执行器（Flow、Data、Attack Commands、Framework Connectors）、交互式 SSH、VNC、浏览器自动化、文本编辑器模拟等；使用 Python、Shell、网络协议工具及日志收集机制。

**📊 数据集**

使用了在 AttackBed 生成的虚拟实验环境与公开日志数据集（收集自实验场景的系统日志、审计日志、Syslog 等），并将 AttackMate 的执行日志与 Caldera 生成的日志进行对比。

**📈 对比分析**

对比方法：在相同攻击场景（权限提升、网络抓包、横向移动）下，分别用 AttackMate 与 Caldera 执行脚本，收集目标系统的日志，比较日志事件类型、频率与系统进程树。结果显示：AttackMate 产生的日志与真实攻击更相似，事件更少、更符合人类行为，且不易被入侵检测系统即时识别；而 Caldera 由于使用代理和非交互命令，日志中出现大量异常进程与多余的审计事件。

**⚠️ 局限性**

局限性包括：①缺乏对攻击步骤时间特征的建模；②部分执行器（如 Metasploit 模块）不支持交互或后台执行，导致无法完全模拟交互攻击；③对外部依赖（如 nmap、tcpdump）没有自动检查；④SSH 执行器不支持后台模式；⑤整体依赖手工编写 Playbook，仍需专业知识。

---

## 929. Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing

**arXiv ID:** 2601.14103 | [PDF](https://arxiv.org/pdf/2601.14103v1)

**作者:** Xiaolu Liu `[一作]` (Zhejiang University), Jianke Zhu `[通讯]` (Zhejiang University)

**通讯引用:** 7637 | [OpenAlex ID](https://openalex.org/A5062252650)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

提出一种无训练的、逐步对齐的3D纹理形态变形框架Interp3D，用以在两个3D资产之间生成平滑、可解释的过渡序列。

**💡 创新点**

创新点在于将语义对齐、结构对齐（利用Treillis的SLAT表示）和纹理细粒度融合三阶段逐步对齐机制引入3D生成过程中，从而同时保证几何一致性、纹理连贯性与过渡平滑度。

**🔧 技术方法**

核心技术包括：DINOv2提取语义条件向量进行Patch级对应；Treillis 3D扩散模型与SLAT（结构潜在）特征的动态Patch对应；注意力融合插值与结构引导的注意力插值；双向加权纹理融合；以及基于Beta分布的插值权重采样。

**📊 数据集**

使用了自构建的Interp3DData数据集，共57对3D模型，按易中难三档划分，涵盖人物、物体、建筑、卡通等类别。

**📈 对比分析**

与MorphFlow、DiffMorpher、FreeMorph、AID-I/O等基线在FID、PPL、LPIPS等指标上对比，Interp3D在所有难度级别均表现出最低FID（约78–83）、最低PPL（约2.4–2.7）和最低LPIPS（约0.059–0.119），并在用户研究中获得约54% 的整体偏好率，显著优于对比方法。

**⚠️ 局限性**

局限性主要体现在：对语义相似度低的源目标对（如建筑与家具）仍可能出现对应不稳定；并且整个过程依赖Treillis等预训练模型，若模型无法覆盖目标域，效果可能下降。

---

## 930. Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems

**arXiv ID:** 2601.14096 | [PDF](https://arxiv.org/pdf/2601.14096v1)

**作者:** Benedikt Hartl `[一作]` (Allen Discovery Center), Michael Levin `[通讯]` (Allen Discovery Center)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

提出将认知视为嵌入空间的重映射与导航的两大不变量，并探讨其在生物与人工智能系统中的普适性。

**💡 创新点**

创新点在于将不同尺度和介质的智能归纳为同一条理性原则，构建跨尺度的“嵌入空间导航”框架。

**🔧 技术方法**

主要使用文献综述、理论推导，并将Transformer、扩散模型、神经元自动机、主动推断等现代AI架构与生物学过程进行对比。

**📊 数据集**

本研究未使用具体实验数据集，而是基于已有文献与案例进行概念性分析。

**📈 对比分析**

未做实验对比，论文通过理论阐述与案例对照说明该框架能够解释多种系统的自适应行为，尚无量化性能评估。

**⚠️ 局限性**

局限在于缺乏经验验证、量化指标不足，以及在多尺度、多介质实现细节上的技术挑战。

---

## 931. Near Optimal Code Construction for the Adversarial Torn Paper Channel With Edit Errors

**arXiv ID:** 2601.14088 | [PDF](https://arxiv.org/pdf/2601.14088v1)

**作者:** Maria Abu-Sini `[一作]` (Technical University of Munich), Reinhard Heckel `[通讯]` (Technical University of Munich)

**通讯引用:** 3205 | [OpenAlex ID](https://openalex.org/A5003606899)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `6215c339-3735-4be3-8a07-5bbb7004712d`

**🎯 论文内容**

构造了一种近似最优的t-切点t_e-编辑错误容忍码，用于对抗性撕裂纸通道；并给出了该通道的列表解码上界与下界。

**💡 创新点**

创新点：①提出了同时抵御插入、删除、替换和任意切割的码；②利用互相不相关的标记、可重复自由序列、Reed–Solomon 纠错与多层哈希结构实现近似最优冗余；③给出了列表解码的通用上界与下界，连接了对抗性与概率性撕裂纸模型。

**🔧 技术方法**

技术手段：互相不相关标记、ℓ-重复自由字母表、Reed–Solomon 码、哈希值层级分块、最长匹配算法、以及对标记位置的精准估计。

**📊 数据集**

无实际数据集，全部为理论构造与证明。

**📈 对比分析**

比较方式：与已有的仅处理切割或仅处理编辑错误的码对比；性能指标为冗余量和解码复杂度。冗余量达到Θ((t+t_e)·log n·loglog n)（与下界匹配，近似最优），但解码复杂度高达Θ(t! n⁴)；在改进的高效编码版本中，复杂度可降至多项式但冗余略增。

**⚠️ 局限性**

局限性：①仅处理对抗性模型，未直接给出概率性模型的实现；②解码复杂度较高，尤其对插入/删除时；③初始构造缺乏高效编码器，后续改进需牺牲冗余；④目前仅在二进制通道分析，推广到多符号情形需进一步工作。

---

## 932. '1'-bit Count-based Sorting Unit to Reduce Link Power in DNN Accelerators

**arXiv ID:** 2601.14087 | [PDF](https://arxiv.org/pdf/2601.14087v1)

**作者:** Ruichi Han `[一作]` (KTH Royal Institute of Technology), Ahmed Hemani `[通讯]` (KTH Royal Institute of Technology)

**通讯引用:** 3568 | [OpenAlex ID](https://openalex.org/A5026355063)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

实现了一个基于popcount的无比较排序单元，并通过近似桶化降低面积与功耗，用于CNN加速器的链路位转换减少。

**💡 创新点**

首次提出比较器无关的精确与近似popcount排序结构，并通过将完整位计数映射到少数粗粒度桶来实现硬件近似，从而在保持大部分BT降低效果的同时显著压缩面积。

**🔧 技术方法**

使用了比较器无关排序网络、前缀和、位桶映射、近似计算、22 nm工艺后仿真与链路BT统计等技术。

**📊 数据集**

在LeNet‑5的前两层卷积与池化工作负载上进行实验，使用随机生成的8位固定点输入与权重数据。

**📈 对比分析**

与基线、列优先排序、准确排序（ACC‑PSU）进行对比，APP‑PSU面积下降35.4%、功耗下降37.3%，链路位转换降低19.5%（仅比ACC‑PSU低4.2%），并实现了16.48%的链路功耗节省。

**⚠️ 局限性**

实验仅覆盖单层卷积与单跳链路，未评估更深网络或多跳NoC的整体效益；近似桶化可能在更大模型或更高精度要求下影响精度。

---

## 933. Two-Stream temporal transformer for video action classification

**arXiv ID:** 2601.14086 | [PDF](https://arxiv.org/pdf/2601.14086v1)

**作者:** Nattapong Kurpukdee `[一作]`, Adrian G. Bors `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种基于Transformer的两流视频分类模型，将原始RGB帧与光流帧作为输入，通过自注意力机制融合两者特征，完成动作识别任务。

**💡 创新点**

创新点在于：①首次在Transformer编码器内直接对RGB与光流两流特征进行自注意力融合；②利用RAFT等神经网络预测的光流代替传统手工光流，大幅提升运动信息表示；③在小模型规模下实现显著性能提升。

**🔧 技术方法**

主要技术包括：多尺度视觉Transformer（MViTv2、MViTv1、Swin）作为编码器；光流预测采用RAFT网络；多头自注意力（MHA）与MLP分类头；轻量级Transformer架构（如MViTv2‑S、Swin‑S）；Adam优化器、交叉熵损失及早停策略。

**📊 数据集**

使用三大公开动作数据集：UCF101、HMDB51 与 Something‑Something V2（SSv2）进行实验评估。

**📈 对比分析**

与基线（MViTv1‑B、MViTv2‑S、Swin‑S）及多种两流CNN、I3D、TSN等模型对比，实验表明在UCF101上提升10.9%（最高93.54%），HMDB51提升25.92%（最高83.39%），SSv2提升6.82%（最高56.38%），整体性能均超过现有最优方法。

**⚠️ 局限性**

局限性包括：未使用任何数据增强策略；光流预测虽准确但计算开销大；在某些视频中光流图像噪声较多；模型仅在小规模架构下测试，未验证大规模模型性能。

---

## 934. VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences

**arXiv ID:** 2601.14066 | [PDF](https://arxiv.org/pdf/2601.14066v1)

**作者:** Hendrik Möller `[一作]` (Technical University of Munich), Jan S. Kirschke `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

提出一种利用多分类头和约束优化的3D脊柱椎体编号方法VERIDAH，能够在任意视野下准确识别枚举异常。

**💡 创新点**

创新点在于将多分类头（椎体标签、区域、过渡、可见度）与全局约束求解结合，实现自动处理TEA/LEA异常。

**🔧 技术方法**

使用3D DenseNet169作为骨干网络，并结合多分类头和动态规划的序列预测算法。

**📊 数据集**

使用德国国家队列NAKO的T2w斜向MRI和多源CT数据，包含TEA/LEA等异常。

**📈 对比分析**

与现有方法（Meng等、SpineNetV2、TotalSpineSeg）对比，VERIDAH在MRI上达到98.3%全序列正确率，TEA/LEA召回率分别为87.8%/94.48%；在CT上亦显著优于基线。

**⚠️ 局限性**

主要限制是需要预先定位椎体，且对不同扫描仪的跨域迁移性能尚需进一步验证。

---

## 935. Partial Reductions for Kleene Algebra with Linear Hypotheses

**arXiv ID:** 2601.14114 | [PDF](https://arxiv.org/pdf/2601.14114v1)

**作者:** Liam Chung `[一作]` (Leiden University), Tobias Kappé `[通讯]` (Leiden University)

**通讯引用:** 205 | [OpenAlex ID](https://openalex.org/A5063583108)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

本文提出了一种基于有限自动机的构造方法，用于在给定线性假设（如 e≤w）下自动生成 Kleene 代数的部分归约（partial reduction），从而实现对带假设的 Kleene 代数的可判定性与完整性；

**💡 创新点**

创新点在于：①引入“patching”与“saturation”两种自动机操作来模拟假设闭包，②允许归约仅在特定表达式域内定义（partial reduction），从而在传统方法失败的情形下仍可得到完整性与可判定性；

**🔧 技术方法**

使用了：有限自动机理论、Brzozowski 衍生、最小解系统、逆向解法、以及对假设闭包的迭代与极限构造；

**📊 数据集**

论文为理论性研究，无实验数据集；

**📈 对比分析**

通过与已知完整系统（如 Kleene 代数加假设、Kleene 代数与测试）对比，证明该方法能够恢复已有的归约，并在更广泛的线性假设下实现可判定性与完整性，性能上主要体现在算法可终止性和自动化程度；

**⚠️ 局限性**

局限性包括：①仅适用于线性假设（e≤w），无法处理更一般的 e≤f；②当假设与表达式交互导致假设闭包不保持正规时，归约可能无法终止；③尚未处理与假设直接交互的集合或通用假设的情况。

---

## 936. Communication Technologies for Intelligent Transportation Systems: From Railways to UAVs and Beyond

**arXiv ID:** 2601.14106 | [PDF](https://arxiv.org/pdf/2601.14106v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2`

---

## 937. Multi-Partner Project: Multi-GPU Performance Portability Analysis for CFD Simulations at Scale

**arXiv ID:** 2601.14159 | [PDF](https://arxiv.org/pdf/2601.14159v1)

**作者:** Panagiotis-Eleftherios Eleftherakis `[一作]` (National Technical University of Athens), Sotirios Xydis `[通讯]` (National Technical University of Athens)

**通讯引用:** 1362 | [OpenAlex ID](https://openalex.org/A5076432415)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

在OpenACC实现的Spectral Element CFD求解器SOD2D上，系统性评估了不同GPU（AMD MI250X、NVIDIA V100/A100）、编译器（NVHPC、Cray Clang）以及精度（FP32/FP64）和内存访问优化（Kernel Splitting、Preloading、Prefetching、Regular Access）对单GPU和多GPU性能的影响；

**💡 创新点**

首次在同一套CFD框架中开展跨厂商完整堆栈对比，揭示GPU架构、编译器和内存优化对性能可移植性的系统性差异，并提出多级参数化调优策略；

**🔧 技术方法**

采用OpenACC GPU加速、MPI分区、NVHPC/Cray Clang编译器堆栈、手工内存访问优化（Kernel Splitting、Preloading、Prefetching、Regular Access）、GNOPS度量、微基准与弱标度实验；

**📊 数据集**

使用Channel Flow（CF）和Taylor‑Green Vortex（TGV）两类典型案例，节点数从1M到16M，分别在FP32和FP64模式下运行；

**📈 对比分析**

通过单GPU多次跑时比较不同优化组合与GPU/精度的交互影响，发现AMD MI250X对V100慢15–23倍，NVIDIA A100对V100在FP32/FP64分别提升1.47×和3.05×；多GPU弱标度实验表明不同优化在不同规模上表现不一致，最佳配置并不随规模线性推断，FP32下GNOPS平均比FP64高1.2倍；

**⚠️ 局限性**

研究仅覆盖两类CFD案例与有限的GPU/编译器组合，缺乏自动化调优流程，且多GPU性能受限于LUMI 400W功率上限和单GCD MI250X；结果对其他硬件或编译器迁移可能不直接适用。

---

## 938. The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning

**arXiv ID:** 2601.14127 | [PDF](https://arxiv.org/pdf/2601.14127v1)

**作者:** Renmiao Chen `[一作]` (Tsinghua University), Minlie Huang `[通讯]` (Tsinghua University)

**通讯引用:** 16270 | [OpenAlex ID](https://openalex.org/A5044042138)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建并发布了 MIR‑SafetyBench，一个针对多图推理的安全性评测基准，用于衡量多模态大型语言模型（MLLMs）在多图情境下的攻击成功率和安全行为。

**💡 创新点**

创新点包括：①首次提出多图推理安全评测框架；②设计了覆盖 9 种多图关系、6 类风险的 2,676 条实例；③引入了注意力熵分析，揭示多图推理导致安全失败的内部机制；④通过系统实验展示了强大推理能力与安全风险的“边缘”关系。

**🔧 技术方法**

技术手段：①自动化实例生成流程（重写、图像合成、攻击测试、危害判定、评估反馈迭代）；②使用现有的文本重写模型、图像生成模型、攻击评估器和危害判别器；③对 19 公开及闭源 MLLMs 进行单轮推理实验；④计算并对比安全/不安全样例的注意力熵差异。

**📊 数据集**

数据集：基于 600 条已知危险种子问题（覆盖 6 种风险）生成 2,676 条多图实例，每条包含 2–4 张合成图像；同时使用公开的危害判别器和评估工具对模型输出进行标注。

**📈 对比分析**

比较方法：对 19 个主流 MLLM（包括开源与闭源、聊天与推理模型）进行 ASR（攻击成功率）评估，最高 ASR 87.63%。实验表明：更强的多图推理能力往往伴随更高的攻击成功率；在单图与多图对照实验中，多图情境下所有模型的 ASR 明显提升；注意力熵对比显示，多图安全失败的注意力更集中，暗示认知负荷导致安全忽视。

**⚠️ 局限性**

局限性：①数据覆盖有限，主要为合成实例，缺乏真实世界多模态交互；②实验仅在单轮、单向提示下进行，未覆盖多轮或工具辅助场景；③实例生成依赖自动化组件，可能带来偏差；④只对 4 个代表性模型做注意力熵分析，缺乏因果解释；⑤未给出针对性缓解方案或训练方法。

---

## 939. Riemannian Liquid Spatio-Temporal Graph Network

**arXiv ID:** 2601.14115 | [PDF](https://arxiv.org/pdf/2601.14115v1)

**作者:** Liangsi Lu `[一作]` (Guangdong University of Technology), Yang Shi `[通讯]` (Guangdong University of Technology)

**通讯引用:** 1517 | [OpenAlex ID](https://openalex.org/A5101908670)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `a8e75ba4-7a2d-4153-b003-06c94533add0` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了一种Riemannian液态时空图网络（RLSTG），将液态时间常数网络（LTC）与黎曼几何结合，实现了在曲率空间上的连续时间图表示学习。

**💡 创新点**

创新点在于：①在黎曼流形上构造可稳定求解的液态ODE，②设计了分裂式Geodesic Decay（GD）求解器以处理刚性动力学，③通过匹配流形曲率与图结构（层次或循环）显著降低欧氏几何扭曲，提高表达能力。

**🔧 技术方法**

技术方法包括：黎曼流形的指数/对数映射、平行运输、Riemannian梯度、液态时间常数机制、ODE求解器GD、以及多种图卷积聚合。

**📊 数据集**

实验使用交通流量数据集 METR‑LA、PEMS03、PEMS04 进行节点特征回归，以及社交邮件网络 ENRON 进行时序链接预测。

**📈 对比分析**

与 DCRNN、GMAN、AGCRN、STGODE、STG‑NCDE、TGODE、LTC 等现有方法对比，RLSTG 在 MAE（交通回归）和 AP（链接预测）上均取得最高或次高分，表现更优。

**⚠️ 局限性**

主要局限在于：计算开销较大（尤其是GD求解器与高维黎曼空间运算），以及对几何空间的固定选择，未来需改进效率、实现自动化流形选取和动态曲率适配。

---

## 940. Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning

**arXiv ID:** 2601.14104 | [PDF](https://arxiv.org/pdf/2601.14104v1)

**作者:** Tairan Huang `[一作]` (Hong Kong Polytechnic University), Haibo Hu `[通讯]` (Hong Kong Polytechnic University)

**通讯引用:** 8461 | [OpenAlex ID](https://openalex.org/A5020630816)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `6215c339-3735-4be3-8a07-5bbb7004712d` `ba576bd1-e51d-44e8-8077-fc943b333c93`

**🎯 论文内容**

研究并验证了在现实机器人平台上执行的强化学习系统中的后门攻击，提出了一种基于扩散模型的可打印地板贴纸触发器的后门攻击框架（DGBA），并在TurtleBot3移动机器人上进行了实车实验。

**💡 创新点**

创新点包括：①提出安全约束控制堆栈会削弱传统后门攻击的“衰减”现象；②利用条件扩散模型生成多样化、与环境相适应的触发器；③在训练期间仅对决策关键状态进行优势驱动的稀疏篡改；④通过物理风格增强使触发器在现实摄像机投影与光照下保持鲁棒；⑤将攻击视为黑盒安全控制堆栈下的目标行为学习。

**🔧 技术方法**

核心技术包括：条件扩散概率模型（U‑Net）、PPO / TRPO 强化学习、优势估计与稀疏状态选择、物理风格增强（尺度、透视、亮度/对比度、颜色扰动、遮挡）、以及对安全控制堆栈的黑盒假设。

**📊 数据集**

数据集与环境：使用Gazebo仿真环境（相机、激光雷达）进行预训练与微调，随后在真实TurtleBot3平台（前置RGB摄像头、2D激光雷达）收集实验数据；任务为从起点导航至目标并避障，没有使用公开的标准数据集。

**📈 对比分析**

对比方法：TrojDRL、BadRL、SleeperNets 等基线后门攻击；评估指标为清洁成功率（CSR）与攻击成功率（ASR）。实验表明：在PPO受害者上，DGBA的ASR高达83.5%（相比对手的最高57.0%），CSR保持在89.1%；在TRPO受害者上，DGBA ASR 76.3%，CSR 90.7%，同样优于对手。

**⚠️ 局限性**

局限性：①仅在单一机器人平台（TurtleBot3）和两类算法（PPO、TRPO）上验证；②需要将物理贴纸打印并放置，受环境摆放与视角限制；③攻击效果受安全控制堆栈设计影响，极端过滤策略仍可能抑制后门；④缺乏对更复杂任务、动态障碍或多机器人协作场景的评估。

---

## 941. VENI: Variational Encoder for Natural Illumination

**arXiv ID:** 2601.14079 | [PDF](https://arxiv.org/pdf/2601.14079v1)

**作者:** Paul Walker `[一作]` (Friedrich-Alexander-Universität Erlangen-Nürnberg), Bernhard Egger `[通讯]` (Friedrich-Alexander-Universität Erlangen-Nürnberg)

**通讯引用:** 928 | [OpenAlex ID](https://openalex.org/A5075603650)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

构建了一种旋转等变性变分自编码器，用于学习自然照明的HDR环境图并生成更平滑的潜在空间。

**💡 创新点**

提出了SO(2)-等变的向量神经网络扩展并将其嵌入ViT编码器，结合VN‑ViT与REN++解码器实现SO(2)等变性与高质量重建。

**🔧 技术方法**

Vector Neuron Vision Transformer（VN‑ViT）、SO(2)-等变全连接层、Spherical Normal分布采样、重构损失（MAGE、scale‑invariant、cosine）、KL正则化。

**📊 数据集**

RENI++ HDR环境图集（1694张）与从Streetlearn LDR图转换得到的HDR集（43,310张）作为预训练与微调数据。

**📈 对比分析**

在PSNR、SSIM、LPIPS、HDR‑PSNR及潜在空间唯一性和一致性指标上与REN‑I++比较，低维（D=27）时精度提升30%~35%，并在大数据集上保持性能不下降。

**⚠️ 局限性**

仍依赖大量HDR数据，对内部场景或非SO(2)旋转的光照缺乏鲁棒性；模型训练与推理计算量相对较大。

---

## 942. Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management

**arXiv ID:** 2601.14069 | [PDF](https://arxiv.org/pdf/2601.14069v1)

**作者:** Nattapong Kurpukdee `[一作]` (University of York), Adrian G. Bors `[通讯]` (University of York)

**通讯引用:** 2882 | [OpenAlex ID](https://openalex.org/A5002932489)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种无监督的视频类增量学习框架 uVCIL，利用深度聚类和特征记忆缓冲实现连续学习并防止灾难性遗忘。

**💡 创新点**

创新点包括：① 用深度嵌入聚类在无标签场景下生成伪标签；② 构建按簇划分的可扩展记忆缓冲，仅存特征向量；③ 结合 RBF 分类器和 Focal Loss 解决类别不平衡；④ 通过知识迁移初始化新任务的分类层实现正向迁移。

**🔧 技术方法**

采用预训练 ResNet‑34 或 VideoMAE‑v2 作为特征提取器；k‑means 进行深度嵌入聚类；RBF 网络做线性分类；Adam + Focal Loss 进行优化；t‑SNE 可视化。

**📊 数据集**

在 UCF101、HMDB51、Something‑to‑Something V2 三个标准动作识别数据集上进行实验。

**📈 对比分析**

与 EWC、MAS、iCaRL、BiC 等监督增量学习方法做对比；uVCIL‑CLU 与 uVCIL‑CLU‑RBF 在所有数据集上获得最高的聚类准确率（ACAcc），并在前向/后向遗忘指标上与基线相当或更好，显著降低了模型参数量和训练成本。

**⚠️ 局限性**

局限性：① 对大规模多样化数据集的 k‑means 聚类效果仍有限；② 只在特征层冻结，不考虑视频时序建模；③ 目前仅对无标签数据有效，缺乏对混合标注场景的适配。

---

## 943. Modular Attractor Acceleration in Infinite-State Games (Full Version)

**arXiv ID:** 2601.14068 | [PDF](https://arxiv.org/pdf/2601.14068v1)

**作者:** Philippe Heim `[一作]` (CISPA Helmholtz Center for Information Security), Rayna Dimitrova `[通讯]` (CISPA Helmholtz Center for Information Security)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

在无限状态博弈的符号求解中，提出一种可组合的加速吸引子计算方法，通过构造通用加速归纳式(GAL)并利用参数化的执行摘要实现高效求解。

**💡 创新点**

创新点包括：①定义可组合的GAL并给出交叉与词典序组合等构造操作；②引入执行摘要来泛化并复用加速归纳式；③在求解流程中进行结构化搜索而非一次性求解，加速计算。

**🔧 技术方法**

使用的技术包括：符号博弈求解、线性算术约束、无解释函数模板、量化消解、循环游戏构造、加速归纳式搜索、执行摘要生成与应用、以及多阶段的模板化与变量点强制化。

**📊 数据集**

数据集包含76个、56个、22个、41个、81个来自已有工具的基准，以及为验证需要复杂加速归纳式而新构造的基准。

**📈 对比分析**

与现有工具（标准版、无加速、其他符号博弈求解器）对比，新的方法在多多数独立求解上取得最优结果，整体性能与最先进工具相当；在需要重复计算相同加速归纳式的布希游戏上，摘要机制显著提升速度，但在某些基准上会产生额外计算开销。

**⚠️ 局限性**

主要限制包括：执行摘要生成的开销导致部分基准性能下降；GAL搜索空间仍较大，需要更精细的引导策略；生成的线性项在求简化时受限；整体方法对非线性理论支持不足，未来可考虑引入抽象技术与改进的量化简化。

---

## 944. XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs

**arXiv ID:** 2601.14063 | [PDF](https://arxiv.org/pdf/2601.14063v1)

**作者:** Mohsinul Kabir `[一作]` (University of Manchester), Sophia Ananiadou `[通讯]` (University of Manchester)

**通讯引用:** 17835 | [OpenAlex ID](https://openalex.org/A5077976343)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了一个包含4.9k句子、1,098个文化特定条目（CSI）的跨文化推理基准XCR-Bench，涵盖三种任务（CSI识别、预测、适配）并与Hall文化层级对应。

**💡 创新点**

创新点在于将Newmark CSI框架与Hall的三层文化模型结合，提供针对可见、半可见、不可见层面的标注，并创建多语言并行适配对。

**🔧 技术方法**

使用大语言模型（GPT‑4o、Claude‑3.7‑Sonnet、DeepSeek‑R1等）进行推理实验，并采用专家提示、BERTScore、CSI_BERT等指标评估。

**📊 数据集**

使用基于CANDLE与Cultural Atlas的文化事实、人工标注与生成句子构建的XCR‑Bench语料。

**📈 对比分析**

与多种LLM比较，发现模型在CSI预测表现好于识别；在适配任务中中文和阿拉伯表现最佳，Bengali最差，整体表现低于预期，显示跨文化推理能力有限。

**⚠️ 局限性**

局限在于只覆盖部分Newmark类别、仅四种文化、只使用一种提示策略，且部分CSI缺乏深层语义，未来需扩展类别与文化，并尝试多种提示方法。

---

## 945. POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion

**arXiv ID:** 2601.14056 | [PDF](https://arxiv.org/pdf/2601.14056v1)

**作者:** Andrea Rigo `[一作]` (University of Trento), Nicu Sebe `[通讯]` (University of Trento)

**通讯引用:** 36497 | [OpenAlex ID](https://openalex.org/A5027171279)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了一种基于扩散模型的3D布局引导图像生成与编辑框架 POCI‑Diff，支持一次性生成完整场景、单体语义控制以及无扭曲的对象编辑。

**💡 创新点**

创新点包括：①将 Blended Latent Diffusion 与深度条件 ControlNet 结合，实现每个 3D 包围盒绑定独立文本提示；②引入 IP‑Adapter 的参考图像条件，实现对象迁移时保持视觉身份；③提出完全基于生成的无扭曲编辑流程，取代传统 copy‑warp‑paste，提升几何一致性和视觉质量。

**🔧 技术方法**

核心技术包括：深度条件 ControlNet 微调、Blended Latent Diffusion、IP‑Adapter 参考图像条件、基于 3D 包围盒的遮罩生成与混合策略、以及多尺度、并行扩散路径。

**📊 数据集**

使用 Flux.1 合成图像数据集（约 22k 张高质量图像）以及从 NYU‑Depth‑v2 通过 SAM 分割、点云投影得到的 3D 布局数据，后者用于微调 ControlNet。

**📈 对比分析**

与 Build‑a‑Scene、LooseControl、Layout‑Guidance 等基线对比，POCI‑Diff 在 CLIP_T2I、对象准确率 (OA) 及 mIoU 上均达到或超过基线；推理时间和显存消耗显著更低（如 8 对象场景 8.15s/5.5GB vs 41.3s/7.19GB）。用户研究显示在 76.83% 的样本中更受欢迎。

**⚠️ 局限性**

局限性：①训练依赖合成数据，可能导致与真实场景的域偏差；②需要准确的 3D 包围盒和相机参数，若布局错误或噪声大会影响结果；③对极其稠密或动态几何场景的处理尚未充分验证。

---

## 946. Implicit Neural Representation Facilitates Unified Universal Vision Encoding

**arXiv ID:** 2601.14256 | [PDF](https://arxiv.org/pdf/2601.14256v1)

**作者:** Matthew Gwilliam `[一作]` (TikTok), Zhenheng Yang `[通讯]` (TikTok)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `6514db3d-8de6-452c-91b7-acdb31787cc4` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `8d10c613-917e-4880-9716-17789f50e119` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种统一视觉表示学习模型 HUVR，利用INR超网络同时实现图像分类、分割和高质量重建。

**💡 创新点**

创新点在于将 patch tokens 直接用作权重 token，加入全局 token 进行多任务学习，并通过压缩的 TinToks 提供高效低维表征。

**🔧 技术方法**

采用 Vision Transformer 作为编码器，INR 超网络预测每个 patch 的权重矩阵，结合知识蒸馏、像素、SSIM、LPIPS 重建损失实现联合训练。

**📊 数据集**

在 ImageNet‑22k、ImageNet‑1k、ADE20K、NYUv2 等公开数据集上进行预训练与评估。

**📈 对比分析**

与 DINOv3、C‑Radio、SigLIP 等现有方法对比，HUVR 在 ImageNet 线性分类、ADE20K 语义分割、深度估计以及重建 PSNR 等指标上均取得或突破 state‑of‑the‑art 结果。

**⚠️ 局限性**

局限包括预训练规模与数据量仍低于部分先进模型、对多模态文本对齐缺失、生成质量相对较弱，需要进一步扩展与优化。

---

## 947. Identification capacity and rate-query tradeoffs in classification systems

**arXiv ID:** 2601.14252 | [PDF](https://arxiv.org/pdf/2601.14252v1)

**作者:** Tristan Simas `[一作]` (McGill University), Tristan Simas `[通讯]` (McGill University)

**通讯引用:** 65 | [OpenAlex ID](https://openalex.org/A5060461525)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac`

**🎯 论文内容**

本文将经典的速率-失真理论扩展到离散分类问题，提出三维资源平衡模型 (L: 标签位长, W: 查询/见证成本, D: 失真)，并在此框架下证明信息障碍、最优标签方案及查询集的马尔可夫结构。

**💡 创新点**

创新点包括：① 在属性查询受限的观察域下证明了零误差识别不可行的“信息障碍”；② 证明使用长度为 ⌈log₂k ⌉ 位的名义标签即可在 O(1) 查询内实现零误差识别，给出最优点并证明下界；③ 将最小区分查询集构造为马尔可夫族，提出可测度“区分维度”并与图熵、零误差源编码关联。

**🔧 技术方法**

主要技术手段为信息理论（零误差识别容量、图熵）、组合数学（马尔可夫族交换公理）、量化信息量（区分维度）、以及 Lean 4 形式化证明，保证了所有定理的可机理化检验。

**📊 数据集**

论文没有使用具体数据集，而是给出多领域实例化（类型系统、数据库、遗传分类、图书分类等）来说明理论适用性；所有证明均为理论性，未进行实验验证。

**📈 对比分析**

对比方法：与仅使用结构查询（duck typing）和无标签查询的方案进行理论比较。结果显示：名义标签方案实现 L = ⌈log₂k⌉ 位、W = O(1)、D = 0，远优于无标签方案的 W = Ω(d)（d 为区分维度）或 W = O(n) 的情况；同时指出当允许失真时，标签可被部分消除，但查询成本随失真降低而上升。

**⚠️ 局限性**

局限性：仅考虑确定性、无噪声的属性查询；零误差（D = 0）设定在理论极端；对噪声查询的扩展仅为开放问题；未讨论动态系统中的缓存/预处理对 W 的影响；实际系统的实现细节（如键冲突、标签压缩）未在理论框架中给出。

---

## 948. Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow

**arXiv ID:** 2601.14243 | [PDF](https://arxiv.org/pdf/2601.14243v1)

**作者:** Haocheng Xi `[一作]` (NVIDIA), Ligeng Zhu `[通讯]` (NVIDIA)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种统一 FP8 精度流的 RL 训练框架 Jet-RL，解决 BF16‑train + FP8‑rollout 的离线不匹配导致的训练不稳定问题。

**💡 创新点**

创新点在于把训练与推理的量化精度保持完全一致，实现真正的 on‑policy FP8 训练，并采用细粒度（1×128/128×128）量化与 FP8 GEMM 加速。

**🔧 技术方法**

使用 FP8 量化、Per‑tensor/Per‑block 量化策略、FP8 TensorCore 内核、vLLM + VeRL 结合、Triton 实现量化与转置等技术。

**📊 数据集**

在 GSM8K、MATH 与 DeepMATH 三个算术/推理数据集上评估。

**📈 对比分析**

与 BF16 基线对比，Jet‑RL 在 8B‑16B 模型上保持不到 1% 的准确率损失；在 8K/16K rollout 长度下，速度提升分别为 1.33×（rollout）、1.41×（训练）和 1.16×（端到端）。

**⚠️ 局限性**

仍需针对更大模型、不同 RL 算法与更深层次的低精度训练（如 4‑bit）进行验证；实现依赖特定 FP8 内核和量化工具，可能影响移植性。

---

## 949. Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression

**arXiv ID:** 2601.14238 | [PDF](https://arxiv.org/pdf/2601.14238v1)

**作者:** Shaurya Mathur `[一作]` (University at Buffalo), Alina Vereshchaka `[通讯]` (University at Buffalo)

**通讯引用:** 67 | [OpenAlex ID](https://openalex.org/A5067785156)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出并实现了FireCastRL框架，将深度学习的火点预测与强化学习的航空灭火策略结合，生成火势威胁评估报告。

**💡 创新点**

一体化预测-响应链路，公开9.5M时空环境样本，利用CNN‑LSTM预测火点并在物理仿真中训练PPO helitack agent。

**🔧 技术方法**

CNN‑LSTM时空分类器、Proximal Policy Optimization强化学习、Rothermel火势模型、3D GIS仿真与多尺度CNN+LSTM策略网络。

**📊 数据集**

IRWIN火灾事件与GRIDMET气象数据整合，构建75天多变量序列，合并为9.5M标记样本。

**📈 对比分析**

与XGBoost、GB、RF、MLP等基线比较，CNN‑LSTM获得73.1%准确率；PPO agent在仿真中燃烧细胞数减至1529，资源使用显著低于规则基准。

**⚠️ 局限性**

无法处理人为点火导致的火灾、单一无人机代理、未考虑地面灭火与多代理协同等限制。

---

## 950. Q-learning with Adjoint Matching

**arXiv ID:** 2601.14234 | [PDF](https://arxiv.org/pdf/2601.14234v1)

**作者:** Qiyang Li `[一作]` (University of California Berkeley), Sergey Levine `[通讯]` (University of California Berkeley)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `40105733-5154-44cd-8090-a8cab9e64b07`

**🎯 论文内容**

利用adjoint matching技术，构造不需要对扩散/流模型进行反向传播的step‑wise目标，从critic的动作梯度中直接提取具有行为约束的最优策略，并将其与TD学习相结合，提出一种新的Q‑learning算法QAM。

**💡 创新点**

创新点在于：①将adjoint matching引入强化学习，解决了传统通过back‑prop对多步denoising过程求梯度导致的不稳定问题；②利用该目标保证收敛到先验正则化的最优策略（π∝πβ·e^{Q}）；③在offline及offline‑to‑online设置中提供了可调的Wasserstein约束与动作编辑方案，进一步提升表达能力。

**🔧 技术方法**

主要技术包括：adjoint matching、流/扩散策略、TD‑backup、critic集成、Wasserstein距离约束、动作剪裁与梯度裁剪、动作编辑策略、以及基于行为克隆的目标。

**📊 数据集**

使用OGBench平台的50个任务（10个域×5任务/域），每个任务均采用动作块化（chunking）策略；实验涵盖离线训练、离线‑到‑在线微调、以及在受噪声或数据截断的版本上的鲁棒性测试。

**📈 对比分析**

与8类代表性基线（Gaussian、Backprop、Advantage‑Weighted、Guidance、Post‑Processing等）在offline、offline‑to‑online和在线微调任务上对比，QAM在总分数上最高（offline 44、结合FQL/FE后分别为45/46），在大多数任务上显著优于FAWAC、BAM、FBRAC、QSM等；在在线微调中表现更稳健，尤其对噪声数据集的鲁棒性突出。

**⚠️ 局限性**

局限性：①对critic梯度的质量高度敏感，若critic不收敛或梯度不稳定会影响训练；②当最优动作在行为分布支持外时，单纯的KL约束易受限，需放宽或引入Wasserstein约束；③算法需要调节温度、流步数、梯度裁剪等超参，复杂度较高；④目前仅在模拟环境验证，尚未在真实机器人上展示效果。

---

## 951. Generalization and Completeness of Stochastic Local Search Algorithms

**arXiv ID:** 2601.14212 | [PDF](https://arxiv.org/pdf/2601.14212v1)

**作者:** Daniel Loscos `[一作]` (Universidad Complutense de Madrid), Ismael Rodriguez `[通讯]`

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出一种统一的形式化模型，能够用参数化方式定义所有已知的随机局部搜索（SLS）算法，并证明该模型及其实例（GA、PSO、ACO）是图灵完备的；

**💡 创新点**

创新点在于构造了最小化参数、最大化公共结构的形式化框架，并通过该框架给出对SLS图灵完备性的严格证明，从而揭示SLS算法不可预测性和相关属性的不可判定性；

**🔧 技术方法**

采用正式语义学、可执行的抽象语法与参数化构造、图灵机模拟、MPCP（修改版对应问题）归约等理论技术；

**📊 数据集**

未使用任何实际数据集；

**📈 对比分析**

未进行实验对比，核心成果是理论证明而非性能评估；

**⚠️ 局限性**

局限在于仅证明了SLS的图灵完备性和不可判定性，未提供具体算法优化或对特定问题的应用指导，并且未讨论在实践中如何克服不可判定性带来的影响。

---

## 952. Storage-Rate Trade-off in A-XPIR

**arXiv ID:** 2601.14202 | [PDF](https://arxiv.org/pdf/2601.14202v1)

**作者:** Mohamed Nomeir `[一作]` (University of Maryland), Sennur Ulukus `[通讯]` (University of Maryland)

**通讯引用:** 13727 | [OpenAlex ID](https://openalex.org/A5021132487)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

研究了在给定通信矩阵的 A-XPIR 环境下，服务器存储与下载成本的权衡。

**💡 创新点**

首次将通信不对称与安全性结合，给出 N=4、K=2 的可达区间与容量解析，并提出基于分组的存储优化。

**🔧 技术方法**

使用信息论容量分析、线性编码、Ingleton 不等式与通信矩阵优化。

**📊 数据集**

论文主要是理论研究，无实验数据集。

**📈 对比分析**

通过对比无安全约束的 PIR 性能，证明在安全条件下可实现相同下载率但存储更高效，容量达 1/3。

**⚠️ 局限性**

仅考虑了无协作服务器或特定协作结构，缺乏对更一般的通信/协作模式的完整分析。

---

## 953. ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction

**arXiv ID:** 2601.14165 | [PDF](https://arxiv.org/pdf/2601.14165v1)

**作者:** Zhenghong Li `[一作]` (Stony Brook University), Haibin Ling `[通讯]` (Stony Brook University)

**通讯引用:** 35154 | [OpenAlex ID](https://openalex.org/A5061469520)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

提出了一种针对光学多普勒层析（ODT）稀疏采样的重建网络 ASBA，用两支路分别处理幅度和相位，并通过 A‑line ROI 状态空间模型、B‑line 相位注意力和流量加权损失实现高效重建。

**💡 创新点**

创新点在于：① 在 A‑line 方向使用 ROI 引导的状态空间模型（A‑RS）突出血流区域；② 在 B‑line 方向构造基于相位差的注意力（B‑PA）捕捉长程流动依赖；③ 引入流量加权损失让网络聚焦血流信号；④ 两支路架构显著提升稀疏采样下的恢复质量。

**🔧 技术方法**

主要技术包括：Mamba 变体状态空间模型、深度卷积与通道注意力、相位差计算与 1D 关注机制、绝对值相位差相似度、滑动对齐、流量加权 MSE 损失，以及传统的 IFFT 与 Doppler 相位差估计。

**📊 数据集**

使用了两套实时采集的小鼠大脑皮层数据集：Wake MCD‑AW（清醒小鼠）和 Anesthetized MCD‑AN（麻醉小鼠），每套包含 20 个 3D ODT 体积（训练 14，测试 6），每体积 500 张 256×12600 的原始 B‑scan。

**📈 对比分析**

与传统稠密采样 ODT、最新稀疏 ODT 方法 ASSAN 以及多种单图像超分辨率方法（SwimIR、HAT、SRFormer、DAT、CFAT、MambaIR、MambaIRv2、MaIR、ASSAN）做对比。ASBA 在 ×8/×16 稀疏率下平均提升 1.0 dB PSNR、1.5 dB MIP‑PSNR、0.09 SSIM，DICE 进一步提升 5–10 %，同时 FLOPs 与推理时间最低（148 G FLOPs、73.9 ms）。

**⚠️ 局限性**

局限性包括：① 数据集规模较小，模型泛化性尚待验证；② 主要针对光学多普勒层析，对其他成像模态的适用性未评估；③ 在极高稀疏率（>×32）下的重建效果仍未知；④ 需要先验的血流 ROI 计算，若血流分布异常可能影响性能。

---

## 954. Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law

**arXiv ID:** 2601.14160 | [PDF](https://arxiv.org/pdf/2601.14160v1)

**作者:** Ali Hamza Bashir `[一作]` (Fraunhofer IAIS), David Berghaus `[通讯]` (Fraunhofer IAIS)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

针对德国法律问答，提出并实现了基于法条的难度分级合成数据生成与过滤流水线，用于对开源LLM进行LoRA微调。

**💡 创新点**

创新在于将法条直接转化为多层难度的问答，结合LLM审阅过滤，生成高质量、合法性强的合成训练集，避免人工标注与无效合成的局限。

**🔧 技术方法**

采用GPT-4/5进行指令式生成和审核、难度分级提示工程、LoRA参数高效微调、LLM‑as‑judge评估。

**📊 数据集**

使用德国民法典(BGB)、刑法(StGB)、社会法(SGB)、基本法(GG)的条文文本作为源，构造四级问答，并在LegalMC4中提取真实法律文档进行评测。

**📈 对比分析**

将生成数据与单一提示基线对比，在四个评测集（BGB QA/MCQ、LegalMC4 QA/MCQ）上使用LLM判分或准确率评估；难度分级数据+过滤后，Gemma3/ LLaMA3.1的法律问答准确率分别提升约40%和20%，并保持或略优的通用推理性能。

**⚠️ 局限性**

限制在于对法律检索和动态法条更新支持不足，评测仍局限于静态条文，且高质量合成需依赖强大LLM生成与审核，产生成本。

---

## 955. Rerank Before You Reason: Analyzing Reranking Tradeoffs through Effective Token Cost in Deep Search Agents

**arXiv ID:** 2601.14224 | [PDF](https://arxiv.org/pdf/2601.14224v1)

**作者:** Sahel Sharifymoghaddam `[一作]` (University of Waterloo), Jimmy Lin `[通讯]` (University of Waterloo)

**通讯引用:** 21986 | [OpenAlex ID](https://openalex.org/A5082997975)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在深度搜索代理中研究推理预算分配，并评估列表式重排序对检索质量和端到端准确率的影响

**💡 创新点**

提出了“有效令牌成本（ETC）”度量来平衡硬件/财务成本与推理效果，并证明中等深度重排序比增加推理预算更具成本效益

**🔧 技术方法**

使用大型语言模型（gpt‑oss‑20b、gpt‑oss‑120b）作为搜索与重排序器，结合 qwen3‑embedding‑8b 检索器，采用 vLLM 并行推理

**📊 数据集**

在 BrowseComp‑Plus 公开数据集上进行实验，该数据集提供人工验证的文档集合和多跳检索任务

**📈 对比分析**

通过对比不同模型规模、推理预算和重排序深度（d=0,10,20,50），发现重排序可显著提升 Recall@5、NDCG 和答案准确率，而额外 ETC（尤其在 β=3 时）增长缓慢；中等深度重排序可获得与高推理预算相当的准确率，但令牌成本更低

**⚠️ 局限性**

实验仅使用同一模型族、固定人类验证的文档库、固定 top‑d 重排序，以及未采用历史压缩或动态子集选择，可能限制了结果的普适性和进一步节省令牌的潜力

---

## 956. InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning

**arXiv ID:** 2601.14209 | [PDF](https://arxiv.org/pdf/2601.14209v1)

**作者:** Matthew Y. R. Yang `[一作]` (Carnegie Mellon University), Aviral Kumar `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Intervention Training（InT）方法，让 LLM 在自身推理过程中通过自我验证定位第一个错误并生成单步干预，随后对干预进行监督微调并继续 RL 训练，以改进推理信用分配。

**💡 创新点**

创新点在于：1）使用模型自身的验证能力（对比参考解）实现精准错误定位；2）直接生成单步纠正干预而非全局奖励模型或多分支 roll‑out；3）通过 SFT 内化干预模式，为后续 RL 提供更高质量的 on‑policy 样本，从而显著降低“零优势”问题。

**🔧 技术方法**

技术手段包括：大规模 LLM（如 Qwen3‑4B‑Instruct、Qwen3‑30B‑A3B‑Instruct），双阶段 prompt 设计（错误定位 + 干预生成），监督微调（SFT）与标准 outcome‑reward RL（GRPO），以及参考解的 diff 方式验证。

**📊 数据集**

数据集：在 4500+ 个难度筛选后的数学推理题（来源于 Polaris、AceReason‑Math、Omni‑MATH 及 IMO‑AnswerBench）上生成 1076 个干预样本；测试集包括 IMO‑AnswerBench、HMMT 2025 Nov、AMO‑Bench、Apex Shortlist 等公开基准。

**📈 对比分析**

对比方法：标准 RL、Reference‑Solution SFT+RL、Self‑Reflection SFT+RL、Hint‑guided RL 等。Intervention Training+RL 在训练集奖励最高、零优势比例最低，并在 IMO‑AnswerBench 的 Pass@1 由 11.7% 提升至 25.6%（≈59% 绝对提升），在 HMMT、AMO‑Bench、Apex Shortlist 等基准同样领先。

**⚠️ 局限性**

局限性：① 需要人工或预先生成的参考解；② 对模型的指令遵循和错误检测能力高度依赖；③ 目前仅针对单步干预，难以处理多步错误链；④ 训练集中对问题难度的筛选可能限制通用性；⑤ 仍未实现完全自我生成问题与验证的闭环。

---

## 957. Analyzing Far-Right Telegram Channels as Constituents of Information Autocracy in Russia

**arXiv ID:** 2601.14190 | [PDF](https://arxiv.org/pdf/2601.14190v1)

**作者:** Polina Smirnova `[一作]` (University of Milan), Mykola Makhortykh `[通讯]` (University of Bern)

**通讯引用:** 1618 | [OpenAlex ID](https://openalex.org/A5087601816)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `67630363-6be0-4f51-ab05-7198250671a5` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究俄罗斯极右翼Telegram社区如何通过meme共创信息化专制的合法化与非合法化叙事，分析其对政治人物形象的塑造作用。

**💡 创新点**

首次将大规模视觉数据与无监督聚类相结合，系统量化非官方参与者对官方宣传的共同生产；揭示meme在极右翼网络中的传播与叙事构建机制。

**🔧 技术方法**

使用计算机视觉技术（人脸检测、Amazon Rekognition人脸识别）、多任务CNN、无监督聚类以及元数据文本分析。

**📊 数据集**

约20万张来自俄语极右翼Telegram频道的图片及其发布日期、文本说明、转发状态等元数据。

**📈 对比分析**

目前以描述性统计和人脸识别验证为主，未进行模型对比或性能指标评估；后续将通过视觉特征聚类评估合法化/非合法化模式，并与官方宣传文本做对比。

**⚠️ 局限性**

局限在于：只保留含人脸的图片，忽略无脸或纯文本meme；验证样本有限，识别准确率受限；尚未完成语义内容分析与跨平台对照；缺乏公开可复现的代码与完整数据集。

---

## 958. IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models

**arXiv ID:** 2601.14188 | [PDF](https://arxiv.org/pdf/2601.14188v1)

**作者:** Liang Shi `[一作]` (Northeastern University), Yun Fu `[通讯]` (Northeastern University)

**通讯引用:** 30782 | [OpenAlex ID](https://openalex.org/A5005819096)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种IIR‑VLM模型，通过在视觉编码器中注入专门的实例识别专家，实现在上下文中一次性学习并识别实例；

**💡 创新点**

将实例识别专家作为辅助视觉编码器并通过注意力融合，同时采用两阶段轻量化微调，避免了昂贵的逐实例微调；

**🔧 技术方法**

使用注意力融合的多模态视觉编码器、投影器、Qwen2.5‑VL‑3B‑Instruct基础VLM、专家模型（如PLIP、ArcFace、DINOv2微调版）以及投影器微调；

**📊 数据集**

利用公开的人体Re‑ID、VGGFace、宠物数据集、Stanford Online Product等，构建跨四类（人、脸、宠物、通用物体）的ILR基准；

**📈 对比分析**

在新构建的ILR基准和MM‑ID基准上与Gemini 2.5 Pro、Qwen2.5‑VL‑7B、IDA‑VLM等对比，IIR‑VLM平均精度达91.3 %（识别）/88.5 %（识别+描述），显著优于现有VLM和无实例微调方法；

**⚠️ 局限性**

仍受限于高视觉相似度任务下的误判、对非支持类别的泛化能力有限，以及在实例描述时偶尔过于保守，未能完全取代昂贵的逐实例微调。

---

## 959. Stabilizer-Assisted Inactivation Decoding of Quantum Error-Correcting Codes with Erasures

**arXiv ID:** 2601.14236 | [PDF](https://arxiv.org/pdf/2601.14236v1)

**作者:** Giulio Pech `[一作]` (Duke University), Henry D. Pfister `[通讯]` (Duke University)

**通讯引用:** 4552 | [OpenAlex ID](https://openalex.org/A5034044119)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

提出一种基于双重消除（dual‑peeling）的量子失效（erasure）解码器，能够在失效错误模型下对 CSS/QLDPC 码实现最大似然（ML）或接近 ML 的解码。

**💡 创新点**

创新点在于：①在标准的消除+无效化（inactivation）流程前先进行“双重消除”，识别所有仅作用于失效位的 stabilizer 并对其自由度进行“free‑fix”，从而显著减少后续无效化猜测的数量；②证明对表面码（surface code）此双重+单纯消除即可达到 ML 性能；③通过实验验证该方法在多类 QLDPC 码上将解码复杂度降低 20% 以上。

**🔧 技术方法**

使用技术包括：经典 Erasure 码的消除（peeling）与无效化（inactivation）解码、基于 stabilizer 矩阵的行运算双重消除、Gaussian 消元求解残余线性系统、CSS 码的张量结构与哈普菲尔德（hypergraph product）构造。

**📊 数据集**

测试数据集：多种 QLDPC 码族（B1、HGP、Surface13、Surface21、Lifted Product 1.8、360、BB108、BB144、BB288 等），在失效率 p ∈ [0.24,0.48] 进行 Monte‑Carlo 逻辑错误率仿真。

**📈 对比分析**

与单纯消除、无效化、硬猜测等传统方案对比：在所有码族上，双重消除 + 消除 的逻辑错误率与 ML 相当；无效化+双重消除的符号猜测次数显著下降，解码复杂度从 O(n³) 降到 O(n²)（或更低），并在 Surface 码上实现了线性时间 ML 解码。

**⚠️ 局限性**

局限性：仅针对失效通道（BEC），未对一般噪声（Pauli 或 depolarizing）给出完整解码方案；对非 CSS 或更稠密的量子 LDPC 码的适用性尚未验证；算法实现仍需高效的行操作与内存管理。

---

## 960. KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning

**arXiv ID:** 2601.14232 | [PDF](https://arxiv.org/pdf/2601.14232v1)

**作者:** Egor Cherepanov `[一作]`, Aleksandr I. Panov `[通讯]` (Cognitive AI Systems Lab)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出 KAGE-Env 与 KAGE-Bench，构建了一个 2D 平台游戏环境，能够通过 93 个可控视觉轴（背景、角色、干扰物、特效、滤镜、布局等）单独改变观察过程，并在此基础上创建 34 对训练‑评估配置，系统评估 pixel‑based RL 在纯视觉分布偏移下的泛化能力。

**💡 创新点**

创新点在于：
1) 通过“已知轴”设计将视觉变化拆解为独立控制的维度，消除环境动态或奖励的混淆，能够精确归因泛化缺陷；
2) 使用 JAX 原生实现，利用端到端编译和向量化，可在单 GPU 上达到 33M 步/秒，支持大规模并行评估；
3) 在同一基准上提供多种指标（距离、进度、成功率、回报）与最大化训练统计，避免仅靠回报隐藏失败。

**🔧 技术方法**

主要技术包括：
- JAX 与 vmap/jit 并行仿真；
- 可插拔视觉渲染模块，支持图像、颜色、光照、滤镜等参数；
- PPO‑CNN 作为基线策略；
- 通过将像素策略映射到隐状态的条件动作分布实现理论分析；
- 对 34 个配置对进行最大训练收益统计与跨轴比较。

**📊 数据集**

使用的“数据集”是 KAGE-Env 自带的视觉资产库：128 张背景图、27 个角色与 NPC 皮肤、9 种几何形状、21 种颜色，以及可配置的光照、滤镜等参数。实验并不依赖外部数据集，而是在同一环境中通过参数变换产生不同视觉分布。

**📈 对比分析**

比较方法：
- 在每个 train‑eval 配对上训练 10 条随机种子，记录训练期间每个指标的最大值；
- 在所有配对内统计均值±SEM，并按轴聚合。与 baseline（PPO‑CNN）在原始训练配置下的表现对比。
- 结果显示：背景、滤镜和光效轴导致成功率下降高达 80%+，而角色外观和干扰物轴的下降仅 20% 左右。回报与距离虽然有一定下降，但成功率的骤降说明仅靠回报评价会误导。

**⚠️ 局限性**

局限性：
- 只覆盖单一平台游戏任务，无法直接推广到三维或更复杂的控制环境；
- 仅测试了 PPO‑CNN，缺乏对其他先进感知/强化学习算法的评估；
- 视觉轴的分离在理论上有效，但实际渲染过程中仍可能存在细微耦合；
- 关注点为视觉分布偏移，未涉及动态环境变化或奖励重构等其他鲁棒性挑战。

---

## 961. VideoMaMa: Mask-Guided Video Matting via Generative Prior

**arXiv ID:** 2601.14255 | [PDF](https://arxiv.org/pdf/2601.14255v1)

**作者:** Sangbeom Lim `[一作]` (Korea University), Joon-Young Lee `[通讯]` (Adobe Research)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出 VideoMaMa 模型，利用预训练的视频扩散模型将二值分割掩码转化为高质量 alpha matte，并基于此生成 MA‑V 大规模伪标注视频数据集。

**💡 创新点**

创新点在于：①通过扩散模型的生成先验实现 mask‑guided matting；②采用两阶段训练（先高分辨率空间层再低分辨率时间层）与 DINOv3 语义知识注入，解决真实视频域差距并保持细节与时序一致；③构建 MA‑V 数据集，突破合成数据局限。

**🔧 技术方法**

技术手段包括：Stable Video Diffusion + VAE、单步扩散推理、mask degradation 以及两阶段训练、DINOv3 语义注入、像素级 L1+Laplacian 损失。

**📊 数据集**

使用 SA‑V（用于生成 MA‑V）、VideoMatte240K、VideoMatting108、VM800、V‑HIM60、YouTubeMatte 等真实与合成视频数据集；MA‑V 共 50k+ 视频。

**📈 对比分析**

与 MaGGIe、MGM、MatAnyone 以及 SAM2 原版等方法对比，在所有帧 mask‑guided 与首帧 mask‑guided 评测中，VideoMaMa 与 SAM2‑Matte 在 MAD、梯度误差等指标上均超过现有 SOTA，SAM2‑Matte 在 V‑HIM60 Hard 与 YouTubeMatte 上取得最优成绩。

**⚠️ 局限性**

主要限制：mask‑guided 方式无法纠正完全错误或误标的掩码；SAM2 的低分辨率解码器限制了高频细节的保留。

---

## 962. Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis

**arXiv ID:** 2601.14253 | [PDF](https://arxiv.org/pdf/2601.14253v1)

**作者:** Hongyuan Chen `[一作]` (Westlake University), Anpei Chen `[通讯]` (Westlake University)

**通讯引用:** 759 | [OpenAlex ID](https://openalex.org/A5060917495)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `4de8e9d8-757b-475f-9627-18a445e50202` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种可直接从单目视频和可选参考网格生成高质量4D动态对象的前馈框架 Motion 3-to-4，能够在保持空间一致性的同时合成完整的时空几何；

**💡 创新点**

创新点在于将4D生成拆分为静态3D形状合成与动态运动重建两部分，并利用可选参考网格学习紧凑运动潜在表示，实现对任意长度序列的实时推断；

**🔧 技术方法**

核心技术包括基于点云的几何编码器、DINOv2视觉编码、交互式注意力的运动潜在学习、基于查询的跨注意力解码器以及帧级 Transformer；

**📊 数据集**

使用自建的 Motion‑80 基准（包含 80 个带真实几何的动画序列）和 Consistent4D 基准，并在 Objaverse/Objaverse‑XL 采集的 16k 对象上训练；

**📈 对比分析**

与 L4GM、GVFD、V2M4 等最先进方法比较，实验显示在几何 CD/F‑Score 以及外观 LPIPS/CLIP/DreamSim 等指标上均实现显著提升，且在长序列和外部视角下保持更好的时空一致性；

**⚠️ 局限性**

局限性包括：对参考网格拓扑的依赖导致当对象部件未清晰分离时出现顶点粘连；无法处理后期出现的拓扑变更；以及对非常稀疏或高度复杂形状的重建仍不够稳健。

---

## 963. LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR

**arXiv ID:** 2601.14251 | [PDF](https://arxiv.org/pdf/2601.14251v1)

**作者:** Said Taghadouini `[一作]` (LightOn), Baptiste Aubertin `[通讯]` (LightOn)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

开发了1B参数的端到端多语言 OCR 视觉‑语言模型 LightOnOCR‑2‑1B，并在模型中加入了图片定位（bbox）功能；

**💡 创新点**

创新点包括：大规模清洗的 43M 页训练混合、使用强化学习可验证奖励（RLVR）针对 OCR 失败模式进行微调、在预训练阶段加入坐标监督并通过 RLVR 进一步优化定位、以及利用轻量化权重技巧（权重平均、任务算术合并）实现 OCR 与定位的显式权衡；

**🔧 技术方法**

使用了 Vision Transformer 作为视觉编码器、两层 MLP 多模态投影、Transformer 解码器、RLVR（GRPO）与 IoU 奖励、FlashAttention‑2、bf16 精度、以及权重平均和任务算术合并等技术；

**📊 数据集**

训练数据主要来自 43M 页的预训练混合，其中包括 PDFA、扫描文档、法国与其他欧洲语言文本、arXiv 学术 PDF、以及公开 OCR 数据集；

**📈 对比分析**

在 OlmOCR‑Bench 上取得 83.2 的最高得分，速度达到 5.71 页/秒，且在自建的 LightOnOCR‑bbox‑bench 上 F1@0.5 超过 0.78，显著优于 9B 规模模型；

**⚠️ 局限性**

主要局限性是：对拉丁文字母体系的印刷文档最适用，对非拉丁语系（如 CJK、阿拉伯语）和手写文本的支持不足；

---

## 964. Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment

**arXiv ID:** 2601.14249 | [PDF](https://arxiv.org/pdf/2601.14249v1)

**作者:** Yuming Yang `[一作]` (Fudan University), Xuanjing Huang `[通讯]` (Fudan University)

**通讯引用:** 16353 | [OpenAlex ID](https://openalex.org/A5088834359)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了在推理蒸馏中数据与学生模型的匹配问题，提出一种基于rank‑surprisal比值的指标来衡量推理轨迹对学生的适用性。

**💡 创新点**

创新点在于将信息量（surprisal）与相对熟悉度（rank）结合，形成一条简单可解释的度量，并证明其能较好预测后训练性能。

**🔧 技术方法**

使用的方法包括token级别的surprisal与rank计算、对轨迹的加权平均与截断，构成最终的R-score；以及在不同教师–学生对上进行SFT实验。

**📊 数据集**

数据集方面使用了5000道数学推理题（AIME'25/24、AMC'23、MATH500）以及GPQA，教师轨迹由11个规模从4B到671B的推理LLM生成。

**📈 对比分析**

与众多基线（概率、rank、规则、LLM质量、梯度影响等）相比，R-score在所有5个学生模型上的Spearman相关均超过0.85，并在轨迹/教师选择任务中取得最优或接近oracle的性能。

**⚠️ 局限性**

局限性包括对可用教师轨迹的依赖、对非数学推理任务的可推广性未知，以及缺乏更深层理论解释。

---

## 965. Transformer Architectures for Respiratory Sound Analysis and Multimodal Diagnosis

**arXiv ID:** 2601.14227 | [PDF](https://arxiv.org/pdf/2601.14227v1)

**作者:** Theodore Aptekarev `[一作]` (Ben Gurion University of Negev), Gregory Furman `[通讯]` (Ben Gurion University of Negev)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

在单中心儿童呼吸病院数据上，评估并比较了Audio Spectrogram Transformer（AST）和多模态 Vision‑Language Model（VLM）在5秒呼吸音片段中筛查哮喘的性能，并与先前的 DenseNet CNN 基线做公平对比。

**💡 创新点**

创新点包括：①将预训练的 AST 迁移到医疗呼吸音领域，实现高达97% 的准确率；②构建 VLM 通过结构化文本 Prompt 把语谱图与患者性别、年龄、录音点等元数据融合，实现诊断结果以 JSON 输出；③证明短5秒片段即可捕获足够的临床信息。

**🔧 技术方法**

使用技术包括：Transformer 结构（AST）与预训练权重迁移；Mel 频谱图与 RGB 处理；LoRA 微调与多模态 Prompt；注意力可解释性（Attention 视觉化）和 Grad‑CAM（CNN 解释）；以及 8‑bit Adam、余弦学习率调度等训练技巧。

**📊 数据集**

数据集为来自 Perm 州儿童医学大学的 1,371 名受试者的匿名呼吸音数据库，包含 1,113 例哮喘、133 例健康、367 例其他呼吸疾病，录音长度约 25 秒，采样率 22–96 kHz，记录点包括气管、胸部、背部、口腔。

**📈 对比分析**

通过在相同数据划分下训练 DenseNet、AST 与 VLM 三种模型，AST 在“哮喘 vs 非哮喘”任务上取得 97% 准确率、F1 ≈ 97% 以及 ROC‑AUC 0.98；VLM 达到 86–87% 准确率；而 DenseNet 约 87% 准确率，显示 AST 在单模态音频上显著优于传统 CNN，VLM 与 CNN 绩效相当。

**⚠️ 局限性**

限制包括：数据集单中心、设备与录音条件相对单一，缺乏跨域验证；Transformer 模型参数多、推理成本高；VLM 在准确率上未能超过 CNN，且目前仅输出诊断标签，缺乏可解释性文本；未对多模态模型的鲁棒性与泛化进行系统评估。

---

## 966. Beyond Polarization: Opinion Mixing and Social Influence in Deliberation

**arXiv ID:** 2601.14221 | [PDF](https://arxiv.org/pdf/2601.14221v1)

**作者:** Mohak Goyal `[一作]` (Stanford University), Kamesh Munagala `[通讯]` (Duke University)

**通讯引用:** 5394 | [OpenAlex ID](https://openalex.org/A5047351951)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过对三次大规模线上决议投票（MCF‑2022、MCF‑2023、SOF）的调查和讨论转录数据进行量化分析，研究了辩论如何改变意见的混合程度、方差以及平均回归，并进一步探究讨论特征与意见转变的机制。

**💡 创新点**

创新点在于首次引入 Kendall 相关系数衡量“意见混合”，揭示辩论可导致意见重新排序而非单纯收敛或极化；同时区分论证质量（正当化与新颖性）对意见转变的不同影响，为评估辩论效果提供更细粒度的诊断工具。

**🔧 技术方法**

使用 Kendall τ、方差变化、平均回归等统计指标，结合 GPT‑4/GPT‑4o 大语言模型对讨论语句进行立场、正当化质量与新颖性评分，并通过 OLS 回归与交互分析挖掘讨论特征与意见转变的关联。

**📊 数据集**

所用数据集为三次线上决议投票：MCF‑2022（n=6,342），MCF‑2023（n=1,529）和 SOF（n=617），涵盖 32 个国家、19 种语言，包含预后与后测调查结果以及完整的讨论转录。

**📈 对比分析**

对比无辩论控制组，结果显示辩论组的 Kendall τ 均显著下降（约 0.05–0.07，p<0.001），方差变化更异质；在 SOF 中，支持度对意见变化的回归系数为 1.60，正当化质量交互显著提升，证明模型能够解释并量化辩论的影响。

**⚠️ 局限性**

局限性包括：SOF 缺乏对照组，无法完全排除测量效应；排除“无意见”响应可能产生选择偏差；LLM 评分可能携带训练数据偏见；模型对讨论特征的解释依赖于假设，结果是否可推广到面对面或更强承诺的情境尚待验证。

---

## 967. Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting

**arXiv ID:** 2601.14208 | [PDF](https://arxiv.org/pdf/2601.14208v1)

**作者:** Nitin Kulkarni `[一作]` (ACV Auctions), Alina Vereshchaka `[通讯]` (University at Buffalo)

**通讯引用:** 67 | [OpenAlex ID](https://openalex.org/A5067785156)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `51c0528b-f690-4182-ae60-bb5f046c276c` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

使用三相机行驶捕捉车辆底盘视频，通过相机标定、同步、基于相机姿态先验的结构光束束调整以及基于DISK+LightGlue的特征匹配，生成稀疏点云并作为种子，随后利用3D高斯溅射（Gaussian splatting）得到高保真、实时可交互的底盘3D模型。

**💡 创新点**

创新点在于：① 针对宽角镜头引起的严重畸变提出一次性高精度相机标定与预畸变校正；② 设计两阶段视频同步算法实现亚帧级时间对齐；③ 在SfM中加入相机机架几何先验并采用DISK+LightGlue的学习型特征/匹配组合，显著提升低视差、宽角场景下的稀疏点云质量；④ 将SfM稀疏点云直接作为高斯溅射的初始化，缩短训练时间并获得更清晰的渲染结果。

**🔧 技术方法**

核心技术包括：ChArUco相机标定、相位相关与L1最小化的视频同步、DISK特征提取、LightGlue注意力匹配、COLMAP增量SfM、基于相机机架的束调整（pose prior）、3D Gaussian splatting（Kerbl等实现）。

**📊 数据集**

数据集为10辆不同品牌/型号车辆的实测数据，使用自制宽角相机机架拍摄三路视频（1920×1080，120fps），每辆车约8秒，共约960帧/相机，手工标记无公开数据集。

**📈 对比分析**

实验与基线（vanilla SfM、SIFT+COLMAP）以及各消除模块的消融对照，结果显示我们的完整管线在稀疏点云密度上提升至约427k点，重投影误差0.49像素；Gaussian splatting渲染在PSNR 30.66 dB、SSIM 0.92、LPIPS 0.19上显著优于基线（PSNR 23.46 dB、SSIM 0.78、LPIPS 0.42），并在RTX A6000上平均达到130 fps。

**⚠️ 局限性**

局限性包括：① 仅适用于直线行驶、均匀视角的车身底盘场景；② 需要硬件同步与三相机机架；③ 对极端光照或遮挡仍易产生点云稀疏；④ 目前尚未实现自动缺陷检测与量化，需要后续集成。

---

## 968. Copy-Trasform-Paste: Zero-Shot Object-Object Alignment Guided by Vision-Language and Geometric Constraints

**arXiv ID:** 2601.14207 | [PDF](https://arxiv.org/pdf/2601.14207v1)

**作者:** Rotem Gatenyo `[一作]` (Reichman University), Ohad Fried `[通讯]` (Reichman University)

**通讯引用:** 2115 | [OpenAlex ID](https://openalex.org/A5021513418)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `5b4c1114-4a70-478e-9921-2514ee03850d` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `4de8e9d8-757b-475f-9627-18a445e50202` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出一种基于文本指导的零样本三维网格对齐方法。

**💡 创新点**

创新点在于将CLIP视觉语言监督与分阶段软ICP和穿透惩罚结合，直接在测试时优化位姿与尺度。

**🔧 技术方法**

使用技术包括可微渲染、CLIP嵌入、分阶段优化、软ICP和穿透损失。

**📊 数据集**

数据集为自行构建的50对网格与文本提示的基准集。

**📈 对比分析**

与几种几何与LLM基线对比，本文方法在语义一致性和低交叉率上均优于对手。

**⚠️ 局限性**

局限包括仍可能出现轻微穿透、视角依赖性强以及极端尺度差异导致梯度弱。

---

## 969. Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance

**arXiv ID:** 2601.14171 | [PDF](https://arxiv.org/pdf/2601.14171v1)

**作者:** Qianli Ma `[一作]` (Shanghai Jiao Tong University), Zhipeng Zhang `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 6088 | [OpenAlex ID](https://openalex.org/A5100410140)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了一套多代理RebuttalAgent框架，利用结构化工作流辅助作者在审稿答复中以证据驱动的方式回应评审意见。

**💡 创新点**

将 rebuttal 视为决策与证据组织任务，提出“先检验后写作”流程，生成可检查的关注点、证据束和回应计划，从而显著提升覆盖度、可信度和全局一致性。

**🔧 技术方法**

基于大型语言模型的多代理协同，包括关注点提取、压缩摘要、混合上下文构建、外部搜索检索、检查器验证与规划器以及最终撰写器，并结合检索增强、证据可视化与人机交互。

**📊 数据集**

采用自建的 RebuttalBench（来自 ICLR OpenReview 讨论数据），包含 9.3K 评审‑答复对和 20 篇论文的挑战集用于评估。

**📈 对比分析**

与 GPT‑5‑mini、Grok‑4.1、Gemini‑3‑Flash、DeepSeekV3.2 等闭源 LLM 的直接文本生成基线同基模型对比，使用 LLM‑judge 打分，RebuttalAgent 在相关性、论证质量与沟通质量上均提升 0.3‑0.8 分，尤其在弱模型上提升更显著。

**⚠️ 局限性**

仍需人工检查与校对，对复杂推理与新实验设计能力有限，系统运行成本相对较高，并高度依赖高质量的外部检索资源。

---

## 970. OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer

**arXiv ID:** 2601.14250 | [PDF](https://arxiv.org/pdf/2601.14250v1)

**作者:** Pengze Zhang `[一作]` (ByteDance), Mingyuan Gao `[通讯]` (ByteDance)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了OmniTransfer，一种统一的时空视频转移框架，可同时实现身份、风格、运动、相机运动和特效的迁移。

**💡 创新点**

创新点在于三大模块：任务感知位置偏置（Task-aware Positional Bias）以增强时空一致性，参考解耦因果学习（Reference-decoupled Causal Learning）避免复制粘贴并提升速度，以及任务自适应多模态对齐（Task-adaptive Multimodal Alignment）利用MLLM实现跨任务语义对齐。

**🔧 技术方法**

技术基础是Wan2.1 I2V 14B扩散模型，结合3D RoPE位置编码、Diffusion Transformer、Reference Latent构造、MLLM（Qwen‑2.5‑VL）与LoRA微调，以及多模态多查询策略。

**📊 数据集**

数据集为作者自行从互联网上收集的多任务视频样本，包含约50条身份视频、20种风格、50条特效、50条相机运动与50条舞蹈视频，未使用公开标注的参考视频对。

**📈 对比分析**

通过与ConsisID、Phantom、Stand‑in（身份）、StyleCrafter、StyleMaster（风格）、Wan2.1 I2V、Seedance（特效）、MotionClone、CamCloneMaster（相机运动）、MimicMotion、WanAnimate（运动）等SOTA方法对比，OMNI在CLIP‑T、VSim、VCSD、用户评分等指标上均优于或相当，且运行时间缩短约20%。

**⚠️ 局限性**

局限性包括依赖自己收集的数据，缺乏大规模公开参考视频对；对极端复杂场景的适应性待验证；仍需显著算力（如A100 GPU），并且在实时性方面尚不成熟。

---

## 971. Soft Tail-dropping for Adaptive Visual Tokenization

**arXiv ID:** 2601.14246 | [PDF](https://arxiv.org/pdf/2601.14246v1)

**作者:** Zeyuan Chen `[一作]` (University of California San Diego), Yuanjun Xiong `[通讯]` (Adobe)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Soft Tail-dropping Adaptive Tokenizer（STAT），一种自适应的 1D 视觉分词器，能够根据图像复杂度动态决定输出 token 数量，并生成可直接用于 1D 自回归生成模型的序列。

**💡 创新点**

创新点：
1) 软尾部丢弃机制——对每个 token 预测 keep 概率并通过 Bernoulli 采样实现 token 数量的自适应控制；
2) 强制概率曲线单调递减，使生成模型可采用 EoS token 进行可变长度推断；
3) 引入内容适应性先验，将 token 数量与图像的感知复杂度（如 LPIPS / JPEG 大小）正相关；
4) 通过稀疏 KL 正则控制全局 token 预算，实现可调节的压缩率。

**🔧 技术方法**

主要技术：
- ViT 编码器 + 1D latent token 结合
- Vector‑Quantized autoencoder（VQ）量化
- 位置感知 MLP 预测 keep 概率
- 软尾部丢弃（soft tail‑dropping）
- 三种正则损失（monotonic, content‑adaptive, sparsity）
- 直通估计（STE）实现梯度流通
- 与 vanilla 自回归模型结合（支持 EoS token）。

**📊 数据集**

使用的数据集：
- ImageNet‑1k（256×256）用于训练、重构评估与图像生成；
- LAION‑2B 语料用于文本条件生成评估；
- 视频数据集（16 帧 clip）用于视频重构评估。

**📈 对比分析**

比较方法与性能：
- 在 ImageNet‑1k 验证集上与 2D VQ‑VAE、TiTok、LlamaGen VQ 等 tokenizers 比较，STAT 在 rFID 下降 30–50%，PSNR 稍逊但保持更低 token 数量；
- 与 vanilla 自回归模型结合时，STAT 的 gFID、IS、Precision/Recall 与最新的 diffusion / 复杂 AR 模型相当甚至优于，且显著低于固定 token 长度的基线；
- 文本条件生成上，STAT 在 GenEval 评测中均分上优于 LlamaGen VQ；
- 视频重构上，STAT‑Video 在 PSNR / LPIPS 方面领跑所有比较方法，rFVD 与主流方法持平。

**⚠️ 局限性**

limitations：
- 需要额外的 keep 概率学习与多项正则，训练过程更复杂；
- 对阈值 τ、稀疏目标 p* 等超参数敏感，需细致调参；
- 软 tail‑dropping 机制在极大模型规模或极端复杂场景下收敛速度慢；
- 目前仅在静态图像和短视频上验证，跨域（如真实视频流、3D 纹理等）还需进一步探索。

---

## 972. XR: Cross-Modal Agents for Composed Image Retrieval

**arXiv ID:** 2601.14245 | [PDF](https://arxiv.org/pdf/2601.14245v1)

**作者:** Zhongyu Yang `[一作]` (Heriot-Watt University), Yingfang Yuan `[通讯]` (Heriot-Watt University)

**通讯引用:** 80 | [OpenAlex ID](https://openalex.org/A5091219117)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种基于多智能体的训练‑无监督框架 X^R，用于完成由参考图像与文本改动组成的组合图像检索任务。

**💡 创新点**

创新点在于将想象、粗过滤与细过滤三阶段多模态智能体协同工作，利用跨模态生成、跨模态相似度融合和事实问答验证，实现从粗到细的递进推理；并且完全不需要任务专门训练。

**🔧 技术方法**

核心技术包括跨模态生成（InternVL3‑8B 生成目标描述），双编码器 CLIP（ViT‑L/14 & ViT‑B/32）进行文本‑图像相似度评估，逆序等级融合（RRF）与跨模态问答验证（Q‑A 形式）进行候选精细化。

**📊 数据集**

在 FashionIQ、CIRR、CIRCO 三大公开检索基准上进行实验，覆盖时尚、自然图像与大规模多目标检索场景。

**📈 对比分析**

与九种基准（包括训练‑基与训练‑无监督）对比，X^R 在 FashionIQ 上 R@10 提升约 8% 以上，CIRR_subset R@3 达 95.21%，CIRCO mAP@50 提升 7% 以上，整体提升可达 38% 的相对增幅，且各模块 ablation 证明其互补性。

**⚠️ 局限性**

主要局限包括对大规模多模态预训练模型的高依赖、相对较高的计算与推理延迟、以及在更复杂或多任务场景下对推理深度与鲁棒性仍有提升空间。

---

## 973. MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems

**arXiv ID:** 2601.14230 | [PDF](https://arxiv.org/pdf/2601.14230v1)

**作者:** Yiyang Wang `[一作]` (Georgia Institute of Technology), Josiah Hester `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 1996 | [OpenAlex ID](https://openalex.org/A5026852792)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种多视角社交协作伙伴的多智能体框架，解决了 persona 崩塌和社交同谋问题，实现在情感支持与工作协作场景中的高质量对话；

**💡 创新点**

创新点包括：bi‑level 优化策略，先通过 RLAIF 训练个体的 persona 一致性，再用 Meta‑Agent 通过群体奖励实现对话协作与多样性；引入 GRPO 低成本高效的 RL 训练；以及将个体与集体目标统一在同一框架内；

**🔧 技术方法**

核心技术包括：强化学习自 AI 反馈（RLAIF）+ 规则基格式奖励、Group Relative Policy Optimization（GRPO）、Meta‑Agent 指令生成、指令‑响应层级化生成与基于群体奖励的导演训练；

**📊 数据集**

主要数据集为 Empathetic Dialogues（ED）和 QMSum（工作协作对话），以及 16 种 MBTI 角色的模拟交互，覆盖情感正面、负面及中性子集；

**📈 对比分析**

与零样本、少样本提示、SFT、Chain‑of‑Thought、Self‑Consistency 及 MultiAgentESC 等基线对比，Persona Consistency 提升最高 +14.1，Social Contribution +10.6，情感支持得分 76.2（相比零样本 CoT 约 60.5）表现突出；

**⚠️ 局限性**

局限性：训练过程需要可访问模型权重的开源体系，难以直接迁移到闭源大模型；目前仅在英文环境验证，跨语言与跨文化适配仍待研究；在极高强度负面情绪场景下表现仍相对薄弱。

---

## 974. Unification of Deterministic Higher-Order Patterns

**arXiv ID:** 2601.14211 | [PDF](https://arxiv.org/pdf/2601.14211v1)

**作者:** Johannes Niederhauser `[一作]` (University of Innsbruck), Aart Middeldorp `[通讯]` (University of Innsbruck)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c`

**🎯 论文内容**

提出了一种对确定性高阶模式（DHP）进行完整统一的推理系统，能够生成最小完整的统一集。

**💡 创新点**

去除了FCU的全局约束并在灵活-灵活对中提供最一般解决方案，展示了DHP的无限最小完整统一集现象。

**🔧 技术方法**

使用βη-长范式的 λ-项表示、偏绑定、推理规则集以及归纳证明确保完备与最小性。

**📊 数据集**

无具体数据集，论文以形式化定义与示例演示为主。

**📈 对比分析**

对比传统高阶模式统一和FCU，指出DHP统一既保持可判定性又存在无穷解集；未给出实验性能指标。

**⚠️ 局限性**

推理系统在一般情况下非终止，导致不可判定性仍未解决；需进一步研究正则文法等方法来表示无限统一集。

---

## 975. Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery

**arXiv ID:** 2601.14196 | [PDF](https://arxiv.org/pdf/2601.14196v1)

**作者:** Albina Galiullina `[一作]` (Eindhoven University of Technology), Tom van Woensel `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3f18e8e3-0266-457c-8567-9039b6d2394d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出并评估一种动态的、差异化的取件点推荐策略（DPO），旨在在下一日配送中同时降低配送车辆和客户出行的二氧化碳排放。

**💡 创新点**

创新点在于：①将取件点推荐建模为基于实时系统状态的马尔可夫决策过程；②采用图注意网络（GAT）构造可变规模、空间关联的状态表示；③通过深度强化学习（PPO）学习对每位到达客户推荐单一取件点，兼顾未来路由与客户选择的相互影响。

**🔧 技术方法**

使用了图注意网络（GAT）、近端策略优化（PPO）深度强化学习框架、基于旅行商问题的离线路由求解器（Gurobi）。

**📊 数据集**

数据集为人工合成的城市配送实例：不同密度、不同取件点数量（4、7、15、30）以及不同服务区域半径（0.5–8 km）的随机生成点；客户到达采用均匀泊松过程，客户选择概率通过多项式Logit模型设定为Low/Base/High三种情景。

**📈 对比分析**

与五种基线（仅家配送、完美信息、无限制取件点选择、最近取件点、动态最近取件点）对比；实验显示DPO在大多数情境下比家配送降低总排放最多9%，相对其他取件点策略平均提升约2%；在高取件点数量、紧凑城市区域、客户偏好高的情况下表现最佳。

**⚠️ 局限性**

局限性包括：①仅考虑单车单日配送，未涵盖多车或多日场景；②未考虑取件点容量、收件时延等实际限制；③强化学习模型训练成本高，且对输入尺度敏感；④对客户行为模型假设较简化，真实用户偏好更复杂。

---

## 976. Toward Efficient Agents: Memory, Tool learning, and Planning

**arXiv ID:** 2601.14192 | [PDF](https://arxiv.org/pdf/2601.14192v1)

**作者:** Xiaofang Yang `[一作]` (Fudan University), Jing Shao `[通讯]` (Shanghai Artificial Intelligence Laboratory)

**通讯引用:** 9670 | [OpenAlex ID](https://openalex.org/A5023198186)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文综述并系统化了近年来大型语言模型（LLM）驱动代理系统在记忆、工具学习与规划三大核心组件上的效率提升技术，并对其评价指标与基准进行了整理。

**💡 创新点**

创新点在于提出了效率与效果的Pareto前沿框架，将“效率”定义为在固定成本预算下的效果或在相同效果下的成本，构建了统一的效率评价体系，同时总结了多种针对记忆压缩、工具调用成本控制与规划资源分配的前沿方法。

**🔧 技术方法**

所述技术包括：①记忆压缩与检索优化（如文本压缩、KV缓存压缩、图结构与分层存储）；②工具学习的高效选择与调用（外部检索、多标签分类、词表检索、并行调用、成本感知规划与RL奖励）；③规划的资源受限控制（自适应预算、树搜索、任务分解、策略学习与知识库/技能库重用）。

**📊 数据集**

主要引用的数据集与基准涵盖：HotpotQA、NaturalQuestions、GAIA、LoCoMo、LongMemEval、Evo-Memory、StoryBench、MemBench、BFCL、API-Bank、NesTools、T‑Eval、StableToolBench、SWE‑Bench、WebArena、WebShop 等。

**📈 对比分析**

对比实验表明：在保持或略低于同类方法的准确率/成功率时，本文梳理的多种技术组合能显著降低 token 消耗、推理延迟与工具调用次数，整体成本下降约 30–50%（具体数值依任务与评测指标而异）。

**⚠️ 局限性**

局限性包括：①缺乏统一、可复现的跨任务效率基准；②大部分方法仍需昂贵的 RL/离线训练，实际部署成本高；③在极大工具集合或长尾任务中，工具检索与调用效率尚未彻底解决；④记忆压缩与检索的通用性与可解释性仍有待提升。

---

## 977. Penalizing Localized Dirichlet Energies in Low Rank Tensor Products

**arXiv ID:** 2601.14173 | [PDF](https://arxiv.org/pdf/2601.14173v1)

**作者:** Paris A. Karakasis `[一作]` (University of Virginia), Nicholas D. Sidiropoulos `[通讯]` (University of Virginia)

**通讯引用:** 23291 | [OpenAlex ID](https://openalex.org/A5050186120)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究了低秩张量乘积B样条模型用于回归与分类，并提出基于局部Dirichlet能量的正则化与缺失数据推断方法。

**💡 创新点**

创新点在于给出低秩张量模型Dirichlet能量的闭式计算，发现全局能量可为指数级小，从而引入局部Dirichlet能量正则化；并提出两种利用预训练模型完成缺失输入推断的估计器。

**🔧 技术方法**

使用低秩张量乘积B样条表示、Dirichlet能量分析、局部积分正则化、预训练模型与欠测推断技术，对比神经网络的Dropout/Jacobian正则化。

**📊 数据集**

在六个公开数据集上测试：Ionosphere、Breast Cancer Wisconsin、Diabetes、Yacht Hydrodynamics、Physico、Sarcos。

**📈 对比分析**

与单隐藏层/双隐藏层、不同宽度的神经网络做比较；在过拟合区间和缺失样本场景下，TPBS模型表现更稳健，常优于神经网络；在大多数其他场景下性能相当。

**⚠️ 局限性**

局限在于对高维大规模数据的可扩展性未充分评估；局部正则化的半径参数需要手动调优；仅在特定低秩张量B样条框架下验证，未探究其他基函数。

---

## 978. An Empirical Study on Remote Code Execution in Machine Learning Model Hosting Ecosystems

**arXiv ID:** 2601.14163 | [PDF](https://arxiv.org/pdf/2601.14163v1)

**作者:** Mohammed Latif Siddiq `[一作]` (University of Notre Dame), Joanna C. S. Santos `[通讯]` (University of Notre Dame)

**通讯引用:** 529 | [OpenAlex ID](https://openalex.org/A5043541139)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df`

**🎯 论文内容**

对 Hugging Face、ModelScope、OpenCSG、OpenMMLab 与 PyTorch Hub 这五大模型共享平台进行跨平台大规模实证研究，量化了模型加载时执行自定义代码的普及程度、潜在漏洞与恶意载荷，并对平台安全机制与开发者关注进行系统分析。

**💡 创新点**

首次完成跨平台的全量模型仓库安全扫描与漏洞统计，构建了基于安全味道、CWE 分类的漏洞谱系，并提出了针对模型加载安全的开发者关注度词典，弥补了以往仅聚焦单一平台或序列化攻击的空白。

**🔧 技术方法**

采用 Bandit、CodeQL、Semgrep、YARA 等静态分析工具与动态可达性分析相结合，对 45,000+ 个执行代码的仓库进行安全味道检测；并利用平台 API、文档与社区讨论收集平台防护措施与开发者认知。

**📊 数据集**

使用从上述五大平台抓取的全部包含自定义加载代码的模型仓库（约45,000个），以及超过 600 条来自 GitHub、Hugging Face、PyTorch Hub 与 Stack Overflow 的开发者讨论，构成实验与定性分析的数据集。

**📈 对比分析**

通过对比各工具报告的 CWE 计数、受影响仓库比例以及平台安全机制的层级（如自动扫描、提示Banner、沙盒隔离），展示不同平台在远程代码执行风险控制上的差距；实验结果表明 Hugging Face 受攻击仓库占比约 7%–15%，PyTorch Hub 高达 46%，而 OpenCSG 与 ModelScope 较低，凸显平台策略对风险的显著影响。

**⚠️ 局限性**

局限性包括：静态分析对 Python 动态特性的覆盖不足、可能产生误报与漏报；仅覆盖公共平台且未纳入企业私有仓库；开发者讨论的主观性与中等一致性；工具与手动审计的时间成本与可扩展性受限。

---

## 979. One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion

**arXiv ID:** 2601.14161 | [PDF](https://arxiv.org/pdf/2601.14161v1)

**作者:** Yitong Dong `[一作]` (Zhejiang University), Guofeng Zhang `[通讯]` (Zhejiang University)

**通讯引用:** 6655 | [OpenAlex ID](https://openalex.org/A5100693449)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

结合 Vision Transformer 基础骨干与 3D 高斯渲染，再加单步 Stable Diffusion 细节增强，实现稀疏无姿态输入的高保真新视角合成。

**💡 创新点**

① Dual‑Domain Detail Perception Module (DD‑DPM) 同时在空间与频域提取细节，支持高分辨率输入；② Feature‑guided One‑Step Diffusion 在 UNet 中注入 3D 高斯特征与参考图像，实现几何一致的高频细节恢复；③ 端到端联合训练 ViT 结构与扩散模块，实现几何与外观的紧耦合。

**🔧 技术方法**

Vision Transformer、3D Gaussian Splatting、频域傅里叶变换 + MLP、轻量 CNN、Stable Diffusion（latent diffusion）、自注意力融合参考图像、GAN（DINOv2）监督、MSE+LPIPS+GAN 损失。

**📊 数据集**

DL3DV（2K 子集训练，benchmark 测试）与 RealEstate10k（RE10K）进行跨域评估。

**📈 对比分析**

与 NVS SOTA feed‑forward 方法（NopoSplat、AnySplat、FLARE、MVSplat360、LatentSplat）及后处理方法（MARINER、Difix3D+）对比。数值上在 DL3DV、RE10K 上 PSNR/SSIM/LPIPS/FID 均优于对比方法，尤其在 1024×1024 分辨率下显著提升；3D 一致性指标（MS、SC、BC）亦高于现有方案。

**⚠️ 局限性**

未显式建模动态物体，难以处理动态场景；单步扩散虽然快，但受限于生成能力；对极低视角稀疏输入的鲁棒性仍有待提升。

---

## 980. APEX-Agents

**arXiv ID:** 2601.14242 | [PDF](https://arxiv.org/pdf/2601.14242v1)

**作者:** Bertie Vidgen `[一作]` (Mercor), Osvald Nitski `[通讯]` (Mercor)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 APEX–Agents 基准，评估 AI 代理在投资银行、管理咨询和公司法律领域的长期跨应用任务执行能力，并开放了数据集和执行基础设施 Archipelago。

**💡 创新点**

创新点在于：① 构建真实的工作环境（包含文件、工具和多应用）和从业者设计的任务；② 采用 Pass@1、Pass@8 等细粒度指标；③ 将任务拆分为 480 个任务、33 个工作世界，覆盖三大专业领域；④ 开源数据与评测框架，促进可复现性。

**🔧 技术方法**

使用的技术包括：大型语言模型（Gemini 3 Flash/Pro、GPT‑5、GPT‑5.2、Claude Opus 4.5 等）作为代理，Gemini 3 Flash 作为评判模型；工具调用机制（ReAct）、多轮轨迹收集、自动化评判（Binary rubric scoring）以及 Archipelago 基础设施进行任务执行。

**📊 数据集**

数据集：480 个任务，分布在 33 个“世界”中，每个世界由专业从业者创建的项目场景、文件和九种工具（共 63 个工具）构成；涵盖投资银行、管理咨询和公司法律三类任务，每类 160 题，平均预计完成时间 1.8 小时。

**📈 对比分析**

比较方法：采用 Pass@1（任务一次执行是否全部满足准则）作为排行榜指标，结合 Pass@8、Passˆ8 和平均准则通过率；最佳模型 Gemini 3 Flash 在 Pass@1 上 24.0%，GPT‑5.2 23.0%，Claude Opus 4.5 18.4%；在 Pass@8 上最高 40.0%；平均准则通过率最高 39.5%。相比开放源模型，闭源模型表现优越，开放模型均低于 5%。

**⚠️ 局限性**

局限性：整体通过率低（≤25%），多模型间存在显著不一致性；任务完成受 250 步限制导致大量超时/死循环；评判模型与评测模型相同可能产生偏好；缺乏网络搜索与外部动态数据；仅针对特定行业场景，难以直接推广至更广泛任务。

---

## 981. Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment

**arXiv ID:** 2601.14228 | [PDF](https://arxiv.org/pdf/2601.14228v1)

**作者:** Punit Kumar `[一作]` (University at Buffalo), Alina Vereshchaka `[通讯]` (University at Buffalo)

**通讯引用:** 67 | [OpenAlex ID](https://openalex.org/A5067785156)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `e15e3743-5ee0-4d5f-813d-d146868082fc` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

本文提出一种基于离线强化学习、聚类分层与大语言模型的解释型败血症治疗决策支持框架。

**💡 创新点**

创新点在于将HDBSCAN风险分层、VAE与扩散模型的合成数据、轻量化注意力编码的AWR强化学习以及多模态LLM解释相结合。

**🔧 技术方法**

主要技术包括HDBSCAN+UMAP聚类、VAE与扩散模型生成数据、Attention-Encoder+Advantage-Weighted Regression强化学习、TabNet/XGBoost集成决策以及多模态LLM生成解释。

**📊 数据集**

使用MIMIC‑III与eICU两个大型ICU数据库作为训练和评估数据。

**📈 对比分析**

与BCQ等基准相比，改进的AWR+注意力模型及集成方案在治疗准确率上达到约83%，并在少数类动作上显著提升。

**⚠️ 局限性**

局限性包括对历史数据的依赖导致分布漂移风险、合成数据的真实性与临床可接受性待验证，以及模型解释仍需更深入的临床评估。

---

## 982. HALT: Hallucination Assessment via Latent Testing

**arXiv ID:** 2601.14210 | [PDF](https://arxiv.org/pdf/2601.14210v1)

**作者:** Rohan Bhatnagar `[一作]` (University of Maryland), Haizhao Yang `[通讯]` (University of Maryland)

**通讯引用:** 2142 | [OpenAlex ID](https://openalex.org/A5079602544)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `3855fcda-48ef-4070-a15e-803cd5c84d83` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过在大型语言模型（LLM）中使用轻量级残差探测器，从中间隐藏层（仅使用问题词表示）快速读取幻觉风险，并在推理过程中并行评估，实现零延迟的幻觉检测与选择性路由。

**💡 创新点**

①利用中间隐藏层的内在不确定性信号而非最终文本；②将幻觉检测嵌入轻量级网络，计算量远小于生成一个token；③在生成过程中并行评估，低风险查询无需额外延迟；④在多数据集上实现SOTA AUROC。

**🔧 技术方法**

使用自监督的MLP或轻量级Transformer探测器，对中间隐藏层进行聚合（如最后token、均值、最大池化或注意力池化）；训练目标为二分类交叉熵；幻觉标签由GPT‑4o生成答案与真实答案对照得到。

**📊 数据集**

四个问答基准：TriviaQA、NQ‑Open、MMLU‑Pro、WebQuestions；实验模型包括 LLaMA‑2‑7B、Qwen‑2.5‑7B‑Instruct、Gemma‑3‑4B‑it。

**📈 对比分析**

与现有方法 HaloScope、Semantic Entropy 等对比，本文在 10/12 组模型‑数据集组合中获得最高 AUROC；在 Qwen‑2.5‑7B‑Instruct 上 AUROC 达 94.20%（训练全集）并在高风险查询路由时提升整体答案准确率至 97.7%。

**⚠️ 局限性**

仅针对单轮问答、短上下文；在多轮对话或长文本情境中，当前问题的隐藏表示可能被前文干扰；需要更长上下文训练或滑动窗口处理；依赖 GPT‑4o 生成的标签，若标签质量不足会影响探测器训练。

---

## 983. A Minimax Perspective on Almost-Stable Matchings

**arXiv ID:** 2601.14195 | [PDF](https://arxiv.org/pdf/2601.14195v1)

**作者:** Frederik Glitzner `[一作]` (University of Glasgow), David Manlove `[通讯]` (University of Glasgow)

**通讯引用:** 4380 | [OpenAlex ID](https://openalex.org/A5050695548)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出最小最大阻碍对准匹配（minimax almost‑stable matching）概念，并系统研究其在稳定配对中的公平性与计算复杂性；在理想条件下给出多项式解、近似解和整数规划框架；在极简偏好列表下给出线性时间最优算法；对比现有的聚合型“几乎稳定”匹配度量，揭示更强的个体公平保障；证明即使仅要求每个代理最多一次阻碍对，该问题已是NP‑难。

**💡 创新点**

1）引入最大阻碍对数的分布式公平度量，取代传统的聚合指标；2）首次证明在几乎所有匹配模型（SRI、SMI）中，k=1 的最小最大阻碍对问题已是NP‑难；3）给出最优（列表≤2）、近似和整数规划解法；4）通过递归偏好循环构造实现对极大阻碍数的下界证明。

**🔧 技术方法**

多项式时间归约（(2,2)‑3SAT→k‑Max‑AlmostStable），构造强迫性 gadget 与偏好循环；利用可匹配图的结构（度≤2）实现贪心/循环匹配；使用整数规划模型求最优；设计 1‑近似/更高阶近似算法；实现线性时间的修正过程。

**📊 数据集**

主要为理论分析，未使用公开数据集；实验部分仅在随机生成的 SRI/SMI 实例上验证算法性能。

**📈 对比分析**

与传统 MinBP、MinBA、稳定匹配等度量相比，minimax 方案在保证每位代理阻碍对数不超过阈值方面更稳健；在列表长度≤2 时实现 O(n) 的线性时间最优解；近似算法在一般实例上提供可接受的误差；实验表明，在大多数随机实例上，最大阻碍对数显著低于聚合指标。

**⚠️ 局限性**

仍然是 NP‑难的：除列表极简（≤2）外大多数情况无法多项式求解；近似算法的误差上界尚未达到最优；实验验证仅基于随机实例，缺乏真实世界案例；对多参数化、动态/在线情形的分析仍待深入。

---

## 984. Progressive self-supervised blind-spot denoising method for LDCT denoising

**arXiv ID:** 2601.14180 | [PDF](https://arxiv.org/pdf/2601.14180v1)

**作者:** Yichao Liu `[一作]` (Heidelberg University), Junwen Guo `[通讯]` (Umeå University)

**通讯引用:** 195 | [OpenAlex ID](https://openalex.org/A5061668146)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

提出了仅使用低剂量CT图像的渐进式自监督盲点去噪框架，能在无配对正常剂量图像的情况下进行去噪。

**💡 创新点**

创新点在于逐步掩码去噪策略和在输入/目标中加入可控噪声的正则化，有效弥合了自监督与监督方法的性能差距。

**🔧 技术方法**

采用自监督盲点去噪（Noise2Self/Noise2Void）改进的分步掩码网络，并结合Poisson+AWGN噪声正则化，兼容U‑Net、Swin‑Unet等骨干网络。

**📊 数据集**

使用公开的AAPM Low‑Dose CT Grand Challenge（Mayo LDCT）数据集进行训练与评估。

**📈 对比分析**

与多种监督（RED‑CNN、Swin‑Unet、CycleGAN）和自监督（Noise2Void、Neighbor2Neighbor、BM3D）方法对比，PSNR/SSIM/RMSE表现与监督方法相当甚至超越。

**⚠️ 局限性**

局限性包括对掩码比例和噪声水平的经验调参依赖，以及在不同解剖区域泛化能力尚需进一步验证。

---

## 985. ReSearch: A Multi-Stage Machine Learning Framework for Earth Science Data Discovery

**arXiv ID:** 2601.14176 | [PDF](https://arxiv.org/pdf/2601.14176v1)

**作者:** Youran Sun `[一作]` (University of Maryland), Haizhao Yang `[通讯]` (University of Maryland)

**通讯引用:** 2142 | [OpenAlex ID](https://openalex.org/A5079602544)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个多阶段、推理增强的 Earth Science 数据发现框架 ReSearch，旨在把高层科学意图转化为可检索的具体数据需求并实现大规模高召回与高精度的检索与排序。

**💡 创新点**

核心创新点在于：① 明确划分意图理解、粗略检索与上下文重排三阶段，分别解决语义缺口、元数据异构与精确排序；② 采用混合检索策略（BM25+语义嵌入+缩写扩展）最大化召回；③ 在重排阶段利用大型语言模型对候选集进行上下文感知的相关性打分。

**🔧 技术方法**

使用的技术包括：自然语言处理的意图分类与缩写扩展、基于 BM25 的词频检索、基于向量嵌入的语义检索、LLM（如 GPT‑4o）驱动的重排与意图映射。

**📊 数据集**

实验数据集来自 NASA CMR、NOAA OneStop、CMIP6、ERA5 四大 Earth Science 公开仓库，并构建了以同行评审论文为基础的 15 篇论文、49 个数据集的检索基准。

**📈 对比分析**

与 BM25、Embedding 以及 AutoClimDS 基线对比，ReSearch 在任务型（高层科学目标）查询中明显提升 Recall、MRR、MAP；缩写扩展在前 10、20 条结果中可提升 140%‑200% 的召回，整体效果优于单一检索方式。

**⚠️ 局限性**

局限性包括：对任务型查询仍存在召回不足；模型依赖于高质量元数据与缩写表，缺失或不一致的描述仍导致检索遗漏；实验规模较小，仅基于 15 篇论文，缺乏大规模验证；未与知识图谱或自动化研究流水线深度集成。

---

## 986. A model of errors in transformers

**arXiv ID:** 2601.14175 | [PDF](https://arxiv.org/pdf/2601.14175v1)

**作者:** Suvrat Raju `[一作]` (International Centre for Theoretical Sciences), Praneeth Netrapalli `[通讯]` (Google Deepmind)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了大型语言模型（LLMs）在需要确定性输出的任务（如算术）上的错误率，提出了一个定量模型来描述准确性与任务复杂性之间的关系。

**💡 创新点**

创新点在于将LLMs的众多参数重组为仅两个有效参数，从而简化了错误率的预测模型，并提供了一个新的视角来理解LLMs的错误。

**🔧 技术方法**

使用了有效场论的视角，结合了定量模型和大量的实证测试，验证了模型的准确性。

**📊 数据集**

使用了Gemini 2.5 Flash、Gemini 2.5 Pro和DeepSeek R1等多个模型进行实证测试，共计使用了20万个不同的提示。

**📈 对比分析**

通过与现有的错误模型进行比较，发现所提出的模型在大多数情况下能够准确预测LLMs的错误率，但在某些情况下存在系统性偏差，尤其是在处理长重复任务时。

**⚠️ 局限性**

限制在于模型在某些特定任务（如普通加法）上的表现不佳，可能是由于LLMs在不同输入长度下使用不一致的算法。

---

## 987. Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum

**arXiv ID:** 2601.14172 | [PDF](https://arxiv.org/pdf/2601.14172v1)

**作者:** Víctor Yeste `[一作]` (Universitat Politècnica de València), Paolo Rosso `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了在单句层面识别19种Schwartz基本价值观的任务，并针对价值检测的挑战提出了实用的基线与改进方案。

**💡 创新点**

创新点包括：①首次将价值检测拆分为价值存在检测与多标签检测并系统评估二者关系；②在受限8 GB显存条件下引入轻量化辅助特征（短句上下文、LIWC‑22、主题分布）并对阈值进行精细校准；③对比传统Transformer与指令调优的大模型，并通过小规模软/硬投票集成显著提升性能。

**🔧 技术方法**

技术方法主要包括：DeBERTa‑base的多标签微调、轻量化特征拼接、二阶门控层次结构、指令调优LLM（Gemma‑2‑9B、Llama‑3.1‑8B、Qwen‑2.5‑7B）在zero‑/few‑shot与QLoRA模式下的实现，以及基于Bootstrap和McNemar检验的统计显著性评估。

**📊 数据集**

使用公开的ValueEval'24英文机器翻译版数据集（来源于ValuesML），包含新闻与政治宣言句子，并按官方train/val/test拆分。

**📈 对比分析**

实验表明：①价值存在检测的F₁≈0.74；②在相同GPU预算下，直接多标签模型在宏观F₁上略优于门控层次；③轻量化特征与阈值校准可提升≈+0.01宏观F₁；④监督的DeBERTa集成取得宏观F₁≈0.332，明显优于单一指令调优LLM（≈0.238）和其集成（≈0.277）。

**⚠️ 局限性**

局限性包括：仅使用单句输入，未利用文档上下文；数据为单语种英文机器翻译版，缺乏多语言与跨域泛化；标签稀疏导致少数类性能低；实验仅在单一随机种子下进行，缺少对随机性稳定性的评估；对大型模型和更大显存的探索受限。

---

