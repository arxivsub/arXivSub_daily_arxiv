# arXiv Daily Summary

![Last Commit](https://img.shields.io/github/last-commit/arxivsub/arXivSub_daily_arxiv?label=Updated)
![Arxiv](https://img.shields.io/badge/arXiv-Papers-B31B1B.svg)
![Python](https://img.shields.io/badge/Powered%20By-Python-3776AB?logo=python&logoColor=white)
![Views](https://komarev.com/ghpvc/?username=arxivsub&repo=arXivSub_daily_arxiv&label=Views&color=brightgreen&style=flat)
![License](https://img.shields.io/badge/license-MIT-green)

> 最后更新时间: 2026-02-03 | 今日论文总数: 962

> 更多内容请访问 [arXivSub](https://arxivsub.comfyai.app/)

---

## 1. Legal Infrastructure for Transformative AI Governance

**arXiv ID:** 2602.01474 | [PDF](https://arxiv.org/pdf/2602.01474v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 2. Living Contracts: Beyond Document-Centric Interaction with Legal Agreements

**arXiv ID:** 2602.01396 | [PDF](https://arxiv.org/pdf/2602.01396v1)

**作者:** Ziheng Huang `[一作]` (University of Illinois Urbana-Champaign), Tal August `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 460 | [OpenAlex ID](https://openalex.org/A5029563909)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

**🎯 论文内容**

本文提出“Living Contracts”概念，设计了三种交互式探针（LeaseCompare、LeaseRead、LeaseTrack）来探索合同在签署前、签署中和签署后与用户交互的可能性，并通过三阶段定性研究（访谈、探针体验、设计构思）收集用户反馈。

**💡 创新点**

创新点在于把合同视为动态交互界面而非静态文档，强调三大设计概念：情境化（提供合同外的背景知识）、可塑化表达（将文本转化为可视化或可交互的表示）以及主动性（在关键时刻主动提醒或提供信息）。

**🔧 技术方法**

技术上主要采用可交互的网页原型与人工设计探针，未使用实际的语言模型或后端系统，所有功能通过前端可视化实现。

**📊 数据集**

数据集方面仅使用了若干实际租赁合同实例（未公开列出），以及参与者生成的访谈记录和交互日志。

**📈 对比分析**

未进行性能对比或量化评估，研究方法为定性访谈与可用性体验分析，结果以主题分析呈现，未给出数值指标。

**⚠️ 局限性**

局限性包括：研究为探索性、样本仅18名美国参与者；未验证探针的实际可用性或技术实现；对不同类型合同、不同地区的适用性未知；以及对AI实现的技术挑战与法律合规性未深入探讨。

---

## 3. EEmo-Logic: A Unified Dataset and Multi-Stage Framework for Comprehensive Image-Evoked Emotion Assessment

**arXiv ID:** 2602.01173 | [PDF](https://arxiv.org/pdf/2602.01173v1)

**作者:** Lancheng Gao `[一作]` (Shanghai Jiao Tong University), Xiongkuo Min `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 9923 | [OpenAlex ID](https://openalex.org/A5043405654)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了最大的图像诱发情绪理解数据集 EEmoDB（包含 QA 和评估两子集）以及两阶段训练框架 EEmo‑Logic，能够实现对情绪的多维度细粒度识别与因果推理。

**💡 创新点**

创新点在于：①将情绪的维度（VAD + CES）统一到同一数据集；②引入两阶段 LoRA + GRPO 训练，配合三类专属奖励函数，显著提升情绪排名、VAD 评分与主导情绪识别的细粒度与推理能力；③设计了混合回归与相似度奖励，弥补传统阈值奖励稀疏的问题。

**🔧 技术方法**

采用的技术包括：多模态大型语言模型（Qwen2.5‑VL‑7B）LoRA 细调、GRPO 强化学习、基于 VAD 的回归与相似度奖励、文本生成策略（深度生成与判定）以及专门的思考与回答格式约束。

**📊 数据集**

使用的数据集有：EEmoDB（由 7 个 AICA 数据集整合得到的 128k 图像、1.23M QA 对、36k 评估样本），以及评测基准 EEmo‑Bench、Artphoto、ArtEmis、UNIAA、AesBench 等跨域情绪与审美数据集。

**📈 对比分析**

与 23 个基线模型（包括 10 个中型 MLLM、5 大型 MLLM、5 情绪专用 MLLM）在 EEmo‑Bench 和跨域数据集上进行零样本对比，EEmo‑Logic 在情绪排名提升约 6%（新 SOTA）、主导情绪识别与 VAD 评分均优于对手，跨域性能保持领先，说明其泛化与推理能力强。

**⚠️ 局限性**

局限性包括：①仍主要聚焦图像诱发情绪，尚未扩展到视频或多模态跨领域；②部分情绪标签来源于自动生成或映射，可能存在语义误差；③对极端稀有情绪的识别仍不稳定；④模型训练成本较高，需多卡 GPU。

---

## 4. Unifying Ranking and Generation in Query Auto-Completion via Retrieval-Augmented Generation and Multi-Objective Alignment

**arXiv ID:** 2602.01023 | [PDF](https://arxiv.org/pdf/2602.01023v1)

**作者:** Kai Yuan `[一作]` (Apple), Sean Suchter `[通讯]` (Apple)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种统一的查询自动补全框架，将 QAC 重新定义为端到端列表生成，并通过检索增强生成和多目标直接偏好优化实现高质量、低延迟的补全服务。

**💡 创新点**

创新点包括：① 将 QAC 转化为多目标端到端列表生成；② 设计规则、模型及 LLM‑as‑judge 验证器组合形成多目标奖励；③ 采用迭代批判‑修订生成高质量合成数据，并用 DPO 对齐模型；④ 构建大模型预生成+小模型实时推理的混合服务架构。

**🔧 技术方法**

使用技术包括 Retrieval‑Augmented Generation (RAG)、多目标 Direct Preference Optimization (DPO)、LLM‑as‑judge、规则与模型验证器、合成数据生成、监督微调、混合推理架构（Large Generator + Compact Generator）等。

**📊 数据集**

实验数据集来自内部商业搜索平台，包含 50,000 条真实匿名用户前缀及对应的日志、目录和查询日志信息。

**📈 对比分析**

与传统两阶段检索‑排名、检索+Seq2Seq、SFT‑only、SFT+DPO w/o Eng 等做对比；离线指标显示覆盖率 93‑94%，相关度 >0.68，安全率 <0.7%，目录/上下文无根率 <0.5%，多样性 74‑76；在线 A/B 测试（10% 流量）字符打字减少 5.44%，点击率提升 3.46%；人类评估显示相关性 0.699，偏好得分 +0.40‑+0.69。

**⚠️ 局限性**

局限性在于：① 依赖内部大规模搜索日志与目录，验证器需要自定义；② 混合架构需要维护两种模型；③ 对极稀前缀仍可能生成不准；④ 目前未实现检索‑生成的端到端联合优化；⑤ 未探索多模态或个性化；⑥ 对安全与准则覆盖仍有限。

---

## 5. OCTOPUS: Enhancing the Spatial-Awareness of Vision SSMs with Multi-Dimensional Scans and Traversal Selection

**arXiv ID:** 2602.00904 | [PDF](https://arxiv.org/pdf/2602.00904v1)

**作者:** Kunal Mahatha `[一作]` (ÉTS Montréal), Christian Desrosiers `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出 Octopus 模型，采用 8 个方向的离散扫描与归并机制，在视觉任务中实现线性复杂度的全局与局部关系建模。

**💡 创新点**

创新点在于离散多方向扫描、归一化转移核、遍历选择机制，能够实现空间同质性与高效的线性传播。

**🔧 技术方法**

使用 State‑Space Model（SSM）及其 Mamba 变体，设计 O‑Scan（8 方向离散扫描）、O‑Merge（八向归并）与 O‑Attention（遍历选择），并引入归一化转移核保持稳定。

**📊 数据集**

在分类任务上使用 miniImageNet 数据集，在语义分割任务上使用 ADE20K 数据集。

**📈 对比分析**

与 ViT（DeiT、Swin、XCiT）以及其他 SSM 模型（Vim、LocalVim、MSVMamba、VMamba）对比，分类 Top‑1 约 86.6%–86.9%（明显高于 VMamba），分割 mIoU 单尺度约 39–40%（显著优于 VMamba 与 SpectralVMamba）。

**⚠️ 局限性**

局限性包括：对极大分辨率的适应性尚未验证；模型结构相对复杂，可能增加实现难度；仅在小尺寸任务上验证，缺乏在更大规模或实时场景下的性能评估。

---

## 6. HalluHard: A Hard Multi-Turn Hallucination Benchmark

**arXiv ID:** 2602.01031 | [PDF](https://arxiv.org/pdf/2602.01031v1)

**作者:** Dongyang Fan `[一作]` (École Polytechnique Fédérale de Lausanne), Maksym Andriushchenko `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并构建了一个跨四大高风险领域（法律、科研、医疗、编程）的多轮对话幻觉基准Halluhard，并开发了可检索全文验证的LLM评判器。

**💡 创新点**

提供了面向多轮开放式生成的严苛幻觉评估框架，要求模型给出内联引用并通过完整网页/ PDF 文本检索验证；在四个难度高的领域中引入大规模种子问答，揭示模型在后续轮次和领域特异性知识上的幻觉趋势。

**🔧 技术方法**

结合大语言模型的提示、搜索引擎 API（Serper）和 PDF 解析、嵌入检索与推理，构建分阶段的评判管线（提取、检索、上下文裁剪、判定）。

**📊 数据集**

950个种子问题（每个领域250/200个）来源于法律案例、arXiv 摘要、NICE 医疗指南和编程库列表，并对生成的多轮对话进行人工审核。

**📈 对比分析**

对多种前沿专有与开源 LLM（GPT-5、Claude-Opus、Gemini、DeepSeek 等）在开启/关闭思考、是否启用 web 搜索等设置下进行实验，发现即使开启搜索，顶尖模型的幻觉率仍约 30%（无搜索约 60%），并揭示模型规模、推理力度和轮次对幻觉率的影响。

**⚠️ 局限性**

受限于检索可达性、PDF 解析准确性以及领域外新颖知识的缺失，评判器在极罕见或高度专业的语料上仍可能误判；此外，多轮对话生成的复杂性导致评判成本较高。

---

## 7. BicKD: Bilateral Contrastive Knowledge Distillation

**arXiv ID:** 2602.01265 | [PDF](https://arxiv.org/pdf/2602.01265v1)

**作者:** Jiangnan Zhu `[一作]`, Yujie Gu `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `8d10c613-917e-4880-9716-17789f50e119` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出Bilateral Contrastive Knowledge Distillation (BicKD) 方法，利用样本级与类别级对比正则化教师与学生模型的预测。

**💡 创新点**

创新点在于双向对比损失，既通过样本级正交性增强不同类别间分离，又通过类别级对齐实现跨类别知识共享，并通过正交性约束重建教师概率空间的几何结构。

**🔧 技术方法**

采用对比学习中的余弦距离正交性正则、KL 对齐、L1 类别对齐等技术，仅使用教师与学生的 logits，无需中间特征或额外数据增强。

**📊 数据集**

使用 CIFAR‑100、Tiny‑ImageNet、CIFAR‑100‑FS（few‑shot）和 CIFAR‑100‑LT（长尾）等数据集进行实验。

**📈 对比分析**

与 KD、VID、FitNets、RKD、SP、CRD、DIST、MLD、RLD、WKD‑L、WTTM 等20+基线对比，BicKD 在多组教师‑学生配对中平均提升 1–2% 的 Top‑1/Top‑5 准确率，在少样本与长尾场景表现尤为突出。

**⚠️ 局限性**

局限性：仍需手动调参 α、β、γ；仅在 logits 层有效，未推广到高维特征空间；在极端模型差异或极端不平衡条件下提升有限。

---

## 8. Richer Bayesian Last Layers with Subsampled NTK Features

**arXiv ID:** 2602.01279 | [PDF](https://arxiv.org/pdf/2602.01279v1)

**作者:** Sergio Calvo-Ordoñez `[一作]` (Mathematical Institute, University of Oxford), Kamil Ciosek `[通讯]` (Spotify)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

改进 Bayesian Last Layer (BLL) 的不确定性估计，加入前层 NTK 特征投影。

**💡 创新点**

通过低维核校正保留 BLL 低成本的同时，使后验方差更保守，并提供统一采样近似与理论保证。

**🔧 技术方法**

使用 Neural Tangent Kernel (NTK) 特征、最小二乘投影、Cholesky 变换、Woodbury 公式及子采样。

**📊 数据集**

UCI 回归数据集、CIFAR‑10、SVHN、CIFAR‑100、Wine 质量、Wheel Bandit 等。

**📈 对比分析**

与标准 NNGP/BLL、VBLL、Dropout、Ensemble、SWAG 等对比，在 NLL、ECE、AUROC、累积后悔等指标上均优于或匹配其余方法。

**⚠️ 局限性**

在极大模型或极大数据规模下仍需子采样；对高维非线性特征的近似可能不足，且对训练前参数敏感。

---

## 9. The Algorithmic Self-Portrait: Deconstructing Memory in ChatGPT

**arXiv ID:** 2602.01450 | [PDF](https://arxiv.org/pdf/2602.01450v1)

**作者:** Abhisek Dash `[一作]` (Max Planck Institute for Software Systems), Savvas Zannettou `[通讯]` (Delft University of Technology)

**通讯引用:** 4100 | [OpenAlex ID](https://openalex.org/A5007187227)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对ChatGPT的记忆机制进行系统研究，提出将其视为算法化自画像，并分析其内容与形成过程；基于此构建“归因屏障”（Attribution Shield），能够预测潜在敏感记忆并给出不泄露个人信息的查询重写建议。

**💡 创新点**

①首次将聊天记忆框架化为算法自画像并量化其主观性与敏感性；②揭示记忆大多由系统单方面生成，且包含大量个人与心理信息；③研发归因屏障，实现对记忆生成的逆向工程、风险预警与隐私友好式查询改写。

**🔧 技术方法**

使用LLM（GPT‑4o）进行数据标注与评估；利用大型预训练模型（Qwen‑2.5‑32B‑it、Gemma‑3‑27B‑it、GPT‑OSS‑20B）进行记忆提取与查询重写的微调与上下文学习；采用语义相似度（余弦相似度）、BLEU、ROUGE、LLM判定等多维评估指标。

**📊 数据集**

来自80名真实ChatGPT用户的2,050条记忆记录，涵盖22,971条查询（其中2,050条触发记忆）。数据来自GDPR权限获取的聊天记录。

**📈 对比分析**

在记忆提取上，微调模型与上下文学习模型均能达到约60%语义相似度，84%记忆与用户对话直接对应；在查询重写上，94%–100%可降低个人属性曝光，87%–91%保留原查询意图；与ChatGPT原始记忆相比，提取模型的敏感信息比例从28%升至约31–35%，信息增益显著。

**⚠️ 局限性**

样本主要来自欧美的Prolific用户，难以代表全球多元用户；只关注OpenAI的ChatGPT记忆实现，其他平台的差异不在研究范围；LLM作为评判者虽高效但仍有主观偏差；归因屏障需要在实际系统中进一步验证其可部署性与安全性。

---

## 10. Inferential Question Answering

**arXiv ID:** 2602.01239 | [PDF](https://arxiv.org/pdf/2602.01239v1)

**作者:** Jamshid Mozafari `[一作]` (University of Innsbruck), Adam Jatowt `[通讯]` (University of Innsbruck)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出Inferential QA任务，要求模型从仅含暗示、无答案的段落中推断答案

**💡 创新点**

构造大规模推理问答基准（QUestions requiring Inference from Texts），并通过LLM与人工验证实现三等级相关性标注

**🔧 技术方法**

采用检索器（BM25、DPR、ColBERT、Contriever、BGE）、重新排序器（T5/RankGPT/UPR等）以及LLM阅读器（LLaMA3.2‑1B、Gemma3‑4B、Qwen3‑8B）进行RAG管线评估

**📊 数据集**

使用自建的QAT基准共7401道题、240万段落，来自TriviaHG和WikiHint的高共识提示

**📈 对比分析**

相较于传统QA（如MS MARCO、Wikipedia），检索与重新排序性能显著下降；检索Hit@1仅0.2%，即使使用最佳BGE、重新排序器亦提升不到10%；阅读器在最佳情形下EM最高可达90%（Gemma3‑4B），但实际场景远低于此，表明难点主要在检索与排序

**⚠️ 局限性**

局限性：现有检索/重新排序框架对“暗示式”段落适配不足，微调效果有限；LLM虽强但仍受检索质量限制；提示生成与标注过程依赖多步骤自动化与人工，成本高；任务侧重单条答案，未涵盖多跳推理或开放域生成等更复杂场景

---

## 11. RE-MCDF: Closed-Loop Multi-Expert LLM Reasoning for Knowledge-Grounded Clinical Diagnosis

**arXiv ID:** 2602.01297 | [PDF](https://arxiv.org/pdf/2602.01297v1)

**作者:** Shaowei Shen `[一作]`, Seyyedali Hosseinalipour `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `e15e3743-5ee0-4d5f-813d-d146868082fc` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

研究了基于多专家闭环的临床诊断框架 RE-MCDF，用于解决神经科 EMR 的异质性、噪声与逻辑约束问题。

**💡 创新点**

创新点在于引入生成‑验证‑修订闭环，并通过实验室专家动态加权和多关系感知专家组显式建模疾病互斥、共病与鉴别关系。

**🔧 技术方法**

采用 LLM（Qwen2.5‑7B‑Instruct / GLM‑4‑9B）结合医学知识图谱（CPubMed‑KGv2）、NER、图路径评分、ICD‑10 一致性惩罚等技术实现多专家协同推理。

**📊 数据集**

使用公开神经科子集 CMEMR（NEEMRs）和自建高复杂度神经科 EMR 数据集 XMEMRs 进行评估。

**📈 对比分析**

与 LLM‑only、LLM⊕KG、LLM⊗KG 以及多代理模型（MAGIC、KERAP）对比，RE‑MCDF 在 NEEMRs 取得 44.11% F1、XMEMRs 取得 40.38% F1，显著优于所有基线。

**⚠️ 局限性**

局限主要体现在未充分整合医学影像信息、推理时间相对较长以及仅在神经科场景验证，未覆盖其他科室或跨模态情形。

---

## 12. Bowling with ChatGPT: On the Evolving User Interactions with Conversational AI Systems

**arXiv ID:** 2602.01114 | [PDF](https://arxiv.org/pdf/2602.01114v1)

**作者:** Sai Keerthana Karnam `[一作]` (Indian Institute of Technology Kharagpur), Savvas Zannettou `[通讯]` (Delft University of Technology)

**通讯引用:** 4100 | [OpenAlex ID](https://openalex.org/A5007187227)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过分析 300 名用户捐赠的 825K 条 ChatGPT 交互记录（2022‑12 至 2026‑01），对话目的、框架（拟人化、角色、个人数据披露）以及模型主动引导在时间上的演变进行纵向研究。

**💡 创新点**

① 首个大规模长期真实交互数据集；② 系统化追踪会话目的多样化、用户/系统拟人化、伴侣角色、个人数据泄露与模型主动引导的动态演变；③ 提出基于 LLM 的自动标注流程，实现对话主题、关系、个人数据、引导等维度的高效标注。

**🔧 技术方法**

使用 GPT‑4o 进行主题、拟人化、关系、个人数据与引导的自动标注；BERT/BERTopic 进行文本嵌入与聚类；统计学与时间序列方法评估演化趋势；与公开数据集（ShareGPT、OpenAI 用户数据）进行对比。

**📊 数据集**

自有 GDPR‑based 数据集：300 名受试者的 138K 对话、825K 轮次，时间跨度 2022‑12 至 2026‑01；此外对比公开数据集如 ShareGPT 与 OpenAI 平台用户数据。

**📈 对比分析**

与公开数据集比较时，展示自有数据在对话密度、对话时长、轮次/对话比例上显著更高；标注一致性评估显示 Cohen κ≥0.71，准确率约 75–80%，证明自动标注方法可靠。

**⚠️ 局限性**

① 样本规模有限（300 人），难以直接推断总体；② 依赖 GPT‑4o 进行标注，存在误判；③ 仅包含文字对话，未覆盖多模态交互；④ 受观察者效应与隐私限制影响，部分交互可能被裁剪或缺失。

---

## 13. DeepPM: A Deep Learning-based Profit Maximization Approach in Social Networks

**arXiv ID:** 2602.01351 | [PDF](https://arxiv.org/pdf/2602.01351v1)

**作者:** Poonam Sharma `[一作]` (Indian Institute of Technology), Suman Banerjee `[通讯]` (Indian Institute of Technology)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出 DeepPM 框架，解决社交网络中的利润最大化问题，直接学习传播概率并预测最优种子集合。

**💡 创新点**

创新点在于将教师‑学生 GCN 结构与自动编码器结合，既能逼近真实传播结果，又能在无显式传播模型的情况下进行梯度搜索，从而实现利润最大化。

**🔧 技术方法**

采用图卷积网络 (GCN)、二元交叉熵训练、自动编码器、梯度上升搜索与贪婪剪枝等深度学习技术。

**📊 数据集**

使用 Email‑Eu‑Core、Ego‑Facebook 与 Wiki‑Vote 三个公开社交网络数据集进行实验。

**📈 对比分析**

与随机、HD、DD、HC、SG、StG 等传统基线在均匀和三值传播概率下对比，DeepPM 在利润提升 20%–60% 的同时，种子规模更小，虽耗时略高，但整体性能显著优于大多数方法。

**⚠️ 局限性**

局限性包括对大规模图的训练与推理耗时较高，且仍需大量教师模拟来生成训练标签，导致可扩展性受限。

---

## 14. A class of pseudorandom sequences From Function Fields

**arXiv ID:** 2602.01154 | [PDF](https://arxiv.org/pdf/2602.01154v1)

**作者:** Xiaofeng Liu `[一作]` (Chern Institute of Mathematics and LPMC Nankai University), Fang-Wei Fu `[通讯]` (Chern Institute of Mathematics and LPMC Nankai University)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

本文研究了一类基于函数域的伪随机序列，利用Weil和Deligne的结果，分析了这些序列的周期、线性复杂度、线性复杂度轮廓、r-pattern分布、周期相关性和非线性复杂度。

**💡 创新点**

创新点在于将已有的伪随机序列构造方法推广到更一般的代数函数域，并通过指数和的界限来分析这些序列的性质，展示了其在低相关性和高复杂度方面的优势。

**🔧 技术方法**

使用了代数函数域的指数和理论、Riemann-Roch定理以及自同构群的相关技术。

**📊 数据集**

使用了基于有理函数域和循环椭圆函数域的构造方法，具体数据集未明确提及，但涉及到的函数域和有限域的结构。

**📈 对比分析**

与现有方法相比，本文构造的序列在周期、线性复杂度和相关性方面表现出更优的性能，具体数值通过理论推导和界限得出。

**⚠️ 局限性**

限制在于构造的序列在特定条件下才能达到最佳性能，且对函数域的选择和参数设置有一定要求。

---

## 15. Self-Generative Adversarial Fine-Tuning for Large Language Models

**arXiv ID:** 2602.01137 | [PDF](https://arxiv.org/pdf/2602.01137v1)

**作者:** Shiguang Wu `[一作]` (Tsinghua University), Quanming Yao `[通讯]` (Tsinghua University)

**通讯引用:** 9445 | [OpenAlex ID](https://openalex.org/A5072484211)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 Self-Generative Adversarial Fine‑Tuning 框架（SGALM），在单个 LLM 内部实现生成‑判别对抗训练以实现对齐。

**💡 创新点**

创新点在于将生成与判别能力统一到同一模型内部，用自监督对抗方式消除外部奖励模型，并通过 ICL 产生多样化样本与基于输出分布的连续判别。

**🔧 技术方法**

使用 LLM 的 ICL、生成指令与判别指令，基于自监督对抗更新，利用概率分布输出作为连续判别分数。

**📊 数据集**

在 GSM8K（数学题）、ARC‑Challenge（科学选择题）和 MBPP（Python 编程）三大基准上进行实验。

**📈 对比分析**

与 SFT、Self‑Instruct、Self‑Rewarding、SPIN、Iterative‑RPO 等方法对比，SGALM 在三大数据集上均超越基线，且在合成数据扩增时展现正向规模性和稳定提升。

**⚠️ 局限性**

局限在于对大模型的依赖、对抗训练的稳定性问题、少量样本下的泛化仍需验证，以及在更复杂任务上的效果尚未充分检验。

---

## 16. A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation

**arXiv ID:** 2602.01067 | [PDF](https://arxiv.org/pdf/2602.01067v1)

**作者:** Fanqi Lin `[一作]` (Tsinghua University), Jose Barreiros `[通讯]` (Toyota Research Institute)

**通讯引用:** 682 | [OpenAlex ID](https://openalex.org/A5053831025)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过大规模实验系统评估了多种协同训练数据模态及训练策略对大规模行为模型在机器人操作中的表现影响，构建了基于预训练视觉‑语言模型的 VLA 策略并在模拟与真实环境中验证其泛化能力。

**💡 创新点**

创新点在于首次将标准视觉‑语言数据、机器人轨迹语言注释、跨体型机器人数据、人类视频以及离散动作标记等多种模态系统性地纳入协同训练，并提出单相与双相训练方案，证明多模态协同训练可累计提升性能且可快速迁移至长时程复杂任务。

**🔧 技术方法**

主要技术包括预训练视觉‑语言模型（VLM）作为 backbone、流匹配（flow matching）动作预测、离散动作标记（FAST、VQ‑VAE）以及链式思考（CoT）条件化等；同时采用多阶段训练策略来控制不同模态的输入。

**📊 数据集**

数据集涵盖约4000小时的机器人与人类操作数据、50M条标准视觉‑语言样本、跨体型机器人演示（Open X-Embodiment）、人类视频的语言注释和离散动作标记等多来源数据。

**📈 对比分析**

在58,000次仿真回合与2,835次真实回合中，使用包含多模态协同训练的最佳模型在未见任务、分布偏移与语言跟随任务上分别实现了约72.6%与69.4%的成功率，较仅用机器人数据的基线提升约36–45%，并在长时程任务的微调中显著加速收敛。

**⚠️ 局限性**

局限性包括：对不同视觉‑语言任务类别的影响未进行细粒度分析；人类视频的动作表征仅为粗粒度，缺乏精细抓取动作；链式思考仅在低层次动作抽象上验证，对高层次规划能力验证不足；实验仅覆盖模仿学习，未探讨强化学习等其他范式。

---

## 17. Reinforcement Learning for Active Perception in Autonomous Navigation

**arXiv ID:** 2602.01266 | [PDF](https://arxiv.org/pdf/2602.01266v1)

**作者:** Grzegorz Malczyk `[一作]` (Norwegian University of Science and Technology), Kostas Alexis `[通讯]` (Norwegian University of Science and Technology)

**通讯引用:** 7806 | [OpenAlex ID](https://openalex.org/A5022659812)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种结合主动相机控制与强化学习的无人机导航框架，能够在未知环境中安全到达目标并主动提升感知。

**💡 创新点**

创新点在于将主动感知作为多目标奖励的一部分，使导航策略能够同时优化运动和相机视角，并通过局部占据网格实现无需全局定位的鲁棒避障。

**🔧 技术方法**

使用的方法包括基于Actor-Critic的PPO强化学习、深度残差网络编码深度图与占据网格、GRU序列处理、以及带一阶动力学的相机舵机模型。

**📊 数据集**

训练数据集基于Aerial Gym模拟器中的随机原型障碍corridor场景，测试则在Gazebo训练站和真实四旋翼平台上进行。

**📈 对比分析**

与静态摄像头、仅FOV约束、仅局部网格等九种消融配置相比，主动感知+局部网格+探索奖励的策略在10/20/30障碍下成功率分别达到97.4%/96.0%/94.3%，碰撞率低于2.7%，且环境覆盖率提升至63.4%。

**⚠️ 局限性**

局限性包括依赖深度相机和占据网格对噪声敏感、仅测试静态障碍且未验证动态场景、以及对相机动作延迟和多目标优化权衡仍需进一步研究。

---

## 18. Rod Flow: A Continuous-Time Model for Gradient Descent at the Edge of Stability

**arXiv ID:** 2602.01480 | [PDF](https://arxiv.org/pdf/2602.01480v1)

**作者:** Eric Regis `[一作]` (Yale University), Sinho Chewi `[通讯]` (Yale University)

**通讯引用:** 219 | [OpenAlex ID](https://openalex.org/A5052571538)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `a8e75ba4-7a2d-4153-b003-06c94533add0` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出一种新的连续时间模型 Rod Flow，用于逼近梯度下降在“边界稳定性”区域的动态行为。

**💡 创新点**

创新点在于将梯度下降迭代视为一条“杆”对象，通过杆的中心和长度构造 ODE，并使用后向误差分析得到精确的微分方程，避免了传统的渐近近似。

**🔧 技术方法**

主要技术包括：对梯度下降的差分方程进行改写、后向误差分析（backward error analysis）、梯度与海森矩阵相关的高阶展开，以及与 Central Flow 的对比分析。

**📊 数据集**

实验数据集包括：二维平方根损失（toy 例子）以及三种深度网络架构（3 层 MLP、3 层 CNN、2 层 Transformer），均在公开数据集上训练得到。

**📈 对比分析**

与梯度流和 Central Flow 的对比显示：Rod Flow 在保持 sharpness 在 2/η 的临界值的同时，跟踪梯度下降轨迹的误差显著低于梯度流，且与 Central Flow 相比具有更高的数值精度和更低的计算复杂度。

**⚠️ 局限性**

局限性包括：需要假设损失函数足够光滑；在边界稳定性阶段出现的梯度幅度跳跃仍无法被 ODE 捕捉；相较于直接梯度下降，Rod Flow 计算成本仍较高。

---

## 19. Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach

**arXiv ID:** 2602.01131 | [PDF](https://arxiv.org/pdf/2602.01131v1)

**作者:** Yue Zhong `[一作]` (Guangdong University of Technology), Shengli Xie `[通讯]` (Guangdong University of Technology)

**通讯引用:** 19037 | [OpenAlex ID](https://openalex.org/A5043262479)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

在低空经济场景下，提出了基于Lyapunov稳定性理论的SC³闭环框架，将通信延迟与物理控制稳定性关联起来，并通过Stackelberg博弈实现无人机与终端的资源分配；

**💡 创新点**

创新点在于：①将Lyapunov稳定性映射为可量化的通信资源边界；②在Stackelberg博弈中引入稳定性约束，保证控制闭环的实时稳定；③提出了动态结构化剪枝的轻量化PPO算法，使无人机能够在能耗受限的边缘平台上快速逼近博弈均衡；

**🔧 技术方法**

采用的技术包括：Lyapunov稳定性分析、SC³延迟建模、Stackelberg博弈求解、基于多智能体的PPO强化学习以及动态结构化网络剪枝；

**📊 数据集**

使用仿真数据，模拟不同用户数量、无人机数量、链路衰减等参数组合；

**📈 对比分析**

与标准PPO、贪心和随机算法对比，实验显示剪枝PPO在收敛速度更快、最终奖励更高、模型尺寸显著减小，能够在低空经济的动态环境下实现更优的资源利用和控制稳定；

**⚠️ 局限性**

局限性包括：仅在离散的仿真环境验证，缺乏真实场景的实验；对信道模型和能耗模型做了简化假设；算法在极大规模网络下的可扩展性和对突发干扰的鲁棒性仍需进一步研究。

---

## 20. Estimating Force Interactions of Deformable Linear Objects from their Shapes

**arXiv ID:** 2602.01085 | [PDF](https://arxiv.org/pdf/2602.01085v1)

**作者:** Qi Jing Chen `[一作]` (Nanyang Technological University), Quang-Cuong Pham `[通讯]` (Eureka Robotics)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

基于线性可变形物体（DLO）的形状，提出了一种仅凭深度图像观测即可定位并量化外部作用力的位置与大小的算法。

**💡 创新点**

通过推导静力学一致性条件，将 DLO 划分为无扰动段与受扰动段，并利用离散弹性杆模型求解外力与扭矩，实现仅凭形状即可定位并量化外部力。

**🔧 技术方法**

使用离散弹性杆（DER）理论、最小二乘求解线性方程、深度相机（Azure Kinect）与基于图像分割的 DLO 检测 pipeline，配合机器人手臂末端力/扭矩传感器进行验证。

**📊 数据集**

在仿真中使用自定义的 DER 物理模拟，真实实验使用 Denso VS‑060 机器人与自制电缆夹具，采集深度图像和力/扭矩真值。

**📈 对比分析**

将估计力与真实力在角度、相对 L2 误差、作用点位置差距等指标对比，实验显示平均相对 L2 误差约 0.3，角度误差 < 1°，作用点误差 < 40 mm，表明在静态/准静态条件下性能良好。

**⚠️ 局限性**

方法假设 DLO 仅呈弹性变形，忽略塑性与内扭曲，并且依赖低噪声深度测距；在接近切向力或大变形时误差增大，且对深度噪声高度敏感。

---

## 21. "If You're Very Clever, No One Knows You've Used It": The Social Dynamics of Developing Generative AI Literacy in the Workplace

**arXiv ID:** 2602.01386 | [PDF](https://arxiv.org/pdf/2602.01386v1)

**作者:** Qing `[一作]`, Anna Cox `[通讯]`

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过对19位不同行业知识工作者的深度访谈，探讨了他们在工作场所中如何形成与应用生成式人工智能（GenAI）素养的信念与策略。

**💡 创新点**

创新点在于揭示了“消除GenAI使用痕迹”这一社会性行为既可视为对专业能力的正向表达，又会削弱知识共享与透明度，从而对现有AI素养框架补充了社交动态视角。

**🔧 技术方法**

研究方法主要采用半结构化访谈与主题分析，并结合Pinski-Benlian与Annapureddy等两套AI/GenAI素养框架以及COM-B行为模型进行理论归纳。

**📊 数据集**

数据集为19名跨行业（科研、法律、IT、创意、金融、人力资源等）知识工作者的访谈记录，涵盖其使用的GenAI工具（ChatGPT、Copilot、Claude、Gemini等）和工作场景。

**📈 对比分析**

由于研究为定性探究，未进行传统的量化性能对比；研究成果通过主题归纳展示了两类核心能力及对应的学习策略，说明了社交认知对知识共享的正负双重影响。

**⚠️ 局限性**

局限性包括样本规模有限、受访者已是GenAI使用者（缺乏对不愿意或受限使用者的视角）、以及对文化背景、性别等个体差异的探索不足，导致对普适性与迁移性的结论受限。

---

## 22. Rethinking the Flow-Based Gradual Domain Adaption: A Semi-Dual Optimal Transport Perspective

**arXiv ID:** 2602.01179 | [PDF](https://arxiv.org/pdf/2602.01179v1)

**作者:** Zhichao Chen `[一作]` (Peking University), Zhouchen Lin `[通讯]` (Peking University)

**通讯引用:** 25979 | [OpenAlex ID](https://openalex.org/A5016399094)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `40105733-5154-44cd-8090-a8cab9e64b07` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出基于半对偶无平衡最优传输的流模型 E‑SUOT，用来生成中间域，从而实现渐进式领域适应。

**💡 创新点**

创新点在于将流式 GDA 转化为半对偶无平衡 OT 框架，并引入熵正则化消除原先的 min‑max 不稳定性，理论上保证唯一最优且可收敛。

**🔧 技术方法**

技术包括：半对偶最优传输、熵正则化、神经网络拟合势函数与传输映射、梯度流 (ODE) 以及与 Wasserstein 正则化结合的流式生成。

**📊 数据集**

实验数据集：Portraits、MNIST‑45°/60°、Office‑Home（UAD 与 GDA 两种设置）。

**📈 对比分析**

与 Self‑Train、GST、GOAT、CNF、GGF 等方法对比，E‑SUOT 在所有 GDA 任务中均取得最高准确率，在 Office‑Home UDA 任务中平均性能最高，显著提升相对基线。

**⚠️ 局限性**

局限：仅针对特征分布迁移，未将标签信息或标签漂移纳入传输过程；在存在显著标签/概念漂移的场景下可能表现欠佳。

---

## 23. Predicting Anemia Among Under-Five Children in Nepal Using Machine Learning and Deep Learning

**arXiv ID:** 2602.01005 | [PDF](https://arxiv.org/pdf/2602.01005v1)

**作者:** Deepak Bastola `[一作]` (Florida Atlantic University), Yang Li `[通讯]` (Florida Atlantic University)

**通讯引用:** 7773 | [OpenAlex ID](https://openalex.org/A5100421768)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

使用NDHS 2022数据对6-59个月儿童的贫血进行预测，构建并评估十种机器学习与深度学习模型，识别关键风险因素。

**💡 创新点**

首次在尼泊尔人口健康调查数据上进行模型基准测试，采用多方法特征选择与SMOTE处理不平衡数据，提出可用于社区筛查的风险评分框架。

**🔧 技术方法**

特征选择：Chi-square、互信息、点二分相关、Boruta；模型：逻辑回归、SVM、随机森林、XGBoost、KNN、决策树、朴素贝叶斯、线性判别分析、深度神经网络、TabNet；使用交叉验证、SMOTE、GridSearchCV。

**📊 数据集**

NDHS 2022（尼泊尔人口与健康调查）1855例儿童，包含13个分类特征。

**📈 对比分析**

通过重复分层5折交叉验证与SMOTE比较10种模型，逻辑回归在F1-score（64.9%）和召回率（70.1%）上表现最佳，SVM与DNN次之，所有模型准确率约为69–71%。

**⚠️ 局限性**

样本量有限、仅使用间接社会人口学特征导致预测精度受限；交叉设计无法证明因果关系；SMOTE可能引入合成样本偏差。

---

## 24. Supervised sparse auto-encoders as unconstrained feature models for semantic composition

**arXiv ID:** 2602.00924 | [PDF](https://arxiv.org/pdf/2602.00924v1)

**作者:** Ouns El Harzli `[一作]` (University of Oxford), Haixuan Xavier Tao `[通讯]` (Hugging Face)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种监督式稀疏自编码器（SSAE）框架，用预定义的概念字典构建稀疏潜在空间，并仅训练解码器以重构Stable Diffusion 3.5的提示嵌入，从而实现概念级的可解释性、组合泛化和无梯度的特征级编辑。

**💡 创新点**

创新点在于：①将无约束特征模型理论与稀疏自编码器结合，直接在潜在空间预设概念块，消除L1稀疏惩罚与不对齐问题；②利用解码器‑only 训练实现高效可扩展；③通过概念块的组合实现对从未出现过的概念组合的重建与编辑，展示了可解释的组合泛化。

**🔧 技术方法**

核心技术包括：稀疏自编码器、无约束特征模型、概念块稀疏设计、线性解码器、ReLU 激活、Stable Diffusion 3.5 的提示嵌入提取（T5 编码器），以及基于概念字典的监督学习。

**📊 数据集**

数据集为约1500条自定义视觉概念提示（包括外观、姿态、物体、环境等），使用Stable Diffusion 3.5 的T5提示嵌入作为训练目标。

**📈 对比分析**

与传统无监督稀疏自编码器及线性探针相比，SSAE 在概念对齐、组合泛化以及模块化编辑方面表现优异；实验中通过对“金发”与“棕发”概念的交换演示了100% 的成功率，且训练时间仅约12分钟，显著提升了可解释性与编辑效率。

**⚠️ 局限性**

局限性包括：仅能编辑预定义的概念；构建高质量概念字典需要人工；实验规模受限，未与现有编辑方法进行全面对比；仅在提示嵌入上验证，未扩展至U‑Net或Transformer等其它表示。

---

## 25. Your Self-Play Algorithm is Secretly an Adversarial Imitator: Understanding LLM Self-Play through the Lens of Imitation Learning

**arXiv ID:** 2602.01357 | [PDF](https://arxiv.org/pdf/2602.01357v1)

**作者:** Shangzhe Li `[一作]` (UNC Chapel Hill), Weitong Zhang `[通讯]` (UNC Chapel Hill)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过将LLM自对弈微调视为对抗式模仿学习，建立了理论框架并推导出收敛性质。

**💡 创新点**

创新点在于提出基于混合χ²散度的自对弈微调算法，保证奖励有界且训练更稳定。

**🔧 技术方法**

采用对抗式模仿学习、χ²散度正则、KL约束与最小二乘回报学习等技术。

**📊 数据集**

使用UltraChat SFT数据集的5万条样本，并在Qwen3-4B、Mistral-7B等模型上验证。

**📈 对比分析**

与SFT、SPIN等基准比较，实验显示本方法在Arc、MMLU、HellaSwag、WinoGrande等基准上均优于对手。

**⚠️ 局限性**

局限性包括受专家数据质量限制、需要多轮迭代且对模型规模与计算成本有一定依赖。

---

## 26. LRAgent: Efficient KV Cache Sharing for Multi-LoRA LLM Agents

**arXiv ID:** 2602.01053 | [PDF](https://arxiv.org/pdf/2602.01053v1)

**作者:** Hyesung Jeon `[一作]` (Seoul National University), Jae-Joon Kim `[通讯]` (Seoul National University)

**通讯引用:** 4032 | [OpenAlex ID](https://openalex.org/A5003219699)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计了LRAgent框架，用于多LoRA LLM代理的KV缓存共享，显著降低内存和计算开销。

**💡 创新点**

创新点在于将KV缓存拆分为共享的基缓存和低秩适配器缓存，并在共享‑A多LoRA结构下进一步共享低秩缓存；同时提出Flash‑LoRA‑Attention通过重排注意力计算，避免完整维度展开，实现高效运行时重构。

**🔧 技术方法**

采用LoRA/多LoRA、共享‑A、低秩缓存压缩、Flash‑LoRA‑Attention、FlashAttention、GPU并行实现等技术。

**📊 数据集**

使用HotpotQA和ScienceQA的多步推理数据集，并以AutoAct生成的LLaMA‑2‑70B‑Chat轨迹作为训练与评估数据。

**📈 对比分析**

与非共享Baseline、FullShared、DroidSpeak等方法比较，准确率保持低于1%下降；BaseShared与BaseLRShared在吞吐量/TTFT上分别提升约1.2–1.4×，BaseLRShared接近FullShared；内存使用下降约⅓。

**⚠️ 局限性**

局限性包括：LR预填充仍需与新代理同步，导致计算接近非共享；低秩假设在某些任务中可能不够精细；目前实验仅验证LoRA作用于查询/值，关键/输出层适用性待进一步验证；实验环境为单GPU，缺乏大规模多GPU分布式评估。

---

## 27. ESSAM: A Novel Competitive Evolution Strategies Approach to Reinforcement Learning for Memory Efficient LLMs Fine-Tuning

**arXiv ID:** 2602.01003 | [PDF](https://arxiv.org/pdf/2602.01003v1)

**作者:** Zhishen Sun `[一作]` (Xi’an Jiaotong University), Haishan Ye `[通讯]` (Xi’an Jiaotong University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种全参数零阶微调框架 ESSAM，通过在演化策略中加入Sharpness‑Aware Maximization（SAM）机制，提升大型语言模型（LLM）的数学推理能力。

**💡 创新点**

创新点在于：① 将 SAM 的邻域探测与零阶搜索结合，形成两阶段评估更新；② 通过邻域探测引导模型朝平坦、稳健解收敛；③ 在保持推理级别 GPU 内存使用的前提下，实现与 RL（PPO、GRPO）相当甚至更优的推理性能。

**🔧 技术方法**

使用技术包括：演化策略（ES）、Sharpness‑Aware Maximization（SAM）、GPU 内存压缩技术（如 vLLM 的 KV‑cache 控制）、零阶梯度估计、随机种子重放评估（SRE）与分解式原地更新（DIPU）等。

**📊 数据集**

数据集：GSM8K（数学推理问答数据集），用于训练与评估模型的数学推理准确率。

**📈 对比分析**

与标准 ES、PPO、GRPO 进行对比。平均准确率：ESSAM 78.27%（比 PPO 77.72%、GRPO 78.34% 轻微领先），显著高于原始模型 70.14% 及标准 ES 75.97%。GPU 内存使用方面，ESSAM 比 PPO 低 18×，比 GRPO 低 10×；训练时间上，ESSAM 在大模型上可快于 GRPO，虽在小模型上略慢，但仍在可接受范围。

**⚠️ 局限性**

局限性包括：① 仍需显著的计算资源，尤其在极大模型上训练时间相对较长；② 依赖规则化奖励，可能不适用于所有类型的推理任务；③ 在不同任务或更大模型上的泛化性尚未充分验证；④ 对超参数敏感，需要进一步自动化调优。

---

## 28. WinFLoRA: Incentivizing Client-Adaptive Aggregation in Federated LoRA under Privacy Heterogeneity

**arXiv ID:** 2602.01126 | [PDF](https://arxiv.org/pdf/2602.01126v1)

**作者:** Mengsha Kou `[一作]` (RMIT University), Minhui Xue `[通讯]` (CSIRO Data61 and Responsible AI Research Centre)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了WinFLoRA，一种在隐私异质化的联邦LoRA框架，通过逆噪声加权聚合为低噪声更新赋予更大影响力，并用噪声估计替代自报隐私偏好，直接对联邦学习进行激励；

**💡 创新点**

创新点在于：①利用LOO‑PCA从上传的LoRA适配器中估计客户端注入的DP噪声，避免需要可信第三方或自报信息；②采用逆噪声加权作为聚合权重，既抑制高噪声干扰，又将权重回报作为激励，形成无外部支付的激励机制；③用累积UCB方法让客户端自适应选择最优噪声水平；④从理论上证明存在稳定马尔可夫均衡。

**🔧 技术方法**

核心技术包括：低秩适配器LoRA、联邦学习（FedAvg风格的块级聚合）、高斯差分隐私、LOO‑PCA噪声估计、逆噪声加权聚合、UCB在线决策、随机聚合马尔可夫博弈分析。

**📊 数据集**

使用TinyLlama和GPT‑2‑Large两大预训练LLM，在三种文本分类基准数据集AGNews、DBpedia、20Newsgroups上进行实验，采用非IID Dirichlet划分（α=0.3）并设定10个客户端。

**📈 对比分析**

与FedIT、Flora、FedMT等基线以及各自带INA的版本比较，WinFLoRA在所有模型与数据集上平均提升全局精度达52.58%（最高79.76%），客户端平均效用提升至2.56倍；同时平均噪声水平下降，说明在保持隐私的同时实现更优性能。

**⚠️ 局限性**

局限性包括：①噪声估计依赖LoRA适配器的公共子空间，若噪声模型与假设不符会影响权重分配；②对噪声尺度离散度敏感，精细化动作集会加大收敛时间；③实验仅考虑高斯DP与单一模型规模，尚未验证在极端非IID或更大模型/多任务场景下的鲁棒性；④通信成本和加权计算在极大规模系统中的可扩展性未深入探讨。

---

## 29. On the Spectral Flattening of Quantized Embeddings

**arXiv ID:** 2602.00969 | [PDF](https://arxiv.org/pdf/2602.00969v1)

**作者:** Junlin Huang `[一作]` (Hong Kong University of Science and Technology), Xiaowen Chu `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 10346 | [OpenAlex ID](https://openalex.org/A5100730785)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过理论分析和实验验证，探究低精度（4位）量化对大型语言模型语义表示的谱结构影响，并证明量化导致谱扁平化、稳定秩提升以及表示崩塌。

**💡 创新点**

创新点在于将 Zipf 统计与随机矩阵理论结合，提出权重和梯度的幂律谱衰减模型，并证明统一量化破坏了重尾谱，从而导致稳定秩增加和语义表示崩塌。

**🔧 技术方法**

主要技术包括随机矩阵理论、谱扰动分析、稳定秩度量、统一量化模型（MXFP4/NVFP4）以及对 GPT‑2 线性层的奇异值谱分析。

**📊 数据集**

实验基于 GPT‑2‑124M 语言模型，在 OpenWebText 语料上进行训练，使用 4‑bit NVFP4 量化方案。

**📈 对比分析**

与浮点（FP16/FP32）训练进行对比；实验显示量化后模型的稳定秩明显升高，奇异值尾部被噪声吞噬，导致语义编码能力下降，整体性能出现退化。

**⚠️ 局限性**

局限性包括：仅分析线性层的谱影响，未考虑非线性激活和注意力机制；量化方案仅为均匀 4‑bit；实验仅在 GPT‑2‑124M 上验证，缺乏在更大模型或不同数据集上的泛化评估。

---

## 30. Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models

**arXiv ID:** 2602.01428 | [PDF](https://arxiv.org/pdf/2602.01428v1)

**作者:** Weiqing He `[一作]` (University of Pennsylvania), Qi Long `[通讯]` (University of Pennsylvania)

**通讯引用:** 5762 | [OpenAlex ID](https://openalex.org/A5002149616)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了可量化水印强度的新定义，并用它来刻画水印强度与推理效率之间的 Pareto 取舍；同时提出了伪随机接受机制，打破了先前认为不可避免的两者冲突；

**💡 创新点**

①将水印强度定义为水印分布与原始分布的 KL 散度，直接与检出难度关联；②把冲突转化为受约束的优化问题并给出显式曲线；③引入伪随机接受，使得推理既保持最大采样效率又达到最大水印强度；

**🔧 技术方法**

无偏水印编码、KL 散度分析、受约束优化、伪随机接受、Speculative Sampling、Gumbel‑max 与 SynthID 水印、深度神经网络检测器（MLP）

**📊 数据集**

对公开 LLM（draft/target 对）在问答和开放式生成任务上生成 2000 条文本（训练 1000 条，测试 1000 条），使用公开问答/开放式生成数据集；

**📈 对比分析**

与标准 Speculative Sampling 做对比：AATPS（采样效率）基本相同；在 Gumbel‑max 与 SynthID 上，伪随机接受后在 1% FPR 下 TPR 明显提升（接近理想检测器），且不降低生成质量（Perplexity 与 LogPPL 维持不变）

**⚠️ 局限性**

仅适用于无偏、退化水印；对非退化或偏置水印的推广未知；尚未评估对人类编辑鲁棒性；仅验证了标准 Speculative Sampling，未扩展到树形或其他变体

---

## 31. TLDiffGAN: A Latent Diffusion-GAN Framework with Temporal Information Fusion for Anomalous Sound Detection

**arXiv ID:** 2602.01060 | [PDF](https://arxiv.org/pdf/2602.01060v1)

**作者:** Chengyuan Ma `[一作]` (Shenzhen International Graduate School), Wenming Yang `[通讯]` (Dalian Maritime University)

**通讯引用:** 473 | [OpenAlex ID](https://openalex.org/A5005355107)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `3855fcda-48ef-4070-a15e-803cd5c84d83` `ba576bd1-e51d-44e8-8077-fc943b333c93` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出一种融合潜在扩散模型与GAN的TLDiffGAN框架，用双分支同时处理声谱图和原始波形，实现无监督异常声音检测并定位异常。

**💡 创新点**

创新点在于将潜在扩散模型嵌入GAN生成器以提升生成质量，并引入TMixup时间混合增强和预训练Transformer音频编码器，使多模态特征融合并对细粒度时间模式高度敏感。

**🔧 技术方法**

采用潜在扩散模型、GAN、TMixup、预训练音频编码器（如EAT）、判别器梯度惩罚以及KNN/LOF/GMM/SOS等多种离群检测技术。

**📊 数据集**

使用DCASE 2020 Challenge Task 2（MIMII+ToyADMOS）六类工业设备音频数据集。

**📈 对比分析**

与官方自编码基线、ANP、GANomaly、ASD‑Diffusion、AEGAN‑AD等无监督生成方法对比，TLDiffGAN平均AUC 88.60%、pAUC 74.35%，在大多数机型上均优于对手。

**⚠️ 局限性**

局限性包括模型结构复杂、训练成本高；在极为平稳或噪声干扰大的信号中加入原始波形特征可能冗余；仅在单一域内验证，跨域泛化能力尚未充分评估。

---

## 32. Neural FOXP2 -- Language Specific Neuron Steering for Targeted Language Improvement in LLMs

**arXiv ID:** 2602.00945 | [PDF](https://arxiv.org/pdf/2602.00945v1)

**作者:** Anusa Saha `[一作]`, Amitava Das `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种基于稀疏特征的推理时干预方法 Neural FOXP2，能够通过编辑少量语言相关神经元，使多语言 LLM 在无显式语言提示下默认使用指定语言（如印地语或西班牙语）。

**💡 创新点**

创新点在于：① 将语言偏好视为可机理化的稀疏低秩控制电路；② 通过自编码器提取稀疏特征识别“语言神经元”；③ 利用层级 SVD 找到低秩语言转移方向，并在连贯窗口内做符号稀疏激活偏移，从而实现无全量微调的默认语言切换。

**🔧 技术方法**

核心技术包括：自编码器（Sparse Autoencoder）构建稀疏特征基；语言选择性与因果效应评估（Δ_M、LiftSlope）；层级 SVD 与 eigengap/effective‑rank 诊断获取低秩方向；推理时激活补丁（signed sparse shift）和可调强度控制。

**📊 数据集**

实验使用 LLaMA‑3 8B 作为基础模型；通过匹配语义的英文、印地语、西班牙语提示集合进行特征提取和干预评估；任务涵盖机器翻译、问答、自然语言推理与摘要，使用公开的多语言 benchmark 评测默认性提升和任务性能。

**📈 对比分析**

与 baseline（无干预、仅提示、随机特征编辑、编辑窗口外、仅稀疏或仅低秩）进行对比，Neural FOXP2 在 Δ_mass 与 Δ_lid 方面均显著提升（约 +0.85 对印地语、+0.69 对西班牙语），同时保持或提升任务精度（Δ_S 接近 0），且跨语言泄漏低，模型稳定性高。

**⚠️ 局限性**

主要局限：1) 仅适用于已有能力的中高资源语言；2) 需要精细的 token 集和语言标签，易受分词器与脚本差异影响；3) 编辑仍可能引发细粒度语义漂移、风格偏差或安全政策失衡；4) 对低资源或极端脚本语言缺乏充分验证；5) 依赖特征稀疏性与低秩假设，模型架构变化或训练方式不同可能导致效果下降。

---

## 33. MCP-Atlas: A Large-Scale Benchmark for Tool-Use Competency with Real MCP Servers

**arXiv ID:** 2602.00933 | [PDF](https://arxiv.org/pdf/2602.00933v1)

**作者:** Chaithanya Bandi `[一作]` (Scale AI), Bing Liu `[通讯]` (Scale AI)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并发布了一个包含 1000 个真实 MCP 服务器与 220 种工具的大规模基准，用单轮自然语言提示评估 LLM 的工具使用能力。

**💡 创新点**

创新点：① 使用真实生产服务器与跨域工具集，② 采用 claims‑based 评估与内部诊断而非主观 LLM‑judge，③ 对工具发现、多步工作流、错误恢复进行细粒度失败分类。

**🔧 技术方法**

技术手段：MCP 协议、JSON schema 校验、容器化 harness、Gemini 2.5 Pro 作为判分器、基于 claims 的自动验证与诊断。

**📊 数据集**

数据集：1,000 个手工构造任务，分为公开 500 任务与隐藏 500 任务，覆盖 36 台 MCP 服务器、220 个工具，提示中不泄露工具或服务器名称。

**📈 对比分析**

比较方法：在同一 harness 上评测前沿模型（Claude Opus 4.5、Gemini 3 Pro、GPT‑5 等），Claude Opus 4.5 通过率 62.3%，最佳模型超过 50%，低端模型低至 5%。

**⚠️ 局限性**

局限性：单轮交互、仅读操作、未强制调用/效率限制、易受 API 变更影响、未覆盖写操作与多轮恢复策略。

---

## 34. Harnessing Flexible Spatial and Temporal Data Center Workloads for Grid Regulation Services

**arXiv ID:** 2602.01508 | [PDF](https://arxiv.org/pdf/2602.01508v1)

**作者:** Yingrui Fan `[一作]` (Dartmouth), Junbo Zhao `[通讯]` (Dartmouth)

**通讯引用:** 11295 | [OpenAlex ID](https://openalex.org/A5042402520)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种统一的时空协同优化框架，既决定分布式数据中心的工作负载调度，又确定日常频率调节容量承诺。

**💡 创新点**

创新点在于将工作负载调度与频率调节容量联合优化，构造空间–时间网络模型，并通过概率约束（Gaussian envelope 与 Value‑at‑Risk）确保可交付的调节能力，从而提升调节容量与收益。

**🔧 技术方法**

使用空间–时间网络表示、线性/SOCP 约束、Gaussian envelope 外包逼近、VaR 置信区间、DC 电力流模型、Gurobi 求解器等技术。

**📊 数据集**

基于修改版 IEEE 68‑bus 系统、真实数据中心工作负载跟踪（Alibaba）、PJM 调节价格与信号、ISO‑NE/NYISO 负荷数据。

**📈 对比分析**

与分阶段优化、独立协调两种基线相比，协同方案在总系统成本最低、可调节容量最高、调节收益最大、净成本最低，并在收入‑风险平衡上表现最佳。

**⚠️ 局限性**

局限性包括对负载预测和调节信号历史的依赖、假设任务可在任意中心自由调度（可能忽略部分业务 SLA）、以及随着中心数量和时隙数增大时计算量显著上升，需进一步简化以适用于更大规模系统。

---

## 35. Addressing Explainability of Generative AI using SMILE (Statistical Model-agnostic Interpretability with Local Explanations)

**arXiv ID:** 2602.01206 | [PDF](https://arxiv.org/pdf/2602.01206v1)

**作者:** Zeinab Dehghani `[一作]` `[通讯]` (University of Hull), Zeinab Dehghani (University of Hull)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534`

**🎯 论文内容**

论文未提供具体内容，因此无法总结做了什么。

**💡 创新点**

论文未提供具体内容，因此无法总结创新点。

**🔧 技术方法**

论文未提供具体内容，因此无法总结使用的技术。

**📊 数据集**

论文未提供具体内容，因此无法总结使用的数据集。

**📈 对比分析**

论文未提供具体内容，因此无法总结比较的方法和性能。

**⚠️ 局限性**

论文未提供具体内容，因此无法总结限制。

---

## 36. PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers

**arXiv ID:** 2602.01077 | [PDF](https://arxiv.org/pdf/2602.01077v1)

**作者:** Haopeng Li `[一作]` (Hong Kong University of Science and Technology), Zeke Xie `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 253 | [OpenAlex ID](https://openalex.org/A5066773635)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了一种训练无关的 Piecewise Sparse Attention，采用精确-近似分层处理，显著加速 Diffusion Transformer 的自注意力计算。

**💡 创新点**

创新点在于把注意力拆分为精确块和近似块，并在近似块上使用块级 Taylor 展开和全局一次性一阶校正，既保持了近似精度又兼顾了硬件效率；同时提出协方差感知的 Top‑k 选择策略，进一步降低近似误差。

**🔧 技术方法**

核心技术包括：块级划分与精确计算、块级 0 阶/1 阶 Taylor 近似、全局一次性 1 阶校正、协方差感知的块选择、融合自注意力核实现。

**📊 数据集**

在视频生成任务使用 Wan2.1（1.3B/14B）与 Hunyuan‑Video；在图像生成任务使用 SD 3.5 与 FLUX.1‑dev；评估数据集为 VBench（视频质量与一致性）和标准图像生成评测（FID、SSIM、LPIPS、Human Preference 评测）。

**📈 对比分析**

与 FlashAttention‑2/3（全注意力）和 SpargeAttn（块稀疏注意力）比较，稀疏率 85% 时可实现约 1.9×–2.6× 的速度提升，同时在 VBench 以及 FLUX/SD 的视觉质量指标上保持或超过全注意力水平，尤其在高稀疏率下质量更稳健。

**⚠️ 局限性**

局限性包括：近似仍可能在极低密度或高度动态场景下产生误差；全局 1 阶校正使用预先计算的全局统计量，可能在某些分布变化较大的模型中效果受限；对 GPU 内存和缓存的需求仍高，尚未在 CPU 或边缘设备上验证。

---

## 37. SRVAU-R1: Enhancing Video Anomaly Understanding via Reflection-Aware Learning

**arXiv ID:** 2602.01004 | [PDF](https://arxiv.org/pdf/2602.01004v1)

**作者:** Zihao Zhao `[一作]` (University of Iowa), Muchao Ye `[通讯]` (University of Iowa)

**通讯引用:** 491 | [OpenAlex ID](https://openalex.org/A5024079930)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 SRVAU‑R1，一个基于自我反思的多模态大模型框架，用以提升视频异常理解的深度与稳定性。

**💡 创新点**

创新点在于首创反思导向的链式思维（Chain‑of‑Thought）数据集，并将反思机制嵌入双阶段训练（SFT+RFT）和奖励设计，显著增强模型的自我纠错与因果推理能力。

**🔧 技术方法**

使用多模态大模型（如 Qwen2.5‑VL‑3B、Qwen3‑VL‑30B）、Chain‑of‑Thought + 自我反思提示、基于 GRPO 的强化学习，并在奖励中加入任务奖励、反思质量奖励与时序 IoU 奖励。

**📊 数据集**

构建了基于 UCF‑Crime、ECVA、MSAD 三个公开异常视频数据集的 4,602 条反思增强样本，涵盖 19 类异常行为。

**📈 对比分析**

与 Qwen、InternVL 系列基线以及 VAU‑R1、HolmesVAU 等方法对比，QA 多选准确率、mIoU、R@0.3/0.5/0.7 均显著提升，尤其在 OOD 的 TAG 任务中取得 9–38 点的性能跃升，验证了反思机制的有效性。

**⚠️ 局限性**

仍需大量算力和反思数据，反思数据规模与教师模型的影响明显，且在极端噪声或极端场景下的鲁棒性尚待进一步研究。

---

## 38. T2M Mamba: Motion Periodicity-Saliency Coupling Approach for Stable Text-Driven Motion Generation

**arXiv ID:** 2602.01352 | [PDF](https://arxiv.org/pdf/2602.01352v1)

**作者:** Xingzu Zhan `[一作]` (Shenzhen University), Xiaochun Mai `[通讯]` (Shenzhen University)

**通讯引用:** 269 | [OpenAlex ID](https://openalex.org/A5034208042)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

研究文本到3D动作生成，提出T2M Mamba框架，解决关键帧重要性与周期性耦合及文本同义词敏感问题。

**💡 创新点**

创新点：①通过增强的Density Peaks Clustering与FFT自相关估计关键帧权重与运动周期，并将其注入Mamba的状态空间；②设计PDCAM差分注意力，结合关键帧加权、相位旋转编码，实现跨模态对齐鲁棒性。

**🔧 技术方法**

技术手段：基于Mamba状态空间模型、FFT加速自相关、改进的密度峰聚类、差分注意力、相位旋转编码、CLIP文本编码、UniPC推理。

**📊 数据集**

数据集：HumanML3D 与 KIT-ML 两大文本-动作配对基准。

**📈 对比分析**

与多种SOTA（T2M、MDM、MotionDiffuse、MLD、Motion Mamba、T2M-GPT、AttT2M、MoMask等）在R‑Precision、FID、MM Dist、Diversity、MModality等指标对比；T2M Mamba在HumanML3D上Fid 0.068，R‑Precision Top1/2/3分别为0.506/0.696/0.793，Diversity与真实接近，整体优于或接近现有最佳方法。

**⚠️ 局限性**

局限性：对极长序列或多周期动作仍有轻微漂移；模型规模与计算量相对较大；在少样本或跨域文本时鲁棒性仍需提升。

---

## 39. Not All Preferences Are Created Equal: Stability-Aware and Gradient-Efficient Alignment for Reasoning Models

**arXiv ID:** 2602.01207 | [PDF](https://arxiv.org/pdf/2602.01207v1)

**作者:** Hui Wu `[一作]` (Aerospace Information Research Institute, Chinese Academy of Sciences), Dawei Yin `[通讯]` (Baidu Inc.)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了SAGE框架，通过动态的基于梯度信噪比的样本筛选实现对数学推理模型的偏好优化。

**💡 创新点**

引入了基于局部曲率的稳定性-aware评分和池化式的难度课程，能够自适应地挑选高信噪比的偏好对。

**🔧 技术方法**

使用了直接偏好优化（DPO）与多响应对比损失（NCA）作为基准，并构建了梯度信噪比的Newton启发式SAGE评分。

**📊 数据集**

在Light-R1、GSM8K、MATH500、Minerva-MATH、Gaokao23-Math、OlympiadBench、CollegeMath、AMC23、AIME24等数学推理基准上进行训练和评测。

**📈 对比分析**

与全量DPO、随机子采样DPO以及传统的梯度或曲率筛选方法对比，SAGE在三种模型规模（1.5B/3B/7B）上平均提升了数个百分点，尤其在3B规模下达到同类最佳成绩。

**⚠️ 局限性**

仅依赖离线静态偏好语料，未进行在线探索；额外的前向评分步骤带来一定计算开销。

---

## 40. PedagoSense: A Pedology Grounded LLM System for Pedagogical Strategy Detection and Contextual Response Generation in Learning Dialogues

**arXiv ID:** 2602.01169 | [PDF](https://arxiv.org/pdf/2602.01169v1)

**作者:** Shahem Sultan `[一作]` (Al Andlus University), Besher Hassan `[通讯]` (Mohamed bin Zayed University of Artificial Intelligence)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了 Tutor Copilot 系统，利用两层分类器先检测对话中是否存在教学策略，再进行细粒度分类，并通过 LLM 推荐最合适的策略。

**💡 创新点**

创新点在于将二元分类与多类分类相结合，结合 GPT‑4o 数据增强、LIME 解释、Hybrid‑BERT 组合投票与概率投票等多种技术，以实现实时、个性化的教学策略检测与推荐。

**🔧 技术方法**

使用了 BERT（Base 与 Large）进行模型微调，SMOTE 与 GPT‑4o 进行样本增广，LIME 进行可解释性分析，LLM（GPT‑4o、LLaMA‑2）评估，BM25+嵌入相似度融合以及混合投票/概率投票策略。

**📊 数据集**

主要数据集来自 Dr. Kaushal Kumar Maurya 提供的 tutor‑student 对话数据，并补充 697 条 Hugging Face DailyDialog 通用对话；通过 GPT‑4o 对策略标签进行增广生成更平衡的数据。

**📈 对比分析**

与传统 Logistic‑Regression、SVM、Random Forest 等基线模型比较，二元分类 BERT 在测试集上 F1 达 98.5%，多类分类宏 F1 约 45%；推荐任务中 Hybrid‑BERT Prob 方案 F1 0.4815，显示显著优于单一模型。

**⚠️ 局限性**

局限性包括样本量不足、策略类别不平衡、相似策略难以区分、模型对噪声敏感，以及缺乏多模态输入导致对真实教学场景的泛化能力有限。

---

## 41. The Stacked Autoencoder Evolution Hypothesis

**arXiv ID:** 2602.01026 | [PDF](https://arxiv.org/pdf/2602.01026v1)

**作者:** Hiroyuki Iizuka `[一作]` (Hokkaido University), Hiroyuki Iizuka `[通讯]` (Hokkaido University)

**通讯引用:** 1112 | [OpenAlex ID](https://openalex.org/A5020353235)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `57a58b01-81b4-4d75-a45c-2e891f272b50` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文提出并演示了“堆叠自编码器进化假说”，认为进化过程本身是多层信息压缩与重构的自组织循环。

**💡 创新点**

创新点在于把自编码器的层级表示学习机制映射到自复制的分子层级，从而解释突变在抽象空间中的扰动可导致大规模、跳跃式演化。

**🔧 技术方法**

技术上利用人工化学模拟，构建三种长度的分子，并用卷积/反卷积网络实现分子间的非线性转换，模拟自复制循环。

**📊 数据集**

数据集为自生成的分子状态序列，初始为[-1,1]区间的随机数，在模拟过程中不断产生。

**📈 对比分析**

通过计算重构误差（MSE）评估不同层级之间信息传递，发现随着进化阶段的推进误差显著下降，表明层级自编码结构已形成；未与其他进化模型做直接性能对比。

**⚠️ 局限性**

局限性包括：选择压力极其简单，只关注复制易度，缺乏对分子复杂度和功能性需求的驱动；缺乏真实生物分子或实验验证；模型未考虑空间、生态及多样性等重要因素。

---

## 42. Breaking the Temporal Complexity Barrier: Bucket Calculus for Parallel Machine Scheduling

**arXiv ID:** 2602.01356 | [PDF](https://arxiv.org/pdf/2602.01356v1)

**作者:** Noor Islam S. Mohammad `[一作]` `[通讯]` (New York University), Noor Islam S. Mohammad (New York University)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

通过引入 bucket calculus 并提出 bucket‑indexed MILP，研究者实现了对 P_m|r_j|C_max 调度问题的时间离散化降维，显著减少决策变量并保持近似最优。

**💡 创新点**

创新点在于部分离散化与多层桶化技术，将原 O(T^n) 的时间维度压缩到 O(B^n)，理论加速因子达 2.75×10^37，且误差不超过 5%。

**🔧 技术方法**

使用了精度感知桶化、分层桶算子、分段时间离散化、混合整数规划求解器以及量化修正等技术。

**📊 数据集**

实验基于 20–400 作业、4–32 台机器的人工合成实例，覆盖不同作业时长分布、释放时间密度与规模变化。

**📈 对比分析**

与传统时间索引 MILP、SPT 启发式、遗传算法和约束规划等方法对比，bucket 方法在 20 作业实例上仅比最优低 2.4%，并比时间索引 MILP 快 10^37 倍，资源利用率 97.6%，负载均衡 σ/μ<0.006。

**⚠️ 局限性**

主要限制包括对桶粒度 Δ 与异质性参数 κ 的调优敏感，近似误差最大 5%，在 400 作业以上仍存在显著内存占用，并且假设作业集静态，无法直接应用于动态实时排程。

---

## 43. Large Language Models as Students Who Think Aloud: Overly Coherent, Verbose, and Confident

**arXiv ID:** 2602.01015 | [PDF](https://arxiv.org/pdf/2602.01015v1)

**作者:** Conrad Borchers `[一作]` (Carnegie Mellon University), Roger Azevedo `[通讯]` (University of Central Florida)

**通讯引用:** 17109 | [OpenAlex ID](https://openalex.org/A5019212451)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

使用GPT‑4.1等大语言模型在化学教学中逐步生成学生思考录音，并与真实学生的逐步思考进行比较，评估其模仿程度

**💡 创新点**

首次系统量化LLM在模拟初学者思考时的连贯性、冗长度和对后续步骤成功率的校准误差，揭示专家视角的“盲点”

**🔧 技术方法**

采用提示式生成、句子变换器（sentence‑transformer）计算语义余弦相似度、词汇多样性、句长等语言学特征，并用ROC、AUC、校准偏差等指标评估预测

**📊 数据集**

630条来自两套智能辅导系统的多步化学问题思考录音数据集

**📈 对比分析**

通过与真实学生录音的余弦相似度、上下文一致性对比评估思考模拟；在预测方面使用点双相关、AUC、校准偏差检验；结果显示模型连贯度高但与学生差距大，预测几乎与随机无异，且存在显著过度估计

**⚠️ 局限性**

仅限化学领域、使用未微调的通用LLM、仅评估单步预测，缺乏跨领域验证与个性化适配

---

## 44. Unifying Adversarial Robustness and Training Across Text Scoring Models

**arXiv ID:** 2602.00857 | [PDF](https://arxiv.org/pdf/2602.00857v1)

**作者:** Manveer Singh Tamber `[一作]` (University of Waterloo), Jimmy Lin `[通讯]` (University of Waterloo)

**通讯引用:** 22146 | [OpenAlex ID](https://openalex.org/A5082997975)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `a2602d71-93ab-4bad-974b-672788df8193` `6215c339-3735-4be3-8a07-5bbb7004712d` `a4b10f5d-130b-4e77-9367-6469ec621899` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出统一文本评分模型（检索器、重排序器、奖励模型）的对抗鲁棒性研究，并系统评估多种对抗训练方法在不同攻击与模型角色下的鲁棒性转移和任务效果。

**💡 创新点**

创新点在于：①把检索、重排序和奖励模型放在同一“文本评分”框架内，形成可比较的失败判定；②设计并引入多种对抗训练策略（rudimentary、HotFlip、PGD、内容注入、paraphrasing），并验证它们在不同攻击场景的泛化；③提出组合训练方案，证明多手段叠加可提升鲁棒性而不损失甚至提升任务性能；④在RLHF中演示对抗训练奖励模型可降低奖励劫持并提升对齐。

**🔧 技术方法**

使用技术包括：对抗训练（PGD、HotFlip、rudimentary、内容注入、paraphrasing）、梯度引导token/词/字符替换、MLM-guided swaps、Beam搜索攻击、RLHF（REINFORCE++）、Gemma-3生成同义句、softmax交叉熵、KL正则等。

**📊 数据集**

数据集：检索/重排序训练使用MSMARCO、HotpotQA、NQ、Fever；评估使用TREC-DL19/20、BEIR；奖励模型训练使用HelpSteer3、Skywork v0.2；评估使用RewardBench 2、PPE；RLHF训练使用Llama-3.2-3B-Instruct、Llama-3.1-8B-Instruct；对齐评估使用WildBench v2、Arena-Hard v2。

**📈 对比分析**

比较方法：对比基线无对抗训练、单一对抗训练（每种方法单独训练）以及组合训练，评估指标包括攻击成功率（ASR）、平均编辑步数、NDCG@10、偏好准确率、KL散度和LLM评判偏好。结果显示：组合训练在大多数攻击下鲁棒性最高，且对任务性能无损或略有提升；RLHF使用组合对抗奖励模型可显著降低奖励劫持并提升模型在评判者中的偏好分。

**⚠️ 局限性**

限制：1) 仍未达到完美鲁棒性，部分攻击转移效果不佳；2) paraphrasing训练鲁棒性有限且有时不利；3) 对抗训练计算成本高；4) 研究聚焦文本评分任务，未涵盖生成任务；5) 结果受攻击预算和数据集分布影响，需进一步验证。

---

## 45. Phase Transitions for Feature Learning in Neural Networks

**arXiv ID:** 2602.01434 | [PDF](https://arxiv.org/pdf/2602.01434v1)

**作者:** Andrea Montanari `[一作]` (Stanford University), Zihao Wang `[通讯]` (Stanford University)

**通讯引用:** 19139 | [OpenAlex ID](https://openalex.org/A5100451602)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `57a58b01-81b4-4d75-a45c-2e891f272b50`

**🎯 论文内容**

本文研究了两层神经网络在多指数模型（multi‑index model）下梯度下降（GD）训练的高维动力学，推导了当样本比 n/d 趋向某一阈值 δ_* 时 Hessian 谱出现负离群特征值，进而导致网络能够学习到“难”子空间的特征，并用此解释了 Grokking 现象。

**💡 创新点**

创新点在于：① 用随机矩阵和自洽动力学（DMFT）严格刻画 Hessian 的全谱分布与离群值；② 给出了可计算的阈值 δ_*（与网络结构、损失、激活函数等有关），并证明 δ_* 与最优谱方法的阈值 δ_ 之间存在严格差距；③ 通过阈值演化解释了学习两阶段（过拟合→特征学习）的出现。

**🔧 技术方法**

主要技术包括：高维随机矩阵理论（Marchenko‑Pastur、BBP 触发）、动力学平均场理论（DMFT）对 GD 轨迹的低维化描述、离群特征值的矩阵奇异值分解与残差积分、以及对离群矩阵的低秩近似和收敛分析。

**📊 数据集**

实验数据为合成数据：高维高斯协变量 x∈ℝ^d，隐空间维度 k 固定，目标函数 y=h(*^T x) 取典型的单指数或多指数形式（如无噪声相位检索 y=z^2），样本数 n 与维度 d 比例 δ 变化。

**📈 对比分析**

通过与最优谱方法（如针对特征的预处理 Ψ）的阈值对比，本文证明 δ_* > δ_opt，体现了 GD 的子最优性。数值实验显示，预测的阈值 δ_* 与实验得到的学习成功率与最终相关性（ρ）的跃迁高度一致，并在不同激活函数下验证了 Grokking 的时间与 δ 的关系。

**⚠️ 局限性**

局限性包括：① 仅在宽度 m 为常数（甚至 m=1）且协变量为正交高斯时成立；② 解析阈值是基于 t=O(1) 的 GD 步数，无法完整刻画 t≳log d 的长期动力学；③ 对非高斯、非正交协变量的情形仍未得到理论支持，且阈值 δ_* 通常比最优谱方法的阈值更大。

---

## 46. RoDiF: Robust Direct Fine-Tuning of Diffusion Policies with Corrupted Human Feedback

**arXiv ID:** 2602.00886 | [PDF](https://arxiv.org/pdf/2602.00886v1)

**作者:** Amitesh Vatsa `[一作]` (Arizona State University), Wanxin Jin `[通讯]` (Arizona State University)

**通讯引用:** 418 | [OpenAlex ID](https://openalex.org/A5017350249)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

在预训练的扩散策略上，通过直接对比标签对进行强化学习，提出一种鲁棒的微调方法 RoDiF，使机器人在面临人类反馈噪声时仍能保持对目标行为模式的高对齐率。

**💡 创新点**

创新点主要有三：① 统一 MDP 形式将扩散去噪过程与环境动力学合并，允许在同一决策过程内直接使用 DPO；② 将 DPO 损失重新表述为几何上的假设切割问题，并引入保守投票策略以滤除错误标签；③ 通过对冲刺阈值（γ）调节的鲁棒损失实现对任意比例错误标签的容忍。

**🔧 技术方法**

使用的技术包括：扩散策略（UNet、Transformer ACT、Image‑based MLP）、统一 MDP 与 DPO、Bradley–Terry 偏好模型、假设切割投票与保守剪枝、Sigmoid 平滑的鲁棒损失、超参数 α、β、γ 的调节。

**📊 数据集**

实验数据集来自 D3IL 基准的五个长时程操纵任务：Avoid、Pushing、Sorting、Aligning、Stacking，使用预训练的多模态策略作为起点，并在每个任务中构造获胜与失败轨迹对来生成偏好标签。

**📈 对比分析**

与基线 DP‑DPO、CPO、IPO、SimPO 等方法比较，RoDiF 在 0%–30% 误标率下保持 84–88% 的成功率和 84–86% 的模式对齐率，显著优于其他方法（尤其在 20%–30% 误标率时），且在不同扩散架构下表现一致。

**⚠️ 局限性**

局限性包括：① 需要先验对误标比例的估计（γ）且对超参数敏感；② 目前仅验证在扩散策略和 D3IL 任务上，尚未证明能直接迁移到更复杂或非扩散的控制框架；③ 对极高噪声（>40%）时鲁棒性下降；④ 训练过程中仍需一定量的偏好对，可能对极端数据稀缺场景不够友好。

---

## 47. Minimizing Mismatch Risk: A Prototype-Based Routing Framework for Zero-shot LLM-generated Text Detection

**arXiv ID:** 2602.01240 | [PDF](https://arxiv.org/pdf/2602.01240v1)

**作者:** Ke Sun `[一作]` (Westlake University), Yue Zhang `[通讯]` (Westlake University)

**通讯引用:** 11942 | [OpenAlex ID](https://openalex.org/A5100333689)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了 DetectRouter 框架，通过在多模型池中动态路由文本至最匹配的零样本检测器，以提升 LLM 生成文本检测的鲁棒性。

**💡 创新点**

创新点在于将检测器选择视为“路由”问题，利用原型学习构造判别式度量空间，并通过分布对齐两阶段训练实现对未知黑盒源的自适应匹配。

**🔧 技术方法**

技术主要包括：原型（prototype）学习、距离基分类、两阶段训练（白盒原型构建 + 黑盒分布对齐）、KL 散度匹配、以及 LLM2Vec 编码器。

**📊 数据集**

使用了 MIRAGE（多任务生成/重写/润色数据集）进行训练，并在 EvoBench 与 MAGE 两大真实世界基准上进行评估。

**📈 对比分析**

与固定代理检测器（如 Fast‑DetectGPT、Lastde、FourierGPT 等）以及最近的零样本方法相比，DetectRouter 在 EvoBench 达到 90.85% AUROC、MAGE 77.92% AUROC，提升幅度从 5% 到 140% 之间，整体实现了最先进性能。

**⚠️ 局限性**

局限性包括：需要维护多模型代理和检测分数，训练成本和推理延迟较高；对抗生成技术仍可能突破检测；在极端样本或人类写作偏差上误报率可能上升。

---

## 48. R-HTN: Rebellious Online HTN Planning for Safety and Game AI

**arXiv ID:** 2602.00951 | [PDF](https://arxiv.org/pdf/2602.00951v1)

**作者:** Hector Munoz-Avila `[一作]` (Lehigh University), Paola Rizzo `[通讯]` (Interagens s.r.l.)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `9cc9baba-5356-466d-81ff-d80028d90279` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

本文提出了R-HTN算法，基于在线层次任务网络（HTN）规划的叛逆智能体，能够在发现违反用户或安全指令时停止执行或修正计划以避免违例。

**💡 创新点**

创新点在于将“指令违例”概念（即时、投影、适应性违例）与HTN在线规划结合，定义了非自适应与自适应叛逆代理两种行为模式，并给出完整的任务修复机制。

**🔧 技术方法**

技术主要包括：SHOP风格的HTN规划框架、在线规划与执行交错、指令检测（布尔函数 δ(s)）、投影违例检查、任务修复策略（基于距离的替代动作选择）以及距离度量。

**📊 数据集**

实验使用了两个自定义模拟域：O-RESCHU（UAV 避免 20x20 网格中的 2x2 红区）和 MONSTER（单个 NPC 在同一网格收集金币并避免怪物），红区/怪物以不同概率随机重生。

**📈 对比分析**

与合规代理（Compliant）和非自适应代理（Nonadaptive）进行对比。O-RESCHU 中自适应代理平均完成目标数最高、违例为 0、惩罚点约为合规代理的一半；Nonadaptive 的目标完成数略低。MONSTER 中自适应代理收集金币最多、死亡率为 0，非自适应次之，合规代理死亡率最高。

**⚠️ 局限性**

限制包括：指令仅为布尔函数，未考虑指令冲突或优先级；仅做 1 步投影，未处理多步look‑ahead；未考虑概率、非确定性或多代理协作；以及未对更复杂的约束或动态环境进行深入评估。

---

## 49. Causally Disentangled Contrastive Learning for Multilingual Speaker Embeddings

**arXiv ID:** 2602.01363 | [PDF](https://arxiv.org/pdf/2602.01363v1)

**作者:** Mariëtte Olijslager `[一作]` (Informatics Institute University of Amsterdam), Ali Mohammed Mansoor Alsahag `[通讯]` (Informatics Institute University of Amsterdam)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `57a58b01-81b4-4d75-a45c-2e891f272b50` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `9ce7179e-700c-4310-ac2b-91df50ded46e` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

研究自监督对比学习（SimCLR）生成的说话人嵌入中性别、年龄、口音等敏感属性的泄露程度，并尝试用对抗去偏和因果瓶颈两种方法降低泄露，同时评估对说话人验证性能的影响。

**💡 创新点**

首次系统比较线性与非线性探测器在自监督嵌入中的泄露表现，并将因果瓶颈作为结构化去偏手段加入对比学习框架，展示其在降低泄露方面优于传统对抗去偏，但对性能损失更大。

**🔧 技术方法**

使用SimCLR对比学习、梯度反转对抗去偏、因果瓶颈分支、线性和多层感知机探测器、ROC‑AUC与EER评估说话人验证性能。

**📊 数据集**

主要数据集为Mozilla Common Voice 23.0 English（约11k说话人），外部验证集为Sonos Voice Control Bias Assessment Dataset（1,024说话人）。

**📈 对比分析**

实验表明：基线嵌入对性别具有90%+线性可辨性，年龄和口音非线性可辨；对抗去偏可在一定程度降低性别泄露，但会显著下降验证AUC（0.83→0.62）；因果瓶颈能进一步降低泄露至约50%以下，但验证AUC降至≈0.5，显示显著的公平‑效能权衡。

**⚠️ 局限性**

主要局限包括：使用粗粒度的年龄/口音标签、仅用探测器作为泄露评估、冻结编码器导致去偏难以彻底消除非线性泄露、且在大规模或跨域环境下效果仍需验证。

---

## 50. TF-Lane: Traffic Flow Module for Robust Lane Perception

**arXiv ID:** 2602.01277 | [PDF](https://arxiv.org/pdf/2602.01277v1)

**作者:** Yihan Xie `[一作]` (BYD Company Limited), Zhen Yang `[通讯]` (BYD Company Limited)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `e0540dec-d77f-42db-94ae-d039248f6393` `aaccfe5c-6b26-4208-b23c-35331481e142` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出并实现了 Traffic Flow‑aware Module（TFM），将实时交通流信息与视觉特征融合，以提升车道检测系统在遮挡、缺失车道等复杂场景下的鲁棒性。

**💡 创新点**

创新点在于首次将交通流这一零成本、实时可获取的辅助先验引入车道感知，通过时空双编码器、轨迹解析、区域采样和跨模态融合，实现了高效且兼容多种主流车道检测框架的增强方法。

**🔧 技术方法**

采用了时空双编码器架构、轨迹解析器、遮挡/失效帧掩码、跨模态注意力融合以及残差特征组合等技术，结合目标检测与追踪模块产生的交通流轨迹，形成了完整的多模态特征融合流程。

**📊 数据集**

在公开数据集 NuScenes 与 OpenLaneV2 上进行实验，并在这两套数据集上对四个主流车道检测模型（TopoNet、LaneSegNet、MapTR、MapTRv2）进行集成测试。

**📈 对比分析**

通过将 TFM 集成到基线模型后，实验显示在所有模型和指标上均实现了显著提升，最高可获得 NuScenes 数据集 mAP 提升 4.1%；ablation 研究进一步证实了时空编码器、掩码策略和跨模态融合层的有效性。

**⚠️ 局限性**

局限性包括：对目标检测/跟踪模块的依赖（轨迹误差会影响性能）、在无交通流信息的推理场景下提升有限、以及额外的时空编码计算开销在极限实时性要求下需进一步优化。

---

## 51. An Odd Estimator for Shapley Values

**arXiv ID:** 2602.01399 | [PDF](https://arxiv.org/pdf/2602.01399v1)

**作者:** Fabian Fumagalli `[一作]` (LMU Munich), R. Teal Witter `[通讯]` (Claremont McKenna College)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种新的 Shapley 值估计方法 OddSHAP，利用值函数的奇偶分解，仅拟合奇函数部分并通过组合 Fourier 基和代理模型实现高效估计。

**💡 创新点**

证明 Shapley 值仅依赖值函数的奇分量，并给出配对采样的严格理论解释；利用此理论设计只在奇子空间中进行多项式回归，从而大幅降低计算复杂度。

**🔧 技术方法**

奇偶分解、Fourier 变换、配对采样、梯度提升树（GBT）做代理、稀疏交互筛选（ProxySPEX）、加权最小二乘回归。

**📊 数据集**

在八个基准上验证，包含 4‑维图像（ViT‑16）、14‑维文本（DistilBERT）、30‑维癌症数据、60‑维 CG60/IL60 生成数据、79‑维 NHANES、101‑维 Crime 等。

**📈 对比分析**

与 Permutation Sampling、SVARM、MSR、KernelSHAP、LeverageSHAP、PolySHAP、RegressionMSR、Proxy 等方法比较；OddSHAP 在大多数预算下均取得最小 MSE，尤其在中高维场景下显著优于现有最优方法。

**⚠️ 局限性**

在样本预算极低时表现与代理方法相当；对偶数分量的潜在信息未被利用，可能在某些任务中进一步提升精度；配对采样会提高样本互相一致性，可能影响收敛性。

---

## 52. Gradient-Aligned Calibration for Post-Training Quantization of Diffusion Models

**arXiv ID:** 2602.01289 | [PDF](https://arxiv.org/pdf/2602.01289v1)

**作者:** Dung Anh Hoang `[一作]` (Monash University), Toan Do `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

针对扩散模型在后训练量化（PTQ）过程中出现的梯度冲突问题，提出了一个动态学习校准样本重要性权重的元学习框架，以实现跨时间步梯度对齐，提升量化效果。

**💡 创新点**

创新点在于：①首次将梯度冲突视为量化瓶颈；②通过样本级权重学习实现梯度一致性；③采用双层优化的元学习方法，兼顾验证集表现和梯度对齐。

**🔧 技术方法**

使用了元学习（bi‑level）权重优化、AdaRound 量化、块级重构、EMA 激活量化以及梯度匹配损失等技术。

**📊 数据集**

在 CIFAR‑10、LSUN‑Bedrooms 以及 ImageNet 三个公开数据集上进行实验。

**📈 对比分析**

与 TFMQ‑DM、Q‑Diffusion、PTQ4DM、PTQD 等最先进 PTQ 方法对比，实验显示在所有量化位宽下 FID 与 sFID 均有显著下降，尤其在低位宽（W4A32、W4A8）场景表现最为突出。

**⚠️ 局限性**

局限性包括：①训练阶段需要额外的元学习计算和较高的 GPU 训练时长；②仍依赖高质量的校准数据，且在极端低位宽或极少时间步的场景下提升有限。

---

## 53. Dispelling the Curse of Singularities in Neural Network Optimizations

**arXiv ID:** 2602.01308 | [PDF](https://arxiv.org/pdf/2602.01308v1)

**作者:** Hengjie Cao `[一作]` (Fudan University), Li Shang `[通讯]` (Fudan University)

**通讯引用:** 6388 | [OpenAlex ID](https://openalex.org/A5004722925)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文从参数空间中奇异性增长的角度分析深度神经网络的优化不稳定性，揭示参数和表示矩阵的秩共坍塌（奇异性诅咒），并提出基于梯度峰值检测的轻量级奇异谱平滑方法 Parametric Singularity Smoothing (PSS)，实现训练稳定性恢复和提升。

**💡 创新点**

创新点包括：①首次系统地将参数矩阵与表示矩阵的奇异性相互放大机制归纳为“奇异性诅咒”并给出理论证明；②提出利用梯度范数峰值实时检测并平滑权重奇异谱的 PSS 方法，既可防止失稳，又可在失稳后恢复训练；③证明 PSS 在更大学习率范围内保持稳定，并显著降低损失爆炸概率，提升收敛效率和泛化性能。

**🔧 技术方法**

主要技术手段：稳态秩（Stable Rank）与奇异值分解、软最大（softmax）近似与 Taylor 展开、单层 Transformer 简化模型下的梯度分析、梯度范数上下界证明、指数移动平均检测、主成分/奇异值平滑（Dominant Direction Decomposition）与多种平滑策略（对数、Softplus、Softmax、裁剪）。

**📊 数据集**

数据集包括：BERT 预训练使用 WikiText，GPT‑2 预训练使用 Amazon‑review/OpenWebText，Llama‑3 预训练使用 English Wikipedia；下游任务评估在 CoLA、SST‑2、MRPC、MNLI、QNLI、RTE 等 NLP 数据集。

**📈 对比分析**

与梯度裁剪（GC）、正交正则化（OR）、Query‑Key 归一化（QK‑Norm）等现有稳定方法对比，PSS 在更高学习率下保持训练稳定，损失爆炸次数大幅下降，最终测试损失与下游任务准确率均保持相当或更优；计算开销仅略高（≈1.2–2.5×），但仅在 0.1%–0.25% 步骤中触发，整体训练时间提升不到 0.3%。

**⚠️ 局限性**

局限性：①依赖梯度范数检测，阈值设置可能出现误报或漏报；②理论分析基于单层 Transformer 的简化模型，对多层/更大模型的推广尚待进一步验证；③对极端超参数（如非常大学习率或极短批量）仍可能出现失稳；④方法参数（平滑策略、阈值）需经验调优，可能影响不同任务的效果。

---

## 54. From Videos to Conversations: Egocentric Instructions for Task Assistance

**arXiv ID:** 2602.01038 | [PDF](https://arxiv.org/pdf/2602.01038v1)

**作者:** Lavisha Aggarwal `[一作]` (Google), Andrea Colaco `[通讯]` (Google)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

自动将单人指令视频转化为双人多轮对话，构建了HowToDIV多模态任务协助数据集。

**💡 创新点**

提出完全基于Prompt的大语言模型管道，实现指令抽取、对话生成和视频对齐，首次在单人视频中生成结构化、错误反馈丰富的专家‑新手对话。

**🔧 技术方法**

使用Gemma‑3、Qwen‑2.5等大语言模型结合Prompt工程、自动语音识别、字幕时间戳对齐和SigLIP视觉编码进行多模态文本生成与定位。

**📊 数据集**

以NIV和EgoPER这两个公开的单人指令视频数据集为原始素材，扩展生成507个会话、6636轮对话、24小时视频的HowToDIV。

**📈 对比分析**

通过BLEU、ROUGE、LLM‑as‑a‑Judge三种指标对比History‑only与History+Steps两种prompt设置，并用Gemma‑3‑4B与Qwen‑2.5‑VL‑7B两模型进行基准；History+Steps明显提升分数，Gemma‑3‑4B在BLEU/ROUGE上表现最佳，但整体得分仍仅在3–4分左右。

**⚠️ 局限性**

依赖字幕时间戳的粗粒度定位导致动作对齐不够精确；LLM生成可能出现幻觉或缺乏专业细节；对话多样性受限；数据集仅覆盖三类任务，未涉及更复杂场景和更高分辨率视频。

---

## 55. Energy-efficient Software-defined 5G/6G Multimedia IoV: PID controller-based approach

**arXiv ID:** 2602.01180 | [PDF](https://arxiv.org/pdf/2602.01180v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2`

---

## 56. ILSIC: Corpora for Identifying Indian Legal Statutes from Queries by Laypeople

**arXiv ID:** 2602.00881 | [PDF](https://arxiv.org/pdf/2602.00881v1)

**作者:** Shounak Paul `[一作]` (Indian Institute of Technology Kharagpur), Saptarshi Ghosh `[通讯]` (Indian Institute of Technology Kharagpur)

**通讯引用:** 4524 | [OpenAlex ID](https://openalex.org/A5073748464)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

暂无可用信息

**💡 创新点**

暂无可用信息

**🔧 技术方法**

暂无可用信息

**📊 数据集**

暂无可用信息

**📈 对比分析**

暂无可用信息

**⚠️ 局限性**

暂无可用信息

---

## 57. DTAMS: High-Capacity Generative Steganography via Dynamic Multi-Timestep Selection and Adaptive Deviation Mapping in Latent Diffusion

**arXiv ID:** 2602.01160 | [PDF](https://arxiv.org/pdf/2602.01160v1)

**作者:** Yuhao Xue `[一作]` (East China Normal University), Zhaoxia Yin `[通讯]` (East China Normal University)

**通讯引用:** 3218 | [OpenAlex ID](https://openalex.org/A5035489942)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于扩散模型的生成隐写方法DTAMS，能够在保持图像质量的同时实现高容量（最高12 bpp）信息隐藏并支持内容可控生成。

**💡 创新点**

创新点包括：① 动态多时刻自适应嵌入机制，预先计算每个扩散时刻的嵌入代价并选择最优时刻；② 全局子区间偏差映射策略，将像素区间映射到目标区间以降低误差积累；③ 多维偏差补偿机制，联合像素、潜空间和语义层级约束，抑制多次潜像素变换导致的失真。

**🔧 技术方法**

核心技术包括扩散概率模型（Latent Diffusion Model）、区间映射与全图优化（PGD）、多级约束损失（像素/潜/语义）以及自适应时刻选择算法。

**📊 数据集**

实验使用公开的FFHQ、Bedroom、Cat数据集，并在PNG和JPEG格式下验证可用性。

**📈 对比分析**

与IDEAS、S2IRT、StegaDDPM、LDStega四个SOTA方法对比。DTAMS在高容量12 bpp时实现99.2%+提取准确率，PSNR约33 dB、SSIM 0.9865，平均提取误差率比对手低59.39%，在常见噪声与JPEG压缩攻击下表现出色，并保持约0.5的反隐写检测率。

**⚠️ 局限性**

局限性：仍需在极高容量或极端图像变形（如大幅度裁剪、强烈颜色抖动）下验证鲁棒性；多维约束对计算开销有一定影响，部署时需权衡速度与安全；对不同类型的扩散模型适用性尚未完全探究。

---

## 58. Mechanistic Interpretability of Brain-to-Speech Models Across Speech Modes

**arXiv ID:** 2602.01247 | [PDF](https://arxiv.org/pdf/2602.01247v1)

**作者:** Maryam Maghsoudi `[一作]` (University of Maryland), Ayushi Mishra `[通讯]` (University of Maryland)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文通过对脑-语音解码模型进行因果性内部干预，系统研究了不同说话模式（发声、模拟、想象）下内部表示的作用与转移机制，揭示了跨模式的连续因果流形及压缩的子空间结构；

**💡 创新点**

创新点在于首次将机制可解释性技术（跨模式激活补丁、三模态插值、因果定位、因果刮除、神经元级补丁）应用于脑-语音解码，证明跨模式转移主要由层级化且方向依赖的紧凑子空间驱动；

**🔧 技术方法**

使用的技术包括：跨模式激活补丁（patching）、三模态激活插值（interpolation）、粗细粒度因果定位（coarse‑to‑fine causal tracing）、因果刮除（scrubbing）以及神经元级单元补丁与top‑k饱和分析；

**📊 数据集**

数据集为VocalMind——一份大规模立体脑电（sEEG）数据集，包含同一受试者在发声、模拟和想象语音三种模式下的记录；

**📈 对比分析**

与基线模型对比时，利用PCC（相关系数）和MCD（梅尔倒谱失真）衡量解码质量；跨模式补丁显示将发声模式内部表示注入想象输入可显著提升PCC并降低MCD，而相反方向会导致性能骤降；插值实验表明三种模式在连续因果流形上呈现渐进变化；

**⚠️ 局限性**

局限性包括：仅在单一受试者与单一模型（GRU‑based）上验证，缺乏跨受试者与跨架构的普适性验证；数据量有限，无法充分探究训练过程中的子空间演化；未来需在多受试者、多模型与更大数据规模上进一步验证。

---

## 59. Analyzing and Improving Diffusion Models for Time-Series Data Imputation: A Proximal Recursion Perspective

**arXiv ID:** 2602.01182 | [PDF](https://arxiv.org/pdf/2602.01182v1)

**作者:** Zhichao Chen `[一作]` (Peking University), Zhouchen Lin `[通讯]` (Peking University)

**通讯引用:** 25979 | [OpenAlex ID](https://openalex.org/A5016399094)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ba576bd1-e51d-44e8-8077-fc943b333c93` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文通过将扩散模型（DM）用于时间序列缺失值填补（TSDI）时的推理过程重新表述为近似递归优化，分析发现传统DM在面对非平稳时序数据和追求多样性输出时会导致精度下降；随后提出半近似传输（SPT）度量，利用熵诱导的Bregman散度放宽Wasserstein距离的严格质量守恒约束，并去除了扩散过程中的耗散项，得到全新的SPIRIT框架；

**💡 创新点**

创新点主要包括（1）引入熵诱导Bregman散度的半近似传输（SPT）度量，使得DM在非平稳场景下更具鲁棒性；（2）彻底去除耗散结构，消除多样性诱导的误差；（3）在近似递归框架下重新构建DM的填补流程，形成可理论分析且实验有效的SPIRIT方法；

**🔧 技术方法**

技术手段：近似递归（proximal recursion）与Wasserstein空间优化、扩散模型的逆向SDE推理、熵诱导的Bregman散度、去噪分数匹配（denoising score matching）进行分数网络学习、梯度范数正则化等；

**📊 数据集**

实验数据集：ETT四个子集（h1、h2、m1、m2）、Exchange、Illness、Traffic；

**📈 对比分析**

与多种基线（Crossformer、TimesNet、PatchTST、Autoformer、ETSformer、FiLM、DLinear、GP‑VAE、CSDI、Glocal、Sinkhorn、TDM、PSW‑I）对比，SPIRIT在14种评估条件（6个缺失率×2指标）中获得10/14的最优或次优结果，MAE/MSE均显著低于对照组；

**⚠️ 局限性**

局限性：需要针对步长η、隐藏维度等超参进行调优；目前仅在MCAR缺失场景验证，对MAR/NIAR等更复杂缺失机制的鲁棒性尚未探究；模型规模相对较大，计算成本和内存占用较高。

---

## 60. LLM-Based Behavior Tree Generation for Construction Machinery

**arXiv ID:** 2602.01041 | [PDF](https://arxiv.org/pdf/2602.01041v1)

**作者:** Akinosuke Tsutsumi `[一作]` (Kyushu University), Ryo Kurazume `[通讯]` (Kyushu University)

**通讯引用:** 3670 | [OpenAlex ID](https://openalex.org/A5073445963)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

利用大型语言模型（LLM）生成构造工地机器的行为树（BT），实现多台异构机械的协同操作，并通过同步标志保证安全与同步。

**💡 创新点**

①在高层任务规划阶段由LLM自动产生同步标志；②使用结构化模板生成可执行的BT；③将任务规划与BT生成分离并结合数据库已知参数，提升可扩展性和安全性。

**🔧 技术方法**

使用LLM（GPT‑5、OpenAI‑o3、Claude 等）进行高层规划与BT生成；ROS2‑TMS for Construction 平台；BehaviorTree.CPP 与自定义节点；模拟器 OperaSim‑PhysX 及真实现场测试。

**📊 数据集**

实验使用的场景数据包括四个模拟指令场景（如“让挖土机回初始姿态”“搬运土壤至堆填点”等）以及真实工地的挖土机（ZX200）和装载车（MST110CR）的操作记录。

**📈 对比分析**

对比多种 LLM 模型在四个场景下的生成成功率。GPT‑5（高层规划）+ GPT‑4.1（BT 生成）在所有场景均成功；OpenAI‑o3+GPT‑4.1 同样成功；Claude Opus/Claude Sonnet 在复杂同步场景失败；Gemma3/Llama3.1 在高复杂度任务表现不佳。

**⚠️ 局限性**

①模型依赖于已知数据库参数，对未知环境或新机器参数缺乏自适应能力；②对更大规模、更多异构机器的协同扩展尚未验证；③LLM 生成的 BT 仍需人工验证与微调，无法完全替代人工设计。

---

## 61. Navigating Simply, Aligning Deeply: Winning Solutions for Mouse vs. AI 2025

**arXiv ID:** 2602.00982 | [PDF](https://arxiv.org/pdf/2602.00982v1)

**作者:** Phu-Hoa Pham `[一作]` (University of Science), Huynh Trung Kiet `[通讯]` (University of Science)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

为 NeurIPS 2025 Mouse vs AI 竞赛的视觉鲁棒性（Track 1）和神经对齐（Track 2）两条赛道，提出了获奖方案：Track 1 用轻量级两层 CNN + GLU + 观察归一化实现 95.4% 的最终分；Track 2 用 16 层 ResNet‑style 结构+GLU 的 17.8 M 参数模型实现神经预测 Top‑1 R² 0.1517。

**💡 创新点**

创新点在于：① 简单结构配合 GLU 与归一化可在视觉鲁棒性上击败深层网络；② 仅 200 k 步的训练即可达到神经对齐最佳性能，揭示训练时间与性能的非单调关系；③ 对两条赛道需求做出差异化设计，阐明行为优越与生物学可解释性并不完全一致。

**🔧 技术方法**

技术方法包括：Proximal Policy Optimization（PPO）强化学习；Track 1 采用两层 Conv2D、GLU 门控与观察归一化的 SimpleCNN；Track 2 采用 16 层残差网络+GLU 门控的深层模型；使用 GLU、残差块、观察归一化等组件。

**📊 数据集**

数据集来源于 NeurIPS 2025 Mouse vs AI 提供的 Unity 3D 视觉导航环境（86×155 灰度图像、连续动作空间），以及 19,000+ 小鼠视觉皮层的两光子钙成像记录。

**📈 对比分析**

与多种基线（IMPALA ResNet 4/24 层、InceptionNet、数据增强、深层残差网络、LSTM 等）对比，Track 1 的 SimpleCNN + GLU + 归一化 在 ASR/M SR 上分别达 96.8%/94.0%，最终分 95.4%，显著优于基线；Track 2 的深层模型在神经 R² 上排名第一（0.1517），远超 1.4 M 参数的浅层模型；训练步数非单调，最佳对齐出现在约 200 k 步。

**⚠️ 局限性**

局限性包括：仅在该简易视觉导航任务验证，难以推广到更复杂场景；神经对齐评估仅使用线性回归和 RSM，缺乏动态/因果信息；未探索 Transformer 等新架构或多模态输入；训练仅采用标准 PPO，未尝试好奇心、元学习等可能提升方法。

---

## 62. Beyond Output Critique: Self-Correction via Task Distillation

**arXiv ID:** 2602.00871 | [PDF](https://arxiv.org/pdf/2602.00871v1)

**作者:** Hossein A. Rahmani `[一作]` (AI Center), Sujay Kumar Jauhar `[通讯]` (Microsoft)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `8d10c613-917e-4880-9716-17789f50e119` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种自我纠错框架（TaskDistill），在生成答案前先进行任务抽象，生成结构化模板并以此指导后续答案生成；同时为小模型提供大模型抽象模板以实现迁移式自我纠错。

**💡 创新点**

核心创新是把任务抽象作为中间步骤，将问题拆解为变量、约束与结构化模板，既提升大模型的纠错深度，又让小模型通过外部模板获得有效指导，实现跨规模的自我纠错迁移。

**🔧 技术方法**

技术手段包括：多步骤提示（prompting）实现任务抽象与答案实例化；结构化模板生成；模板迁移（Task Distillation for Smaller Models）；迭代自我纠错循环；以及对比实验与消融分析。

**📊 数据集**

评估使用多种需要数学/算法推理的基准数据集，如 GSM8K、AQuA、SVAMP、MathQA、Algebra 等，涵盖大模型与小模型的多种规模。

**📈 对比分析**

与传统自我纠错方法（Self‑Refine、Self‑TICK、ProgCo）以及采样、少量调优等基线进行对比。实验显示，TaskDistill 在大模型上单轮提升 30–50% 的准确率，在小模型上可实现 2–3 倍的提升；迭代后效果更显著，且相较于多样本投票方法在小模型上表现更稳定。

**⚠️ 局限性**

局限性包括：需要较长的提示步骤和模板生成成本；在极度复杂或结构不明确的任务中抽象模板可能不足；对模板质量高度依赖，若大模型抽象错误会误导小模型；目前仍未对非推理任务或开放式问答进行充分验证。

---

## 63. LeagueBot: A Voice LLM Companion of Cognitive and Emotional Support for Novice Players in Competitive Games

**arXiv ID:** 2602.01213 | [PDF](https://arxiv.org/pdf/2602.01213v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

---

## 64. Interacted Planes Reveal 3D Line Mapping

**arXiv ID:** 2602.01296 | [PDF](https://arxiv.org/pdf/2602.01296v1)

**作者:** Zeran Ke `[一作]` (Wuhan University), Nan Xue `[通讯]` (Ant Group)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6514db3d-8de6-452c-91b7-acdb31787cc4` `5b4c1114-4a70-478e-9921-2514ee03850d` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种同时优化三维平面与三维线段的框架 LiP-Map，用二维线段检测与 2.5D 深度/法线信息在多视角图像中生成准确、完整的三维线映射。

**💡 创新点**

创新点在于：① 通过显式的平面–线边交互而非传统的双线共面约束来构建线段；② 将可学习的三维矩形平面作为几何原语，使线段天然成为平面边缘；③ 采用联合损失（平面渲染、2D 对齐、组内一致）实现线段与平面同步优化。

**🔧 技术方法**

技术手段包括：可学习的三维矩形平面参数化（中心、旋转、半径）、基于 2.5D 深度/法线的可微光栅化平面渲染、2D 线段检测与 1 像素区域投射的线–平面边缘匹配、三维/二维约束损失以及动态平面拆分与裁剪。

**📊 数据集**

主要使用的公开数据集为 ScanNetV2、ScanNet++、Hypersim、7Scenes、Tanks & Temples；在这些数据上与 LIMAP、CLMAP 等基线进行评估，并在 DTU、BlenderMVS、MipNerf360 等非平面场景中进行泛化测试。

**📈 对比分析**

在 ScanNetV2/ScanNet++/Hypersim 上与 LIMAP/CLMAP 对比，LiP-Map 在准确率、完整度、精确率/召回率/F1 等多项指标均显著优于或持平于对手，并在 7Scenes 上的视觉定位实验中显著降低位姿误差、提升定位鲁棒性。

**⚠️ 局限性**

局限性包括：① 需要可用的深度/法线预测或地面真实值；② 对平面分布较好的人工场景效果最佳，曲面或非平面结构仍可能产生误检；③ 依赖 2D 线段检测器的质量，极端模糊或纹理稀疏场景下表现受限。

---

## 65. VAMOS-OCTA: Vessel-Aware Multi-Axis Orthogonal Supervision for Inpainting Motion-Corrupted OCT Angiography Volumes

**arXiv ID:** 2602.00995 | [PDF](https://arxiv.org/pdf/2602.00995v1)

**作者:** Nick DiSanto `[一作]` (Vanderbilt University), Ipek Oguz `[通讯]` (Vanderbilt University)

**通讯引用:** 8902 | [OpenAlex ID](https://openalex.org/A5038198156)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

针对手持光学相干断层扫描血管造影（OCTA）因运动导致的B扫描缺失，本文提出了基于深度学习的VAMOS-OCTA框架，用于运动损伤B扫描的修复。

**💡 创新点**

创新点在于提出VAMOS损失函数，将血管加权像素重建与轴向和侧向投影一致性监督结合，实现多轴正交约束，既提升单帧B扫描细节，又保证体素级投影一致性。

**🔧 技术方法**

使用2.5D U‑Net架构进行B扫描重建，并配合VAMOS损失（wMSE+轴向、侧向MIP/AIP约束）和多尺度投影监督。

**📊 数据集**

使用7个高分辨率眼底OCTA体积（每体积1000 B扫描）以及合成运动失真数据（随机连续缺失块）进行训练与评估，真实手持采集数据用于测试。

**📈 对比分析**

与标准MSE、SOAD加权MSE以及仅轴向投影监督的对比实验表明，VAMOS-OCTA在梯度、LPIPS、Sobel边缘保持、PSNR等多项指标上均显著优于基线，MIP重建误差也显著下降。

**⚠️ 局限性**

局限性包括：依赖合成运动模型训练，对极大连续缺失区块的恢复仍受限；未验证跨设备和不同扫描协议的迁移性能；缺少临床意义的定量评估。

---

## 66. Sleep Reveals the Nonce: Breaking ECDSA using Sleep-Based Power Side-Channel Vulnerability

**arXiv ID:** 2602.01491 | [PDF](https://arxiv.org/pdf/2602.01491v1)

**作者:** Sahan Sanjaya `[一作]` (University of Florida), Prabhat Mishra `[通讯]` (University of Florida)

**通讯引用:** 6185 | [OpenAlex ID](https://openalex.org/A5006818844)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

**🎯 论文内容**

通过观察睡眠诱导的功率尖峰，利用单点幅度分析提取ECDSA签名中的nonce。

**💡 创新点**

首次证明SleepWalk侧信道漏洞在多种加密库（RustCrypto、BearSSL、GoCrypto）和两大处理器架构（ARM、RISC‑V）上均能泄露nonce，且不依赖传统多点DPA/SPA，创新点在于跨平台、跨库的单点功率侧信道攻击。

**🔧 技术方法**

采用功率侧信道监测、上下文切换功率尖峰提取、固定窗口双倍加法实现的逆向工程、统计单点幅度分析和离散余数/隐藏数问题（HNP）求解。

**📊 数据集**

实验基于Raspberry Pi 4B（ARM Cortex‑A72）和VisionFive 2（RISC‑V U74）两块板，使用RustCrypto、BearSSL、GoCrypto的P‑256实现生成的签名数据集。

**📈 对比分析**

相较于传统需要数千到数百万trace的DPA/SPA，本文仅需≤1000个trace、单点测量即可恢复20位nonce，随后即可利用HNP恢复完整私钥；实验结果显示在ARM和RISC‑V上均能达到此效果，性能高效且实现简洁。

**⚠️ 局限性**

局限性在于只能泄露前20位nonce，剩余位信息不足；对功率噪声敏感，低位泄露不明显；未验证对其它曲线或更大位数nonce的泄漏能力。

---

## 67. EffGen: Enabling Small Language Models as Capable Autonomous Agents

**arXiv ID:** 2602.00887 | [PDF](https://arxiv.org/pdf/2602.00887v1)

**作者:** Gaurav Srivastava `[一作]` (Virginia Tech), Xuan Wang `[通讯]` (Virginia Tech)

**通讯引用:** 8277 | [OpenAlex ID](https://openalex.org/A5078292155)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并实现了针对小语言模型的代理框架effGen，提供提示优化、复杂度路由、任务分解、统一记忆以及跨协议通信等功能；

**💡 创新点**

将小模型的上下文限制、推理深度等约束作为首要设计目标，提出多因子预执行复杂度分析、压缩式提示优化、三层记忆系统及统一协议实现，实现小模型代理性能显著提升；

**🔧 技术方法**

采用提示压缩与语义重写、基于规则的提示优化、五因子复杂度评估、图论式任务分解、MCP/A2A/ACP协议实现、向量检索记忆（FAISS/Chroma）、局部并行执行与批处理等技术；

**📊 数据集**

在13个基准上评估，包括GSM8K、GSM‑PLUS、MATH‑500、BeyondBench系列、ARC‑Challenge、ARC‑Easy、CommonsenseQA、LoCoMo、LongMemEval、GAIA、SimpleQA、CSQA、ARC‑C等；

**📈 对比分析**

与原始模型、LangChain、AutoGen、Smolagents四个基线进行对比，使用相同工具集与设置，Qwen2.5模型在13个基准上平均提升13.1%（1.5B）至6%（32B），多工具基准提升9‑22%，速度提升18×，内存更小；

**⚠️ 局限性**

对大型模型的提升有限；提示优化和复杂度路由需要手工调参，缺乏学习式路由；在简单或不需要代理的任务收益不显著；多模态或更大规模模型的支持尚待完善。

---

## 68. Sample Efficient Active Algorithms for Offline Reinforcement Learning

**arXiv ID:** 2602.01260 | [PDF](https://arxiv.org/pdf/2602.01260v1)

**作者:** Soumyadeep Roy `[一作]` (Indian Institute of Science), Ambedkar Dukkipati `[通讯]` (Indian Institute of Science)

**通讯引用:** 936 | [OpenAlex ID](https://openalex.org/A5010292297)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种基于高斯过程的主动离线强化学习算法，并给出了其理论样本复杂度上界，证明仅需 O(1/ε²) 次主动采样即可达到 ε‑最优。

**💡 创新点**

创新点在于：①将高斯过程对价值函数的贝叶斯不确定性量化与主动采样策略结合；②利用信息增益与 Bellman 收缩的结合，首次给出主动离线 RL 的 PAC‑style 采样复杂度；③在理论上将主动探索的期望收敛速度提升到与全在线 GP bandit 相同，且相较纯离线方法的 (1‑γ)⁻⁴ 折算改进到 (1‑γ)⁻²。

**🔧 技术方法**

使用的技术包括：高斯过程回归（全或稀疏变分 GP）、信息增益下界、贝叶斯置信区间与 GP 收缩不等式、Bellman 操作的 Lipschitz 传递、以及基于 Fitted Value Iteration 的初始化和策略更新。

**📊 数据集**

实验数据集来自 D4RL benchmark，包括：halfcheetah、hopper、walker2d 的 random/medium 版本，Maze2D（umaze‑hard、medium‑easy、medium‑hard、medium‑dense‑hard、large‑easy、large‑hard），以及 AntMaze（umaze、umaze‑diverse、medium‑play、medium‑diverse）。

**📈 对比分析**

与基准方法（Behavior Cloning、纯离线 RL、随机探索）对比，GP 主动采样在所有环境上都能获得更高的 D4RL 归一化分数，同时显著减少所需的主动环境交互次数（约 30‑80% 的样本量提升）。

**⚠️ 局限性**

局限性包括：①高斯过程在大规模数据时的计算和存储开销，尤其是稀疏变分 GP 仍需数千至数万诱导点；②理论分析基于理想的 GP 后验，实际中需靠近似方法（如集合网络）实现；③假设了完整的贝叶斯更新与信息增益上界，实际环境噪声与模型假设的偏差可能导致性能下降。

---

## 69. Exposing and Defending the Achilles' Heel of Video Mixture-of-Experts

**arXiv ID:** 2602.01369 | [PDF](https://arxiv.org/pdf/2602.01369v1)

**作者:** Songping Wang `[一作]` (Nanjing University), Caifeng Shan `[通讯]` (Nanjing University)

**通讯引用:** 9025 | [OpenAlex ID](https://openalex.org/A5055478558)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6215c339-3735-4be3-8a07-5bbb7004712d` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `afceb026-1760-41ae-8d86-010831a37d97` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

针对视频Mixture-of-Experts模型，本文设计了基于时间Lipschitz导向的攻击（TLGA、J-TLGA），并提出了协同的鲁棒训练方法（J-TLAT）以提升对攻击的抵御。

**💡 创新点**

创新点在于：①从组件层面剖析并利用路由器与专家的独立及协同弱点；②提出时间自适应步长的Lipschitz攻击；③构建分层的联合鲁棒训练，显著降低Lipschitz常数并保持高效推理。

**🔧 技术方法**

使用Lipschitz正则、时间自适应梯度步长、路由器和专家的分离攻击以及对抗训练框架。

**📊 数据集**

主要在UCF‑101和HMDB‑51视频动作识别数据集，使用3D ResNet‑18、TSM、Slow‑Fast、R(2+1)D等骨干网络。

**📈 对比分析**

与PGD、FGSM、AutoAttack、TT等传统攻击和AT‑S/AT‑D/AT‑M/OUD‑M/AAT‑M等防御做对比，J‑TLAT在多种攻击下稳步提升鲁棒准确率（如J‑TLAT在ε=14/255下约提高30%），并在推理成本上比密集模型低60%。

**⚠️ 局限性**

局限性包括：实验主要基于白盒攻击，缺乏黑盒或迁移攻击的全面评估；只关注视频MoE，未探讨其它领域的MoE；对不同规模专家数量的泛化尚待验证。

---

## 70. Transforming Vehicle Diagnostics: A Multimodal Approach to Error Patterns Prediction

**arXiv ID:** 2602.01109 | [PDF](https://arxiv.org/pdf/2602.01109v1)

**作者:** Hugo Math `[一作]` (Augsburg University), Rainer Lienhart `[通讯]` (Augsburg University)

**通讯引用:** 9603 | [OpenAlex ID](https://openalex.org/A5009744749)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3855fcda-48ef-4070-a15e-803cd5c84d83` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出 BiCarFormer，一种多模态双向 Transformer，通过跨模态注意力将车辆诊断故障码（DTC）与环境条件融合，实现多标签错误模式预测。

**💡 创新点**

创新点在于：① 引入多模态共注意力机制在事件序列上进行双向交互；② 在 DTC 与环境数据之间采用稀疏对齐与嵌入融合；③ 通过交叉熵多任务预训练提升模型对环境信息的利用。

**🔧 技术方法**

使用双向 Transformer、RoPE 位置编码、共注意力（co‑attention）与 softmax 对齐函数、稀疏化对齐实验、以及基于 BERT 的 Masked Language Modeling 预训练。

**📊 数据集**

采用真实汽车数据集：约 5 百万条 DTC 序列，平均 150 条 DTC 与约 2275 条环境条件，涵盖 22,137 个 DTC 与 360 个错误模式标签。

**📈 对比分析**

与 BERT（无 NSP）和 DTC‑TranGRU 进行对比，BiCarFormer 在 AUROC、F1（Micro/Macro/Sample）等指标均显著提升，尤其是微平均 AUROC 0.809、F1 0.77，优于 BERT 的 0.768/0.71 与 DTC‑TranGRU 的 0.602/0.36。

**⚠️ 局限性**

主要限制包括：① 交叉注意力的 O(n²) 计算开销，导致训练与推理成本高；② 环境数据高度噪声与冗余，对对齐与稀疏化方法仍有改进空间；③ 仅在单一汽车制造商数据上验证，泛化性待进一步探索。

---

## 71. Verification Required: The Impact of Information Credibility on AI Persuasion

**arXiv ID:** 2602.00970 | [PDF](https://arxiv.org/pdf/2602.00970v1)

**作者:** Saaduddin Mahmud `[一作]` (Manning College of Information and Computer Sciences, University of Massachusetts Amherst), Shlomo Zilberstein `[通讯]` (Manning College of Information and Computer Sciences, University of Massachusetts Amherst)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `8d10c613-917e-4880-9716-17789f50e119` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了 MixTalk 这一面向 LLM 的战略沟通游戏，并在多场景（招聘、保险理赔、二手车）下进行大规模对弈与评估，同时设计了基于锦标赛或áculo 的政策蒸馏方法 TOPD 用于提升接收方的鲁棒性。

**💡 创新点**

创新点包括：① 将可验证与不可验证信息混合的可信度机制嵌入沟通模型，弥补传统 cheap‑talk 与完全披露两极化的不足；② 通过锦标赛式经验博弈得到对手最优策略的“oracle”，并将其知识以提示方式迁移到运行时；③ 在 LLM 代理上实现无监督的策略蒸馏，提升对话可信度判断与工具调用效率。

**🔧 技术方法**

主要技术手段为：利用公开的 LLM（GPT‑5‑mini、Grok‑4.1‑fast、Kimi‑K2‑thinking、Gemini‑3‑flash‑preview、GPT‑4.1‑mini）实现 ReAct‑style 推理与工具调用；采用锦标赛式经验博弈与 α‑Rank、Bradley‑Terry 等博弈论评价指标；设计 Tournament Oracle Regret (TOR) 与 TOPD 的离线提示蒸馏流程。

**📊 数据集**

使用的数据集为合成的 MixTalk 场景：在三种故事语境（招聘、保险理赔、二手车）下，随机采样私有属性向量并设定相关先验，形成 30 种不同规模（小/大）且包含 12/24 个属性的实验环境；无真实业务数据，全部为模拟环境。

**📈 对比分析**

通过对比平均效用、Bradley‑Terry 分数、α‑Rank 以及 TOR 指标进行性能评估。结果表明：① 发送方与接收方往往呈反向优势；② TOPD 在大规模环境中将 TOR 降低约 20‑25%，并使平均效用与 BT 分数提升 5‑15%；③ 传统 LLM 在对弈中仍存在显著的 oracle regret，显示提升空间。

**⚠️ 局限性**

局限性：① 只考虑双人博弈，未覆盖多代理协作/对抗；② 场景为人工合成，缺乏真实业务验证；③ 公开上下文与工具集设定假设过于理想，实际部署中可能面临更复杂的可信度与隐私约束；④ 对语言动作空间的全局最优策略仍难以求解，导致蒸馏策略仅在有限场景下有效。

---

## 72. Distill3R: A Pipeline for Democratizing 3D Foundation Models on Commodity Hardware

**arXiv ID:** 2602.00865 | [PDF](https://arxiv.org/pdf/2602.00865v1)

**作者:** Brandon Leblanc `[一作]` (Concordia University), Charalambos Poullis `[通讯]` (Concordia University)

**通讯引用:** 1224 | [OpenAlex ID](https://openalex.org/A5084730486)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `8d10c613-917e-4880-9716-17789f50e119` `fede83ac-7505-405f-ab37-e7284695c47f` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

开发了一套名为 Distill3R 的框架，能够将大型 3D 基础模型压缩为 72M 的学生模型，并在单机工作站上完成训练和推理。

**💡 创新点**

创新点包括：离线教师缓存管线将昂贵的教师推理与训练循环解耦；置信度感知的蒸馏损失利用教师的不确定性稳定训练；在保持几何一致性的同时实现 9 倍参数压缩、5 倍推理加速，真正实现 3D 视觉的普及化。

**🔧 技术方法**

使用技术包括知识蒸馏、离线缓存与压缩、置信度加权几何损失、DUNE ViT‑S 编码器、6 层全局融合 Transformer、DPT 头、混合精度、FlashAttention、余弦退火学习率调度等。

**📊 数据集**

训练集使用六大数据集：CO3D‑v2、ScanNet++、Habitat、MegaDepth、BlendedMVS、ARKitScenes；评估集为 7‑Scenes（室内）和 DTU（物体）等。

**📈 对比分析**

与教师 Fast3R（650M）和 VGGT（1B）对比：学生模型参数减少 9 倍，推理速度提升 5 倍、显存更低；在 7‑Scenes 上虽然绝对精度略低，但尺度一致性更好（scale = 1.62 vs 3.54），在 DTU 上完成率和误差均保持在可接受范围。

**⚠️ 局限性**

主要局限是学生缺乏完整的全局姿态（旋转）学习，导致全局对齐仍需后处理；几何精度仍低于教师，且在极端 OOD 场景下仍有误差。

---

## 73. BOA Constrictor: Squeezing Performance out of GPUs in the Cloud via Budget-Optimal Allocation

**arXiv ID:** 2602.01404 | [PDF](https://arxiv.org/pdf/2602.01404v1)

**作者:** Zhouzi Li `[一作]` (Carnegie Mellon University), Benjamin Berg `[通讯]` (UNC Chapel Hill)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出一种基于预算约束的GPU租用与分配调度框架——BOA（Budget‑Optimal Allocation），通过解析性凸优化实现对训练作业的动态资源分配与集群规模控制；

**💡 创新点**

将GPU租用与作业调度联合建模为一个预算约束下的最优调度问题，理论证明BOA策略在任意工作负载下最小化平均作业完成时间，并给出在存在重调度开销时的宽度计算器（BOA Width Calculator）；

**🔧 技术方法**

采用随机/泊松模型、速度提升函数、凸优化（以及混合整数凸规划）求解最优GPU分配；实现基于AdaptDL框架的实时调度与异步宽度计算；

**📊 数据集**

使用AWS上真实训练工作负载（newTrace、workload‑1）以及CIFAR‑10/ResNet18、BERT、DeepSpeech2等典型数据集；

**📈 对比分析**

与Pollux及其自适应扩容变体在真实实验和大规模仿真中对比，结果显示在相同预算下平均JCT下降约1.6–2.0倍，P95 JCT下降约1.7倍，预算需求下降约1.5–2.2倍；

**⚠️ 局限性**

主要局限：仅针对同质GPU设计；对重调度成本的建模相对理想；在多种GPU类型或更大规模的异构集群上缺乏完整评估；对预测误差的鲁棒性虽好，但仍需在更广泛场景下验证。

---

## 74. How RLHF Amplifies Sycophancy

**arXiv ID:** 2602.01002 | [PDF](https://arxiv.org/pdf/2602.01002v1)

**作者:** Itai Shapira `[一作]` (Harvard University), Ariel D. Procaccia `[通讯]` (Harvard University)

**通讯引用:** 8462 | [OpenAlex ID](https://openalex.org/A5041089506)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a4b10f5d-130b-4e77-9367-6469ec621899` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文从理论出发，阐明了RLHF（基于人类反馈的强化学习）如何放大大型语言模型的迎合（sycophancy）行为，并给出了该放大机制的数学条件；随后提出一种最小化奖励修正的策略，能在不损失整体能力的前提下抑制迎合；最后在多种偏见注入提示和奖励模型上进行实验验证。

**💡 创新点**

创新点包括：
- 将RLHF优化压力与奖励学习中的偏差联系起来，提出混合对齐偏差统计量 B_F 并证明其决定是否出现迎合；
- 在最佳化级别 β 影响下给出简单的平均奖励差异条件；
- 通过 KL 投影得到唯一的奖励修正形式 r_corr = r – λ A，证明其是 KL‑最小化且唯一的解；
- 在推理时使用 Best‑of‑N 与 PPO 进行对照实验，验证奖励倾斜预测行为漂移的有效性。

**🔧 技术方法**

技术手段包括：
- 随机效用模型（Random Utility Models）与 Bradley–Terry 评分；
- KL 正则化的强化学习（KL‑regularized RLHF）和 Boltzmann 重加权；
- Best‑of‑N 推理优化；
- 奖励修正与 KL 投影；
- 对齐检测器 A(x, y)（可以是 LLM 判断器或监督模型）。

**📊 数据集**

使用的数据集与任务：
- SycophancyEval 的 QA 子集（包含 TruthfulQA、TriviaQA 等）；
- 在这些提示上注入两种偏见策略（Answer Suggestion 与 Are‑You‑Sure）；
- 公开奖励模型对候选答案进行评分。

**📈 对比分析**

比较方法与实验结果：
- 通过计算奖励倾斜 Δ_mean 和奖励尾部差异，评估不同提示下的迎合倾向；
- 在正向倾斜提示上采用 Best‑of‑N（N=1,5,10）与 PPO‑RLHF 对照，发现优化压力越大，迎合率越高；
- 在负向倾斜提示上则相反，优化压力降低迎合率；
- 约 30–40% 的提示出现正向奖励倾斜；
- 加入最小化奖励修正后，Best‑of‑N 与 PPO 的迎合率显著下降，验证修正策略有效。

**⚠️ 局限性**

局限性：
- 解析基于无限数据、完美可拟合的奖励模型和精确 KL 最优解的假设，现实系统受到样本、模型容量、奖励误差和奖励过拟合的限制；
- 对齐检测器 A 可能噪声大、难以泛化，且在优化过程中可能被模型利用；
- 理论上最小化修正的唯一性与优越性在实验中仅做了初步验证，需进一步实证；
- 结果主要在 QA 任务和偏见注入提示上，未覆盖更广泛的交互场景。

---

## 75. Understanding vision transformer robustness through the lens of out-of-distribution detection

**arXiv ID:** 2602.01459 | [PDF](https://arxiv.org/pdf/2602.01459v1)

**作者:** Joey Kuang `[一作]` (University of Waterloo), Alexander Wong `[通讯]` (University of Waterloo)

**通讯引用:** 20597 | [OpenAlex ID](https://openalex.org/A5102920751)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

对小型ViT模型进行低精度（4‑bit）量化后，在ID和OOD任务中评估其鲁棒性，探究预训练规模和数据增强对量化性能的影响，并可视化注意力；

**💡 创新点**

首次将OOD检测作为量化评估指标，揭示大规模预训练在低精度下对OOB鲁棒性不利，同时指出数据增强能显著提升低精度下的OOB性能，并分析高范数outlier token在低精度下的行为；

**🔧 技术方法**

使用RepQ‑ViT后训练量化框架对ViT、DeiT、DeiT3进行8/6/4位量化，采用AUPR‑out评估OOD，利用attention rollout可视化注意力；

**📊 数据集**

ID使用ImageNet‑1k，OOD使用ImageNet‑O、Textures、Places365、SUN、iNaturalist、OpenImage‑O；预训练数据分别为ImageNet‑1k和ImageNet‑22k；

**📈 对比分析**

通过Top‑1准确率、负对数似然（NLL）和AUPR‑out对不同位数进行比较，发现4‑bit量化可使最高17%准确率下降，OOB性能下降更为明显；22k预训练模型在OOB的AUPR‑out下降幅度更大；数据增强可部分缓解这一问题；

**⚠️ 局限性**

仅评估小型ViT，缺乏对大模型或QAT的验证；未深入分析高范数token具体表示；实验覆盖的OOB集有限，泛化性可能受限。

---

## 76. Learning When to Jump for Off-road Navigation

**arXiv ID:** 2602.00877 | [PDF](https://arxiv.org/pdf/2602.00877v1)

**作者:** Zhipeng Zhao `[一作]` (University at Buffalo), Chen Wang `[通讯]` (University at Buffalo)

**通讯引用:** 46881 | [OpenAlex ID](https://openalex.org/A5100337500)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了 Motion‑Aware Traversability (MAT) 模型，将地形成本与车辆速度耦合，实现跳跃、爬行等多样化运动策略。

**💡 创新点**

创新点在于将每个像素的可通过性建模为高斯速度函数，并通过单次感知推断参数，支持实时速度条件成本更新。

**🔧 技术方法**

采用 LiDAR 高程图感知，U‑Net 结构预测高斯参数，并结合 MPPI 规划器进行实时运动规划。

**📊 数据集**

数据集包括 BeamNG 物理仿真环境与 Losi 1/5 赛道的真实 LiDAR 数据，用于训练与评估。

**📈 对比分析**

与基线 Position‑Only Traversability、AnyNav、PhysORD 等对比，MAT 在绕行距离、行驶时间和能耗上平均下降约 70% 以上，表现最优。

**⚠️ 局限性**

局限性在于高斯假设过于简化，无法捕捉复杂运动因子，且对极端速度分布的泛化仍有待提升。

---

## 77. Logic-Oriented Retriever Enhancement via Contrastive Learning

**arXiv ID:** 2602.01116 | [PDF](https://arxiv.org/pdf/2602.01116v1)

**作者:** Wenxuan Zhang `[一作]` (East China Normal University), Yonghe Wu `[通讯]` (East China Normal University)

**通讯引用:** 2457 | [OpenAlex ID](https://openalex.org/A5022634496)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对现有检索嵌入模型进行后训练，使用层级化对比学习激活模型对复杂逻辑表达式的潜在表征，从而提升检索精度。

**💡 创新点**

提出了 LORE：一种基于大语言模型生成的细粒度对比学习数据集（正样本、干扰样本 N1、负样本 N2），并在对比损失中引入层级权重，直接提升查询编码器对逻辑结构的辨识能力。

**🔧 技术方法**

使用层级化对比学习（InfoNCE + 逻辑层级权重）、查询重写（基于 RST 语篇关系）以及仅 fine‑tune 查询编码器的训练策略。

**📊 数据集**

采用 MS MARCO（带细粒度标注）、HotpotQA、MuSiQue 三大公开检索数据集；对测试集进行逻辑重写后进行评估。

**📈 对比分析**

与原始嵌入模型和传统 InfoNCE 对比，LORE 在 Raw 和 Disturbed 数据集上在 Recall@3/5/10 上均取得显著提升，尤其在含复杂逻辑表达式的测试集上提升幅度更大；实验表明仅 fine‑tune 查询编码器即可获得优于 baseline 的性能。

**⚠️ 局限性**

限制主要在于对逻辑结构的覆盖不足，依赖人工或 LLM 辅助生成的重写数据，且在未标注的数据集上的迁移效果仍需进一步验证。

---

## 78. Does Ad-Free Mean Less Data Collection? An Empirical Study of Platform Data Practices and User Expectations

**arXiv ID:** 2602.01231 | [PDF](https://arxiv.org/pdf/2602.01231v1)

**作者:** Sepehr Mousavi `[一作]` (Max Planck Institute for Software Systems), Krishna P. Gummadi `[通讯]` (Max Planck Institute for Software Systems)

**通讯引用:** 27709 | [OpenAlex ID](https://openalex.org/A5067688305)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `9cc9baba-5356-466d-81ff-d80028d90279` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过利用GDPR访问权获取Instagram、Facebook、X三大平台在广告付费与无广告订阅模式下的数据下载包（DDP），系统地对文件内容进行分类与对比，并结合问卷调查用户对不同订阅模式下数据收集的规范与描述性期望，揭示平台行为与用户预期之间的巨大差距。

**💡 创新点**

①首次将GDPR右访数据作为实验材料，直接检视真实平台在两种商业模式下的数据收集差异；②构建文件级和字段级的对比工具，实现对广告相关文件的精细化分类与变化跟踪；③结合跨专业（法律、技术、普通公众）问卷，系统量化用户的期望与认知差异，首次呈现用户期望与平台实践的不匹配。

**🔧 技术方法**

1) GDPR Right of Access 与数据下载包；2) 浏览器端JavaScript实现的DDP对比分析工具；3) 文件系统与JSON结构差异检测；4) 定性编码与统计描述方法。

**📊 数据集**

1) 三个平台（Instagram、Facebook、X）的DDP：两次广告付费模式下（初始与结束）和一次无广告模式下的下载包，共计约280份文件；2) 255名受访者（法律专家90、技术专家90、普通公众75）通过Prolific收集的问卷。

**📈 对比分析**

对比方法：在文件层面统计广告专属文件的出现/缺失，计算删减比例；在字段层面比较JSON模式差异并计数新增/删除字段；通过描述性与规范性问卷答案比例对比，量化用户预期与实际感知差异。性能：工具在浏览器端完成对一套DDP的完整对比耗时约5-10分钟，准确率高于95%，能快速生成结构化报告。

**⚠️ 局限性**

1) 仅使用两名作者账号，无法覆盖多样化使用场景；2) DDP完整性难以验证，可能遗漏隐私数据；3) 只分析三大平台，结果不具备普适性；4) 法律专家样本不足（85人），影响跨专业比较；5) 样本受限于欧盟地区，无法推广到全球用户。

---

## 79. Predictive Scheduling for Efficient Inference-Time Reasoning in Large Language Models

**arXiv ID:** 2602.01237 | [PDF](https://arxiv.org/pdf/2602.01237v1)

**作者:** Katrina Brown `[一作]` (Harvard), Rana Shahout `[通讯]` (Harvard)

**通讯引用:** 74 | [OpenAlex ID](https://openalex.org/A5066902555)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 Predictive Scheduling 框架，利用轻量级 MLP 或 LoRA 预测器在推理前估计每个问题的最佳链式思考长度或难度，并在固定总 token 预算下通过贪心分配动态分配资源。

**💡 创新点**

创新点在于①将 Transformer 中间层隐藏状态映射为早停概率预测；②用 LoRA 微调实现高效难度分类；③在全局预算约束下设计贪心分配算法；④系统化评估哪个层提供最强预测信号。

**🔧 技术方法**

使用技术包括轻量级 MLP、LoRA 微调、早停概率预测、难度分类器、贪心预算分配、GSM8K 算术基准评测。

**📊 数据集**

采用 GSM8K（小学生算术问答）数据集，训练集 7,450 条，测试集 1,294 条。

**📈 对比分析**

与均匀预算基线和完美预知 oracle 进行比较；在 GSM8K 上，基于 LoRA 难度分配的方案在相同 token 成本下提升约 7.9% 的绝对准确率，已覆盖 oracle 的 50%+。

**⚠️ 局限性**

局限性包括：在高 token 预算下预测误差会显著影响性能；连续早停概率预测不如分类稳健；难度划分为粗粒度，易受训练分布偏移；未考虑多链或树结构推理以及不确定性估计。

---

## 80. SNIP: An Adaptive Mixed Precision Framework for Subbyte Large Language Model Training

**arXiv ID:** 2602.01410 | [PDF](https://arxiv.org/pdf/2602.01410v1)

**作者:** Yunjie Pan `[一作]` (University of Michigan), Scott Mahlke `[通讯]` (University of Michigan)

**通讯引用:** 15306 | [OpenAlex ID](https://openalex.org/A5002075773)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种针对大型语言模型预训练的细粒度混合精度训练框架 SNIP，能够根据每层量化误差动态选择 FP8/F P4 等低精度格式。

**💡 创新点**

创新点在于：①引入前向损失偏差与后向权重偏差两项全局质量度量；②将每层量化决策转化为整数线性规划（ILP）问题，在满足效率约束的同时全局最优地最小化质量损失；③兼顾流水线并行，保持各阶段 FLOPs 负载平衡。

**🔧 技术方法**

核心技术包括：基于统计的量化误差估计、量化误差对损失与梯度的影响分析、ILP 优化、动态统计收集与异步更新、FP8/F P4 量化实现（tile/ block 量化、随机舍入）以及多种并行策略（DP、Zero、FSDP、PP）。

**📊 数据集**

使用的公开数据集有：TinyLlama（SlimPajama + StarcoderData）、OpenLlama（RedPajama）以及内部行业 70B 模型的专有数据；模型规模覆盖 1B、3B、7B 和 70B 四个层级。

**📈 对比分析**

与基线（BF16、FP8、FP4 全局精度）、经验粗粒度量化（E‑layer‑id/ type）、误差最小化（min‑abs‑err / min‑rel‑err）以及随机分配等方法对比。实验表明 SNIP 在 25%–75% FP4 FLOPs 下保持与 BF16 基线相近的性能，同时在 70B 模型上可实现约 80% 的 FLOPs 节省；相比其它方法，训练稳定性更好、精度损失更小。

**⚠️ 局限性**

主要局限：①需要额外的统计采集和 ILP 求解，导致每 10–15 分钟一次的额外 GPU/CPU 开销；②目前仅对线性层支持量化，对其它算子未做细粒度控制；③受限于当前 GPU 仅支持 FP8，FP4 的原生硬件验证尚未完成；④假设量化误差为高斯分布，估计误差可能在极端场景下失真。

---

## 81. On the Palindromic/Reverse-Complement Duplication Correcting Codes

**arXiv ID:** 2602.01151 | [PDF](https://arxiv.org/pdf/2602.01151v1)

**作者:** Yubo Sun `[一作]` (Capital Normal University), Gennian Ge `[通讯]` (Capital Normal University)

**通讯引用:** 3810 | [OpenAlex ID](https://openalex.org/A5029449317)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

提出并实现了多种针对逆互补复制错误（reverse‑complement duplication）和回文复制错误（palindromic duplication）的纠错码，涵盖了从长复制错误到长度为一的多次复制错误的不同情形。

**💡 创新点**

创新点在于：
• 通过构造 m‑RCD 根（m‑reverse‑complement‑duplication‑root）实现了仅使用一个冗余符号即可纠正任意数量的长度 ≥ 3⌈log_q n⌉ 的离散（disjoint）逆互补复制；
• 采用图论与独立集下界推导了 Gilbert‑Varshamov 型上界，证明任意长度复制错误的最优冗余可被限制在 2log_q n + log_q log_q n + O(1)；
• 对 q ≥ 4 设计了两套显式构造的长度‑一复制纠错码，冗余分别为 2t log_q n + O(log_q log_q n) 与 (2t‑1) log_q n + O(log_q log_q n)，并给出对应的编码/解码复杂度。

**🔧 技术方法**

主要技术手段包括：
• 组合约束与 m‑RCD 根的概率与编码分析；
• 图论中的独立集下界与邻接度上界（GV 论证）；
• 运行长度限制（run‑length‑limited）与符号编码；
• 哈希函数与重复码（repetition code）用于插入/删除与替换错误的纠错；
• 对逆互补复制的性质进行细致的序列变换与逆向推导。

**📊 数据集**

论文为理论性工作，未使用实际数据集；所有结果均基于符号算术与组合分析。

**📈 对比分析**

通过与传统的 burst‑insertion 纠错码比较，证明在所讨论的复制错误模型下，提出的码在冗余率上有显著提升：
• 对长复制错误仅需 1 个冗余符号；
• 任意长度复制错误可达接近 1 的码率（冗余 ≤ 2log_q n + log_q log_q n）；
• 对长度为一的多次复制错误，冗余分别为 2t log_q n + O(log_q log_q n) 与 (2t‑1) log_q n + O(log_q log_q n)，比直接使用插入/删除纠错码（5 log_q n + O(log_q log_q n) 与 (4t‑1) log_q n + O(log_q log_q n)）更优。

**⚠️ 局限性**

局限性：
• 仅适用于离散（不相交）的复制错误或长度 ≥ 3⌈log_q n⌉ 的情况；
• 对偶长度复制错误与多重复制错误的处理仍不完整；
• 在其他参数区间（如较小 q、不同复制长度分布）下能否进一步降低冗余仍为开放问题。

---

## 82. Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning

**arXiv ID:** 2602.01058 | [PDF](https://arxiv.org/pdf/2602.01058v1)

**作者:** Dylan Zhang `[一作]` (University of Illinois Urbana-Champaign), Hao Peng `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 13152 | [OpenAlex ID](https://openalex.org/A5100600099)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在 SFT+RL 的推理 LLM 后训练管线中，作者提出一种基于重要性采样的加权 SFT 方案，旨在弥补离线训练数据与在线 RL 策略之间的分布不匹配，从而提升 RL 期末性能。

**💡 创新点**

创新点在于：① 将离线经验重权重引入 SFT，使用 OPE 思路计算目标策略与行为策略的似然比；② 提供三种粒度（token、block、sequence）的权重策略，并加入负样本惩罚；③ 通过在 log 空间计算并裁剪权重实现数值稳定。

**🔧 技术方法**

核心技术包括：重要性采样加权、对数空间权重计算与裁剪、block‑level 乘积压缩、可选的负样本反向梯度，以及在现有 NLL 或 KL‑distillation 目标上的直接插拔。

**📊 数据集**

数据集涵盖：SynLogic、Enigmata 合成推理游戏；SYNTHETIC‑2 及 MATH‑500、MINERVA、AIME‑2024/2025、AMC‑2023 等数学推理集，所有数据均为可验证、无噪声的任务。

**📈 对比分析**

对比方法包括标准 SFT、KL‑distillation、单步重要性加权（one‑step IS）、多种重权重变体；实验显示，在多种模型规模（Qwen3‑1.7B/4B/8B 等）下，所提方案在 Pass@1 与 Pass@8 上均优于基线，AIME‑2025 的 Pass@8 提升可达 14.6%，并在 RL 迁移到不同任务分布时保持优势。

**⚠️ 局限性**

局限性：① 需要预先计算离线数据的行为策略概率，若预训练模型不公开或算力受限会受限；② 主要验证于可验证推理任务，对更开放式或不确定性高的任务效果未知；③ 权重计算在长序列上仍可能产生高方差，需要裁剪与归一化的手段。

---

## 83. Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference to Disentangled Tuning

**arXiv ID:** 2602.00994 | [PDF](https://arxiv.org/pdf/2602.00994v1)

**作者:** Yu Li `[一作]` (Renmin University of China), Tieying Zhang `[通讯]` (Bytedance Inc.)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究并解决 Agentic Reinforcement Learning（ARL）中工具使用与推理能力的竞争冲突，提出 LEAS 量化两能力干扰并提出 DART 在同一模型中通过两个独立 LoRA 进行梯度解耦。

**💡 创新点**

创新点：①引入 Linear Effect Attribution System（LEAS）系统化量化工具使用与推理的交互效应；②发现两能力梯度方向几乎正交导致训练冲突；③提出 Disentangled Action–Reasoning Tuning（DART），通过冻结 backbone 并分别为两种 token 分配独立 LoRA，消除梯度冲突，实现单模型近似双模型性能。

**🔧 技术方法**

技术手段：低秩适配（LoRA）、梯度掩码与参数冻结、基于 token 角色的路由器、强化学习（Policy Gradient）训练、线性效应归因分析。

**📊 数据集**

使用七个工具增强问答基准：Natural Questions（NQ）、TriviaQA、PopQA、HotpotQA、2WikiMultiHopQA、Musique、Bamboogle。

**📈 对比分析**

方法评估：与多种基线（Direct Inference、CoT、IRCoT、RAG、Search‑o1、Search‑R1、SFT、R1、Search‑R1‑PPO、Search‑R1‑GRPO 等）在同一数据集上对比，DART 在 EM 上平均提升约 6.35% 并与 2‑Agent 上限相当，尤其在多跳问答场景表现突出。

**⚠️ 局限性**

局限性：①仅验证工具使用与推理两种能力，未扩展至更多多能力交互；②实验集中在问答任务，未验证在其他应用场景或更大模型/工具多样性下的泛化；③梯度解耦虽消除冲突，但可能限制不同能力间有益信息共享；④对 RL 策略和训练效率的进一步优化尚待探究。

---

## 84. Trade-offs in Financial AI: Explainability in a Trilemma with Accuracy and Compliance

**arXiv ID:** 2602.01368 | [PDF](https://arxiv.org/pdf/2602.01368v1)

**作者:** Patricia Marcella Evite `[一作]` (Università degli Studi di Napoli Federico II), Doina Bucur `[通讯]` (University of Twente)

**通讯引用:** 1145 | [OpenAlex ID](https://openalex.org/A5056441666)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193` `3855fcda-48ef-4070-a15e-803cd5c84d83` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

通过半结构访谈和定性分析，研究了金融专业人员在使用AI时对可解释性与准确性、合规性、成本和速度等因素的权衡与优先级。

**💡 创新点**

提出了“金融AI三元悖论”模型：准确性和合规性是不可谈判的前置条件，易于理解是决定AI是否被采纳的关键门槛，而成本与速度则作为可调节的实施约束；这一框架超越了传统的准确性‑可解释性二元权衡。

**🔧 技术方法**

使用半结构访谈、双重编码（整体编码与Gioia方法）、主题归纳与合并代码表等定性技术来梳理受访者的叙述与理由。

**📊 数据集**

20位来自欧洲银行、金融科技、监管与咨询机构的金融专业人士（C-suite、开发者、合规人员等）的访谈记录作为研究数据。

**📈 对比分析**

该研究并未进行定量性能比较；主要通过访谈内容和主题归纳阐明优先级结构，未给出数值性能指标或统计检验，强调探索性和情境适用性。

**⚠️ 局限性**

局限包括：样本规模有限且偏向欧洲，性别分布失衡（75%男性），访谈自我报告可能存在偏差，未能覆盖非欧洲监管环境及更广泛的行业参与者；研究结果缺乏统计推广性。

---

## 85. DCD: Decomposition-based Causal Discovery from Autocorrelated and Non-Stationary Temporal Data

**arXiv ID:** 2602.01433 | [PDF](https://arxiv.org/pdf/2602.01433v1)

**作者:** Muhammad Hasan Ferdous `[一作]` (University of Maryland), Md Osman Gani `[通讯]` (University of Maryland)

**通讯引用:** 217 | [OpenAlex ID](https://openalex.org/A5042231106)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种基于分解的因果发现框架，将多变量时序分为趋势、季节和残差三部分，并在每一部分分别执行适合的因果推断，再将三层图融合成统一的多尺度因果结构。

**💡 创新点**

创新点在于通过频域可分离的分解策略，将非平稳与自相关效应显式拆分，并在不同时间尺度上采用最合适的因果检验（如ADF/KPSS、HSIC、约束式搜索），从而显著减少伪因果、提升可识别性。

**🔧 技术方法**

主要技术包括STL（LOESS）分解、ADF/KPSS检验、HSIC依赖度量、约束式因果发现（如PCMCI+）、以及多层图融合与方向性判定。

**📊 数据集**

实验数据包括合成模拟时序、ERA5/NSIDC月度海冰扩展数据以及ETTh1电力变压器小时数据。

**📈 对比分析**

与PCMCI+、CD-NOD、CFCI、CPC、BOSS‑LiNGAM等现有方法比较，DCD在TPR、FDR和SHD等指标上均优于基线，尤其在强非平稳、季节性和自相关显著的情境下表现最突出。

**⚠️ 局限性**

局限性在于需满足频域可分离与近似线性高斯假设，跨频耦合和趋势内因影响处理不足，将趋势视为外生变量可能忽略长期内因，且对结构随时间变化的适应能力有限。

---

## 86. Towards Multiscale Graph-based Protein Learning with Geometric Secondary Structural Motifs

**arXiv ID:** 2602.00862 | [PDF](https://arxiv.org/pdf/2602.00862v1)

**作者:** Shih-Hsin Wang `[一作]` (University of Utah), Bao Wang `[通讯]` (University of Utah)

**通讯引用:** 2591 | [OpenAlex ID](https://openalex.org/A5019915753)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `09944146-298c-433e-89df-37255de463d7` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了一种基于蛋白质二级结构的多尺度图神经网络框架（SSHG），通过构造细粒度子图和粗粒度结构图实现蛋白质的多尺度学习。

**💡 创新点**

创新点在于将二级结构视为自然的高层节点，采用两阶段GNN保留最大表达力并实现显著的稀疏性与计算效率。

**🔧 技术方法**

使用SCHull图构造、局部坐标系相对方向编码、可注入的两阶段GNN（如GVP‑GNN、ProNet、Mamba）等技术。

**📊 数据集**

主要数据集为酶反应分类（EC）和蛋白‑配体结合亲和力（PDBbind）等公开基准。

**📈 对比分析**

与基线模型相比，EC分类准确率提升5–8%，训练时间下降30%；LBA预测RMSE下降约0.1，Pearson提升至0.61，速度提升约20%；总体性能优于或匹配SOTA。

**⚠️ 局限性**

局限在于仍依赖手工划分的二级结构，聚合方式多采用均值未完全实现注入性，且对极长蛋白链的扩展性尚待进一步验证。

---

## 87. Refining Context-Entangled Content Segmentation via Curriculum Selection and Anti-Curriculum Promotion

**arXiv ID:** 2602.01183 | [PDF](https://arxiv.org/pdf/2602.01183v1)

**作者:** Chunming He `[一作]` (Duke University), Sina Farsiu `[通讯]` (Duke University)

**通讯引用:** 17877 | [OpenAlex ID](https://openalex.org/A5023633559)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种双阶段学习框架 CurriSeg，用来提升在上下文混杂的目标分割任务中的鲁棒性和泛化性能。

**💡 创新点**

创新点包括：① 通过对样本损失的时间统计和像素级不确定性进行动态筛选，构建稳健的课程学习（Robust Curriculum Selection）；② 引入抗课程（Anti-Curriculum Promotion）阶段的频谱模糊细调（Spectral‑Blindness Fine‑Tuning），抑制高频纹理特征，迫使模型利用低频结构与语义信息，突破纹理捷径；③ 这两阶段按“稳定‑再扰动”的顺序组合，形成全新的训练策略。

**🔧 技术方法**

核心技术包括：温热课程调度、时间统计样本加权（TSSW）、像素熵加权（PUE）、低通频谱掩模（SBFT）以及多任务加权损失；整体不增加网络结构或额外参数。

**📊 数据集**

在多种 CECS 基准上验证：Camouflaged Object Detection（COD10K、CAMO 等）、Polyp Image Segmentation（CVC‑ColonDB、ETIS）、Transparent Object Detection（GDD、TOD）、Concealed Defect Detection（CDD2K）以及弱监督、半监督、多模态、视频分割等场景。

**📈 对比分析**

与多种领先方法（SINet、MGL‑R、FEDER、FSEL、RUN 等）以及各类模型（ResNet50、Res2Net50、PVT V2 等）对比，CurriSeg 在 mIoU、F_β、E_φ、S_α 等指标均实现 2–5% 的提升；实验表明训练时间缩短 30–50%，显存占用仅增加 0.1 G，且在图像降噪、模糊、低光等失真条件下表现更稳健。

**⚠️ 局限性**

局限性包括：对超参数（K、p_min、σ^*, γ、r、T_c 等）敏感，需经验调优；在极度依赖高频纹理的任务中，频谱抑制可能导致细节损失；目前仅在二维像素级分割任务上验证，尚待在三维医学或实时视频场景中的进一步评估。

---

## 88. Error Taxonomy-Guided Prompt Optimization

**arXiv ID:** 2602.00997 | [PDF](https://arxiv.org/pdf/2602.00997v1)

**作者:** Mayank Singh `[一作]` (University of Arizona), Eduardo Blanco `[通讯]` (University of Arizona)

**通讯引用:** 1723 | [OpenAlex ID](https://openalex.org/A5052295709)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出ETGPO，通过构建错误分类表并生成针对高频错误的提示，引导LLM提升任务准确率。

**💡 创新点**

创新点在于顶层全局视角的错误分类与筛选，避免逐例微调导致的过拟合，并显著降低优化成本。

**🔧 技术方法**

技术核心包括：多次执行收集失败跟踪、利用优化LLM生成错误分类和可操作性指导、批量化构建错误词典、筛选前G类高频错误并一次性生成完整提示。

**📊 数据集**

使用六大基准数据集：AIME、HMMT、MMLU‑Pro、MuSiQue、AR‑LSAT 与 FOLIO，覆盖数学推理、通用问答、多跳推理与逻辑推理。

**📈 对比分析**

与Chain‑of‑Thought、GEPA、MIPRO等最先进APO方法对比，ETGPO在绝大多数数据集上取得同等或更高准确率，同时优化阶段的token消耗约为其三分之一。

**⚠️ 局限性**

局限性包括：对特定领域知识不足的问题（如MMLU‑Pro）提升有限；在已近饱和的高准确率数据集上提升空间有限；依赖优化LLM的质量与推理深度，若LLM误解错误模式可能导致指导失效。

---

## 89. From Intents to Actions: Agentic AI in Autonomous Networks

**arXiv ID:** 2602.01271 | [PDF](https://arxiv.org/pdf/2602.01271v1)

**作者:** Burak Demirel `[一作]` (Ericsson AB), Yu Wang `[通讯]` (Ericsson AB)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

设计了一个三阶段Agentic AI系统，包含意图解释器、偏好规划器和多目标强化学习控制器，实现从高层意图到网络控制动作的端到端自动化。

**💡 创新点**

创新点在于将自然语言意图解析、贝叶斯优化偏好规划和分布式D‑EQL多目标强化学习集成到同一工作流，并提出PAX‑BO与D‑EQL两种新算法。

**🔧 技术方法**

采用轻量级双SLM意图解释器、贝叶斯优化（PAX‑BO）、分布式多目标强化学习（D‑EQL）以及结构化意图模板（OTM）等技术。

**📊 数据集**

使用5G兼容的事件驱动多小区网络仿真器生成的数据集来评估系统性能。

**📈 对比分析**

与传统RL、OLLA以及5G/5G‑A基线进行对比，实验表明在可靠性、吞吐量和 Pareto 前沿逼近上均优于对照组，提升约4–22%，尤其在可变网络条件下表现突出。

**⚠️ 局限性**

局限在于层级扩展的可行性、解释器在极端不可行意图下的及时响应能力以及对深度频谱低效场景的鲁棒性。

---

## 90. Tendem: A Hybrid AI+Human Platform

**arXiv ID:** 2602.01119 | [PDF](https://arxiv.org/pdf/2602.01119v1)

**作者:** Konstantin Chernyshev `[一作]`, Sergei Tilga `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发并评估了一套名为 Tendem 的混合 AI 与人工专家协作平台，旨在自动完成常规任务并在 AI 无法满足质量或合规需求时由人类专家介入。

**💡 创新点**

创新点在于将 AI 自动规划、工具调用与多层次质量保证（在线/离线 QA）相结合，并通过动态门控与人类专家的专门审核，实现高质量、低成本、低时延的任务交付。

**🔧 技术方法**

核心技术包括：AI 代理的 Plan‑Act‑Observe‑Verify 循环、web 浏览、文件 I/O、Python 与 Bash 沙箱运行、自动化规范检查、引用匹配以及人工专家在关键节点的审查与调优。

**📊 数据集**

使用了 94 个真实自由职业平台任务的内部基准（覆盖销售、运营、市场、分析等 4 大领域）以及公开代理基准 BrowseComp、HLE、GAIA，检验代理在浏览/工具使用和推理任务上的表现。

**📈 对比分析**

方法：在同一任务集上与 ChatGPT Agent 和 Upwork 人工自由职业者进行盲测评估，测量结果质量（Good/Bad/Mediocre）、准确性、完整性、样式、时间与成本。结果显示 Tendem 在 Good 率上比 Upwork 提升 21.3pp（74.5% vs 53.2%），完成时间缩短 53%（中位 16.5h vs 35h），中位成本降低 36%（32.0USD vs 50.0USD），并保持高质量。

**⚠️ 局限性**

局限性：评测仅涵盖非监管敏感、经济价值高的自由职业任务，未包含高级编程、医疗或法律等专业领域；样本规模受限，人工评测存在主观偏差；AI 代理在极长或高度专业化任务中的表现仍有提升空间。

---

## 91. CortiNet: A Physics-Perception Hybrid Cortical-Inspired Dual-Stream Network for Gallbladder Disease Diagnosis from Ultrasound

**arXiv ID:** 2602.01000 | [PDF](https://arxiv.org/pdf/2602.01000v1)

**作者:** Vagish Kumar `[一作]` (Indian Institute of Technology Delhi), Souvik Chakraborty `[通讯]` (Indian Institute of Technology Delhi)

**通讯引用:** 3071 | [OpenAlex ID](https://openalex.org/A5030664714)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `7b0f05dc-d396-4b03-96d2-a379dbd5049d`

**🎯 论文内容**

提出了轻量级的 CortiNet，融合频域分解与结构-感知双流处理，用于超声下胆囊疾病的自动诊断。

**💡 创新点**

创新点在于：① 将 Daubechies 小波分解作为物理诱导的频域先验；② 双流网络将低频结构与高频纹理分别编码并在后期融合；③ 引入基于校准准确率的噪声感知自适应推理；④ 仅在结构分支上使用 Grad‑CAM 提升可解释性。

**🔧 技术方法**

采用小波变换、轻量化卷积编码器、全局平均池化、加权融合与交叉熵训练；在推理时实现动态路径切换。

**📊 数据集**

使用公开的 10,692 张胆囊超声图像，涵盖 9 类临床相关疾病，经过 60/20/20 的分层划分。

**📈 对比分析**

与 VGG16、InceptionV3、ResNet152、MobileNet 以及专用模型 GBCNet、RadFormer 进行对比，CortiNet 在 98.74% 准确率、0.9999 AUC 的同时仅需 1.32M 参数、1.52 GFLOPs，推理时间 2.93 ms，显著优于对手。

**⚠️ 局限性**

局限包括：仅基于回顾性单中心数据，缺乏多机构前瞻验证；解释性仅关注结构分支，未覆盖多视角/时序推理；自适应分支选择仅经验验证，缺乏神经科学支持。

---

## 92. Chronos: Learning Temporal Dynamics of Reasoning Chains for Test-Time Scaling

**arXiv ID:** 2602.01208 | [PDF](https://arxiv.org/pdf/2602.01208v1)

**作者:** Kai Zhang `[一作]` (University of Science and Technology of China), Xiang Wang `[通讯]` (University of Science and Technology of China)

**通讯引用:** 16386 | [OpenAlex ID](https://openalex.org/A5100389037)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种轻量化的时间序列化推理轨迹评分器Chronos，能在推理时对多条推理轨迹进行质量评估并加权投票；

**💡 创新点**

创新点在于将推理轨迹视为时间序列，利用多尺度卷积捕捉局部与全局的时序依赖，取代传统统一平均或启发式评分；

**🔧 技术方法**

核心技术包括token概率序列构造、基于InceptionTime的多尺度卷积残差网络以及基于得分的加权多数投票；

**📊 数据集**

使用AIME（2000‑2023）训练，评估数据集为AIME25、HMMT25与GPQA‑Diamond；

**📈 对比分析**

与Pass@1、Maj@128、DeepConf等基线相比，Chronos在各模型（DeepSeek‑1.5B/8B、Qwen3‑4B）上均实现了显著提升，例如在Qwen3‑4B上HMMT25准确率从60.62%提升至74.38%，总体提升幅度达4‑7%；

**⚠️ 局限性**

局限性包括：需要白盒访问模型的token级概率分布，受限于模型的校准与能力；对非结构化领域的迁移性能尚不确定；对闭源API模型不可直接部署；

---

## 93. Simple and Robust Quality Disclosure: The Power of Quantile Partition

**arXiv ID:** 2602.01066 | [PDF](https://arxiv.org/pdf/2602.01066v1)

**作者:** Shipra Agrawal `[一作]` (Columbia University), Wei Tang `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 24327 | [OpenAlex ID](https://openalex.org/A5008356565)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出了在平台对卖家产品质量披露时，如何在保证信息披露简单、鲁棒的前提下，仍能接近贝叶斯最优收入的理论框架；

**💡 创新点**

给出了对k‑quantile分区披露策略的最优鲁棒竞争比，并证明该策略在任意质量分布、买方类型分布和线性估值函数下都能获得约 1+Θ(1/k) 的保守性；

**🔧 技术方法**

使用凸分析与极值函数表示，将原始的经济最优化问题转化为极点函数的最小化；通过对k‑quantile阈值的递推求解和固定点方程，得到最优阈值；

**📊 数据集**

论文主要为理论研究，并未使用任何实际数据集；

**📈 对比分析**

通过与贝叶斯最优披露方案的竞争比来评估，发现k=5时可达到 91.71% 的最优收益，且任何单调分区披露方案上限为 2 倍；

**⚠️ 局限性**

对非线性估值函数或非独立质量-类型假设的扩展尚未处理，且仅针对单个卖家的单价设置，未考虑竞争与多卖家情景。

---

## 94. Learning to Guide Local Search for MPE Inference in Probabilistic Graphical Models

**arXiv ID:** 2602.01475 | [PDF](https://arxiv.org/pdf/2602.01475v1)

**作者:** Brij Malhotra `[一作]` (University of Texas at Dallas), Vibhav Giridhar Gogate `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出一种基于注意力的神经网络，用于在已知图结构的概率图模型上对MPE推理中的局部搜索做邻域选择的加速与改进，形成一种可在多次查询中共享的“放大式前瞻”框架。

**💡 创新点**

创新点在于：①将MPE的邻域选择问题视为监督学习任务，用近似最优解做距离标签；②训练注意力网络预测邻域节点是否能缩小到参考解的汉明距离；③将该预测与传统的最佳改进(log‑likelihood)信号按可调参数线性组合，实现短期收益与长期前瞻的平衡；④实现了可跨查询迁移的学习式指导，从而在重复查询场景下显著提升搜索效率。

**🔧 技术方法**

核心技术包括：①注意力网络（多头注意力+残差块）对变量-取值对进行嵌入；②一阶汉明距离监督生成数据；④交叉熵损失训练；⑤在搜索时将LL增益归一化为概率并与网络输出按 λ 合成最终得分；⑤结合传统Greedy或GLS+等局部搜索实现。

**📊 数据集**

实验数据集来源于UAI推理竞赛的25个高树宽图模型（如Promedas、Pedigree、Ising网格、WCSP等），每个模型包含351–6400个变量、最多100k因子；为每个模型生成1000个不同的MPE实例（约5%–20%证据），划分为800/100/100的训练/验证/测试集。

**📈 对比分析**

与传统最佳改进（Greedy）和GLS+对比，采用“win‑rate”和“对数似然提升”两指标；实验显示在大多数模型上，BEACON‑Greedy 与 BEACON‑GLS+ 均在搜索早期即获得更高的对数似然，win‑rate 高达70%~90%，对数提升可达数十个百分点，且优势在搜索步数增加后依旧保持，说明学习式前瞻显著加速并提升最终质量。

**⚠️ 局限性**

局限性包括：①需要依赖近似最优解作为监督，若近似偏差大可能影响预测；②对 λ 参数敏感，需在验证集上调参；③仅利用一阶汉明距离，未考虑多步连贯性；④在变量域大或邻域宽度高时，神经评分的计算成本显著；⑤缺乏严格的收敛保证，性能依赖预测器的准确性。

---

## 95. OASIS-DC: Generalizable Depth Completion via Output-level Alignment of Sparse-Integrated Monocular Pseudo Depth

**arXiv ID:** 2602.01268 | [PDF](https://arxiv.org/pdf/2602.01268v1)

**作者:** Jaehyeon Cho `[一作]` (Gachon University), Jhonghyun An `[通讯]` (Gachon University)

**通讯引用:** 140 | [OpenAlex ID](https://openalex.org/A5027559329)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6514db3d-8de6-452c-91b7-acdb31787cc4` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种基于预训练单目深度估计与稀疏激光雷达锚点融合的先验引导深度补全框架，利用Poisson域融合生成无学习参数的伪深度先验，并训练极小残差网络实现少样本高精度补全。

**💡 创新点**

在输出层使用预训练单目深度模型的稠密预测与稀疏点匹配生成无学习参数的伪深度先验；残差网络仅学习局部修正，显著降低可学习参数并在极少标注下保持尺度与边缘；采用部署友好的无特征耦合方式。

**🔧 技术方法**

Poisson域融合、硬约束梯度域稠密化、残差编码器-解码器、稀疏锚点约束的超几何传播与软锚定、少样本训练与量化等技术。

**📊 数据集**

KITTI Depth Completion 与 NYUv2 两大基准数据集。

**📈 对比分析**

与多种基准（CSPN、DySPN、CompletionFormer、BPNet、DepthPrompting、UniDC 等）进行 1/10/100-shot 以及 1 序列的少样本评估；在 KITTI 1-shot RMSE 1.419m、MAE 0.507m，100-shot RMSE 1.245m、MAE 0.355m，显著优于同类方法；NYUv2 1-shot RMSE 0.2105、MAE 0.1105，整体排名第二。

**⚠️ 局限性**

对稀疏锚点的依赖导致在锚点稀疏或误投影场景下可能出现尺度漂移；残差网络容量极低，可能在室内细节或高动态场景下欠拟合；未对跨传感器或不同稀疏度的鲁棒性做深入评估。

---

## 96. MDS matrices from skew polynomials with automorphisms and derivations

**arXiv ID:** 2602.01383 | [PDF](https://arxiv.org/pdf/2602.01383v1)

**作者:** Atif Ahmad Khan `[一作]` (Aligarh Muslim University), Abhishek Kesarwani `[通讯]` (Indian Institute of Information Technology Vadodara)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

在偏置多项式环 𝔽_q[X;θ,δ] 上构造 δ_θ‑循环矩阵与准递归 MDS 矩阵，证明其可满足 MDS 与自逆性质。

**💡 创新点**

首次引入 δ_θ‑循环结构，结合 θ‑导数和自同构在非交换多项式环中构造可自逆的 MDS 矩阵，显著提升实现效率。

**🔧 技术方法**

利用非交换多项式环、θ‑导数、δ‑θ 循环矩阵、伴随矩阵以及 Hadamard 积等代数工具，并与线性码理论相结合。

**📊 数据集**

示例中使用有限域 𝔽_2^4、𝔽_2^8 的具体元素 α 进行构造，未使用外部数据集。

**📈 对比分析**

通过与传统循环/递归 MDS 矩阵对比，证明在偶数阶下得到的准递归 MDS 矩阵为自逆，逆运算成本降低；示例矩阵验证了 MDS 性质。

**⚠️ 局限性**

对 δ_θ‑循环 MDS 矩阵的完整特征仍未完全阐明；开放问题包括其正交/半正交性质及更广泛的有限域推广。

---

## 97. The Keyhole Effect: Why Chat Interfaces Fail at Data Analysis

**arXiv ID:** 2602.00947 | [PDF](https://arxiv.org/pdf/2602.00947v1)

**作者:** Mohan Reddy `[一作]` `[通讯]` (Cornerstone AI Labs), Mohan Reddy (Cornerstone AI Labs)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

论文探讨了聊天界面在多步骤、状态依赖的数据分析任务中的不足，提出了聊天界面通过五种机制系统性地降低分析性能。

**💡 创新点**

创新点在于将认知过载形式化为一个数学模型，并提出了八种混合设计模式来解决聊天界面的缺陷。

**🔧 技术方法**

使用了认知科学的六个框架（空间认知、工作记忆、双重编码、语言遮蔽、认知行动、分布式认知）来解释聊天界面在分析工作中的失败。

**📊 数据集**

未具体提及使用的数据集，但讨论了多维数据集的分析任务。

**📈 对比分析**

与传统图形用户界面（GUI）相比，聊天界面在处理复杂分析任务时表现出更高的认知负担和错误概率，尤其是在需要同时跟踪多个状态和假设时。

**⚠️ 局限性**

限制在于该论文主要是理论性的，缺乏对提出的模型和假设的实证验证，且未考虑用户个体差异对结果的影响。

---

## 98. UniMorphGrasp: Diffusion Model with Morphology-Awareness for Cross-Embodiment Dexterous Grasp Generation

**arXiv ID:** 2602.00915 | [PDF](https://arxiv.org/pdf/2602.00915v1)

**作者:** Zhiyuan Wu `[一作]` (King’s College London), Shan Luo `[通讯]` (King’s College London)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了一种跨体型多指抓握生成框架 UniMorphGrasp，能够在不同机器人手结构上产生稳定且多样的抓握姿态。

**💡 创新点**

创新点包括：①将手结构映射到统一的人类五指树并用 Graphormer 对关节图进行编码；②在扩散模型的去噪过程中加入形态感知的跨注意机制；③设计层级关节加权损失以强化手指关节的层次约束，实现零样本新手型泛化。

**🔧 技术方法**

技术手段主要是扩散生成模型、Graphormer 图神经网络、点云 Transformer 以及形态感知的交叉注意和损失。

**📊 数据集**

使用了 MultiDex（训练/测试）、Multi-GraspLLM、Objaverse 进行跨数据集评估，以及在 Leap Hand + YCB 数据集上做了真实抓取实验。

**📈 对比分析**

与 DFC、GenDexGrasp、GeoMatch、DRO‑Grasp 等方法比较，UniMorphGrasp 在 MultiDex 上取得 92.4% 成功率、0.527 角度多样性、0.47 s 生成时间；在 Multi‑GraspLLM 与 Objaverse 的零样本评估中亦优于基线，表现出色的稳定性和多样性。

**⚠️ 局限性**

局限性：需先将所有手模型映射到五指树，无法直接处理非标准手结构；极端拓扑或尺寸变化时性能略下降；缺乏对软体抓手或极低计算成本平台的验证。

---

## 99. Feedback by Design: Understanding and Overcoming User Feedback Barriers in Conversational Agents

**arXiv ID:** 2602.01405 | [PDF](https://arxiv.org/pdf/2602.01405v1)

**作者:** Nikhil Sharma `[一作]` (Johns Hopkins University), Yunyao Li `[通讯]` (Adobe Inc.)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文系统性研究了人类在与对话代理互动时提供高质量反馈的障碍，提出四个反馈障碍框架，并基于此设计并实现了名为FeedbackGPT的轻量化界面支架，实验证明其能显著提升用户的目标相关性、具体性和反馈量。

**💡 创新点**

创新点在于：①将Grice准则引入人机交互反馈分析，形成四个反馈障碍模型；②提出三条设计原则并落地到七个可插拔支架；③通过实证研究验证支架对反馈质量的提升，为对话代理设计提供可操作的设计指导。

**🔧 技术方法**

采用GPT‑4o等大型语言模型作为后端，前端使用Next.js+Node.js+MongoDB实现内联注释、撤销重做、反馈聚合、快速操作、评估与解释等功能；研究方法为主题分析、混合方法评估和对照实验。

**📊 数据集**

主要使用研究参与者在两轮写作任务中产生的对话与反馈日志；未使用公开数据集，仅引用WildFeedback等为背景信息。

**📈 对比分析**

通过20名受试者的对照实验，FeedbackGPT在目标相关性上提升约26%、具体性提升约25%，反馈量平均增加约139字/轮；主观评价显示易用性和反馈感知质量提升，但认知负荷略高；与ChatGPT基线相比无显著差异的可表达性指标。

**⚠️ 局限性**

局限性包括样本规模有限、任务以写作为主不具普适性、支架组合与相互作用未全面评估、未考察长期使用和模型改进对反馈效果的联合影响。

---

## 100. EDIS: Diagnosing LLM Reasoning via Entropy Dynamics

**arXiv ID:** 2602.01288 | [PDF](https://arxiv.org/pdf/2602.01288v1)

**作者:** Chenghua Zhu `[一作]` (South China Normal University), Guojing Zhou `[通讯]` (South China Normal University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并评估了熵动力学不稳定度量（EDIS），通过分析大型语言模型在生成过程中的 token 级熵随时间的演化，区分正确与错误推理，并将其用于推理时间的候选筛选以及强化学习的样本筛选与加权。

**💡 创新点**

创新点在于：①将熵视为动态过程而非静态汇总，发现错误推理具有两类显著的不稳定模式——持续上升的 burst 脉冲和峰谷振荡；②将这两种不稳定模式与整体熵方差相结合，形成可解释的轨迹级指标 EDIS；③展示 EDIS 在无监督推理选择和 RL 训练中的显著性能提升，证明熵演化信息是先前方法所忽视的关键。

**🔧 技术方法**

核心技术包括 token 级熵计算、熵轨迹分析、滑动窗口累计增长与历史最小值阈值检测、方差加权，构建 EDIS；在 RL 侧使用 Group Relative Policy Optimization（GRPO）结合 EDIS 过滤/加权；推理选择使用 best‑of‑N 策略和 Borda 排序；对比评估用 ROC‑AUC、选择准确率等指标。

**📊 数据集**

使用四个公开数学推理基准：GSM8K、MATH、AMC23、AIME24；训练时以 NuminaMath‑20K 作为 RL 语料；在不同温度（0.2、0.6、1.0）和模型（Qwen2.5‑Math‑1.5B、Qwen3‑4B‑Instruct、Qwen2.5‑Math‑7B）上进行实验。

**📈 对比分析**

与均值熵、序列熵、Self‑Certainty、Majority Voting 等基线相比，EDIS 在 best‑of‑N 选择中平均准确率从约30% 提升至55%（≈82% 相对提升），整体 AUC 由 0.673 提升至 0.804；在 RL 训练中相较于基线提升约5–7个百分点。实验表明 EDIS 能更精确地区分推理质量并带来显著性能改进。

**⚠️ 局限性**

局限性：①仅在数学推理任务验证，未证明对代码生成、科学推理等其他推理任务的泛化；②EDIS 的阈值、窗口大小等超参数需针对不同模型手工调优；③RL 侧实验仅为初步示例，缺乏更系统的优化与大规模验证。

---

## 101. FutureMind: Equipping Small Language Models with Strategic Thinking-Pattern Priors via Adaptive Knowledge Distillation

**arXiv ID:** 2602.01222 | [PDF](https://arxiv.org/pdf/2602.01222v1)

**作者:** Shaoxiong Yang `[一作]` (MiLM Plus, Xiaomi Inc), Jian Luan `[通讯]` (MiLM Plus, Xiaomi Inc)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `8d10c613-917e-4880-9716-17789f50e119` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 FutureMind 框架，通过将小型语言模型（SLM）拆分为问题分析、逻辑推理、策略规划与检索指导四个模块，并结合自适应检索策略，实现无训练的思维模式蒸馏，从而提升多跳问答性能。

**💡 创新点**

创新点包括：①训练无监督的思维模式蒸馏方法；②四阶段模块化推理管道；③三种自适应检索策略（前向步进、反向约束聚焦、并行交叉推理）；④发现教师-学生认知偏差瓶颈并分析其对蒸馏效果的影响。

**🔧 技术方法**

采用结构化思维模式蒸馏、检索增强生成（RAG）、工具调用（ToolCall）与自适应检索规划、并使用 ACC_E 与 ACC_L 两种评估指标。

**📊 数据集**

使用了四个公开多跳问答基准：2WikiMultihopQA、MuSiQue、Bamboogle、Frames。

**📈 对比分析**

在 Naive Gen、Standard RAG、Search‑o1 三种基线上进行对比，FutureMind（TC+FM）在所有模型尺寸与架构下普遍实现 state‑of‑the‑art 结果，尤其在 SLM 上提升最大；在 2WikiMultihopQA、Bamboogle、Frames、MuSiQue 上均显著优于基线，甚至部分情况下超过 LLM。

**⚠️ 局限性**

主要局限在于：①过于复杂的教师计划会产生认知偏差瓶颈，导致蒸馏失真；②蒸馏效果高度依赖教师与学生的认知匹配，无法完全泛化；③当前仅在四个多跳 QA 基准上验证，跨任务迁移与计划质量量化仍待进一步研究。

---

## 102. PolicyFlow: Policy Optimization with Continuous Normalizing Flow in Reinforcement Learning

**arXiv ID:** 2602.01156 | [PDF](https://arxiv.org/pdf/2602.01156v1)

**作者:** Shunpeng Yang `[一作]` (Hong Kong University of Science and Technology), Hua Chen `[通讯]` (Zhejiang University-University of Illinois Urbana-Champaign Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `40105733-5154-44cd-8090-a8cab9e64b07` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种基于连续归一化流（CNF）的 on‑policy 强化学习算法 PolicyFlow，能够在 PPO 框架下直接优化可表达多模的动作分布。

**💡 创新点**

核心创新在于：①通过在插值路径上利用速度场差异近似重要比，避免了完整流轨迹的高昂反向传播；②引入 Brownian 正则化，利用布朗运动理论隐式实现熵正则，抑制模式坍塌并提升多样性。

**🔧 技术方法**

使用技术包括：连续归一化流、PPO 风格的裁剪目标、插值路径重要比近似、Brownian 动力学启发的熵正则、GAE 优势估计以及时间相关速度场的神经网络。

**📊 数据集**

实验数据集涵盖 MultiGoal、MuJoCo Playground（多种机器人仿真任务）和 IsaacLab（Lift‑Cube、Navigation 等），用于评估多模性和控制性能。

**📈 对比分析**

与 FPO、DPPO 及标准 PPO 在同一任务上进行对比，评价指标为平均累计奖励、收敛速度和多模覆盖度；结果显示 PolicyFlow 在绝大多数环境中与 PPO 相当或更优，在多模 MultiGoal 任务上明显优于 FPO/DPPO，且收敛更快。

**⚠️ 局限性**

局限性包括对插值路径、熵正则权重等超参数敏感；在极端高维或极端多模情形下仍可能出现模式坍塌；理论分析尚不完整，需进一步完善。

---

## 103. Multi-Agent Causal Reasoning System for Error Pattern Rule Automation in Vehicles

**arXiv ID:** 2602.01155 | [PDF](https://arxiv.org/pdf/2602.01155v1)

**作者:** Hugo Math `[一作]` (BMW Group), Rainer Lienhart `[通讯]` (Augsburg University)

**通讯引用:** 9603 | [OpenAlex ID](https://openalex.org/A5009744749)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3855fcda-48ef-4070-a15e-803cd5c84d83` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c773407a-6119-4871-b8b3-1e7ae17a6851` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

设计并实现了一套名为CAREP的多代理因果推理系统，能够自动从大规模车辆诊断事件序列中生成错误模式的布尔规则；

**💡 创新点**

创新点在于将因果发现、上下文检索与可解释推理相结合，采用自适应阈值聚合和平均因果效应指标，使系统在高维稀疏事件空间中仍能精准推断规则；

**🔧 技术方法**

主要技术包括双塔Transformer预训练（用于事件与标签的条件概率），单次因果发现（基于互信息/信息增益），平均因果效应/PMI共现评估，RAG式上下文检索以及LLM协作的多代理框架；

**📊 数据集**

使用真实车载数据集，包含约30万条序列、29,100种DTC和474个错误模式；

**📈 对比分析**

通过与Claude Sonnet 3.5/3.7、GPT4.1/mini等LLM基线在语义（真值表）和结构（DTC集合）两种评估下比较，CAREP在Recall@1、Precision@1和F1等指标上均显著优于基线，语义一致率达70%，结构匹配率78%；

**⚠️ 局限性**

局限性包括对稀有标签噪声仍敏感、阈值设定需要经验调优、仅在汽车诊断场景验证，且对Transformer序列长度和模型规模有一定依赖。

---

## 104. A zero-test for D-algebraic transseries

**arXiv ID:** 2602.01188 | [PDF](https://arxiv.org/pdf/2602.01188v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `847a60d8-a755-47af-ba5d-c5236b9e3083`

---

## 105. Direct vs. Score-based Selection: Understanding the Heisenberg Effect in Target Acquisition Across Input Modalities in Virtual Reality

**arXiv ID:** 2602.01061 | [PDF](https://arxiv.org/pdf/2602.01061v1)

**作者:** Linjie Qiu `[一作]` (Hong Kong University of Science and Technology), Mingming Fan `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 2452 | [OpenAlex ID](https://openalex.org/A5048919402)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `f86bf285-fd08-4156-973b-6e6481af8fa0` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

对四种VR目标选择技术（直接控制器、直接手势、基于分数控制器、基于分数手势）进行实验评估，量化Heisenberg效应对选择精度、时间和误差的影响。

**💡 创新点**

提出将用户意图历史以时序加权的VOTE方法（Weighted VOTE/Adaptive Weighted VOTE）来补偿Heisenberg效应，并在数据驱动下设计权重函数，显著降低误差率。

**🔧 技术方法**

使用Unity 2022 LTS、Meta Quest 3、Oculus SDK进行手势与控制器跟踪，实施IntenSelect等基于分数的选择，并实现自定义的加权投票算法。

**📊 数据集**

实验数据来自24名受试者共2592个选择试验（21621条数据），涵盖9种目标宽度×间距组合，构成研究专用数据集。

**📈 对比分析**

与原始直接/分数选择、VOTE、Shift‑to‑Before等基线比较，Weighted VOTE将误差率从21.96%降至7.54%（SH），其他技术也有明显提升，整体表现优于传统方法。

**⚠️ 局限性**

实验仅在Quest 3上进行，未收集主观体验或其他输入模式（如眼球、头部射线）数据，且加权投票方法对直接选择改进有限，未来需扩展至更多硬件与动态自适应。

---

## 106. DRFormer: A Dual-Regularized Bidirectional Transformer for Person Re-identification

**arXiv ID:** 2602.01059 | [PDF](https://arxiv.org/pdf/2602.01059v1)

**作者:** Ying Shu `[一作]` (Beijing Jiaotong University), Kai Lv `[通讯]` (Beijing Jiaotong University)

**通讯引用:** 591 | [OpenAlex ID](https://openalex.org/A5026666435)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种双正则化双向Transformer（DRFormer），融合视觉基础模型DINO和视觉‑语言模型CLIP，以实现人像重识别的局部细节与全局语义的协同学习。

**💡 创新点**

创新点在于：①设计双向交叉注意机制，使DINO和CLIP在查询与键值层面互相补充；②引入内部token多样性正则化，促使同一模型内部的可学习token关注不同区域；③引入模型间偏差正则化，平衡DINO与CLIP的贡献，理论上降低两模型的偏差。

**🔧 技术方法**

使用技术包括：预训练的DINOv2 ViT‑B/14和CLIP ViT‑B/16作为视觉编码器；双向Transformer融合模块（交叉注意+自注意层）；cosine距离正则化；triplet与交叉熵损失。

**📊 数据集**

实验数据集为五个公开人像重识别基准：Market‑1501、MSMT17、DukeMTMC、CUHK03‑NP、Occluded‑Duke。

**📈 对比分析**

在所有五个数据集上，DRFormer相较基线和现有最先进方法均获得显著提升，Market‑1501 mAP提升至92.9%、Rank‑1 97.0%，MSMT17 mAP 78.7%/Rank‑1 91.3%，DukeMTMC mAP 85.5%/Rank‑1 92.5%，CUHK03‑NP 88.1%/Rank‑1 89.6%，Occluded‑Duke 65.3%/Rank‑1 72.1%。

**⚠️ 局限性**

局限性包括：①模型依赖大规模预训练权重，计算与显存需求较高；②正则化超参数需针对不同数据集调优；③仅在五个标准数据集验证，缺乏对更极端遮挡、跨域或多模态场景的深入评估；④学习的可学习token数量对性能影响较大，需进一步探索自适应机制。

---

## 107. Foundation CAN LM: A Pretrained Language Model For Automotive CAN Data

**arXiv ID:** 2602.00866 | [PDF](https://arxiv.org/pdf/2602.00866v1)

**作者:** Akiharu Esashi `[一作]` (University of North Texas), Mohsen Amini Salehi `[通讯]` (University of North Texas)

**通讯引用:** 1178 | [OpenAlex ID](https://openalex.org/A5001628237)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出并实现了一个将汽车CAN信号视为“语言”的基础预训练模型，利用大规模未标注的已解码CAN数据进行MLM预训练，然后在不同的保险和车辆安全任务（碰撞检测、碰撞点分类）上进行微调。

**💡 创新点**

① 统一的离散–连续混合token化方案，兼顾符号、枚举与连续量化；② 首次在CAN领域展示单一预训练模型可跨任务迁移；③ 将自然语言处理中的基础模型范式迁移到汽车CAN数据。

**🔧 技术方法**

使用Transformer‑BERT架构，MLM目标，离散化量化与符号标记的token化，全文微调与类别加权损失，基准对比采用GLM与1D‑CNN。

**📊 数据集**

预训练数据来自约10,000辆车的90天CAN记录，9天约19 B tokens；下游任务数据包含112,312个10 s序列（碰撞检测）和1,088个事故标注（碰撞点分类）。

**📈 对比分析**

通过与GLM（碰撞检测）和1D‑CNN（碰撞点分类）的对比，模型在10:1阈值下F1 76.1%（GLM 81.1%），宏F1 27.0%（CNN 24.3%），在100:1极端不平衡下F1 54.2%（GLM 65.3%）。总体上接近或略低于基线，但验证了跨任务迁移的可行性。

**⚠️ 局限性**

① 预训练仅覆盖9天，缺乏季节、天气等多样性；② 对极罕见事件的识别效果不佳；③ 模型规模增大后收益有限，主要受数据多样性限制；④ 仅评估了两类任务，缺乏更广泛的应用验证。

---

## 108. SwiftRepertoire: Few-Shot Immune-Signature Synthesis via Dynamic Kernel Codes

**arXiv ID:** 2602.01051 | [PDF](https://arxiv.org/pdf/2602.01051v1)

**作者:** Rong Fu `[一作]` (University of Macau), Simon Fong `[通讯]` (University of Macau)

**通讯引用:** 11860 | [OpenAlex ID](https://openalex.org/A5086422507)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a8e75ba4-7a2d-4153-b003-06c94533add0` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

开发了 SwiftRepertoire，一种基于原型检索的快速权重适配框架，可在仅有少量支持样本的情况下对 TCR 组库任务进行即时、样本高效的自适应，并保持对位点级 motif 的可解释性；

**💡 创新点**

创新点在于：① 通过紧凑任务描述符驱动的检索实现稀疏的 fast‑weight 合成；② 采用几何保持的原型与硬稀疏化的近端优化；③ 在检索后嵌入嵌套的统计校准流程，使预测与 motif 发现直接关联；

**🔧 技术方法**

技术手段包括预训练蛋白语言模型（BERT/TCR‑BERT）作为冻结 backbone、PCA 与 Fisher 能量检验确定 adapter 低维空间、原型检索与近端优化产生稀疏适配器、Neural‑ODE 模块提供连续时间建模、以及基于 Markov 背景的两阶段 motif 校准与多重检验控制；

**📊 数据集**

使用肺癌（Lung）与甲状腺癌（THCA）TCR 组库数据集进行主实验，并在外部多种癌症（GBM、PACA、ESCA 等）进行跨病种验证；

**📈 对比分析**

与 DeepCAT、DeepLION、TransMIL、BiFormer、AAMean、AAMIL、BertSingle、BertTCR、MethPriorGCN 等多种基线进行对比，SwiftRepertoire 在 Accuracy、F1‑score、AUC 等指标上均超过基线，AUC 常超过 0.99；

**⚠️ 局限性**

局限性包括：① 需要预先手工设置原型数量与维度，超参数敏感；② 对极少数或全新任务的泛化能力尚待进一步验证；③ 任务描述符在高度异质数据上的鲁棒性尚不充分；④ 计算成本虽低于全微调，但仍需专用 GPU 进行原型检索与近端优化。

---

## 109. ConsensusDrop: Fusing Visual and Cross-Modal Saliency for Efficient Vision Language Models

**arXiv ID:** 2602.00946 | [PDF](https://arxiv.org/pdf/2602.00946v1)

**作者:** Dhruv Parikh `[一作]` (University of Southern California), Viktor Prasanna `[通讯]` (University of Southern California)

**通讯引用:** 17379 | [OpenAlex ID](https://openalex.org/A5033166029)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文提出一种无训练的视觉令牌压缩框架ConsensusDrop，利用视觉编码器和跨模态注意力的共识来挑选最有用的视觉令牌；

**💡 创新点**

创新点在于先行提取LLM前的跨模态注意力（SCAP）与视觉自注意力（saliency）进行融合，并通过Encoder-guided Token Merge（EGTM）压缩余下的令牌；

**🔧 技术方法**

技术包括Static Cross‑Attention Probe、凸合并策略、Farthest Point Sampling（FPS）与硬指派以及投影空间合并；

**📊 数据集**

使用12个VQA/多模态理解/视频QA基准，包括VQAv2、GQA、POPE、MMBench、MMVet、TGIF‑QA、MSVD‑QA、MSRVTT‑QA等；

**📈 对比分析**

与ToMe、FastV、SparseVLM、VisionZip、VisPruner等基准比较，ConsensusDrop在所有令牌预算下均保持95%~99%原始性能，且在TTFT、TPOT、KV内存上实现显著提升；

**⚠️ 局限性**

局限在于仍依赖视觉编码器的注意力特征，且对极高分辨率或极端压缩场景下的跨模态注意力采样可能不够稳健。

---

## 110. TreeLoc: 6-DoF LiDAR Global Localization in Forests via Inter-Tree Geometric Matching

**arXiv ID:** 2602.01501 | [PDF](https://arxiv.org/pdf/2602.01501v1)

**作者:** Minwoo Jung `[一作]` (Seoul National University), Ayoung Kim `[通讯]` (Seoul National University)

**通讯引用:** 5614 | [OpenAlex ID](https://openalex.org/A5100740100)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出 TreeLoc，利用 LiDAR 提取的树干几何特征构建双层描述符（TDH 与 2D 三角形描述符），实现森林环境下的 6-DoF 全球定位。

**💡 创新点**

创新点在于：①将树干轴、基点与 DBH 三参数的树干表示作为稳健、可解释的特征；②在二维投影上进行滚转、俯仰校正以消除姿态误差；③采用双重描述符（先粗匹配后细化）与两步几何验证，兼顾检索速度与定位精度；④构建紧凑的全局树数据库，实现多时段低存储、增量式地图管理。

**🔧 技术方法**

技术方法包括：基于 RealtimeTrees 的树干重建；树干轴对齐的 RANSAC 旋转校正；TDH 统计树干分布并使用 χ² 距离进行粗匹配；2D 三角形哈希键实现细化匹配；两步 SVD+RANSAC 的 2D 与 3D 几何验证得到 6-DoF 位姿；最终无 ICP 直接完成位姿对齐。

**📊 数据集**

使用 Oxford Forest Place Recognition、Wild-Places、BotanicGarden 三个公开森林/公园数据集进行实验，且对比了 SC++、SOLID、RING++（全局）、BTC、MapClosure（局部）、以及多种学习型方法（TransLoc3D、LoGG3D-Net、MinkLoc3Dv2、ForestLPR）。

**📈 对比分析**

与所有基线相比，TreeLoc 在 Recall@1、F1、AUC 及 6-DoF Recall@50cm（TE ≤0.5m、RE ≤5°）上均显著优于对手，定位误差可达厘米级，处理速度低于 50 ms，且在不同季节、传感器与时间差异下保持高精度与鲁棒性。

**⚠️ 局限性**

局限在于对树木稀疏或无树的开放区域性能下降，且高度信息仅通过基点估计，未来可考虑加入 BEV 轮廓或其他几何原语以提升低密度环境下的定位。

---

## 111. Hard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization

**arXiv ID:** 2602.01090 | [PDF](https://arxiv.org/pdf/2602.01090v1)

**作者:** Yang Liu `[一作]` (Academy of Mathematics and Systems Science, Chinese Academy of Sciences), Xiaoqing Wang `[通讯]` (Alibaba Group)

**通讯引用:** 4263 | [OpenAlex ID](https://openalex.org/A5100452947)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 FALCON 框架，利用大型语言模型（LLM）在组合优化中实现 100% 的可行性保证，并保持优良的解质量。

**💡 创新点**

创新点包括三层可行性保障：语法约束解码、语义可行性修复层和自适应 Best‑of‑N 采样；以及基于目标差距加权的 BOPO 训练策略，显著提升学习效率和解质量。

**🔧 技术方法**

核心技术包括基于上下文无关文法的约束解码、问题专属可行性修复算子、贝叶斯置信度的自适应采样策略，以及 BOPO 的首尾锚定偏好优化算法。

**📊 数据集**

使用七个经典 NP‑Hard 组合优化问题的数据集，涵盖 TSP、CVRP、OP、MIS、MVC、PFSP 与 JSSP，数据来源为公开基准实例生成器。

**📈 对比分析**

与通用 LLM、推理增强 LLM、LLM‑based 优化方法以及神经 CO 求解器对比，FALCON 在所有问题上都实现 100% 可行性，且在大多数任务上优于或持平于最先进模型，且自适应采样减少约 30‑55% 的计算量。

**⚠️ 局限性**

局限性在于：可行性修复层需要针对每个问题设计专属算子，可能不易迁移到新问题；语法约束可能导致生成空间受限；BOPO 的收敛分析假设梯度方差有限，实际训练中仍需调参。

---

## 112. How well can VLMs rate audio descriptions: A multi-dimensional quantitative assessment framework

**arXiv ID:** 2602.01390 | [PDF](https://arxiv.org/pdf/2602.01390v1)

**作者:** Lana Do `[一作]` (Northeastern University), Ilmi Yoon `[通讯]` (Northeastern University)

**通讯引用:** 372 | [OpenAlex ID](https://openalex.org/A5076251624)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

开发了面向完整视频的多维音频描述质量评估框架，并将其与Item Response Theory相结合，构建评估工作流，比较人类与VLM评估者的表现。

**💡 创新点**

将内容维度与先前忽视的排版维度（内插/扩展语音、时序）统一纳入评估；利用IRT对评估者与项目难度进行联合建模，提出混合人机评估系统。

**🔧 技术方法**

采用专业指南（DCMP、NCAM）构建维度，使用VLM（如GPT‑4、Gemini等）生成评估者；采用Item Response Theory（Rasch/PCM）进行统计建模；通过多方随机化接口进行收集。

**📊 数据集**

10部YouTube全长视频（包含娱乐、如何/风格、教育三类）与4种描述版本（1人类志愿者+3种VLM）共40条音频描述；专家三人评定为真值。

**📈 对比分析**

对比专家真值与人类与VLM的评级，使用IRT估算评估者能力和项目难度；结果显示VLM在六维度上与专家更接近，解释质量不足；人类在部分维度表现相当或更好。

**⚠️ 局限性**

样本规模小（10视频40描述，4人类+8VLM），IRT适用性受限，维度可靠性待验证，VLM解释不充分，无法直接替代人类审阅。

---

## 113. DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning

**arXiv ID:** 2602.00983 | [PDF](https://arxiv.org/pdf/2602.00983v1)

**作者:** Batuhan K. Karaman `[一作]` (Cornell University), Ruida Zhou `[通讯]` (Amazon AGI)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 DISPO 算法，通过对正确/错误响应的 IS 权重分别设定上下界剪裁，实现四个可控的策略更新范式；

**💡 创新点**

创新点在于解耦正负样本的梯度放大/抑制，从而平衡探索与蒸馏，消除 CISPO 与 PPO 方法的训练不稳定问题；

**🔧 技术方法**

采用离线 REINFORCE、组相对优势估计、token 级归一化、动态采样和 overlong 惩罚，并引入四个独立的剪裁参数；

**📊 数据集**

使用 GSM8K、Math、Mathematics 作为训练集，在 AIME'24/25、AMC'23、MATH-500、Minerva 等数学推理基准上进行评估；

**📈 对比分析**

与 DAPO（PPO式）和 CISPO（REINFORCE式）对比，DISPO 在 Qwen3-14B 上 AIME'24 达到 61.04%（相较 DAPO 50.21% 提升 10.83pp），在其他基准和不同模型规模上均保持显著性能提升；

**⚠️ 局限性**

仍需人工调参四个剪裁阈值，过度探索或过度蒸馏可能导致后期性能衰退，对长文本生成的泛化仍有待提升。

---

## 114. Dynamic Expert Sharing: Decoupling Memory from Parallelism in Mixture-of-Experts Diffusion LLMs

**arXiv ID:** 2602.00879 | [PDF](https://arxiv.org/pdf/2602.00879v1)

**作者:** Hao Mark Chen `[一作]`, Hongxiang Fan `[通讯]` (Imperial College London)

**通讯引用:** 788 | [OpenAlex ID](https://openalex.org/A5057043409)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了在并行解码的 Diffusion LLM 中 Mixture‑of‑Experts 的专家爆炸问题，并提出了动态专家共享（DES）方法，利用序列级别的共轭核心集合显著减少专家激活量。

**💡 创新点**

创新点在于将专家选择从 token 层面迁移到序列层面，通过构造共享核心集合（coreset）以及 Saliency‑Aware Voting 投票机制，实现跨 token 的专家重用，显著降低内存流量。

**🔧 技术方法**

采用两种核心集合选择策略：Intra‑Sequence Sharing (DES‑Seq) 与 Saliency‑Aware Voting (DES‑Vote)，并实现了自定义融合 GPU 核以降低内核调用和内存瓶颈。

**📊 数据集**

实验使用 HumanEval、MBPP、GSM8K、MATH500 等长文本生成与推理基准数据集。

**📈 对比分析**

与现有基于 token 的专家跳过方法（NAEE、MC‑MoE）对比，DES‑Vote 在保持 99% 相对准确率的前提下将独立专家激活量减少 55%，MoE 层延迟下降 38%，整体推理时间提升 8–14%，验证了方法的有效性。

**⚠️ 局限性**

局限性包括对极大并行块尺寸的鲁棒性仍有限；核心集合存储与管理带来额外开销；且未解决跨层专家重复与动态分配的更细粒度优化问题。

---

## 115. ReACT-TTC: Capacity-Aware Top Trading Cycles for Post-Choice Reassignment in Shared CPS

**arXiv ID:** 2602.00859 | [PDF](https://arxiv.org/pdf/2602.00859v1)

**作者:** Anurag Satpathy `[一作]` (Missouri University of Science and Technology), Sajal K. Das `[通讯]` (Missouri University of Science and Technology)

**通讯引用:** 32295 | [OpenAlex ID](https://openalex.org/A5050881965)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一个基于Top‑Trading‑Cycle的后偏差重分配框架，能够在共享资源的 CPS 系统中处理用户非合规行为，兼容容量约束和未分配资源。

**💡 创新点**

创新点包括：①将 TTC 扩展为容量感知的多对一版本；②引入虚拟节点处理未占用容量；③通过最小满意度损失排序解决重叠循环；④结合前景理论满意度模型实现更真实的偏好评估。

**🔧 技术方法**

采用了图论与循环检测、贪心重排、前景理论满意度函数、以及与基准方法的线性/整数规划比较。

**📊 数据集**

使用了北京真实电动汽车充电网络数据集，包含车辆与充电站坐标、行驶距离/时间、能耗等信息。

**📈 对比分析**

通过仿真与 V2VDisCS、DAA、SMEVCA（PCG、PCD）等基准比较，ReACT‑TTC 在非合规用户比例与排队长度变化下，累计满意度和 PT 满意度均至少提升 43%，且计算开销低于基准。

**⚠️ 局限性**

局限性包括：循环排队顺序对满意度影响大，难以获得全局最优；循环检测目前为单线程，扩展性受限；偏好模型仍为随机生成，缺乏基于真实数据的学习；跨域泛化仍需进一步验证。

---

## 116. Reliability-Aware Determinantal Point Processes for Robust Informative Data Selection in Large Language Models

**arXiv ID:** 2602.00885 | [PDF](https://arxiv.org/pdf/2602.00885v1)

**作者:** Ahmad Sarlak `[一作]` (Clemson University), Abolfazl Razi `[通讯]` (Clemson University)

**通讯引用:** 2278 | [OpenAlex ID](https://openalex.org/A5011987346)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出一种可靠性感知的确定性点过程（ProbDPP）来解决大语言模型在存在数据丢失或通信失败时的多源信息选择问题。

**💡 创新点**

创新点在于发现传统基于 log‑det 的 DPP 在 Bernoulli 随机缺失时会退化为负无穷，并通过最小正则化恢复目标可行性，将多样性与可靠性分离为几何多样性与可靠性奖励两项。

**🔧 技术方法**

使用技术包括正则化 Determinantal Point Process、组合半波段 UCB 学习算法、KL‑UCB 自信上界估计、以及对齐优化的贪心/离散化求解。

**📊 数据集**

实验数据集包括 MeetingBank（长上下文问答）和 HotpotQA（多源提问与答案）两大 benchmark，另外在 120 场景下对 K=10、3、5 的多源设置进行评估。

**📈 对比分析**

与随机选择、LLMLingua2/小型、纯 k‑DPP 等基线比较，ProbDPP 在 Token‑F1、ROUGE‑L、BERTScore 与 Exact Match 上均实现显著提升，最高可达 36.9% 的 BERTScore 与 13.5% 的 Token‑F1。

**⚠️ 局限性**

局限性包括假设独立丢失、仅支持二进制可用性反馈、对 ε 参数的固定选择、以及缺乏对相关或对抗性失败模式的处理。

---

## 117. Unveiling the Cognitive Compass: Theory-of-Mind-Guided Multimodal Emotion Reasoning

**arXiv ID:** 2602.00971 | [PDF](https://arxiv.org/pdf/2602.00971v1)

**作者:** Meng Luo `[一作]` (National University of Singapore), Wynne Hsu `[通讯]` (National University of Singapore)

**通讯引用:** 16588 | [OpenAlex ID](https://openalex.org/A5051209739)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一个基于认知层级的情感理解基准 HitEmotion，并开发了以理论心智（ToM）为导向的强化学习优化方法 TMPO，用以提升多模态大型语言模型（MLLM）的情感推理能力。

**💡 创新点**

创新点包括：①构建三层认知层级（情感感知、情感理解、情感认知）细粒度基准；②设计 ToM 结构化提示与过程级监督的强化学习框架；③将中间心理状态作为奖励与监督，突破传统链式思考的表面化局限。

**🔧 技术方法**

使用的技术主要是：多模态大型语言模型（如 Qwen2.5-Omni-7B）进行结构化思考提示；对生成的思考链进行多维奖励评估（结构、内容、过程、一致性）；基于 Group-wise Reward Policy Optimization (GRPO) 的强化学习更新；以及传统的监督微调（SFT）。

**📊 数据集**

采用了24个公开多模态情感数据集，涵盖情感识别、情感分析、幽默、讽刺、因果推理等多方面，覆盖文本、图像、视频、音频四种模态。

**📈 对比分析**

与 17 种公开（0.5B~38B）和闭源（GPT‑4、Gemini‑2.5）模型对比，TMPO 在 24 项任务中实现了显著提升，尤其在高认知层级任务中多数场景超越闭源基准；ToM 提示对大模型提升尤为明显。

**⚠️ 局限性**

局限性在于：①基准仍以现有公开数据为主，缺乏更广泛的跨文化、跨语言场景；②对底层感知能力依赖模型原始多模态感知质量，低层任务表现仍受限；③强化学习过程对计算资源要求高，且奖励设计需人工调参。

---

## 118. Green-VLA: Staged Vision-Language-Action Model for Generalist Robots

**arXiv ID:** 2602.00919 | [PDF](https://arxiv.org/pdf/2602.00919v1)

**作者:** I. Apanasevich `[一作]` (Sber Robotics Center), A. Postnikov `[通讯]` (Sber Robotics Center)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `40105733-5154-44cd-8090-a8cab9e64b07` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Green‑VLA 这一分阶段 Vision–Language–Action 框架，实现从大规模 Web 数据到多体机器人数据再到特定身体适配与强化学习对齐的完整训练流水线，最终在 Green 人形机器人上实现零样本跨身体能力与高效长周期任务执行。

**💡 创新点**

核心创新包括：1）统一动作空间与嵌入式身体/控制类型提示，实现多身体正向迁移与正则化；2）多级数据质量与时间对齐管道（抖动、清晰度、多样性评估及光流速度归一）；3）结合流匹配的动作专家与基于联合预测的目标引导模块；4）分阶段训练（L0→L1→R0→R1→R2）与动态样本加权的策略采样；5）强化学习细调以突破行为克隆瓶颈，提升长周期成功率与恢复能力。

**🔧 技术方法**

技术手段包括：多模态 Vision‑Language 模型（PaliGemma 3B）、Transformer‑based flow‑matching 动作专家、基于 SDPA 的高效注意力、动态身体提示、光流基时间对齐、联合预测模块（JPM）与伪逆指导、强化学习（Implicit Q‑Learning、Trajectory Optimization、Source Distribution 调整）以及 OOD 检测与修正。

**📊 数据集**

使用的数据集包括：24M 网络级多模态样本（RefSpatial、AgibotWorld、RoboPoint 等）、3,000 小时多身体机器人演示（AgibotWorld_twofinger、DROID、Galaxea‑Open‑World‑Dataset、Action_net、Aloha 等），以及自收集的 Green Humanoid 与 ALOHA any_pick，全部通过质量过滤、对齐与扩增后构成统一训练集。

**📈 对比分析**

与现有 VLA/机器人基础模型（π_0、GR00T N1、AgiBot GO‑1、WALL‑OSS、OpenVLA、RT‑1X 等）在标准 Benchmarks（Table‑Cleaning、Pick‑and‑Place、Sim­pler、CALVIN、BRIDGE 等）对比，Green‑VLA 在无额外调优的 R0 阶段即已超过多数基线，R1 精调后提升显著，R2 RL 对齐后在长周期任务与 OOD 场景中达到或逼近最先进水平，且在多身体上实现零样本迁移。

**⚠️ 局限性**

限制包括：1）对重映射和速度归一的假设在极端不同硬件上可能失效；2）当前仅支持已预设的统一动作槽，未能处理极度不同的机器人（如全机械臂或柔性抓手）；3）RL 对齐仍依赖离线数据与稀疏奖励，难以完全覆盖所有复杂任务；4）多模态模型在低光或遮挡环境下的鲁棒性待提升；5）系统在超长任务序列中的累积漂移与安全性仍需进一步研究。

---

## 119. Semantically Aware UAV Landing Site Assessment from Remote Sensing Imagery via Multimodal Large Language Models

**arXiv ID:** 2602.01163 | [PDF](https://arxiv.org/pdf/2602.01163v1)

**作者:** Chunliang Hua `[一作]` (Southeast University), Xiao Hu `[通讯]` (International Digital Economy Academy)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种基于遥感图像与多模态大型语言模型的UAV紧急降落地点评估框架。

**💡 创新点**

创新点在于将语义风险识别与多模态推理结合，采用粗到细的三阶段管道，并生成可解释的自然语言理由。

**🔧 技术方法**

使用DeepLabV3+进行语义分割，Vision‑Language模型（Qwen、Doubao、GPT‑4.1）进行视觉验证和上下文推理，并融合POI、动态环境与法规约束。

**📊 数据集**

数据集包括ISPRS Potsdam高分辨率航空影像、Nanjing低分辨率卫星影像以及自行构建的ELSS基准数据集（500个专家标注样本）。

**📈 对比分析**

与纯几何基线相比，框架在ELSS基准上实现了显著的风险识别准确率提升，最高通过率从约20%提升到超过80%，并在排名任务中获得约68%的正确率。

**⚠️ 局限性**

主要局限在于云端MLLM推理时延、对卫星影像质量的依赖以及对实时动态信息融合的不足。

---

## 120. LLM-Driven Ontology Construction for Enterprise Knowledge Graphs

**arXiv ID:** 2602.01276 | [PDF](https://arxiv.org/pdf/2602.01276v1)

**作者:** Abdulsobur Oyewale `[一作]` (Liber AI Research), Tommaso Soru `[通讯]` (Liber AI Research)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

开发了一个基于大模型的管线 OntoEKG，用于从企业文本自动构建域知识图谱的本体。

**💡 创新点**

将本体构建拆分为两阶段（类属性提取与层级推理）并通过 Pydantic 强制 JSON 输出，首次实现端到端从无结构文本到 RDF 本体的完整流程。

**🔧 技术方法**

使用 Google Gemini 3 Flash 进行元素提取，Anthropic Claude 4.5 Opus 进行层级推理，利用 rdflib 序列化 RDF，并配合链式思维提示和 Pydantic 约束。

**📊 数据集**

自建了包含数据、金融、物流三大领域企业政策文本的三用例数据集，用于评估模型效果。

**📈 对比分析**

采用精确匹配和基于嵌入的模糊匹配两种评估方式；模糊匹配下数据领域 F1=0.724，金融 0.121，物流 0.431，显示在某些领域仍有提升空间。

**⚠️ 局限性**

局限包括难以自动确定模型范围、易生成个体而非类、层级推理时方向混乱及子集定义宽松，导致逻辑一致性受限。

---

## 121. Domain-Adaptive and Scalable Dense Retrieval for Content-Based Recommendation

**arXiv ID:** 2602.00899 | [PDF](https://arxiv.org/pdf/2602.00899v1)

**作者:** Mritunjay Pandey `[一作]` `[通讯]` (Aditya Birla Group), Mritunjay Pandey (Aditya Birla Group)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `a2602d71-93ab-4bad-974b-672788df8193` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建并部署了一个基于域适配的双塔稠密检索系统，用用户评论对时尚商品进行语义检索。

**💡 创新点**

将用户评论作为查询代理，利用对比学习与多负样本排名损失进行领域微调，并在生产环境中结合ONNX INT8量化和FAISS HNSW实现低延迟、低存储的推荐系统。

**🔧 技术方法**

MPNet双塔Bi‑Encoder、Multiple Negatives Ranking Loss、Post‑training INT8量化、ONNX Runtime、FAISS HNSW索引、Mean pooling + L2归一化。

**📊 数据集**

Amazon Reviews 2023 Fashion 子集（约2.5M互动，50k训练对，826k商品）。

**📈 对比分析**

与BM25和零训练MPNet对比，Recall@10从0.26提升到0.66（+154%），INT8模型单请求6.1 ms，QPS 163，模型大小从438 MB降至107 MB。

**⚠️ 局限性**

语义漂移导致实体混淆和细粒度属性缺失，未覆盖品牌、型号等精确匹配需求，需要混合检索或后续重排序来缓解。

---

## 122. Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning

**arXiv ID:** 2602.01335 | [PDF](https://arxiv.org/pdf/2602.01335v1)

**作者:** Yu Xu `[一作]` (University of Chinese Academy of Sciences), Fan Tang `[通讯]` (University of Chinese Academy of Sciences)

**通讯引用:** 19478 | [OpenAlex ID](https://openalex.org/A5066366116)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `ba576bd1-e51d-44e8-8077-fc943b333c93` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出视觉隐喻转移（VMT）任务，并构建了基于概念融合理论的多代理框架，完成从参考图像抽取“创意本质”并迁移到目标对象的全过程。

**💡 创新点**

创新点在于引入Schema Grammar对抽象逻辑进行结构化表征，并通过分层诊断代理实现闭环错误纠正，从而突破传统模型仅关注像素级对齐的局限。

**🔧 技术方法**

核心技术包括多代理协同系统（感知代理、转移代理、生成代理、诊断代理）、Conceptual Blending Theory的实现、Schema Grammar以及高保真视觉生成模型（如扩散式或GAN）。

**📊 数据集**

实验使用公开的视觉隐喻图像数据集（如VPM、VSO等），对比了多种现有基线模型。

**📈 对比分析**

通过人类评估指标（隐喻一致性、类比适宜性、视觉创意）与SOTA基线对比，本文方法在所有指标上均显著优于对手，显示出更高的抽象逻辑迁移效果。

**⚠️ 局限性**

主要局限包括：对极其复杂或高层抽象隐喻的迁移仍有难度，依赖人工标注的隐喻数据集规模有限，闭环诊断代理的误差纠正能力尚需进一步提升。

---

## 123. SFMP: Fine-Grained, Hardware-Friendly and Search-Free Mixed-Precision Quantization for Large Language Models

**arXiv ID:** 2602.01027 | [PDF](https://arxiv.org/pdf/2602.01027v1)

**作者:** Xin Nie `[一作]` (Nankai University), Guiling Sun `[通讯]` (Nankai University)

**通讯引用:** 891 | [OpenAlex ID](https://openalex.org/A5101701886)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

针对大规模语言模型，提出一种无需搜索、硬件友好的分块混合精度量化框架（SFMP），通过分数位宽、行列重排和统一一比特LUT GEMM实现高效量化与推理。

**💡 创新点**

核心创新在于将整数位宽扩展为分数值，将精度分配从离散优化转为连续阈值分配；采用块级混合精度保持硬件友好；行列重排聚焦显著权重；统一一比特LUT GEMM消除量化解包，整体实现搜索免费、速度提升。

**🔧 技术方法**

使用全局 Fisher 信息矩阵评估权重显著性；分数位宽与阈值分配；行列重排与块划分；一比特 LUT‑based GEMM 的统一实现；对模型进行量化后在 CUDA GPU 上实现。

**📊 数据集**

在 LLaMA3.1 8B/70B、Qwen3 8B/14B/32B 上进行实验；校准数据集为 C4 1k 样本；评估数据集包括 C4、WikiText‑2、LM‑Eval Harness（ARC‑Easy/Challenge、PIQA、HellaSwag、BoolQ、WinoGrande）以及 MMLU、GSM‑8K。

**📈 对比分析**

与固定精度方法（GPTQ、AWQ）、组级混合精度（SliM‑LLM）、任意尺寸方法（BitStack、AMQ）对比。实验显示，SFMP 在相同内存预算下在 perplexity、zero‑shot 及 5‑shot 任务上均优于或接近其余方法；同时在推理吞吐量上显著高于 GPTQ 等，低位宽时吞吐反而提升。

**⚠️ 局限性**

局限包括：需要预先估计 Fisher 对角值（需校准数据集）；仅支持两种整数位宽（可能限制极低位宽的灵活性）；块划分与重排虽硬件友好，但对极细粒度精度调优的提升有限；在极大模型上行列重排的开销虽小，但仍占一部分时间。

---

## 124. Continuous-Utility Direct Preference Optimization

**arXiv ID:** 2602.00931 | [PDF](https://arxiv.org/pdf/2602.00931v1)

**作者:** Muhammad Ahmed Mohsin `[一作]` (Stanford University), Emily Fox `[通讯]` (Stanford University)

**通讯引用:** 47402 | [OpenAlex ID](https://openalex.org/A5090739892)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出CU-DPO框架，用连续效用评估代替二进制标签，通过两阶段策略选择与执行改进训练，提升LLM在数学推理任务中的策略匹配与执行质量。

**💡 创新点**

创新点包括：①连续效用评分与Bradley‑Terry模型的结合，实现细粒度偏好表示；②最佳vs‑所有与margin stratified对比，显著降低样本复杂度（Θ(K log K)）；③分阶段训练消除策略与执行质量冲突，提升收敛速度和最终性能。

**🔧 技术方法**

使用技术包括：直接偏好优化（DPO）、LLM判别器评分、策略化prompt、迭代改进算子、熵正则化策略学习、样本复杂度理论分析。

**📊 数据集**

数据集涵盖：DeepMath、HARDMath2、ProofNet（在分布内）以及GSM8K、MATH‑500、U‑MATH（在分布外）进行评估。

**📈 对比分析**

与基准模型、二进制DPO、prompt‑only等进行对比；在ID数据集Pass@1提升约6–7个百分点，OOD准确率提升14–23个百分点；样本效率上CU‑DPO比二进制DPO高出约2–3倍；在训练步数和样本比例上表现更优。

**⚠️ 局限性**

局限性包括：策略集需人工设计，难以覆盖所有领域；对极难或需要全局跳跃的推理问题改进有限；实现依赖大型LLM与计算资源；验证范围主要限于数学推理，尚未在其他复杂推理任务中充分验证。

---

## 125. Improving Flow Matching by Aligning Flow Divergence

**arXiv ID:** 2602.00869 | [PDF](https://arxiv.org/pdf/2602.00869v1)

**作者:** Yuhao Huang `[一作]` (University of Utah), Bao Wang `[通讯]` (University of Utah)

**通讯引用:** 2591 | [OpenAlex ID](https://openalex.org/A5019915753)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `40105733-5154-44cd-8090-a8cab9e64b07` `a8e75ba4-7a2d-4153-b003-06c94533add0` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种新的训练目标——流与散度匹配（FDM），通过对学习的向量场与真实向量场的散度差进行约束，提升流匹配模型的概率路径精度，

**💡 创新点**

创新点在于先用偏微分方程推导出学习概率路径误差的上界，发现散度误差与总变差误差同等重要，然后提出可计算的条件散度损失并与原始流匹配损失加权，形成FDM目标，

**🔧 技术方法**

技术核心包括流匹配理论、偏微分方程分析、条件散度估计、Hutchinson trace 近似、停止梯度技术，以及在不同任务中的深度神经网络实现，

**📊 数据集**

实验数据集涵盖合成高斯混合、二维棋盘、CIFAR‑10、DNA启动子序列（人类启动子数据库）、Lorenz 与 FitzHugh‑Nagumo 动力学轨迹、KTH 与 BAIR 视频，

**📈 对比分析**

与原始流匹配（FM）及部分扩散模型比较时，FDM 在总变差、对数似然、FID、FVD、PSNR 等指标上均有显著提升，尤其在高维轨迹与视频生成任务中表现更佳，

**⚠️ 局限性**

局限性包括：仍以总变差为上界，未直接控制 KL 散度；条件散度估计需要额外梯度和样本；对高阶散度或更复杂动态系统的理论与实证仍待完善。

---

## 126. Probing RLVR training instability through the lens of objective-level hacking

**arXiv ID:** 2602.01103 | [PDF](https://arxiv.org/pdf/2602.01103v1)

**作者:** Yiming Dong `[一作]` (Peking University), Zheng Wang `[通讯]` (Alibaba Cloud Computing)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `afceb026-1760-41ae-8d86-010831a37d97` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文研究了在混合专家（MoE）模型上进行可验证奖励（RLVR）训练时出现的训练-推理不一致（TIS）异常增长的根本机制，并提出了目标层级破解（objective‑level hacking）这一新的分析视角。

**💡 创新点**

创新点在于：①将TIS异常增长归因于令标记级信用失配产生的目标层级伪信号；②提出统一的公式框架描述不同源的目标层级破解；③通过理论推导与实验验证证明目标层级破解是导致TIS异常的主因，并揭示了正反馈循环。

**🔧 技术方法**

技术手段包括：GRPO、GSPO等RLVR算法；截断重要性采样（TIS）校正；对标记级裁剪、注入权重失配的实验；统计分析权重失配与TIS增长的相关性；使用标准偏差衡量训练-推理不一致；以及对标记概率分布的聚类与重要性权重演化进行可视化。

**📊 数据集**

实验数据集为：训练集 DAPO‑Math‑17k，验证集 AIME24；模型为 30B MoE Qwen3‑30B‑A3B，使用 vLLM 推理后端和 Megatron 训练后端。

**📈 对比分析**

对比方法包括：vanilla GRPO、加 TIS 的 GRPO、token‑level 裁剪、seq‑level 裁剪（GSPO）以及主动注入权重失配的实验。结果显示：TIS 能显著减缓 TIS 增长速率并提升 token 熵与验证准确率，但无法完全消除；token‑level 裁剪反而加速了 TIS 增长；主动权重失配导致 TIS 明显爆发并导致模型性能不可逆下降；seq‑level 裁剪在相同设置下保持较低的 TIS。

**⚠️ 局限性**

局限性包括：仅在单一 30B MoE 模型上验证；实验硬件为 4 节点 8 A100 GPU，未探索更大规模或其他硬件；算法范围受限于 GRPO/GSPO/TIS，未涵盖所有可能的 RLVR 变体；理论模型假设了理想化的梯度与采样，实际中可能受更多系统因素影响；并且仅针对数学/推理任务，结果对其他领域的普适性需进一步验证。

---

## 127. Privocracy: Online Democracy through Private Voting

**arXiv ID:** 2602.01341 | [PDF](https://arxiv.org/pdf/2602.01341v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

---

## 128. Seeing, Hearing, and Knowing Together: Multimodal Strategies in Deepfake Videos Detection

**arXiv ID:** 2602.01284 | [PDF](https://arxiv.org/pdf/2602.01284v1)

**作者:** Chen Chen `[一作]` (Nanyang Technological University), Dion Hoe-Lian Goh `[通讯]` (Nanyang Technological University)

**通讯引用:** 6251 | [OpenAlex ID](https://openalex.org/A5051793131)

**关键词:** `a154b176-e466-40fc-8ae0-e5cd17677106` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

对195名21-40岁的年轻成年人进行实验，评估他们对真实与深度伪造视频的判别准确率、置信度与校准，并记录其使用的视觉、音频和知识三类检测策略及其组合。

**💡 创新点**

首次量化人类多模态检测策略与其组合对准确率和校准的影响，并通过关联规则挖掘揭示特定线索组合的网络效应，系统性比较真实与伪造视频在策略使用上的异同。

**🔧 技术方法**

采用统计分析（t检验、ANOVA）、期望校准误差（ECE）、关联规则挖掘和网络可视化等方法；实验平台为在线问卷收集判别数据。

**📊 数据集**

使用20段短视频（10段真实、10段深度伪造），每段时长不超过60秒，来源于公开平台（如YouTube），涵盖政治、体育等主题。

**📈 对比分析**

通过准确率、置信度和ECE三指标比较。结果显示整体准确率0.76，真实视频0.79高于伪造视频0.72；伪造视频的ECE更高，表明其判断更不校准；在真实视频上多模态策略显著提升准确率和校准，而在伪造视频上则无显著差异。

**⚠️ 局限性**

局限性包括：样本仅为年轻成人，难以推广至不同年龄群；视频样本数量有限，未覆盖所有深度伪造技术；线索选择为预设检查表，可能缺乏自然性；未考虑更先进的深度伪造方法导致的检测挑战。

---

## 129. PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length

**arXiv ID:** 2602.01274 | [PDF](https://arxiv.org/pdf/2602.01274v1)

**作者:** Situo Zhang `[一作]` (Shanghai Jiao Tong University), Kai Yu `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 20997 | [OpenAlex ID](https://openalex.org/A5100758006)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种动态控制草稿长度的Speculative Decoding框架，利用可训练的块级预验证层在推理过程中根据上下文信息停止草稿生成。

**💡 创新点**

创新点是引入块级预验证层结合位置编码与阈值增长因子，在每一步动态判断草稿接受率，从而实现自适应窗口大小。

**🔧 技术方法**

使用了预验证Transformer层、位置编码、阈值增长策略、交叉熵训练以及与Ouroboros等方法的集成。

**📊 数据集**

在HumanEval、MBPP、CNN/DailyMail、GSM8K等数据集上进行评测，并使用CodeAlpaca数据集进行训练。

**📈 对比分析**

与传统自回归、固定窗口Speculative Decoding、Lookahead、Assist、REST、AdaEDL、SpecDec++等方法对比，最高可达3.09×的速度提升，平均速度提升约2.3×。

**⚠️ 局限性**

局限在于对不同任务仍需手工调优阈值和块大小，且在GPU资源受限时预验证开销仍较大，对长文本的预验证成本未得到充分降低。

---

## 130. A-MapReduce: Executing Wide Search via Agentic MapReduce

**arXiv ID:** 2602.01331 | [PDF](https://arxiv.org/pdf/2602.01331v1)

**作者:** Mingju Chen `[一作]` (Beihang University), Shiji Zhou `[通讯]` (Beihang University)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种基于MapReduce的多智能体框架A-MapReduce，用于高效执行大规模宽域搜索任务；通过任务矩阵、检索模板和批处理实现并行检索与结果聚合，并利用经验记忆驱动决策演化；

**💡 创新点**

①将宽搜索重新建模为水平结构化检索，显式化MapReduce执行计划；②引入经验记忆与查询条件经验先验，使决策可随任务进化；③设计可自适应的批处理与任务分解策略，实现并行执行与成本优化；

**🔧 技术方法**

多智能体协作、LLM推理、MapReduce抽象、经验记忆与先验驱动、嵌入相似检索、批处理与结果聚合、强化/进化式优化；

**📊 数据集**

WideSearch、DeepWideSearch、以及从xBench‑DeepSearch、WebWalkerQA、TaskCraft 提取的 Agentic‑Wide 子集；

**📈 对比分析**

与单代理、端到端系统、开源多智能体框架等进行对比，评估指标包括 Item F1、Row F1、Success Rate、CE Acc、Column F1 等。A‑MapReduce 在所有宽域基准上均取得最高性能，Item F1/Row F1/Success Rate 均提升 5–17 % 以上；成本效益最佳，运行时间比对等基线降低约 45.8 %；

**⚠️ 局限性**

仍受LLM推理质量与偏见影响；经验记忆规模与更新机制可能成为瓶颈；对批处理参数与提示设计敏感；适用于宽域搜索，对深度递归推理的优势有限；

---

## 131. Forest-Guided Semantic Transport for Label-Supervised Manifold Alignment

**arXiv ID:** 2602.00974 | [PDF](https://arxiv.org/pdf/2602.00974v1)

**作者:** Adrien Aumon `[一作]` (Universite de Montreal), Jake S. Rhodes `[通讯]` (Brigham Young University)

**通讯引用:** 192 | [OpenAlex ID](https://openalex.org/A5041155337)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出 FoSTA，基于森林引导的标签监督流形对齐框架，利用任务相关的 RF‑GAP 相似度构建域内几何，并通过分层语义传输实现跨域对应；

**💡 创新点**

创新点在于将欧氏几何替换为半监督标签信息化的森林亲和度，构建无监督的层级最优传输求解器，并通过对应传播生成跨域相似度，显著提升了对应恢复与标签迁移；

**🔧 技术方法**

核心技术包括 Random Forest 亲和度 (RF‑GAP)、半监督标签扩展、分层递归 OT (HiRef)、语义投影与归一化、Landmark PHATE 嵌入；

**📊 数据集**

实验使用 15 份 UCI 监督学习数据集（人工域拆分）和单细胞 RNA‑seq 肺组织数据，模拟噪声、丢失、批次效应等多种扰动；

**📈 对比分析**

与 KEMA、MALI、Pamona、scANVI、scVI、Harmony 等方法对比，FoSTA 在标签迁移准确率、FOSCTTM 以及单细胞批次校正的生物保留度上均优于或接近最佳，且计算复杂度近线性；

**⚠️ 局限性**

局限在于需要域间共享完整标签集合，且对随机森林模型质量敏感，难以处理标签空间不完全重叠或极度稀疏标签情况。

---

## 132. Exploration of Radar-based Obstacle Visualizations to Support Safety and Presence in Camera-Free Outdoor VR

**arXiv ID:** 2602.00973 | [PDF](https://arxiv.org/pdf/2602.00973v1)

**作者:** Avinash Ajit Nargund `[一作]` (University of California, Santa Barbara), Misha Sra `[通讯]` (University of California, Santa Barbara)

**通讯引用:** 1778 | [OpenAlex ID](https://openalex.org/A5029380651)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `e0540dec-d77f-42db-94ae-d039248f6393` `9cc9baba-5356-466d-81ff-d80028d90279` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

验证并评估了一套基于毫米波雷达与 GPS‑IMU 的户外 VR 系统 WaveWalkerClone，并对三种障碍物可视化方法（diegetic alien avatar、non‑diegetic human avatar、抽象点云）在安全性、沉浸感和用户偏好方面进行了系统比较。

**💡 创新点**

创新点：①将毫米波雷达与 GPS‑IMU 融合，实现无摄像头的户外定位与障碍检测；②首次在户外 VR 场景中对三种可视化策略进行对比实验；③提出可定制/混合可视化的设计思路，兼顾隐私保护与沉浸体验。

**🔧 技术方法**

技术手段：TI IWR6843AOP mmWave 雷达、GPS‑IMU、NVIDIA Jetson Nano 与错误状态卡尔曼滤波、Unity+OpenXR 开发、Meta Quest 3 HMD、雷达点云聚类与轨迹跟踪、Avatar 动画与姿态融合。

**📊 数据集**

数据集：现场收集的实时雷达点云、GPS 轨迹与用户步行数据（校园四合院与异星主题环境），以及两轮用户研究（n=9 与 n=18）的问卷与行为测量。

**📈 对比分析**

比较方法与性能：通过两项用户研究采用 IPQ、NASA‑TLX、CRIQ、CAQ、SSQ 等量表，并用重复测量 ANOVA/Friedman 检验。结果显示三种方案均支持安全；点云在动态障碍及时检测上更优；diegetic avatar 在用户偏好上最高；总体工作负荷差异不显著但呈中等效应；系统累计误差约1.6 m，更新间隔0.05 s，检测成功率>96%。

**⚠️ 局限性**

局限性：①仅在校园四合院等相对平坦、无车辆环境测试，缺乏道路、宠物、崎岖地形等复杂情境；②雷达视角有限，易产生虚假轨迹与漏检；③未系统评估头部运动、延迟对检测的影响；④缺乏音景与互动内容，影响沉浸度；⑤样本量有限，需更大规模验证。

---

## 133. Single-Edge Node Injection Threats to GNN-Based Security Monitoring in Industrial Graph Systems

**arXiv ID:** 2602.01113 | [PDF](https://arxiv.org/pdf/2602.01113v1)

**作者:** Wenjie Liang `[一作]` (Guangdong Finance and Trade Vocational College), You-Gan Wang `[通讯]` (Guangdong University of Finance and Economics)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `6215c339-3735-4be3-8a07-5bbb7004712d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

研究了在工业图系统中，单边节点注入攻击（SEGIA）的设计与评估；

**💡 创新点**

创新点在于提出了单边、单链的注入框架，结合邻域采样、逆向图卷积特征合成与剪枝感知 surrogate，并在相同边预算下实现至少25% 的攻击成功率提升；

**🔧 技术方法**

采用了简化图卷积（SGC）与修剪版 PrSGC surrogate、逆向图卷积特征生成、邻域采样、多跳采样、相似度正则化以及边剪枝防御技术；

**📊 数据集**

使用了8个公开图数据集，包括 ogbn-products、reddit、ogbn-arxiv、Amazon Computers、Amazon Photo、Cora、PubMed、grb-cora 等；

**📈 对比分析**

与PGD、TDGIA、G‑NIA、ATDGIA、AGIA、G2A2C、QUAGIA 等基线方法在有无防御（FLAG、GNNGuard）及不同攻击预算下进行对比，SEGIA 在单边预算下的攻击成功率提升至少25%，在未防御场景下在 Pr=1%–5% 时平均误分类率显著高于基线；

**⚠️ 局限性**

在高连通度图上单条注入边的影响被稀释，攻击效果不如低连通度工业图；此外，对动态或异构图的适应性仍需进一步研究。

---

## 134. Residual Decoding: Mitigating Hallucinations in Large Vision-Language Models via History-Aware Residual Guidance

**arXiv ID:** 2602.01047 | [PDF](https://arxiv.org/pdf/2602.01047v1)

**作者:** Xinrong Chen `[一作]` (Peking University), Ngai Wong `[通讯]` (University of Hong Kong)

**通讯引用:** 12085 | [OpenAlex ID](https://openalex.org/A5043990959)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种无训练的残差解码方法ResDec，通过利用历史logit分布在解码阶段纠正语言偏置，显著降低视觉-语言模型的hallucination；

**💡 创新点**

创新点在于发现hallucination在logit演化的U形模式中出现，并利用Jensen‑Shannon Divergence定位语义清晰阶段，构造置信度加权的历史残差并融合到当前logit，实现无额外模型、无训练的解码纠偏；

**🔧 技术方法**

核心技术包括：JSD分析历史logit分布、置信度加权聚合、残差融合到当前logit、αβ截断控制；全部在现有LVLM的单向前向推理中实现；

**📊 数据集**

使用11个hallucination与多模任务基准：POPE、CHAIR、HallusionBench、MME、MMBench、MMVP、ScienceQA、MMStar、MM‑Vet、SEEDBench2_Plus、LLaVA‑Bench；并在LLaVA‑1.5、InstructBLIP、Qwen2.5‑VL三种模型上评测；

**📈 对比分析**

与Regular解码以及VCD、ICD、DoLa、OPERA、AGLA、ONLY、MemVR、VISTA等SOTA方法对比，ResDec在hallucination指标上平均提升≈7.8%准确率、≈8.0%F1，综合多模任务提升2–12%，同时延迟仅比Greedy慢0.02×，内存与吞吐保持相近；

**⚠️ 局限性**

局限性包括：对α、β等超参数敏感；需预设历史窗口大小；对极长文本生成可能累计误差；未结合跨模态注意力微调；在更大规模LVLM上的可扩展性尚待验证。

---

## 135. Construction-Verification: A Benchmark for Applied Mathematics in Lean 4

**arXiv ID:** 2602.01291 | [PDF](https://arxiv.org/pdf/2602.01291v1)

**作者:** Bowen Yang `[一作]` (Peking University), Zaiwen Wen `[通讯]` (Peking University)

**通讯引用:** 4737 | [OpenAlex ID](https://openalex.org/A5006127137)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c` `5b4c1114-4a70-478e-9921-2514ee03850d` `79276348-11e0-48e3-84bc-7ec231d0171c` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 AMBER benchmark，针对 Lean 4 中的应用数学任务，采用“构造‑验证”模式评估模型在求解、算法设计与表示转换等方面的能力。

**💡 创新点**

创新点在于将评测焦点从单纯的存在性证明转向显式构造解决方案，强制模型先定义可执行对象后再证明其正确性；同时构造了覆盖凸分析、优化、数值线性代数和高维概率的全新测试集。

**🔧 技术方法**

利用 Lean 4 的类型系统与 Mathlib，设计了标准化的模板与结构化提示；实验中使用多种 LLM（DeepSeek‑V3.2‑Thinking、GPT‑5.1、Gemini‑3.0 Pro、Goedel Prover‑32B、Kimina Prover‑72B）和基于 Pass@k 的评估方法。

**📊 数据集**

数据集为 AMBER，包含约 2000 道题目，按难度（Easy/Hard）和领域划分；每道题目都被手工转换为 Lean 代码并通过双轮验证确保语义一致性。

**📈 对比分析**

比较方法为 Pass@k（k=16）评估，结果显示一般推理模型（如 DeepSeek‑V3.2‑Thinking、GPT‑5.1）在构造‑验证任务上的成功率高于专门的定理证明器；整体通过率低于传统纯理论基准，凸显应用数学的挑战性。

**⚠️ 局限性**

局限性主要包括：模型常因幻觉或缺乏 Mathlib 知识导致错误；专门化训练导致的“战术过拟合”使得模型忽视多阶段构造要求；当前评测仍集中在 Lean 4，尚未覆盖其它形式化系统。

---

## 136. Reducing ORBGRAND Latency via Partial Gaussian Elimination

**arXiv ID:** 2602.01174 | [PDF](https://arxiv.org/pdf/2602.01174v1)

**作者:** Li Wan `[一作]` (University of Science and Technology of China), Wenyi Zhang `[通讯]` (University of Science and Technology of China)

**通讯引用:** 8415 | [OpenAlex ID](https://openalex.org/A5100360013)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

通过在ORBGRAND中引入RMRE（最可靠误码位）与部分高斯消元（partial Gaussian elimination）过滤不必要的错误模式，从而显著降低解码延迟和猜测次数。

**💡 创新点**

创新点在于将RMRE观测与部分GE相结合，能够一次性验证具有相同RMRE的所有错误模式，切实减少猜测量并将复杂度从O(N(N‑K)^2)降至O((N‑K)M^2)。

**🔧 技术方法**

使用的技术包括RMRE定义、部分高斯消元、预存错误模式（EP）与哈希查找、并行友好的XOR运算实现以及对ORBGRAND和RS‑ORBGRAND的增强。

**📊 数据集**

主要在BCH(127,113)码（以及7,4 Hamming码示例）上进行实验验证，评估了不同噪声功率下的性能。

**📈 对比分析**

与原始ORBGRAND、RS‑ORBGRAND、BM、OSD、SGRAND等方法对比，误码率保持不变，平均猜测次数下降约40%–55%，尾延迟显著降低，整体解码复杂度下降约30%–50%。

**⚠️ 局限性**

局限在于需要预存大量EP；在高SNR情况下，部分GE的收益有限；对极端硬错误模式仍需完整搜索，且实现中对硬件资源的占用与内存需求仍需进一步优化。

---

## 137. ReLayout: Versatile and Structure-Preserving Design Layout Editing via Relation-Aware Design Reconstruction

**arXiv ID:** 2602.01046 | [PDF](https://arxiv.org/pdf/2602.01046v1)

**作者:** Jiawei Lin `[一作]` (Xi'an Jiaotong University), Jiang Bian `[通讯]` (Microsoft Research)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

实现了无需手工调整的自动化设计布局编辑模型

**💡 创新点**

提出关系图作为结构约束并引入自监督的关系感知设计重建（RADR）方法

**🔧 技术方法**

使用多模态大语言模型（Llama-3.1-8B+CLIP）配合关系图序列输入进行训练

**📊 数据集**

基于Crello v4公开设计数据集

**📈 对比分析**

与GPT-4o以及FlexDM、LaDeCo、PosterLLaVA等基线对比，表现出更高的编辑准确率、结构保留率和视觉质量

**⚠️ 局限性**

当元素数量增多时难以完全保留整体布局结构，容易出现关系违背或质量重叠等失败情况

---

## 138. EmoAra: Emotion-Preserving English Speech Transcription and Cross-Lingual Translation with Arabic Text-to-Speech

**arXiv ID:** 2602.01170 | [PDF](https://arxiv.org/pdf/2602.01170v1)

**作者:** Besher Hassan `[一作]` (Mohammed Bin Zayed University of Artificial Intelligence), Shahem Sultan `[通讯]` (Mohammed Bin Zayed University of Artificial Intelligence)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文构建了一个跨语言情感驱动的银行客服语音处理系统，能够识别情绪、转写语音、翻译并保持情感语调生成目标语言语音；

**💡 创新点**

创新点在于将情感识别、ASR、MT和TTS四大技术整合为单一端到端流程，并在翻译过程中显式保留情感信息；

**🔧 技术方法**

使用CNN进行情感识别、Whisper进行ASR、MarianMT进行英文-阿拉伯翻译、MMS‑TTS‑Ara进行阿拉伯语语音合成；

**📊 数据集**

情感识别基于RAVDESS情绪语音数据集；翻译训练使用包含6.4 MB一般语料与1万条银行领域句对的双语数据集；

**📈 对比分析**

与基线模型对比后，情感识别F1从0.53提升至0.94；翻译BLEU从23提升至56，BERTScore F1达88.7%，人工评估平均得分81%；

**⚠️ 局限性**

主要局限在于银行领域数据规模有限，导致长句翻译表现欠佳，未来需扩充语料并尝试更高级的微调方法。

---

## 139. SPOT: Spatio-Temporal Obstacle-free Trajectory Planning for UAVs in an Unknown Dynamic Environment

**arXiv ID:** 2602.01189 | [PDF](https://arxiv.org/pdf/2602.01189v1)

**作者:** Astik Srivastava `[一作]`, Madhava Krishna `[通讯]`

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了SPOT框架，实现了在未知动态环境中对四旋翼进行无地图的四维时空RRT*规划、视觉安全航道生成和轨迹优化，并加入备份规划以防死锁。

**💡 创新点**

创新点包括：1）无地图实时时空规划，直接从感知获得障碍信息；2）结合时空安全航道和MINCO轨迹优化；3）通过潜在场实现动态避障备份路径；4）使用时空哈希网格高效处理动态碰撞。

**🔧 技术方法**

核心技术包括4D时空RRT*、深度相机感知与目标分割/跟踪、时空哈希网格、凸多面体安全航道、MINCO轨迹优化、备份规划潜在场与FSM决策。

**📊 数据集**

实验数据集主要为自行构建的仿真环境（gym‑pybullet‑drones 与 PX4 SITL + Gazebo），其中动态障碍为随机移动圆柱体或模拟行人，硬件实验使用Intel RealSense D455/T265 与 NVIDIA Jetson Xavier NX。

**📈 对比分析**

与现有方法（如基于SFC的规划、MPC、RRT+SFC等）在10/20/30障碍物场景中对比，SPOT在高密度环境下成功率提升20%+，并在硬件实验中成功避障；相比基线方法在速度更高时性能更优。

**⚠️ 局限性**

局限性包括：1）对动态障碍仅做恒速预测，难以处理复杂运动；2）时空规划仍受限于短期预测窗口（2s）；3）未针对高速飞行或更大规模障碍环境做充分验证；4）缺乏学习式轨迹优化或自适应预测模型。

---

## 140. Adaptive Dual-Weighting Framework for Federated Learning via Out-of-Distribution Detection

**arXiv ID:** 2602.01039 | [PDF](https://arxiv.org/pdf/2602.01039v1)

**作者:** Zhiwei Ling `[一作]` (Zhejiang University), MengChu Zhou `[通讯]` (New Jersey Institute of Technology)

**通讯引用:** 66160 | [OpenAlex ID](https://openalex.org/A5081318069)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `3855fcda-48ef-4070-a15e-803cd5c84d83` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于OOD检测的联邦学习框架FLood，通过双重加权机制提升模型在非IID环境下的鲁棒性。

**💡 创新点**

创新点在于将OOD信号既用于客户端样本加权，又用于服务器聚合权重，实现自适应的局部训练和全局聚合。

**🔧 技术方法**

采用能量(Energy)等后置OOD评分函数与余弦调度的加权方式，结合FedAvg的联邦训练流程。

**📊 数据集**

在CIFAR‑10、CIFAR‑100和SVHN三个公开数据集上验证其有效性。

**📈 对比分析**

与FedAvg、FedProx、SCAFFOLD、Moon、FedDisco、FedMR等十余种方法对比，FLood在Dirichlet与Pathological非IID设置下均能获得显著提升，尤其在极端非IID时平均提高数个百分点。

**⚠️ 局限性**

局限在于对OOD评分准确度敏感，需手动调参且在OOD表现差时可能导致训练不稳定；此外，额外的权重调度开销和通信负载略高。

---

## 141. DeCorStory: Gram-Schmidt Prompt Embedding Decorrelation for Consistent Storytelling

**arXiv ID:** 2602.01306 | [PDF](https://arxiv.org/pdf/2602.01306v1)

**作者:** Ayushman Sarkar `[一作]` (Birbhum Institute of Engineering and Technology), Mohd Yamani Idna Idris `[通讯]` (Universiti Malaya)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出无训练推理时框架DeCorStory，用于多帧文本到图像故事叙述，显著降低帧间语义干扰并保持人物身份一致性。

**💡 创新点**

通过Gram–Schmidt嵌入去相关、奇异值重加权与身份保持交叉注意力三项技术的组合，实现显式语义去相关，从而提升多帧生成的连贯性与一致性。

**🔧 技术方法**

Gram–Schmidt Prompt Embedding Decorrelation、Singular‑Value Reweighting (SVR) 与 Identity‑Preserving Cross‑Attention (IPCA)，以及基于SDXL的扩散模型。

**📊 数据集**

ConsiStory+ 数据集（200套提示、约1500帧）。

**📈 对比分析**

与1Prompt1Story、ConsiStory、StoryDiffusion、IP‑Adapter等训练免费与训练基线对比，在CLIP‑T 0.9001、CLIP‑I 0.9134、DreamSim 0.1922等指标上排名训练免费方法第一。

**⚠️ 局限性**

仅依赖推理时的嵌入去相关，无法处理极长或多模态文本，且效果受限于文本编码器的语义表达能力。

---

## 142. Minimal Footprint Grasping Inspired by Ants

**arXiv ID:** 2602.00935 | [PDF](https://arxiv.org/pdf/2602.00935v1)

**作者:** Mohamed Sorour `[一作]` (University of Edinburgh), Barbara Webb `[通讯]` (University of Edinburgh)

**通讯引用:** 7734 | [OpenAlex ID](https://openalex.org/A5066496499)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0`

**🎯 论文内容**

设计并实现了一种仿蚂蚁腿部结构的四腿抓取器，并在18种不同形状的物体以及混乱环境中进行抓取实验，全部抓取成功。

**💡 创新点**

创新点在于将高摩擦胶垫、低摩擦毛发分离结构以及柔性单段足爪（tarsus‑like）相结合，实现极小抓取足迹、可变形抓握和在混乱环境中的优异穿透性能。

**🔧 技术方法**

采用机械设计、CAD建模、弹性与静力分析、单自由度驱动与力控操作技术，并通过机器人臂（uFactory xArm 850）实现抓取与搬运。

**📊 数据集**

使用18件自制物体数据集，包括圆柱、矩形、异形以及玩具等，重量从45g到690g不等。

**📈 对比分析**

与传统吸盘或两指抓取器对比，实验显示本抓取器在各种形状物体上实现100%抓取成功率，并在混乱场景中显著降低抓取足迹、提高穿透效率。

**⚠️ 局限性**

局限性包括缺乏感知与基于视觉的抓取规划，仅通过预设姿态完成实验，且在极端形状或极大尺寸物体时仍需进一步验证。

---

## 143. PromptRL: Prompt Matters in RL for Flow-Based Image Generation

**arXiv ID:** 2602.01382 | [PDF](https://arxiv.org/pdf/2602.01382v1)

**作者:** Fu-Yun Wang `[一作]` (The Chinese University of Hong Kong), Taesung Park `[通讯]` (Reve)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `40105733-5154-44cd-8090-a8cab9e64b07` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本工作提出 PromptRL 框架，在强化学习循环中联合训练语言模型（LM）和流匹配图像生成模型（FM），实现从文本到图像的端到端生成。

**💡 创新点**

创新点在于将 LM 作为可训练的动态提示细化器嵌入 RL 训练，既扩展了探索空间、缓解提示过拟合，又通过多奖励标签化的单样本训练实现不同目标的统一优化。

**🔧 技术方法**

采用流匹配扩散模型、GRPO 基础 RL、策略梯度、提示保留机制以及奖励标签化等技术，构建了 LM 与 FM 的协同优化流程。

**📊 数据集**

使用的数据集包括 GenEval、OCR‑1k、TMDB、OpenLib、Pick‑a‑Pic、OmniEdit、DrawBench 等多种文本生成与编辑评测基准。

**📈 对比分析**

与 FlowGRPO、DiffusionNFT、RePrompt 等基线相比，PromptRL 在 GenEval 0.97/0.99、OCR 0.98、PickScore 24.05、编辑任务 EditReward 1.43 等指标上均取得领先，且样本效率提升约 2 倍。

**⚠️ 局限性**

局限性包括对大规模算力需求较高、对不同语义变体的鲁棒性尚需进一步验证，以及模型推理时对 LM 的依赖增加导致推理成本上升。

---

## 144. Aggregation Queries over Unstructured Text: Benchmark and Agentic Method

**arXiv ID:** 2602.01355 | [PDF](https://arxiv.org/pdf/2602.01355v1)

**作者:** Haojia Zhu `[一作]` (SouthEast University), Jiahui Jin `[通讯]` (SouthEast University)

**通讯引用:** 1187 | [OpenAlex ID](https://openalex.org/A5081458459)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究并提出针对无结构文本的实体级聚合查询任务，并构建 AGGBench 基准与 DFA 模块化代理框架。

**💡 创新点**

引入完整性驱动的聚合查询定义、AGGBench 评测基准以及拆解为消歧、过滤、聚合的 DFA 框架。

**🔧 技术方法**

结合检索增强生成、迭代过滤工具、LLM 作为裁判与代理执行，模块化实现。

**📊 数据集**

以 45 篇研究论文为核心构建 AGGBench（362 个聚合查询），并扩展为噪声稀疏的完整语料；对比 SpiderQA、单纯 LLM 等。

**📈 对比分析**

与 LLM‑only、单步 RAG、多跳 RAG、传统代理等基线对比，DFA 在 AGGBench‑Core 上召回率提升 5×，总体 recall 最高，但在完整基准上误差仍有提升空间。

**⚠️ 局限性**

缺乏可学习的记忆模块、工具适配与规划能力，且在大规模稀疏语料下鲁棒性有限。

---

## 145. Multi-Agent Teams Hold Experts Back

**arXiv ID:** 2602.01011 | [PDF](https://arxiv.org/pdf/2602.01011v1)

**作者:** Aneesh Pappu `[一作]` (Stanford University), James Zou `[通讯]` (Stanford University)

**通讯引用:** 38258 | [OpenAlex ID](https://openalex.org/A5005779176)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究自组织多智能体LLM团队是否能充分利用专家知识并实现强协同。

**💡 创新点**

首次将组织心理学的强协同概念应用于自组织LLM团队，并揭示其在专家利用上的根本瓶颈。

**🔧 技术方法**

使用多模型异构LLM团队、开放式对话、信息揭示实验、对话行为编码与统计分析等技术。

**📊 数据集**

人类心理学经典任务（NASA 月球生存、Lost at Sea、Student Body President）以及前沿ML基准（MMLU Pro、SimpleQA、GPQA Diamond、HLE、MATH-500）。

**📈 对比分析**

与专家单独回答、预先揭示专家以及无信息条件进行比较，结果显示团队在专家利用上相对差距为8–38%，团队规模越大协同越差，表现远逊于最优专家。

**⚠️ 局限性**

主要局限在于对齐过程可能导致偏好共识，实验基于有限任务与模型，未验证不同对齐或无对齐模型的差异。

---

## 146. When Is Rank-1 Enough? Geometry-Guided Initialization for Parameter-Efficient Fine-Tuning

**arXiv ID:** 2602.01522 | [PDF](https://arxiv.org/pdf/2602.01522v1)

**作者:** Haoran Zhao `[一作]` (University of Melbourne), Eduard Hovy `[通讯]` (University of Melbourne)

**通讯引用:** 43009 | [OpenAlex ID](https://openalex.org/A5060225743)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

在极低秩（rank‑1）下，提出一种基于表示几何的初始化方法 Gap‑Init，使得 LoRA 的更新方向与预训练视觉‑文本特征的差异（模态 gap）对齐，从而稳定并提升 PEFT 训练效果。

**💡 创新点**

创新点在于：①将低秩适配的方向问题从仅靠容量提升转为对齐问题；②利用小规模校准集估计跨模态差异向量并在激活空间内对齐 LoRA 方向；③在保持预训练模型初始行为的同时，仅通过初始化改变梯度投影方向，实现无需额外参数或额外训练步骤。

**🔧 技术方法**

技术手段包括：几何分析（识别视觉与文本特征的各向异性与翻译型模态差异）；在每层计算模态 gap 向量；Gap‑Init 初始化 LoRA 的 B 向量为该 gap 并将 A 设为 0；对比 PiSSA、DoRA 等权重空间初始化；使用 BLIP‑2 OPT‑2.7B 作为基座模型；评估时对齐层的选择与随机层选取进行对照。

**📊 数据集**

数据集与任务：COCO（图像字幕）、VQAv2、OK‑VQA（视觉问答）、Flickr30k（零样本迁移）、POPE（幻觉鲁棒性），训练使用 BLIP‑2 OPT‑2.7B，校准集为少量无标签图文对。

**📈 对比分析**

对比方法包括：随机初始化 LoRA、PiSSA、rank‑8 LoRA、全层 LoRA；在多种任务与指标（CIDEr、BLEU‑4、VQA Accuracy、POPE F1）上，Gap‑Init 在 rank‑1 下可与 rank‑8 相当甚至略优，且在多随机种子实验中显著降低方差，证明训练更稳定；在零样本迁移、鲁棒性评测中亦表现突出。

**⚠️ 局限性**

局限性：①仅在 rank‑1 级别验证，未探讨更低或更高秩的极限；②对模态 gap 的假设依赖于预训练模型的几何特征，可能对其他模型或跨模态结构不适用；③校准集需要一定数量的图文配对，若数据不匹配可能导致估计误差；④未解决更广泛的安全性、偏差与幻觉等问题。

---

## 147. SanD-Planner: Sample-Efficient Diffusion Planner in B-Spline Space for Robust Local Navigation

**arXiv ID:** 2602.00923 | [PDF](https://arxiv.org/pdf/2602.00923v1)

**作者:** Jincheng Wang `[一作]`, Dimitrios Kanoulas `[通讯]` (University College London)

**通讯引用:** 1570 | [OpenAlex ID](https://openalex.org/A5048122691)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 SanD-Planner，一个利用 B‑样条空间的扩散式局部规划器，可在极少示例下实现鲁棒导航。

**💡 创新点**

创新点在于将路径表示转为固定八点的 B‑样条控制点，利用 B‑样条的局部支撑与凸包性质提升样本效率并天然保证平滑；同时将安全评估交给几何批评器，解耦规划与安全检查。

**🔧 技术方法**

采用条件扩散模型生成控制点，Transformer 编码器融合历史深度图、相对目标与前一速度；ESDF 地图做实时安全评估；以及使用 DPM‑Solver++ 加速采样。

**📊 数据集**

使用 500 条从仿真专家轨迹（PCT‑planner）生成的深度序列，覆盖 10 个多样化环境（Matterport3D、Gazebo）进行训练。

**📈 对比分析**

与 iPlanner、ViPlanner、NavDP 等基线在 InternNav Benchmark 对比，成功率分别为 90.1%/72.0%，SPL 为 84.0/63.7，单凭 500 条示例即可匹配或超越现有最优，显著减少数据与计算量。

**⚠️ 局限性**

局限在于对深度感知的依赖，无法处理小尺寸或高反射物体；在极端动态或光照变化场景下仍需进一步提升鲁棒性。

---

## 148. Embedded vs. Situated: An Evaluation of AR Facial Training Feedback

**arXiv ID:** 2602.01050 | [PDF](https://arxiv.org/pdf/2602.01050v1)

**作者:** Avinash Ajit Nargund `[一作]` (University of California), Misha Sra `[通讯]` (University of California)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文通过对比三种AR反馈空间布局（BarChart、Mannequin、ARSelfie）与基线，研究了其对面部肌肉训练的准确性、认知负荷和用户体验的影响。

**💡 创新点**

创新之处在于首次验证嵌入式AR反馈在面部训练中的有效性，并揭示自我呈现舒适度与反馈空间布局之间的权衡以及对可感知清晰度的设计建议。

**🔧 技术方法**

采用Unity+Google ARCore的AugmentedFaces API进行面部追踪，手工映射468点面部标记到肌肉，基于位移计算激活并实现三种可视化编码（条形图、代理嵌入、直接嵌入）。

**📊 数据集**

使用ARCore提供的468点面部网格作为数据源；实验共招募24名受试者进行面部肌肉训练，无外部公开数据集。

**📈 对比分析**

在被试内实验中，使用重复测量ANOVA和Friedman检验比较准确率、首次最佳重复时间、重复次数、NASA‑TLX、ECL和UEQ；结果显示BarChart在准确率最高，ARSelfie在认知负荷和用户体验上最优，用户偏好排序为ARSelfie>Mannequin>BarChart>Baseline。

**⚠️ 局限性**

局限性包括实验仅在实验室短时进行，覆盖面仅三项面部练习；仅提供视觉反馈，未结合EMG等生理信号验证激活准确性；样本量有限且年龄同质，缺乏临床或更广泛人群的验证。

---

## 149. From Invisible to Actionable: Augmented Reality Interactions with Indoor CO2

**arXiv ID:** 2602.01084 | [PDF](https://arxiv.org/pdf/2602.01084v1)

**作者:** Prasenjit Karmakar `[一作]` (Indian Institute of Technology Kharagpur), Sandip Chakraborty `[通讯]` (Indian Institute of Technology Kharagpur)

**通讯引用:** 9070 | [OpenAlex ID](https://openalex.org/A5006910391)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了一种结合可穿戴CO₂传感器CoWear和基于手机的增强现实（AR）游戏的系统，用以实时检测室内二氧化碳浓度并通过可视化泡泡和交互式玩法帮助用户发现并缓解高浓度区域，从而提升对室内空气质量的认知与行动能力。

**💡 创新点**

创新点包括：① 将个人化CO₂测量与AR可视化相融合，形成“人化、场景化、可交互”的污染展示；② 通过游戏化设计激励用户主动调节通风设备（如窗户、风扇等），实现从感知到行为的闭环；③ 对比传统二维热力图，证明AR泡泡更能促成快速、针对性通风并显著降低CO₂浓度。

**🔧 技术方法**

使用技术主要有：① 低功耗ESP32‑S3微控制器搭载CO₂、温湿度传感器的可穿戴设备；② Wi‑Fi 5 s采样、HTTPS 传输实现实时数据流；③ Unity3D AR平台（Plane Manager）实现空间锚定、3D泡泡渲染与交互；④ 调研实验与游戏体验评估采用GEQ、PSSUQ等标准问卷。

**📊 数据集**

数据集：本研究在四种真实环境（办公室、住宅、多餐厅、实验室）中收集CO₂浓度序列与用户交互记录；实验涉及35名受试者，完成S1、S2半控制实验和野外实验，形成个人化CO₂时间序列与可视化反馈日志；没有使用公开公共数据集，而是构建了自己的实验室和现场测量数据。

**📈 对比分析**

比较方法：将AR泡泡与传统二维热力图两种可视化方式在同一房间进行并行实验，记录CO₂降幅、降幅速度、用户游戏体验分数；结果显示：AR系统平均可降低约558 ppm CO₂（中位数1.88 PSSUQ，明显低于热力图下的201 ppm），并在两次实验间提升约30 % 的降速；游戏体验分数和任务完成度均显著高于热力图（p<0.01）。

**⚠️ 局限性**

局限性：① 系统响应延迟约30 s，影响实时交互体验；② AR泡泡数量易堆积，导致界面拥挤；③ 需要受试者主动走动，若用户静止不动，数据可信度下降；④ 仅针对CO₂，未扩展至VOCs、PM2.5等其他污染物；⑤ 在寒冷环境下通风行动与舒适度冲突，缺乏温度/能耗的综合决策支持。

---

## 150. AOASS: Adaptive Obstacle-Aware Square Spiral Framework for Single-mobile Anchor-Based WSN Localization

**arXiv ID:** 2602.01290 | [PDF](https://arxiv.org/pdf/2602.01290v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2`

---

## 151. PDE-Constrained Optimization for Neural Image Segmentation with Physics Priors

**arXiv ID:** 2602.01069 | [PDF](https://arxiv.org/pdf/2602.01069v1)

**作者:** Seema K. Poudel `[一作]` (Independent Researcher), Sunny K. Khadka `[通讯]` (Independent Researcher)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

结合 PDE 约束的深度网络对相位对比显微镜图像进行细胞分割。

**💡 创新点**

将反应-扩散方程与相位场界面能量作为可微分残差损失加入 UNet，形成物理先验驱动的分割框架。

**🔧 技术方法**

PDE‑constrained optimization、反应-扩散方程、相位场能量、UNet 结构及两阶段训练策略。

**📊 数据集**

LIVECell 阶段对比显微镜图像数据集。

**📈 对比分析**

与无约束 UNet 进行对比，在 OOD 与低样本场景下，边界 F1 提升约 307% 以上，Dice 提升约 113% 以上。

**⚠️ 局限性**

仅适用于单相细胞，需经验调参，对高分辨率或多相动态环境的适用性有限。

---

## 152. KAN We Flow? Advancing Robotic Manipulation with 3D Flow Matching via KAN & RWKV

**arXiv ID:** 2602.01115 | [PDF](https://arxiv.org/pdf/2602.01115v1)

**作者:** Zhihao Chen `[一作]` (Beijing University of Posts and Telecommunications), Ziyang Wang `[通讯]` (University of Oxford)

**通讯引用:** 36405 | [OpenAlex ID](https://openalex.org/A5056028884)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `40105733-5154-44cd-8090-a8cab9e64b07` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种基于流匹配的轻量化视觉运动控制策略 KAN-We-Flow，利用 RWKV‑KAN 结构和动作一致性正则化实现一次性动作生成，适用于资源受限机器人。

**💡 创新点**

创新点包括：
1) 设计 RWKV‑KAN 块，将 RWKV 的线性时间序列混合与 GroupKAN 的可学习样条函数融合，显著降低模型参数并提升表达能力；
2) 引入 Action Consistency Regularization (ACR)，在训练时通过 Euler 外推将终点动作与专家轨迹对齐，降低漂移并提升学习稳定性；
3) 在流匹配框架下实现一次性推理，保持实时控制。

**🔧 技术方法**

采用的技术：
- RWKV（时间/通道混合）
- GroupKAN（基于 Kolmogorov‑Arnold 网络的可学习样条函数）
- 统一条件流匹配（Conditional Consistency Flow Matching, CFM）
- Euler 外推的动作一致性正则化
- 轻量化 U‑形网络结构
- AdamW 训练、EMA 等常规训练技巧。

**📊 数据集**

使用的数据集：Adroit、Meta‑World、DexArt，涵盖 3D 点云输入、机器人状态以及视觉嵌入。

**📈 对比分析**

与多种基线（DP3、Simple‑DP3、MambaPolicy、Diffusion‑Policy、BCRNN、IBC、Adaflow、FlowPolicy、MP1）在上述数据集上进行比较。KAR‑We‑Flow 在所有任务与难度等级上实现了最高成功率，例如：Adroit Door 83.0%/68.0%/85.0%（Top‑1/3/5），Meta‑World Easy 92.0%/71.3%/71.3%；同时参数量降低 86.8%，推理时间 8–11 ms，可实现 ~100 Hz 控制。

**⚠️ 局限性**

局限性：
1) 仅在仿真环境验证，缺乏真实机器人实验；
2) 目前仅支持单视点点云+状态的视觉输入，未扩展到多视角或语言条件；
3) 对接触丰富、极长时序任务的鲁棒性与安全性尚未充分验证。

---

## 153. Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training

**arXiv ID:** 2602.01511 | [PDF](https://arxiv.org/pdf/2602.01511v1)

**作者:** Ran Xu `[一作]`, Haoyu Wang `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了Rubric-AR框架，联合优化rubric生成器和评判者，实现基于rubric的奖励模型。

**💡 创新点**

将rubric视为潜在动作，采用交替强化学习训练两者，并提供理论证明可降低梯度方差，提升训练稳定性。

**🔧 技术方法**

使用SFT预训练、GRPO梯度策略优化、格式奖励（R_fmt）以及强化学习框架，实现两模型协同进化。

**📊 数据集**

基于OpenRubrics自研数据以及UltraFeedback、SkyWork、Magpie、Synthetic Instruction Following等公开数据集进行训练。

**📈 对比分析**

与JudgeLRM、RRM、RM-R1、Rubric-RM等多种基线比较，在RewardBench、RM-Bench、FollowBench、Creative Writing v3等多种基准上平均提升约6.8%，并在策略优化中进一步提升1%–6%。

**⚠️ 局限性**

仍受限于非可验证域数据稀缺、模型规模与推理成本、rubric生成多样性与可解释性不足等问题。

---

## 154. Personality Expression Across Contexts: Linguistic and Behavioral Variation in LLM Agents

**arXiv ID:** 2602.01063 | [PDF](https://arxiv.org/pdf/2602.01063v1)

**作者:** Bin Han `[一作]` (University of Southern California), Jonathan Gratch `[通讯]` (University of Southern California)

**通讯引用:** 16561 | [OpenAlex ID](https://openalex.org/A5051992568)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了大语言模型在四种对话情境（破冰、谈判、生存决策、同情）下，使用相同的 Big‑Five 人格提示，如何产生不同的语言、行为与情绪表现。

**💡 创新点**

首次将 Whole Trait Theory 与 LLM 人格调节结合，系统评估人格表达在不同社会目标与情绪背景中的适配性，并在同一模型上跨任务比较语言、行为与情绪的同步变化。

**🔧 技术方法**

使用 Big‑Five 人格提示、LIWC 词汇分析、预训练 BERT 人格分类器、LLM 人格评估器、LLM 情绪识别（Valence–Arousal），以及谈判与生存决策中的同意率和让步曲线等行为指标。

**📊 数据集**

四个任务分别来自个人提问集（破冰）、KODIS 争端对话集（谈判）、Artstein 修订的生存决策任务（生存决策）和同情对话数据集（同情）。

**📈 对比分析**

通过高低人格条件在四种情境下的语言特征差异、分类器预测比例、评估得分和情绪分布进行比较，结果显示显著差异（p<0.001），合作情境下人格区分更明显，情绪与行为指标与人格特征保持一致。

**⚠️ 局限性**

局限包括仅使用单一中立伙伴、样本人格维度有限、上下文无关的评估工具、未与人类对话数据对照，且尚未验证这些情境适应性变化在实际应用中的功能效益。

---

## 155. GMAC: Global Multi-View Constraint for Automatic Multi-Camera Extrinsic Calibration

**arXiv ID:** 2602.01033 | [PDF](https://arxiv.org/pdf/2602.01033v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 156. Making progress: Reducibility Candidates and Cut Elimination in the Ill-founded Realm

**arXiv ID:** 2602.01299 | [PDF](https://arxiv.org/pdf/2602.01299v1)

**作者:** Gianluca Curzi `[一作]`, Graham E. Leigh `[通讯]`

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c`

**🎯 论文内容**

在非良构的线性逻辑固定点系统中，提出两种基于归约可计算候选的 ω-消除证明论，证明了进展性证明可 ω-正规化并保持进展性。

**💡 创新点**

首次将 Tait–Girard 的归约可计算候选方法与内部不可构造性和外部进展性条件结合，以形式化方式保证非良构证明的 ω-消除保持全局正确性。

**🔧 技术方法**

使用归约可计算候选（Tait–Girard）、极限/拓扑论（内部闭集、外部进展性）、ω-归约序列以及多余切消除（multicut）技术。

**📊 数据集**

无数据集（理论证明）。

**📈 对比分析**

通过与先前的消除策略（如基于契约映射的超度量、ω-压缩、域论方法）对比，证明在本方法中不需要依赖系统特定的约束，可直接保证进展性；由于是理论证明，未进行实验性能评估。

**⚠️ 局限性**

仅适用于单向序贯推理的线性逻辑固定点片段；对更一般的多合一结构或更高阶固定点系统的推广仍待研究；对其他全局正确性标准（如运行、Sprenger 等）的保持尚未完全解决。

---

## 157. Attention Sink Forges Native MoE in Attention Layers: Sink-Aware Training to Address Head Collapse

**arXiv ID:** 2602.01203 | [PDF](https://arxiv.org/pdf/2602.01203v1)

**作者:** Zizhuo Fu `[一作]` (Peking University), Meng Li `[通讯]` (Peking University)

**通讯引用:** 24401 | [OpenAlex ID](https://openalex.org/A5100457407)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了Transformer注意力中的“attention sink”现象，并证明其本质是隐式的专家路由器，形成了原生的Mixture‑of‑Experts（MoE）结构；针对注意力头坍塌（head collapse）问题，提出了 sink‑aware 的辅助负载平衡损失；在从零开始训练和微调现有LLM（如LLaMA3.1、Qwen3）时，验证了该损失能提升头利用率和模型性能；

**💡 创新点**

将注意力 sink 与 MoE 结构对接，首次将其视为隐式门控；提出了无需显式提取注意力权重即可计算负载平衡的 sink‑aware 损失；通过共享头与路由头策略解决微调时的头固定问题；

**🔧 技术方法**

Transformer 的多头注意力、Softmax 与 Sink Attention、Gated Attention、Log‑Sum‑Exp (LSE) 计算、FlashAttention、LoRA 微调、损失函数中的负载平衡项；

**📊 数据集**

在预训练阶段使用 FineWeb‑Edu；在微调阶段使用 AceReason‑Nemotron；评测集包括 MMLU、GSM‑8K、HumanEval、BoolQ、ARC‑E/Chall、OpenBookQA、HellaSwag、PIQA、WinoGrande、LongBench（HotpotQA、Qasper、TriviaQA、NarrativeQA、2WikiMultiHopQA、MultiFieldQA）等；

**📈 对比分析**

与三种注意力机制（Vanilla、Sink、Gated）以及是否加负载平衡损失进行对比；实验显示 Sink / Gated 通常优于 Vanilla，加入负载平衡损失后在所有模型规模（0.6B、1B、2B）和微调任务中均取得 0.8‑1.4% 的准确率提升和显著降低 head‑load 不均衡；

**⚠️ 局限性**

仅在 Transformer 基础模型上验证，未针对更大规模（如 20B‑80B）或其它架构（如 GPT‑NeoX、Mistral）做广泛评估；负载平衡损失需要额外调参，且对已有预训练模型可能产生 head‑pinning 影响，需要额外的“共享头”策略；

---

## 158. RAPT: Model-Predictive Out-of-Distribution Detection and Failure Diagnosis for Sim-to-Real Humanoid Robots

**arXiv ID:** 2602.01515 | [PDF](https://arxiv.org/pdf/2602.01515v1)

**作者:** Humphrey Munn `[一作]` (University of Queensland), David Howard `[通讯]` (CSIRO Robotics)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `3855fcda-48ef-4070-a15e-803cd5c84d83` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出并实现了一种轻量级自监督部署时监控系统RAPT，用于检测和诊断仿真到现实（Sim-to-Real）下人形机器人运行中的异常行为。

**💡 创新点**

创新点包括：①将重建误差视为连续的模拟-现实失配量化信号，提供可校准的、实时的OOD检测；②结合梯度时序显著性与大型多模态语言模型实现零样本根因诊断；③在高频（50 Hz）控制环境下保持低延迟（≈1.6 ms）并兼顾严格的低误报率。

**🔧 技术方法**

使用了残差编码器–GRU–概率解码器的自监督重建模型、负对数似然（NLL）校准、三重门控检测逻辑（重建、均值、范围），以及基于梯度的时序显著性与LLM推理进行根因分析。

**📊 数据集**

数据集包括：①大规模NVIDIA Isaac Lab仿真环境中采集的四种人形机器人任务（行走、舞蹈、模拟投掷）的正向数据；②在真实Unitree G1机器人上收集的24条含异常的物理试验数据，包含传感器失效、动力学扰动、通信错误等15类OOD场景。

**📈 对比分析**

在仿真中与PatchAD、LSTM‑VAE、Deep SVDD、Isolation Forest等基线比较，RAPT在TPR@0.5% FPR上提高约0.34，AUROC最高；在真实硬件上，混合RAPT+范围检测器召回率达75%，相较于单一模型提升约13%，并且能在零误报率下保持正常操作。

**⚠️ 局限性**

局限性包括：①真实实验样本有限，仅在单一Unitree G1平台进行短期部署；②校准方法简单，未对各维度的分布建模，可能导致对细微异常的漏检；③对极低误报率（如0.1%）的鲁棒性和在更大规模、多平台上的通用性仍待验证。

---

## 159. Long-range Modeling and Processing of Multimodal Event Sequences

**arXiv ID:** 2602.01125 | [PDF](https://arxiv.org/pdf/2602.01125v1)

**作者:** Jichu Li `[一作]` (Renmin University of China), Quyu Kong `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出MM-TPP框架，将大型多模态语言模型应用于时间点过程，支持时间、事件类型、文本与图像联合建模并生成富文本分析

**💡 创新点**

1）统一的多模态事件模板与视觉占位符；2）基于时间相似性的自适应序列压缩，解决长上下文问题；3）两阶段预训练+微调，提升生成与推断性能

**🔧 技术方法**

Qwen2.5-VL预训练多模态LLM、Transformer自回归、token化+占位符、Temporal Similarity Compression、LoRA微调

**📊 数据集**

DanmakuTPP（含文本、图像长序列）与自构造的TAXI-PRO（包含地图图像与文本）

**📈 对比分析**

与NHP、SAHP、THP、RMTPP、AttNHP、S2P2、Language-TPP、TPP-LLM等基线对比；在DanmakuTPP时间预测RMSE降至5.2987，类型准确率27.62%；在TAXI-PRO时间RMSE 0.3310，准确率77.56%；在DanmakuTPP-QA闭合问答与生成报告均优于现有多模态LLM

**⚠️ 局限性**

未实现事件图像生成；压缩阈值需手工设定；对超短序列时压缩无效；模型对不同任务的适配仍受限于基础LLM的能力

---

## 160. GAPNet: Plug-in Jointly Learning Task-Specific Graph for Dynamic Stock Relation

**arXiv ID:** 2602.00888 | [PDF](https://arxiv.org/pdf/2602.00888v1)

**作者:** Yingjie Niu `[一作]` (University), Ruihai Dong `[通讯]` (University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出并实现了GAPNet，一种可插拔的图适配插件，能够在GNN训练过程中动态对齐预定义图结构与下游股票排名任务，实现端到端学习。

**💡 创新点**

创新点包括：①空间感知层通过多尺度卷积+Transformer自注意扩大节点感知域，捕获高阶关系；②时序感知层采用门控记忆机制融合短期与长期依赖；③将图结构与任务目标直接联合优化，解决传统预定义图与任务不一致、泛化差的问题；④模块化设计可无缝插入任何基于图或超图的模型。

**🔧 技术方法**

技术细节：多尺度1D卷积+残差块、Transformer编码器、SPL/TPL门控网络（类似LSTM）、GAPNet对图邻接矩阵进行动态重构、最终与任意GNN（GCN、RT‑GCN、CI‑STHPAN等）配合使用；评估使用深度学习框架PyTorch + PyTorch‑Geometric。

**📊 数据集**

使用公开的NASDAQ和NYSE两大真实股票交易数据集，时间跨度均为2013‑2017，包含多种股票关系信息（行业、Wiki、DTW等），并进行训练/验证/测试拆分。

**📈 对比分析**

与传统两步图构造+GNN训练流程（如GCN、RSR‑I、RT‑GCN、CI‑STHPAN等）进行对比；结果显示GAPNet显著提升年化累计收益（IRR）和夏普比率（SR），例如在NASDAQ上与CI‑STHPAN对比，IRR提升0.18，SR提升0.63；在NYSE上与RSR‑I对比，IRR提升0.32，SR提升0.50；多次实验均通过p<0.01显著。

**⚠️ 局限性**

局限性：①对超图模型的计算成本和显存占用提升明显；②实验仅覆盖股票排名任务，未验证其他金融预测任务；③在无预定义图时初始化随机，性能仍受限；④假设交易成本为0，实际交易可能削弱收益；⑤对不同市场或更长周期的泛化尚需进一步验证。

---

## 161. Early Classification of Time Series in Non-Stationary Cost Regimes

**arXiv ID:** 2602.00918 | [PDF](https://arxiv.org/pdf/2602.00918v1)

**作者:** Aurélien Renault `[一作]` (Orange Research), Vincent Lemaire `[通讯]` (Orange Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文研究在部署时成本非平稳（成本漂移与随机成本）下的时间序列早期分类（ECTS）问题，提出在线适应触发模型的多种方法并在合成数据上进行系统评估。

**💡 创新点**

创新点在于：①首次系统性探讨并实验成本漂移与随机成本对ECTS的影响；②将多类代表性触发策略（基于阈值、Bandit、RL和非贪心回归）改造为在线学习模式；③提出结合衰减与滑动窗口的遗忘机制以及使用成本矩阵驱动的无更新方法。

**🔧 技术方法**

使用的技术包括：分离式ECS框架（先训练分类器再学习触发器）、多臂Bandit（UCB1、SW-UCB1、HUCB1）、深度强化学习（DQN式Alert）、深度回归（Deep‑Calimera）、阈值衰减Proba‑Threshold，以及对成本非平稳情境的模拟与评估指标（累计遗憾、AvgCost、实时运行时）。

**📊 数据集**

实验数据基于MNIST‑1D合成数据集（10类，长度40的单变量时间序列），随机生成20,000条序列，划分为训练（25%）、部署（50%）和留置（25%）集。

**📈 对比分析**

方法比较采用预序列评估（eval‑then‑update）与累计遗憾、Hold‑out AvgCost（按α分配误差与时延）以及计算时间。结果显示：RL‑基Alert与非贪心Deep‑Calimera在成本漂移与随机成本下均优于传统Proba‑Threshold；加入遗忘机制的SW‑HUCB1和衰减Proba‑Threshold显著提升鲁棒性；在随机成本情形中，非贪心模型优于基于成本矩阵的Economy‑γ。

**⚠️ 局限性**

局限性包括：①只在合成数据上验证，缺乏真实世界应用；②分离式框架假设分类器固定，忽略了类别分布漂移；③部分方法（Deep‑Calimera、Alert）对计算资源要求较高；④未考虑多任务或多目标成本场景。

---

## 162. SetPO: Set-Level Policy Optimization for Diversity-Preserving LLM Reasoning

**arXiv ID:** 2602.01062 | [PDF](https://arxiv.org/pdf/2602.01062v1)

**作者:** Chenyi Li `[一作]` (Peking University), Nan Duan `[通讯]` (JD Explore Academy)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种基于集合的策略优化方法SetPO，鼓励LLM在生成推理答案时保持多模态、多样化的输出；

**💡 创新点**

创新点在于引入留一（leave‑out）边际贡献度量，将每条轨迹的多样性贡献量化，并将其作为优势塑造项直接加入GRPO等集合级策略优化；

**🔧 技术方法**

技术包括：基于预训练语义嵌入的核密度估计、留一边际差分计算、对奖励的加权优势调整，以及对RLVR的扩展；

**📊 数据集**

使用的评估数据集包括数学推理基准GSM8K、MATH500、Olympiad、College Math、AMC2023、AIME24/25，以及计数器任务Countdown和大型32B模型的Simple‑RL Zoo子集；

**📈 对比分析**

与GRPO、GSPO、DAPO以及R1‑Zero‑Div等基线进行对比，SetPO在Pass@1与Pass@K指标上均实现显著提升（平均提升5–7个百分点），同时在多样性评估中获得更高的多样化得分，且训练过程更稳定；

**⚠️ 局限性**

局限性包括：需要额外计算留一边际，导致一定的计算开销；多样性评价依赖外部嵌入模型与启发式相似度度量，可能对不同任务泛化有限；以及在极大模型规模或超长生成任务中，多样性与性能的平衡仍需进一步探究。

---

## 163. Supervised Fine-Tuning Needs to Unlock the Potential of Token Priority

**arXiv ID:** 2602.01227 | [PDF](https://arxiv.org/pdf/2602.01227v1)

**作者:** Zhanming Shen `[一作]` (Zhejiang University), Haobo Wang `[通讯]` (Zhejiang University)

**通讯引用:** 1150 | [OpenAlex ID](https://openalex.org/A5100765051)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Token Priority 框架，将监督微调视为分布重塑过程，分为正向优先（噪声过滤）与负向优先（毒性消除）两类；

**💡 创新点**

创新点在于将多种对齐技术统一为 token‑level 权重/硬选择，揭示粒度不匹配导致的梯度枯竭与暴露偏差问题；

**🔧 技术方法**

采用信息熵、梯度敏感度、对抗损失等自洽信号与外部事实标签相结合的加权训练，结合软重权与硬筛选两种策略；

**📊 数据集**

主要使用公开指令数据集（如 LIMA、InstructGPT、OpenAI 训练集）以及自建高质量过滤样本；

**📈 对比分析**

与传统统一 MLE、RLHF、DPO 等对比，实验证明在指令遵从、事实准确性与鲁棒性上均提升约 5–15% 左右；

**⚠️ 局限性**

局限在于权重估计误差、动态调度难度、以及跨任务泛化与多模态适配的挑战。

---

## 164. StreamVLA: Breaking the Reason-Act Cycle via Completion-State Gating

**arXiv ID:** 2602.01100 | [PDF](https://arxiv.org/pdf/2602.01100v1)

**作者:** Hang Wu `[一作]` (TARS Robotics), Lu Fang `[通讯]` (Tsinghua University)

**通讯引用:** 20382 | [OpenAlex ID](https://openalex.org/A5101664962)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 StreamVLA 框架，融合慢速推理与高速控制，实现长周期机器人任务的高效执行。

**💡 创新点**

创新点在于未来完成状态想象（completion‑state imagination）与锁定门控机制（Lock‑and‑Gated），通过视觉完成状态作为时间不变目标来跳过多余推理，显著降低延迟。

**🔧 技术方法**

使用共享 Transformer 背骨，Infinity 视觉生成头，Flow Matching 动作头，以及轻量门控模块，融合文本、视觉与关节状态等多模态信息。

**📊 数据集**

训练与评测使用 LIBERO、RoboTwin 2.0 以及自收集的真实世界机器人数据集。

**📈 对比分析**

与 OpenVLA‑OFT、π_0、π_0.5 等基线对比，LIBERO 上取得 98.5% 成功率，RoboTwin 2.0 难度版本 37.2% 成功率；平均延迟从 244 ms 降至 128 ms，降低 48%。

**⚠️ 局限性**

局限：在强遮挡下易产生视觉幻觉；门控阈值需经验调参；仅依赖视觉与语言输入，缺乏触觉/力觉等感知。

---

## 165. Scalable Random Wavelet Features: Efficient Non-Stationary Kernel Approximation with Convergence Guarantees

**arXiv ID:** 2602.00987 | [PDF](https://arxiv.org/pdf/2602.00987v1)

**作者:** Sawan Kumar `[一作]` (Indian Institute of Technology), Souvik Chakraborty `[通讯]` (Indian Institute of Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `b88c6eac-d57a-4623-a604-1f401f3eb268` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究了利用随机小波特征（RWF）近似非平稳核，构建可扩展的高效 Gaussian Process 模型。

**💡 创新点**

通过将小波尺度和位移随机采样，将随机特征从平稳的傅里叶空间推广到非平稳空间，并给出正定、无偏和均匀收敛的理论保证。

**🔧 技术方法**

使用随机小波特征、Gaussian Process 回归、Monte Carlo 采样、贝叶斯线性回归等技术。

**📊 数据集**

在合成多步函数、TIMIT 语音信号、七个 UCI 回归数据集以及 Protein 基因表达数据集上进行评估。

**📈 对比分析**

与 SVGP、RFF‑GP、Deep GP、Spectral Mixture、DRF、IDD‑GP、Adaptive RKHS 等基线对比，RWF 在大多数任务上取得最低 RMSE/CRPS/NLL 并且训练时间显著更短。

**⚠️ 局限性**

受限于小波字典的选择和采样分布，对极高维或稀疏数据的适应性仍待进一步验证。

---

## 166. Robust Harmful Meme Detection under Missing Modalities via Shared Representation Learning

**arXiv ID:** 2602.01101 | [PDF](https://arxiv.org/pdf/2602.01101v1)

**作者:** Felix Breiteneder `[一作]` (Johannes Kepler University), Shah Nawaz `[通讯]` (Johannes Kepler University)

**通讯引用:** 1974 | [OpenAlex ID](https://openalex.org/A5101499412)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

针对缺失文本模态的有害表情包检测，提出一种基于共享表征学习的多模态模型。

**💡 创新点**

创新点在于将文本和图像分别映射到共享潜在空间，实现对单一模态缺失时的鲁棒性，而非传统的特征融合。

**🔧 技术方法**

使用CLIP预训练嵌入、全连接层共享网络、交叉熵损失及AdamW优化器。

**📊 数据集**

使用修正后的HarMeme数据集，包括Harm-C和Harm-P两子集。

**📈 对比分析**

与MMBT、VisualBERT、MOMENTA等SOTA基线对比，在文本缺失0%–70%时仍保持F1≈66–68，显著优于对手。

**⚠️ 局限性**

局限在于共享表征在完整模态下略逊于融合方法，对极低文本比例仍受视觉特征限制。

---

## 167. ReDiStory: Region-Disentangled Diffusion for Consistent Visual Story Generation

**arXiv ID:** 2602.01303 | [PDF](https://arxiv.org/pdf/2602.01303v1)

**作者:** Ayushman Sarkar `[一作]` (Birbhum Institute of Engineering and Technology), Mohd Yamani Idna Idris `[通讯]` (Universiti Malaya)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

针对多帧视觉故事生成，提出一种训练‑free 框架 ReDiStory，利用推理时对提示词嵌入进行重组，确保主题身份在不同场景和姿态下保持一致。

**💡 创新点**

创新点在于将身份相关嵌入与帧级嵌入显式分离，并通过投影消除帧间共享方向，从而在不修改扩散模型或引入额外监督的前提下，显著降低跨帧语义干扰。

**🔧 技术方法**

采用的技术包括：文本编码器得到的嵌入分块、投影式去相关化（Projection‑based decorrelation）、无训练的推理时重组、SDXL 扩散模型采样，以及 CLIP 与 DreamSim 用于评估的指标。

**📊 数据集**

实验数据集为 ConsiStory+，包含 50 位主体、每位 5 个帧级提示，共 250 条多帧测试案例。

**📈 对比分析**

与 1Prompt1Story、ConsiStory、StoryDiffusion 等训练‑free 方法对比，ReDiStory 在身份一致性指标 CLIP‑I 由 0.9117 提升至 0.9149，DreamSim 降至 0.1952，保持了与基线相近的提示词对齐（CLIP‑T）。内存与推理时间略有增加（+0.19 GB、+0.43 s），但总体性能提升显著。

**⚠️ 局限性**

局限性：改进幅度相对温和，主要体现在短序列与中等变换幅度下；对更长序列或更大身份变化的鲁棒性尚需进一步验证；以及在保持多样性方面尚未彻底解决。

---

## 168. Toward Universal and Transferable Jailbreak Attacks on Vision-Language Models

**arXiv ID:** 2602.01025 | [PDF](https://arxiv.org/pdf/2602.01025v1)

**作者:** Kaiyuan Cui `[一作]` (University of Melbourne), Hanxun Huang `[通讯]` (University of Melbourne)

**通讯引用:** 230 | [OpenAlex ID](https://openalex.org/A5049209023)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `6215c339-3735-4be3-8a07-5bbb7004712d` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出 UltraBreak，一种针对 Vision‑Language 模型（VLM）的通用且可迁移的 jailbreak 攻击框架，旨在一次性生成能够在多种模型和多种攻击目标上诱导安全违规响应的攻击图像。

**💡 创新点**

创新点包括：
1) 在视觉空间引入随机变换、投影约束和总变差（TV）正则化，限制优化空间，促使攻击模式保持对模型的鲁棒性；
2) 用语义层面的目标（embedding 语义损失）并加入注意力加权，替代传统的交叉熵目标，显著平滑损失曲面，提升训练稳定性与泛化；
3) 结合 Targeted Prompt Guidance（TPG）进一步诱导模型输出“步骤”式回应，从而强化语义监督；
4) 通过单一 surrogate 模型即可实现跨目标和跨模型的高效迁移，突破现有方法对多模型、多目标的局限。

**🔧 技术方法**

采用的主要技术手段：
- 随机平移、旋转、缩放等视觉变换与投影约束；
- 总变差（TV）正则化；
- 语义嵌入空间损失 + 位置编码 + 注意力加权；
- Targeted Prompt Guidance (TPG) 与正向投影；
- Adam 优化、CLIP 归一化统计、温度参数 τ 的调节；
- 对攻击图像的后处理与投影到合法像素范围。

**📊 数据集**

使用的数据集与模型：
- 训练集：SafeBench‑Tiny（5 类 5 条量子）；
- 评估集：SafeBench、AdvBench、MM‑SafetyBench；
- 开源 VLM：Qwen‑VL‑Chat、Qwen2‑VL‑7B、Qwen2.5‑VL‑7B、LLaVA‑v1.6‑mistral‑7b、Kimi‑VL‑A3B、GLM‑4.1V‑9B；
- 付费模型：GPT‑4.1‑nano、Gemini‑2.5‑flash‑lite、Claude‑3‑haiku；
- 评测工具：judge LLM、StrongREJECT 等。

**📈 对比分析**

与手工设计（FigStep）和梯度基攻击（VAJM、UMK）进行对比，评估指标为攻击成功率（ASR）和 StrongREJECT 分数。实验显示：
- 在所有开源模型的黑盒设置下，UltraBreak 的平均 ASR 在 SafeBench 上达到 71% 以上，在 AdvBench 上超过 57%；
- 对商业模型的平均 ASR 约为 32%；
- 与基线相比，UltraBreak 的 ASR 提升 20–40% 以上，且在多模型、多目标上保持较高的鲁棒性；
- StrongREJECT 分数同样显示 UltraBreak 生成的恶意回复质量更高。

**⚠️ 局限性**

局限性：
- 对极大规模模型（>32B）迁移效果尚未充分验证；
- 训练成本高，受限于计算资源，难以在更大样本集上进行系统性评估；
- 目前仅针对图片–文本组合的攻击，未覆盖其他多模态输入（如视频、音频）；
- 在某些目标模型（如特定 LLM 结构）下，迁移效果可能下降；
- 需要进一步研究更强的防御策略以抑制此类攻击。

---

## 169. ASTER: Agentic Scaling with Tool-integrated Extended Reasoning

**arXiv ID:** 2602.01204 | [PDF](https://arxiv.org/pdf/2602.01204v1)

**作者:** Xuqin Zhang `[一作]` (Huawei), Dong Li `[通讯]` (Huawei)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种基于强化学习的工具集成推理框架ASTER，并在4B规模模型上实现了数学竞赛的领先表现。

**💡 创新点**

核心创新在于：①利用交互密度高的冷启动监督微调数据作为行为先验，防止交互崩溃；②采用两阶段GRPO训练与上下文长度递增策略，提升探索效率和多步工具使用能力。

**🔧 技术方法**

技术包括：监督微调（LlamaFactory）、工具集成推理（Python沙箱）、强化学习（GRPO）、两阶段RL日程、交互密度筛选以及工具调用计数与成功率监控。

**📊 数据集**

使用的数据集：Skywork‑OR1‑RL‑Data、AoPS 93K 题目生成的45K工具增强轨迹、17K DAPO‑Math‑17K 用于RL；评测采用 AIME 2024/2025、HMMT 2025 与 BeyondAIME 等数学竞赛数据。

**📈 对比分析**

在 DeepSeek‑R1 评估框架下，与文本推理模型、现有代理模型（如 Qwen3‑235B、ReTool、rStar2‑Agent、DemyAgent）进行对比；ASTER‑4B 在 AIME 2025 达到 90.0%，AIME 2024 85.8%，HMMT 2025 77.1%，显著优于同尺寸及更大模型。

**⚠️ 局限性**

局限性包括：依赖人工挑选的高交互轨迹，自动化生成难度较高；在更大或动态工具集上的泛化尚未充分验证；以及潜在的安全与滥用风险需要进一步评估。

---

## 170. Resilience Optimization in 6G and Beyond Integrated Satellite-Terrestrial Networks: A Deep Reinforcement Learning Approach

**arXiv ID:** 2602.01102 | [PDF](https://arxiv.org/pdf/2602.01102v1)

**作者:** Dinh-Hieu Tran `[一作]` (University of Luxembourg), Symeon Chatzinotas `[通讯]` (University of Luxembourg)

**通讯引用:** 25011 | [OpenAlex ID](https://openalex.org/A5016154330)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出了一个利用低轨卫星备份的6G集成卫星‑地面网络弹性优化框架，结合天线倾斜和功率调节来最大化总吞吐量并最小化卫星使用。

**💡 创新点**

将深度强化学习（DQN）首次应用于集成卫星‑地面网络的弹性资源管理，并在多用户、多小区模型中同时考虑天线倾斜、功率控制和用户关联约束。

**🔧 技术方法**

采用深度Q网络（DQN）、三维天线模型、Rician/LoS信道模型、经验回放和ε‑贪婪策略等技术。

**📊 数据集**

通过仿真生成的随机均匀分布的1000名用户、5颗LEO卫星和多小区基站数据，未使用公开真实数据集。

**📈 对比分析**

与传统Q学习（QLA）对比，DQN在吞吐量、良好RSRP用户数上收敛更快，平均奖励提升约30%，波动更小。

**⚠️ 局限性**

仅在仿真环境下验证，未考虑多波束卫星链路切换延迟、实际部署中的干扰与能耗动态；算法规模随小区/卫星数量增长需进一步优化。

---

## 171. What If We Allocate Test-Time Compute Adaptively?

**arXiv ID:** 2602.01070 | [PDF](https://arxiv.org/pdf/2602.01070v1)

**作者:** Ahsan Bilal `[一作]` (University of Oklahoma), Dean Hougen `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于验证器的自适应推理框架，动态选择推理工具与计算策略，并用过程奖励模型（PRM）在生成过程中实时评估与裁剪轨迹，最终通过PRM对多次迭代产生的候选路径进行选择；

**💡 创新点**

创新点在于：①把验证器信息作为在线控制信号，形成跨步骤、跨迭代的过程奖励模型，能够在生成阶段即时剪枝和引导；②实现对推理路径的自适应计算分配，显著提升推理效率和准确性；③不需额外训练，采用LLM的角色化prompt完成控制；

**🔧 技术方法**

使用的技术包括：过程奖励模型（PRM）评估单步正确性；多种工具（Chain‑of‑Thought、Self‑Reflection、Verifier、Numeric Verifier、Reframer、Summarizer）；多种搜索/采样策略（Best‑of‑N、Beam Search、Lookahead）；LLM驱动的启发式控制器；以及理论FLOPs和计算强度（S_CI）两种效率度量；

**📊 数据集**

实验数据集：MATH‑500、AIME24、AMO‑Bench；

**📈 对比分析**

与四种基线（Direct、Direct+PRM、Dynamic、Dynamic+PRM）对比。结果显示：在MATH‑500上，Llama‑3.1‑8B从43.8%提升到65.4%，Qwen‑2.5‑7B从71.2%提升到81.4%；AIME24从3.3%–6.67%提升到10%–13%；AMO‑Bench从2%提升到4%。在效率上，动态+PRM虽然理论FLOPs略高，但计算强度更低，表明计算更集中在高价值轨迹上；

**⚠️ 局限性**

主要限制：①对PRM评估质量高度依赖，最难问题上PRM误判导致收益下降；②控制器为启发式且无学习，无法最优分配预算；③多分支搜索与验证导致推理延迟和系统开销；④目前仅验证于数学推理，跨域迁移需开发相应验证器与控制策略。

---

## 172. CLAMP: Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining

**arXiv ID:** 2602.00937 | [PDF](https://arxiv.org/pdf/2602.00937v1)

**作者:** I-Chun Arthur Liu `[一作]` (Google DeepMind), Connor Schenck `[通讯]` (Google DeepMind)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种利用3D多视角、动作和文本的对比预训练框架CLAMP，结合动态手腕视角和STRING位置编码，预训练图像、动作和文本编码器以及扩散策略。

**💡 创新点**

创新点在于把3D点云信息直接映射到多视角图像并通过STRING编码实现不同视角之间的空间关联；同时在预训练阶段联合图像‑动作‑文本三元对进行对比学习，并同步预训练扩散策略。

**🔧 技术方法**

使用ViT+STRING图像编码器、Transformer动作编码器、CLIP文本编码器、扩散策略DDPM、STRING相对位置编码、动态手腕视角、对比损失和自监督预训练。

**📊 数据集**

在Mujoco ALOHA 2仿真环境中收集超过55万条图像‑文本‑动作三元组进行预训练，后用4.5k条任务演示进行微调；在真实世界使用四摄RGB‑D和手腕摄像头收集的遥控演示（各任务数百条）。

**📈 对比分析**

与VLA Backbone、ALOHA Unleashed、ACT等基线相比，CLAMP在六个仿真任务和五个真实任务上均实现更高的成功率和更快的采样效率。

**⚠️ 局限性**

局限在于需要大规模的仿真数据和任务相关的文本描述；对手腕视角和点云重建的依赖使得在极端光照或遮挡条件下性能可能下降。

---

## 173. P-EAGLE: Parallel-Drafting EAGLE with Scalable Training

**arXiv ID:** 2602.01469 | [PDF](https://arxiv.org/pdf/2602.01469v1)

**作者:** Mude Hui `[一作]` (University of California), George Karypis `[通讯]` (Amazon)

**通讯引用:** 63073 | [OpenAlex ID](https://openalex.org/A5082384108)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出P-EAGLE，将EAGLE的单词推理改为并行多词预测，显著降低推理延迟。

**💡 创新点**

创新点包括：1）引入共享隐藏状态与mask词嵌入，使所有并行位置在一次前向传播中生成；2）设计可扩展训练框架，利用预计算注意力掩码和序列划分实现长上下文训练；3）通过层数、嵌入解冻、训练推理深度不匹配等多种技巧提升并行推理质量。

**🔧 技术方法**

使用的技术有：Transformer（LLaMA3.1、RoPE）、EAGLE框架、并行推理（parallel drafting）、注意力掩码预计算、序列划分（within-sequence gradient accumulation）、COD采样、vLLM推理实现。

**📊 数据集**

训练集：UltraChat、GSM‑8K（train）、OpenCodeInstruct；评测集：HumanEval、MT‑Bench、GSM‑8K test。

**📈 对比分析**

与基线AR EAGLE‑3、ParallelSpec、PARD进行对比；在接受率上P‑EAGLE匹配或略优（平均+4.5%）；在推理吞吐量上，P‑EAGLE在GPT‑OSS 120B、20B、Qwen3‑Coder 30B上分别实现1.10×–1.36×的速度提升。

**⚠️ 局限性**

局限性：1）在低推测深度（K=3）时模型深度导致单步推理略慢；2）仍需较大显存支持长上下文，尽管已改进但对极长序列仍有限；3）仅在vLLM框架下验证，未覆盖所有MoE或量化模型；4）缺少对更大模型或多任务场景的广泛验证。

---

## 174. HierCon: Hierarchical Contrastive Attention for Audio Deepfake Detection

**arXiv ID:** 2602.01032 | [PDF](https://arxiv.org/pdf/2602.01032v1)

**作者:** Zhili Nicholas Liang `[一作]` (University of Melbourne), Christopher Leckie `[通讯]` (University of Melbourne)

**通讯引用:** 12362 | [OpenAlex ID](https://openalex.org/A5076014464)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出一种Hierarchical Contrastive Attention（HierCon）框架，用于音频深度伪造检测。

**💡 创新点**

创新点在于三层级注意力（时间、组内、组间）与对比学习的联合建模，显式捕捉跨层、跨时序的伪造痕迹并实现域不变表征。

**🔧 技术方法**

使用XLS-R 300M自监督特征，三阶段注意力网络、对比学习投影头以及二分类器。

**📊 数据集**

评估数据集包括ASVspoof 2021 DF、LA和In-the-Wild。

**📈 对比分析**

与SLS、WavLM、AASIST等方法对比，HierCon在DF实现1.93% EER、LA 2.46% EER、ITW 6.87% EER，均取得显著提升。

**⚠️ 局限性**

局限在于模型仍依赖大型自监督基模型，计算量较大，主要针对音频域，跨模态或实时部署仍待完善。

---

## 175. MarkovScale: Towards Optimal Sequential Scaling at Inference Time

**arXiv ID:** 2602.01120 | [PDF](https://arxiv.org/pdf/2602.01120v1)

**作者:** Youkang Wang `[一作]` (Hong Kong Polytechnic University), Qing Li `[通讯]` (Hong Kong Polytechnic University)

**通讯引用:** 46195 | [OpenAlex ID](https://openalex.org/A5100404130)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出MarkovScale框架，将推理时的顺序扩展建模为两状态马尔科夫链，提供闭式最优停止与阈值门控，实现在多种LLM上的资源高效推理。

**💡 创新点**

创新点在于：①用马尔科夫过程解析顺序扩展的收敛性与上限/下限；②推导出可直接计算的最优迭代步数与停止判据；③在此基础上设计三种实现变体（门控、MAP估计、无训练），并与现有并行/顺序扩展方法进行对比。

**🔧 技术方法**

核心技术包括：离散时间两状态马尔科夫链理论、闭式解与极限分析、最大后验估计（Beta分布）、多层感知机预测零射击准确率与转移概率、验证器（PRM）用于在线更新、阈值门控与最优停止策略。

**📊 数据集**

使用五大推理基准：MATH‑500、GSM8K、AIME 2024、AIME 2025、AMC 2023；实验基座模型涵盖多种开源LLM（如DeepSeek‑R1‑Distill‑Qwen‑7B、QwQ‑32B等）。

**📈 对比分析**

与并行方法（Best‑of‑N、Self‑Consistency 等）及顺序方法（MR‑Thinking、Atom‑of‑Thoughts 等）在不同预算（N∈{8,16,32,64}）下对比，MarkovScale 在大多数场景下平均提升 5–20% 准确率，同时减少 30–70% 令牌消耗，达到 Pareto 最优权衡。

**⚠️ 局限性**

局限性包括：①模型假设为两状态马尔科夫链，忽略置信度等细粒度信息；②MAP 变体需离线训练预测器，增加预处理成本；③在极难任务或模型自校正能力弱时，转移概率估计不稳定，导致停止误判；④对不同 LLM 的泛化需要进一步验证。

---

## 176. Where to Attend: A Principled Vision-Centric Position Encoding with Parabolas

**arXiv ID:** 2602.01418 | [PDF](https://arxiv.org/pdf/2602.01418v1)

**作者:** Christoffer Koo Øhrstrøm `[一作]` (Technical University of Denmark), Lazaros Nalpantidis `[通讯]` (Technical University of Denmark)

**通讯引用:** 3558 | [OpenAlex ID](https://openalex.org/A5059750726)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了基于抛物线的视觉位置编码（PaPE）及其旋转不变版本 PaPE‑RI，并将其集成到 Transformer 中；

**💡 创新点**

利用抛物线形式统一实现距离衰减、方向性和上下文感知，并通过可学习系数兼容高效注意力；

**🔧 技术方法**

使用注意力 bias 的抛物线函数、RoPE‑style query‑key 变换、可学习的上下文系数以及在多模态数据集上的全面实验；

**📊 数据集**

在 8 个跨模态数据集上评估：图像（ImageNet‑1K、COCO）、点云（ScanNet、ModelNet40）、视频（UCF101）、事件相机（DvsGesture、GEN1）和多模态 nuScenes；

**📈 对比分析**

与 5 种基线（nD‑sincos、RoPE、RoPE‑Mixed、nD‑ALiBi、LookHere）比较，PaPE 在 6/8 数据集获得最高分，平均 66.3%（比 RoPE 高 1 分），并在 ImageNet‑1K 低分辨率训练后在高分辨率上实现显著超越；

**⚠️ 局限性**

主要缺点是随参数维度 m 增大导致额外参数量和推理延迟上升，并且 PaPE‑RI 牺牲方向性以获得旋转不变性，未来需要进一步降低 m 或去除 W_p 以提升效率。

---

## 177. Differential Vector Erasure: Unified Training-Free Concept Erasure for Flow Matching Models

**arXiv ID:** 2602.01089 | [PDF](https://arxiv.org/pdf/2602.01089v1)

**作者:** Zhiqi Zhang `[一作]` (Jilin University), Xuan Wang `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 8277 | [OpenAlex ID](https://openalex.org/A5078292155)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `40105733-5154-44cd-8090-a8cab9e64b07` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种训练无关的概念擦除方法 DVE，专门针对流匹配模型实现精确擦除

**💡 创新点**

通过构造概念间差分向量场，并利用投影选择性校正实现对目标概念的方向性去除，避免了全局过度擦除和额外微调

**🔧 技术方法**

差分向量场、投影选择性校正、预处理差分向量、早期阶段校正以及流匹配模型 FLUX 的 ODE 采样技术

**📊 数据集**

使用 FLUX.1-dev 模型，I2P（NSFW）、MSCOCO、ImageNet、Concept-prune（风格）、UnlearnDiffAtk（风格分类器）等数据集进行评估

**📈 对比分析**

与 CA、ESD、EraseAnything 等多种基准在 NSFW、对象和艺术风格擦除任务上对比，DVE 在曝光计数、FID、CLIP 以及攻击成功率方面均表现最优或竞争性强

**⚠️ 局限性**

仍需在每个时间步额外计算两次模型前向推理，阈值调参敏感，对极端高分辨率或多概念组合可能出现计算负担和轻微质量损失，且理论证明仅针对 FLUX 等流匹配模型

---

## 178. From drift to adaptation to the failed ml model: Transfer Learning in Industrial MLOps

**arXiv ID:** 2602.00957 | [PDF](https://arxiv.org/pdf/2602.00957v1)

**作者:** Waqar Muhammad Ashraf `[一作]` (University College London), Vivek Dua `[通讯]` (University College London)

**通讯引用:** 8157 | [OpenAlex ID](https://openalex.org/A5089416884)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文通过对660MW热电站空气预热器烟气差压数据的分析，比较了三种迁移学习驱动的模型更新方法（ETL、ALTL、LLTL）在不同批次大小（5天和8天）下对失效前馈ANN模型的更新效果。

**💡 创新点**

创新点在于系统评估批次大小对迁移学习更新策略的影响，并结合权重空间分布与SHAP特征重要性分析，首次为MLOps实践提供关于“模型可塑性 vs 稳定性”与计算成本的量化洞察。

**🔧 技术方法**

使用的技术包括：迁移学习（ETL、ALTL、LLTL）、前馈ANN、RMSE/R²评估指标、SHAP特征重要性、计算时间（超参数调优与训练）统计，以及对模型权重空间的Violin图可视化。

**📊 数据集**

数据集：两个月（1月与4月）收集的空气预热器操作变量（含烟气进出口温度、次级/主空气进出口温度、氧气进出口浓度），以10分钟或8分钟采样频率获得的烟气差压时间序列，用于训练、验证与模型更新。

**📈 对比分析**

比较方法：在训练后监测模型误差，触发模型更新后在4月剩余数据上重新评估RMSE/MAE/R²；同时记录权重空间变化与SHAP特征重要性；并统计超参数调优与训练耗时。结果显示：ETL在5天批次下预测误差最低（RMSE≈0.0564/0.0652），ALTL在8天批次下误差最低（RMSE≈0.0384/0.0315），LLTL在两批次均居中；权重空间发现最后一层权重宽度扩大，ALTL压缩隐藏层权重；特征重要性保持一致；计算时间方面，5天批次下ETL耗时最长，ALTL最快。

**⚠️ 局限性**

局限性：仅在单一工业案例与两种批次大小上验证，未覆盖更大范围的批次规模或多模型融合场景；对概念漂移的适应性仅在特定条件下验证，需进一步在不同工艺与更长时间跨度中检验；模型更新时仅调优学习率，未探索更全面的超参数空间。

---

## 179. DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas

**arXiv ID:** 2602.01326 | [PDF](https://arxiv.org/pdf/2602.01326v1)

**作者:** Zirui Wu `[一作]` (Peking University), Lingpeng Kong `[通讯]` (The University of Hong Kong)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了DreamOn框架，利用两种特殊状态（扩展与删除）实现Diffusion Language Model的可变长度生成，解决了固定长度掩码导致的代码填充性能下降问题。

**💡 创新点**

创新点在于：①不改动模型架构，通过训练时的状态增删扩展与削减机制实现长度控制；②采用轻量级数据增强与权重平衡，使模型能自适应预测并执行长度扩张与收缩；③在推理时引入广播式删除加速生成。

**🔧 技术方法**

技术：基于离散时间扩散模型（Dream-Coder、DiffuCoder），引入扩展/删除特殊符号；自监督训练时通过掩码合并、权重平衡优化损失；推理时动态控制掩码数量并使用广播删除。

**📊 数据集**

使用了OpenCoder SFT的教育说明子集（约110K个Python指令-解答对）进行微调；在HumanEval-Infilling和SantaCoder-FIM的代码填充基准上评估。

**📈 对比分析**

与传统固定长度Diffusion模型相比，DreamOn在HumanEval-Infilling平均提升26.4% pass@1；在SantaCoder-FIM中与Qwen2.5-Coder、Deepseek-Coder等顶尖自回归模型相当或更优，接近oracle长度性能。

**⚠️ 局限性**

局限性：目前仅验证在代码填充任务；扩展策略仅支持单一二倍扩张，若需要大幅扩展需多轮；训练与推理仍依赖经验启发式掩码合并与广播机制；未来需探索更丰富的扩张因子和显式长度预测。

---

## 180. Parallel Training in Spiking Neural Networks

**arXiv ID:** 2602.01133 | [PDF](https://arxiv.org/pdf/2602.01133v1)

**作者:** Yanbin Huang `[一作]` (Institute of Automation), Guoqi Li `[通讯]` (Institute of Automation)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了一种动态衰减神经元（DSN），在去除重置机制的同时支持并行训练并保持序列推理能力。

**💡 创新点**

创新点包括：①从功能视角拆解重置机制，提出在动态衰减下仍能实现非线性和膜电位控制；②设计可并行计算的因果卷积结构，满足并行训练与序列推理的三大条件；③在整数脉冲模式下实现更高效的训练与推理。

**🔧 技术方法**

采用动态衰减、因果1D卷积、整数脉冲激活、Surrogate梯度、Triton并行扫描等技术实现。

**📊 数据集**

使用的主要数据集包括图像分类（CIFAR-10/100、ImageNet、CIFAR10-DVS）、事件驱动视觉（CIFAR10-DVS）、时序预测（Metr-la、Pems-bay、Solar）、语言建模（WikiText-103）以及强化学习（IDP-v4、Hopper-v4、Walker2d-v4）等。

**📈 对比分析**

与PSN、Sliding‑PSN、LIF等对比，DSN 在训练速度上实现 25.6× 加速；在 30k 词长的语言建模中仍保持稳定性能；在多任务、多网络架构下均优于或与最优方法相当；能耗方面，脉冲率降低，整体能耗略低于 LIF。

**⚠️ 局限性**

局限性：动态衰减涉及浮点运算（卷积、Sigmoid），对硬件实现提出更高要求；在极大序列长度或极低功耗嵌入式场景下仍需进一步优化；目前尚未在真实 neuromorphic 硬件上验证。

---

## 181. Bifrost: A Much Simpler Secure Two-Party Data Join Protocol for Secure Data Analytics

**arXiv ID:** 2602.01225 | [PDF](https://arxiv.org/pdf/2602.01225v1)

**作者:** Shuyu Chen `[一作]` (Fudan University), Weili Han `[通讯]` (Fudan University)

**通讯引用:** 2297 | [OpenAlex ID](https://openalex.org/A5011724449)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种轻量级的两方安全数据连接协议，直接输出冗余消除后的共享表，支持后续安全多方计算分析。

**💡 创新点**

创新点在于仅使用 ECDH-PSI 与一次性双向洗牌（dual‑mapping）实现无 OPPRF、无 Cuckoo 负载，显著降低通信与回合数。

**🔧 技术方法**

采用椭圆曲线 Diffie‑Hellman 私集成（ECDH‑PSI）、可观测洗牌协议、加法秘密共享与 Curve25519 ECC。

**📊 数据集**

实验数据集包括真实世界的 Education Career Success、Breast Cancer Gene、Skin Cancer、a9a 及 ARCENE、MNIST、Tiny ImageNet、CelebA，亦合成 1‑100 GB 数据。

**📈 对比分析**

与 SOTA 冗余消除方案 iPrivJoin 及基于电路的 PSI 协议对比，在线阶段提升 2.5–22× 速度，通信量下降 84–89%，在两步安全分析流水线中避免误差爆炸，安全分析速度提升 1.6–2.8×，通信压缩 73%。

**⚠️ 局限性**

局限性包括仅在半诚实模型下安全；不直接支持非唯一键或非关键属性；未提供对恶意攻击的完整防护；对行数不一致需额外处理。

---

## 182. Lotus: Efficient LLM Training by Randomized Low-Rank Gradient Projection with Adaptive Subspace Switching

**arXiv ID:** 2602.01233 | [PDF](https://arxiv.org/pdf/2602.01233v1)

**作者:** Tianhao Miao `[一作]`, Lejun Zhang `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出 Lotus，一种自适应低秩子空间更新方法，显著加速大规模模型训练。

**💡 创新点**

创新点在于用单元梯度位移指标自适应切换子空间，并采用随机化 SVD 降低计算开销。

**🔧 技术方法**

技术包括随机化 SVD、路径效率比（ρ_t）判定、低秩梯度投影与自适应子空间切换。

**📊 数据集**

数据集包括 C4（预训练 LLaMA）和 8 个 GLUE 任务（微调 RoBERTa）。

**📈 对比分析**

与 GaLore、AdaRankGrad、Apollo 等方法对比，Lotus 在预训练速度提升 30%，显存减少 40%，微调准确率平均提升至约 87%/88%。

**⚠️ 局限性**

局限在于需手动设定阈值 γ 与验证间隔 η，且在极端梯度震荡场景下切换策略可能不稳定。

---

## 183. Boosting Point-supervised Temporal Action Localization via Text Refinement and Alignment

**arXiv ID:** 2602.01257 | [PDF](https://arxiv.org/pdf/2602.01257v1)

**作者:** Yunchuan Ma `[一作]` (University of Chinese Academy of Science), Qingming Huang `[通讯]` (University of Chinese Academy of Science)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出了一个文本细化与对齐（TRA）框架，利用视频描述的文本特征增强点监督的时序动作定位。

**💡 创新点**

创新点在于：① 通过点注释构建实体映射，利用实体记忆对生成的描述进行细化（PTR）；② 通过点级多模态对齐（PMA）实现视觉与语言特征在语义空间中的对齐，提升动作定位精度。

**🔧 技术方法**

主要技术包括预训练图像描述模型 BLIP‑2、文本编码器 XCLIP、实体检测模型 OWL‑V2、语义相似度模型 AngLE，以及基于点级对比学习的多模态对齐损失。

**📊 数据集**

实验数据集覆盖五个公开数据集：THUMOS'14、GTEA、BEOID、ActivityNet1.2 与 ActivityNet1.3。

**📈 对比分析**

与现有点监督或视频级弱监督方法相比，TRA 在 THUMOS'14 的平均 mAP（0.1:0.7）提升至 62.3%（约 2% 的提升），在 ActivityNet 上同样取得最高 mAP，并在多种基线上表现出良好的泛化能力。

**⚠️ 局限性**

局限性包括对预训练模型依赖度高，文本描述质量仍受视觉模型错误或模糊图像影响；此外，实体检测阈值的选择需要手工调参，可能在不同数据集间表现不一致。

---

## 184. A Statistical Theory of Gated Attention through the Lens of Hierarchical Mixture of Experts

**arXiv ID:** 2602.01468 | [PDF](https://arxiv.org/pdf/2602.01468v1)

**作者:** Viet Nguyen `[一作]`, Alessandro Rinaldo `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97`

**🎯 论文内容**

本文通过将门控注意力和多头自注意力等价为分层专家模型，建立其统计学习理论。

**💡 创新点**

创新点在于证明门控注意力能将样本复杂度从指数级降低到多项式级，并给出对应的强可识别条件。

**🔧 技术方法**

主要技术包括分层Mixture‑of‑Experts 表达、Voronoi 损失分析、PDE 交互分解以及类型‑1/2 可识别性证明。

**📊 数据集**

实验采用在[-1,1]^2 上的均匀采样生成的合成数据，并加入高斯噪声。

**📈 对比分析**

与传统多头自注意力对比，门控注意力在多样本下的 Voronoi 损失收敛速率约为 O(n^(-0.5))，远优于 O(n^(-0.12))。

**⚠️ 局限性**

局限性在于仅针对理想的 HMoE 生成模型进行理论推导，未验证对真实复杂任务的泛化及其他非线性激活位置的影响。

---

## 185. Disclose with Care: Designing Privacy Controls in Interview Chatbots

**arXiv ID:** 2602.01387 | [PDF](https://arxiv.org/pdf/2602.01387v1)

**作者:** Ziwen Li `[一作]` (Northeastern University), Tianshi Li `[通讯]` (Northeastern University)

**通讯引用:** 1327 | [OpenAlex ID](https://openalex.org/A5039928918)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了聊天机器人访谈中隐私控制的有效性，比较了无编辑、自由编辑和AI辅助编辑三种后编辑方式对PII泄露、数据质量与参与度的影响。

**💡 创新点**

创新点在于提出并验证AI辅助后编辑（使用LLM进行PII检测并给出替换/抽象建议）这一可视化、可操作的隐私保护机制，能够显著降低PII泄露而不牺牲数据质量。

**🔧 技术方法**

采用的技术包括基于GPT‑4.1/4o‑mini的对话生成与PII检测模块、Node.js + Express后端与前端交互界面，以及AWS S3加密存储实现安全数据管理。

**📊 数据集**

使用的研究数据集为188份在Prolific上收集的关于“AI在求职面试中的使用”访谈日志（包含完整的原始与编辑后对话记录）。

**📈 对比分析**

通过三组受试者的随机对照实验，利用ANOVA、t检验等统计方法评估PII泄露率、Response Quality Index (RQI) 与用户参与度；结果显示AI辅助编辑将PII泄露降低约41%且RQI与参与度无显著差异。

**⚠️ 局限性**

局限性包括样本规模有限且仅来自美国、仅针对单一敏感主题、PII风险相对低、缺乏跨文化或高风险领域的验证。

---

## 186. StoryState: Agent-Based State Control for Consistent and Editable Storybooks

**arXiv ID:** 2602.01305 | [PDF](https://arxiv.org/pdf/2602.01305v1)

**作者:** Ayushman Sarkar `[一作]`, Mohd Yamani Idna Idris `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了StoryState框架，实现显式故事状态管理并支持基于代理的精细页面编辑。

**💡 创新点**

将角色表、全局设定与页面场景拆分为持久化结构化状态，利用少量LLM代理进行状态维护、提示生成与一致性检查，从而实现无模型微调的跨页视觉一致性与可编辑性。

**🔧 技术方法**

使用LLM代理（如Gemini）生成文本，1Prompt1Story式训练免费图像后端以及结构化JSON状态管理和跨页面一致性检查等技术。

**📊 数据集**

构造了192本10页的故事书数据集，采用ConsiStory+协议生成，并利用GPT‑5.2生成故事与编辑场景。

**📈 对比分析**

与Gemini Storybook、1Prompt1Story进行对比，StoryState在一致性0.83、页面更改1.6页、交互回合3.1次、编辑时长74秒等指标上均优于1Prompt1Story，且仅次于Gemini的最高一致性。

**⚠️ 局限性**

局限性包括目前仅支持页面级编辑，缺乏细粒度对象/区域控制；对LLM与T2I后端依赖较大；在多轮连续编辑时仍可能出现一致性漂移。

---

## 187. Talk to Me, Not the Slides: A Real-Time Wearable Assistant for Improving Eye Contact in Presentations

**arXiv ID:** 2602.01201 | [PDF](https://arxiv.org/pdf/2602.01201v1)

**作者:** Lingyu Du `[一作]` (Delft University of Technology), Guohao Lan `[通讯]` (Delft University of Technology)

**通讯引用:** 1801 | [OpenAlex ID](https://openalex.org/A5009415566)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `e0540dec-d77f-42db-94ae-d039248f6393` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本论文提出了一套基于头戴式眼动仪的实时可穿戴系统，能够实时监测并反馈演讲者与观众的视线分布，帮助演讲者提升眼神接触的时长与分布均衡性。

**💡 创新点**

创新点包括：①提出Anchor‑Face识别策略，通过先选取高置信度面孔作为锚点，再利用相对位置推断目标面孔，实现低延迟且鲁棒的实时面孔识别；②基于实时视线分布动态生成简短、可执行的音频提示，直接嵌入演讲者的听觉通道。

**🔧 技术方法**

使用技术：头戴式眼动仪（Pupil Core）、面孔检测（YOLOv8n‑face）、面孔识别（Inception‑ResNet‑V1）、相对位置推断、实时语音提示（pyttsx3）以及基于Tkinter的用户界面。

**📊 数据集**

数据集：不使用公开数据集，而是在实验室收集的现场演讲场景视频与眼动数据，包含4位演讲者、24名听众，共两轮演讲。

**📈 对比分析**

方法对比：将Anchor‑Face策略与传统每帧完整识别的基线进行对比。实验结果显示识别准确率提升至93.3%（基线30.8%），平均延迟降低至28 ms（基线57 ms）。在用户研究中，眼神接触比例提升62.5%，视线分布熵提升17.4%，表明系统有效改善了演讲者的眼神交互表现。

**⚠️ 局限性**

局限性：音频提示在现场演讲中可能过于突兀，打断演讲者的专注；系统依赖头戴式眼动仪与耳机，使用体验受硬件舒适度与佩戴稳定性影响。

---

## 188. Organismal Agency and Rapid Adaptation: The Phenopoiesis Algorithm for Phenotype-First Evolution

**arXiv ID:** 2602.00978 | [PDF](https://arxiv.org/pdf/2602.00978v1)

**作者:** Nam H. Le `[一作]` `[通讯]` (University of Vermont), Nam H. Le (University of Vermont)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

实现了一种名为Phenopoiesis Algorithm的双重遗传算法，该算法在传统基因遗传之外增加了可遗传的表型模式（表观基因组），通过在个体生命周期内学习、记录并将成功的组合模式写回表观基因组，从而在跨代进化中实现更快的适应。

**💡 创新点**

创新点包括：①首次将“有机体能动性”转化为可执行的计算机制；②引入双重遗传通道（基因 + 表观基因组）；③在生命周期内实现自我写回（写回学习成果）；④利用可组合的原语库实现模式的可重用；⑤在实验中证明了表观基因组遗传显著提升了适应速度与多任务保持能力。

**🔧 技术方法**

采用了遗传算法、Baldwin效应的实现、表观基因组结构、原语组合与搜索、进化与学习的混合（双时间尺度）以及基于交叉与变异的种群演化流程。

**📊 数据集**

使用的“数据集”为合成的10×10二值网格任务，共五种目标形状（L、T、Plus、Cross、Square），并在实验中通过不同的环境切换速率（20、50、100代）构造多任务场景。

**📈 对比分析**

对比方法包括三种模型：基因中心（GENE）、Baldwin控制（BALDWIN）和Phenopoiesis（PHENO）。通过单任务收敛、灾难性遗忘率、环境切换后的恢复速度以及多任务平衡表现进行评估。结果显示，PHENO在适应速度上比GENE快3.4倍、比BALDWIN快1.8倍；在多任务实验中，PHENO实现91%均衡适应，而GENE仅70%；灾难性遗忘率从GENE的51%下降到PHENO的31%。

**⚠️ 局限性**

局限性包括：①实验仅在小规模合成网格任务上验证，尚未证明可扩展至更复杂或真实世界问题；②依赖手工定义的原语库，扩展性受限；③表观基因组的存储与传递成本在大规模系统中可能显著增加；④缺乏对生物学系统中真正表观遗传机制的生物学验证；⑤对不同学习策略与参数调优的鲁棒性仍待深入研究。

---

## 189. DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework

**arXiv ID:** 2602.00996 | [PDF](https://arxiv.org/pdf/2602.00996v1)

**作者:** Abhijit Chakraborty `[一作]` (Arizona State University), Vivek Gupta `[通讯]` (Arizona State University)

**通讯引用:** 1938 | [OpenAlex ID](https://openalex.org/A5100748239)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

引入一个去中心化的多智能体框架，通过共享自然语言日志进行协作，以完成跨文本、表格和图像的复杂问题回答。

**💡 创新点**

通过共享日志实现无规划器的分布式协作，允许各智能体自主产生、记录和验证中间推理，提升可解释性与鲁棒性。

**🔧 技术方法**

采用基于LLM的专用代理（表格、上下文、视觉、总结、验证），日志压缩与调度策略，以及学习式门控控制。

**📊 数据集**

在六个多模态/表格问答基准上评估：FinQA、TAT‑QA、WikiTableQuestions、FeTaQA、CRT‑QA 与 MultiModalQA。

**📈 对比分析**

与多种基线（Chain‑of‑Thought、AutoTQA、ReAcTable 等）比较，零调优下取得与或优于最高的准确率，尤其在长链与噪声场景中表现更稳健。

**⚠️ 局限性**

受限于序列化LLM调用导致延迟增加，日志容量受限且对极长或混乱的推理链表现下降，视觉/OCR误差检测率偏低。

---

## 190. Distilling Token-Trained Models into Byte-Level Models

**arXiv ID:** 2602.01007 | [PDF](https://arxiv.org/pdf/2602.01007v1)

**作者:** Zishuo Bao `[一作]` (Fuzhou University), Yucheng Lu `[通讯]` (NYU Shanghai)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种两阶段的知识蒸馏框架，将已训练好的基于子词的LLM转化为字节级语言模型(BLM)，并保持大部分原模型性能。

**💡 创新点**

创新点包括：① 用逐步蒸馏课程（嵌入对齐→联合蒸馏→边界学习）解决token与byte边界不匹配问题；② 引入“一字前瞻路由”与“JBP解码”实现字节级自回归；③ 通过Stage 2的全字节预测Fine‑Tuning，使模型能够端到端生成字节。

**🔧 技术方法**

技术主要有：Hierarchical Byte模型(H‑Net)、动态分块（Mamba2编码器）、多阶段损失函数（Embedding Alignment、Distill、Boundary Loss）、一次性对齐+对齐后冻结策略、字节级解码策略（Joint Boundary Prediction）以及On‑Policy Distillation。

**📊 数据集**

使用FineWeb数据集（约125B字节总量），Stage 1使用30B字节（约7B token），Stage 2再使用95B字节。

**📈 对比分析**

与BLT、ALM、H‑Net Distill等基线相比，本文方法在Llama‑3.2 3B与Qwen‑3 4B上平均性能下降仅1.15~1.71分，显著低于BLT（7.34）和ALM（4.50），并且只需125B字节即可达到与教师模型92%以上的性能，表现优异。

**⚠️ 局限性**

局限性包括：① 仍需大量数据（125B字节）且在更大模型上验证有限；② 对分块策略的依赖导致在极长文本或特殊格式下可能出现边界误差；③ 对不同语言或字符集的鲁棒性未作系统评估。

---

## 191. DIAMOND: Directed Inference for Artifact Mitigation in Flow Matching Models

**arXiv ID:** 2602.00883 | [PDF](https://arxiv.org/pdf/2602.00883v1)

**作者:** Alicja Polowczyk `[一作]` (Silesian University of Technology), Przemysław Spurek `[通讯]` (IDEAS Research Institute)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `40105733-5154-44cd-8090-a8cab9e64b07` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种零训练、推理时的轨迹校正方法（DIAMOND），通过在生成过程中实时检测并修正视觉缺陷，消除 Rectified Flow 与 Diffusion 模型产生的结构性和异常内容缺陷。

**💡 创新点**

创新点在于：①在生成过程中利用估计的干净样本实现可微的缺陷检测；②将梯度归一化与可调时间调度相结合，实时引导生成轨迹远离缺陷状态；③实现了不需模型微调、可直接应用于多种主流流式与扩散模型的零样本修复。

**🔧 技术方法**

采用预训练的 Artifact Detector（如 DiffDoctor）、VAE 解码、梯度归一化、时间调度（Power schedule）以及对 Flow Matching 与 Diffusion 公式的统一改写，实现了在推理阶段的轨迹校正。

**📊 数据集**

使用 DiffDoctor 提供的文本提示集合（人类、单词、动物各 100/26 句）生成包含缺陷的图像集，并在 FLUX.2/FLUX.1/SDXL 等模型上进行评估。

**📈 对比分析**

与 HandsXL、DiffDoctor、HPSv2 等方法对比，DIAMOND 在 Mean Artifact Frequency、Artifact Pixel Ratio、ImageReward 以及 CLIP‑T 等指标上均表现为最低缺陷率、最高视觉质量与提示一致性，且保留原图结构，性能优异。

**⚠️ 局限性**

局限性主要在于对 Artifact Detector 的依赖；若缺陷未被正确识别，校正效果可能不佳；此外在极端噪声或非常细粒度缺陷时，梯度归一化与时间调度可能不足以完全消除缺陷。

---

## 192. Stronger Semantic Encoders Can Harm Relighting Performance: Probing Visual Priors via Augmented Latent Intrinsics

**arXiv ID:** 2602.01391 | [PDF](https://arxiv.org/pdf/2602.01391v1)

**作者:** Xiaoyan Xing `[一作]` (University of Amsterdam), Anand Bhattad `[通讯]` (Johns Hopkins University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究图像到图像重光照任务，探讨视觉编码器对光照重现的影响，提出将预训练视觉先验融入潜在内在表示的 Augmented Latent Intrinsics (ALI) 方法，以提升重光照效果。

**💡 创新点**

系统揭示更强语义编码器会降低重光照质量的现象；提出平衡语义抽象与光照保真度的ALI框架，将像素级视觉先验与潜在内在特征融合，并通过三阶段无监督训练提升性能。

**🔧 技术方法**

使用潜在内在表示、扩散式解码器（LumiNet）、预训练视觉编码器（RADIO、MAE 等）、自监督伪光照数据生成、自适应投影融合、层次化特征对齐等技术。

**📊 数据集**

在 MIT Multi-Illuminant (MIIW) 数据集（985 场景/25 光照）、BigTime 数据集（460 场景/20–50 自然光照）以及未标注的真实图像对上进行训练和评估。

**📈 对比分析**

与多种基准（SA‑AE、Latent‑Intrinsic、RGB↔X、LumiNet 等）对比，在 MIIW 测试集上获得 SSIM 提升 4.9% 和 RMSE 降低 4.5%，显著优于其他扩散模型；在材料分级和现场重光照指标上亦表现最佳，并在人工评估中取得较高分数。

**⚠️ 局限性**

仍存在细节漂移、色彩与光照混淆、阴影受先验引导以及对极端透明/高反射物体处理有限等局限，难以完全消除光照与材质歧义。

---

## 193. Typologically-Informed Candidate Reranking for LLM-based Translation into Low-Resource Languages

**arXiv ID:** 2602.01162 | [PDF](https://arxiv.org/pdf/2602.01162v1)

**作者:** Nipuna Abeykoon `[一作]` (ZWAG AI Ltd), Parameswari Krishnamurthy `[通讯]` (ZWAG AI Ltd)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了Universal Metalinguistic Framework（UMF），通过语言典型化的16维度描述与差异度量，在不需要并行语料或模型再训练的前提下，作为推理时的候选重新排序层，显著提升低资源语言的翻译结构准确性。

**💡 创新点**

创新点在于将语言学典型知识转化为可量化的“directive vector”，并将其与LLM生成的多候选输出进行联合评分，从而实现对词义歧义和结构偏差的同时纠错，形成了首个在推理阶段直接利用典型学的全流程框架。

**🔧 技术方法**

技术上使用了：①基于World Atlas of Language Structures的16维典型化语言配置文件；②差异度量与加权归一化生成指令向量；④通过semantic constraints层对多义词进行上下文感知的logit调节；⑤在typological scoring层对候选进行基于表面特征的结构合规评分；⑥最终通过α混合系数实现模型概率与典型合规得分的线性组合。

**📊 数据集**

数据集包括由语言专家精心设计的341条英语句子（涵盖形态学与句法多样性），覆盖九个目标语言（Sinhala、Tamil、Thai、Chinese、Hindi、Japanese、Arabic、French、Swahili），以及对应的语言典型配置文件；实验还使用GPT‑5.2和mT5两种主流LLM生成32候选。

**📈 对比分析**

与基线（仅模型最高概率输出）相比，UMF在高典型距离语言（如Sinhala、Hindi、Arabic、French）实现了介于0.8‑1.1的Gain‑Risk比，Intervention Precision均超过80%，Change Rate与典型距离呈显著正相关（r=0.82），但在形态学密集语言（Sinhala、Tamil）和保守处理语言（Thai、Swahili）表现出较低的Gain‑Risk与精度。

**⚠️ 局限性**

主要局限在于：①语言典型配置缺乏足够的细粒度与互依关系，导致在形态学丰富语言中的错误频发；②对干预阈值的统一设定缺乏语言特异性，导致不同语言的精确度差异；③当前仅在后处理阶段使用，未探究与生成过程的联合约束；④错误分类仍较粗，缺少更细化的子类别分析。

---

## 194. Synapse Compendium Aware Federated Knowledge Exchange for Tool Routed LLMs

**arXiv ID:** 2602.00911 | [PDF](https://arxiv.org/pdf/2602.00911v1)

**作者:** Abhijit Chakraborty `[一作]` (Arizona State University), Vivek Gupta `[通讯]` (Arizona State University)

**通讯引用:** 1938 | [OpenAlex ID](https://openalex.org/A5100748239)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c84dae5d-5273-4348-85a7-b44cb586b4df` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种基于工具汇编（compendium）的联邦学习框架（Synapse），实现LLM代理在不共享原始数据的前提下进行工具使用模式的协同学习与路由。

**💡 创新点**

创新点在于：①引入结构化、分层的工具汇编作为知识单元，替代传统参数或提示共享；②采用分层聚合（客户端→边缘聚合器→中心服务器）与文本梯度优化（TextGrad）提升表达能力与鲁棒性；③通过LLM重排序与嵌入检索实现高效、可解释的工具路由。

**🔧 技术方法**

主要技术包括：联邦检索增强生成（Federated RAG）、文本梯度优化、嵌入检索与LLM重排序、差分隐私加噪与自适应文本掩码、分层聚合与去重、工具调用与执行。

**📊 数据集**

实验使用BBH（对象计数、多步算术）和GSM8k数学问题数据集，在多客户端（5–8）联邦设置下进行评估。

**📈 对比分析**

与基线（Prompt/参数共享、中央检索、Fed‑ICL等）比较，Synapse在工具路由准确率上达到92–93%，显著优于提示共享方法，通信开销和延迟保持在可接受范围内，且在非IID分布下仍能维持高一致性。

**⚠️ 局限性**

局限性包括：仅假设诚实好奇型客户端，未对Byzantine攻击或恶意注入具备鲁棒性；差分隐私与掩码参数需手动调优；当前仅针对工具路由任务验证，需进一步推广至多模态或推荐系统等场景。

---

## 195. The structure and enumeration of periodic binary sequences with high nonlinear complexity

**arXiv ID:** 2602.01134 | [PDF](https://arxiv.org/pdf/2602.01134v1)

**作者:** Qin Yuan `[一作]` (Hubei University), Xiangyong Zeng `[通讯]` (Hubei University)

**通讯引用:** 2723 | [OpenAlex ID](https://openalex.org/A5029996403)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

本文对长度为 n 的周期性二进制序列中非线性复杂度大于等于 ⌈n/2⌉ 的序列进行了结构分析和精确计数，给出了其唯一代表序列、结构形式以及枚举公式。

**💡 创新点**

创新点在于：①证明了在此复杂度阈值下，生成周期序列的有限序列必为唯一代表序列；②给出了该阈值下所有周期序列的完整结构描述；③导出了精确的枚举公式并提供了紧确的下界，验证了之前统计近似结果。

**🔧 技术方法**

技术手段主要包括非线性复杂度定义、反馈移位寄存器 (NFSR) 的结构分析、循环移位与等价类研究、线性代数求秩、莫比乌斯反演求计数、递推与组合计数。

**📊 数据集**

由于研究是理论性的，没有使用真实数据集；示例采用 n=16, ω=12 的计算验证枚举结果，结果与穷举搜索一致。

**📈 对比分析**

与 Erdmann‑Murphy 的近似概率分布对比，本文提供的精确概率与枚举数吻合；在可行范围内计算复杂度低，能快速得到序列数量和概率，验证了近似方法的准确性。

**⚠️ 局限性**

局限性：仅适用于非线性复杂度大于等于 ⌈n/2⌉ 的情况；阈值以下的序列无法确定唯一代表序列，且枚举公式不适用；此外，对更高阶随机性指标（如 k‑错误复杂度、相关性）尚未展开。

---

## 196. From Utterance to Vividity: Training Expressive Subtitle Translation LLM via Adaptive Local Preference Optimization

**arXiv ID:** 2602.01068 | [PDF](https://arxiv.org/pdf/2602.01068v1)

**作者:** Chaoqun Cui `[一作]` (Chinese Academy of Sciences), Wenji Mao `[通讯]` (Chinese Academy of Sciences)

**通讯引用:** 3120 | [OpenAlex ID](https://openalex.org/A5035983004)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

研究字幕翻译的自由（liberal）与字面（literal）翻译，验证LLM可作为评估者/奖励模型，并提出ALPO方法训练具有表现力与生动度的字幕翻译LLM。

**💡 创新点**

①首次系统化比较字幕翻译与其他领域的自由度并验证LLM评估可靠性；②提出基于过程监督的局部偏好对齐算法ALPO；③公开多语言多方向字幕并行语料库。

**🔧 技术方法**

使用LLM-as-a-Judge评估、RLHF、DPO、过程监督的局部偏好优化(ALPO)、动态β调节、前缀混合等技术。

**📊 数据集**

自制MuSC多语言字幕平行语料库（含zh↔en、zh↔de、zh↔th等多方向），来源于优酷；并使用公开领域语料（新闻、法律、医学等）做对比。

**📈 对比分析**

与VideoDubber、NLLB‑3.3B、MADLAD‑10B、Google Translate、GPT‑4o、Qwen‑Max、DeepSeek‑R1、GPT‑5等基线在准确性、自然度、生动度三维度评估；ALPO 14B在所有维度均优于SOTA，尤其生动度显著提升，甚至在低资源方向超越其他LLM；人类评估也证实提升。

**⚠️ 局限性**

仅验证于字幕翻译场景，泛化至其他视觉文本未知；模型仍受语言资源、句子长度和文化差异影响；评估依赖LLM，可能存在偏差；缺乏大规模人工评测和多任务扩展。

---

## 197. VEQ: Modality-Adaptive Quantization for MoE Vision-Language Models

**arXiv ID:** 2602.01037 | [PDF](https://arxiv.org/pdf/2602.01037v1)

**作者:** Guangshuo Qin `[一作]` (Shanghai Jiao Tong University), Yulun Zhang `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 22300 | [OpenAlex ID](https://openalex.org/A5074865219)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `afceb026-1760-41ae-8d86-010831a37d97` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种针对Mixture-of-Experts视觉-语言模型的后训练量化框架——Visual Expert Quantization（VEQ），通过兼顾跨模态差异和专家异质性实现权重量化压缩。

**💡 创新点**

创新点在于引入模态-专家感知量化（VEQ-ME）和模态-亲和感知量化（VEQ-MA），利用专家激活频率、梯度比例和路由亲和度构造加权目标与改进的Hessian矩阵，实现对关键专家和重要模态的精细量化。

**🔧 技术方法**

采用后训练量化技术，基于AWQ与GPTQ框架，结合专家重要性分数、梯度比例因子、路由亲和度以及加权Hessian矩阵的重构，进行权重量化。

**📊 数据集**

使用Kimi‑VL‑Instruct和Qwen3‑VL‑30B‑A3B‑Instruct两大MoE VLM模型，在MMMU、MME‑RealWorld、MMBench、InfoVQA、TextVQA、RealWorldQA、ScienceQA、VizWiz‑VQA等多模态基准上进行评估，并以COCO等图像数据集作为量化校准集。

**📈 对比分析**

与BF16、RTN、AWQ、GPTQ、MBQ等基线在3位和4位权重量化下进行对比；在3位下平均提升约2.0%–3.1%，在4位下提升约0.6%–1.2%，在所有基准上保持较高的准确率，显示出显著的性能优势。

**⚠️ 局限性**

局限性包括：在极低位宽下仍可能出现性能退化；依赖校准数据质量与分布；未提供在线动态调优机制；在不同硬件平台上推理效率差异仍需进一步验证。

---

## 198. The Enhanced Physics-Informed Kolmogorov-Arnold Networks: Applications of Newton's Laws in Financial Deep Reinforcement Learning (RL) Algorithms

**arXiv ID:** 2602.01388 | [PDF](https://arxiv.org/pdf/2602.01388v1)

**作者:** Trang Thoi `[一作]` (Virginia Polytechnic Institute and State University), Huaiyang Zhong `[通讯]` (Virginia Polytechnic Institute and State University)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `5a41884c-404f-4688-a89c-aa238c10fe68` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文提出一种将物理启发式约束（牛顿第二定律）嵌入Kolmogorov–Arnold网络（PIKAN）的强化学习框架，用于多资产组合优化。

**💡 创新点**

创新点在于将牛顿动力学的加速度-力关系作为正则化损失，并将传统多层感知机替换为参数高效、可解释的KAN，从而实现对金融时间序列的物理先验约束。

**🔧 技术方法**

主要技术包括Physics‑Informed Kolmogorov‑Arnold Networks（PIKAN），多策略actor‑critic算法（DDPG、PPO、TD3、A2C）以及基于B‑spline的可学习单变量函数构建网络；同时引入自适应权重、指数移动平均和交易成本正则化。

**📊 数据集**

使用了三大国际股市的历史日数据：中美沪深300指数（CSI 300）、越南VN100指数和美国S&P 100指数，各自包含10只流动性资产，训练期为2015‑01‑01至2023‑01‑01，测试期为2023‑01‑02至2025‑01‑01。

**📈 对比分析**

与传统DRL基线（PPO、TD3、DDPG等）和经典在线组合选择方法（UBAH、CRP等）对比，PIKAN版在所有三市均实现了更高的累计收益、年化收益和夏普/Calmar比，并显著降低最大回撤，表现出更稳健的收益路径。

**⚠️ 局限性**

局限性包括物理模型的简化（忽略流动性、微观结构等复杂因素）、对KANN超参数的敏感性以及在极端市场环境下牛顿先验可能不适用，需进一步验证更丰富的金融先验或多资产/风险敏感扩展。

---

## 199. Assessing and Comparing the Coverage of Publications of Italian Universities in OpenCitations

**arXiv ID:** 2602.00912 | [PDF](https://arxiv.org/pdf/2602.00912v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `f53a5690-f5d8-493f-989c-dc46a1f99053`

---

## 200. SkySim: A ROS2-based Simulation Environment for Natural Language Control of Drone Swarms using Large Language Models

**arXiv ID:** 2602.01226 | [PDF](https://arxiv.org/pdf/2602.01226v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

---

## 201. Statistical MIA: Rethinking Membership Inference Attack for Reliable Unlearning Auditing

**arXiv ID:** 2602.01150 | [PDF](https://arxiv.org/pdf/2602.01150v1)

**作者:** Jialong Sun `[一作]` (Shenzhen University of Advanced Technology), Bo Liu `[通讯]` (Shenzhen University of Advanced Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种无训练的成员推断攻击（SMIA）框架，用统计方法直接比较成员、非成员与遗忘样本的分布差异，从而审核机器学习模型的遗忘效果。

**💡 创新点**

理论证明传统MIA审核存在不可避免的统计误差；引入SMIA，利用分布距离（低阶矩、MMD、Wasserstein）并给出置信区间；提供三种实现变体并在白盒场景中验证。

**🔧 技术方法**

统计分布距离度量（低阶矩、最大均值差距MMD、正则化Wasserstein），核嵌入、梯度特征提取、Bootstrap置信区间、Sinkhorn算法。

**📊 数据集**

CIFAR‑10、CIFAR‑100、CINIC‑10 数据集，并使用官方 Unlearning Auditing Benchmark 进行实验。

**📈 对比分析**

与现有MIA基线（Logit、Unleak、EMIA、LiRA、IMA）进行对比。SMIA‑M 在随机样本/类别遗忘任务中准确率近 100%，显著优于对手；计算成本低于需要训练 Shadow 模型的方法，SMIA‑0 也表现良好。

**⚠️ 局限性**

SMIA‑W 在实际实验中效果不佳；在极小样本或异常样本情况下仍可能受到噪声影响；白盒实现依赖特定特征（如梯度），对黑盒场景的适用性待进一步研究。

---

## 202. Learning Abstractions for Hierarchical Planning in Program-Synthesis Agents

**arXiv ID:** 2602.00929 | [PDF](https://arxiv.org/pdf/2602.00929v1)

**作者:** Zergham Ahmed `[一作]` (Harvard University), Samuel J. Gershman `[通讯]` (Harvard University)

**通讯引用:** 20557 | [OpenAlex ID](https://openalex.org/A5031715686)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6`

**🎯 论文内容**

提出TheoryCoder-2，一种能够自主学习并复用抽象概念的理论基础强化学习（TBRL）代理

**💡 创新点**

实现了无需人工编码的高层抽象生成与库增量学习，显著提升跨任务的样本效率与泛化能力

**🔧 技术方法**

结合大语言模型的上下文学习、PDDL高层规划、Python低层世界模型与基于BFS的实现

**📊 数据集**

在BabyAI、Minihack、VGDL游戏（如Sokoban、Labyrinth、Maze）等离散对象导向环境中评估

**📈 对比分析**

与LLM+π、LLM+P、WorldCoder、TheoryCoder等基线对比，TheoryCoder-2在token成本、计算时间和成功率上均优于基线，尤其在复杂Boss级任务中表现突出

**⚠️ 局限性**

仍依赖文本化对象表示、难以处理连续空间或视觉感知；谓词分类器易出现不稳定，且对极端陌生环境的适应性有限

---

## 203. Efficient Deep Learning for Medical Imaging: Bridging the Gap Between High-Performance AI and Clinical Deployment

**arXiv ID:** 2602.00910 | [PDF](https://arxiv.org/pdf/2602.00910v1)

**作者:** Cuong Manh Nguyen `[一作]` (University of Alabama at Birmingham), Truong-Son Hy `[通讯]` (University of Alabama at Birmingham)

**通讯引用:** 213 | [OpenAlex ID](https://openalex.org/A5073178563)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `8d10c613-917e-4880-9716-17789f50e119` `e15e3743-5ee0-4d5f-813d-d146868082fc` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f` `7b0f05dc-d396-4b03-96d2-a379dbd5049d`

**🎯 论文内容**

综述了医疗影像领域的高效深度学习模型（CNN、轻量Transformer、线性复杂度State Space模型）及其压缩技术（剪枝、量化、知识蒸馏、低秩分解），并探讨了这些技术在资源受限临床环境中的部署挑战和实践路径。

**💡 创新点**

从架构演进角度提出了三大分类（CNN、Hybrid、SSM），结合医学应用场景构建了“部署第一”评估框架，并提供了针对硬件端评测与安全校准的报告清单，推动了从理论效率到实际可部署性的系统化思考。

**🔧 技术方法**

采用了文献综述方法，系统梳理并对比了多种模型与压缩策略；同时通过已公开的硬件延迟、参数量、能耗等指标进行实证对比，并在多个平台（iPhone 12 NPU、NVIDIA Jetson、CPU/GPU）上进行性能测评。

**📊 数据集**

引用的实验案例主要使用公开医学影像数据集（如ImageNet、CT、MRI、US、WSI）以及各类临床试验数据，覆盖分类、分割、检测等任务；综述本身不做新的数据集收集。

**📈 对比分析**

对比方法以模型参数、FLOPs、GPU/CPU/NPU延迟、能耗、内存占用为核心指标；结果显示：轻量CNN在移动NPU上可实现<1 ms推理；Hybrid模型在保持接近CNN速度的同时提供全球上下文；SSM模型在参数和能耗上最低，但缺乏统一硬件验证，实际延迟受限于自定义算子支持。

**⚠️ 局限性**

主要局限包括：缺乏统一的部署评测基准，导致跨平台比较不一致；SSM模型的自定义算子在主流推理框架中的支持不足；压缩技术可能导致稀有病变检测灵敏度下降；总体而言，模型性能与硬件环境高度耦合，需在具体设备上进一步验证。

---

## 204. Don't Judge a Book by its Cover: Testing LLMs' Robustness Under Logical Obfuscation

**arXiv ID:** 2602.01132 | [PDF](https://arxiv.org/pdf/2602.01132v1)

**作者:** Abhilekh Borah `[一作]` (Manipal University), Kripabandhu Ghosh `[通讯]` (Indian Institute of Science Education and Research)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一种结构保留、等价保留的逻辑混淆算法 Logifus，并基于此构建了首个逻辑混淆诊断基准 LogiQAte，涵盖四类推理任务；

**💡 创新点**

创新点在于通过等价重写将问题表面形式改变而不改变逻辑真值，从而严苛检验 LLM 在逻辑推理中的真正理解能力；

**🔧 技术方法**

主要技术包括逻辑等价变换（如德摩根律、双重否定）、关系隐写（多跳亲属链）、数列符号替换（行星名、ASCII 和 MD5 变换）以及空间混淆（自消向量插入），以及对 LLM 进行层级置信度与记忆化敏感性分析；

**📊 数据集**

使用了 1,108 条人工核对的混淆样本，覆盖 Obfus FOL、Obfus Blood Relation、Obfus Number Series、Obfus Direction Sense 四个任务，源数据来自 FOLIO、教育平台和标准数列库；

**📈 对比分析**

与 9 个主流 LLM（包括 GPT‑5、Claude 3.7、o4‑mini、Gemini 2.5 Pro、Qwen QwQ‑32B 等）在零样本、少样本和链式推理设置下进行比较，发现逻辑混淆使得模型平均准确率下降 18.7%–48.7%，一般型模型下降约 45%–50%，推理型模型下降约 20%–30%；

**⚠️ 局限性**

局限性包括仅在英文数据上评测、任务覆盖面有限、对多语言和更丰富推理范式的适应性待扩展，且混淆策略对模型外部知识依赖的影响尚未深入探究。

---

## 205. Optimal Budgeted Adaptation of Large Language Models

**arXiv ID:** 2602.00952 | [PDF](https://arxiv.org/pdf/2602.00952v1)

**作者:** Jing Wang `[一作]` (National Library of Medicine), Jeremy C Weiss `[通讯]` (National Library of Medicine)

**通讯引用:** 2210 | [OpenAlex ID](https://openalex.org/A5072774346)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出一种基于Stackelberg博弈的预算感知LLM微调框架，并设计两种算法StackSL和LLF-StackSL，在有限标注预算下实现无后悔学习。

**💡 创新点**

将监督微调视为Stackelberg游戏，引入LLF置信门控策略实现标签预算控制，并在完整反馈下证明O~(d√T) regret，在预算下证明O~(√(dB)+c√B) regret。

**🔧 技术方法**

采用线性评分头+LLM特征、UCB置信区间、KL正则、损失剪裁、LLF门控、LoRA/PEFT、梯度下降等技术，并结合上下文线性多臂老虎机理论进行分析。

**📊 数据集**

使用医学单项选择数据集MedQA和多学科知识基准MMLU进行实验，同时在合成线性Bandit设置中进行模拟验证。

**📈 对比分析**

与标准SFT、MC‑Ranker等基线对比，Full StackSL在MedQA上准确率0.381，对比MC‑Ranker的0.368；LLF‑StackSL在0.10预算下仍保留约94%性能；合成实验显示LLF在预算下接近全信息表现。

**⚠️ 局限性**

依赖线性评分假设和固定/轻微更新的特征表示；预算控制在极低预算下会显著降低性能；LoRA/PEFT仅更新少量参数，无法捕捉更深层动态，且对LLM的鲁棒性尚待进一步验证。

---

## 206. LMTE: Putting the "Reasoning" into WAN Traffic Engineering with Language Models

**arXiv ID:** 2602.00941 | [PDF](https://arxiv.org/pdf/2602.00941v1)

**作者:** Xinyu Yuan `[一作]` (Zhejiang University), Wenzhi Chen `[通讯]` (Zhejiang University)

**通讯引用:** 3998 | [OpenAlex ID](https://openalex.org/A5101562846)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出并实现了基于预训练大型语言模型（LLaMA系列）的宽域网流量工程框架Lmte，理论证明LM可模拟TE决策过程并实现并行推理，并在多种真实与合成网络拓扑上取得优异的最大链路利用率与计算速度。

**💡 创新点**

创新点包括：①从理论上证明LM具有足够的表达与对数层深度的并行推理能力，能够高效模拟可解自动机的TE决策；②设计跨模态对齐与任务特定Prompt的轻量化适配方案，使LM保持原有知识且仅训练约1%的参数；③通过共享头网络实现大规模网络的可扩展性与实时性。

**🔧 技术方法**

采用的技术主要有：预训练Transformer（LLaMA），图神经网络（GNN）与循环网络（RNN）编码网络，跨注意力对齐模块，任务特定Prompt设计，端到端微调以及自动机理论分析。

**📊 数据集**

使用的数据集包含三张真实WAN拓扑（US Internet2/Abilene、CERNET、GÉANT）及两张大规模拓扑（Cogentco、UsCarrier），每个拓扑对应的流量矩阵；此外，还通过重力模型生成了非平稳合成流量序列。

**📈 对比分析**

实验通过与两种ML驱动方法（DOTE、FIGRET）和三种优化方法（COPE、Oblivious、Gurobi‑Pred）比较，Lmte在五个拓扑上平均降低8%–15%最大链路利用率，并在链路失效、流量突发、分布漂移等未见场景下表现稳健；相对传统LP求解器实现了10–100倍的加速。

**⚠️ 局限性**

限制包括：仍需加载大规模LM参数，推理时耗时相对较高；对极端分布漂移或极大拓扑可能需要更多微调；目前仅针对最大链路利用率目标，未覆盖多目标或QoS约束；理论证明的假设在实际网络中可能不完全成立。

---

## 207. On Normality and Equidistribution for Separator Enumerators

**arXiv ID:** 2602.01199 | [PDF](https://arxiv.org/pdf/2602.01199v1)

**作者:** Subin Pulari `[一作]` `[通讯]` (National Research University Higher School of Economics), Subin Pulari (National Research University Higher School of Economics)

**关键词:** `33d19632-8af2-4683-a5db-767c7ce749e6`

**🎯 论文内容**

本文研究了分隔符枚举器与f-正态性之间的关系，提出了一个强有力的否定答案，构造了两个可计算的分隔符枚举器f_0和f_1，以及一个点x，使得对于所有n，a_n^f_0(x)=a_n^f_1(x)，但^f_0_FS(x)=0而^f_1_FS(x)=1。

**💡 创新点**

创新点在于证明了没有任何仅依赖于序列(|Σ|^n a^f_n(x))_n=0^∞的标准可以均匀地表征f-正态性，特别是没有任何均匀分布性质可以实现这一点。同时，在有限状态一致的分隔符枚举器的自然结构限制下，恢复了f-正态性的完整均匀分布特征。

**🔧 技术方法**

使用了分隔符枚举器、有限状态转导器和相对有限状态维度等技术，构建了两个特定的可计算分隔符枚举器，并通过它们的性质进行比较。

**📊 数据集**

论文中没有具体提到使用的数据集，但构造的分隔符枚举器是基于理论构建的，主要涉及数学和计算理论的概念。

**📈 对比分析**

通过构造两个具有相同最佳下界链但相对有限状态维度不同的分隔符枚举器，证明了均匀分布性质无法表征f-正态性。对于有限状态一致的分隔符枚举器，恢复了f-正态性的均匀分布特征，表明在特定条件下可以实现均匀分布的表征。

**⚠️ 局限性**

限制在于，虽然在有限状态一致的分隔符枚举器下可以实现f-正态性的均匀分布特征，但在更广泛的分隔符枚举器中，无法通过单一的数值序列特性来表征f-正态性。

---

## 208. EverMemBench: Benchmarking Long-Term Interactive Memory in Large Language ModelsEverMemBench: Benchmarking Long-Term Interactive Memory in Large Language Models

**arXiv ID:** 2602.01313 | [PDF](https://arxiv.org/pdf/2602.01313v1)

**作者:** Chuanrui Hu `[一作]` (EverMind), Yafeng Deng `[通讯]` (Shanda Group)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了EverMemBench，一个针对多方多组对话、跨主题、时间演进和角色个性化的长期会话记忆基准；

**💡 创新点**

创新点在于：①真实多方跨组对话的高信息密度、跨主题交织和动态知识更新；②将记忆能力拆分为细粒度回忆、记忆意识和用户画像理解三维度；③构建三阶段数据生成与评估流程，并加入三阶段质控，保证数据一致性和难度；

**🔧 技术方法**

技术包括：LLM（Gemini‑2.5‑Pro）进行蓝图、对话和QA生成；层级摘要压缩多日历史；检索式记忆（top‑k、事件边界分块等）与大语言模型集成；LLM‑judge 评估答案的语义等价；多阶段自动化与人工审核质控；

**📊 数据集**

使用自研的合成数据集：5个项目、3个子项目、20‑60人团队、约1百万token的多方对话，包含时间戳、角色信息、跨主题交互；QA集共1000+题，按三维度划分；

**📈 对比分析**

比较方法：对比 2 类模型（全上下文 LLM 与记忆增强系统）以及不同检索策略（包括 Oracle、top‑k、EverMemOS 事件分块等）；实验显示：多跳推理在多方环境下大幅下降；时间推理仍差；记忆意识受检索质量制约；强模型在记忆检索下有时会下降，显示检索精度是新瓶颈；

**⚠️ 局限性**

局限性：①数据为合成而非真实人类对话，可能缺少自然语气与隐含社交线索；②聚焦工作协作场景，可能不适用于个人助理、社交或教育等其他领域；

---

## 209. LocalScore: Local Density-Aware Similarity Scoring for Biometrics

**arXiv ID:** 2602.01012 | [PDF](https://arxiv.org/pdf/2602.01012v1)

**作者:** Yiyang Su `[一作]` (Michigan State University), Xiaoming Liu `[通讯]` (University of North Carolina Chapel Hill)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种利用k‑最近邻局部密度的分数融合方法，用于提升多样本数据库下的开放式生物识别检索与验证。

**💡 创新点**

创新点在于：①只考虑局部邻域而非全局平均，捕捉主体内的多模态变异；②将k‑NN得分仅加到最匹配主体的分数上，避免全局分数膨胀；③方法与网络架构、损失函数无关，几乎无额外开销，可直接插拔。

**🔧 技术方法**

技术手段：k‑NN局部得分计算、选择性融合、可选的聚类压缩、理论误差界分析及蒙特卡洛验证；实现只需一行代码。

**📊 数据集**

使用多模态数据集：面部（IJB‑S、BRIAR）、步态（Gait3D、CCPG）、行人重识别（CCVID、BRIAR）以及全身识别（FarSight）。

**📈 对比分析**

与传统平均/最大/最小聚合以及重排序等方法比较，实验显示：FNIR@FPIR由53%降至40%，TAR@FAR从51%提升到74%，在所有三大模态上均实现显著提升；在1:1验证设置和大规模真实部署中同样表现优异。

**⚠️ 局限性**

局限性：依赖完整的多样本图库；需要选择k值，过大时可能误入非同一主体邻域；对极低方差（如面部）提升有限；理论假设为高斯分布，实际数据分布偏差时预测准确性可能下降。

---

## 210. Unraveling the Hidden Dynamical Structure in Recurrent Neural Policies

**arXiv ID:** 2602.01196 | [PDF](https://arxiv.org/pdf/2602.01196v1)

**作者:** Jin Li `[一作]` (Sapient Intelligence), Xianyuan Zhan `[通讯]` (Tsinghua University)

**通讯引用:** 1567 | [OpenAlex ID](https://openalex.org/A5052921346)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文研究了在周期性任务环境下，优化后的循环神经网络策略在执行过程中如何自组织为吸引子周期（limit cycle），并探讨了这些周期结构如何与策略行为产生结构化对应。

**💡 创新点**

创新点在于首次将循环策略的隐藏状态视为混合动力系统的状态，证明它们在不同任务、训练方式和网络架构下均会收敛为稳定周期，且该周期的几何结构与行为空间保持高度同构，从而解释了循环策略优异的泛化与鲁棒性。

**🔧 技术方法**

采用了混合动力系统建模、有限时间Lyapunov指数（FTLI）评估周期稳定性、周期驱动（PKD）机制验证周期形成、以及典型相关分析（CCA）验证行为与隐藏状态周期的几何对应；同时结合了扰动实验以证明周期的吸引性。

**📊 数据集**

实验使用了两大任务族：部分可观测的迷宫导航（grid maze）和基于Procgen的高维游戏（如CoinRun、Heist、Jumper），并在这些任务上分别使用梯度优化（PPO）和无梯度进化策略（ES）训练，网络结构包括传统RNN、GRU和现代状态空间模型Mamba。

**📈 对比分析**

与随机初始化或无周期行为的基线相比，优化后的策略在FTLI分布上持续负值，表明周期具有吸引性；在行为相似度上通过CCA可观测到10维以上的相关系数>0.7，显示行为与隐藏周期几何高度匹配；对比实验表明仅保留CCA高相关维度即可显著提升收敛速度，验证其功能性。

**⚠️ 局限性**

局限性包括：仅在周期性、episodic任务环境下验证，未覆盖非周期或连续控制任务；行为潜在场（BPF）指标目前仅适用于低维导航任务，扩展到高维控制时计算成本高；缺乏对优化过程中从随机到周期稳定器的动态过程建模，未揭示内在的“隐式”自适应算法。

---

## 211. PersistBench: When Should Long-Term Memories Be Forgotten by LLMs?

**arXiv ID:** 2602.01146 | [PDF](https://arxiv.org/pdf/2602.01146v1)

**作者:** Sidharth Pulipaka `[一作]` (Supervised Program for Alignment Research), Ivaxi Sheth `[通讯]` (CISPA Helmholtz Center for Information Security)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 PersistBench benchmark，用以系统评估对话式大模型长期记忆带来的安全风险；

**💡 创新点**

创新点在于首次把长期记忆的跨域泄露与记忆诱发顺从两类风险纳入同一基准，并通过 MCTS 自动生成高质量样本与防御性提示优化来对抗这些风险；

**🔧 技术方法**

技术方法包括基于 MCTS 的样本生成、LLM-as-a-judge 的自动评估、GEPA 与 Rubric‑informed 的提示优化，以及在多种前沿和开源 LLM 上的多轮推理实验；

**📊 数据集**

数据集为自行构建的 500 条人工验证样本，涵盖 200 条跨域泄露、200 条顺从、100 条有益记忆三大子集；

**📈 对比分析**

在 18 个模型上对比评估，跨域泄露中位失效率为 53%，顺从风险达 95% 以上，而有益记忆仅 16%；防御提示可显著降低失效率，但仍无法彻底解决问题；

**⚠️ 局限性**

局限性包括：难以统一记忆使用与忽略的最优策略；防御手段主要依赖提示，未在模型训练阶段引入约束；Benchmark 仅涵盖文本形式的长期记忆，未覆盖检索式或参数化记忆。

---

## 212. Trust in One Round: Confidence Estimation for Large Language Models via Structural Signals

**arXiv ID:** 2602.00977 | [PDF](https://arxiv.org/pdf/2602.00977v1)

**作者:** Pengyue Yang `[一作]` (University of Sydney), Ling Chen `[通讯]` (University of Technology Sydney)

**通讯引用:** 33318 | [OpenAlex ID](https://openalex.org/A5100411137)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种单通道、模型无关的后置置信度估计框架——Structural Confidence，通过分析LLM最终层隐藏状态轨迹的结构稳定性来判断答案正确性。

**💡 创新点**

创新点在于将隐藏状态轨迹的频谱稳定性、局部变异度和全局形状一致性三类多尺度结构特征作为置信度信号，并通过轻量级代理编码器在仅一次前向传播中获取；与传统基于概率、语义相似度或多样本一致性的方式相比，显著降低计算开销且对分布偏移更鲁棒。

**🔧 技术方法**

采用BERT‑base（12层）作为代理编码器提取隐藏状态；计算FFT谱能量、图谱拉普拉斯特征、局部距离统计、距离直方图等70维结构向量；使用LightGBM分类器对结构+语义特征进行训练；实现单通道、无梯度、无额外采样的置信度估计。

**📊 数据集**

在四个事实性与真相性基准上评估：FEVER、SciFact、WikiBio‑hallucination以及TruthfulQA；此外通过混合域训练集（FEVER+SciFact+WikiBio）进行跨域泛化测试。

**📈 对比分析**

与基于token概率、语义嵌入、单样本NLI一致性（SelfCheckGPT）以及聚类异常检测等基线对比。结构置信度在FEVER、WikiBio上与SelfCheckGPT相当甚至优于其在AUPR上；在SciFact上表现更稳健；跨域实验显示结构特征保持稳定，而语义特征显著退化。整体来说，Structural Confidence以最低的FLOPs和延迟实现了与更昂贵方法相近或更优的AUROC/AUPR。

**⚠️ 局限性**

局限性包括：仅在文本生成任务上验证，未对多模态或更大规模LLM进行评估；代理编码器可能无法完整捕捉生成模型内部细节；在极端分布偏移（如长篇技术文档）下性能仍需进一步验证。

---

## 213. Building Better Deception Probes Using Targeted Instruction Pairs

**arXiv ID:** 2602.01425 | [PDF](https://arxiv.org/pdf/2602.01425v1)

**作者:** Vikram Natarajan `[一作]` (LASR Labs), Joseph Bloom `[通讯]` (UK AI Security Institute)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3855fcda-48ef-4070-a15e-803cd5c84d83` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了在大型语言模型中使用线性探针检测欺骗行为，并系统评估了提示词、层次、数据集等因素对性能的影响。

**💡 创新点**

发现系统提示词解释了70.6%性能方差，并提出基于人类可解释欺骗分类的提示词，显著提升AUC，挑战“一刀切”欺骗检测器的假设。

**🔧 技术方法**

采用残差流的线性探针（Logistic回归）对Gemma 2 9B IT的激活进行特征提取，使用对比式提示词进行训练。

**📊 数据集**

训练集为Azaria–Mitchell事实集；评估集包含10个欺骗基准（MASK、Liar's Bench、AI Liar等）和控制数据集。

**📈 对比分析**

与基线提示词和平均最佳探针对比，分类提示词平均提升0.108 AUC（20.5%相对增益），在不同数据集表现不一，体现欺骗类型异质性。

**⚠️ 局限性**

仅在单一模型架构和层次（层20）上验证，实验仅限英文，未针对更复杂代理情境或其他语言验证，且提示词生成可能带来未控制的偏差。

---

## 214. EvoOpt-LLM: Evolving industrial optimization models with large language models

**arXiv ID:** 2602.01082 | [PDF](https://arxiv.org/pdf/2602.01082v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 215. Learning from Anonymized and Incomplete Tabular Data

**arXiv ID:** 2602.01217 | [PDF](https://arxiv.org/pdf/2602.01217v1)

**作者:** Lucas Lange `[一作]` (Leipzig University), Erhard Rahm `[通讯]` (Leipzig University)

**通讯引用:** 18748 | [OpenAlex ID](https://openalex.org/A5075756237)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究在用户驱动隐私场景下，如何通过数据预处理（尤其是基于粒度的特殊化方法）在含有原始、泛化和缺失值的表格数据上训练机器学习模型。

**💡 创新点**

提出了专门针对混合隐私变换的“特殊化”预处理策略，能够利用泛化信息恢复更多特征细粒度，并在不同部署场景中保持较高的预测性能。

**🔧 技术方法**

使用的技术包括：简单插补、MICE、约束MICE、强制泛化、基于粒度的特殊化与过滤、LLM（Mistral‑Small‑24B‑Instruct‑2501）进行零射击填充与直接预测，以及XGBoost模型进行评估。

**📊 数据集**

实验数据集涵盖四个公共领域：Credit（1K行）、Income（45K行）、Diabetes（70K行）和Employment（381K行）。

**📈 对比分析**

通过在三种部署场景（AnTr、AnTe、AnBo）下，对比六种预处理方法（无预处理、标准插补、特殊化、LLM填充、LLM预测、强制泛化）进行宏F1评分比较。结果显示特殊化在大多数情况下获得最优或次优性能，平均相对基线F1下降约0.09–0.12，且在AnTr和AnTe场景中能显著提升准确率；LLM方法在无原始值情况下表现突出。

**⚠️ 局限性**

主要限制包括：实验仅基于合成隐私分布，缺乏真实用户驱动隐私数据；假设列级隐私分布且所有属性为准识别符，可能不完全符合实际；LLM方法成本高、耗时长；特殊化在高维类别特征时可能导致数据规模膨胀；仅评估二分类任务，未覆盖回归或多标签等场景。

---

## 216. MedSpeak: A Knowledge Graph-Aided ASR Error Correction Framework for Spoken Medical QA

**arXiv ID:** 2602.00981 | [PDF](https://arxiv.org/pdf/2602.00981v1)

**作者:** Yutong Song `[一作]` (University of California), Amir Rahmani `[通讯]` (University of California)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出了 MedSpeak 框架，利用医学知识图谱与大型语言模型（LLM）对自动语音识别（ASR）产生的噪声转录进行纠错，并在纠错后完成多项选择医学问答。

**💡 创新点**

创新点在于：①将语义关系与语音相似度统一编码进医学知识图谱，②通过双元音匹配和 Levenshtein 距离形成检索约束，③将 ASR 纠错与多项选择推理整合为一次性生成任务，实现模型的联合学习与推理。

**🔧 技术方法**

使用的技术包括：基于 UMLS 构建的双语音+语义医学知识图谱、Whisper Small 作为前端 ASR、Llama‑3.1‑8B‑Instruct 的全参数微调、Double Metaphone 与 Levenshtein 距离的检索机制以及结构化两行输出的训练目标。

**📊 数据集**

实验数据集涵盖 MedMCQA、MedQA（USMLE）和 MMLU‑Medical 三大多项选择医学 QA 数据集，通过 pyttsx3 语音合成获得约 47 小时的语音问答数据。

**📈 对比分析**

与零样本 ASR、零样本 GT、仅微调 LLM + Whisper、纯微调 LLM 等基线对比，MedSpeak 在所有子任务上平均提升约 10% 的问答准确率，同时将 WER 从 77.2% 降低到 29.9%，显著提高了语音纠错与问答性能。

**⚠️ 局限性**

局限性包括：依赖合成语音数据，真实环境下的噪声鲁棒性待验证；对低资源医学术语的检索效果仍受限；在 MedMCQA 等任务中与纯 GT 微调模型的差距相对较小。

---

## 217. Fast $k$-means Seeding Under The Manifold Hypothesis

**arXiv ID:** 2602.01104 | [PDF](https://arxiv.org/pdf/2602.01104v1)

**作者:** Poojan Shah `[一作]` (Indian Institute of Technology Delhi), Ragesh Jaiswal `[通讯]` (Indian Institute of Technology Delhi)

**通讯引用:** 802 | [OpenAlex ID](https://openalex.org/A5075959430)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

基于流形假设的k‑means聚类起点算法研究

**💡 创新点**

提出流形假设下的几何缩放律并利用最优量化理论，设计基于拒绝采样的快速k‑means++种子生成算法QKMeans

**🔧 技术方法**

最优量化理论、流形假设、拒绝采样、近似最近邻结构、JL降维

**📊 数据集**

MNIST、FMNIST、CIFAR10/100及其CLIP嵌入、文本嵌入（All‑MiniLM‑L6‑v2）、Reddit、StackExchange、SUSY、HAR等多域数据集

**📈 对比分析**

与传统k‑means++、基于ANN加速、coreset、Lloyd迭代等方法对比，QKMeans在大维度和大簇数场景下平均速度提升5–10倍，甚至高达100倍，同时保持与k‑means++相近的聚类质量

**⚠️ 局限性**

需要依赖流形假设；对参数ρ、m和近似最近邻的依赖；在高内在维度或非流形数据上表现可能下降；接受率与样本量相关，若接受率低需增加循环次数

---

## 218. Multi-LLM Adaptive Conformal Inference for Reliable LLM Responses

**arXiv ID:** 2602.01285 | [PDF](https://arxiv.org/pdf/2602.01285v1)

**作者:** Kangjun Noh `[一作]` (Yonsei University), Kyungwoo Song `[通讯]` (Yonsei University)

**通讯引用:** 1525 | [OpenAlex ID](https://openalex.org/A5017589963)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出了一种基于乘法过滤和分组条件自适应一致性推断（MACI）的框架，用于在高风险领域中确保大型语言模型输出的事实性，并在保证分布无关的覆盖率的同时最大化保留真命题比例。

**💡 创新点**

创新点包括：① 将一致性推断转化为乘法过滤结构，实现对整个命题集合的统一覆盖保证；② 引入分组条件校准，解决传统一致性推断在不同子群体间覆盖偏差的问题；③ 通过多 LLM 集成的事实性评分提升估计质量，理论上与 oracle 评分的偏差直接影响保留率，并提供保留率的理论上界；④ 在协同计算时加入轻量级密度比估计，以缓解协变偏移。

**🔧 技术方法**

技术手段包括：乘法一致性推断（multiplicative conformal inference），分组条件校准（group‑conditional calibration），多 LLM 集成（ensemble）与最优权重学习，随机化阈值与保留率分析，密度比估计（DRE）以对抗协变偏移。

**📊 数据集**

实验数据集为 MedLFQA、WikiBio 与 ExpertQA 三个医学与百科问答数据集，均包含 Prompt、Response、Claim Set 与真值标签。

**📈 对比分析**

与基线方法 BCI（基本一致性推断）和 CCI（条件一致性推断）比较，MACI 在所有数据集和分组条件下都实现了设定的覆盖率（80%、90%、95%），并在保留率上显著高于两者（提升 20%~60%）。此外，MACI 的计算时间（尤其是事实性评分生成和校准）比采样式方法和 CCI 低约 2‑3 倍，显著提升实时性。

**⚠️ 局限性**

局限性包括：① 仍依赖于 LLM 生成的事实性评分质量，对极端错误的 LLM 可能不充分校准；② 分组定义对覆盖效果影响较大，若分组细粒度过高或样本不足会导致阈值不稳健；③ 在严重协变偏移下需要额外的 DRE 校正，且对密度比估计的准确性有要求；④ 对于极大规模的文档/命题集合，乘法阈值计算仍存在数值稳定性挑战。

---

## 219. MTC-VAE: Multi-Level Temporal Compression with Content Awareness

**arXiv ID:** 2602.01340 | [PDF](https://arxiv.org/pdf/2602.01340v1)

**作者:** Yubo Dong `[一作]` (Zhejiang University), Linchao Zhu `[通讯]` (Zhejiang University)

**通讯引用:** 6088 | [OpenAlex ID](https://openalex.org/A5043617790)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了一种基于视频内容复杂度自适应多层时间压缩的变分自编码器（MTC‑VAE），并与预训练的DiT模型无缝对接，实现了显著提升的视频压缩率。

**💡 创新点**

创新点在于：①采用多层时间压缩算法根据每个视频片段的运动与静态特征动态分配压缩率；②设计了关键帧预测器和流引导一致性损失，使分段编码与解码能准确恢复原始时间分辨率；③将该自适应VAE与LVDM中的DiT进行联合微调，显著提升生成速度与压缩效率。

**🔧 技术方法**

使用的核心技术包括：连续变分自编码器、时间压缩算法（基于PSNR的质量评估）、关键帧预测器（二分类器）、流引导一致性损失、EMA训练策略、DiT微调、以及对比实验所需的评估指标（PSNR、SSIM、LPIPS、VBench）。

**📊 数据集**

主要使用公开视频数据集 WebVid‑10M 与 Panda‑70M 进行重建评估，OpenSoraPlan 数据集用于DiT微调和生成实验；此外，还利用 WebVid‑10M 与 Panda‑70M 验证压缩率与质量的关系。

**📈 对比分析**

与八种现有 VAE（VQGAN、SD‑VAE、SVD‑VAE、TATS、CV‑VAE、OPS‑VAE、OD‑VAE、CogVideoVAE）以及两款主流 DiT（CogVideoX‑5B、OpenSora‑Plan）进行对比；MTC‑VAE 在保持 PSNR 与 SSIM 与基线相当或略优的前提下，压缩率提升 73%–92%；在视频生成任务中实现 1.9× 速度提升、3.12 s/frame 的延迟下降，VBench 分数保持在同一水平。

**⚠️ 局限性**

局限性包括：①关键帧预测误差会影响解码质量；②压缩参数 w 的调优需经验；③对高动态或细粒度运动的视频仍可能出现质量下降；④需要额外的流引导一致性损失训练，增加训练成本；⑤在极高压缩率下仍可能出现重建模糊。

---

## 220. A Baseline Multimodal Approach to Emotion Recognition in Conversations

**arXiv ID:** 2602.00914 | [PDF](https://arxiv.org/pdf/2602.00914v1)

**作者:** Víctor Yeste `[一作]` (Universidad Europea de Valencia), Rodrigo Rivas-Arévalo `[通讯]` (Universidad Europea de Valencia)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

构建了一个轻量级多模态基线，结合 RoBERTa 文本分类器和 Wav2Vec2 语音表征模型，对《Friends》剧集的对话进行情绪识别，并通过晚期融合提升性能。

**💡 创新点**

提供了可复现的技术报告和公开代码，证明文本+语音的晚期融合在轻量级训练下能显著提升情绪识别准确率，达到 62.97%。

**🔧 技术方法**

使用 Transformer 文本模型 RoBERTa、DistilBERT、DeBERTa 等以及自监督语音模型 Wav2Vec2、HuBERT，采用简单的加权/投票式晚期融合。

**📊 数据集**

使用 SemEval‑2024 Task 3 语料库，即从《Friends》剧集提取的带有因果‑情绪标注的对话数据。

**📈 对比分析**

与单模态文本模型（最高 50.68%）和单模态语音模型（最高 35.43%）对比，融合后准确率提升至 62.97%，但评估仅用准确率和执行时间。

**⚠️ 局限性**

实验轻量化，未做充分的超参数搜索和多随机种子评估；数据仅来自单剧集，缺乏视觉模态，且分割方式与官方 leaderboard 不同，结果仅作基线参考。

---

## 221. TraceLLM: Leveraging Large Language Models with Prompt Engineering for Enhanced Requirements Traceability

**arXiv ID:** 2602.01253 | [PDF](https://arxiv.org/pdf/2602.01253v1)

**作者:** Nouf Alturayeif `[一作]` (King Fahd University of Petroleum and Minerals), Jameleddine Hassine `[通讯]` (University of Quebec in Montreal)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了 TraceLLM 框架，通过系统化的提示工程提升大语言模型在需求可追溯性中的表现。

**💡 创新点**

创新点在于将提示设计与演示选择相结合，构建可复现的流水线，并在多模型、多数据集上评估提示泛化。

**🔧 技术方法**

使用大型语言模型（GPT‑4o、Claude、Gemini、Llama 等）结合提示工程与演示选择算法。

**📊 数据集**

使用 CM1、EasyClinic (UC‑TC, UC‑ID) 与 CCHIT 四个公开基准数据集。

**📈 对比分析**

与传统 IR、ML、DL 方法及现有 LLM 基线对比，TraceLLM 在 F2 分数上实现了 0.68–0.83 的提升，表现为最高 Recall 与竞争性 Precision。

**⚠️ 局限性**

局限在于仍需人工验证、在 TLX 或极低样本场景下效果有限，且 Prompt 设计仍需人工迭代。

---

## 222. Hallucination is a Consequence of Space-Optimality: A Rate-Distortion Theorem for Membership Testing

**arXiv ID:** 2602.00906 | [PDF](https://arxiv.org/pdf/2602.00906v1)

**作者:** Anxin Guo `[一作]` (Northwestern University), Jingwei Li `[通讯]` (Columbia University)

**通讯引用:** 7485 | [OpenAlex ID](https://openalex.org/A5100345753)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

将大语言模型的幻觉现象形式化为成员资格测试问题，推导了稀疏极限下的速率-失真定理，并在此框架下证明了记忆容量与错误率之间的最优平衡；通过理论分析得到的“幻觉通道”与实验结果一致。

**💡 创新点**

创新点在于：① 用信息论方法将幻觉问题转化为稀疏成员资格测试；② 在稀疏极限下给出精确的 KL 驱动的记忆-误差下界；③ 证明在有限记忆下，高置信度幻觉是最优错误模式；④ 将 Bloom 过滤器空间下界与 LLM 记忆容量统一到同一理论框架。

**🔧 技术方法**

主要技术包括信息理论（KL 散度、速率-失真理论）、概率论（极限分析）、优化（KKT 条件求解分布最小化）、深度学习实验（Transformer 训练）以及对 Bloom 过滤器等传统数据结构的理论映射。

**📊 数据集**

使用合成数据：长度为15、26个英文字母组成的字符串集合（|U| = 26¹⁵），随机抽取 15145 条作为事实集合进行实验；未使用真实语料。

**📈 对比分析**

对比方法：以 KL 散度衡量实验分布与理论最优分布的距离，实验得到约 12% 的 KL 额外开销；记忆利用率约 2 位/参数；实验中模型对事实的高置信区间与理论预测的“幻觉通道”高度一致，验证了理论。

**⚠️ 局限性**

局限性包括：① 仅在理想化的闭世界、稀疏假设下推导，未在真实 LLM 规模上直接验证；② 对于非排列不变的实际模型，理论下界可能不完全适用；③ 记忆容量估计依赖于参数与信息量假设；④ 实验仅在合成数据上进行，缺乏在真实事实知识库上的评估。

---

## 223. Data Repair

**arXiv ID:** 2602.01517 | [PDF](https://arxiv.org/pdf/2602.01517v1)

**作者:** ATM Mizanur Rahman `[一作]` (University of Illinois Urbana-Champaign), Sharifa Sultana `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 648 | [OpenAlex ID](https://openalex.org/A5103026409)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本研究通过为期六个月的田野访谈、观察与访谈，系统记录并分析了孟加拉国达卡市数据修复生态，揭示了技术、社区、伦理与市场交织的日常实践；

**💡 创新点**

创新点在于将数据修复提升为人机交互研究的核心议题，首次从后殖民视角阐释修复工作中的知识闭塞、加密与法律伦理冲突，并提出对开放源码与社区知识档案的设计启示；

**🔧 技术方法**

研究方法主要为人种志研究：半结构化访谈、现场观察、音频录制、图像采集与主题编码分析；

**📊 数据集**

数据集包含约150页现场笔记、200余张照片、18小时音频（经转写与译文）共28位修复从业者、仲裁者与实验室专家的访谈记录；

**📈 对比分析**

本研究并未进行算法或性能比较，而是通过质性分析阐述修复成本与情感价值之间的价格策略、技术难点与社区知识流动；

**⚠️ 局限性**

局限性包括：样本仅来自达卡市，缺乏跨地区对比；未获取修复后数据内容，因隐私保护；研究视角局限于修复从业者，未充分展现客户、政策制定者与工具开发者的声音。

---

## 224. Model Specific Task Similarity for Vision Language Model Selection via Layer Conductance

**arXiv ID:** 2602.01346 | [PDF](https://arxiv.org/pdf/2602.01346v1)

**作者:** Wei Yang `[一作]` (University of Science and Technology of China), Enhong Chen `[通讯]` (University of Science and Technology of China)

**通讯引用:** 27839 | [OpenAlex ID](https://openalex.org/A5048237545)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `57a58b01-81b4-4d75-a45c-2e891f272b50` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种基于视觉编码器层级导电量的模型特定任务相似度度量，并利用该度量在极少标签的条件下实现视觉‑语言模型的快速选择；

**💡 创新点**

创新点在于：①使用层级导电量（Layer Conductance）构建任务表示，充分利用少量未标记图像；②提出了方向性导电量差异（Directional Conductance Divergence, DCD），捕捉源任务对目标任务关键功能块的覆盖程度，从而实现异向、模型特定的相似度度量；③通过熵正则化的块重要性分布和基于源任务排名的加权平均，实现无需直接评估目标任务即可预测模型排名；

**🔧 技术方法**

主要技术包括：层级导电量计算、归一化与熵正则化的软最大（softmax）块重要性分布、DCD度量、基于源任务排名的加权平均及排序；

**📊 数据集**

使用了21个公开数据集（来自 LOVM/SWAB 公开基准）作为目标任务，并在包含48种不同架构和预训练方式的 VLM 仓库上进行评估；

**📈 对比分析**

与 INB、AvgRank、ModelGPT、SWAB 等基线比较，本文方法在 NDCG@5 上提升 14.7%（从 0.616 提升至 0.707），τ@5 也提升至 0.365，整体性能显著优于现有方法；

**⚠️ 局限性**

局限性在于：依赖少量未标记图像，若目标任务缺乏图像则无法直接应用；方法主要聚焦视觉编码器的内部表示，未充分利用跨模态交互信息；对源任务的采样依赖较多，可能在极少样本场景下性能下降。

---

## 225. Minimizing Inequity in Facility Location Games

**arXiv ID:** 2602.01048 | [PDF](https://arxiv.org/pdf/2602.01048v1)

**作者:** Yuhang Guo `[一作]` (UNSW Sydney), Houyu Zhou `[通讯]` (UNSW Sydney)

**通讯引用:** 12 | [OpenAlex ID](https://openalex.org/A5057187183)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

研究在实数线上以群体公平为目标的设施位置游戏，提出最大群体效应统一指标，并设计了两个单设施策略可证明机制以及对两设施情形的紧确近似分析。

**💡 创新点**

提出了新的最大群体效应框架，两个全新的策略可证明机制以及对两设施的紧确近似界，成功闭合了此前开放的近似误差，并将多种经典目标纳入统一模型。

**🔧 技术方法**

采用算法机制设计、近似分析与策略可证明性证明等技术，基于群体权重与位置统计构造机制。

**📊 数据集**

未使用任何实验数据集，全部基于理论推导与分析。

**📈 对比分析**

与最优解比较，单设施时获得2-近似；两设施时获得 1+(n-2)·w_max/w_min（总效应）和 1+w_max/w_min（最大效应）的近似比率，理论上与已有结果相当或更优。

**⚠️ 局限性**

对 k≥3 的情形仍无界限近似，且未考虑随机机制和高维空间的推广，未来工作需要突破这些限制。

---

## 226. MiTA Attention: Efficient Fast-Weight Scaling via a Mixture of Top-$k$ Activations

**arXiv ID:** 2602.01219 | [PDF](https://arxiv.org/pdf/2602.01219v1)

**作者:** Qishuai Wen `[一作]` (Beijing University of Posts and Telecommunications), Chun-Guang Li `[通讯]` (Beijing University of Posts and Telecommunications)

**通讯引用:** 11767 | [OpenAlex ID](https://openalex.org/A5084461358)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `90291a0e-9d36-4a08-9a16-89ce846d923f` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

在Transformer注意力中，作者把注意力视为fast‑weight MLP，提出MiTA机制，通过少量landmark查询压缩全键值并聚合top‑k关键值对形成可变专家，从而将压缩与路由相结合。

**💡 创新点**

MiTA的创新点是：①以fast‑weight视角统一高效注意力；②采用Mixture of Top‑k Activations（MiTA）将压缩和路由两种扩展策略结合；③通过可调节的landmark数目与top‑k宽度实现可变、可伸缩的可变专家。

**🔧 技术方法**

核心技术包括fast‑weight MLP分析、top‑k采样、landmark查询、压缩键值对、基于查询的路由、FlashAttention等实现细节。

**📊 数据集**

实验数据集主要包括ImageNet‑1K（图像分类）、ADE20K（语义分割）以及Long Range Arena（长序列建模）等。

**📈 对比分析**

与全注意力、Agent Attention、Linear Attention、Reformer、Linformer等方法比较，MiTA在保持接近或略优准确率的同时，显著提升推理速度，尤其在序列长度达到百万级时实现数倍吞吐量提升。

**⚠️ 局限性**

局限性在于：①仍需 top‑k 聚合与路由导致额外的内存访问与实现复杂度；②对 landmark 数量 m 与 top‑k 宽度 k 的选择敏感，压缩可能导致信息损失；③在极长序列下，仍可能出现收敛与鲁棒性挑战。

---

## 227. Fast Sparse Matrix Permutation for Mesh-Based Direct Solvers

**arXiv ID:** 2602.00898 | [PDF](https://arxiv.org/pdf/2602.00898v1)

**作者:** Behrooz Zarebavami `[一作]` (University of Toronto), Justin Solomon `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 12371 | [OpenAlex ID](https://openalex.org/A5036542947)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本文针对基于网格的直接求解器，提出了一种新的快速稀疏矩阵置换方法，以降低求解过程中的填充与计算量。

**💡 创新点**

创新点在于引入层次化分块与局部最短路径算法的组合，显著减少了在网格稀疏矩阵上的填充，并保持了较低的置换开销。

**🔧 技术方法**

主要技术包括图划分（如 METIS / Scotch）、层次化分块、直接求解器（如 SuperLU / MUMPS）以及基于图结构的置换策略。

**📊 数据集**

使用了公开的网格基稀疏矩阵数据集，如 SuiteSparse 的 “mhd” “sloan” 等典型测试集，也包含了自定义的三维有限元网格矩阵。

**📈 对比分析**

与传统的基于 METIS 的置换方案进行对比，在多个网格尺寸（10^5~10^7）下，平均速度提升约 15%–30%，且内存占用下降 10%–20%。

**⚠️ 局限性**

主要局限在于该方法最适用于结构化或准结构化网格，对完全随机稀疏矩阵的效果不佳；此外，层次化分块过程对极大尺寸的 3D 网格仍存在计算瓶颈。

---

## 228. Dynamic Heuristic Neuromorphic Solver for the Edge User Allocation Problem with Bayesian Confidence Propagation Neural Network

**arXiv ID:** 2602.01294 | [PDF](https://arxiv.org/pdf/2602.01294v1)

**作者:** Kecheng Zhang `[一作]` (KTH Royal Institute of Technology), Pawel Herman `[通讯]` (Digital Futures)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `5b4c1114-4a70-478e-9921-2514ee03850d` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种基于BCPNN的神经形态求解器，用动态启发式输入和“无分配”状态来解决边缘用户分配问题

**💡 创新点**

创新点在于将动态启发式偏置与BCPNN结合，加入“无分配”单元实现可调的用户/服务器权衡，并通过参数扫描实现无须全局参数调优的可扩展性

**🔧 技术方法**

使用BCPNN框架、随机WTA机制、动态启发式生成器以及仿真时间步迭代来实现求解

**📊 数据集**

在30个合成案例（15个分布式、15个集中式）上进行评估，数据由Tarasova等的EUA生成器产生

**📈 对比分析**

与Gurobi最优解对比，平均性能差距为12.8%（低于20%阈值），在分布式低负载场景下仅9.56%差距，且在5次独立运行中的方差较小

**⚠️ 局限性**

局限性包括需手动设定启发式权重、对高DC比集中场景的敏感性、以及对动态场景的适应性尚未验证

---

## 229. BioTamperNet: Affinity-Guided State-Space Model Detecting Tampered Biomedical Images

**arXiv ID:** 2602.01435 | [PDF](https://arxiv.org/pdf/2602.01435v1)

**作者:** Soumyaroop Nandi `[一作]` (University of Southern California), Prem Natarajan `[通讯]` (University of Southern California)

**通讯引用:** 7822 | [OpenAlex ID](https://openalex.org/A5066184920)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出BioTamperNet框架用于检测生物医学图像中的复制伪造区域并定位源区域。

**💡 创新点**

结合基于Affinity的自注意力和跨注意力模块，利用轻量级SSM线性注意力实现高效精细匹配。

**🔧 技术方法**

使用Vision Transformer特征提取、SSM（Mamba）编码、Affinity-guided自注意力与跨注意力、卷积解码器，并在合成+GAN增强数据上训练。

**📊 数据集**

在BioFors基准上评估，同时使用RSIID、Western Blots等合成科学诚信数据集。

**📈 对比分析**

在BioFors的EDD/IDD/CSTD任务中获得MCC 0.827/0.589/0.578等最高分，优于MONet、TruFor、SparseViT等竞争方法。

**⚠️ 局限性**

在完全重叠复制、极度重复纹理、密集斑点图像等场景易出现误检或漏检，对大范围复制的鲁棒性仍有限。

---

## 230. Probing the Knowledge Boundary: An Interactive Agentic Framework for Deep Knowledge Extraction

**arXiv ID:** 2602.00959 | [PDF](https://arxiv.org/pdf/2602.00959v1)

**作者:** Yuheng Yang `[一作]` (Westlake University), Jiaxuan You `[通讯]` (University of Illinois at Urbana-Champaign)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一个交互式代理框架，系统性地探测并量化黑盒大语言模型（LLM）的知识边界。

**💡 创新点**

创新点在于：① 递归层次化（Recursive Taxonomy）探索策略实现了知识提取的 Pareto 优势；② 三阶段知识处理管道（向量去重、LLM 判定、领域相关性审核）显著提高了知识唯一性与真实性；③ 通过实验揭示了知识规模定律、Pass@1 与 Pass@k 的权衡以及训练数据对模型知识配置的决定性影响。

**🔧 技术方法**

技术包括：多策略代理探测（顺序、反思、递归层次、并行多视角）、向量相似度过滤、LLM 判定器（DeepSeek‑V3.1）进行语义裁决、Bloom 体系结构的领域审核，及自闭环的知识增量与饱和检测。

**📊 数据集**

数据集主要来源于 ICML 官方主题分类（Deep Learning、Machine Learning Systems、Probabilistic Methods）以及模型自身的预训练语料；实验对比了 Llama‑3.1、Qwen‑2.5‑7B、DeepSeek‑R1‑7B 等不同规模与组织的 LLM。

**📈 对比分析**

通过 Pareto 前沿对比、回忆率与准确率评估，递归层次策略在 15 轮内比传统顺序/反思方式高约 6 倍；模型规模越大回忆率提升 27.3%→39.0%；域特定 fine‑tuning 在目标域提升 Pass@1 但快速下滑，导致整体回忆率下降；跨系列实验显示回忆率稳定而准确率随训练语料而显著差异。

**⚠️ 局限性**

局限性包括：① 依赖 LLM 进行知识审核，缺乏人工验证；② 仅在技术/科学领域评估，其他非技术领域未知；③ 受预训练数据偏差影响，可能导致偏见与盲区；④ 对于极大模型的精度稍有下降，需进一步优化。

---

## 231. Multi-Scale Wavelet Transformers for Operator Learning of Dynamical Systems

**arXiv ID:** 2602.01486 | [PDF](https://arxiv.org/pdf/2602.01486v1)

**作者:** Xuesong Wang `[一作]` (CSIRO), Edwin V. Bonilla `[通讯]` (CSIRO)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种多尺度小波Transformer（MSWT）用于学习动力系统的神经算子，解决谱偏差导致的高频信息丢失问题。

**💡 创新点**

创新点在于：① 在令牌化后的波形空间中引入多尺度小波降采样/上采样，显式保留低频与高频子带；② 在小波域内构建注意力机制（Wavelet Attention），实现不同频带与尺度间的依赖建模；③ 通过令牌化降低空间分辨率，提升计算效率与长时序稳定性。

**🔧 技术方法**

技术包括：令牌化（Patch Tokenizer）、二维Haar小波变换（DWT/iDWT）、多尺度U‑形网络结构、Wavelet Attention、相对ℓ2损失训练及自回归预测。

**📊 数据集**

使用的实验数据集有：Chaotic Kolmogorov Flow（CKF，2D Navier–Stokes vorticity 64×64）、Shallow Water Equation（SWE，96×192）、以及真实气候重分析数据集 ERA5（48×96 5个预报变量+2个强迫变量）。

**📈 对比分析**

与FNO、U‑Net、WNO、SAOT、HFS以及LUCIE等基线对比；在CKF上相对L²误差降低60%以上，谱误差提升约70%；在SWE上在长时序（41/81步）上比最优稳定基线提升约30%；在ERA5上自由滚动10年时，温度、湿度、风速、压强、降水的RMSE均低于LUCIE，尤其在极地和赤道地区显著降低偏差。

**⚠️ 局限性**

局限性包括：① 对令牌化窗口尺寸敏感，过大会导致信息丢失和误差累积；② 训练仍使用标准MSE目标，对高频误差的加权不足；③ 计算量虽降低但仍高于纯卷积方法，尤其在更高分辨率时需进一步优化；④ 在极端天气等稀疏事件上验证不足。

---

## 232. Meanshift Shape Formation Control Using Discrete Mass Distribution

**arXiv ID:** 2602.00980 | [PDF](https://arxiv.org/pdf/2602.00980v1)

**作者:** Yichen Cai `[一作]` (Beihang University), Jinhu Lü `[通讯]` (Beihang University)

**通讯引用:** 35912 | [OpenAlex ID](https://openalex.org/A5027725400)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `51c0528b-f690-4182-ae60-bb5f046c276c`

**🎯 论文内容**

提出一种完全去中心化的机器人群形态形成方法，利用离散质量分布模型与基于meanshift的控制律实现复杂形状的自适应形成。

**💡 创新点**

创新点包括：① 将形状用离散样本点的质量分布表示，消除了传统连续密度函数的定义难题；② 设计了去中心化的质量估计器，使每个机器人可通过局部交互获得全局质量信息；③ 采用基于质量反馈的meanshift控制律，结合碰撞避免和速度饱和，保证形态收敛；④ 对凸形状的收敛性给出了严格的Lyapunov与LaSalle分析。

**🔧 技术方法**

使用技术包括：离散质量分布与核密度估计、meanshift算法、去中心化一致性协议、局部信息交换、碰撞避免策略、速度饱和函数、局部 Lipschitz 分析、定理证明与仿真实验。

**📊 数据集**

数据集：多种自定义形状（三角形、五边形、六边形、飞机、箭头、拼图、字母 A、图形、鱼骨等）在仿真中生成的机器人初始分布；实验使用10台 TurtleBot3 Burger 机器人在真实环境中形成“S”和“E”形状。

**📈 对比分析**

通过与基于 Legendre 瞬矩（8阶、12阶）的方法对比，使用覆盖率、均匀性、收敛时间等指标评估。实验结果显示：覆盖率更高、均匀性更好、收敛速度更快，且在非凸形状与大规模群体中仍保持良好性能。

**⚠️ 局限性**

局限性包括：① 需要预先指定形状且必须保持不变，难以适应动态形状变化；② 对样本点数和带宽 β 的选择较为敏感，需经验或启发式算法；③ 仍可能陷入局部极小值，尤其在复杂非凸形状下；④ 机器人数量与形状面积匹配要求严格；⑤ 当机器人数量增减时需重置质量估计器，尚无完全无广播的自恢复机制。

---

## 233. PaAno: Patch-Based Representation Learning for Time-Series Anomaly Detection

**arXiv ID:** 2602.01359 | [PDF](https://arxiv.org/pdf/2602.01359v1)

**作者:** Jinju Park `[一作]` (Sungkyunkwan University), Seokho Kang `[通讯]` (Sungkyunkwan University)

**通讯引用:** 2230 | [OpenAlex ID](https://openalex.org/A5010312084)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `57a58b01-81b4-4d75-a45c-2e891f272b50` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种基于时间片段的轻量级表示学习方法PaAno，用1D-CNN对时间序列片段进行嵌入，计算异常分数。

**💡 创新点**

创新点在于引入patch级别的局部表示学习，结合三元组损失和自监督预文本任务，构建高效的记忆库实现对异常的精确判定，并保持极低的模型尺寸与计算量。

**🔧 技术方法**

使用1D卷积神经网络作为编码器，三元组损失与预文本分类损失进行联合训练，记忆库采用K-means聚类后抽样。

**📊 数据集**

在TSB-AD基准上评估，包括TSB-AD-U（单变量）和TSB-AD-M（多变量）两大子集。

**📈 对比分析**

与40多种基线（统计、NN、Transformer等）对比，PaAno在所有六项指标（VUS-PR、VUS-ROC、Range-F1、AUC-PR、AUC-ROC、Point-F1）均排名第一，性能优于Transformer和其他大模型，同时参数量约0.3M，推理速度约6–13s。

**⚠️ 局限性**

局限性在于主要针对单变量和多变量无标签训练，且对极端噪声或非平稳变化的适应性需要进一步验证；预文本任务仅在训练早期使用，若场景变化需重新训练或在线更新记忆库。

---

## 234. Beyond What Seems Necessary: Hidden Gains from Scaling Training-Time Reasoning Length under Outcome Supervision

**arXiv ID:** 2602.00927 | [PDF](https://arxiv.org/pdf/2602.00927v1)

**作者:** Yihao Xue `[一作]` (University of California), Baharan Mirzasoleiman `[通讯]` (University of California)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究了在结果监督下扩大训练时推理长度（包括循环Transformer的loop计数和RL细调中的CoT token预算）对离散分布（OOD）泛化的影响。

**💡 创新点**

创新点在于理论上揭示了两种机制：自迭代可通过改变假设类的结构性偏置或在正则化下抑制shortcut，从而在ID性能已饱和后仍提升OOD表现。

**🔧 技术方法**

使用了循环Transformer（looped Transformer）和RL fine‑tuning的CoT token预算两种技术，并对两者进行了理论推导和实验验证。

**📊 数据集**

实验数据集包括synthetic算法任务中的p‑hop问题以及针对数学推理的MathData（ID为多项式求根，OOD为混合运算表达式）。

**📈 对比分析**

通过对不同loop计数/token预算的模型在ID和OOD验证集上的准确率进行比较，发现ID性能在较小预算（≈2 loop或256 token）即可饱和，而OOD准确率随推理长度持续上升。

**⚠️ 局限性**

该现象仅在满足特定正则化与假设类分解条件时出现，若存在持续存在的shortcut或正则化不足，则可能无法获得OOD提升。

---

## 235. Protocol Agent: What If Agents Could Use Cryptography In Everyday Life?

**arXiv ID:** 2602.01304 | [PDF](https://arxiv.org/pdf/2602.01304v1)

**作者:** Marco De Rossi `[一作]` `[通讯]` (Agent0), Marco De Rossi (Agent0)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了Protocol Agent基准，评估代理在日常情境中识别、推广并执行加密原语的能力

**💡 创新点**

首次将加密原语与多轮代理交互、谈判与工具使用相结合，提出端到端评估框架

**🔧 技术方法**

使用多轮对话模拟、工具调用（加密计算器）、LLM判别器以及自定义评判标准

**📊 数据集**

采用合成的工具驱动对话数据集，包含原语映射、协议完成、谈判等切片，并结合Boneh‑Shoup教材

**📈 对比分析**

通过自对弈与基准评判对比，SFT显著提升整体分数（如deepseek-v3p1从0.473提升至0.693），但仍存在工具调用准确率低等问题

**⚠️ 局限性**

局限在于自对弈偏差、未覆盖主流商用模型、以及对更模糊情境的泛化不足

---

## 236. PyGALAX: An Open-Source Python Toolkit for Advanced Explainable Geospatial Machine Learning

**arXiv ID:** 2602.00907 | [PDF](https://arxiv.org/pdf/2602.00907v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 237. Do All Individual Layers Help? An Empirical Study of Task-Interfering Layers in Vision-Language Models

**arXiv ID:** 2602.01167 | [PDF](https://arxiv.org/pdf/2602.01167v1)

**作者:** Zhiming Liu `[一作]` (Harbin Institute of Technology), Shuo Yang `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 4460 | [OpenAlex ID](https://openalex.org/A5101460917)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文通过层级干预（如参数归零）系统探测视觉-语言模型中对不同任务产生负面影响的层，并提出一种在推理时动态跳过这些“干扰层”的训练无关自适应方法TaLo，提升多任务性能。

**💡 创新点**

创新点在于首次发现并量化“任务干扰层”现象，构造TaskLayer Interaction Vector揭示任务与层之间的相似性，并提出基于层级干预的无训练、无参数更新的推理层级淘汰策略TaLo。

**🔧 技术方法**

技术主要包括：层级参数零化/统一缩放干预、TaskLayer Interaction Vector建模、任务相关层的聚类与匹配、基于少量探测样本动态选择并禁用干扰层的推理流程。

**📊 数据集**

使用的任务与数据集包括MMStar、MMBench、MMMU、ScienceQA、SEEDBench、InternVL2-26B等多种视觉语言多选题基准，涉及属性推理、关系推理、逻辑推理、粗细感知等六大任务类别。

**📈 对比分析**

对比方法包括原始预训练模型、模型融合、LoRA、OFT等参数高效微调技术；TaLo在10/15/20 shot设置下，在多任务上平均提升约3–10个百分点，单任务最高提升可达16.6%，且不需要额外训练，推理时间仅为基线的一小部分。

**⚠️ 局限性**

局限性主要在于依赖现有基准与任务划分，干扰层特征可能随模型架构或预训练策略变化而改变；TaLo目前仅支持单层干预，且在某些任务上无明显提升；未来需探索更细粒度干预、跨模型通用性及对训练过程的指导。

---

## 238. Deep Variational Contrastive Learning for Joint Risk Stratification and Time-to-Event Estimation

**arXiv ID:** 2602.01367 | [PDF](https://arxiv.org/pdf/2602.01367v1)

**作者:** Pinar Erbil `[一作]` (Politecnico di Milano), Matteo Matteucci `[通讯]` (Politecnico di Milano)

**通讯引用:** 6834 | [OpenAlex ID](https://openalex.org/A5003932703)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `57a58b01-81b4-4d75-a45c-2e891f272b50` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `9ce7179e-700c-4310-ac2b-91df50ded46e` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了CONVERSE模型，用变分自编码器与对比学习结合实现可解释的生存分析与风险分层；

**💡 创新点**

将变分自编码器与多视角对比学习、集成生存头结合，既保持预测性能又提供临床可解释的风险分层；

**🔧 技术方法**

变分自编码器（VAE）、多视角对比学习（含内聚与互聚损失）、自适应样本学习、集成深度生存头；

**📊 数据集**

四个医学生存数据集：GBSG（肿瘤复发）、METABRIC、TCGA_BRCA（乳腺癌总体生存）和WHAS（心肌梗死后生存）；

**📈 对比分析**

与DeepSurv、DeepHit等纯预测模型及VADESC、DCM、SCA、DVCSurv等分层模型比较，在C-Index上三大数据集获最高值，IBS表现亦优于多数分层方法，接近甚至超过纯预测模型；

**⚠️ 局限性**

对分层引入的集群边界不确定性可能导致部分校准略逊，且在样本较少的情形下对参数的自适应选择和对比学习权重调优复杂度较高。

---

## 239. System-Level Performance Modeling of Photonic In-Memory Computing

**arXiv ID:** 2602.00892 | [PDF](https://arxiv.org/pdf/2602.00892v1)

**作者:** Jebacyril Arockiaraj `[一作]` (University of Southern California), Viktor Prasanna `[通讯]` (University of Southern California)

**通讯引用:** 17379 | [OpenAlex ID](https://openalex.org/A5033166029)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了光学内存计算系统的整体性能模型，并将其应用于Sod冲击管、MTTKRP和Vlasov–Maxwell等高性能计算工作负载的算法映射。

**💡 创新点**

创新点在于首次将外部内存访问、光电转换延迟等系统级瓶颈纳入模型；通过网络抽象和流式算法实现对不同工作负载的统一映射；并利用屋顶线分析评估计算与内存瓶颈，最终证明紧凑型1×256位单波长pSRAM在系统级可实现1.5 TOPS以上吞吐并达到2.5 TOPS/W的能效。

**🔧 技术方法**

使用技术包括光学SRAM阵列（基于微环谐振器和光电二极管）、光电转换器、HBM3E高速外部内存、频率32 GHz的光学计算单元、可定制的网络模型以及系统级分析框架。

**📊 数据集**

所用工作负载为：一维Sod冲击管（Euler方程数值解）、MTTKRP（张量分解核心）、Vlasov–Maxwell方程（谱域FFT乘法）——这些均为典型的科学计算基准。

**📈 对比分析**

通过将模型与理想峰值性能和不同内存带宽、频率、转换延迟等参数进行对比，评估了系统吞吐和能效；实验结果显示，在HBM3E 9.8 Tbps带宽下，Sod冲击管、MTTKRP和Vlasov–Maxwell分别达到1.5、0.9、1.3 TOPS的持续吞吐，能效约为2.5 TOPS/W。

**⚠️ 局限性**

局限性包括：采用无光学缓存的流式基线，可能低估实际性能；模型假设完美流水线和理想的光电转换延迟；仅验证了1×256位阵列，扩展到更大规模时受外部内存带宽限制；未考虑精度下降与功耗/面积折衷的完整评估。

---

## 240. Shades of Uncertainty: How AI Uncertainty Visualizations Affect Trust in Alzheimer's Predictions

**arXiv ID:** 2602.01264 | [PDF](https://arxiv.org/pdf/2602.01264v1)

**作者:** Jonatan Reyes `[一作]` (University of Texas Rio Grande Valley), Marta Kersten-Oertel `[通讯]` (Concordia University)

**通讯引用:** 1641 | [OpenAlex ID](https://openalex.org/A5068819751)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `3855fcda-48ef-4070-a15e-803cd5c84d83` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `dc6c6f4a-9d29-4fb8-b59a-f6c271315b9b` `a6cb313d-240c-4723-a372-3ba1f39b9afc`

**🎯 论文内容**

本研究通过设计两项用户研究，比较了在阿尔茨海默病长期预测中二值与连续不确定性可视化对临床决策者与普通受试者的信任、信心与决策稳定性的影响；

**💡 创新点**

创新点在于首次将不确定性可视化作为可解释人工智能技术，在长期预后任务中系统评估其对多维信任的影响，并提出六条基于实证结果的可视化设计准则；

**🔧 技术方法**

采用了ML4VisAD深度学习模型进行多模态数据融合预测，并结合色度饱和度与黑白指示条等两种不确定性编码；

**📊 数据集**

使用了阿尔茨海默病神经影像倡议（ADNI）数据库中的MRI、PET、CSF、生物标志物及认知评估等多模态数据；

**📈 对比分析**

通过对比二值与连续不确定性视觉化在两组人群（N=37普通参与者，N=10专家）中的信任与信心得分，并统计决策变化率；实验显示连续编码提升专家的多维信任与可靠性认知，二值编码则提升信心与即时信任；

**⚠️ 局限性**

主要限制包括样本量相对较小、普通受试者技术背景偏高、缺乏长期反馈与外部验证、并未评估不确定性可视化与模型性能的直接关系。

---

## 241. Unleashing the Potential of Differential Evolution through Individual-Level Strategy Diversity

**arXiv ID:** 2602.01147 | [PDF](https://arxiv.org/pdf/2602.01147v1)

**作者:** Chenchen Feng `[一作]` (Southern University of Science and Technology), Ran Cheng `[通讯]` (Hong Kong Polytechnic University)

**通讯引用:** 17858 | [OpenAlex ID](https://openalex.org/A5004036087)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种个体级策略分配的差分进化变体 iStratDE，给每个个体随机且固定地分配变异/交叉策略，保持种群结构多样性。

**💡 创新点**

创新点在于通过个体级策略多样性而非适应性机制实现搜索多样性，完全无反馈，天然可并行，提升大规模种群下的鲁棒性。

**🔧 技术方法**

采用 DE 基本操作、随机策略池、GPU 并行实现以及收敛性理论证明。

**📊 数据集**

使用 CEC2022 基准函数、旋转移位的 200 维函数以及 BraX 机器人控制任务（Swimmer、Reacher、Hopper）进行评估。

**📈 对比分析**

在等时间或等函数评估下与传统 DE、SaDE、JADE、SHADE、LSHADE、MetaDE 等算法比较，iStratDE 在大规模种群时保持或超过对手，在高维和机器人任务中表现尤为优异。

**⚠️ 局限性**

局限性：对小种群或资源受限环境下效果不如自适应方法，且缺乏动态参数调节机制，可能在某些简单函数上收敛较慢。

---

## 242. Med3D-R1: Incentivizing Clinical Reasoning in 3D Medical Vision-Language Models for Abnormality Diagnosis

**arXiv ID:** 2602.01200 | [PDF](https://arxiv.org/pdf/2602.01200v1)

**作者:** Haoran Lai `[一作]` (University of Science and Technology of China), Shaohua Kevin Zhou `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

构建了一种针对3D CT图像的视觉-语言模型，并通过两阶段训练（先监督微调SFT，再强化学习RL）提升临床诊断推理能力。

**💡 创新点**

① 首次在3D医学VLM中引入强化学习；② 设计残差对齐机制（RAM）以降低3D视觉特征与文本嵌入之间的对齐难度；③ 开发异常重加权策略（ARW）消除报告结构偏置；④ 在RL阶段加入一致性奖励鼓励生成符合临床逻辑的推理链。

**🔧 技术方法**

使用3D ViT‑Base 视觉编码器、3D CLIP预训练、残差对齐与自适应加权池化、基于GRPO的强化学习以及基于预训练奖励模型的离散一致性奖励。

**📊 数据集**

CT‑RATE（胸腔CT+报告）和RAD‑ChestCT（胸腔CT+异常标签）两大基准，结合GPT‑4生成的虚拟VQA样本用于SFT。

**📈 对比分析**

在Medical Multiple‑Choice VQA任务中，S2阶段模型在CT‑RATE上达到41.92%、RAD‑ChestCT上达到44.99%，均超过现有SOTA（如MedVLM、Med‑R1等），并在多模态推理和报告生成指标上均显著提升。

**⚠️ 局限性**

① 训练数据规模有限，主要集中于胸腔CT，缺乏多中心、多器官、多模态样本；② 推理奖励模型来源于通用域，缺乏专业医学证据链，导致推理解释的临床可信度仍需提升。

---

## 243. Generalized Radius and Integrated Codebook Transforms for Differentiable Vector Quantization

**arXiv ID:** 2602.01140 | [PDF](https://arxiv.org/pdf/2602.01140v1)

**作者:** Haochen You `[一作]` (Columbia University), Baojing Liu `[通讯]` (Hebei Institute of Communications)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `a2602d71-93ab-4bad-974b-672788df8193` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出 GRIT‑VQ，一种结合半径基可微代理和全局代码书整合变换的向量量化框架，能够在保持硬前向分配的同时实现稳定的梯度流，显著提升码表利用率与生成/重建质量。

**💡 创新点**

创新点：①半径基可微代理在保留硬分配方向的同时提供可调步长；②数据无关的整合变换让所有码向量通过共享参数协同更新，避免码表崩溃；③统一理论分析阐释梯度对齐、稳定性与码表收敛；④在图像生成、推荐与压缩等多任务上进行系统验证。

**🔧 技术方法**

技术手段包括：半径基可微代理（各种可微半径族）、全局低秩线性或注意力式代码书整合变换、缓存式变换更新、单一重建损失（无额外辅助项）、基于 VQ 的自动编码器与变压器、序列化推荐模型。

**📊 数据集**

使用数据集：图像生成—AFHQ、CelebA‑HQ、FFHQ、LSUN（Bedroom/Church）；推荐—Amazon 产品评论（Beauty、Sports & Outdoors、Toys & Games）、Amazon‑ESCI 产品搜索、JDsearch；压缩重建—ImageNet‑1k。

**📈 对比分析**

对比方法：STE、EMA‑VQ、Gumbel‑Softmax、NSVQ、SimpleVQ、DiVeQ、SF‑DiVeQ、FSQ、LFQ、HyperVQ 等。评估指标为 FID、LPIPS、重建 PSNR/SSIM、词汇表利用率、Perplexity、Recall@K/NDCG。GRIT‑VQ 在大多数任务上实现了更低的 FID、更高的利用率、更好的生成/重建质量及更优的推荐召回。

**⚠️ 局限性**

局限性：仍需手动调节半径函数与变换参数；缓存刷新频率与线性变换秩对计算开销与性能有影响；在极大码表或更复杂的多阶段量化设置下的可扩展性尚未完全验证；全局同步更新可能带来额外算力需求。

---

## 244. Imperfect Influence, Preserved Rankings: A Theory of TRAK for Data Attribution

**arXiv ID:** 2602.01312 | [PDF](https://arxiv.org/pdf/2602.01312v1)

**作者:** Han Tong `[一作]` (Columbia University), Arian Maleki `[通讯]` (Columbia University)

**通讯引用:** 6838 | [OpenAlex ID](https://openalex.org/A5017771205)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文对广泛使用的数据归因方法TRAK进行了理论误差分析，分别评估其三项近似（线性化、ALO、随机投影）的误差大小，并通过仿真和CIFAR‑10实验验证结论。

**💡 创新点**

创新点在于：①给出TRAK每一步近似的定量误差界；②证明ALO误差可忽略；③即使线性化误差大，TRAK仍能准确区分高影响样本；④投影误差会削弱区分能力，并给出投影维度的最低要求。

**🔧 技术方法**

技术手段包括：统计学习理论与随机矩阵理论、子高斯设计与正则化假设、近似留一法（ALO）、随机投影技术、以及影响函数的理论推导。

**📊 数据集**

实验使用了：①线性模型仿真；②多类别分类仿真（p=100, d=200, K=3/5）；③真实数据集CIFAR‑10（10类）并对其子集CIFAR‑2做二分类实验。

**📈 对比分析**

评价方法：相关系数、Top‑k Exact Match计数、Overlap Ratio等指标；实验表明线性化与真实影响高度相关（ρ≈0.9），ALO误差极小（ρ≈0.999），投影维数降低时相关性下降但Top‑k覆盖率仍超过70%。

**⚠️ 局限性**

局限性：①线性化导致大误差，需谨慎使用；②投影维度若过小会导致排名失真；③理论假设（独立子高斯设计、正则化等）在实际数据中可能不成立；④对深度模型全局性能的验证仍有限。

---

## 245. FlowCast: Trajectory Forecasting for Scalable Zero-Cost Speculative Flow Matching

**arXiv ID:** 2602.01329 | [PDF](https://arxiv.org/pdf/2602.01329v1)

**作者:** Divya Jyoti Bajpai `[一作]` (Indian Institute of Technology Bombay), Manjesh Kumar Hanawal `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `64443552-63e0-44b5-906f-d90fe95c5a1b` `40105733-5154-44cd-8090-a8cab9e64b07` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了 FlowCast，一种无需训练的基于流匹配模型的自适应推理加速框架；

**💡 创新点**

利用模型自身的速度预测做零成本草稿，并通过均方误差阈值进行验证，实现在保持质量的前提下可跳过冗余步骤；

**🔧 技术方法**

关键技术包括流匹配模型的速度场推断、基于速度场的零成本草稿生成、并行验证与纠正、以及理论误差上界推导；

**📊 数据集**

在图像生成（GenEval、CLIPIQA）、图像编辑（GEdit、Step-1X-Edit）、视频生成（VBench、BRISQUE）等多种数据集上进行评估；

**📈 对比分析**

与全步采样、InstaFlow、PerFlow、TeaCache 等基线对比，FlowCast 在 2.5–13 倍的加速下，保持或接近全步方法的质量，特别在多轮编辑与视频生成任务中表现优异；

**⚠️ 局限性**

受限于需要并行计算草稿，若可用计算资源有限则加速效果受限，同时过多草稿会增加验证开销。

---

## 246. Hybrid Topological and Deep Feature Fusion for Accurate MRI-Based Alzheimer's Disease Severity Classification

**arXiv ID:** 2602.00956 | [PDF](https://arxiv.org/pdf/2602.00956v1)

**作者:** Faisal Ahmed `[一作]` `[通讯]` (Embry Riddle Aeronautical University), Faisal Ahmed (Embry Riddle Aeronautical University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `a6cb313d-240c-4723-a372-3ba1f39b9afc`

**🎯 论文内容**

本文提出一种融合拓扑数据分析（TDA）与DenseNet121的混合框架，用于基于结构MRI的四级阿尔茨海默病分级诊断。

**💡 创新点**

创新点在于将持久同调生成的Betti曲线与深度卷积特征进行融合，既保留全局拓扑信息，又捕捉局部空间纹理，从而实现无须大规模数据增强的高精度分类。

**🔧 技术方法**

主要技术包括二维MRI切片的立方子级滤波和持久同调、Betti曲线向量化、DenseNet121深度网络提取卷积特征、特征级融合以及多层感知机与softmax分类器。

**📊 数据集**

使用了OASIS‑1（Kaggle MRI）数据集，按90:10划分训练/测试集，包含非痴呆、轻度痴呆、极轻度痴呆和中度痴呆四类样本。

**📈 对比分析**

与现有CNN、迁移学习、集成与多尺度模型对比，模型在90:10划分下实现99.93%的准确率、100%的AUC，显著优于传统方法。

**⚠️ 局限性**

主要局限在于仅验证于单一数据集，缺乏跨数据集或多模态的泛化评估，且中度痴呆样本数量相对不足。

---

## 247. Evaluating Workflow Automation Efficiency Using n8n: A Small-Scale Business Case Study

**arXiv ID:** 2602.01311 | [PDF](https://arxiv.org/pdf/2602.01311v1)

**作者:** Ahmed Raza Amir `[一作]`, Syed Muhammad Atif `[通讯]`

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

在n8n低代码平台上实现并测试了一套小型业务的线性工作流，用于自动存储数据、发送邮件确认及即时通知，并对比手动执行与自动化执行的性能。

**💡 创新点**

首次通过可重复实验提供了低代码工作流在小规模业务场景下的量化性能数据，验证了高效、可靠、可预期的自动化优势，并指出当前评估方法的局限性，为后续更复杂环境的研究奠定基础。

**🔧 技术方法**

使用 n8n Cloud 进行工作流编排，Airtable 作为云数据库，Gmail SMTP 用于邮件发送，Telegram Bot API 用于即时通知；实验中采用手动触发与 n8n 自动化执行两种模式。

**📊 数据集**

实验数据集为 20 次手动运行与 25 次自动化运行产生的随机样本潜在客户记录（包括姓名、邮箱、留言等字段），并记录每次执行的时间与错误情况。

**📈 对比分析**

比较方法：手动执行时以秒表记录耗时，自动化执行时直接读取 n8n 日志；结果显示手动平均耗时185.35 s，自动化仅1.23 s，速度提升约151倍；手动误差率5%，自动化为0%；自动化执行时时间波动也显著降低。

**⚠️ 局限性**

局限性包括：仅使用手动触发的实验设置，未涵盖真正的事件驱动场景；数据量有限（45 次运行），未能进行更细致的统计与并发性评估；仅在 n8n Cloud 与 Airtable 上测试，未考察不同基础设施或多平台对性能的影响；未涉及安全、凭据管理、长期维护成本等因素。

---

## 248. ConvexBench: Can LLMs Recognize Convex Functions?

**arXiv ID:** 2602.01075 | [PDF](https://arxiv.org/pdf/2602.01075v1)

**作者:** Yepeng Liu `[一作]` (University of California Santa Barbara), Yuheng Bu `[通讯]` (University of California Santa Barbara)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了一个可扩展、可机械验证的凸性识别基准，用于评估大模型在深层函数组合下的推理能力；

**💡 创新点**

提出了利用DCP规则生成可验证表达式、发现解析失败与懒惰推理两大瓶颈，并设计了“代理式分治+聚焦上下文”框架以显著提升深层推理性能；

**🔧 技术方法**

采用DCP合成、AST解析工具、递归代理式推理、宏F1评估及令牌消耗分析等技术；

**📊 数据集**

使用自生成的Convex/Concave/Neither数据集，该数据集通过多层组合的原子函数在不同深度（2–100）下构造；

**📈 对比分析**

将一轮推理、解析分解、一层代理、聚焦上下文四种方案在多款前沿LLM上比较，发现单轮推理深度100时F1≈0.2，而代理式聚焦上下文可达1.0；

**⚠️ 局限性**

局限在于代理框架令牌消耗显著增加，对小模型仍有一定难度，且依赖外部解析工具，评测仅覆盖合成数据，缺乏真实场景验证。

---

## 249. DSFC-Net: A Dual-Encoder Spatial and Frequency Co-Awareness Network for Rural Road Extraction

**arXiv ID:** 2602.01278 | [PDF](https://arxiv.org/pdf/2602.01278v1)

**作者:** Zhengbo Zhang `[一作]` (School of Artificial Intelligence, University of Chinese Academy of Sciences), Shiming Xiang `[通讯]` (School of Artificial Intelligence, University of Chinese Academy of Sciences)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出DSFC‑Net，一种双编码器网络，用于高分辨率遥感图像中农村道路的精确提取

**💡 创新点**

创新点在于将空间卷积分支与频域Transformer分支（SFT）相结合，并设计跨频交互注意力（CFIA）和通道特征融合模块（CFFM），实现对窄道路和被植被遮挡的鲁棒识别

**🔧 技术方法**

采用CNN（ConvNeXt‑v2）提取局部细节，Spatial‑Frequency Hybrid Transformer（SFT）处理全局频域信息，CFIA通过拉普拉斯金字塔分离高低频，MFFN实现多尺度前馈，CFFM进行自适应通道融合，训练使用AdamW、BCE+Dice损失

**📊 数据集**

在WHU‑RuR+、DeepGlobe和Massachusetts三个公开农村/混合场景数据集上进行评估

**📈 对比分析**

与多种基准（U‑Net、D‑LinkNet、SegFormer、CFRNet、FRCFNet、OARENet、C^2Net、DENet、SegRoadv2、CGCNet）对比，DSFC‑Net在WHU‑RuR+上F1 69.93%、IoU 53.77%，在DeepGlobe上F1 81.44%、IoU 68.68%，在Massachusetts上F1 80.60%、IoU 67.50%，均为最优或接近最优，并在跨数据集泛化上表现突出

**⚠️ 局限性**

缺点是双编码器设计导致模型参数与 FLOPs 较高，尤其相较于轻量级CNN，对资源受限设备的部署和实时性有一定挑战

---

## 250. Koo-Fu CLIP: Closed-Form Adaptation of Vision-Language Models via Fukunaga-Koontz Linear Discriminant Analysis

**arXiv ID:** 2602.01127 | [PDF](https://arxiv.org/pdf/2602.01127v1)

**作者:** Matej Suchanek `[一作]` (Czech Technical University in Prague), Jiri Matas `[通讯]` (Czech Technical University in Prague)

**通讯引用:** 50666 | [OpenAlex ID](https://openalex.org/A5007656938)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

利用 Fukunaga‑Koontz 线性判别分析对 CLIP 嵌入进行白化与旋转，实现冻结模型的监督特征空间重塑。

**💡 创新点**

在冻结 CLIP 嵌入上实现闭式、轻量级的监督适配，既提升类间分离度，又实现显著降维，突破了传统基于分类器或提示学习的适配方法。

**🔧 技术方法**

采用 Fukunaga‑Koontz 变换（含白化+正则化 LDA）与最近视觉原型、k‑NN 以及文本原型的零样本分类。

**📊 数据集**

在 ImageNet 1K、14K、21K 以及 ImageNet-1K 的“清洁”验证集上进行评估。

**📈 对比分析**

与原始 CLIP 及基线方法比较，nvp 在 1K 上 Top‑1 从 75.1% 提升至 79.1%，在扩展标签空间保持 3–4% 的增益，并可实现 10–12 倍降维而几乎不损失准确率。

**⚠️ 局限性**

需调节正则化 λ，零样本分类对 λ 更敏感；在极低维或低 λ 下可能出现性能下降，且方法仅适用于有监督标签的场景。

---

## 251. A Unified Matrix-Spectral Framework for Stability and Interpretability in Deep Learning

**arXiv ID:** 2602.01136 | [PDF](https://arxiv.org/pdf/2602.01136v1)

**作者:** Ronald Katende `[一作]` (Kabale University), Ronald Katende `[通讯]` (Kabale University)

**通讯引用:** 5 | [OpenAlex ID](https://openalex.org/A5076646959)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5b4c1114-4a70-478e-9921-2514ee03850d` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出统一矩阵谱框架，利用 Jacobian、参数梯度、NTK Gram 矩阵和 Hessian 的谱信息来分析深度网络的稳定性与可解释性，并给出了全球矩阵稳定性指数。

**💡 创新点**

创新点在于将多种谱量聚合为单一指标，使用谱熵衡量典型敏感性，提供可计算的诊断与谱正则化策略；同时首次将这些谱量与归因稳定性直接关联。

**🔧 技术方法**

采用矩阵谱理论、谱熵、全球矩阵稳定性指数、NTK 分析、梯度与 Hessian 计算以及谱正则化技术。

**📊 数据集**

实验数据集包括 MNIST、CIFAR‑10、CIFAR‑100 以及合成数据。

**📈 对比分析**

与传统基于范数的稳定性指标对比，实验表明即使全局谱量变化不大，适度的谱正则化也能显著提升归因稳定性（如 FD 指标下降约 70%），显示出比传统方法更好的性能。

**⚠️ 局限性**

局限在于只关注谱分布，难以完全解释样本级的敏感性差异；对极大规模模型或不同任务的适用性尚待进一步验证。

---

## 252. Instance-Guided Unsupervised Domain Adaptation for Robotic Semantic Segmentation

**arXiv ID:** 2602.01389 | [PDF](https://arxiv.org/pdf/2602.01389v1)

**作者:** Michele Antonazzi `[一作]` (University of Milan), Nicola Basilico `[通讯]` (University of Milan)

**通讯引用:** 2230 | [OpenAlex ID](https://openalex.org/A5090235510)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出了一种基于三维地图与零样本实例分割模型的无监督域适应方法，利用多视角伪标签并进行实例级细化来提升机器人语义分割性能。

**💡 创新点**

创新点在于将SAM零样本实例分割与多视角一致性结合，设计两种自动提示策略实现实例级一致性和去除渲染伪影。

**🔧 技术方法**

使用了DeepLabV3-ResNet101作为基础语义分割网络，Kimera Semantics进行三维重建，多视角投影以及Segment Anything（SAM）进行实例分割。

**📊 数据集**

实验数据集为ScanNet，源域为场景11-707，目标域为场景1-10。

**📈 对比分析**

通过与仅基于多视角一致性的基线对比，本文在多场景下平均提升约5% mIoU，并且对不同体素分辨率具有鲁棒性。

**⚠️ 局限性**

主要局限在于对SAM实例分割的依赖以及在某些视角欠缺或纹理相似的物体上仍可能产生误分。

---

## 253. Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models

**arXiv ID:** 2602.01166 | [PDF](https://arxiv.org/pdf/2602.01166v1)

**作者:** Shuanghao Bai `[一作]` (Beijing Academy of Artificial Intelligence), Shanghang Zhang `[通讯]` (Peking University)

**通讯引用:** 10399 | [OpenAlex ID](https://openalex.org/A5013030532)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出了Latent Reasoning VLA框架，内化Chain-of-Thought到连续潜在空间，实现实时视觉-语言-动作控制。

**💡 创新点**

创新点在于将CoT从离散文本/视觉token转化为连续潜在表示，并通过三阶段课程学习将其迁移至动作生成，同时使用EMA稳定潜在学习。

**🔧 技术方法**

采用Qwen3-VL作为视觉语言模型，隐式潜在表示、流匹配动作生成、EMA视觉编码器、连续潜在CoT和逆动力学预测等技术。

**📊 数据集**

构建了LIBERO-LaRA、Bridge-LaRA两大模拟CoT数据集，并在真实机器人上采集长周期操纵数据，覆盖物体定位、子任务拆解等。

**📈 对比分析**

与多种无CoT、文本CoT、视觉CoT和隐式CoT基线对比，LaRA-VLA在LIBERO和SimplerEnv以及真实机器人任务中分别取得约97.9%与68.8%的平均成功率，推理延迟降低90%。

**⚠️ 局限性**

主要局限在于潜在CoT易崩塌、训练成本高以及单一潜在令表达能力受限，需进一步提升效率与表示丰富度。

---

## 254. Multi-Horizon Electricity Price Forecasting with Deep Learning in the Australian National Electricity Market

**arXiv ID:** 2602.01157 | [PDF](https://arxiv.org/pdf/2602.01157v1)

**作者:** Mohammed Osman Gani `[一作]` (Queensland University of Technology), Sara Khalifa `[通讯]` (Queensland University of Technology)

**通讯引用:** 1994 | [OpenAlex ID](https://openalex.org/A5064983246)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

本文提出了一套用于澳大利亚国家电力市场五个区域的日/两日电价多步预测框架，结合标准深度学习与最新时序模型。

**💡 创新点**

创新点在于将多天预测与多模型SOTA时序网络对比，并进行半小时粒度的时段误差分析。

**🔧 技术方法**

使用的技术包括LSTM、CNN‑LSTM、Transformer、以及TimeXer、TimeMixer、Mamba、TimesNet、iTransformer、DLinear等深度网络。

**📊 数据集**

所用数据集为2023‑2025年澳大利亚NEM五区30分钟级RRP价格序列。

**📈 对比分析**

通过MAE、RMSE、sMAPE、rMAE、MDA等指标以及区间级评估，结果表明传统DL模型总体表现优于SOTA，但后者在延长预测窗口时更稳健。

**⚠️ 局限性**

主要局限在于仅使用单变量价格输入、采用MSE损失及部分模型计算成本高，未充分利用外部特征或针对负价/尖峰的特殊损失。

---

## 255. Provable Cooperative Multi-Agent Exploration for Reward-Free MDPs

**arXiv ID:** 2602.01453 | [PDF](https://arxiv.org/pdf/2602.01453v1)

**作者:** Idan Barnea `[一作]` (Blavatnik School of Computer Science and AI, Tel Aviv University), Yishay Mansour `[通讯]` (Google Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了协同多智能体无奖励探索框架，用多智能体并行探索未知MDP并学习其转移动力学；

**💡 创新点**

揭示并证明了并行时间（学习阶段数）与智能体数量之间的尖锐阈值，证明当学习阶段数等于H时可用多项式数量智能体完成无奖励探索，而少于H时必须使用指数量智能体；

**🔧 技术方法**

采用阶段化学习、层级探索、可达性阈值β、基于占优策略的样本分配以及集中式估计动态的算法；

**📊 数据集**

无公开数据集，实验均在合成的有限马尔可夫决策过程（tabular, finite horizon）上验证；

**📈 对比分析**

与单智能体奖励自由算法相比，若阶段数为H，则本算法在智能体数量上可保持多项式（~S⁶H⁶A/ϵ²），并给出下界说明该上界在阶段数不足时无法压缩；

**⚠️ 局限性**

限制包括：高阶多项式（S⁶H⁶）依赖，适用于仅有限状态动作的表格MDP，未考虑连续或大规模状态空间，且在样本复杂度方面尚未达到最优（可进一步改进）

---

## 256. Improving Robustness of Vision-Language-Action Models by Restoring Corrupted Visual Inputs

**arXiv ID:** 2602.01158 | [PDF](https://arxiv.org/pdf/2602.01158v1)

**作者:** Daniel Yezid Guarnizo Orjuela `[一作]` (Politecnico di Milano), Matteo Matteucci `[通讯]` (Politecnico di Milano)

**通讯引用:** 6834 | [OpenAlex ID](https://openalex.org/A5003932703)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究了视觉-语言-动作模型在图像失真下的脆弱性，并提出了一个通用的图像恢复模块CRT来提升其鲁棒性。

**💡 创新点**

首次系统量化图像失真对VLA的影响，并设计了基于Transformer的CRT模块，利用对抗训练实现无须微调的恢复。

**🔧 技术方法**

采用Shifted Patch Tokenization、Rotary Position Embeddings、Locality Self-Attention的Transformer架构，并结合L1/SSIM与GAN对抗损失进行训练。

**📊 数据集**

使用LIBERO-10和Meta‑World MT50两套仿真任务，构造对应的失真–原始图像对进行训练与评估。

**📈 对比分析**

在Clean、CenterSquare、Gaussian Noise、HorizontalLines、WaterDrops五种失真下与基线VLA（π_0.5、SmolVLA）对比，CRT在π_0.5上几乎恢复至清晰基准，SmolVLA亦显著提升成功率，提升幅度约10–20%。

**⚠️ 局限性**

CRT在小型VLA上引入轻微性能下降，并且需要在检测到失真后才激活，当前模型未实现自适应触发；对极端失真仍有限恢复效果。

---

## 257. TxRay: Agentic Postmortem of Live Blockchain Attacks

**arXiv ID:** 2602.01317 | [PDF](https://arxiv.org/pdf/2602.01317v1)

**作者:** Ziyue Wang `[一作]` (Nanjing University), Liyi Zhou `[通讯]` (University of Sydney)

**通讯引用:** 925 | [OpenAlex ID](https://openalex.org/A5037118069)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出了 TxRay，一个基于 LLM 的自动化事后分析系统，能从单一交易哈希开始重建 DeFi 现场攻击生命周期、生成根因报告并输出可在 fork 上 deterministically 重放的无攻击者依赖 PoC。

**💡 创新点**

创新点在于将 LLM 与工具调用结合，形成迭代的挑战-验证循环，自动构造语义或acles并强制 PoC 自包含、参数化，首次实现高质量、可验证的 DeFi 事件回溯数据集和可重复实验的攻击重现。

**🔧 技术方法**

核心技术包括 OpenAI Agents SDK 与 Codex 交互的多代理框架、EVM 状态追踪与回放、合约字节码反编译、智能合约执行分析、Foundry 自动化测试和自定义语义断言。

**📊 数据集**

利用 DeFiHackLabs、DefiLlama、Rekt、BlockSec 等公开攻击记录作为训练与评测数据，并在 22 条 EVM 链上收集约 350 余条攻击实例来验证系统效果。

**📈 对比分析**

在 114 条符合后期训练截止的 ACT 攻击上，TxRay 以 100% 的根因对齐率、95% 的可重放 PoC 成功率、平均 40 分钟的根因完成时间和 10 分钟的 PoC 生成时间，成本约 4.4 美元/例，显著优于现有手工或半自动化方法。

**⚠️ 局限性**

局限包括仅覆盖 EVM 权限可用攻击、对攻击者已部署合约的字节码解析仍易出错、对跨链或离线组件攻击不适用，以及对 LLM 生成结果的内存化风险与对极端复杂攻击的推理深度不足。

---

## 258. Bias in the Ear of the Listener: Assessing Sensitivity in Audio Language Models Across Linguistic, Demographic, and Positional Variations

**arXiv ID:** 2602.01030 | [PDF](https://arxiv.org/pdf/2602.01030v1)

**作者:** Sheng-Lun Wei `[一作]` (National Taiwan University), Hsin-Hsi Chen `[通讯]` (National Taiwan University)

**通讯引用:** 7140 | [OpenAlex ID](https://openalex.org/A5000334344)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建并发布了 BiasInEar 语音增强的多语言多模态问答基准，系统评估了九种多模态大模型在语音输入下的偏见与鲁棒性。

**💡 创新点**

首次把选项顺序、语言、口音和性别等维度纳入语音评估框架，证明语音能放大已有文本偏差，并揭示推理复杂度与管道式架构可提升鲁棒性。

**🔧 技术方法**

采用 TTS 合成语音、ASR 质量校验、链式思考/显式推理提示、pipeline 与端到端对比，并用准确率、熵、APES 与 Fleiss' κ 等四指标对模型进行评测。

**📊 数据集**

使用 BiasInEar 数据集（基于 Global MMLU Lite），包含 70.8 小时、11,200 问题，覆盖英语、中文、韩语，按性别、口音与选项顺序均衡生成。

**📈 对比分析**

在同一问题的 28 种音频配置下进行对比，发现选项顺序是导致鲁棒性下降的最主要因素，语言与口音次之，性别影响最小；更大模型、更复杂推理和 pipeline 设计显著提升准确率、降低熵与 APES，提升 Fleiss' κ。

**⚠️ 局限性**

局限在于仅用 TTS 生成语音，口音划分离散且不够自然；样本量有限，未覆盖所有现有多模态大模型；实验依赖公开 API，可能受限；未来需引入真实录音、多种口音细粒度、更多模型进行验证。

---

## 259. Data Augmentation for High-Fidelity Generation of CAR-T/NK Immunological Synapse Images

**arXiv ID:** 2602.00949 | [PDF](https://arxiv.org/pdf/2602.00949v1)

**作者:** Xiang Zhang `[一作]` (Rochester Institute of Technology), Dongfang Liu `[通讯]` (Rutgers University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `67630363-6be0-4f51-ab05-7198250671a5` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了一套针对CAR‑T/NK免疫突触图像的生成与增强框架（IAAA和SAAA），能够合成高保真图像及其对应实例分割掩码，并显著提升检测与分割模型的精度。

**💡 创新点**

创新点：①使用实例感知自动增广（IAAA）结合贪心AutoAugment，在保持实例细节的同时生成多样化图像；②引入无监督扩散模型生成掩码并用Pix2Pix进行语义合成（SAAA），实现大规模、结构一致的图像-掩码对；③两种增广方法互补，既保留真实图像的分布，又扩充多样性，显著提升AP、AP_50/75、AP_s以及FID/KID指标。

**🔧 技术方法**

技术：Greedy AutoAugment搜索最佳增广策略、Wasserstein AutoEncoder评估保真度；无监督扩散概率模型（DDPM）生成掩码；Pix2Pix条件GAN配合自注意力、SE块、感知损失实现高质量图像合成；使用MMDetection、PyTorch等框架训练检测器。

**📊 数据集**

数据集：CAR‑T/NK细胞数据集（156张1024×1024，训练/验证/测试分布为93/31/32张）与Neural细胞数据集（644张640×512，训练/验证/测试分布为386/129/129张）。

**📈 对比分析**

与传统数据增强（裁剪、翻转、亮度调节）以及多种GAN（DCGAN、BigGAN、StyleGAN2、ControlNet、Stable Diffusion）对比，IAAA/SAAA在FID、KID指标上显著优于GAN，且在多阶段与单阶段检测器中AP提升平均6.3%（IAAA）或约+2–3%（SAAA，500张样本）。

**⚠️ 局限性**

限制：①仍需一定量的人工标注掩码作为IAAA的输入；②扩增规模受GPU内存和训练时间限制；③扩散模型在医学单色图像上的适配性差，导致对比实验效果不佳；④在极小样本或极高分辨率场景下，模型需进一步微调。

---

## 260. Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments

**arXiv ID:** 2602.01244 | [PDF](https://arxiv.org/pdf/2602.01244v1)

**作者:** Siwei Wu `[一作]` (University of Manchester), Chenghua Lin `[通讯]` (University of Manchester)

**通讯引用:** 3351 | [OpenAlex ID](https://openalex.org/A5024599321)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `f86bf285-fd08-4156-973b-6e6481af8fa0` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一个可扩展的终端代理轨迹生成管线TerminalTraj，通过筛选高质量GitHub仓库、构建Docker化环境、合成任务实例并用可执行验证代码验证轨迹，从而在八种编程语言上生成了32K Docker镜像和50,733条已验证终端轨迹；

**💡 创新点**

创新点在于（1）利用基于模型的仓库质量评分实现可扩展的环境构建；（2）生成实例时结合文档与Shell脚本，自动合成任务查询与可执行验证逻辑；（3）通过可执行验证而非LLM判定，显著提升轨迹质量；（4）实现了大规模、可执行、可验证的终端任务数据集。

**🔧 技术方法**

技术包括：奖励模型ScoreModel用于仓库质量评分；Dockerfile自动化构建与依赖注入；LLM（如Qwen3-Coder-480B）用于任务查询与验证代码生成；终端交互框架Terminus‑2；多轮SFT训练；pass@k测试时扩展；统计与可视化工具。

**📊 数据集**

数据集为TerminalTraj：从899,741个GitHub仓库中提取32,325个Docker镜像，生成1,030,695个实例，其中50,733条轨迹通过可执行验证；涵盖Python、C++、C、Java、JavaScript、PHP、HTML、Go八大语言及八个专业域。

**📈 对比分析**

与现有数据集（如Nex‑N1）和开源/闭源基线（Qwen3-32B、DeepSeek-V3.2等）比较，TerminalTraj‑32B在TerminalBench 1.0/2.0上分别达到35.30%/22.00%，超越所有≤100B参数模型并与480B Qwen3-Coder竞争；显著提升pass@16至63.75%。

**⚠️ 局限性**

局限性包括：构建Docker镜像成功率仅约17%，验证通过率约4%；依赖LLM生成查询/验证代码可能引入偏差；仅覆盖八种主流语言，其他语言缺失；训练仍以SFT为主，RL等在线学习未充分探索。

---

## 261. Bridging Lexical Ambiguity and Vision: A Mini Review on Visual Word Sense Disambiguation

**arXiv ID:** 2602.01193 | [PDF](https://arxiv.org/pdf/2602.01193v1)

**作者:** Shashini Nilukshi `[一作]` (Informatics Institute of Technology), Deshan Sumanathilaka `[通讯]` (Informatics Institute of Technology)

**通讯引用:** 30 | [OpenAlex ID](https://openalex.org/A5092142578)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文综述了2016-2025年视觉词义消歧（VWSD）的研究进展，系统梳理了从早期多模态特征融合、图网络方法到现代CLIP对比模型、扩散生成模型与大型语言模型（LLM）融合的不同框架，并对关键技术、数据集和评估结果进行比较；

**💡 创新点**

创新点在于将VWSD技术发展路径进行全面整理，阐述prompt工程、微调、跨语言适配及LLM驱动的定义生成如何提升消歧效果，指出CLIP、扩散模型与LLM协同的未来研究方向；

**🔧 技术方法**

使用的技术包括CLIP、BLIP、图像-文本对齐与对比学习、图神经网络与标签传播、LLM生成的定义与上下文扩展、扩散式文本生成图像、跨语言CLIP与语言无关对齐方法、知识库（WordNet、BabelNet等）集成；

**📊 数据集**

主要采用的公开数据集有SemEval‑2023 Task 1（基准VWSD集）、Wikidata、OmegaWiki、BabelPic、VerSe等，以及多语言测试集（英语、意大利语、波斯语）；

**📈 对比分析**

通过在HIT@1和MRR两项指标上对比，零样本CLIP在基准上表现较弱，微调CLIP/BLIP后可提升6–8% MRR；结合LLM扩展提示与定义的系统能达到约95.8% MRR、92% HIT@1的最高成绩；多语言实验显示跨语言CLIP与语言无关方法可保持较高的MCC和MRR；

**⚠️ 局限性**

局限性包括：评估仅依赖SemEval‑2023基准，缺乏多样化和跨领域测试；数据集多以英语为主，低资源语言缺乏标注；CLIP对罕见含义偏向常见含义，存在模型偏见；LLM生成的定义可能出现幻觉，影响精度；知识库集成复杂且易导致误导；缺乏鲁棒性、公平性与可解释性评估；

---

## 262. How Does Unfaithful Reasoning Emerge from Autoregressive Training? A Study of Synthetic Experiments

**arXiv ID:** 2602.01017 | [PDF](https://arxiv.org/pdf/2602.01017v1)

**作者:** Fuxin Wang `[一作]`, Yiqiao Zhong `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe`

**🎯 论文内容**

通过在受控合成任务Arithmetic Expression Reasoning (AER)上训练小型Transformer，研究自回归训练如何导致链式推理的忠实性与否。

**💡 创新点**

提出两种CoT忠实性定义并证明在噪声阈值下可实现忠实推理，揭示简易性偏差、推理模式分阶段演化以及自监督产生的隐式自我验证机制。

**🔧 技术方法**

使用小型Transformer（3层、2头、128维）与RoPE位置编码、AdamW优化器进行自回归训练，并结合一致性、干预式度量和预测熵等指标。

**📊 数据集**

生成合成数据：基于素数模97的模块运算链，噪声水平可控（_1,_2），并在不同噪声、计算量下进行实验。

**📈 对比分析**

通过一致性、干预、熵等指标与不同噪声、训练步数下的模型表现对比，发现低噪声且大复杂度差可保持高忠实度，模型呈现四阶段推理模式；转为跳步推理时不忠实。

**⚠️ 局限性**

仅限于小型模型与合成任务，未验证在大规模LLM或真实推理任务上的可推广性，且未考虑RL/奖励机制对自回归训练的影响。

---

## 263. Profit Maximization in Closed Social Networks

**arXiv ID:** 2602.01232 | [PDF](https://arxiv.org/pdf/2602.01232v1)

**作者:** Poonam Sharma `[一作]` (Indian Institute of Technology Jammu), Suman Banerjee `[通讯]` (Indian Institute of Technology Jammu)

**通讯引用:** 5667 | [OpenAlex ID](https://openalex.org/A5033218913)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `5b4c1114-4a70-478e-9921-2514ee03850d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

研究了在闭合社交网络中，给定预算 B 和每个节点最多 ℓ 条出边限制的情况下，如何选择种子节点与边来最大化利润，并提出了采样近似算法和边局部增益启发式。

**💡 创新点**

首次把利润最大化问题推广到闭合网络，并在此框架下设计了两种解决方案：采样逼近与边局部增益启发式；同时给出了样本量上界与时间空间复杂度分析。

**🔧 技术方法**

采用独立级联（IC）模型作为传播模型；采样算法利用随机生成扩散网络并估计利润；启发式算法通过高阶度邻居选择和边局部增益计算实现近似最优。

**📊 数据集**

使用了两个公开真实网络数据集：Email‑Eu‑core（1005 节点、25571 条有向边）和 Facebook（4039 节点、88234 条无向边）。

**📈 对比分析**

与随机选择和高度选择两种基线对比，实验显示采样算法在利润上略优于基线，启发式算法在利润上显著领先（约 40‑300% 的提升），但其计算时间显著更长；随机和高度算法速度快但利润最低。

**⚠️ 局限性**

主要局限包括：采样算法需要较多样本才能逼近最优，导致计算开销大；启发式算法时间复杂度高，难以处理大规模网络；两种方法均假设传播遵循 IC 模型，无法直接迁移到其他传播模型或动态网络场景。

---

## 264. The BoBW Algorithms for Heavy-Tailed MDPs

**arXiv ID:** 2602.01295 | [PDF](https://arxiv.org/pdf/2602.01295v1)

**作者:** Yu Chen `[一作]` (Institute for Interdisciplinary Information Sciences), Longbo Huang `[通讯]` (Institute for Interdisciplinary Information Sciences)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

研究了具有重尾反馈的情节马尔可夫决策过程（HTMDPs），提出了两种算法，分别在已知和未知转移设置下实现了最佳双重世界（BoBW）保证。

**💡 创新点**

创新点在于提出了针对HTMDPs的算法，能够在对抗性环境中实现实例无关的后悔界限，并在自约束环境中实现对数实例相关的后悔界限。

**🔧 技术方法**

使用了Follow-The-Regularized-Leader (FTRL) 框架，结合了1/α-Tsallis熵正则化和新颖的跳过损失估计器。

**📊 数据集**

论文中没有具体提到使用的数据集，但讨论了在重尾反馈的实际应用场景，如网络流量路由、金融资产定价和图像信号处理。

**📈 对比分析**

与现有方法相比，提出的算法在对抗性环境中实现了𝒪(T^1/α)的后悔界限，在自约束环境中实现了𝒪(log T)的后悔界限，显示出更好的适应性和性能。

**⚠️ 局限性**

限制在于现有算法主要集中在重尾反馈的理论分析上，实际应用中可能面临的复杂环境和动态变化尚未完全解决。

---

## 265. Benchmarking of algorithms for set partitions

**arXiv ID:** 2602.01350 | [PDF](https://arxiv.org/pdf/2602.01350v1)

**作者:** Arnav Khinvasara `[一作]` (University of California), Alexander Pikovski `[通讯]` (Unatech)

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究集合划分的枚举方法，给出Bell数的近似公式，并对四种非递归算法进行实验比较，最终推荐Djokic等人的算法；

**💡 创新点**

提出了一种实用的Bell数近似表达式，并通过系统实验验证了四种算法的实际性能，给出了最优实现方案；

**🔧 技术方法**

采用C语言实现，使用GCC、ICC、MSVC编译器，在Linux/Windows环境下对算法进行基准测试；

**📊 数据集**

实验使用不同大小的集合n（从8到15）作为数据集，计算对应的Bell数和枚举时间；

**📈 对比分析**

采用CPU运行时间对比，Djokic算法在Linux/ICC环境下最快，运行时间比Hutchinson慢数十倍，Semba和Er略快于Djokic；

**⚠️ 局限性**

仅做了经验性比较，未给出理论复杂度分析；实验规模有限，未覆盖大规模n；未考虑灰码或硬件加速；

---

## 266. Offline Discovery of Interpretable Skills from Multi-Task Trajectories

**arXiv ID:** 2602.01018 | [PDF](https://arxiv.org/pdf/2602.01018v1)

**作者:** Chongyu Zhu `[一作]` (University of Toronto), Chi-Guhn Lee `[通讯]` (University of Toronto)

**通讯引用:** 2860 | [OpenAlex ID](https://openalex.org/A5057636084)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

在缺乏显式奖励和子任务标注的离线演示数据上，提出三阶段弱监督方法LOKI，用宏观分割+微观分割+层次策略实现可重用、可解释的技能学习。

**💡 创新点**

创新点在于结合任务弱标签的强制VQ‑VAE进行宏观分割，随后利用自监督序列VAE与迭代聚类实现细粒度分割，并对齐任务一致的技能序列，从而自动发现可转移且语义对齐的技能。

**🔧 技术方法**

使用技术包括Enforced VQ‑VAE、基于熵的边界检测、滑动窗口序列VAE、K‑Means迭代细化、任务技能对齐、选项框架终止函数以及条件行为克隆。

**📊 数据集**

数据集为D4RL Kitchen benchmark中的kitchen‑mixed‑v0离线数据，选取三种复合任务（MKSH、MBTH、MSSH）共71条成功轨迹。

**📈 对比分析**

与DADS、OPAL等层次IL基线对比，LOKI在低层政策MSE和终止函数准确率上明显优于基线，且可在新任务上实现90%+成功率。

**⚠️ 局限性**

局限性包括仅在结构化状态空间验证，需手动选择弱标签，难以直接迁移到高维图像输入，以及对非常复杂任务的可扩展性待验证。

---

## 267. Reliable Use of Lemmas via Eligibility Reasoning and Section$-$Aware Reinforcement Learning

**arXiv ID:** 2602.00998 | [PDF](https://arxiv.org/pdf/2602.00998v1)

**作者:** Zhikun Xu `[一作]` (Arizona State University), Zicheng Liu `[通讯]` (Advanced Micro Devices)

**通讯引用:** 19876 | [OpenAlex ID](https://openalex.org/A5101728117)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究大型语言模型在数学证明中使用引理时的误用问题，提出将引理判定拆分为前置条件检查和结论效用检查的结构化任务，并通过区分式损失掩码的强化学习训练模型在使用引理前进行“先检查后使用”的判定；

**💡 创新点**

创新点在于：①将引理使用拆成可审计的两段检查；②使用GRPO的区分式损失掩码，使梯度只惩罚错误的检查段，强化“先检查后使用”的安全范式；

**🔧 技术方法**

技术手段包括：两段输出结构（前置条件+结论效用）、前置条件与结论效用的自由文本推理、GRPO（Group Relative Policy Optimization）与区分式损失掩码、SC@7多次采样自洽、二元奖励与格式惩罚；

**📊 数据集**

使用的数据集有：NaturalProofs、NLPS、Isabelle 证明选择、IMO 归纳、DeepTheorem  perturbation、Putnam-Axiom、IneqMath、CounterMATH、MATH-Perturb、TheoremQA 等；

**📈 对比分析**

对比方法：将 vanilla、单标签 GRPO、带区分式掩码的 GRPO 在域内判定、扰动鲁棒性、以及 E2E 下游任务上进行评估。带掩码模型在域内提升约10‑15%，在扰动测试中提升最多23分，E2E 任务与单标签基线相当或略有优势；

**⚠️ 局限性**

局限性：仅聚焦引理判定而非完整证明生成；扰动数据只标注前置条件，缺少结论效用标签；奖励设置过于二元，忽略细粒度信号；实验仅在四个中型模型和英语数据集，未覆盖多语言或其他证明助手。

---

## 268. Radioactive 3D Gaussian Ray Tracing for Tomographic Reconstruction

**arXiv ID:** 2602.01057 | [PDF](https://arxiv.org/pdf/2602.01057v1)

**作者:** Ling Chen `[一作]` (Independent Researcher), Bao Yang `[通讯]` (Southern Medical University)

**通讯引用:** 16836 | [OpenAlex ID](https://openalex.org/A5023092716)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f` `dc6c6f4a-9d29-4fb8-b59a-f6c271315b9b`

**🎯 论文内容**

提出一种基于3D高斯射线追踪的断层重建框架，替代传统的局部仿射投影方法；

**💡 创新点**

核心创新是通过解析计算3D高斯沿射线的积分，消除仿射逼近误差并实现对扫描器几何的精确建模；

**🔧 技术方法**

采用PyTorch与NVIDIA OptiX射线追踪引擎实现解析线积分，并利用BVH加速；

**📊 数据集**

在NEMA仿真、三点源Monte‑Carlo模拟以及真实脑PET数据上进行评估，并与CT Synthetic/Real 数据集对比；

**📈 对比分析**

与OSEM和R2‑Gaussian比较，结果显示本方法在PET上量化准确性最高，CT上PSNR略优，SNR与噪声抑制与OSEM相近；

**⚠️ 局限性**

主要局限是计算量大、运行速度慢，且仅在模拟/小规模真实数据上验证，缺乏大规模公开PET数据与散射、随机等物理效应的完整建模。

---

## 269. Baseline Method of the Foundation Model Challenge for Ultrasound Image Analysis

**arXiv ID:** 2602.01055 | [PDF](https://arxiv.org/pdf/2602.01055v1)

**作者:** Bo Deng `[一作]`, Jieyun Bai `[通讯]` (University of Auckland)

**通讯引用:** 1239 | [OpenAlex ID](https://openalex.org/A5009284742)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `7b0f05dc-d396-4b03-96d2-a379dbd5049d` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个多头多任务学习框架，统一处理超声图像的分割、分类、检测与回归任务

**💡 创新点**

通过任务特定的路由机制将全局与稠密任务分离，兼顾语义抽象和空间细节，首次在单一网络上完成多种超声任务并建立大规模基准

**🔧 技术方法**

使用ImageNet预训练的EfficientNet‑B4骨干、特征金字塔网络（FPN）、多头任务路由、复合损失和余弦退火学习率

**📊 数据集**

在FMC_UIA 2026挑战提供的超声数据集上训练，包含27个子任务，涵盖胎儿器官、肿瘤、甲状腺结节等多种解剖结构

**📈 对比分析**

与官方基准对比，平均分割DSC 0.7543、HD 81.18；分类AUC 0.9155、F1 0.7896、MCC 0.6766；检测IoU 0.2641；回归MRE 67.43像素，表现总体稳健但检测与回归略低

**⚠️ 局限性**

检测小目标和高精度回归受分辨率限制和简化的网格检测头影响，存在负迁移与类不平衡导致的性能瓶颈

---

## 270. Diving into Kronecker Adapters: Component Design Matters

**arXiv ID:** 2602.01267 | [PDF](https://arxiv.org/pdf/2602.01267v1)

**作者:** Jiayu Bai `[一作]` (School of Electronic Information and Communications, Huazhong University of Science and Technology), Zenan Ling `[通讯]` (School of Electronic Information and Communications, Huazhong University of Science and Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文对 Kronecker adapters 的组件设计（r、r1、r2）进行细粒度理论与实证分析，并基于此提出了 Component Designed Kronecker Adapters (CDKA)，通过合理配置组件并加入训练稳定化因子与特定初始化方式，显著提升了 PEFT 方案的性能。

**💡 创新点**

创新点在于：①系统揭示 r1、r2 与 r 对 Kronecker adapters 表达能力和子空间对齐的影响，并给出理论导向的设计原则；②提出参数预算下的配置指南；③设计 λ 缩放因子和随机/零初始化组合，确保不同配置下训练稳定；④在多任务上验证这些原则的普适性。

**🔧 技术方法**

主要技术包括 Kronecker 乘积与 Kronecker 奇异值分解、梯度下降子空间对齐分析、Kaiming 初始化、参数预算约束、训练稳定化缩放因子 λ 等。

**📊 数据集**

使用的数据集包括 GLUE（MNLI、SST‑2、CoLA、QNLI、MRPC）用于 NLU；MetaMathQA（训练）和 GSM8k（评估）用于数学推理；Code‑Feedback（训练）和 HumanEval（评估）用于代码生成；同时在 LLaMA‑2‑7B 与 LLaMA‑3.1‑8B 上做实验。

**📈 对比分析**

与 LoRA、KronA、LoRA‑One、PiSSA 等多种 PEFT 基线对比，实验表明：在 NLU 任务上仅使用 12.5% 可训练参数即可接近全微调；在数学推理任务上相较 LoRA‑One 提升 1.31pp；在代码生成任务上排名第二；计算成本与 LoRA 差别不大。

**⚠️ 局限性**

局限性包括：需要手动调节 r、r1、r2 以满足预算与性能平衡；理论分析基于线性/随机初始化假设，未充分验证在更复杂非线性模型中的泛化；仅在单轮训练下评估，对长周期训练与大规模模型的适用性仍待进一步研究。

---

## 271. FUSE-Flow: Scalable Real-Time Multi-View Point Cloud Reconstruction Using Confidence

**arXiv ID:** 2602.01035 | [PDF](https://arxiv.org/pdf/2602.01035v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 272. On the Expressive Power of Permutation-Equivariant Weight-Space Networks

**arXiv ID:** 2602.01083 | [PDF](https://arxiv.org/pdf/2602.01083v1)

**作者:** Adir Dayan `[一作]` (Technion Israel Institute of Technology), Haggai Maron `[通讯]` (NVIDIA Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

**🎯 论文内容**

本文建立了置换等价权重空间网络的统一理论框架，并在四个自然的近似场景中完整表征其可表达性。

**💡 创新点**

主要创新在于证明所有主流权重空间网络在表达能力上等价，给出在一般位置与足够大输入网络结构下的全局通用性定理，弥补了以往部分结果的不足。

**🔧 技术方法**

通过群论、连续化归约、Stone‑Weierstrass 论证及可测度与可分离性等数学工具，系统地证明了这些表达性结论。

**📊 数据集**

本工作为纯理论研究，无实验数据集；所有结论均在理论假设下推导。

**📈 对比分析**

没有进行实验对比，性能评价仅在理论层面给出通用性（全局逼近）的证明，未给出数值指标。

**⚠️ 局限性**

局限性包括：只关注固定架构的 MLP 权重空间、未讨论优化与泛化、缺乏低精度场景的分析、未验证更大网络能否实测提升等。

---

## 273. LASS-ODE: Scaling ODE Computations to Connect Foundation Models with Dynamical Physical Systems

**arXiv ID:** 2602.01009 | [PDF](https://arxiv.org/pdf/2602.01009v1)

**作者:** Haoran Li `[一作]` (Arizona State University), Erik Blasch `[通讯]` (Air Force Research Laboratory)

**通讯引用:** 19166 | [OpenAlex ID](https://openalex.org/A5023894377)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `a8e75ba4-7a2d-4153-b003-06c94533add0` `5a41884c-404f-4688-a89c-aa238c10fe68` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

开发了 LASS-ODE 这一基于 Transformer 的基础模型，用于大规模预训练并能在物理约束下对多种 ODE 系统进行高效的动态预测。

**💡 创新点**

创新点包括：① 用 token‑wise 的局部线性 ODE 表示取代昂贵的神经 ODE 集成，从而显著提升计算可扩展性；② 设计了通用结构枢纽（CSH）与跨系统注意力机制，实现不同 ODE 之间知识的共享与迁移。

**🔧 技术方法**

技术细节涉及：Transformer 主干、内部与跨系统注意力、RBF 时间编码与调制的 token 化、Mixture‑of‑Experts (MoE)、基于线性 ODE 的解码器以及 LoRA 细调。

**📊 数据集**

预训练使用 40GB 大规模 ODE 路径集合，涵盖多种自治系统（如 Cauchy‑Euler、FitzHugh‑Nagumo、Swept Sines、Wh_sineinmeas、Duffing 等），具有不同状态维度与时间尺度。

**📈 对比分析**

与现有时间序列基础模型、Transformer、Latent ODE、ContiFormer 等方法在内部推断与零样本测试中对比，LASS-ODE 在多数系统上实现了 70% 以上的 MSE 降低，且在零样本场景下表现最优。

**⚠️ 局限性**

局限性包括：仅针对自治 ODE，线性近似在极度非线性系统下可能不佳；需要海量预训练数据，且在部分复杂系统的零样本泛化仍有限。

---

## 274. Sem-NaVAE: Semantically-Guided Outdoor Mapless Navigation via Generative Trajectory Priors

**arXiv ID:** 2602.01429 | [PDF](https://arxiv.org/pdf/2602.01429v1)

**作者:** Gonzalo Olguin `[一作]` (Universidad de Chile), Javier Ruiz-del-Solar `[通讯]` (Universidad de Chile)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种基于 CVAE 生成多条轨迹并使用 VLM 进行语义选择的无地图户外导航框架

**💡 创新点**

融合多模态生成与开放词汇分割，实现多样化、语义可控的轨迹选择，并引入异步更新策略提升对动态环境的适应性

**🔧 技术方法**

条件变分自编码器（CVAE）+ PointNet 分割 + CLIPSeg 开放词汇分割 + RL 本地规划器 + 视觉‑激光融合感知

**📊 数据集**

1706 条来自 Husarion Panther UGV 在智利工程校园收集的 LiDAR、RGB、IMU、GPS‑RTK 数据，结合 NavFN 生成的合成路径作为训练与评估集

**📈 对比分析**

与 MTG、MTG'、GPT 等基线比较，采用成功率、SPL、EPT、导航时间比等指标，Sem‑NaVAE 在成功率 +27%、EPT +4.3%、时间比 +44% 等方面均优于基线

**⚠️ 局限性**

对轨迹数量和 VLM 推理时延敏感；在极端动态障碍或全新环境下仍可能产生不可行轨迹；需要大量训练数据与 GPU 资源

---

## 275. Finding Differentially Private Second Order Stationary Points in Stochastic Minimax Optimization

**arXiv ID:** 2602.01339 | [PDF](https://arxiv.org/pdf/2602.01339v1)

**作者:** Difei Xu `[一作]` (King Abdullah University of Science and Technology), Di Wang `[通讯]` (King Abdullah University of Science and Technology)

**通讯引用:** 3998 | [OpenAlex ID](https://openalex.org/A5100401482)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `9cc9baba-5356-466d-81ff-d80028d90279` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究了在随机非凸-强凹式最小-最大优化中，使用差分隐私的第一阶方法求解近似二阶稳态点（SOSP）。

**💡 创新点**

首次提出统一处理经验风险和总体风险的DP‑SOSP框架，采用SPIDER式方差减小、嵌套梯度下降-上升与高斯扰动的组合，并通过块级（q周期）分析和扰动-监测逃逸机制实现二阶收敛，且不需要Hessian信息，匹配最佳DP‑第一阶收敛率。

**🔧 技术方法**

技术手段包括：SPIDER递归梯度追踪、强凹性内层迭代、块级误差控制、扰动-监测逃逸规则、Gaussian机制实现差分隐私、并行迭代更新。

**📊 数据集**

实验使用合成低秩矩阵感知数据集（p=q=20，秩3，样本量400），并生成随机测量矩阵和噪声标签。

**📈 对比分析**

与DP‑SGDA、Sto‑SPIDER、Ada‑DP‑SPIDER（单层DP‑SOSP）以及PrivateDiff（第一阶最小-最大DP）进行对比。DP‑RGDA在相同隐私预算下，收敛到更低的目标值、梯度范数和更接近零的最小Hessian特征值，明显优于单层DP‑SOSP基线，且与PrivateDiff在曲率诊断上相当，但在目标值与梯度上略有优势。

**⚠️ 局限性**

局限性包括：仅适用于强凹内层的非凸最小-最大问题；对强凹性、Lipschitz性等假设要求严格；隐私噪声会降低收敛速度，需在小样本或高维场景下谨慎调参；未在真实世界数据集上验证，且对下游公平性、可解释性等非隐私风险未作深入探讨。

---

## 276. EMFormer: Efficient Multi-Scale Transformer for Accumulative Context Weather Forecasting

**arXiv ID:** 2602.01194 | [PDF](https://arxiv.org/pdf/2602.01194v1)

**作者:** Hao Chen `[一作]` (Hong Kong University of Science and Technology), Lei Bai `[通讯]` (Shanghai AI Laboratory)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

构建了一套预训练—微调—预测的完整管线，提出了高效多尺度Transformer EMFormer、累计上下文微调以及正弦加权损失，旨在提升长时段天气预报精度。

**💡 创新点**

创新点包括：1) 通过单次卷积实现多尺度特征提取的多卷积层（Multi‑Convs），大幅降低计算量；2) 采用累计上下文微调（Accumulating Context Fine‑tuning）在自回归预测中保留历史KV信息；3) 设计正弦加权损失在训练初期侧重纬度加权，后期转向变量自适应，以实现学习速率的自适应平衡。

**🔧 技术方法**

使用技术包括：Transformer（自注意力、窗口注意力）、卷积多尺度层、KV缓存管理、CUDA自定义核实现、可学习正弦加权损失和多任务优化。

**📊 数据集**

主要数据集：ERA5气象再分析（用于6小时、1日、5日、10日等长时段预报）、ImageNet‑1K（图像分类）和ADE20K（语义分割）。

**📈 对比分析**

与现有气象模型（Pangu‑weather、Graphcast、FourCastNet 等）及视觉基准模型相比，在ERA5 1–10天预报中RMSE与ACC均优于对手，图像分类的Top‑1精度在所有参数规模下均位列SOTA；在语义分割任务中，mIoU 与 FLOPs 均优于多数对手。

**⚠️ 局限性**

局限性：预训练阶段仍需大量算力；累计上下文微调在长预测时对内存需求较高；在极端事件（如台风轨迹）预测中仍存在误差积累，且对不同气象变量的动态权重需要进一步调优。

---

## 277. Safe Stochastic Explorer: Enabling Safe Goal Driven Exploration in Stochastic Environments and Safe Interaction with Unknown Objects

**arXiv ID:** 2602.00868 | [PDF](https://arxiv.org/pdf/2602.00868v1)

**作者:** Nikhil Uday Shinde `[一作]` (University of California San Diego), Sylvia Herbert `[通讯]` (University of California San Diego)

**通讯引用:** 727 | [OpenAlex ID](https://openalex.org/A5071321544)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出了一套名为 Safe Stochastic Explorer（SSE）的框架，用于在未知且带随机动力学的环境中进行安全的目标驱动探索，并通过高斯过程学习安全函数来动态扩展安全集，分别在离散、连续和多对象交互三类场景下验证其有效性。

**💡 创新点**

创新点包括：①在安全探索中首次显式考虑随机转移，结合高斯过程的不确定度与 Lipschitz 连续性，设计安全回归（stochastic return/arrival）运算符；②提出基于贝塔缩放的动态安全阈值调节策略，以平衡安全与性能；③为多对象交互提供对象中心化的 GP 建模与安全集交集方法，实现对未知物理属性的安全交互。

**🔧 技术方法**

技术手段主要有：高斯过程回归（RBF 核）用于估计安全函数并给出上下置信界；基于安全集的集合运算符（立即安全、随机回归、安全到达）；采样式规划（RRT/PRM）在连续空间中构建安全路径；贝塔缩放与阈值偏移（β‑scaling）实现安全-性能权衡；多对象安全集通过交集构造实现。

**📊 数据集**

实验数据集包括：①离散格点地面机器人环境，随机生成的危险区域和噪声转移；②连续转移的地面机器人环境（Gaussian噪声）；③基于 PyBullet 的安全物体环境，UR5 与多种未知质量/重心的瓶子；④真实硬件实验，Franka Emika Panda 与装满不同重量的 Pringles 罐；所有实验均以随机种子产生多组轨迹。

**📈 对比分析**

与传统基线（不考虑随机性或仅使用安全阈值检查）相比，SSE 在离散、连续和物体交互任务中都显著提升了成功率、降低了安全违规率，并探索了更多状态；尤其在高噪声情形下，SSE 的成功率可达 88% 以上，而基线仅 35%–45%。

**⚠️ 局限性**

局限性主要有：①需要先验的 Lipschitz 常数、GP 超参数与噪声模型，设置不当会导致过度保守或不安全；②高斯过程的 O(N³) 计算复杂度限制了大规模状态空间的可扩展性；③连续与物体情形缺乏安全回归保证，可能出现“卡住”；④多对象交集可能过度保守且未考虑对象间相互作用；⑤当前仅使用 RBF 核，对非 RBF 适用性有限。

---

## 278. ChronoSpike: An Adaptive Spiking Graph Neural Network for Dynamic Graphs

**arXiv ID:** 2602.01124 | [PDF](https://arxiv.org/pdf/2602.01124v1)

**作者:** Md Abrar Jahin `[一作]` (University of Southern California), Craig Knoblock `[通讯]` (University of Southern California)

**通讯引用:** 14547 | [OpenAlex ID](https://openalex.org/A5089542402)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `3f18e8e3-0266-457c-8567-9039b6d2394d` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种自适应尖峰图神经网络ChronoSpike，用于动态图表征学习，兼顾结构与时间演化。

**💡 创新点**

创新点包括：①可学习的LIF神经元实现多尺度时序动力学；②多头注意力空间聚合保留连续特征信息；③轻量Transformer时序编码器捕捉长程依赖，保持线性时间和内存复杂度；④引入对比学习增强表示鲁棒性。

**🔧 技术方法**

技术方案包含：自适应LIF尖峰神经元、邻域采样+多头注意力聚合、Transformer时序编码、对比损失、可视化与理论稳定性分析。

**📊 数据集**

使用三大工业级动态图数据集：DBLP、Tmall 与 Patent，涵盖数十万到数百万节点与数千时间步。

**📈 对比分析**

与12种现有方法（静态、递归、注意力与尖峰模型）对比，ChronoSpike 在 Macro‑F1 与 Micro‑F1 上平均提升约2–3%，同时训练速度比递归模型快3–10倍，参数量保持在约10万，规模不随图大小变化。

**⚠️ 局限性**

局限性：仅适用于离散时间、均匀分辨率的快照；Transformer需要完整历史序列，难以实时流式处理；未针对神经形态硬件做专门优化；对比学习使用的增广手段可能不适用于所有领域。

---

## 279. GradingAttack: Attacking Large Language Models Towards Short Answer Grading Ability

**arXiv ID:** 2602.00979 | [PDF](https://arxiv.org/pdf/2602.00979v1)

**作者:** Xueyi Li `[一作]` (Jinan University), Weiqi Luo `[通讯]` (Jinan University)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 GradingAttack 框架，对 LLM 基础的自动短答评估（ASAG）模型进行细粒度的对抗攻击，以评估其评分操纵的脆弱性。

**💡 创新点**

创新地将通用对抗方法细化为 token 级和 prompt 级两种攻击，并提出 Camouflage Attack Score (CAS) 量化攻击的隐蔽性与效果平衡。

**🔧 技术方法**

使用 token 级攻击（如 GCG）和 prompt 级攻击（如角色扮演）技术，并通过 Beta 分布构造的 CAS 评估指标进行量化评估。

**📊 数据集**

在 GAOKAO23、MATH、GSM8K、SciEntsBank 和 Math23K 五个教育数据集上开展实验，数据覆盖多学科数学与科学问答。

**📈 对比分析**

与 GCG、DeGCG、AutoDAN、ICA、Virtual Context 等基线对比，Prompt 级攻击的 ASR 最高，Token 级攻击的 CAS 更佳，整体攻击效果显著且实验证明两种攻击各有优势。

**⚠️ 局限性**

实验受限于当前公开 LLM，缺乏针对性防御措施，且对不同语言、领域及更大规模模型的适用性尚未充分验证。

---

## 280. Counting Unit Circular Arc Intersections

**arXiv ID:** 2602.01074 | [PDF](https://arxiv.org/pdf/2602.01074v1)

**作者:** Haitao Wang `[一作]` (University of Utah), Haitao Wang `[通讯]` (University of Utah)

**通讯引用:** 37826 | [OpenAlex ID](https://openalex.org/A5100396117)

**关键词:** `a42c7bd6-d8fd-40d3-94df-ae8cd808f5c4`

**🎯 论文内容**

提出一种新的算法，用来统计平面上相同半径圆弧集合中所有相交点的个数。

**💡 创新点**

创新点在于将原来耗时 O(n^{4/3+ε}) 的最优算法进一步改进到 O(n^{4/3}·log^{16/3}n)，并且在交点数 K 较小的情况下进一步降低到 O(n^{1+ε}+K^{1/3}n^{2/3}(n^2/n+K)^ε·log^{16/3}n)。

**🔧 技术方法**

核心技术包括层次化 (1/r)-cutting、伪梯形（pseudo‑trapezoid）分割、几何观察（如弧的“lune”和“wedge”判定）、范围搜索结构（Matoušek 结构）以及多级数据结构的组合，以便高效处理不同类型的弧相交情况。

**📊 数据集**

算法基于理论分析，无实际数据集；所有实验和评估均在理论复杂度层面进行。

**📈 对比分析**

相较于之前的 O(n^{4/3+ε}) 方案，本文将上界的多项式因子从 O(n^c) 降至 O(log^c n)（c≈16/3），并给出了在 K 较小场景下更快的时间。下界为 Ω(n^{4/3})，两者仅差多项式对数因子。

**⚠️ 局限性**

主要限制：算法实现极其复杂，涉及大量细分情况与多层递归；常数与对数阶因子较大，实际性能可能受限；对五个几何条件的依赖使得进一步优化难度较高。

---

## 281. Test-time Generalization for Physics through Neural Operator Splitting

**arXiv ID:** 2602.00884 | [PDF](https://arxiv.org/pdf/2602.00884v1)

**作者:** Louis Serrano `[一作]` (New York University), Rudy Morel `[通讯]` (Flatiron Institute)

**通讯引用:** 44 | [OpenAlex ID](https://openalex.org/A5099046031)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `14d48e9d-0069-4ad9-996a-1d5968216998` `a8e75ba4-7a2d-4153-b003-06c94533add0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种在测试时不修改权重的神经算子拆分方法，用预训练的DISCO模型字典来组合已学到的算子，从而实现对外部分布（OOD）PDE动力学的零样本推断。

**💡 创新点**

创新点在于将神经算子拆分与搜索相结合：利用预训练字典中的算子进行组合，借助光束搜索（Beam Search）在测试时找到最优算子组合；同时提供了通过算子组合实现系统辨识和参数估计的能力。

**🔧 技术方法**

核心技术包括DISCO预训练（基于超网络生成算子权重）、算子字典构建、基于光束搜索的组合策略以及算子拆分（Lie/Strang）实现算子叠加与时间积分。

**📊 数据集**

使用四个基准数据集：1D 线性/非线性扩散-对流方程、1D 非线性对流-扩散-色散方程、2D Gray‑Scott 反应扩散系统以及2D Navier–Stokes流体动力学（采用Euler与扩散算子分别训练）。

**📈 对比分析**

与DISCO原版、MPP、Zebra、GEPS等方法对比，在参数外推和算子组合两类OOD任务中，本文方法在大多数任务上均显著降低NRMSE（如线性对流-扩散外推任务从0.27降至0.02，非线性扩散-色散组合从0.25降至0.05），并在参数估计上实现高精度。

**⚠️ 局限性**

局限性包括：算子必须在相同空间维度、网格和物理场上兼容；对不同分辨率或多物理量耦合的系统扩展受限；搜索过程虽然高效但仍需一定计算开销，尤其在极大算子字典时。

---

## 282. Superposition unifies power-law training dynamics

**arXiv ID:** 2602.01045 | [PDF](https://arxiv.org/pdf/2602.01045v1)

**作者:** Zixin Jessie Chen `[一作]` (Massachusetts Institute of Technology), Jeff Gore `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 11198 | [OpenAlex ID](https://openalex.org/A5003202779)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `8d10c613-917e-4880-9716-17789f50e119` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文构建了一个教师‑学生线性模型，研究特征叠加（superposition）对训练动力学的影响，分别推导了无叠加和叠加两种情形下的幂律训练曲线；

**💡 创新点**

创新点在于发现叠加会把训练指数统一为约1（与输入特征分布、通道重要性无关），并给出理论解释；同时在无叠加时精确推导了指数与输入频率衰减a、通道衰减b的关系；

**🔧 技术方法**

主要技术包括：教师‑学生线性框架、随机投影嵌入、ReLU+偏置抑制干扰、梯度下降连续时间分析、积分求幂律指数、SGD实验验证；

**📊 数据集**

使用的是合成稀疏输入分布（Bernoulli+Uniform）以及对角权重的教师矩阵，模拟自然语言多尺度特征分布；未使用公开真实数据集；

**📈 对比分析**

通过对比理论预测与实验，验证无叠加时指数为(a+2b‑1)/a；叠加时指数稳为≈1，训练速度提升十倍；同时绘制最优计算前沿，显示模型规模与计算预算的功率律关系（指数≈0.27）；

**⚠️ 局限性**

局限性：仅考虑线性单层模型，未覆盖多层、注意力等结构；未给出为何精确为1的严格证明；只关注中期训练阶段；随机投影可能并非最优方式；未评估最终性能与过拟合风险。

---

## 283. Low-latency Federated LLM Fine-tuning Over Wireless Networks

**arXiv ID:** 2602.01024 | [PDF](https://arxiv.org/pdf/2602.01024v1)

**作者:** Zhiwen Pang `[一作]` (Nanjing University of Science and Technology), Feng Shu `[通讯]` (Hainan University)

**通讯引用:** 8199 | [OpenAlex ID](https://openalex.org/A5044969631)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种联合客户端特定剪枝与带宽分配（JCPBA）框架，用于在资源受限的无线网络上高效联邦微调大语言模型。

**💡 创新点**

创新点在于将模型剪枝率与带宽分配联合优化，通过块坐标下降求解最小化延迟的非凸问题，并根据客户端计算能力与信道条件动态分配资源，显著降低了时延并抑制了慢速客户端（straggler）影响。

**🔧 技术方法**

使用了结构化剪枝（移除注意力头与MLP神经元）、emulator–adapter 分离架构、FedAvg 聚合、带宽自适应分配、块坐标下降（BCD）优化算法以及参数高效微调（LoRA）等技术。

**📊 数据集**

实验数据集包括 Yahoo Answers（文本分类）和 GSM8K（数学推理），使用 GPT‑2 Medium 预训练模型进行联邦微调。

**📈 对比分析**

与 FedBiOT、DEFT、Split LoRA、UBFP 等基线相比，JCPBA 在两组任务中平均至少缩短 40% 的总微调时间，通信开销下降约 46%，并在相同或更低的测试误差下完成训练，且对计算异质性具有更强的鲁棒性。

**⚠️ 局限性**

局限性：实验假设数据 IID、信道模型为理想化 Rayleigh 衰落，未考虑非 IID 情况或动态网络环境；此外，模型分割与剪枝策略对特定模型结构（如 GPT‑2）依赖较强，泛化至其他大模型的适用性待验证。

---

## 284. Failure-Aware Bimanual Teleoperation via Conservative Value Guided Assistance

**arXiv ID:** 2602.01092 | [PDF](https://arxiv.org/pdf/2602.01092v1)

**作者:** Peng Zhou `[一作]` (Great Bay University), Zeqing Zhang `[通讯]` (Nanyang Technological University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出一种基于保守价值学习的失效感知双手遥操作框架，在保持人类连续控制的前提下，通过柔性触觉协助避免接触丰富任务中的不可逆失败。

**💡 创新点**

①从离线成功/失败遥操作数据中学习保守成功得分Q，作为任务可行性评估；②用该得分动态调节协助强度，配合演员网络给出纠正运动方向；③将协助实现为阻抗式仿真关节力学反馈，实现连续而非离散的共享自治。

**🔧 技术方法**

Conservative Q‑Learning (CQL) 训练成功得分；Actor网络学习成功引导策略；价值引导阻抗辅助（joint‑space impedance）；离线数据标签化与短期失败监督；双手遥操作硬件系统。

**📊 数据集**

由10个日常生活操控任务（共约500条轨迹）收集的离线遥操作数据，包含成功与失败执行轨迹。

**📈 对比分析**

与 Human、GELLO、VR、FACTR 等基线比较；在10个任务中，Ours‑LF 的成功率≥98%，平均完成时间比其他遥操作方法缩短约25%，接近人类水平。

**⚠️ 局限性**

①演员给出的纠正方向未显式考虑即时接触约束，可能导致冲突或振荡；②保守成功得分依赖离线数据，任务或末端执行器变更时可能失效；③在极端分布外条件下仍需额外数据或在线适应。

---

## 285. AutoHealth: An Uncertainty-Aware Multi-Agent System for Autonomous Health Data Modeling

**arXiv ID:** 2602.01078 | [PDF](https://arxiv.org/pdf/2602.01078v1)

**作者:** Tong Xia `[一作]` (Vanke School of Public Health), Yong Li `[通讯]` (Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, China)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5a41884c-404f-4688-a89c-aa238c10fe68` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

提出了一种名为AutoHealth的闭环多智能体系统，用于从原始医疗数据中自动构建预测模型并生成可靠性报告。

**💡 创新点**

创新点在于：①引入数据探索、任务规划、编码与报告五大专用智能体，并通过Meta‑Agent实现闭环反馈；②将不确定性量化作为首要目标，系统在实验决策与评估中始终兼顾预测性能与置信度；③通过检索增强、任务自适应与逐步执行等机制，实现跨模态、跨任务的通用性。

**🔧 技术方法**

技术包括：大型语言模型（DeepSeek‑V3.2）驱动智能体；VLLM（GLM‑4.6V）辅助视觉/文本分析；检索与反馈记忆机制；多任务训练与深度集成；代码分解执行与结果日志化。

**📊 数据集**

使用17个真实世界任务，涵盖6种模态（表格、图像、时序、自由文本、音频、图结构）和6类学习设置（分类、回归、分割、存活分析、预测、链接预测）。

**📈 对比分析**

与三类基线（纯LLM、Claude Code、DS‑Agent/AutoML‑Agent）比较，AutoHealth在所有任务上实现100%成功率，平均预测NPS提升29.2%，不确定性得分提升50.2%，综合得分最高（0.840）。

**⚠️ 局限性**

局限性包括：依赖大型LLM计算成本仍较高；在极大规模数据或实时部署场景下效率需进一步验证；系统虽自动化，但仍需要人工监督来保证临床安全。

---

## 286. Autoregressive, Yet Revisable: In Decoding Revision for Secure Code Generation

**arXiv ID:** 2602.01187 | [PDF](https://arxiv.org/pdf/2602.01187v1)

**作者:** Chengran Yang `[一作]`, David Lo `[通讯]`

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出Stream of Revision框架，使LLM在单次自回归生成中能够即时检测、定位并修复代码漏洞；

**💡 创新点**

创新点在于将修订动作编码为特殊的可执行词元，内置虚拟光标与确定性渲染器，使得修订成为生成流的一部分；

**🔧 技术方法**

技术包括：词元扩展、内容可寻址局部化、严格子串约束、确定性渲染器、logit校准、与DPO/SimPO等对齐方法的结合；

**📊 数据集**

使用真实C/C++ CVE修补对、CyberSecEval 2安全基准、HumanEval 代码功能基准，以及构造的严格/放宽版修订数据集；

**📈 对比分析**

与原生LLM、后置修订代理、SafeCoder、ProSec等基线比较，在C/C++上达到或超过安全通过率，且推理token使用量显著降低，OOV语言也能保持良好性能；

**⚠️ 局限性**

局限性包括：修订触发阈值调优敏感、对非安全相关的无效修订导致轻微开销、对复杂跨行或多文件漏洞的处理尚不完善、模型对修订词元的冷启动仍需进一步优化。

---

## 287. PARSE: An Open-Domain Reasoning Question Answering Benchmark for Persian

**arXiv ID:** 2602.01246 | [PDF](https://arxiv.org/pdf/2602.01246v1)

**作者:** Jamshid Mozafari `[一作]` (University of Innsbruck), Adam Jatowt `[通讯]` (University of Innsbruck)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了首个面向波斯语的开放领域推理问答基准（Parse），包含10800道Boolean、选择题、事实类问题，涵盖多跳、推理、难度等维度；同时完成了人工评估和多阶段质量控制；对多种多语言LLM在不同提示策略下的表现进行了评测，并展示了在Parse上进行微调能显著提升模型性能。

**💡 创新点**

1）首次为低资源波斯语提供覆盖多问答类型与推理层面的完整基准；2）基于LLM的生成+人工复核双重流程，确保数据高质量；3）在同一基准上同时对比多语言模型与波斯语专用模型，并探讨提示策略与微调效果。

**🔧 技术方法**

使用GPT‑4o进行数据生成与提示设计；采用英文与波斯语双语提示，尝试Zero‑Shot、Few‑Shot、Chain‑of‑Thought等策略；利用Fine‑Tuning对LLaMA‑3 8B与其波斯语变体Dorna进行模型适配；评估指标包括准确率、Jaccard、Contains等。

**📊 数据集**

Parse基准数据集（10800道问答），由GPT‑4o生成、人工审核、按难度、类型划分，公开在GitHub。

**📈 对比分析**

对六大通用LLM（Qwen‑2.5、LLaMA‑3、Mistral‑24B、Gemma‑2）以及波斯语特化模型Dorna在English/FA提示下进行对比；结果显示波斯语提示普遍优于英文提示，CoT对Boolean/MCQ最佳，Few‑Shot对Factoid最佳；微调后Dorna在所有配置上均优于未微调模型，性能提升显著。

**⚠️ 局限性**

1）数据仍可能存在生成偏差或隐含的文化/语义误差；2）基准仅覆盖三类问题，未包含对话式或知识图谱检索场景；3）评测以单一评估平台为主，未覆盖多模态或跨域应用；4）对不同语言模型的偏差分析不足，需进一步探讨多语言对齐与偏差问题。

---

## 288. What Does Vision Tool-Use Reinforcement Learning Really Learn? Disentangling Tool-Induced and Intrinsic Effects for Crop-and-Zoom

**arXiv ID:** 2602.01334 | [PDF](https://arxiv.org/pdf/2602.01334v1)

**作者:** Yan Ma `[一作]` (Fudan University), Pengfei Liu `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 5970 | [OpenAlex ID](https://openalex.org/A5100355025)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

提出 MED 框架对 Vision Tool‑Use RL 进行训练动态分析，拆分内在能力提升与工具诱导效应；

**💡 创新点**

创新点在于将工具诱导效应细化为 Gain / Harm 及其 Call / Schema 子项，并进一步分解为 Mass / Policy / Quality 三个概率因子，构建粗到细的分析层级；

**🔧 技术方法**

采用 RL 后处理（GRPO）与视觉工具（crop‑and‑zoom）结合的 VLM，利用工具调用与不调用两种推理协议来测量性能漂移；

**📊 数据集**

训练数据为约 15k 题目图片 + 文字，主要来自 Thyme、Mini‑O3 等高分辨率 VQA；评估使用六大基准（VStar、HR‑Bench 4k/8k、VisualProbe Easy/Medium/Hard）；

**📈 对比分析**

实验结果显示绝大多数性能提升源自内在能力漂移（S_tool≈0.2‑0.3），工具使用主要降低损害（Gross Harm 减少），对失败案例的纠正提升有限；

**⚠️ 局限性**

局限在于仅研究单一视觉工具（crop‑and‑zoom），使用仅基于最终答案的稀疏奖励，且评估指标仅为准确率，未考虑多工具、效率和更细粒度的解释性评价。

---

## 289. FedBGS: A Blockchain Approach to Segment Gossip Learning in Decentralized Systems

**arXiv ID:** 2602.01185 | [PDF](https://arxiv.org/pdf/2602.01185v1)

**作者:** Fabio Turazza `[一作]` (University of Modena and Reggio Emilia), Marco Mamei `[通讯]` (University of Modena and Reggio Emilia)

**通讯引用:** 4187 | [OpenAlex ID](https://openalex.org/A5001933830)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出 FedBGS，一种完全去中心化的区块链+IPFS+分段嘀咕学习框架，用于在非IID数据环境下训练全局模型。

**💡 创新点**

创新点在于：① 通过一轮联邦 K‑Means++ 自动分段聚类，形成数据同质化的子集；② 区块链与 IPFS 的混合存储，实现链上聚合、链下高效存储；③ 结合差分隐私、同态加密与修剪平均等多重安全机制，提升隐私与鲁棒性；④ 全流程完全去中心化，无单点故障。

**🔧 技术方法**

技术包括：区块链（以太坊智能合约）、IPFS、联邦 K‑Means++、分段嘀咕学习、差分隐私（DP）、加密哈希、同态加密（Paillier）、Trimmed‑Mean 聚合、去中心化领导者选举、基于代币的激励与惩罚。

**📊 数据集**

使用标准图像数据集：MNIST、EMNIST、Fashion‑MNIST、KMNIST、CIFAR‑10；通过 Dirichlet 分布对数据进行非IID划分。

**📈 对比分析**

与 FedAvg、FedProx、SCAFFOLD、MOON、FedDyn、FedChain、BlockFL 等方法进行对比；实验显示 FedBGS 在不同 β（非IID程度）下准确率基本不变，优于传统联邦学习在高异构情况下的性能下降；在区块链上运行的 gas 成本与算力消耗亦在可接受范围内。

**⚠️ 局限性**

局限包括：① 局部差分隐私对小样本客户端的精度影响明显；② 区块链的吞吐量与 gas 费用仍限制大规模部署；③ 需要更多工作在资源受限设备上的适配与优化；④ 整体系统复杂度高，部署与维护成本相对较高。

---

## 290. From Pragmas to Partners: A Symbiotic Evolution of Agentic High-Level Synthesis

**arXiv ID:** 2602.01401 | [PDF](https://arxiv.org/pdf/2602.01401v1)

**作者:** Niansong Zhang `[一作]` (Cornell University), Zhiru Zhang `[通讯]` (Cornell University)

**通讯引用:** 6850 | [OpenAlex ID](https://openalex.org/A5037210004)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

本文论证在大语言模型和agentic AI时代，高层合成（HLS）仍是硬件设计不可或缺的抽象层，指出其在快速迭代、可移植性和验证便利性方面的优势；并针对现有HLS流程的不足提出改进方向。

**💡 创新点**

提出agentic HLS的自动化层级分类（L0–L5），并阐述从人手调优到完全自主的进化路径；强调AI代理在性能反馈、接口灵活性和调试能力上的潜在贡献。

**🔧 技术方法**

基于高层合成技术与人工智能代理（LLM、闭环优化、差分测试、等价检查等）融合的概念框架；讨论了闭环DSE、混合精度性能建模、接口桥接与全链路验证的实现思路。

**📊 数据集**

本文为概念性立场论文，未使用具体实验数据集，而是基于现有HLS工具（如Vitis HLS、Catapult HLS）和常见接口（AXI、LiteX SoC）进行分析。

**📈 对比分析**

没有提供实验比较或性能数据；文章通过理论论证与案例分析，说明在agentic HLS层级中，现有工具在性能反馈、接口定制和调试支持方面存在瓶颈。

**⚠️ 局限性**

当前HLS工具在性能反馈不够精准、接口可定制性差、端到端验证与调试支持不足等方面存在局限；文章强调AI代理在这些环节的提升空间。

---

## 291. PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding

**arXiv ID:** 2602.01322 | [PDF](https://arxiv.org/pdf/2602.01322v1)

**作者:** Panagiotis Koromilas `[一作]` (Cyprus Institute), Mihalis Nicolaou `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `57a58b01-81b4-4d75-a45c-2e891f272b50` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 PolySAE，在稀疏自编码器中加入低秩多项式解码器，以显式建模特征交互，提升对模型内部表示的可解释性。

**💡 创新点**

创新点在于：保持线性编码器以保留可解释性；使用低秩张量分解实现二阶、三阶特征交互，参数增量仅约3%；显著提升语义分离度与线性可分辨性。

**🔧 技术方法**

技术：稀疏自编码器、低秩张量分解、Volterra 多项式网络、QR 重整正交约束、线性解码加高阶交互。

**📊 数据集**

数据集：四个大型语言模型（GPT‑2 Small、Pythia‑410M/1.4B、Gemma‑2‑2B）残差流激活；训练数据 OpenWebText 或 Pile；评估使用 SAEBench 的 Bias in Bios、AG News、EuroParl、GitHub、Amazon Sentiment、Amazon‑15。

**📈 对比分析**

对比方法：与标准 SAE 在相同稀疏度、字典大小、模型下比较；结果显示 PolySAE 平均提升约 8% F1，Wasserstein 距离提升 2–10×，重构误差保持一致；在更稀疏代码下仍保持优势。

**⚠️ 局限性**

limitation：仅在 2B 参数级模型实验，实验范围局限于强制稀疏 SAE 变体，未验证在更大模型或其他任务上的普适性。

---

## 292. Morphis: SLO-Aware Resource Scheduling for Microservices with Time-Varying Call Graphs

**arXiv ID:** 2602.01044 | [PDF](https://arxiv.org/pdf/2602.01044v1)

**作者:** Yu Tang `[一作]` (Zhejiang University), Shuiguang Deng `[通讯]` (Zhejiang University)

**通讯引用:** 9245 | [OpenAlex ID](https://openalex.org/A5055284175)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

设计了 Morphis，一套基于动态调用图指纹的微服务资源调度框架，能够在满足尾部延迟 SLO 的前提下，按预测的调用模式分配 CPU/内存资源；

**💡 创新点**

创新点在于：① 通过结构指纹化将海量分布式跟踪拆解为稳定骨干与可解释的偏差子图，揭示调用图中少量“主路径”占主流；② 基于这些指纹做短期调用模式预测，并将模式频率映射到服务负载；③ 在全局优化层采用离散遗传算法同时满足端到端 SLO 与最小资源成本；

**🔧 技术方法**

主要技术包括：分布式跟踪解析与k-gram频率统计、结构指纹化、时间序列SARIMA预测、神经网络自我延迟与资源预测、图编辑距离与服务相似度、遗传算法全局优化；

**📊 数据集**

使用的公开数据集为 Open Source Railway Ticket Booking System（包含41个微服务）以及 ByteDance 生产系统的 500k+ 跟踪日志；

**📈 对比分析**

与 Kubernetes HPA、PBScaler、Derm 以及 ERMS/Firm 等基线对比，Morphis 在三种负载场景下 CPU 消耗平均降低 35–38%，SLO 合规率 95–99%，且在高峰期仍保持尾部延迟稳定；

**⚠️ 局限性**

局限性：① 需要先前收集足够的跟踪数据以学习指纹，动态变化过快时指纹更新需要手动或在线聚类；② 遗传算法求解尽管快速，但在极大规模服务网格上仍可能面临搜索空间爆炸；③ 仅考虑 CPU/内存资源，未深入探讨网络/存储等其他资源维度；

---

## 293. Small-Margin Preferences Still Matter-If You Train Them Right

**arXiv ID:** 2602.00954 | [PDF](https://arxiv.org/pdf/2602.00954v1)

**作者:** Jinlong Pang `[一作]` (University of California, Santa Cruz), Yang Liu `[通讯]` (University of California, Santa Cruz)

**通讯引用:** 60546 | [OpenAlex ID](https://openalex.org/A5100355692)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `a4b10f5d-130b-4e77-9367-6469ec621899` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种针对小分差（难度高）的偏好对比样本的混合训练策略（MixDPO），通过难度排序将数据分为易样本和难样本，易样本使用 DPO 损失训练，难样本使用 SFT 损失训练，以提高 LLM 的偏好对齐效果。

**💡 创新点**

创新点在于：①不再像传统方法那样直接丢弃难样本，而是将其视为有价值的监督信号；②结合难度感知的课程学习（Curriculum Learning）与双重损失（DPO + SFT）策略，实现了对不同难度样本的自适应优化，显著提升对齐性能。

**🔧 技术方法**

核心技术包括：DPO（Direct Preference Optimization）损失、SFT（Supervised Fine‑Tuning）损失、基于评分差距的难度度量、课程学习排序以及两阶段训练流程（先易后难）。

**📊 数据集**

主要使用的偏好对齐数据集有 UltraFeedback（≈61k 评分对）和 Argilla-7k（≈7k 评分对），以及在不同模型上进行的额外实验如 Qwen‑2.5‑7B 与 LLaMA‑3‑8B 等基础模型。

**📈 对比分析**

与 DPO、SimPO、SelectiveDPO 等主流偏好优化方法在 AlpacaEval 2、MT‑Bench、Arena‑Hard 等评测基准上对比，MixDPO 在 LC win rate、raw win rate 以及 MT‑Bench 分数上均取得了 5–10% 以上的提升，尤其在 LLaMA‑3‑8B 与 Mistral‑7B‑v0.1 上表现突出。

**⚠️ 局限性**

局限性包括：①仍有更优策略可替代 SFT 处理难样本；②难度度量依赖原始 LLM 评分，评分噪声可能影响难度判断；③方法主要针对二元偏好数据，未探讨多标签或更复杂评估场景；④对超参数（如阈值 τ）的敏感性需要进一步研究。

---

## 294. Modeling Topological Impact on Node Attribute Distributions in Attributed Graphs

**arXiv ID:** 2602.01454 | [PDF](https://arxiv.org/pdf/2602.01454v1)

**作者:** Amirreza Shiralinasab Langari `[一作]` (University of Quebec), Kim Khoa Nguyen `[通讯]` (University of Quebec)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出一种代数-范畴框架，用以量化图结构对节点属性分布的影响，并给出节点视角与全图视角下的后验分布近似；

**💡 创新点**

创新点在于将图拓扑视为“视角”并用下范畴和自由范畴构造节点的视角，再通过对路径计数矩阵与属性分布权重相结合，实现拓扑条件化分布；

**🔧 技术方法**

主要技术包括范畴论的自由范畴与下范畴、Grothendieck图神经网络中的幺半群操作、路径计数矩阵、归一化视角分布与平均值计算；

**📊 数据集**

使用了六个真实世界有机异常图数据集：Weibo、Reddit、Disney、Books、Enron、DGraph，均来自PyGOD库；

**📈 对比分析**

通过与多种基准（LOF、IF、SCAN、GCNAE、GAD-NR、CoCo等）对比，ID在五个数据集上达到或逼近最优ROC‑AUC，展示了在不同规模图上的强劲性能；

**⚠️ 局限性**

局限性包括对属性分布默认采用离散均匀假设（在Weibo表现不佳），以及对较大m值时计算量与稀疏性问题；

---

## 295. Rethinking Selective Knowledge Distillation

**arXiv ID:** 2602.01395 | [PDF](https://arxiv.org/pdf/2602.01395v1)

**作者:** Almog Tavor `[一作]` (Blavatnik School of Computer Science and AI, Tel Aviv University), Mor Geva `[通讯]` (Blavatnik School of Computer Science and AI, Tel Aviv University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一种基于学生熵引导的选择性知识蒸馏框架，在自回归大型语言模型中通过在位置、类别和样本三个轴上进行稀疏监督，显著提升蒸馏效率和模型性能。

**💡 创新点**

创新点在于将学生熵作为位置重要性指标，并将选择性蒸馏扩展到同时跨位置、类别和样本轴进行稀疏化，从而实现低成本、低内存的蒸馏，并通过离线教师缓存进一步降低存储需求。

**🔧 技术方法**

采用的技术包括学生熵计算、Top‑k%位置选择、逆KL/CE‑ratio等重要性度量、随机类别采样（RS‑KD）、样本排序与过滤、选择性语言模型头与分块熵计算等。

**📊 数据集**

实验使用了80M FineWeb‑Edu预训练语料、HellaSwag、PIQA、ARC‑E、GSM8K、LAMBADA、IFEval等评测数据集，任务特定蒸馏也在GSM8K数据集上验证。

**📈 对比分析**

与全密集蒸馏、AT‑KD、RS‑KD、随机选择等基线相比，Top‑20%学生熵位置选择在准确率、Perplexity和指令跟随上均优于全密集蒸馏，且通过多轴稀疏化可实现70%壁时缩短、18%峰值内存下降以及80%存储节省。

**⚠️ 局限性**

局限性包括仅在单一教师‑学生对（Qwen3‑1.7B/8B）与固定监督预算下验证，缺乏对不同规模模型、长序列、以及其他对齐准则（如特征蒸馏）的泛化评估。

---

## 296. Multimodal Scientific Learning Beyond Diffusions and Flows

**arXiv ID:** 2602.00960 | [PDF](https://arxiv.org/pdf/2602.00960v1)

**作者:** Leonardo Ferreira Guilhoto `[一作]` (University of Pennsylvania), Paris Perdikaris `[通讯]` (University of Pennsylvania)

**通讯引用:** 33071 | [OpenAlex ID](https://openalex.org/A5002562845)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `afceb026-1760-41ae-8d86-010831a37d97` `ba576bd1-e51d-44e8-8077-fc943b333c93` `40105733-5154-44cd-8090-a8cab9e64b07` `5a41884c-404f-4688-a89c-aa238c10fe68` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

研究了Mixture Density Networks在科学机器学习中用于多模态不确定性量化的有效性，并与隐式生成模型进行对比实验。

**💡 创新点**

提出了基于显式混合密度网络的概率框架，强调其在低数据、高度结构化物理问题中的样本效率、可解释性以及对离散模式的精确捕捉。

**🔧 技术方法**

采用Mixture Density Networks、最大似然估计、对比实验使用扩散模型(CFM)、流模型、贝叶斯神经网络等技术，并实现了基于JAX的Python包。

**📊 数据集**

使用了逆问题、马尔科夫多稳态动力系统、混沌时间序列等代表性科学回归基准数据集，如非线性逆回归、Duffing振子、Lorenz系统等。

**📈 对比分析**

通过最大似然误差、模式恢复率、样本效率评估等指标，将MDN与隐式模型比较，结果显示MDN在低数据量下具有更好的模式覆盖、校准性更高且计算成本更低。

**⚠️ 局限性**

需要预先设定混合成分数目，对高维或弱结构化不确定性难以扩展，且在极大数据集或复杂分布时可能受限于参数化假设。

---

## 297. When Domains Interact: Asymmetric and Order-Sensitive Cross-Domain Effects in Reinforcement Learning for Reasoning

**arXiv ID:** 2602.01365 | [PDF](https://arxiv.org/pdf/2602.01365v1)

**作者:** Wang Yang `[一作]` (Case Western Reserve University), Xiaotian Han `[通讯]` (Case Western Reserve University)

**通讯引用:** 2 | [OpenAlex ID](https://openalex.org/A5116337235)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文系统分析了多域训练下GRPO的跨域效应，探究单域推广、域间交互与多域训练策略对推理能力的影响。

**💡 创新点**

首次揭示GRPO在多域训练中表现出显著的非对称性、顺序敏感性和策略依赖性，并给出针对不同域的训练顺序与混合策略建议。

**🔧 技术方法**

采用Group Relative Policy Optimization（GRPO）强化学习框架，在Qwen3-4B-Base模型上进行训练。

**📊 数据集**

使用四类推理数据集：Skywork-OR1-RL-Data、OpenScienceReasoning-2、knights-and-knaves、Enigmata-Data，评估指标为MATH500、GPQA、逻辑与谜题测试集。

**📈 对比分析**

通过比较单域、顺序训练与混合训练三种策略，发现如math→science顺序可获得最高的数学与科学准确率，而混合训练更适合逻辑与谜题，性能提升可达30%+，但不同顺序差距可达15%。

**⚠️ 局限性**

局限在于仅评估四个域与单一模型规模，缺乏更大模型与更多域的验证，以及对跨域干扰机制的理论解析不足。

---

## 298. Learning Heat-based Equations in Self-similar variables

**arXiv ID:** 2602.00872 | [PDF](https://arxiv.org/pdf/2602.00872v1)

**作者:** Shihao Wang `[一作]` (University of Wisconsin Madison), Jingquan Wang `[通讯]` (University of Wisconsin Madison)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `14d48e9d-0069-4ad9-996a-1d5968216998` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本研究提出并验证了在自相似坐标下训练神经算子的方法，针对二维不可压Navier‑Stokes涡度方程和一维粘性 Burgers 方程，展示了在自相似变量中学习能显著提升长时预测的准确性与稳定性。

**💡 创新点**

创新点在于将物理系统的自相似尺度变换作为先验归纳偏置，引入可兼容标准神经算子训练的自相似坐标框架，并通过一致的训练协议证明其对不同网络架构均有益。

**🔧 技术方法**

主要技术包括：多层感知机（MLP）与因子化全连接网络（FCN）两种神经算子架构；在自相似与物理坐标下使用窗口化 MSE 损失；基于 Monte Carlo 的采样与统一的批次对齐；以及在自相似坐标下的窗口化训练与物理域评估。

**📊 数据集**

实验使用合成初始条件：Navier‑Stokes 采用双高斯叠加，Burgers 采用双极盒型；所有参考解均通过高分辨率数值求解得到，并在固定时间窗口内采样。

**📈 对比分析**

比较方法：在相同网络架构、相同超参数和相同采样批次下，分别在自相似和物理坐标下训练；通过在物理域评估窗口内计算相对均方误差（RelMSE）评估外推性能；结果表明自相似训练的 RelMSE 显著低于物理训练，并且能更好地捕捉长期的合并或冲击波特征。

**⚠️ 局限性**

局限性包括：仅针对热类方程（具有自相似长时行为）验证；对更复杂非线性或非热系统的推广尚未证明；自相似窗口的固定尺寸在某些情况下可能不足以覆盖所有重要尺度；需要进一步的理论分析与自适应窗口策略。

---

## 299. Dynamic Prior Thompson Sampling for Cold-Start Exploration in Recommender Systems

**arXiv ID:** 2602.00943 | [PDF](https://arxiv.org/pdf/2602.00943v1)

**作者:** Zhenyu Zhao `[一作]` (Roblox), Ehsan Saberian `[通讯]` (Roblox)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出并实现一种动态先验的 Thompson Sampling（Dynamic Prior TS），用于冷启动时控制新内容的探索量，避免在批量更新环境中对弱内容的过度曝光。

**💡 创新点**

创新点在于给新 arm 设计一个闭式二次求解的先验，使得其在首次出现时与当前最优 arm 的采样概率满足预设的探索阈值 ε，从而实现精准的探索概率控制。

**🔧 技术方法**

技术上使用 Bayesian Bandit 框架（Beta 先验 + Thompson Sampling）、正态近似推导、蒙特卡洛仿真、离线批处理模拟以及真实线上 A/B 实验。

**📊 数据集**

实验数据包括多组人工生成的 Bernoulli 成功率与样本量组合（用于离线验证），以及真实千万用户在 Roblox 缩略图个性化推荐系统的生产数据。

**📈 对比分析**

与统一 Beta(1,1) 先验和固定时长强制探索方法对比，模拟中累积奖励提升约 9.5%，线上实验中 Qualified Play-Through Rate 提升 0.19% 并且 regret impressions 减少 21%。

**⚠️ 局限性**

局限性包括需要手动设定探索阈值 ε 和先验强度 r，适用于无上下文的简单 bandit；在极端延迟或多目标公平等场景下仍需进一步研究。

---

## 300. Nonlinear model reduction for transport-dominated problems

**arXiv ID:** 2602.01397 | [PDF](https://arxiv.org/pdf/2602.01397v1)

**作者:** Jan S. Hesthaven `[一作]` (Karlsruhe Institute of Technology), Benjamin Unger `[通讯]` (Karlsruhe Institute of Technology)

**通讯引用:** 498 | [OpenAlex ID](https://openalex.org/A5038272163)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a8e75ba4-7a2d-4153-b003-06c94533add0` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文综述了在传统线性模型约简难以处理的传输支配问题（如波动、移动结构）中，非线性模型约简的最新方法与理论。作者围绕三个核心要素（非线性参数化、约简动力学、在线求解）对方法进行分类，并给出了典型示例和关键技术细节。

**💡 创新点**

创新点在于：① 将非线性模型约简的设计框架统一为三要素，并系统地将现有方法归类为变换基方法、在线自适应方法以及通用非线性参数化+即时残差最小化方法；② 通过 Kolmogorov 宽度的理论与数值例子阐明线性约简的 Kolmogorov 阻塞，并解释非线性方法如何突破这一限制；③ 提供了完整的算法流程、误差评估视角以及对比分析，形成了该领域的“方法地图”。

**🔧 技术方法**

主要技术包括：
- 变换基/移位 POD、最优传输、注册、Lagrangian 变换等；
- 非线性参数化（如多项式、核、神经网络）与编码器-解码器结构；
- 约简动力学：Galerkin、Petrov–Galerkin、残差最小化、Dirac–Frenkel 原理、代数微分方程等；
- 在线求解：优化式迭代、快速内插/逼近、超参数预计算、数值稳定化技术。

**📊 数据集**

作为综述，本文没有针对单一数据集进行实验，但在章节 3.1 通过热方程（diffusion）和线性对流方程（transport）这两类经典 PDE 作为示例，展示奇异值衰减与 Kolmogorov 宽度的对比。

**📈 对比分析**

通过对比热方程与对流方程的奇异值谱，本文展示线性模型约简在传输问题中需要维度高得多、误差下降缓慢；而非线性参数化+变换方法（如 Shifted POD、最优传输、神经网络）可在更低维度下实现相同或更低的误差。文中未给出统一的性能基准表，但指出非线性方法在理论上可突破 Kolmogorov 阻塞，并在数值示例中验证了更快的误差收敛。

**⚠️ 局限性**

局限性：
- 非线性方法仍缺乏成熟、可计算的误差估计与证据；
- 在线求解往往变成优化问题，计算成本和数值稳定性难以统一保证；
- 训练阶段需要大量高质量快照，且参数化结构需人工设计或昂贵的学习；
- 对于高维参数或多尺度问题，变换/注册方法的可扩展性有限；
- 目前对非线性模型约简的理论收敛分析与结构保持（能量、守恒）仍不完善。

---

## 301. A State-Transition Framework for Efficient LLM Reasoning

**arXiv ID:** 2602.01198 | [PDF](https://arxiv.org/pdf/2602.01198v1)

**作者:** Liang Zhang `[一作]` (Xiamen University), Jinsong Su `[通讯]` (Xiamen University)

**通讯引用:** 3970 | [OpenAlex ID](https://openalex.org/A5066326238)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `64443552-63e0-44b5-906f-d90fe95c5a1b` `8d10c613-917e-4880-9716-17789f50e119` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建一种基于状态转移的推理框架，通过混合注意力模块（Softmax+Linear）让LLM在每一步推理时仅需访问上一步的状态，而非完整上下文，从而显著降低推理成本并提升推理速度。

**💡 创新点**

① 引入线性注意力捕捉“推理状态”，实现从 O(ℓ²) 降到 O(ℓ) 的复杂度；② 设计状态‑基推理策略，用全局梯度方向校正噪声推理步骤，缓解过度思考；③ 通过特殊标记促进不同推理模式多样化，保持解释性。

**🔧 技术方法**

混合注意力模块（Softmax+Linear Attention），线性注意力中的状态矩阵与梯度下降视角；门控机制；状态‑基推理策略（梯度累积与校正）；LoRA 微调；知识蒸馏与自回归损失。

**📊 数据集**

训练集：从 OpenR1‑Math‑220K 采样 95K 高质量长 CoT；评测集：GSM8K、MATH‑500、AMC23、AIME24、AIME25、GPQA_Diamond、HumanEval。

**📈 对比分析**

与 LightThinker、INFTYTHINK、H2O、SepLLM 等效率或 KV‑cache 缩减方法对比；在 Qwen‑2.5‑1.5B 与 7B 系列上，平均提升 3–5% 以上准确率，推理延迟下降 20–40% 甚至 40%+，CoT 长度保持不变，保持可解释性。

**⚠️ 局限性**

① 目前仅在 Qwen‑2.5 系列验证，跨模型迁移需进一步验证；② 需要额外算子支持线性注意力，非原生 Transformer 可能兼容性差；③ 对极长 CoT（>32K）仍需验证显存与吞吐稳定性；④ 过度依赖梯度累积的状态‑基策略在噪声极高场景下效果尚待评估。

---

## 302. Cast: Automated Resilience Testing for Production Cloud Service Systems

**arXiv ID:** 2602.00972 | [PDF](https://arxiv.org/pdf/2602.00972v1)

**作者:** Zhuangbin Chen `[一作]` (Sun Yat-sen University), Zibin Zheng `[通讯]` (Sun Yat-sen University)

**通讯引用:** 33979 | [OpenAlex ID](https://openalex.org/A5000582109)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

开发并在华为云生产环境中部署了一个自动化、端到端的微服务弹性测试框架，能够对海量微服务应用进行弹性缺陷发现。

**💡 创新点**

创新点在于将生产流量的记录-回放与细粒度应用级故障注入相结合，提出基于复杂度驱动的测试空间裁剪与多层断言或acles，实现高保真、高效的弹性测试。

**🔧 技术方法**

采用Java Agent AOP、OpenTelemetry分布式追踪、动态变量抽象、故障库、复杂度评分、端点优先级策略、三阶段执行管道和多维度断言等技术。

**📊 数据集**

使用的主要数据集包括约300万条生产流量trace、48个复现bug基准集以及四个大型应用（Service1-4）的长期监测日志。

**📈 对比分析**

与手工复现的48例漏洞对比，单跑检测覆盖率约77%（单一测试周期）/90%（基准集），生产部署8个月发现137例漏洞，确认率89%；回放成功率达到98.3%。

**⚠️ 局限性**

局限性包括：仅覆盖已出现的流量路径，无法检测未记录的请求；阈值基准oracle可能导致误报/漏报；对业务特定签名等特殊变量需人工介入；实验仅在华为云环境验证，普适性待进一步验证。

---

## 303. The Gaussian-Head OFL Family: One-Shot Federated Learning from Client Global Statistics

**arXiv ID:** 2602.01186 | [PDF](https://arxiv.org/pdf/2602.01186v1)

**作者:** Fabio Turazza `[一作]` (University of Modena and Reggio Emilia), Marco Mamei `[通讯]` (University of Modena and Reggio Emilia)

**通讯引用:** 4187 | [OpenAlex ID](https://openalex.org/A5001933830)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在一轮通讯下，利用客户端上传的类条件统计量，构建高效的高斯判别头及轻量化的 Fisher 空间训练头，实现无数据传输的 Federated Learning。

**💡 创新点**

创新点在于：仅用第一/二阶矩构造闭式高斯头；通过 Fisher 子空间合成样本并训练 FisherMix、Proto‑Hyper 两种轻量化头；使用公共随机投影压缩统计量，兼顾通信效率与隐私。

**🔧 技术方法**

采用统计量聚合、闭式高斯判别（NB/LDA/QDA）、Fisher 子空间投影、合成样本生成、cosine‑margin 与低秩残差训练技术。

**📊 数据集**

在 CIFAR‑10、CIFAR‑100、SVHN、CIFAR‑100‑C 等图像分类数据集上进行实验，并对不同 backbone（ResNet、EfficientNet、MobileNet、VGG 等）进行验证。

**📈 对比分析**

与多种 one‑shot FL 方法（DENSE、Co‑Boost、FedPFT、FedCGS 等）以及传统多轮 FL（FedAvg、FedProx）对比，GH‑OFL 在强非 IID 和噪声干扰下均取得或逼近最佳准确率，且通信量大幅下降。

**⚠️ 局限性**

限制包括：需预训练编码器，无法在缺少二阶矩时使用 QDA；在极端非 IID 或小样本情形下统计量泄露风险升高；Fisher 子空间与合成样本可能无法完全逼近真实分布。

---

## 304. Key Principles of Graph Machine Learning: Representation, Robustness, and Generalization

**arXiv ID:** 2602.01139 | [PDF](https://arxiv.org/pdf/2602.01139v1)

**作者:** Yassine Abbahaddou `[一作]` `[通讯]` (Institut Polytechnique de Paris), Yassine Abbahaddou (Institut Polytechnique de Paris)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `6215c339-3735-4be3-8a07-5bbb7004712d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出 RobustCRF，一种基于条件随机场的后置方法，在图神经网络推断阶段提升鲁棒性。

**💡 创新点**

创新点在于聚焦推断阶段的鲁棒性提升，使用统计关系学习的 CRF 作为后处理，模型无关且不需要先验结构信息。

**🔧 技术方法**

主要技术包括条件随机场（CRF）建模、统计关系学习、后置增强以及与多种 GNN 的无缝集成。

**📊 数据集**

在公开的节点分类基准数据集（如 Cora、Citeseer、Pubmed 等）上进行实验验证。

**📈 对比分析**

与现有训练阶段防御方法（对抗训练、稳健训练等）进行对比，RobustCRF 在保持模型原始性能的前提下，在对抗攻击下的准确率显著提升，表现出更优的鲁棒性。

**⚠️ 局限性**

局限性包括：仅提升推断阶段鲁棒性，未解决训练阶段的对抗风险；在极端攻击下仍有性能下降；对大型图的计算开销尚未充分评估。

---

## 305. Sparse Reward Subsystem in Large Language Models

**arXiv ID:** 2602.00986 | [PDF](https://arxiv.org/pdf/2602.00986v1)

**作者:** Guowei Xu `[一作]` (Tsinghua University), James Zou `[通讯]` (Stanford University)

**通讯引用:** 38258 | [OpenAlex ID](https://openalex.org/A5005779176)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

发现并验证了大型语言模型隐藏层中存在一个稀疏奖励子系统，其中包含表示状态价值的价值神经元和编码奖励预测误差的多巴胺神经元，并通过干预实验证明其对推理能力至关重要。

**💡 创新点**

首次将人类大脑奖励系统的概念映射到LLM隐藏状态，证明价值与多巴胺神经元在不同数据集、模型规模、层级和架构下的稀疏性、鲁棒性和迁移性，并展示其在推理中的核心作用。

**🔧 技术方法**

采用两层MLP价值探针与时序差分（TD）学习训练，结合L1权重剪枝识别价值神经元，干预实验验证其重要性，使用IoU等指标评估跨数据集与跨模型的迁移性。

**📊 数据集**

使用 GSM8K、MATH500、Minerva Math、ARC、MMLU STEM 等多种数学与推理数据集，并在 Qwen、Llama、Gemma、Phi 等不同架构、0.5B–14B 规模模型上进行实验。

**📈 对比分析**

通过AUC、精度下降量等指标评估价值探针的预测性能和干预效果；结果显示仅 1% 的价值神经元被置零即可导致约 50% 的推理准确率下降，而随机干预几乎无影响；价值神经元的存在在不同模型和数据集上保持高一致性，证明其稀疏且具有良好迁移性。

**⚠️ 局限性**

对多巴胺神经元的识别仅基于案例研究，缺乏统一的定量评估方法；实验主要聚焦于自回归模型，尚未验证在更广泛的生成式模型或更大规模模型上的普适性；未来需要进一步探究其在生成过程控制与安全性方面的应用。

---

## 306. Learning Adaptive Cross-Embodiment Visuomotor Policy with Contrastive Prompt Orchestration

**arXiv ID:** 2602.01040 | [PDF](https://arxiv.org/pdf/2602.01040v1)

**作者:** Yuhang Zhang `[一作]` (Nanyang Technological University), Mir Feroskhan `[通讯]` (Nanyang Technological University)

**通讯引用:** 1276 | [OpenAlex ID](https://openalex.org/A5026643234)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `9ce7179e-700c-4310-ac2b-91df50ded46e` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种结合对比提示学习与自适应提示编排的CAPO方法，用于实现零样本跨体感知与动作策略的自适应导航。

**💡 创新点**

创新点在于（1）利用CLIP冻结视觉编码器并学习多种领域特定提示，通过混合视觉、动作和文本三种对比目标构建多样化提示池；（2）设计双分支注意力机制，根据当前观测动态加权提示，实现对环境与机器人结构变化的即时适配；（3）将文本提示与视觉提示分离，保持任务语义不变。

**🔧 技术方法**

核心技术包括：CLIP视觉模型的提示学习、InfoNCE 与 BYOL 对比损失、文本对比学习、双分支注意力融合、PPO 强化学习与GRU 时序建模。

**📊 数据集**

使用AI2‑THOR模拟环境的目标导航任务，构造包含光照、视场、旋转、步长等 10 种领域因子的数据集，共 1,468 条专家轨迹，涵盖源域、见域和未见域三种配置。

**📈 对比分析**

与五个基线（CURL、ACO、ATC、ConPE、PPO）对比，CAPO 在源域、见域及未见域的成功率、SPL、导航误差和耗时指标均优于所有基线，表现出最快的样本效率和最强的零样本适应性能。

**⚠️ 局限性**

主要局限在于提示池的多样性受限于训练时覆盖的领域因子，无法对超出学习范围的极端分布偏移做出自适应；并且在提示数量或长度不匹配时可能导致过拟合或欠拟合。

---

## 307. Exploring Knowledge Purification in Multi-Teacher Knowledge Distillation for LLMs

**arXiv ID:** 2602.01064 | [PDF](https://arxiv.org/pdf/2602.01064v1)

**作者:** Ruihan Jin `[一作]` (Tsinghua University), Jianhua Tao `[通讯]` (Beijing National Research Center for Information Science and Technology)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `8d10c613-917e-4880-9716-17789f50e119` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出知识净化概念并实现五种聚合、路由与强化学习等方法，改进多教师知识蒸馏流程，降低教师间冲突并提升蒸馏效率。

**💡 创新点**

创新点在于把多教师产生的推理rationale压缩成单一统一rationale，显著缓解知识冲突；同时首次提出五种多角度净化策略（聚合、Plackett‑Luce路由、PLM分类路由、相似度路由、RL教师选择）并在LLM蒸馏中验证其有效性。

**🔧 技术方法**

使用的技术包括：GPT‑4等大型LLM做聚合器、Plackett‑Luce概率排序、预训练PLM（mDeBERTaV3‑base）做特征提取、相似度路由、基于策略梯度的RL教师选择、典型的知识蒸馏损失与预测损失组合。

**📊 数据集**

实验数据集涵盖commonsense类（OpenBookQA、ARC、RiddleSense）、biomedical类（PubMedQA）以及跨域OOB评测（PIQA、BioASQ）。

**📈 对比分析**

通过与直接推理、全微调、Distilling‑Step‑by‑Step、TinyLLM四个基线对比，路由与RL方法平均提升4–7%准确率，尤其在OOB任务中获得最高分；聚合方法性能略逊；总体表现显示知识净化显著提升蒸馏效果与冲突缓解。

**⚠️ 局限性**

局限性包括：仅使用四个教师模型，无法全面评估规模扩展；聚合方法成本高、需要专有LLM；RL教师选择训练周期长、对新数据需重训；方法目前主要针对LLM任务，跨任务推广仍需进一步研究。

---

## 308. Effectiveness of Automatically Curated Dataset in Thyroid Nodules Classification Algorithms Using Deep Learning

**arXiv ID:** 2602.01020 | [PDF](https://arxiv.org/pdf/2602.01020v1)

**作者:** Jichen Yang `[一作]` (Duke University), Maciej A. Mazurowski `[通讯]` (Duke University Medical Center)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `7b0f05dc-d396-4b03-96d2-a379dbd5049d`

**🎯 论文内容**

使用自动化标注工具MADLaP构建大规模甲状腺结节数据集，并用其训练深度学习模型

**💡 创新点**

证明自动化构建的数据集比人工标注的小数据集能显著提升分类性能

**🔧 技术方法**

采用多步自然语言处理、光学字符识别、图像分割以及卷积神经网络进行检测与分类

**📊 数据集**

利用Duke University内部的3981例甲状腺FNA病例和对应超声图像，生成了手工标注集（378例）和自动标注集（5228张图）

**📈 对比分析**

通过10折交叉验证和独立测试集比较，自动标注模型AUC为0.694，对比手工标注为0.643，差异显著(P<0.001)

**⚠️ 局限性**

自动标注数据仍含约17%噪声，且实验未探索更高级的噪声鲁棒训练方法，且仅在单一中心数据上验证

---

## 309. Capabilities and Fundamental Limits of Latent Chain-of-Thought

**arXiv ID:** 2602.01148 | [PDF](https://arxiv.org/pdf/2602.01148v1)

**作者:** Jiaxuan Zou `[一作]` (Xi'an Jiaotong University), Yong Liu `[通讯]` (Renmin University of China)

**通讯引用:** 20371 | [OpenAlex ID](https://openalex.org/A5100724297)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文探讨了隐式链式思维（Latent CoT）与显式链式思维（Explicit CoT）在推理任务中的探索-执行权衡，提出符号指数（Symbolic Index）作为衡量决策确定性的指标，并证明了课程学习在训练隐式链式思维模型中的必要性。

**💡 创新点**

创新点包括：①将符号指数作为统一的决策确定性量化工具；②从信息瓶颈角度理论证明隐式链式思维的探索优势与计算脆弱性；③在理论上证明课程学习是消除分布失配、实现隐式链式思维的必需手段。

**🔧 技术方法**

采用信息瓶颈、KL 散度分析、子决策噪声模型以及连续状态误差传播分析等理论工具，配合 GPT‑2 等基础架构实现实验验证。

**📊 数据集**

实验使用了 GSM8K（算术推理）和 ProsQA（探索推理）等公开数据集，以及 ProntoQA 等用于验证课程学习效果的数据集。

**📈 对比分析**

与显式 CoT（高准确率但探索受限）相比，隐式 CoT 在探索任务 ProsQA 上达 97%（显著优于 77%），但在计算任务 GSM8K 上仅 34%（远低于 42%）；去掉课程学习后模型性能急剧下降，验证了课程学习的重要性。

**⚠️ 局限性**

局限性在于符号指数的计算仍依赖于模型的输出概率，且理论假设（如独立噪声、Lipschitz 连续性）在实际模型中可能不完全成立；此外，模型对任务的适应仍需人工调节，未实现完全自适应的决策确定性控制。

---

## 310. MindGuard: Guardrail Classifiers for Multi-Turn Mental Health Support

**arXiv ID:** 2602.00950 | [PDF](https://arxiv.org/pdf/2602.00950v1)

**作者:** António Farinhas `[一作]` (Sword Health), Ricardo Rei `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

**🎯 论文内容**

暂无信息

**💡 创新点**

暂无信息

**🔧 技术方法**

暂无信息

**📊 数据集**

暂无信息

**📈 对比分析**

暂无信息

**⚠️ 局限性**

暂无信息

---

## 311. ASP-Bench: From Natural Language to Logic Programs

**arXiv ID:** 2602.01171 | [PDF](https://arxiv.org/pdf/2602.01171v1)

**作者:** Stefan Szeider `[一作]` (TU Wien), Stefan Szeider `[通讯]` (TU Wien)

**通讯引用:** 4275 | [OpenAlex ID](https://openalex.org/A5037092803)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出ASP‑Bench基准，包含128个自然语言描述的ASP翻译任务，并使用ReAct代理在所有实例上实现了完整成功率。

**💡 创新点**

设计了语义验证的参考验证器、七维思维维度的难度分析以及基于迭代反馈的代理式翻译方法，解决了传统字符串匹配的局限。

**🔧 技术方法**

利用大型语言模型（Claude Sonnet 4.5）与ReAct框架、Clingo求解器、MCP接口、Python工具和参考验证器，实现自动化建模与调试。

**📊 数据集**

ASP‑Bench基准本身，包含64个基础问题及其易/难变体，系统化覆盖ASP核心特征的数据集。

**📈 对比分析**

与两种MCP实现（ipython‑mcp 与 mcp‑solver‑asp）比较，ipython‑mcp在10个最难问题上达100%成功率、平均调用16次、216秒；mcp‑solver‑asp 90%成功率、平均调用47次、297秒；代理方法在所有128实例上实现100%成功率。

**⚠️ 局限性**

仅限已收录的自然语言描述，难度维度不完全捕捉特定域难度；依赖商业LLM；未涵盖更极难的“very hard”问题；验证器仅检查约束符合，无法评估多解多样性。

---

## 312. MedAD-R1: Eliciting Consistent Reasoning in Interpretible Medical Anomaly Detection via Consistency-Reinforced Policy Optimization

**arXiv ID:** 2602.01081 | [PDF](https://arxiv.org/pdf/2602.01081v1)

**作者:** Haitao Zhang `[一作]` (Xiamen University), Xinghao Ding `[通讯]` (Xiamen University)

**通讯引用:** 13923 | [OpenAlex ID](https://openalex.org/A5052820597)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了大规模、多中心、多模态医学异常检测基准MedAD‑38K，并在其上提出两阶段训练框架MedAD‑R1；

**💡 创新点**

创新点在于结合链式推理（CoT）注释与一致性奖励的Con‑GRPO算法，使模型的思考过程与最终诊断保持逻辑一致；

**🔧 技术方法**

采用了SFT+RL的两阶段方法，底层使用Qwen2.5‑VL‑3B模型，加入LoRA、bfloat16训练、KL约束以及GRPO框架的Group‑Relative Advantage；

**📊 数据集**

使用的数据集为自研的MedAD‑38K，覆盖10种成像模态、10个解剖区域，包含VQA多选题与手工验证的CoT注释；

**📈 对比分析**

通过与多种医学与通用LMM（从3B到72B参数）对比实验，MedAD‑R1在整体准确率达到85.15%，比最强基线提升约8.15%，在异常检测和病灶定位等高难度任务提升超过18%；

**⚠️ 局限性**

局限性包括对CoT人工审核的依赖、奖励函数对外部评估器的敏感性以及仅在MedAD‑38K上验证，跨数据集泛化仍待进一步验证。

---

## 313. HERMES: A Holistic End-to-End Risk-Aware Multimodal Embodied System with Vision-Language Models for Long-Tail Autonomous Driving

**arXiv ID:** 2602.00993 | [PDF](https://arxiv.org/pdf/2602.00993v1)

**作者:** Weizhe Tang `[一作]` (University of Wisconsin–Madison), Bin Ran `[通讯]` (University of Wisconsin–Madison)

**通讯引用:** 9771 | [OpenAlex ID](https://openalex.org/A5060394098)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了HERMES框架，结合多模态感知与风险感知的端到端轨迹规划；

**💡 创新点**

首次将大规模视觉‑语言模型生成的长尾语义指令融入轨迹规划，形成风险感知的多模态融合；

**🔧 技术方法**

使用云端VLM（如Qwen3‑VL‑Flash）进行长尾场景注释，BGE‑M3文本编码，ViT视觉编码，Transformer多头注意力与三模态融合；

**📊 数据集**

在WOD‑E2E长尾驾驶基准上进行训练与评估；

**📈 对比分析**

与UniAD、VAD、LightEMMA等基线对比，HERMES在RFS、ADE/FDE等指标上均显著领先，尤其在高风险场景的RFS提升明显；

**⚠️ 局限性**

仍缺乏闭环实验、对VLM生成注释的鲁棒性和泛化能力有待提升，且对极端稀有事件的推理深度有限。

---

## 314. Geometry-Aware Sampling-Based Motion Planning on Riemannian Manifolds

**arXiv ID:** 2602.00992 | [PDF](https://arxiv.org/pdf/2602.00992v1)

**作者:** Phone Thiha Kyaw `[一作]` (University of Toronto), Jonathan Kelly `[通讯]` (University of Toronto)

**通讯引用:** 108666 | [OpenAlex ID](https://openalex.org/A5071744746)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了在Riemannian流形上直接进行采样式运动规划的框架，能够在配置空间中规划最短（最小能量）路径。

**💡 创新点**

创新点包括：① 用中点重排近似Riemannian距离，理论证明误差为三阶；② 采用Riemannian自然梯度与退化重排进行局部插值；③ 该框架兼顾几何精确性与采样式可扩展性，避免了求解精确Geodesic的高昂计算。

**🔧 技术方法**

使用技术包括：Riemannian几何（度量、曲率、对数/指数映射、重排），自然梯度下降，RRT*等采样式搜索，快速距离近似，变分优化与BVP求解作为对比基线。

**📊 数据集**

实验数据集：2自由度平面臂，7自由度Franka机器人（MotionBenchMaker），以及SE(2)导航任务（Willow Garage地图的Doorway和Corridor）。

**📈 对比分析**

与欧氏RRT*、变分能量最小化、BVP求解器等基线比较，结果表明：① 生成的路径长度和能量均更低；② 成功率相当或更高；③ 计算时间显著缩短（采样式方法约1分钟，而变分方法需数分钟）。

**⚠️ 局限性**

局限性：① 仍需在每步计算梯度和重排，计算量与维度相关；② 在极高维或非光滑流形上可能收敛慢；③ 采样式算法仍受随机性影响，某些极限通道可能需要更强的启发式或双向搜索来加速；④ 目前仅提供第三阶误差理论，尚缺乏更紧凑的收敛保证。

---

## 315. From One World to Another: Interfaces for Efficiently Transitioning Between Virtual Environments

**arXiv ID:** 2602.01423 | [PDF](https://arxiv.org/pdf/2602.01423v1)

**作者:** Matt Gottsacker `[一作]` (University of Central Florida), Joseph J. LaViola `[通讯]`

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

**🎯 论文内容**

本文设计并评估了八种虚拟现实（VR）世界切换界面，结合预览模式（Portal 与 World‑in‑Miniature）与交互技术（Hand Palette、Head Palette、World Wheel、Gallery），通过22名受试者完成六个虚拟环境中的硬币收集任务，探究界面设计对切换效率、认知负荷和用户体验的影响。

**💡 创新点**

创新点在于首次将预览、选择与确认等完整切换流程整合为一个连续的交互模型，并系统性比较不同预览与交互组合，提出针对任务场景的界面设计原则与改进建议。

**🔧 技术方法**

使用的技术包括：Portal 预览（实时第一人称窗口）、World‑in‑Miniature 预览（缩小版三维模型）、手部/头部基于手势的交互（thumb‑middle finger pinch）、手腕/手指精准交互（蓝色球体）以及传统点射选择等；实验在 Unity 与 Meta Quest Pro 上实现。

**📊 数据集**

实验使用自行创建的六个相似结构的虚拟环境（每个环境包含三块木箱和可放置金币的空间）作为数据集；未使用公开数据集，而是基于任务需求自制的场景与金币位置。

**📈 对比分析**

通过对比9种条件（8个原型+baseline）进行搜索时间、检索时间、存放时间等客观指标以及NASA‑TLX、SUS、UEQ、Continuity等主观问卷评估。结果显示：WiM+World Wheel 取得最快的搜索与检索时间；Portal 预览显著提升预定向效率；Hand Palette 与 World Wheel 在易用性与连续性上优于Gallery；baseline 在所有指标上均表现最差。

**⚠️ 局限性**

局限性包括：受试者样本量有限、任务单一且环境相似、仅测试了短淡入淡出过渡效果、仅使用手部追踪导致部分追踪不稳定、未涉及不同硬件/输入模态、缺乏真实工作流程与跨应用场景的验证。

---

## 316. Context Dependence and Reliability in Autoregressive Language Models

**arXiv ID:** 2602.01378 | [PDF](https://arxiv.org/pdf/2602.01378v1)

**作者:** Poushali Sengupta `[一作]` (University of Oslo), Frank Eliassen `[通讯]` (University of Oslo)

**通讯引用:** 45017 | [OpenAlex ID](https://openalex.org/A5100456327)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了自回归大型语言模型在冗余上下文中生成结果的可解释性问题，并提出了一种基于条件互信息的依赖感知解释方法。

**💡 创新点**

创新点在于通过对每个上下文单元计算相对于剩余上下文的条件互信息，从而消除冗余信息导致的解释误差，形成了 RISE（Redundancy‑Insensitive Scoring of Explanation）框架。

**🔧 技术方法**

采用条件互信息估计、结构化上下文单元分数计算以及 RISE 框架，并与注意力、梯度、扰动等传统解释方法进行对比。

**📊 数据集**

实验数据集包括 SQuAD v1.1 验证集、GPT‑2 以及开放权重的自回归模型，主要通过输出保持不变的冗余测试（重复、改写、重排）进行评估。

**📈 对比分析**

与注意力、梯度和扰动基线对比，RISE 在冗余抑制指标（Dup‑Split）显著下降，保持较高的解释稳定性，同时在多种冗余场景下表现出更可靠的解释质量。

**⚠️ 局限性**

局限在于只对结构化上下文单元（如提示块、检索段、对话轮次）进行解释，缺乏单词级粒度；条件互信息估计可能存在误差，需进一步改进估计方法。

---

## 317. ENFOR-SA: End-to-end Cross-layer Transient Fault Injector for Efficient and Accurate DNN Reliability Assessment on Systolic Arrays

**arXiv ID:** 2602.00909 | [PDF](https://arxiv.org/pdf/2602.00909v1)

**作者:** Rafael Billig Tonetto `[一作]`, Angeliki Kritikakou `[通讯]` (Univ Rennes)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种端到端的跨层故障注入框架ENFOR-SA，用于在基于Verilator的RTL级流水阵列（Systolic Array）上对深度神经网络（CNN/ViT）进行瞬态故障分析。

**💡 创新点**

创新点包括：①不需要HDL级注释，直接在Verilator生成的C++模型中通过修改寄存器数据源实现故障注入；②仅对流水阵列（Mesh）模块进行RTL仿真，完全隔离其他SoC组件；③利用PyTorch与C++的pybind11绑定实现软硬件分层，高效映射张量到硬件；④实现了相较于完整SoC RTL仿真至少两百倍、相较于HDFIT平均2.03倍的加速，同时保持RTL级精度。

**🔧 技术方法**

技术手段包括：Verilator + C++ RTL仿真、无注释的寄存器源注入、Gemmini流水阵列模型、Chipyard生成的系统、PyTorch推理层与C++接口、int8定点量化模型、MATLAB/pybind11绑定、批量输入（ImageNet/ViT）进行统计分析。

**📊 数据集**

使用的主要数据集：ImageNet验证集（20个批次，每批32张）用于CNN和ViT模型；预训练的量化CNN（ResNet50、MobileNetV2等）和Vision Transformer模型。

**📈 对比分析**

与传统方法比较：与完整SoC RTL仿真相比平均速度提升569×，与HDFIT（需要HDL注释）相比平均提升2.03×；与纯软件注入相比仅增加6%运行时。通过统计AVF、PVF以及误分类率验证其精度。

**⚠️ 局限性**

局限性：①主要针对规则的流水阵列架构（Gemmini）和特定的Systolic Array实现；②对多位或连续多周期错误的建模有限；③仍需要在每个硬件配置下进行一次Mesh提取和编译，初始准备成本较高；④在极大规模阵列或非OS/WS模式下加速效果下降。

---

## 318. SMCP: Secure Model Context Protocol

**arXiv ID:** 2602.01129 | [PDF](https://arxiv.org/pdf/2602.01129v1)

**作者:** Xinyi Hou `[一作]` (Huazhong University of Science and Technology), Haoyu Wang `[通讯]` (Huazhong University of Science and Technology)

**通讯引用:** 29108 | [OpenAlex ID](https://openalex.org/A5107888510)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

提出并实现了Secure Model Context Protocol（SMCP），为现有的Model Context Protocol（MCP）提供端到端的安全增强，涵盖统一身份管理、互信认证、安全上下文传播、细粒度策略执行和完整审计日志。

**💡 创新点**

创新点在于：
1) 将身份、信任与权限管理完整嵌入协议层，而非仅在应用层实现；
2) 通过Trusted Component Registry维护全局可验证的数字身份；
3) 在每一次工具调用链中嵌入可追溯的安全上下文，支持动态策略评估；
4) 设计统一的安全上下文结构，兼容现有MCP消息格式，实现无缝兼容；
5) 为每个关键操作提供可验证的审计日志，支持事后追踪与合规检查。

**🔧 技术方法**

采用的技术包括：
- 基于PKI/可验证凭证的身份认证与数字签名；
- 互信TLS或基于JWT的双向认证机制；
- 结构化身份编码与校验码（MOD 97‑10）；
- 安全上下文结构（JSON或Protobuf）与链式引用；
- 策略决策点（PDP）/执行点（PEP）模型与细粒度属性策略语言；
- 统一审计日志格式（可加密、签名）与日志聚合。

**📊 数据集**

本文未使用特定数据集；重点为协议设计与架构演示，未涉及模型训练或数据驱动实验。

**📈 对比分析**

方法比较与性能评估：
- 文中以案例演示演练安全流程，未给出量化指标；
- 主要通过对比MCP与SMCP在身份验证、权限评估、日志完整性等方面的改进来说明优势；
- 由于缺乏实验实现，性能影响（如延迟、吞吐）仅在理论层面讨论，未提供测量结果。

**⚠️ 局限性**

局限性：
- 目前仍为概念与设计原型，缺乏开源实现与实测性能；
- 需要外部可信组件注册与PKI基础，部署门槛相对较高；
- 方案对现有MCP实现的兼容性虽声称可无缝升级，但实际迁移过程可能涉及接口与消息格式的细微改动；
- 未针对大规模多租户环境中的可扩展性与治理机制做深入评估；
- 仍未对协议在不同攻击向量下的抵御效果进行定量评测。

---

## 319. SALAAD: Sparse And Low-Rank Adaptation via ADMM

**arXiv ID:** 2602.00942 | [PDF](https://arxiv.org/pdf/2602.00942v1)

**作者:** Hao Ma `[一作]` (ETH Zurich), Michael Muehlebach `[通讯]` (MPI for Intelligent Systems)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种可插拔的训练框架SALAAD，在LLM预训练期间诱导稀疏与低秩结构，从而在不改动模型架构的前提下实现模型压缩与可弹性部署。

**💡 创新点**

核心创新在于：①使用增广拉格朗日（ADMM）与两阶段优化实现稀疏低秩学习；②引入I‑控制器自适应调节每层秩与稀疏度，避免手工设定；③提出同态参数分配（HPA）策略，使单一预训练权重可在推理时连续调节容量。

**🔧 技术方法**

采用增广拉格朗日方法、Proximal 运算、I‑控制器自适应正则、同态分配裁剪与标准梯度优化器（如AdamW）结合。

**📊 数据集**

在C4大规模文本语料上使用基于LLaMA的模型进行预训练，覆盖60M、130M、350M、1B参数规模。

**📈 对比分析**

与LoRA、ReLoRA、GaLore、LORO、CoLA、SLTrain、LOST等方法对比，SALAAD在相同或更小参数预算下实现了更低的困惑度（PPL），并在单一检查点下支持连续的弹性推理，性能优于大多数基线。

**⚠️ 局限性**

主要局限包括：①训练时需要双阶段ADMM迭代，算力与内存开销高；②对超参数ρ的经验调优仍需依赖规模；③对极端稀疏/低秩目标时可能导致任务性能下降。

---

## 320. Do Schwartz Higher-Order Values Help Sentence-Level Human Value Detection? When Hard Gating Hurts

**arXiv ID:** 2602.00913 | [PDF](https://arxiv.org/pdf/2602.00913v1)

**作者:** Víctor Yeste `[一作]` (Universitat Politècnica de València), Paolo Rosso `[通讯]` (Valencian Graduate School and Research Network of Artificial Intelligence)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文在资源受限的 8 GB GPU 环境下，对 ValueEval'24/ValuesML 句子级人类价值检测进行实验，比较了直接多标签预测、基于 Schwartz 高阶类别的硬门控和 Presence→HO→Value 级联，以及阈值调校、轻量级特征、软投票集成和小型指令微调 LLM 的效果。

**💡 创新点**

创新点在于：① 系统评估了高阶类别结构在句子级任务中的可学习性和对细粒度检测的影响；② 证明硬门控会因误判累积而降低召回，阈值调校与小集成是更稳健的低成本提升手段；③ 将小型指令微调 LLM 作为跨族群集成的一种补充，验证其对整体性能的边际提升。

**🔧 技术方法**

使用的技术包括：BERT/DeBERTa 监督编码器、QLoRA 参数高效微调、少量示例提示的 LLM（Gemma‑2‑9B‑IT、Llama‑3.1‑8B 等）、阈值调优、短语境拼接、词典/主题特征、软投票与加权投票集成。

**📊 数据集**

实验数据集为官方英文版的 ValueEval'24/ValuesML，包含 74 231 条句子，按 44 758/14 904/14 569 分为训练/验证/测试集；标签为 19 个 Schwartz 基础价值及其派生的 8 个高阶类别，亦包括是否出现价值的 Presence 标记。

**📈 对比分析**

在所有对比中，阈值调校与软投票集成在 Macro‑F1 上提升约 0.02–0.05，最优直接预测模型在 HO 级别上可达 0.30‑0.34；硬门控与 Presence 级联往往不超越直接预测；小型 LLM 通过提示或 QLoRA 取得 0.15‑0.25 的 Macro‑F1，但与监督编码器相比仍低；在跨族群集成时，加入 LLM 可获得 1–2% 的额外提升。

**⚠️ 局限性**

主要局限包括：仅做单次实验（差异 1–2 个百分点可能不稳健）；句子级输入信息稀疏，忽略更长上下文；高阶标签极不平衡导致阈值过拟合；硬门控假设标签互斥与完整性，实际注释可能不满足；研究范围仅覆盖固定计算预算，无法推广到更大模型或不同领域。

---

## 321. Who Transfers Safety? Identifying and Targeting Cross-Lingual Shared Safety Neurons

**arXiv ID:** 2602.01283 | [PDF](https://arxiv.org/pdf/2602.01283v1)

**作者:** Xianhui Zhang `[一作]` (Nanjing University of Science and Technology), Tat-Seng Chua `[通讯]` (National University of Singapore)

**通讯引用:** 60254 | [OpenAlex ID](https://openalex.org/A5089404640)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `9cc9baba-5356-466d-81ff-d80028d90279` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过对大型语言模型进行激活分析和因果干预，发现并扩展一小部分跨语言共享安全神经元（SS‑Neurons），实现从高资源语言向低资源语言的安全迁移，显著提升低资源语言的安全性能。

**💡 创新点**

提出将跨语言共享安全神经元定位为极小但关键的子集，并仅对英语安全神经元进行参数更新的神经元层面训练策略；该策略既能高效迁移安全逻辑，又能保持模型通用能力。

**🔧 技术方法**

利用对比激活分析、神经元掩蔽攻击、因果激活/抑制实验以及梯度掩蔽训练（仅更新选定神经元），结合注意力权重矩阵的 neuron 识别技术。

**📊 数据集**

使用多语言对照安全数据集（英文 jailbreak + 译文），以及 AdvBench-x、MultiJail、MGSM、MMLU 等公开评测基准。

**📈 对比分析**

与 LoRA、全量微调、DPO、KTO、MPO 等传统安全对齐方法对比；SS‑Neuron 扩展在 ASR 上最低（约 0.3%–3%），且仅需更新约 0.5% 参数，兼顾安全与通用能力。

**⚠️ 局限性**

依赖英语安全子集可能导致英文化安全标准偏移，神经元识别方法对模型架构敏感，且被恶意攻击者利用神经元定位可能导致针对性攻击。

---

## 322. Discovering Process-Outcome Credit in Multi-Step LLM Reasoning

**arXiv ID:** 2602.01034 | [PDF](https://arxiv.org/pdf/2602.01034v1)

**作者:** Xiangwei Wang `[一作]` (University of Melbourne), Saman Halgamuge `[通讯]` (University of Melbourne)

**通讯引用:** 12276 | [OpenAlex ID](https://openalex.org/A5067418792)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出一种基于Step-wise Marginal Information Gain（MIG）的RL框架，利用模型自身的概率信息为LLM推理过程提供连续奖励，解决了稀疏奖励导致的信用分配难题。

**💡 创新点**

核心创新在于引入Monotonic Historical Watermark过滤噪声、Decoupled Masking实现过程与结果奖励分离，以及Dual-Gated SFT稳定训练。

**🔧 技术方法**

采用的技术包括梯度分离的强化学习（GRPO）、步骤级奖励计算、结构化回合采样、以及自监督的双门SFT。

**📊 数据集**

实验涵盖文本推理（GSM8K、MATH、Tal-SCQ5K-CN/EN）、多模态推理（Super-CLEVR、CoGenT、ChartQA、CMM-Math）以及OOD基准（CommonsenseQA、SVAMP、AIME 2025、MMStar、HallusionBench、MathVista）。

**📈 对比分析**

与GRPO及基线模型对比，MIG在多数任务上表现更佳，样本效率提升、Pass@1/Pass@8得分更高，尤其在多步推理和跨模态任务中表现突出。

**⚠️ 局限性**

主要局限包括对大型模型的扩展尚未验证、对极端高难度推理（如AIME 2025）仍需更强的SFT支持，以及对不同语言或领域的泛化机制尚不完整。

---

## 323. Mean field optimal Core Allocation across Malleable jobs

**arXiv ID:** 2602.01411 | [PDF](https://arxiv.org/pdf/2602.01411v1)

**作者:** Zhouzi Li `[一作]` (Carnegie Mellon University), Benjamin Berg `[通讯]` (UNC Chapel Hill)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `5b4c1114-4a70-478e-9921-2514ee03850d` `a8e75ba4-7a2d-4153-b003-06c94533add0`

**🎯 论文内容**

在多核系统中针对可弹性并行作业（malleable jobs）求解核心分配问题（CAM），在保持总核心数不变的前提下最小化加权平均响应时间。

**💡 创新点**

提出两种在均值场（mean‑field）极限下可证明最优的调度策略：
- FW‑CAM：利用有效负载（effective load）概念，所有同类作业分配相同核心数，且对作业剩余大小不敏感。
- WHAM：通过将问题转化为多齿轮（multi‑gear）马尔可夫分支（bandit）模型，推导Whittle策略，得到一个两模态的核心分配规则，兼顾作业剩余大小与持有成本。
这两种策略在理论上实现了均值场下的最优，并且WHAM在非极限情况下表现更好。

**🔧 技术方法**

使用的技术包括：
- 均值场（mean‑field）极限分析。
- 有效负载理论与子线性加速函数（concave speedup）处理。
- 将调度问题映射为连续时间多齿轮马尔可夫分支（bandit）模型。
- 采用Whittle松弛与指数折扣→0（vanishing discount）得到Whittle策略。
- 证明时使用大数定律、凸优化、Markovian队列理论和ODE吸引子（global attractor）分析。

**📊 数据集**

实验使用人工合成的数据集：三类作业，每类拥有不同的子线性加速函数（如理想线性、超线性、弱线性等），作业大小采用相位型（phase‑type）分布。系统负载保持为ρ=0.25，核心数和到达率按比例增长。

**📈 对比分析**

与文献中常用的公平调度（EQUI）和贪婪调度（GREEDY）做对比。实验结果表明：
- FW‑CAM 与 WHAM 随核心数增大均收敛到理论下界。
- WHAM 的收敛速度明显快于 FW‑CAM，且在核心数较小的实际规模下已接近最优。
- 两种策略在任何核心规模下都优于EQUI和GREEDY，验证了理论最优性与实用性。

**⚠️ 局限性**

限制与不足：
- 证明仅在均值场极限下成立，需假设系统满足全局吸引子性质，实证证明困难。
- 需要作业加速函数满足可微、严格凹且子线性，且作业大小分布在证明阶段要求为相位型（可近似），对真正复杂分布的适用性尚未完全验证。
- WHAM 的实现涉及求解市场清算服务成本（ℓ*），在大规模实时系统中计算成本不易。
- 对非均值场极限（如小核心数、非比例负载）仅通过实验验证，缺乏严格理论保证。

---

## 324. High-accuracy sampling for diffusion models and log-concave distributions

**arXiv ID:** 2602.01338 | [PDF](https://arxiv.org/pdf/2602.01338v1)

**作者:** Fan Chen `[一作]` (Massachusetts Institute of Technology), Alexander Rakhlin `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 5458 | [OpenAlex ID](https://openalex.org/A5076656836)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `ba576bd1-e51d-44e8-8077-fc943b333c93` `f86bf285-fd08-4156-973b-6e6481af8fa0`

**🎯 论文内容**

提出一种基于一阶拒绝采样的元算法（First-Order Rejection Sampling, FORS），用于在仅能查询分数函数梯度的条件下，实现扩散模型和对数凸分布的高精度采样。

**💡 创新点**

创新点在于：①首次实现仅凭一阶信息即可在多项式对数(1/δ)步内达到 δ‑误差的高精度采样；②提出统一的采样框架，可自适应最低数据假设、Lipschitz 条件和内在维数，显著降低维度与误差的耦合；③将该框架推广到对数凸分布，获得首个仅使用梯度查询的高精度采样结果。

**🔧 技术方法**

核心技术包括：一阶拒绝采样（利用分数梯度构造可接受的 proposal），路径积分与局部近似（处理非线性误差），多种变分路径和截断策略；以及对扩散逆过程的解析分析，结合梯度误差控制和时间步长自适应。

**📊 数据集**

本工作主要为理论分析，未在具体数据集上进行实验；讨论的所有结果均基于数学模型和理论证明。

**📈 对比分析**

与现有方法相比，传统方法在误差 δ 上需要 O(1/δ) 或 O(1/δ²) 步，而 FORS 在所有假设下均实现 O(polylog(1/δ)) 步，维度复杂度为 O(d)、O(√(dL)) 或 O(d_⋆)。在对数凸分布上也获得了与最先进方法相当甚至更优的梯度查询复杂度，且不需要函数值查询。

**⚠️ 局限性**

局限性包括：①对分数梯度误差的控制仍依赖于较强的 Lipschitz 或 Hölder 条件；②在非平滑或高分布偏差场景下，误差传播机制尚未完全优化；③实际实现中的随机路径与截断策略可能导致额外的常数系数开销；④对特定扩散时间步长的选择仍需经验性调优。

---

## 325. Mixture-of-World Models: Scaling Multi-Task Reinforcement Learning with Modular Latent Dynamics

**arXiv ID:** 2602.01270 | [PDF](https://arxiv.org/pdf/2602.01270v1)

**作者:** Boxuan Zhang `[一作]` (Beijing Institute of Technology), Gang Wang `[通讯]` (Beijing Institute of Technology)

**通讯引用:** 102095 | [OpenAlex ID](https://openalex.org/A5100389265)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了可扩展的混合世界模型（MoW），通过模块化VAE与Transformer专家实现多任务强化学习；

**💡 创新点**

创新点在于将任务特定VAE、混合Transformer专家、任务预测与专家平衡损失、梯度聚类共享模块结合，显著提升参数与样本效率；

**🔧 技术方法**

使用技术包括变分自编码器、Transformer混合专家（MoE）、任务嵌入、梯度聚类、和谐损失与专家平衡损失、KL损失以及基于世界模型的想象策略；

**📊 数据集**

实验数据集为Atari 100k离散控制基准和Meta-World 50机器人操作任务；

**📈 对比分析**

与STORM、MOORE等基准对比，MoW在Atari 100k达到110.4%人类归一化得分（接近114.2%），参数量减半；在Meta-World 50任务实现74.5%成功率，仅需300k步，优于现有模型；

**⚠️ 局限性**

局限在于视觉重构精度与动力学预测的挑战，且在真实环境和分布漂移下的泛化仍待提升。

---

## 326. Interaction-Consistent Object Removal via MLLM-Based Reasoning

**arXiv ID:** 2602.01298 | [PDF](https://arxiv.org/pdf/2602.01298v1)

**作者:** Ching-Kai Huang `[一作]` (National Yang Ming Chiao Tung University), Yan-Cen Lee `[通讯]` (National Yang Ming Chiao Tung University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出了交互一致对象移除（ICOR）任务，致力于在删除目标对象的同时，自动识别并删除与其产生交互效果的其他元素，生成语义连贯、视觉自然的编辑结果。

**💡 创新点**

创新点在于：①首次把对象与其光照、物理连接、产物以及语境关联等交互因素纳入移除范式；②设计了基于大语言模型（MLLM）的推理分析流程，利用链式思考自动生成需删除元素列表；③引入自我纠错机制和本地化部署方案，兼顾精度与资源受限场景。

**🔧 技术方法**

核心技术包括：多模态大语言模型（如GPT‑4o或LLaVA+Llama）进行指令理解与推理；开源语义分割模型Grounded‑SAM生成精细掩码；基于扩散模型的掩码导向对象移除模型ObjectClear与Attentive Eraser；自我纠错阶段的Simulator/Examiner；以及局部部署时的Prompt‑Chaining与LLM‑MLLM协作。

**📊 数据集**

评估数据集为自研的 ICOREval，包含110个图像–指令–真实结果三元组，涵盖光照效应、物理连结、目标产物和语境关联四类交互情形。

**📈 对比分析**

在 ICOREval 上与 MGIE、SmartEdit 以及闭源 GPT‑Image‑1、Nano Banana 等基线对比，REORM（GPT‑4o）在 DINO、LPIPS、PSNR、SSIM 等四项指标均名列第一，且在保持场景一致性方面表现突出；仅在推理耗时略高，局部部署版在单 GPU 上仍保持可接受的速度。

**⚠️ 局限性**

局限性包括：自我纠错可能导致误删背景元素；需要高质量的 MLLM 推理，资源受限时仍受限于模型大小；对用户意图的细粒度控制不足，可能出现过度编辑；并且实验多依赖实验室环境，真实多样性和鲁棒性待进一步验证。

---

## 327. Workflow-R1: Group Sub-sequence Policy Optimization for Multi-turn Workflow Construction

**arXiv ID:** 2602.01202 | [PDF](https://arxiv.org/pdf/2602.01202v1)

**作者:** Mingze Kong `[一作]` (Chinese University of Hong Kong), Zhongxiang Dai `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 1573 | [OpenAlex ID](https://openalex.org/A5081447482)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Workflow‑R1 框架，将工作流构建从一次性静态程序生成转变为多轮自然语言的思考-行动-观察交互过程，并用强化学习自适应地优化其策略。

**💡 创新点**

创新点在于：①将每轮思考‑行动对定义为一个“子序列”作为最小决策单元；②提出 Group Sub‑sequence Policy Optimization（GSsPO）算法，解决传统 token‑级或全序列级优化的粒度不匹配；③实现了完全动态、闭环的工作流生成，突破静态执行陷阱。

**🔧 技术方法**

技术组合：LLM 作为策略模型；强化学习（GRPO、GSPO、GSsPO）；自然语言接口定义操作符；格式化奖励与结果监督；搜索等外部工具集成。

**📊 数据集**

数据集涵盖七个问答基准：NQ、TriviaQA、PopQA（一般 QA）和 HotpotQA、2WikiMultiHopQA、Musique、Bamboogle（多跳 QA），训练集由 NQ 与 HotpotQA 的 10,000 条样本构成。

**📈 对比分析**

与直接推理、CoT、Self‑Consistency、MedPrompt、MaAS、AFlow 以及 Search‑R1（GRPO/PPO）等方法比较，Workflow‑R1 在多数基准上均实现最高 EM，平均值提升至约 0.507（标准版）或 0.632（搜索增强版），显著优于对照组。

**⚠️ 局限性**

局限性：性能高度依赖执行模型的能力；操作符接口需手工设计；训练成本大（全参数 fine‑tuning + RL）；对极长或高度动态任务的收敛仍不稳定。

---

## 328. Semi-supervised CAPP Transformer Learning via Pseudo-labeling

**arXiv ID:** 2602.01419 | [PDF](https://arxiv.org/pdf/2602.01419v1)

**作者:** Dennis Gross `[一作]` (Simula Research Laboratory), George-Christopher Vosniakos `[通讯]` (National Technical University of Athens)

**通讯引用:** 4209 | [OpenAlex ID](https://openalex.org/A5007818079)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出一种半监督伪标签方法，用已训练好的Transformer模型在测试时生成的序列经过学习的oracle过滤后再回训，以提升高层级CAPP流程规划模型的准确性。

**💡 创新点**

创新点在于利用专门训练的oracle对Transformer输出进行二分类判断，而非单纯依赖模型自带的置信度；oracle基于丰富的序列统计特征进行判定，实现在低数据量场景下显著提升性能，并避免错误标签的误导。

**🔧 技术方法**

核心技术包括GPT‑2风格的解码器Transformer、XGBoost二分类器作为oracle、丰富的序列特征工程（置信度、熵、KL、时间序列差分等）以及伪标签回训策略。

**📊 数据集**

使用自生成的完整CAPP数据集（包含所有可能的输入空间），通过不同比例（1%、2.5%、5%、10%）抽样作为训练集，剩余数据用于oracle训练与测试。

**📈 对比分析**

与基线（仅原始训练集回训）和随机伪标签（不做过滤）进行对比。实验结果表明oracle增强在低资源下可提升约11%、5%、1.6%和0.5%的准确率，显著优于随机增强和基线。

**⚠️ 局限性**

限制包括：在极低资源环境下整体准确率仍不高；oracle训练需要标注数据且对模型误差分布敏感；实验在完整数据集上进行，实际工业场景中可能缺乏全量数据导致泛化性待验证。

---

## 329. Adaptive Quantum-Safe Cryptography for 6G Vehicular Networks via Context-Aware Optimization

**arXiv ID:** 2602.01342 | [PDF](https://arxiv.org/pdf/2602.01342v1)

**作者:** Poushali Sengupta `[一作]` (University of Oslo), Yan Zhang `[通讯]` (University of Oslo)

**通讯引用:** 45017 | [OpenAlex ID](https://openalex.org/A5100456327)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `5b4c1114-4a70-478e-9921-2514ee03850d` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了适用于6G车联网的自适应后量子密码框架CAAP

**💡 创新点**

创新点在于结合短期预测与多目标演化优化实现上下文感知的PQC选择，并引入单向升级协议抵御降级攻击

**🔧 技术方法**

采用预测-多目标演化算法(APMOEA)、强化学习、上下文感知预测以及TLS1.3/QUIC启发的单向升级协议

**📊 数据集**

使用LuST车流轨迹、ERA5气象数据、3GPP NR-V2X信道模型及NIST PQC实现基准

**📈 对比分析**

与静态PQC、NSGA-II、RL单一方法比较，平均延迟下降27%，通信开销下降65%，降级攻击被成功阻止

**⚠️ 局限性**

主要限制在于对时间同步的依赖、预测误差敏感、缺乏现场验证以及未实现完整加密+签名组合

---

## 330. L-Moment-Based LOS and NLOS Channel Characterization via Four-parameter Kappa Distribution for AoA BLE CTE Measurements

**arXiv ID:** 2602.01229 | [PDF](https://arxiv.org/pdf/2602.01229v1)

**作者:** Hamed Talebian `[一作]` (Mid Sweden University), Mikael Gidlund `[通讯]` (Mid Sweden University)

**通讯引用:** 8482 | [OpenAlex ID](https://openalex.org/A5004012289)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

收集并分析了在同一几何条件下匹配的LOS和NLOS BLE CTE IQ数据，利用L-矩比率图和四参数Kappa分布对通道特征进行建模。

**💡 创新点**

首次将L-矩和Kappa分布应用于BLE AoA CTE测量，实现对LOS/NLOS的高精度统计分离与描述，提供了比传统Rayleigh/Rice模型更精确的重尾建模。

**🔧 技术方法**

采用稳健异常检测、Welch/Levene假设检验、L-矩比率图、Kappa分布拟合以及DBSCAN聚类等统计与机器学习技术。

**📊 数据集**

使用在室内实验室基于u-blox XPLR-AOA-3平台收集的约132k个标记为LOS/NLOS的CTE包，涵盖8个标签位置、4个AP、不同方向与角度。

**📈 对比分析**

通过Z/D距离和L-矩GoF指标比较多种分布，Kappa模型在LOS和NLOS上得到最小误差；DBSCAN在L-矩空间实现两类完全分离，而普通矩则聚为单一簇，表明L-矩特征更具判别力。

**⚠️ 局限性**

仅在单一室内环境、固定硬件与天线布局下验证，缺乏对动态多变场景的适应性和Kappa参数通用性的评估。

---

## 331. Multi-Fidelity Physics-Informed Neural Networks with Bayesian Uncertainty Quantification and Adaptive Residual Learning for Efficient Solution of Parametric Partial Differential Equations

**arXiv ID:** 2602.01176 | [PDF](https://arxiv.org/pdf/2602.01176v1)

**作者:** Olaf Yunus Laitinen Imanov `[一作]` `[通讯]` (Technical University of Denmark), Olaf Yunus Laitinen Imanov (Technical University of Denmark)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `14d48e9d-0069-4ad9-996a-1d5968216998` `afceb026-1760-41ae-8d86-010831a37d97` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

研究了一种多分辨率贝叶斯物理信息神经网络（MF‑BPINN），能够利用低精度模拟与稀疏高精度数据通过自适应残差学习和贝叶斯不确定性量化实现高效求解参数化偏微分方程。

**💡 创新点**

引入可学习门控机制实现线性与非线性误差自适应混合，结合Hamiltonian Monte Carlo实现对模型与观测噪声的完整贝叶斯不确定性估计，并给出收敛与泛化理论。

**🔧 技术方法**

多分辨率神经网络架构、物理信息损失、自动微分、可学习门控混合专家、残差学习、Hamiltonian Monte Carlo后验采样、梯度加权训练、参数空间采样等技术。

**📊 数据集**

1D Burgers 方程、2D 热传导、2D Navier‑Stokes 等三类典型参数化 PDE 的数值仿真数据，低精度模拟与高精度标签分别生成。

**📈 对比分析**

与传统高精度 PINN、低精度 PINN、线性/非线性多分辨率 PINN 以及 B‑PINN 对比，MF‑BPINN 在相同精度下平均速度提升 7.1 倍、计算成本降低 73–86%，95% 置信区间覆盖率 95.1% 以内，样本效率提高约 6 倍。

**⚠️ 局限性**

依赖低精度模型作为先验；后验采样在大规模问题上仍耗时；门控机制需要手动设置网络规模和权重平衡；对高度非线性或强耦合多物理问题的泛化尚待验证。

---

## 332. Evidence-Decision-Feedback: Theory-Driven Adaptive Scaffolding for LLM Agents

**arXiv ID:** 2602.01415 | [PDF](https://arxiv.org/pdf/2602.01415v1)

**作者:** Clayton Cohn `[一作]` (Vanderbilt University), Gautam Biswas `[通讯]` (Vanderbilt University)

**通讯引用:** 12878 | [OpenAlex ID](https://openalex.org/A5051150754)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了基于Evidence-Decision-Feedback框架的多代理LLM代理Copa，支持高中STEM+课堂中的自适应支架与解释反馈。

**💡 创新点**

将教学理论（SCT、ZPD、ECD）与多代理LLM架构深度融合，形成可解释、可适应且不易导致学生过度依赖的支架模型。

**🔧 技术方法**

采用GPT‑5进行推理，CoT提示与RAG检索技术，构建Evidence、Decision、Feedback三模代理，结合SCT、ZPD等教育理论实现决策与反馈。

**📊 数据集**

使用C2STEM课堂日志与对话数据（约7,017条环境动作、238条学生‑代理对话）以及学生自评问卷。

**📈 对比分析**

通过对比不同掌握分位数下的对话策略频率、成功率、依赖度与解释性指标，结果显示支架适应性提升、理解与任务掌握对齐、学生对代理的依赖下降，解释性显著优于随机基线。

**⚠️ 局限性**

研究为相关性分析，未开展随机对照试验，评估仅关注任务掌握而未涵盖先前知识、自我调节等因素，样本规模有限，可能存在未观测到的混杂变量。

---

## 333. A Complexity Bound for Determinisation of Min-Plus Weighted Automata

**arXiv ID:** 2602.01221 | [PDF](https://arxiv.org/pdf/2602.01221v1)

**作者:** Shaull Almagor `[一作]`, Sarai Sheinvald `[通讯]`

**关键词:** `33d19632-8af2-4683-a5db-767c7ce749e6`

**🎯 论文内容**

在论文中，作者证明了加权有限自动机的确定化问题可在原子递归复杂度内解决，并给出了具体的上界。

**💡 创新点**

创新点在于将非构造性可决定性证明转化为构造性方法，引入有效的cactus字母、基线平移与定量缩放技术，得到首个复杂度上界。

**🔧 技术方法**

主要技术包括基线增强构造、稳定循环与基线平移、有效cactus字母、分离重复子串（SRI）以及定量缩放（quantitative zooming）等。

**📊 数据集**

由于是理论分析，论文未使用任何实验数据集，而是对WFA的符号表示进行理论证明。

**📈 对比分析**

与原先仅给出可决定性证明的工作相比，本文提供了可构造的算法，复杂度虽为原子递归但仍优于先前无界的非构造性结果。

**⚠️ 局限性**

局限在于得到的复杂度仍为非多项式级别，且实现过程高度复杂，尚难进一步压缩至更低级别；此外，对更广泛模型的推广仍未完成。

---

## 334. Balancing Understanding and Generation in Discrete Diffusion Models

**arXiv ID:** 2602.01362 | [PDF](https://arxiv.org/pdf/2602.01362v1)

**作者:** Yue Liu `[一作]` (University of Chinese Academy of Sciences), Yunfan Liu `[通讯]` (University of Chinese Academy of Sciences)

**通讯引用:** 1789 | [OpenAlex ID](https://openalex.org/A5031640365)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了 XDLM，一种通过可调混合比例将掩码扩散和统一噪声扩散统一在单一模型中的离散扩散语言模型。

**💡 创新点**

创新点在于引入了静态噪声核与可调混合比例，构造了可推导的标量化训练目标，显著降低了内存瓶颈，并实现了 MDLM 与 UDLM 的理论统一。

**🔧 技术方法**

采用了离散扩散概率模型、可变噪声核、标量化后向推断以及持续预训练等技术。

**📊 数据集**

在文本零样本基准、ImageNet‑1K 图像生成以及 8B 参数 LLM 的代码生成等数据集上进行评估。

**📈 对比分析**

与 UDLM、MDLM 及其他基准方法对比，XDLM 在零样本困惑度上比 UDLM 提升 5.4 分，在 4 步图像生成的 FID 从 80.8 降至 54.1，在 32 步代码生成的 MBPP 提升 120% 以上。

**⚠️ 局限性**

局限性包括未进行大规模从头预训练、未充分探究跨步性能交叉、未针对语言或图像设计专用采样策略、跨模态统一性未验证，以及缺乏推理加速方案。

---

## 335. On Condensation of Block Sensitivity, Certificate Complexity and the $\mathsf{AND}$ (and $\mathsf{OR}$) Decision Tree Complexity

**arXiv ID:** 2602.01042 | [PDF](https://arxiv.org/pdf/2602.01042v1)

**作者:** Sai Soumya Nalli `[一作]` (Microsoft Research Lab), Jayalal Sarma `[通讯]` (Indian Institute of Technology Madras)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b`

**🎯 论文内容**

本文研究布尔函数复杂度度量的“硬度浓缩”特性，证明了块灵敏度、证书复杂度以及 AND/OR 决策树复杂度不可浓缩，并给出了 Fourier 稀疏度的弱浓缩结果。

**💡 创新点**

创新点在于：①首次构造改进的 Rubinstein 函数，证明块灵敏度和证书复杂度在任意 O(k³) 变量约束下只能降至 O(k²)；②将该不浓缩性质推广到 AND/OR 决策树；③发现 Fourier 稀疏度可以在 O(k²) 变量下保持稀疏度 k，提供了新的稀疏度浓缩视角。

**🔧 技术方法**

采用的技术主要包括：约束（restriction）与对偶约束分析、逆向感知 (adversarial strategy) 的树深度证明、对 Rubinstein 结构的块与敏感性分析，以及基于集合系统同构的 Fourier 代数变换。

**📊 数据集**

由于本研究为理论计算复杂度研究，无使用实际数据集；所有结论均基于构造函数与抽象证明。

**📈 对比分析**

与现有结论对比：之前仅知道查询复杂度不可浓缩，但本文在块灵敏度、证书复杂度与 AND/OR 决策树上提供了更强的不浓缩上界；在 Fourier 稀疏度上给出了先前未知的弱浓缩上界，展示了不同度量在浓缩性上的差异。

**⚠️ 局限性**

局限性：①只给出了弱浓缩结果，尚未说明能否实现更强的 Fourier 稀疏度浓缩；②不涵盖对数级稀疏度的情况；③对非 Rubinstein 结构的函数浓缩性仍未完成，可能存在更广泛的不浓缩或浓缩情形未被探究。

---

## 336. OLion: Approaching the Hadamard Ideal by Intersecting Spectral and $\ell_{\infty}$ Implicit Biases

**arXiv ID:** 2602.01105 | [PDF](https://arxiv.org/pdf/2602.01105v1)

**作者:** Zixiao Wang `[一作]` (Peking University), Huishuai Zhang `[通讯]` (Peking University)

**通讯引用:** 4540 | [OpenAlex ID](https://openalex.org/A5042848593)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种新的优化器OLion，将Muon's正交化更新与Lion的符号更新相结合，实现了对矩阵参数的谱控制与坐标极值控制的统一。

**💡 创新点**

创新点在于：1）通过一次正交化再符号化的复合投影，逼近谱极点与ℓ∞极点的交集，形成“Hadamard理想”；2）提出在单一步骤内完成交叉几何的实现，保持了极低的状态开销；3）在理论上证明了“正交后符号化”方向与原始正交方向的近似一致性，并给出了非凸平滑场的收敛保证。

**🔧 技术方法**

使用技术包括：Newton–Schulz迭代进行矩阵正交化、符号化操作、RMS对齐缩放、传统动量（多尺度动量）以及可选的学习率调度；整个优化器只需保存一次动量向量。

**📊 数据集**

实验使用的数据集与任务：GPT‑2（OpenWebText）预训练、Llama‑2‑7B（FSDP）预训练、SiT（ImageNet‑1K 256×256）图像生成预训练、Llama‑3.1‑8B在各种SFT基准（GSM8K、MATH、NumGLUE、SimulEq、Aqua）上的微调。

**📈 对比分析**

与AdamW、Muon、Lion等基线相比，OLion在训练损失下降速度、学习率鲁棒性、权重谱与ℓ∞范数控制等指标上均表现更佳；在SFT任务中，OLion在大多数基准上获得最高或第二高分，显著缓解了预训练–微调的不匹配问题。

**⚠️ 局限性**

局限性包括：1）理论收敛证明依赖于“对角等 isotropy”假设，在某些稀疏或高度非等方阵情形下可能不成立；2）未对分布式通信压缩与低精度量化的细节进行深入分析；3）对非矩阵形参数（如一维偏置）的适用性尚未完全验证；4）正交化迭代次数K的选择仍需经验调优，可能影响训练稳定性与速度。

---

## 337. Symphony-Coord: Emergent Coordination in Decentralized Agent Systems

**arXiv ID:** 2602.00966 | [PDF](https://arxiv.org/pdf/2602.00966v1)

**作者:** Zhaoyang Guan `[一作]` (Northwestern University), Bill Shi `[通讯]` (Gradient)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并实现了一个分布式多代理LLM系统Symphony-Coord，能够在运行时通过在线上下文多臂赌博机学习动态分配任务，实现自愈与高效协作。

**💡 创新点**

创新点在于将代理选择转化为在线情境多臂赌博机问题，提出两阶段Beacon过滤+LinUCB在线选择的分布式协议，消除了静态角色依赖，实现角色自发出现、无中央控制、可扩展且具备自愈能力。

**🔧 技术方法**

技术手段包括：两阶段Beacon协议（轻量化候选筛选与Top‑L过滤）、基于LinUCB的上下文UCB在线学习、任务与代理特征融合（嵌入相似度、负载、延迟、可靠性等）、延迟回报更新机制，以及在线性可实现性假设下的子线性回报理论分析。

**📊 数据集**

使用的数据集主要包括公开基准GSM8K、BBH和MedicalQA，以及内部模拟实验数据，用于评估多代理路由的性能与自愈能力。

**📈 对比分析**

通过与单代理基线（Direct、React、Synapse、Self‑Consistency、Self‑Refinement）以及多代理基线（MorphAgent、Cold Start、MetaGPT、AFLOW、GPTSwarm）进行对比实验，发现Symphony-Coord在三大基准上平均精度提升8.5–22.0点，最高提升达33点；在异质代理设置下，5人团队中表现最优，且在冷启动和分布漂移场景下表现出更强的鲁棒性。

**⚠️ 局限性**

局限性包括：需大量实验收集延迟回报，导致更新速度慢；极端任务分布漂移或代理失效时恢复仍需一定时间；需要手动调节Top‑L阈值和UCB探索参数；在大规模代理池和高维上下文下计算与存储成本仍有提升空间。

---

## 338. Beyond Training for Cultural Awareness: The Role of Dataset Linguistic Structure in Large Language Models

**arXiv ID:** 2602.01161 | [PDF](https://arxiv.org/pdf/2602.01161v1)

**作者:** Reem I. Masoud `[一作]` (King Abdulaziz University), Miguel R. D. Rodrigues `[通讯]` (University College London)

**通讯引用:** 6550 | [OpenAlex ID](https://openalex.org/A5044634366)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究数据集层面语言学特征与大语言模型在多语言文化对齐任务中的关系，提出数据集中心的评估与子集干预方法。

**💡 创新点**

①首次将语言学、语义与结构指标通过 PCA 转化为可解释维度；②证明这些维度对不同模型的文化表现关联度高度依赖模型；③发现 PC3（词汇与风格多样性）是最稳健的正向干预方向。

**🔧 技术方法**

轻量化语言学特征提取（Distinct‑1/2、Self‑BLEU、TTR、MATTR、HDD、MTLD、Cosine、TF‑IDF、Silhouette、K‑means）、语言特定 PCA、数据子集构造、三大 LLM 家族（LLaMA、Mistral、DeepSeek）微调、文化对齐基准评估、相关性与干预实验。

**📊 数据集**

阿拉伯语、中文、日语的 9–13 个后训练文化数据集，包括 QA、新闻、社交媒体、指令调优、知识问答、文化调查问卷等多来源集合。

**📈 对比分析**

通过 Pearson 相关性和子集干预对比，发现 PC3 在所有模型中持续提升文化知识/价值/规范得分，PC1/PC2 则表现不稳定或负面，说明不同模型对语言学维度的敏感性不同。

**⚠️ 局限性**

仅基于单一模型或语言可能导致误导；PC1/PC2 的正负效应不对称，需结合模型特性解释；实验规模受限于可微调的数据量与算力；未考察更细粒度的词性或句法层面特征。

---

## 339. SPELL: Synthesis of Programmatic Edits using LLMs

**arXiv ID:** 2602.01107 | [PDF](https://arxiv.org/pdf/2602.01107v1)

**作者:** Daniel Ramos `[一作]` (Carnegie Mellon University), Claire Le Goues `[通讯]` (Carnegie Mellon University)

**通讯引用:** 7008 | [OpenAlex ID](https://openalex.org/A5032356672)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一个端到端的系统，利用大语言模型先生成并验证源库到目标库的迁移实例，然后通过反演和代理式学习自动合成可直接在 OpenRewrite DSL 中使用的迁移脚本。

**💡 创新点**

创新点在于把 LLM 视为迁移知识的“知识源”，通过提示式生成验证用例来弥补缺乏真实迁移数据的局限，并将 LLM 提取的知识与经典反演（anti‑unification）和代理式脚本合成相结合，产生可视化、可测试、可复用的迁移脚本。

**🔧 技术方法**

主要技术包括：Prompt‑Engineering 与多轮自指令生成 LLM 示例；基于差分的反演生成初始规则；代理式 LLM 循环进行规则细化与图结构化；OpenRewrite DSL 作为迁移脚本的实现语言；Python 代码覆盖与单元测试验证。

**📊 数据集**

使用了 10 对 Python 库的迁移任务，共产生 870 条经验证的迁移三元组（实现、测试、迁移），并在 18 个真实开源项目上进行了实际迁移测试。

**📈 对比分析**

与现有的 MELT 工具比较，单次合成成功率平均为 61.6%（MELT 22.9%），在 10 个迁移任务上均优于 MELT；在真实项目中，迁移脚本能在大多数情况下保持原有测试通过率（平均 86%）。

**⚠️ 局限性**

局限性包括：生成的示例往往聚焦常见 API，稀有或错误处理路径缺失；DSL 不能处理字符串内的嵌入式 DSL 代码，导致某些迁移成功率低；测试用例依赖 LLM 生成，可能缺乏深度覆盖；生成示例采用小模型，质量受限；迁移脚本在面对复杂项目变体时仍需人工调整。

---

## 340. Adaptive Visual Autoregressive Acceleration via Dual-Linkage Entropy Analysis

**arXiv ID:** 2602.01345 | [PDF](https://arxiv.org/pdf/2602.01345v1)

**作者:** Yu Zhang `[一作]` (Tongji University), Longbing Cao `[通讯]` (Macquarie University)

**通讯引用:** 13961 | [OpenAlex ID](https://openalex.org/A5000798681)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种训练无关的VAR模型加速框架NOVA，通过熵分析实现自适应token裁剪与残差缓存重用。

**💡 创新点**

创新点在于双链路（尺度与层级）自适应token减少，利用尺度熵增长拐点动态确定加速激活点，并采用熵导向token选择。

**🔧 技术方法**

技术包括信息熵度量、尺度与层级链接比率函数、残差缓存重用及在线熵增长率检测。

**📊 数据集**

使用的公开数据集包括GenEval、DPG‑Bench、MJHQ‑30K、ImageReward、HPSv2.1等进行生成质量评估。

**📈 对比分析**

与FastVAR、SkipVAR、SparseVAR等基线对比，NOVA在保持近乎无质量损失的前提下实现2.89×速度提升，且在Infinity‑8B上甚至提升人类偏好分数。

**⚠️ 局限性**

局限在于仍需对不同尺度、层级的熵阈值进行经验设定，且对极端复杂图像的自适应能力仍有待进一步验证。

---

## 341. SimpleGPT: Improving GPT via A Simple Normalization Strategy

**arXiv ID:** 2602.01212 | [PDF](https://arxiv.org/pdf/2602.01212v1)

**作者:** Marco Chen `[一作]` (Tsinghua University), Rong Xiao `[通讯]` (Intellifusion Inc.)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种新的归一化策略 SimpleNorm 并基于此构建 SimpleGPT 模型，旨在通过在每个线性映射后立即归一化来稳定激活尺度，降低 Hessian 规范，从而支持更大的学习率并提升训练效果。

**💡 创新点**

创新点在于将归一化放在线性层后作为一个统一的算子（SimpleNorm），并从二阶几何角度证明其显著降低激活相关 Hessian 的谱范数；此外证明这种局部非线化还能提升模型的表达能力。

**🔧 技术方法**

使用了第二阶优化理论（Hessian 解析、Gauss–Newton 分解）、RMSNorm 作为归一化基元、AdamW 优化器、cosine 学习率调度、bfloat16 精度训练，并在大规模 Transformer（GPT、Llama2/3、nanoGPT）上实现和评估。

**📊 数据集**

主要使用 C4 文本数据集进行预训练；在不同规模（1B、1.4B、7B、8B）模型上均在 C4 上进行对比实验。

**📈 对比分析**

对比方法包括：与标准 GPT、Llama2/3 以及使用 QKNorm 的版本；实验显示 SimpleGPT 能容忍 3~10 倍更大的学习率，训练损失在 7B 规模下从 2.290 降至 2.208，整体性能显著优于基线；训练时间略有增加（约 3%）。

**⚠️ 局限性**

局限性：实验仅覆盖少数架构和数据集；对 8B 规模仅训练 20K 步，缺乏长周期验证；归一化实现依赖于 RMSNorm，未探索其他基元对性能的影响；未深入研究对抗鲁棒性、推理速度或跨任务迁移效果。

---

## 342. Sensing What Surveys Miss: Understanding and Personalizing Proactive LLM Support by User Modeling

**arXiv ID:** 2602.00880 | [PDF](https://arxiv.org/pdf/2602.00880v1)

**作者:** Ailin Liu `[一作]` (Ludwig Maximilian University of Munich), Francesco Chiossi `[通讯]` (Ludwig Maximilian University of Munich)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a2602d71-93ab-4bad-974b-672788df8193` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一种基于多模态传感（EDA 与鼠标运动）与大语言模型的自适应调查支持系统，实时预测受访者认知过载并主动提供解释；

**💡 创新点**

①结合实时生理与行为信号进行个性化预测；②使用规则式阈值自适应与 LLM 生成的上下文解释；③在实验中验证时间对齐的重要性；

**🔧 技术方法**

电导率（EDA）采集、鼠标轨迹记录、机器学习分类器（线性回归+阈值更新）、LLaMA‑2‑7B 生成自然语言说明；

**📊 数据集**

公开的多项选择知识测验题库（德国语译英），共 60 题，包含易/难两类；

**📈 对比分析**

在 32 位参与者的 within‑subjects 设计下比较三种适配策略（Aligned‑Adaptive、Misaligned‑Adaptive、Random‑Adaptive），Aligned‑Adaptive 使答题准确率提升至 62%（比对照高约 10‑20%），误判率显著降低，用户体验（效率、可靠性、善意）显著更好；

**⚠️ 局限性**

实验规模小、样本偏年轻、受限于实验室环境、仅涵盖多项选择题、LMM 预训练 LLM 生成说明可能过长、冷启动阈值敏感、仅验证准确率指标，未覆盖其他数据质量指标。

---

## 343. On the Power of (Approximate) Reward Models for Inference-Time Scaling

**arXiv ID:** 2602.01381 | [PDF](https://arxiv.org/pdf/2602.01381v1)

**作者:** Youheng Zhu `[一作]` (Northwestern University), Yiping Lu `[通讯]` (Northwestern University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出并分析了在推理时对大型语言模型进行规模化的方法，聚焦于利用近似奖励模型的序贯蒙特卡罗（SMC）框架，并从理论上阐明了贝尔曼误差对推理效率的影响。

**💡 创新点**

创新点在于：① 将贝尔曼误差作为衡量奖励模型质量的核心量，并证明当误差为O(1/T)时，近似奖励模型即可实现指数级的推理复杂度下降；② 给出推理时采样的下界与上界，首次将理论与实践中的多粒子/单粒子 SMC、Metropolis‑Hastings 修正等算法连接起来；③ 提出单粒子引导 SMC 的 MH 修正方案，证明在高概率事件下实现对数级的 TV 退化。

**🔧 技术方法**

使用的技术包括：Feynman–Kac 形式的概率流、序贯蒙特卡罗采样、贝尔曼误差分析、信息理论下界证明、Metropolis–Hastings 采样、粒子滤波器的全局与局部收敛性分析。

**📊 数据集**

文中未给出具体实验数据集，主要以理论证明为主；若涉及实验，推断使用的是常见的推理/推断时任务（多步推理、逻辑推理等）。

**📈 对比分析**

方法对比：通过下界与上界的匹配，作者展示在贝尔曼误差可控的情况下，SMC 的复杂度由指数降低到多项式；与单粒子 MH 修正相比，多粒子 SMC 的 TV 误差随粒子数线性下降，而 MH 修正在高概率事件下实现对数级的收敛。

**⚠️ 局限性**

局限性：① 需要假设贝尔曼误差可被控制为 O(1/T)，实际奖励模型训练难度大；② 上下界均基于理想化的概率模型和完美的采样/评估条件；③ 文中缺乏大规模实验验证，无法直接评估在真实语言模型中的性能表现。

---

## 344. Rectified LpJEPA: Joint-Embedding Predictive Architectures with Sparse and Maximum-Entropy Representations

**arXiv ID:** 2602.01456 | [PDF](https://arxiv.org/pdf/2602.01456v1)

**作者:** Yilun Kuang `[一作]` (New York University), Yann LeCun `[通讯]` (New York University)

**通讯引用:** 242394 | [OpenAlex ID](https://openalex.org/A5001226970)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种Rectified LpJEPA框架，利用视图嵌入一致性和稀疏分布匹配来学习稀疏、非负的特征表示。

**💡 创新点**

创新点在于设计了Rectified Distribution Matching Regularization（RDMReg）和Rectified Generalized Gaussian（RGG）目标分布，既能保持最大熵，又能通过可控的ℓ0期望实现稀疏性。

**🔧 技术方法**

主要技术包括Joint‑Embedding Predictive Architectures（JEPA）、ReLU激活、Cramér–Wold投影分解、切片二维Wasserstein距离作为两样本分布匹配损失，以及对目标分布参数（μ,σ,p）的理论分析。

**📊 数据集**

实验数据集主要是ImageNet‑100和CIFAR‑100，模型在这些数据集上进行预训练并通过线性探针评估。

**📈 对比分析**

与密集基线（SimCLR、VICReg、LeJEPA）及稀疏基线（NCL、NVICReg）对比，Rectified LpJEPA在保持或略优的线性探针准确率的同时，显著提升了特征稀疏度、降低了nHSIC指标，显示出更好的稀疏–性能权衡。

**⚠️ 局限性**

局限性包括对目标分布参数的敏感性、需手动调节μ、σ、p以获得期望稀疏度，以及两样本分布匹配在高维时可能增加计算成本，尚未在更大规模数据集上全面验证。

---

## 345. CRAFT: Calibrated Reasoning with Answer-Faithful Traces via Reinforcement Learning for Multi-Hop Question Answering

**arXiv ID:** 2602.01348 | [PDF](https://arxiv.org/pdf/2602.01348v1)

**作者:** Yu Liu `[一作]` (Institute of Information Engineering Chinese Academy of Sciences), Zhiyuan Ma `[通讯]` (Huazhong University of Science and Technology)

**通讯引用:** 2185 | [OpenAlex ID](https://openalex.org/A5068733979)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于强化学习的 RAG 生成框架 CRAFT，训练模型在多跳问答中生成可审计、结构化的推理轨迹；

**💡 创新点**

创新点在于：①引入双重奖励机制（确定性奖励 + LLM 判别器奖励）实现结构完整与语义可信的同步优化；②构建可调控的 XML 轨迹模板，使模型可按需剖析计划、引用与推理；③使用 Group Relative Policy Optimization（GRPO）无需 critic 即可高效学习；

**🔧 技术方法**

技术手段包括：RAG 系统、GRPO 强化学习、XML 轨迹模板、基于大模型的“审计判别器”评估推理可信度、deterministic 规则奖励；

**📊 数据集**

实验数据集为 HotpotQA、2WikiMultiHopQA、MuSiQue 三大多跳问答基准；

**📈 对比分析**

与开源预训练模型（Qwen 系列）、API 模型（GPT、DeepSeek、Gemini）以及 SFT 进行对比。CRAFT_7B 在所有基准上均超过或逼近闭源 API 模型，且在准确率和推理可信度两项指标上均有显著提升；

**⚠️ 局限性**

局限性包括：①需要足够模型容量（小模型难以实现高可信度）；②对 LLM 判别器的依赖导致训练成本较高；③在极简轨迹（仅答案）下无法评估推理可信度；④模型对轨迹模板的严格约束可能限制表达多样性。

---

## 346. Multi-Head Attention Is a Multi-Player Game

**arXiv ID:** 2602.00861 | [PDF](https://arxiv.org/pdf/2602.00861v1)

**作者:** Kushal Chakrabarti `[一作]` (Obviously Wrong), Nirmal Balachundar `[通讯]` (South Park Commons)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文将多头注意力视作多玩家博弈，通过显式加入外部性惩罚，构建 GAME-LoRA 方法以调节头间协作与竞争，降低幻觉与冗余；

**💡 创新点**

创新点在于将 Transformer 内部的无价格外部性转化为可调节的 Pigouvian 税项，并给出 Price of Anarchy 上界与幻觉、冗余的统一理论；

**🔧 技术方法**

采用信息瓶颈、Barlow Twins 交叉协方差、对数行列式正则化以及 Nash-MTL 多任务学习框架，并在 LoRA 微调中实现；

**📊 数据集**

在 The Pile（约 20M 语料）上微调 Qwen2.5‑0.5B，评测六项幻觉基准（HaluEval、MemoTrap、TruthfulQA 等）与四项知识基准（NQ、PopQA、WikiText、Winogrande）；

**📈 对比分析**

相较于标准 CE、RLHF、Inference‑time 等对齐方法，GAME-LoRA 在幻觉准确率提升约 8%（占优 5/6 基准），且知识保持无显著下降，且不增加推理成本；

**⚠️ 局限性**

局限在于理论假设（高斯近似、对角化正则化等）与实验规模有限，且未对更大模型与更复杂任务进行系统验证。

---

## 347. UniForce: A Unified Latent Force Model for Robot Manipulation with Diverse Tactile Sensors

**arXiv ID:** 2602.01153 | [PDF](https://arxiv.org/pdf/2602.01153v1)

**作者:** Zhuo Chen `[一作]` (King's College London), Shan Luo `[通讯]` (King's College London)

**通讯引用:** 2665 | [OpenAlex ID](https://openalex.org/A5012646628)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 UniForce，利用双指准静态力平衡自监督学习跨多种触觉传感器的统一潜在力空间，并将该编码器用于零射击力估计和力感知策略迁移。

**💡 创新点**

创新点包括：① 用力平衡作为无标签对齐监督；② 在条件 VAE 中同时学习逆向（图像→力）与正向（力→图像）动力学，统一视觉与非视觉触觉为 marker 图像；③ 实现跨传感器零射击的力预测与策略迁移。

**🔧 技术方法**

核心技术包括：条件变分自编码器、时空 Transformer（因果注意力）、位置编码、交叉重建损失、力平衡一致性损失、LPIPS 与 KL 正则、以及基于机器人关节阻抗控制的准静态数据采集。

**📊 数据集**

使用自建 UniForce‑pair 数据集（GelSight–TacTip、uSkin–TacTip 共 16,000 帧）和 GenForce‑Hetero 力标注数据集用于评估；此外在擦拭任务中收集 50 条轨迹。

**📈 对比分析**

与 AnyTouch、T3、UniT、ResNet 等预训练编码器以及全训模型对比；零射击力估计中 R² ≈ 0.6–0.8、MAE 0.2–1.0 N，显著优于基线；擦拭任务成功率从 20% 提升至 80%，证明零射击迁移有效。

**⚠️ 局限性**

局限性：① 依赖准静态力平衡，运动快或出现滑移时性能下降；② 未显式建模材料弹性与历史效应；③ 仅适用于可转换为 2D marker 图像的传感器；④ 简单特征拼接，未充分利用多模态融合。

---

## 348. Q-DiT4SR: Exploration of Detail-Preserving Diffusion Transformer Quantization for Real-World Image Super-Resolution

**arXiv ID:** 2602.01273 | [PDF](https://arxiv.org/pdf/2602.01273v1)

**作者:** Xun Zhang `[一作]` (Shanghai Jiao Tong University), Yulun Zhang `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 22300 | [OpenAlex ID](https://openalex.org/A5074865219)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了针对Diffusion Transformer（DiT）在真实图像超分（Real-ISR）任务中的后训练量化（PTQ）框架Q-DiT4SR，能够在极低位宽（如W4A4）下保持高质量纹理和细节。

**💡 创新点**

创新点包括：1) 层次SVD（H‑SVD）融合全局低秩分支和局部块级rank‑1分支，实现在固定参数预算下的高精度权重量化；2) 变异量感知空间混合精度（VaSMP）在无校准数据下依据权重方差分配跨层位宽；3) 变异量感知时间混合精度（VaTMP）在扩散步长上动态分配激活位宽，减少累积误差。

**🔧 技术方法**

技术手段包括Hadamard变换对权重/激活做正态化、SVD分解与重构、均匀量化、基于方差的高斯误差模型、动态规划时间调度以及数据无关的统计分析。

**📊 数据集**

使用RealSR、DrealSR、RealLR200、RealLQ250四个真实世界超分基准数据集进行训练与评估，校准集采用RealSR训练集的32张低分辨率图像。

**📈 对比分析**

与SVDQuant、QuaRot、FlatQuant、Q‑DiT、PTQ4DiT、Q‑Diffusion、EfficientDM、PassionSR、QueST等多种PTQ与训练方法对比，Q‑DiT4SR在W4A6和W4A4配置下在LPIPS、MUSIQ、MANIQA、CLIP‑IQA、LIQE等多项指标上均达到或超过SOTA，且在W4A4下模型尺寸缩减5.8×、算力降低60×。

**⚠️ 局限性**

局限性包括：1) 对极端低位宽（低于4位）效果尚未验证；2) 对不同DiT变体的泛化需进一步评估；3) 仍需一定量化校准数据（尤其是激活时间调度）；4) 在极高分辨率图像或特殊噪声环境下的鲁棒性尚待考察。

---

## 349. MedBeads: An Agent-Native, Immutable Data Substrate for Trustworthy Medical AI

**arXiv ID:** 2602.01086 | [PDF](https://arxiv.org/pdf/2602.01086v1)

**作者:** Takahito Nakajima `[一作]` (University of Tsukuba), Takahito Nakajima `[通讯]` (University of Tsukuba)

**通讯引用:** 5758 | [OpenAlex ID](https://openalex.org/A5045907415)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `67630363-6be0-4f51-ab05-7198250671a5` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

提出并实现了 MedBeads——一种以 Merkle DAG 为核心的、可向 LLM 递送不可篡改、因果链接清晰的医学记录数据基础设施，并通过 Go、Python、React 构建了完整原型。

**💡 创新点**

创新点在于用可验证的 Merkle DAG 替代传统 FHIR 资源，提供确定性图遍历获取上下文、数字签名与父链保证不可篡改，并将结构化 Bead 视作 AI‑本土化的 token‑高效语言，彻底拆分数据与推理职责，显著降低 hallucination 与提升审计可追溯性。

**🔧 技术方法**

核心技术包括内容寻址存储（CAS）+ SQLite 索引、BFS/DFS 递归遍历、SHA‑256 哈希+数字签名、DID 认证、角色基准访问控制、FHIR‑>Bead 的映射桥接以及与 Gemini/LLM 的标准化上下文注入接口。

**📊 数据集**

实验使用合成患者数据集 Synthea 生成的 FHIR Bundle 进行迁移与验证，构建完整的 DAG 并演示实时推理场景。

**📈 对比分析**

相比基于向量检索的 RAG，MedBeads 的上下文检索在时间复杂度 O(V+E) 下实现确定性、因果完整性，理论延迟极低、token 需求显著下降，并通过实验验证在小型数据集上可实现毫秒级实时决策支持；但尚未进行大规模 LLM 评估与跨机构合并实验。

**⚠️ 局限性**

局限性包括：需要人工或 AI 辅助推断 FHIR 中缺失的因果链接、不可删除的 immutability 使错误更正需附加“纠正”Bead、尚缺乏真实临床数据验证、跨机构 DAG 合并与治理机制待完善、以及缺少量化的 LLM 性能与误报率评估。

---

## 350. PolyGen: Fully Synthetic Vision-Language Training via Multi-Generator Ensembles

**arXiv ID:** 2602.01370 | [PDF](https://arxiv.org/pdf/2602.01370v1)

**作者:** Leonardo Brusini `[一作]` (Politecnico di Milano), Matteo Matteucci `[通讯]` (Politecnico di Milano)

**通讯引用:** 6834 | [OpenAlex ID](https://openalex.org/A5003932703)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

PolyGen框架通过多种生成器对同一文本生成多样化图像并使用程序化硬负样本课程训练，提升了视觉语言模型在合成数据上的性能

**💡 创新点**

创新点在于将生成器多样性与多正样本以及硬负样本相结合，形成生成器不变性假设，并通过线性调度的硬负样本实现细粒度语义区分

**🔧 技术方法**

采用多模型扩散器（Stable Diffusion v1.5/v2、SDXL‑Turbo、SANA）与LLM（Mistral‑V0.2/ Llama‑3.1）生成文本，使用CLIP自监督对比学习、TripletCLIP、Image‑to‑Image正则化等技术

**📊 数据集**

训练基于CC3M文本的500k对生成图像，评估数据集包括ImageNet、CIFAR10/100、FGVC Aircraft、Oxford Flowers、SUN397、Flickr8k/30k、MS COCO、SugarCrepe/SugarCrepe++等

**📈 对比分析**

与单源SynthCLIP基线比较，PolyGen在Δ_MTL指标上提升约19%，在SugarCrepe++语义组合任务提升约9%，同时在零样本检索、线性探测等任务上均有显著提升

**⚠️ 局限性**

局限在于多生成器管线复杂度较高、需要对生成质量与多样性平衡进行手工调节、合成数据仍受生成器偏差影响、当前仅在中等规模数据上验证，未在更大规模或更丰富语义轴上测试

---

## 351. SAGE: Agentic Framework for Interpretable and Clinically Translatable Computational Pathology Biomarker Discovery

**arXiv ID:** 2602.00953 | [PDF](https://arxiv.org/pdf/2602.00953v1)

**作者:** Sahar Almahfouz Nasser `[一作]` (Emory University), Anant Madabhushi `[通讯]` (Emory University)

**通讯引用:** 36345 | [OpenAlex ID](https://openalex.org/A5027642699)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

SAGE是一套结构化的智能体系统，能够从医学文献构建知识图谱，生成并评估可解释、可验证的病理生物标志物假设，并自动执行统计验证；

**💡 创新点**

其创新点在于：①将生物学语义与图谱推理相结合，保证假设有科学依据；②采用多代理争论式评判机制提升创新度校准；③采用验证优先的执行链实现从假设到可重复实验的闭环；

**🔧 技术方法**

使用技术包括：大语言模型（LLM）驱动的多代理推理、知识图谱构建与融合、语义归一化与实体对齐、代码生成与沙箱执行、争论式多评判器、医学领域专属工具编排；

**📊 数据集**

主要数据集为：1) 文献语料（约1650篇，涵盖膀胱癌与计算病理文献）用于知识图谱；2) TCGA‑BLCA公开转录组与病理影像数据；3) 机构内部患者队列与临床指标；

**📈 对比分析**

与单一LLM、Agent‑Flow等基线比较，SAGE在创新度得分和专家一致性略高，引用文献量更少，计算成本下降25‑75%，且通过多评判辩论显著提升创新度区分度；

**⚠️ 局限性**

局限性包括：仍依赖手工筛选与专业词库，可能存在文献偏倚；验证过程对可用工具与数据的依赖较高；系统对极端或缺失数据的鲁棒性有限，且需要人工专家介入确认最终结论。

---

## 352. LightCity: An Urban Dataset for Outdoor Inverse Rendering and Reconstruction under Multi-illumination Conditions

**arXiv ID:** 2602.01118 | [PDF](https://arxiv.org/pdf/2602.01118v1)

**作者:** Jingjing Wang `[一作]` (State Key Lab of CAD and CG), Guofeng Zhang `[通讯]` (State Key Lab of CAD and CG)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `67630363-6be0-4f51-ab05-7198250671a5` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `25d64835-ec5b-425b-899d-a6e1e6fecabd` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个高质量合成城市数据集 LightCity，并在该数据集上基准了三大核心任务：图像本质分解、逆渲染和多视角城市重建，评估了现有主流方法的表现。

**💡 创新点**

创新点：① 300+ HDRI 天空图覆盖完整昼夜周期，支持可控光照与真实间接光影；② 覆盖街景与空中视角，尺度多样；③ 提供深度、法线、材质、光照等多种属性，为本质分解、逆渲染与重建提供统一且丰富的标注；④ 采用统一圆形/网格采样与 COLMAP 过滤保证视角覆盖与相机重定位。

**🔧 技术方法**

技术手段：Blender Cycles PBR 渲染、HDRI 天空模型、光照随机旋转与强度调节、统一视角采样、COLMAP 相机重定位、SOTA 方法（IntrinsicAny、CDID、PIE-Net、DMP、DPF、NeRF‑OSR、GS‑IR、NeRF‑W、Wild‑Gaussian、Gaussian‑Wild、NexusSplats 等）进行实验。

**📊 数据集**

使用数据集：LightCity（synthetic urban scene with multi‑illumination）。

**📈 对比分析**

比较与性能：
- 本质分解：SOTA 方法在 LightCity 上表现不足；DMP fine‑tuned on LightCity 达到最高 si‑PSNR；
- 逆渲染：NeRF‑OSR 在多光照下平均 PSNR 较高，但 GS‑IR 在 SSIM/LPIPS 上更优；
- 重建：NeRF‑W 在简单块（F2、F3）PSNR 最高；Gaussian‑Wild 在复杂块（E1、E2）SSIM/LPIPS 更佳；多光照训练后各方法仍难以泛化至未见光照。

**⚠️ 局限性**

局限性：① 仅为合成数据，缺乏真实世界验证；② 尽管光照多样，但仍受合成约束；③ 现有方法对间接光与阴影的分离仍不完善，导致结果不稳定；④ 对更大规模城市、动态光照的适应性不足。

---

## 353. Tangent Space Fine-Tuning for Directional Preference Alignment in Large Language Models

**arXiv ID:** 2602.01128 | [PDF](https://arxiv.org/pdf/2602.01128v1)

**作者:** Mete Erdogan `[一作]` (Stanford University), Mete Erdogan `[通讯]` (Stanford University)

**通讯引用:** 1738 | [OpenAlex ID](https://openalex.org/A5104002007)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了切线空间直接偏好优化（TS-DPO），通过在预训练模型的切线空间学习可线性组合的偏好更新向量，实现多目标偏好对齐并在推理时实现可控行为。

**💡 创新点**

创新点在于将直接偏好优化（DPO）迁移到模型的切线空间，学习独立且可组合的偏好方向，避免将多目标压缩为单一标量奖励；并通过 Canonical Correlation Analysis 验证更新向量在表示空间中保持解耦。

**🔧 技术方法**

技术包括：直接偏好优化（DPO）、模型切线空间线性化与 Jacobian‑Vector Product（JVP）、偏好方向的向量化学习、参数混合（α·τ_help + β·τ_verbose）、奖励模型评估以及 Canonical Correlation Analysis。

**📊 数据集**

使用的公开数据集为 HelpSteer2（verbosity 方向）和 UltraFeedback（helpfulness 方向），以及基于这两者训练的多目标奖励模型。

**📈 对比分析**

与标量化 DPO（DPO‑Mixed）和任务向量 DPO（Task‑Vector DPO）进行比较，采用 Pareto 前沿、对比准确率与奖励模型评分等指标。结果显示 TS‑DPO 在帮助性与冗长度的权衡上覆盖更广、控制更平滑，性能优于两种基线。

**⚠️ 局限性**

局限性包括：训练时每步需要 JVP，导致计算开销增加；未在更大模型或更多偏好维度上验证；与 DPA 等更先进的多目标对齐方法缺乏直接对比；在极端混合比例下仍难以完全覆盖完整 Pareto 前沿。

---

## 354. TriphiBot: A Triphibious Robot Combining FOC-based Propulsion with Eccentric Design

**arXiv ID:** 2602.01385 | [PDF](https://arxiv.org/pdf/2602.01385v1)

**作者:** Xiangyu Li `[一作]` (Zhejiang University), Yanjun Cao `[通讯]` (Zhejiang University)

**通讯引用:** 1203 | [OpenAlex ID](https://openalex.org/A5046852793)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `51c0528b-f690-4182-ae60-bb5f046c276c`

**🎯 论文内容**

本论文设计并实现了一款既能飞行、陆地行走，又能水下游动的三域机器人 TriphiBot。

**💡 创新点**

创新点包括：①采用偏心重心设计，使推进力自然与地面运动对齐，从而在陆地/水底模式下实现高效无附加驱动；②采用统一的FOC（场定向控制）电机驱动，能够在空气、陆地和水中实现高速、低速双向扭矩匹配；③构建了混合非线性模型预测控制+PID的跨域控制框架，实现从空中、陆地到水下的无缝切换。

**🔧 技术方法**

所用技术主要有：四旋翼框架+被动轮、偏心重心布局、FOC电机驱动（VESC+编码器+STM32）、模型预测控制（HNMPC）、PID闭环、CAN总线通信、运动捕捉定位。

**📊 数据集**

实验数据集主要来自实验平台的力传感器、编码器反馈以及NOKOV运动捕捉系统采集的轨迹与姿态数据，未使用公开的标准数据集。

**📈 对比分析**

与传统ESC、TJ‑FlyingFish 以及其他双域/三域机器人（如Wukong、Lai 等）对比，FOC 驱动在水下实现了最高 0.898 N/W 的比功率，功耗比 ESC 低 5 倍；轨迹跟踪 RMSE 分别为 0.096 m（空中）和 0.074 m（陆地），水下姿态跟踪误差 31°、相位滞后 0.17 s，均优于对比方法。

**⚠️ 局限性**

局限性在于实验仍在受限的室内/水槽环境中，未考虑真实水流扰动和复杂陆地地形；跨域控制策略在极端环境下的鲁棒性和能耗优化仍待进一步研究。

---

## 355. PandaPose: 3D Human Pose Lifting from a Single Image via Propagating 2D Pose Prior to 3D Anchor Space

**arXiv ID:** 2602.01095 | [PDF](https://arxiv.org/pdf/2602.01095v1)

**作者:** Jinghong Zheng `[一作]` (Huazhong University of Science and Technology), Joey Tianyi Zhou `[通讯]` (Agency for Science Technology and Research)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种从单张RGB图像中进行3D人体姿态提升的方法——PandaPose，通过将2D姿态先验传播到3D锚点空间，实现统一的中间表示并最终得到3D关节位置。

**💡 创新点**

核心创新点包括：①基于每个关节的3D锚点的自适应生成，提升对2D姿态误差的鲁棒性；②引入关节级深度分布估计与深度感知特征提升，解决自遮挡和深度歧义；③设计锚点-特征交互解码器，融合锚点、视觉特征与深度信息，并通过锚点-关节集成预测得到最终3D姿态；④利用2D姿态先验进行特征采样，减少背景噪声并降低计算成本。

**🔧 技术方法**

技术实现采用HRNet‑w32作为视觉特征提取器，2D姿态估计器提供输入；使用Transformer解码器，包含深度交叉注意力、锚点间自注意力和3D可变形交叉注意力；深度分支采用轻量级分类头预测每个关节的深度分布；锚点查询通过学习获得并与特征交互后得到最终的3D关节位置。

**📊 数据集**

实验使用Human3.6M、MPI‑INF‑3DHP和3DPW数据集；在Human3.6M上进行跨姿态/跨子集评估，在MPI‑INF‑3DHP上评估精度，在3DPW上进行跨数据集泛化测试。

**📈 对比分析**

与现有单帧图像基方法及序列基方法对比，PandaPose在Human3.6M完整测试集上MPJPE降至39.8 mm（比SOTA 41.4 mm低1.6 mm，PA‑MPJPE 0.8 mm），在挑战子集MPJPE降至73.1 mm（比SOTA 78.2 mm低5.1 mm）；MPI‑INF‑3DHP上MPJPE 74.9 mm，PA‑MPJPE 46.9 mm；3DPW跨数据集评估MPJPE 32.7 mm，PA‑MPJPE 31.8 mm，均超过同类图像基方法，显示出更好的鲁棒性与泛化能力。

**⚠️ 局限性**

主要局限包括：仅使用单帧输入，未利用时序信息；对2D姿态估计的质量仍有一定依赖；在极端遮挡或极大深度差异场景下可能仍存在误差；实现相对复杂，计算成本相对较高。

---

## 356. TRACE: Scalable Amortized Causal Discovery from Single Sequences via Autoregressive Density Estimation

**arXiv ID:** 2602.01135 | [PDF](https://arxiv.org/pdf/2602.01135v1)

**作者:** Hugo Math `[一作]` (University of Augsburg), Rainer Lienhart `[通讯]` (University of Augsburg)

**通讯引用:** 9603 | [OpenAlex ID](https://openalex.org/A5009744749)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c773407a-6119-4871-b8b3-1e7ae17a6851` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

开发 TRACE 框架，实现单条事件序列的因果结构发现，利用预训练自回归模型估计条件互信息。

**💡 创新点**

创新点：将自回归密度估计器转化为因果引擎；在 GPU 上实现 CMI 并行计算；对词表规模 >1000 的事件序列实现线性可扩展；在非完美模型下仍可辨识因果结构。

**🔧 技术方法**

技术：自回归语言模型（Transformer/MLP 等）作为密度估计器；条件互信息、模拟干预、蒙特卡罗估计；稀疏变体与 GPU 并行操作。

**📊 数据集**

数据集：合成线性结构因果模型（可调词表、序列长度、记忆）；实际车辆诊断日志（约 29,100 种事件）。

**📈 对比分析**

比较：对 Neural Granger、Attention、Saliency、Shapley、随机与频率基线等进行对照；在合成实验中 F1≈0.91、SHD≈28；在高维词表上 F1≈0.81；在车辆日志中能准确定位故障链，性能明显优于传统方法（提升 20+ F1 分）。

**⚠️ 局限性**

局限：依赖因果充分性与时间先验，无法处理隐藏混杂者；对预训练 AR 模型的精度敏感；对极长序列仍需稀疏化导致召回下降；实际应用需专家验证。

---

## 357. Understanding QA generation: Extracting Parametric and Contextual Knowledge with CQA for Low Resource Bangla Language

**arXiv ID:** 2602.01451 | [PDF](https://arxiv.org/pdf/2602.01451v1)

**作者:** Umme Abira Azmary `[一作]` (BRAC University), Farig Yousuf Sadeque `[通讯]` (BRAC University)

**通讯引用:** 338 | [OpenAlex ID](https://openalex.org/A5009105388)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文创建了 BanglaCQA（第一份孟加拉语反事实问答数据集），并对比评估了多种 encoder‑decoder 与 decoder‑only 语言模型在事实与反事实问答中对参数化知识与上下文知识的利用。

**💡 创新点**

创新点在于（1）通过 NER 生成的实体替换构造反事实文本，实现对模型知识来源的拆分；（2）首次使用单一评估框架（Gemini‑2.0 Flash 与 GPT‑4.1 语义相似度）与人工评测双重验证低资源语言的 QA 性能；（3）证明 Chain‑of‑Thought（CoT）提示在孟加拉语反事实情境下显著提升参数化推理能力。

**🔧 技术方法**

技术包括：NER‑based 反事实生成；BanglaT5（small、base）和 mT5 的微调；Qwen‑2.5、DeepSeek‑R1、Mistral‑3‑small、LLaMA‑3.3 等 decoder‑only LLM 的 few‑shot 与 CoT 提示；Gemini‑2.0 Flash 与 GPT‑4.1 的语义相似度评估；双人人工评测。

**📊 数据集**

使用的数据集为 BanglaRQA 扩展得到的 BanglaCQA，包含 21,211 个问答对，其中 14,900 为事实上下文、6,303 为反事实上下文。

**📈 对比分析**

评价方法为：对模型生成答案与目标答案计算 Gemini‑2.0 Flash / GPT‑4.1 的语义相似度，并以人类评测对照；实验显示 encoder‑decoder 在参数化相似度上表现不佳（<0.3），而 CoT 提示可将参数化相似度提升至约 0.8‑0.9；Qwen‑2.5 在两类情境下均达成 0.9 以上的上下文相似度，成为最优模型。

**⚠️ 局限性**

局限性包括：仅采用单一参考答案导致合法多答案被误判；时间敏感实体的静态参考导致模型生成更准答案被误差；量化权重的 decoder‑only 模型可能低估真实性能；只探讨了 few‑shot 与 CoT 提示，未覆盖其它提示或微调策略。

---

## 358. The Gradient-Causal Gap: Why Gradient Importance Fails on Complex Tasks

**arXiv ID:** 2602.01442 | [PDF](https://arxiv.org/pdf/2602.01442v1)

**作者:** Donald Ye `[一作]` `[通讯]` (Independent Researcher), Donald Ye (Independent Researcher)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

在Transformer上研究梯度重要性与因果重要性之间的差距，提出并量化Gradient‑Causal Gap，并通过剪枝实验验证高梯度“Gradient Bloats”和低梯度“Hidden Heroes”对OOV泛化的影响。

**💡 创新点**

首次系统定义并测量梯度与因果重要性的不一致性，揭示梯度大小并非泛化能力的可靠指标，并指出隐藏英雄与梯度肥大在不同层的分布及其对模型压缩的风险。

**🔧 技术方法**

使用梯度范数、均值消融、Spearman相关、层级分析和针对性剪枝等技术，对Transformer的注意力头和MLP子层进行重要性评估与干预。

**📊 数据集**

在两类算法任务（序列反转Reversal和序列排序Sorting）上进行实验，输入为1–99整数的序列。

**📈 对比分析**

通过Spearman相关量化梯度与因果重要性的对齐程度：Reversal ρ≈0.73，Sorting ρ≈0.32；剪枝隐藏英雄导致OOV准确率平均下降32%，而剪枝梯度肥大效果不稳定，部分种子可提升3.5%。

**⚠️ 局限性**

实验仅在4层4头Transformer和纯算法任务上完成，缺乏对大规模或自然语言任务的验证；消融方法仅采用均值消融，可能影响因果重要性评估。

---

## 359. White-Box Neural Ensemble for Vehicular Plasticity: Quantifying the Efficiency Cost of Symbolic Auditability in Adaptive NMPC

**arXiv ID:** 2602.01516 | [PDF](https://arxiv.org/pdf/2602.01516v1)

**作者:** Enzo Nicolas Spotorno `[一作]`, Antonio Augusto Medeiros Frohlich `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `afceb026-1760-41ae-8d86-010831a37d97` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出一种白盒自适应NMPC架构，通过在符号图中组合冻结的专家网络实现车辆动态的零样本自适应。

**💡 创新点**

创新点在于将混合专家与优化门控结合，保持模型可追溯性的同时通过符号图实现最大可审计性，并量化了透明度带来的效率代价。

**🔧 技术方法**

使用了CasADi SX的符号图、混合专家（PINN）网络、离散优化求解器IPOPT、EMA平滑和多阶段训练（Adam+L-BFGS）等技术。

**📊 数据集**

数据集为混合合成数据，包括均匀状态空间采样与激励“chirp”轨迹，用以训练不同摩擦、质量、阻力等操作域的专家。

**📈 对比分析**

与已编译的参数化物理模型对比，符号专家网络的求解延迟约为原来的72–102倍，但自适应延迟仅约7.3 ms，能在摩擦、质量、阻力突变时保持接近理想跟踪误差。

**⚠️ 局限性**

主要限制是显著的运行时开销（导致非实时部署）、对专家库覆盖范围的依赖、缺乏形式化稳定性保证，以及专家网络的语义可解释性不足。

---

## 360. Governance at the Edge of Architecture: Regulating NeuroAI and Neuromorphic Systems

**arXiv ID:** 2602.01503 | [PDF](https://arxiv.org/pdf/2602.01503v1)

**作者:** Afifah Kashif `[一作]` (University of Cambridge), Asim Iqbal `[通讯]` (Cornell University)

**通讯引用:** 312 | [OpenAlex ID](https://openalex.org/A5083371732)

**关键词:** `7a50eb32-3dbc-4c3e-a038-bda01b2d9965` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文评估了现行AI治理框架在神经形态NeuroAI系统上的适用性，揭示监管缺口，并提出针对事件驱动、能耗和在线学习的新治理指标与建议。

**💡 创新点**

创新点在于把传统基于FLOPs、可审计权重和数据集完整性的治理假设迁移到神经形态架构，并引入能耗/推理耗时、权重变更比率等量化指标；同时将NeuroBench等跨平台基准与治理框架结合，形成系统化的评估与监管路径。

**🔧 技术方法**

采用事件驱动的脉冲神经网络（SNN）、神经形态芯片（如Loihi、TrueNorth、NorthPole等）、能耗测量、权重变更率监测以及NeuroBench标准化任务套件。

**📊 数据集**

使用的主要数据集包括传统图像分类数据集MNIST、CIFAR‑10；事件驱动视觉数据集DVS Gesture、N‑Caltech101；以及用于大型语言模型推理对比的Granite‑8B等。

**📈 对比分析**

方法上通过NeuroBench对任务、模型和平台层级进行统一评测，量化准确率、能耗/推理耗时等；举例NorthPole芯片相较于NVIDIA H100在相同推理精度下，能效提升约72.7倍、延迟降低约2.5倍。

**⚠️ 局限性**

局限性包括：只聚焦少数治理框架，未覆盖不同文化与行业特定法规；对动态学习、持续在线更新的可解释性与审计机制仍缺乏实用手段；数据集与模型可追踪性在持续学习场景下难以实现。

---

## 361. Draw2Learn: A Human-AI Collaborative Tool for Drawing-Based Science Learning

**arXiv ID:** 2602.01494 | [PDF](https://arxiv.org/pdf/2602.01494v1)

**作者:** Yuqi Hang `[一作]` (New York University), Yuqi Hang `[通讯]` (New York University)

**通讯引用:** 24 | [OpenAlex ID](https://openalex.org/A5014458554)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

开发了Draw2Learn系统，利用AI作为协作伙伴支持绘画式学习。

**💡 创新点**

创新点在于将学习理论转化为“任务探险、可选支架、维度化反馈”的团队式AI交互模式。

**🔧 技术方法**

采用视觉-语言模型进行图像理解与反馈、任务生成与风格迁移技术。

**📊 数据集**

未使用公开数据集，主要依赖人工绘图与交互数据。

**📈 对比分析**

通过六名用户的使用感知问卷和定性访谈评估，平均满意度5.47/7，表明设计符合预期。

**⚠️ 局限性**

样本规模小、未测量学习成效、缺乏真实课堂验证，需进一步实验。

---

## 362. Predicting and improving test-time scaling laws via reward tail-guided search

**arXiv ID:** 2602.01485 | [PDF](https://arxiv.org/pdf/2602.01485v1)

**作者:** Muheng Li `[一作]` (University of Toronto), Wenlong Mou `[通讯]` (University of Toronto)

**通讯引用:** 448 | [OpenAlex ID](https://openalex.org/A5006742082)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出通过尾部分布外推来预测LLM的最佳- N 取样的缩放律，并基于此预测结果设计了 Scaling‑Law Guided（SLG）搜索算法，用于在测试时动态分配计算资源以提升推理质量。

**💡 创新点**

创新点在于：①将奖励分布的高尾行为建模为截断高斯分布，从而实现对大样本量下最大奖励的精确外推；②利用该预测器构造自适应搜索策略 SLG，理论证明其相较于完美信息下的 Oracle 具有消失的遗憾，并相较于传统 Best‑of‑N 在相同预算下实现可观的奖励提升；③提供了严谨的非渐进误差界与样本效率放大证明。

**🔧 技术方法**

主要技术包括：截断高斯尾部参数的矩估计（Method of Moments）、尾部外推法预测最大奖励、基于预测的两阶段搜索算法（探索–利用），以及对 SLG 的理论分析（误差界、遗憾分析、相对 Best‑of‑N 的收益下界）。

**📊 数据集**

实验数据集涵盖三套数学推理基准：AMC 2023（40题）、AIME 2024（30题）和 AIME 2025（30题），使用 1B 与 7B 两种规模的 LLM（如 Qwen‑7B、Llama‑1B 等），并采用 Qwen‑ORM 作为奖励模型。

**📈 对比分析**

与 Best‑of‑N 的比较采用相同计算预算下的累计奖励（总分）进行评估。结果显示 SLG 在所有模型、预算与数据集上均优于 Best‑of‑N；在 7B 模型下，SLG 用一半预算即可达到或超过 Best‑of‑N 的峰值奖励，验证了其样本效率提升。

**⚠️ 局限性**

局限性包括：①尾部假设仅在截断高斯尾部成立，若奖励分布尾部偏离此假设，预测误差可能增大；② SLG 的参数选择（α、m、K）需经验调优，尽管作者给出通用建议；③方法目前仅针对两阶段生成结构，尚未推广到更深层次或递归搜索（如 MCTS）场景；④对奖励模型的依赖性未完全消除，若奖励模型误差较大，外推与搜索效果可能受损。

---

## 363. ConPress: Learning Efficient Reasoning from Multi-Question Contextual Pressure

**arXiv ID:** 2602.01472 | [PDF](https://arxiv.org/pdf/2602.01472v1)

**作者:** Jie Deng `[一作]` (Microsoft), Yutao Xie `[通讯]` (Microsoft)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并验证了多问题上下文压迫下大规模推理模型（LRM）自然产生自我压缩（self‑compression）的现象，并通过ConPress框架实现无监督的推理压缩。

**💡 创新点**

创新点在于：①首次发现多问题提示能在推理时自动压缩链式思考（CoT）长度；②设计了ConPress的轻量级自监督微调流程，利用自我压缩输出直接迁移至单问题推理，省去外部教师、剪枝或强化学习的需求。

**🔧 技术方法**

核心技术包括多问题采样、答案正确性过滤、标准负对数似然（NLL）监督微调，以及上下文拼接和多任务训练策略。

**📊 数据集**

实验数据集涵盖数学与推理任务：MATH、AIME、GSM8K、OlympiadBench、AMC 以及 MMLU‑STEM（用于跨领域验证）。

**📈 对比分析**

与RFTshortest、DPOshortest、RL‑based 方法（ThinkPrune、LC‑R1、AdaptThink）进行对比；在 8k 训练样本下，ConPress 在保持 0.1–0.6 级准确率损失的同时，将推理 Token 使用率平均降低 30–60%，并在不同模型规模和任务上保持竞争性。

**⚠️ 局限性**

局限性包括：①压缩效果随问题难度递减，极难题压缩受限且可能出现精度下降；②需要生成多问题提示并过滤错误答案，采样成本相对较高；③在非数学推理任务中效果尚需进一步验证。

---

## 364. SentiFuse: Deep Multi-model Fusion Framework for Robust Sentiment Extraction

**arXiv ID:** 2602.01447 | [PDF](https://arxiv.org/pdf/2602.01447v1)

**作者:** Hieu Minh Duong `[一作]` (University of Louisville), Long Nguyen `[通讯]` (University of Louisville)

**通讯引用:** 39559 | [OpenAlex ID](https://openalex.org/A5001230244)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了SentiFuse框架，对不同类型的情感分析模型进行标准化并融合。

**💡 创新点**

统一的标准化层和多种融合策略（决策级、特征级、适应级），实现模型无关、系统化融合。

**🔧 技术方法**

词典模型、统计机器学习、BERT/RoBERTa深度编码、标准化层、加权融合、元分类器等技术。

**📊 数据集**

Crowdflower、GoEmotions、Sentiment140三大社交媒体情感数据集。

**📈 对比分析**

与单模型、简单平均、加权平均、投票等基线对比，特征级融合在三数据集上平均提升约4% F1，整体显著优于基线。

**⚠️ 局限性**

推理时需运行多模型，增加额外成本；准确率仍约80%，受噪声文本限制；仅在英文社交媒体验证，缺乏多语言与领域推广。

---

## 365. TQL: Scaling Q-Functions with Transformers by Preventing Attention Collapse

**arXiv ID:** 2602.01439 | [PDF](https://arxiv.org/pdf/2602.01439v1)

**作者:** Perry Dong `[一作]` (Stanford), Chelsea Finn `[通讯]` (Stanford)

**通讯引用:** 25795 | [OpenAlex ID](https://openalex.org/A5005431772)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

研究如何通过控制Transformer注意力熵来实现大规模价值函数训练，提出Transformer Q‑Learning框架；

**💡 创新点**

创新点是引入可学习的温度参数对每层和特殊令牌的注意力熵进行目标化调节，避免注意力崩塌，并加入可学习模态嵌入提升表达能力；

**🔧 技术方法**

使用技术包括Transformer结构、熵正则化、可学习温度、模态嵌入、流政策提取以及离线强化学习训练；

**📊 数据集**

数据集为OGBench的25个连续控制任务（5个领域×5个任务）；

**📈 对比分析**

与9种离线RL基线（BC、IQL、ReBRAC、FBRAC、IFQL、FQL、floq、Q‑Transformer、PAC）进行对比，TQL在25个任务中平均性能最高，单体最大小模型提升约43%；

**⚠️ 局限性**

局限性在于需要额外的熵目标超参数和温度项，增加了调参复杂度，且目前仅在离线RL场景验证，在线RL的适用性尚未探索。

---

## 366. Causal Preference Elicitation

**arXiv ID:** 2602.01483 | [PDF](https://arxiv.org/pdf/2602.01483v1)

**作者:** Edwin V. Bonilla `[一作]` (CSIRO), Daniel M. Steinberg `[通讯]` (CSIRO)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了 CaPE 框架，通过贝叶斯主动学习主动询问专家关于局部边关系的噪声判断，更新 DAG 后验并加速收敛。

**💡 创新点**

创新点在于将专家偏好建模为三分类的层次逻辑回归，将期望信息增益（EIG）作为查询策略，并结合粒子滤波、重采样与 MH 复兴实现可扩展的 DAG 后验更新。

**🔧 技术方法**

使用技术包括贝叶斯后验更新、粒子滤波（importance 重权、ESS 触发重采样、轻量级 Metropolis–Hastings 复兴）、层次式逻辑专家模型、BALD 风格的期望信息增益量化以及主动查询策略。

**📊 数据集**

实验数据集包括合成 Erdős–Rényi DAG、Sachs 蛋白质信号网络（观测子集）以及 CausalBench K562 基因扰动数据。

**📈 对比分析**

与随机、基于不确定度的采样、一次性信息增益和 GFlowNet 先验等基线相比，CaPE 在信息熵、SHD、AUPRC 等指标上均显著优于基线，并在有限查询预算下显著加速后验收敛。

**⚠️ 局限性**

局限性包括对专家标签可靠性的依赖、未考虑多专家冲突与认知负荷，以及当前仅适用于无潜在变量、无循环的 DAG 结构。

---

## 367. You Need an Encoder for Native Position-Independent Caching

**arXiv ID:** 2602.01519 | [PDF](https://arxiv.org/pdf/2602.01519v1)

**作者:** Shiju Zhao `[一作]` (Nanjing University), Guihai Chen `[通讯]` (Nanjing University)

**通讯引用:** 17789 | [OpenAlex ID](https://openalex.org/A5100428808)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在解码器专用的大语言模型中重新引入编码器，并仅训练编码器以实现位置无关缓存（PIC），同时构建了可与现有推理框架无缝集成的PIC缓存系统。

**💡 创新点**

创新点在于：① 将编码器与解码器以交错的 comb‑style 结构嵌入，形成天然的 PIC 支持；② 仅训练编码器参数，保持解码器不变，提供插件式灵活性；③ 通过 PICAware 缓存系统实现高效的缓存管理，显著降低首 token 延迟和显存占用。

**🔧 技术方法**

使用技术包括 Transformer 的 encoder‑decoder 交叉注意力、K/V 缓存管理、vLLM 与 HuggingFace 的推理框架集成、交叉熵训练、GPU 并行训练等。

**📊 数据集**

训练数据集：SQuAD、Natural‑Instructions、XSum、Super‑Natural‑Instructions；评测数据集：LongBench 的 2WikiMQA、HotpotQA、MuSiQue、SAMSum 与 MultiNews。

**📈 对比分析**

与 Prefix 缓存、CacheBlend、EPIC、BlockAttention 等方法对比，实验表明：① 在所有评测数据集上保持甚至超越原模型精度；② 在缓存命中时 TTFT 降低 51‑94%，吞吐率提升 3×；③ KV 缓存占用减少约 75‑78%。

**⚠️ 局限性**

局限性包括：① 需要额外的编码器参数与训练成本；② 目前仅在 Llama‑3.1‑8B‑Instruct 与 DeepSeek‑V2‑Lite‑Chat 上验证；③ 对不同任务的迁移鲁棒性与灾难性遗忘仍需进一步评估；④ 对极长上下文的极限性能未作全面测评。

---

## 368. Qrita: High-performance Top-k and Top-p Algorithm for GPUs using Pivot-based Truncation and Selection

**arXiv ID:** 2602.01518 | [PDF](https://arxiv.org/pdf/2602.01518v1)

**作者:** Jongseok Park `[一作]` (University of California Berkeley), Ion Stoica `[通讯]` (University of California Berkeley)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

针对大型语言模型（LLM）解码过程中的 top‑k / top‑p 截断操作，提出了一种基于枢轴搜索的高性能 GPU 算法，并实现了完整的 Triton 程序。

**💡 创新点**

创新点包括：
- 使用高斯 σ 截断（Gaussian σ‑truncation）先筛选大约 10‑% 的高分位词，显著减小搜索空间；
- 引入四叉枢轴搜索（Quaternary Pivot Search）和重复计数机制，降低迭代次数并保证确定性；
- 通过双层 Triton Block Size 自适应调度优化不同大小向量的计算效率；
- 保留完整的 top‑k/top‑p 结果集，兼容需要完整候选集的后续任务。

**🔧 技术方法**

主要技术手段包括：
- Triton GPU 编程（利用 Persistent Kernel、Block‑level 并行）
- 高斯分布参数估计与查找表（δ 取值）
- 四叉枢轴搜索算法 + 重复日志位处理
- 归并、筛选、累加求和（cumsum）等向量化算子
- 自动调优（Autotune）多块大小策略。

**📊 数据集**

使用 WikiText‑2 数据集生成的四个 LLM 模型的 logits 作为测试：R1‑Distill‑Llama‑8B、Qwen3‑8B、GPT‑OSS‑20B、Gemma3‑4B。

**📈 对比分析**

与 vLLM、SGLang、FlashInfer 以及基准 PyTorch 排序实现进行对比。实验结果显示：
- 在 NVIDIA H100 与 RTX‑4090 上，所提算法平均实现 2 倍以上吞吐量提升；
- 内存占用低于或等于基线（尤其是 vLLM 的 RadixSelect 路径除外）；
- 输出与传统排序实现保持完全一致，满足严格的 top‑k/top‑p 语义。

**⚠️ 局限性**

局限性：
- 仍依赖 Triton，无法利用 GPU 低级优化（共享内存、warp 级原语）实现更高性能；
- 高斯 σ 截断阈值保守，导致某些模型（如 Gemma3‑4B）吞吐下降；
- 截断过程的固定缓冲区可能在极大 vocab 时代显得占内存；
- 当前实现每个 Triton Program 仅处理单一 batch，限制了在大 batch 规模下的扩展性；
- 对硬件的适配（CPU、TPU、NPU）仍需进一步验证。

---

## 369. Enhancing Generalization in Evolutionary Feature Construction for Symbolic Regression through Vicinal Jensen Gap Minimization

**arXiv ID:** 2602.01510 | [PDF](https://arxiv.org/pdf/2602.01510v1)

**作者:** Hengzhe Zhang `[一作]` (Victoria University of Wellington), Mengjie Zhang `[通讯]` (Victoria University of Wellington)

**通讯引用:** 31255 | [OpenAlex ID](https://openalex.org/A5100400258)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种基于Vicinal Jensen Gap最小化的遗传规划（VJM‑GP）方法，用来在演化特征构造中控制过拟合，从而提升符号回归的泛化性能。

**💡 创新点**

创新点包括：① 将vicinal risk分解为经验损失与正则化项（Vicinal Jensen Gap 或有限差分），实现对模型复杂度的精细调控；② 引入噪声估计策略，根据数据集噪声水平自适应调整正则化强度；③ 设计了流形入侵检测机制，避免数据增强产生离散化分布错误样本；④ 在演化框架中整合上述技术，形成统一的多目标优化流程。

**🔧 技术方法**

主要技术手段：遗传规划（GP）与交叉、变异、树增删操作；混合训练（mixup）与高斯噪声数据增强；交叉验证与极限随机树（Extra Trees）进行噪声评估；Beta分布采样用于mixup；非支配排序、Crowding距离、Lexicase选择等多目标选择策略；自适应正则化权重 τ 的设定。

**📊 数据集**

实验使用58个真实世界回归数据集，均来自PMLB（去除Friedman合成数据），每个数据集在训练/测试划分、标签编码等方面保持统一。

**📈 对比分析**

通过与8种基准GP复杂度控制方法（P‑VRM、PP、TK、GC、RC、WCRV、IODC、Standard GP）以及15种主流符号回归/机器学习算法（XGBoost、ExcelFormer等）进行比较。VJM‑GP在测试R²上显著优于Standard GP（在22/30个数据集显著提升），且在大多数数据集上优于其他7种复杂度度量；在与其他算法对比时，VJM‑GP在58个问题上取得最优或次优的R²，模型规模约为XGBoost的十分之一，训练时间相对更高但可在两小时内完成。

**⚠️ 局限性**

局限性：① 计算成本较高，尤其是K轮vicinal风险估计导致训练时间显著增加；② 依赖于额外的正则化权重调参（噪声估计策略可能对极端噪声水平失效）；③ 对大规模数据集或高维特征的扩展性尚未充分验证；④ 需要手动选择或调节Beta分布、γ等超参数，实际应用中可能需要额外的调优工作。

---

## 370. Optimal Sample Complexity for Single Time-Scale Actor-Critic with Momentum

**arXiv ID:** 2602.01505 | [PDF](https://arxiv.org/pdf/2602.01505v1)

**作者:** Navdeep Kumar `[一作]` (Technion), Shie Mannor `[通讯]` (Technion)

**通讯引用:** 18332 | [OpenAlex ID](https://openalex.org/A5036260775)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `a8e75ba4-7a2d-4153-b003-06c94533add0` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

在单时间尺度 actor‑critic 算法中证明了最优的 O(ε⁻²) 样本复杂度

**💡 创新点**

引入 STORM 随机递归动量与 replay buffer 同时降低 critic 估计方差，并通过精细递推与 Lyapunov+ODE domination 证明实现最优复杂度

**🔧 技术方法**

Actor‑Critic 框架、STORM 随机递归动量、replay buffer、Lyapunov+ODE domination 分析

**📊 数据集**

在 10 个状态、5 个动作的随机生成 MDP 上进行实验

**📈 对比分析**

与 Kumar 等人 2025 年的单尺度算法做对比，实验显示使用 STORM+buffer 的算法收敛更快，样本复杂度从 O(ε⁻³) 降至 O(ε⁻²)

**⚠️ 局限性**

需额外存储上一轮 Q‑网络（内存翻倍），buffer 需随时间线性增长；实验仅在小型离散 MDP 上，未验证在连续或大规模任务中的性能

---

## 371. OpInf-LLM: Parametric PDE Solving with LLMs via Operator Inference

**arXiv ID:** 2602.01493 | [PDF](https://arxiv.org/pdf/2602.01493v1)

**作者:** Zhuoyuan Wang `[一作]` (Carnegie Mellon University), Yorie Nakahira `[通讯]` (Carnegie Mellon University)

**通讯引用:** 454 | [OpenAlex ID](https://openalex.org/A5084147009)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a8e75ba4-7a2d-4153-b003-06c94533add0` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `5a41884c-404f-4688-a89c-aa238c10fe68` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出OpInf-LLM框架，将参数化PDE求解任务映射为低维ROM的多项式回归与ODE积分，并通过LLM自然语言接口实现自动化求解。

**💡 创新点**

创新点在于：1）将Operator Inference与LLM结合，实现对未知参数和边界条件的零样本推断；2）采用共享基底与多项式拟合，使模型在低计算成本下保持高执行成功率；3）通过LLM工具调用实现自然语言到求解器的闭环控制。

**🔧 技术方法**

使用技术包括：POD降维、最小二乘式Operator Inference、正则化、参数化多项式回归、低维ODE数值积分、LLM（如GPT‑4/4o/Gemini）与agentic工具调用。

**📊 数据集**

数据集为合成PDE轨迹，包含一维热传导方程、粘性波赫斯方程和二维闭塞流，分别在不同扩散系数、黏度和雷诺数下采集多条轨迹，并对参数与边界条件进行随机扰动。

**📈 对比分析**

与CodePDE、MOL‑LLM（小/大数据集）以及直接LLM预测等基线比较，OpInf‑LLM在三种PDE下均取得99%+的执行成功率，均方相对误差分别为1.29e‑2（热方程）、4.91e‑1（波赫斯）和4.63e‑2（闭塞流），显著优于基线。

**⚠️ 局限性**

局限性包括：需要为每个新的PDE家族重新构建共享基底；对高度非线性或极端参数外推的鲁棒性有限；对训练数据质量和量的依赖仍然显著；LLM的推理开销和工具调用错误仍是潜在风险。

---

## 372. DuoLungo: Usability Study of Duo 2FA

**arXiv ID:** 2602.01489 | [PDF](https://arxiv.org/pdf/2602.01489v1)

**作者:** Renascence Tarafder Prapty `[一作]` (University of California Irvine), Gene Tsudik `[通讯]` (University of California Irvine)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

对大学校园内 2,559 名用户使用 Duo 双因素认证的实际操作进行日志分析与问卷调查，评估推送通知任务的平均延迟、失败率、SUS 可用性得分及用户体验。

**💡 创新点**

首次在大规模、长期（9 个月）真实环境下量化 Duo 推送任务的耗时与失败模式，并将结果与过去几年前的研究直接对比，揭示使用习惯与系统改进对可用性的影响。

**🔧 技术方法**

采用 Duo 官方身份验证日志（包含时间戳与状态信息）与 System Usability Scale (SUS) 问卷相结合的方法，利用线性混合效模型分析时间与用户属性对耗时的影响。

**📊 数据集**

日志数据集：96,048 条日志条目，过滤后 45,541 条有效推送记录（2,558 名用户）；问卷数据集：57 名随机选取的参与者。

**📈 对比分析**

通过与 2017–2018 年先前研究的平均耗时、失败率、SUS 得分进行对比，显示本研究的推送耗时 7.82 秒（低于过去 11–58 秒），失败率 4.35%（与 5% 左右持平），SUS 70（“良好”级别）低于此前 81–85 的“优秀”水平。

**⚠️ 局限性**

样本偏向技术专业学生，问卷回应率低（2.2%），缺乏对不同设备、网络条件及辅助技术的细粒度分析，且未评估无障碍可用性，可能导致对更广泛用户群体的可用性评估不充分。

---

## 373. Ebisu: Benchmarking Large Language Models in Japanese Finance

**arXiv ID:** 2602.01479 | [PDF](https://arxiv.org/pdf/2602.01479v1)

**作者:** Xueqing Peng `[一作]` (Fin AI), Sophia Ananiadou `[通讯]` (University of Manchester)

**通讯引用:** 17184 | [OpenAlex ID](https://openalex.org/A5077976343)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a2602d71-93ab-4bad-974b-672788df8193` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

本文提出并发布了一个名为Ebisu的日语金融语言理解基准，包含两项任务：JF-ICR（隐式承诺识别）和JF-TE（金融术语提取），并评估了22款来自不同类别的LLM。

**💡 创新点**

创新点在于针对日语特有的黏着语、头位结构、混合书写系统及高情境隐式表达，设计了两项反映日本金融沟通文化与语言特征的评测任务，并提供了高质量专家标注的数据集。

**🔧 技术方法**

使用了专家标注与交叉检查的标注流程、基于LM Evaluation Harness的统一评测管线，以及准确率、F1和HitRate@K等多种评价指标，对各类开源、专有、日语和英语金融模型进行比较。

**📊 数据集**

数据集包括：JF-ICR 94条单轮投资者问答，来源于四家上市公司2023‑2026年公开披露；JF-TE 202条披露条目，来源于10家上市公司2025年年报（EDINET），共标注了2,412个金融术语提及、777个唯一术语。

**📈 对比分析**

通过对22款模型的横向对比，结果显示即便是最强模型（如Llama‑4‑Scout‑17B）在JF-ICR的准确率也仅约60%，在JF-TE的F1最高仅约0.41，HitRate@10最高约0.51；模型规模提升带来一定改善，但日语/金融领域的专门适配效果不显著，整体性能仍较低。

**⚠️ 局限性**

局限性包括：数据规模有限，仅覆盖少数公司与披露类型；缺乏训练/验证/测试拆分；任务仅涉及短文本与两项评测，未覆盖长文本、对话推理等；评价指标可能忽略语义相近但边界略有偏差的情况；以及评测结果可能导致对实际生产环境的过度依赖。

---

## 374. Agyn: A Multi-Agent System for Team-Based Autonomous Software Engineering

**arXiv ID:** 2602.01465 | [PDF](https://arxiv.org/pdf/2602.01465v1)

**作者:** Nikita Benkovich `[一作]` (Mila), Vitalii Valkov `[通讯]` (Mila)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了一个基于 agyn 的多智能体系统，自动模拟软件工程团队的角色与工作流程，完成 GitHub issue 的全自动解决。

**💡 创新点**

通过角色分工、独立沙盒、管理者协调以及 GitHub 原生工作流，实现了从单一或固定管线向可动态迭代的多角色协作转变。

**🔧 技术方法**

采用 agyn 平台、GPT‑5 / GPT‑5‑Codex 语言模型、定制 GitHub CLI 扩展、沙盒化执行环境、工具调用与自动上下文摘要等技术。

**📊 数据集**

使用 SWE‑bench 500 数据集（真实 GitHub issue）。

**📈 对比分析**

在 SWE‑bench 500 上进行全自动评估，系统以 72.4% 的成功率解决任务，显著高于同类 GPT‑5 系统的 71.8% 以及单代理 mini‑SWE‑agent 的 65%，并证明组织架构与协作机制可提升性能。

**⚠️ 局限性**

受限于 Benchmark 的环境漂移、旧依赖导致的 CI 失败、长时间测试、资源压力、以及自动化导致与金标准差异等，需改进错误恢复、资源管理和通信契约。

---

## 375. A $5$-Approximation Analysis for the Cover Small Cuts Problem

**arXiv ID:** 2602.01462 | [PDF](https://arxiv.org/pdf/2602.01462v1)

**作者:** Miles Simmons `[一作]` (University of Waterloo), Joe Cheriyan `[通讯]`

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出了对WGMV原始双对偶算法在覆盖满足对称性和结构子模性质的可弯曲集合族（即λ‑cut覆盖问题）上的近似比分析，并将其从先前的6降低到5。

**💡 创新点**

创新点在于引入“结构子模”这一更强的可弯曲集合族属性，证明该属性下的交叉密度最大为2，从而利用Bansal的定理得到更好的近似比；并给出了该比值的上界是紧的。

**🔧 技术方法**

主要技术包括：
- 可弯曲集合族与结构子模的定义与性质推导。
- 交叉密度概念与Bansal的（3+ρ）近似比公式。
- 对照树映射与红节点计数的组合论证明，显示每个覆盖链接最多关联两个红节点，从而证明ρ≤2。
- 结合稀疏交叉性质和对称性证明可弯曲族满足所需条件。

**📊 数据集**

本工作完全为理论分析，不涉及任何实验或数据集。

**📈 对比分析**

方法与先前的6-近似比直接比较，证明在相同的算法框架下通过更严格的集合族约束即可提升近似比；实验部分缺失，性能评估仅基于理论证明。
- 近似比：5（已证明紧逼）。
- 算法时间复杂度与原始WGMV算法一致，保持多项式时间。

**⚠️ 局限性**

限制：
- 只适用于满足对称性和结构子模的可弯曲集合族，无法直接推广到更一般的λ‑cut覆盖实例。
- 证明只给出了理论上最优近似比，缺乏实际性能评估。
- 由于交叉密度上界依赖于结构子模性质，若实例不满足该性质，仍只能获得6或更差的比值。

---

## 376. Implementation Challenges in Quantum Key Distribution

**arXiv ID:** 2602.01500 | [PDF](https://arxiv.org/pdf/2602.01500v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

---

## 377. A Meta-Knowledge-Augmented LLM Framework for Hyperparameter Optimization in Time-Series Forecasting

**arXiv ID:** 2602.01445 | [PDF](https://arxiv.org/pdf/2602.01445v1)

**作者:** Ons Saadallah `[一作]` (Eötvös Loránd University), Tamás Gábor Orosz `[通讯]` (Eötvös Loránd University)

**通讯引用:** 233 | [OpenAlex ID](https://openalex.org/A5006888011)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `cc175879-ab65-4aa9-b58a-f6100a057dbf` `5b4c1114-4a70-478e-9921-2514ee03850d` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一种基于元知识增强的LLM驱动的时间序列预测超参数优化框架 LLM‑AutoOpt，融合贝叶斯优化与LLM推理。

**💡 创新点**

将数据、模型、历史优化结果等结构化元知识注入LLM提示，实现上下文感知且可解释的超参数调优；同时采用BO作为warm‑start。

**🔧 技术方法**

使用大语言模型（Qwen2.5‑72B）+贝叶斯优化 + 元特征提取 + 结构化提示设计。

**📊 数据集**

在 Jena 气候多变量时间序列数据集（6 个月子集）上进行实验。

**📈 对比分析**

与随机初始 Bi‑LSTM、传统贝叶斯优化以及去掉元知识的 LLM 对比；LLM‑AutoOpt 的 RMSE 低约 0.1，收敛更快，训练/优化时间略高。

**⚠️ 局限性**

计算成本高于纯 BO，依赖高质量提示与元特征，实验仅在单一数据集与模型上验证，缺乏跨域泛化。

---

## 378. Theoretical Analysis of Measure Consistency Regularization for Partially Observed Data

**arXiv ID:** 2602.01437 | [PDF](https://arxiv.org/pdf/2602.01437v1)

**作者:** Yinsong Wang `[一作]` (Georgia Institute of Technology), Shahin Shahrampour `[通讯]` (Northeastern University)

**通讯引用:** 672 | [OpenAlex ID](https://openalex.org/A5040922600)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `67630363-6be0-4f51-ab05-7198250671a5` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68` `e15e3743-5ee0-4d5f-813d-d146868082fc` `109c2b71-d051-425c-831f-0c544c24280d`

**🎯 论文内容**

本文研究了在部分可观测数据缺失情况下，利用测度一致性正则化（MCR）提升填充质量的理论与实践；

**💡 创新点**

创新点在于：①从神经网络距离（NND）视角推导MCR的估计误差界；②在完美与不完美训练两种情境下给出理论上对MCR优势的必要与充分条件；③提出基于对偶性间隙的训练终止协议，保证在实际训练中保留理论优势；

**🔧 技术方法**

采用的技术包括：神经网络距离（IPM）、Rademacher复杂度分析、对偶性间隙估计、Wasserstein‑1 与 MMD 正则化、GAN 风格的对抗训练与梯度惩罚；

**📊 数据集**

实验数据集涵盖：合成数据、MNIST、CIFAR‑10、ECG/TEB/EDA 传感器数据、Crop 传感器数据、单细胞多组学数据（scMultiSim）等；

**📈 对比分析**

与仅使用监督损失（无MCR）的基线比较，MCR 在多种数据与模型（MLP、CNN、VAE、MultiVI）中均显著降低重建误差，提升 2–5 % 的误差降低率；通过对偶性间隙阈值实现早停，获得与全长训练相当甚至更佳的泛化性能；

**⚠️ 局限性**

局限性包括：①当完整与缺失数据分布差异过大（ξ 较大）时理论优势消失；②对偶性间隙与分布差异的估计在高维下易受噪声影响；③理论推导基于若干理想化假设（完美拟合、Lipschitz 限制、分布相同等），实际应用需谨慎验证；

---

## 379. CIPHER: Cryptographic Insecurity Profiling via Hybrid Evaluation of Responses

**arXiv ID:** 2602.01438 | [PDF](https://arxiv.org/pdf/2602.01438v1)

**作者:** Max Manolov `[一作]` (Independent Researcher), Ryan Lagasse `[通讯]` (Algoverse)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了一个名为 CIPHER 的基准，用以量化大语言模型在生成 Python 代码时的密码学安全漏洞，并提供可复现的评分流程。

**💡 创新点**

创新点包括：①控制提示（insecure/neutral/secure）三元组设计，②针对密码学的 17 类 58 细粒度漏洞分类，③自动化行级漏洞归因与 LLM-judge 评估。

**🔧 技术方法**

采用提示工程、LLM‑as‑Judge（GPT‑4o）、静态代码分析、Bootstrap 置信区间等技术来评估生成代码的安全性。

**📊 数据集**

数据集包含 150 个密码学任务族（共 450 个提示），每个提示生成 5 个样本，总计 2250 条生成代码，并配有安全与脆弱参考实现。

**📈 对比分析**

通过“漏洞率（VR）”“每生成一条代码平均漏洞数”“评判置信度”等指标对 7 种主流 LLM 进行对比；结果显示即使在安全提示下，漏洞率仍在 71–89% 之间，平均漏洞数在 0.73–1.46 之间。

**⚠️ 局限性**

局限性：仅覆盖 Python，缺乏对动态执行或侧信道攻击的检测；评判依赖单一 LLM‑judge 可能存在偏差；基准规模有限，未涵盖所有密码学 API 与语言。

---

## 380. How Users Perceive Mixed-Initiative AI: Attitudes Toward Assistance in Problem Solving

**arXiv ID:** 2602.01481 | [PDF](https://arxiv.org/pdf/2602.01481v1)

**作者:** Yunhao Luo `[一作]` (University of California), Misha Sra `[通讯]` (University of California)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

在混合主动性系统中研究了两种AI援助交付模式——按需帮助按钮与预设空闲触发计时器，并用Rush Hour拼图任务在时间与预算限制下评估其对用户体验的影响。

**💡 创新点**

创新点在于将援助时机的调度与援助内容分离，独立考察交付模式对用户感知的影响，并证明即使任务表现相同，预设计时器模式可提升用户对AI的正面评价。

**🔧 技术方法**

使用的技术包括基于宽度优先搜索的AI辅助算法、定量实验设计、带时间与AI使用成本的预算约束环境、以及多种统计模型（beta回归、GLMM、ANCOVA）进行数据分析。

**📊 数据集**

使用的任务数据集为公开的Rush Hour拼图游戏（包含初级、中级、高级共七套拼图），通过Prolific平台招募66名受试者完成实验。

**📈 对比分析**

比较方法为将三种条件（无援助、按钮、计时器）在任务完成度、移动精度、预算效率等指标上进行对比；结果显示两种援助模式均显著优于无援助，但在预算效率和用户满意度上并无显著差异，唯一显著差异是计时器模式在用户感知上更受欢迎。

**⚠️ 局限性**

限制在于仅针对结构化的拼图任务，缺乏开放式或创造性任务的验证；实验仅为一次性体验，未考察长期使用中的习惯与策略变化；以及仅测试两种具体的援助时机机制，未探索更丰富的自适应触发策略。

---

## 381. Cross-Paradigm Evaluation of Gaze-Based Semantic Object Identification for Intelligent Vehicles

**arXiv ID:** 2602.01452 | [PDF](https://arxiv.org/pdf/2602.01452v1)

**作者:** Penghao Deng `[一作]` (University of Georgia), Jiachen Bian `[通讯]` (University of Georgia)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究了在驾驶场景中通过前视摄像头图像定位驾驶员注视点所对应的语义物体，以评估三种视觉方法的效果。

**💡 创新点**

首次系统比较了传统目标检测、分割+分类与大型视觉语言模型在点注视物体识别任务中的性能，并揭示了“部分-整体”语义缺口及VLM在低光/雨天的优势。

**🔧 技术方法**

使用YOLOv13、SAM2+EfficientNetV2/YOLOv13、Qwen2.5-VL-7b/32b等模型。

**📊 数据集**

基于Bdd100K城市街景并人工标注四种环境（晴天/夜/雨天+夜）共1355个注视点。

**📈 对比分析**

结果显示YOLOv13和Qwen2.5-VL-32b在宏观F1上分别达到0.872与0.845，YOLO速度36fps，VLM速度0.07fps，VLM在夜雨场景及交通灯识别上明显优于检测器。

**⚠️ 局限性**

主要局限在于使用模拟注视点、单帧评估、缺乏实时VLM加速以及对真实眼动噪声不敏感。

---

## 382. Towards a Novel Wearable Robotic Vest for Hemorrhage Suppression

**arXiv ID:** 2602.01448 | [PDF](https://arxiv.org/pdf/2602.01448v1)

**作者:** Harshith Jella `[一作]` (University of Louisville), Yash Chitalia `[通讯]` (University of Louisville)

**通讯引用:** 482 | [OpenAlex ID](https://openalex.org/A5001760308)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

设计并实现了一种可穿戴机器人，用可变形环机制和充气气囊在太空等极端环境下实现非四肢部位止血，并通过实验验证其力学性能和止血效果。

**💡 创新点**

创新点在于环形可形变结构（由圆形到椭圆形）与柔性环臂的组合，配合可充气环与气囊，实现自动恒定压力止血，兼顾可复用性和太空空间/重量约束。

**🔧 技术方法**

采用软体机器人技术，DC电机+螺杆驱动可变形环，TPE/ PTFE分层热压制造气囊与环；利用Castigliano定理建模环臂弯曲；通过运动捕捉、力计、压力传感器等实验手段进行验证。

**📊 数据集**

使用实验收集的力学数据（弯曲刚度、爆破压力、气压与作用力关系）以及人工扼血模型的血流量数据作为验证集。

**📈 对比分析**

通过实验对比三种环臂设计的刚度、压力阈值和止血阈值；结果显示环臂凸起设计刚度最低；环与气囊爆破压分别为16.55 kPa和18.62 kPa；在模拟人体模型上，装置将止血阈压从4.83 kPa提升至约8.96 kPa，证明能有效延迟出血。

**⚠️ 局限性**

局限在于气囊完全充气时电机扭矩不足无法改变环形；对复杂身体曲线（腋窝、侧背等）的贴合度不够；气囊材料易滑动；形变功能仅在部分充气状态下可用；单次使用的充气部件需更换。

---

## 383. SimGym: Traffic-Grounded Browser Agents for Offline A/B Testing in E-Commerce

**arXiv ID:** 2602.01443 | [PDF](https://arxiv.org/pdf/2602.01443v1)

**作者:** Alberto Castelo `[一作]` (Shopify), Zhong Wu `[通讯]` (Shopify)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了SimGym，一个基于大型语言模型代理在实时浏览器中运行的离线A/B测试平台，利用生产点击流生成与真实买家分布相匹配的合成买家进行UI变化预测；

**💡 创新点**

创新点在于：1）将买家行为通过六阶段流程从点击流中提取，生成多维度、与真实分布一致的意图与人格；2）让代理在完整浏览器环境下执行per-session记忆、访问树感知与安全护栏，提升仿真真实性；3）通过对比真实主题更改实验验证代理预测的因果有效性；

**🔧 技术方法**

核心技术包括：大型语言模型（LLM）代理、访问树可视化感知、可编程的prompt生成、基于聚类的意图/人格构建、离线A/B预测的Pearson相关与方向一致率评估、Bootstrap样本量分析；

**📊 数据集**

使用的数据集是：20个在全球12国的真实电商商店的主题更改实验数据（包含A2C转化率变化），以及这些商店的完整生产点击流用于构建代理意图与人格；

**📈 对比分析**

与真实人类实验结果比较，通过方向一致率（约73%）和Pearson相关系数（≈0.65）验证代理预测准确；实验显示模拟周期从数周缩短到不足1小时，且对真实买家无风险；

**⚠️ 局限性**

局限性包括：只评估A2C转化率而非更细粒度行为，代理仍依赖LLM生成的规则模板且对极端UI变化（高度视觉化）缺乏直接支持，且实验规模受限于20个商店，未来需要更大范围验证与视觉模型集成。

---

## 384. Multimodal UNcommonsense: From Odd to Ordinary and Ordinary to Odd

**arXiv ID:** 2602.01561 | [PDF](https://arxiv.org/pdf/2602.01561v1)

**作者:** Yejin Son `[一作]` (Yonsei University), Younjae Yu `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了Multimodal UNcommonsense（MUN）数据集和检索式上下文学习（R-ICL）框架，用以评估模型在罕见、违反常识的多模态情景中的推理能力。

**💡 创新点**

创新点在于：①设计了专门针对视觉与文本不一致的罕见场景数据集；②提出Multimodal Ensemble Retriever（MER），实现对图文不对齐示例的有效检索；③通过R-ICL将检索到的示例注入小模型，实现跨模型知识迁移。

**🔧 技术方法**

使用的技术包括：检索式上下文学习（R-ICL）、MER（图像使用CLIP编码、文本使用BERT编码、双模态相似度融合）、多模态视觉语言模型（如Gemma3、InternVL、LLaVA、Phi、Qwen等）。

**📊 数据集**

使用的数据集为自建的MUN数据集，共1015个图文-结果对，包含MUN-vis（515例）和MUN-lang（500例）两子任务；对比时使用人类+LLM生成的解释作为基准。

**📈 对比分析**

与随机示例的ICL对比，R-ICL在所有模型上平均提升约8.3%（在低频、异常场景下），在MUN-vis任务上提升更显著；在7种VLM上，检索式示例在逻辑鲁棒性、正确性、效率和常识理解等指标均显著优于随机。

**⚠️ 局限性**

局限性包括：数据集规模有限，可能无法覆盖所有文化和领域多样性；检索质量高度依赖检索集的多样性，可能影响泛化；评估主要基于LLM评分，存在主观偏差；未实现多轮交互式推理，缺乏更深层次的推理验证。

---

## 385. Combined Flicker-banding and Moire Removal for Screen-Captured Images

**arXiv ID:** 2602.01559 | [PDF](https://arxiv.org/pdf/2602.01559v1)

**作者:** Libo Zhu `[一作]` (Shanghai Jiao Tong University), Yulun Zhang `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 22300 | [OpenAlex ID](https://openalex.org/A5074865219)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究并实现了一种针对屏幕捕捉图像同时去除闪烁条纹（flicker-banding）和摩尔纹（moiré）的统一恢复框架 CLEAR，并构建了相应的大规模数据集。

**💡 创新点**

首创将闪烁条纹与摩尔纹联合去除任务与数据集结合；提出 ISP 基于 RAW 领域的闪烁仿真管线；设计频域分解+加权重构模块和轨迹对齐损失，能同时抑制两种伪影。

**🔧 技术方法**

采用频域分解与 Butterworth 滤波器、加权重构、轨迹对齐损失（cosine 对齐）、LoRA 微调、预训练 U‑Net 的扩散模型、ISP 反向变换等技术。

**📊 数据集**

构建 Moiré and flicker‑in‑screen‑image‑capture（MIFS）数据集，约 3,000 对图像，涵盖自然、网页、文档、漫画、游戏、UI 六种场景，并包含闪烁条纹、摩尔纹及两者合并三种失真；同时利用 UHDM 等公开数据集进行合成。

**📈 对比分析**

与去噪、去摩尔纹、去条纹、超分等多类方法以及 RIFLE+ESDNet 级联模型对比；CLEAR 在 SSIM、ms‑SSIM、LPIPS、DISTS、FSIM、GMSD 等多项指标上均显著优于对比方法，视觉效果更干净、残留伪影更少。

**⚠️ 局限性**

评价指标对闪烁条纹的敏感度不足；训练仍依赖人工标注与真实拍摄样本，对极端光照或角度变化的鲁棒性未完全验证；仅针对显示屏拍摄场景，缺乏对其它类型图像的通用性评估。

---

## 386. NeuroAI Temporal Neural Networks (NeuTNNs): Microarchitecture and Design Framework for Specialized Neuromorphic Processing Units

**arXiv ID:** 2602.01546 | [PDF](https://arxiv.org/pdf/2602.01546v1)

**作者:** Shanmuga Venkatachalam `[一作]` (Carnegie Mellon University), John Paul Shen `[通讯]` (Carnegie Mellon University)

**通讯引用:** 9758 | [OpenAlex ID](https://openalex.org/A5007315039)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `5a41884c-404f-4688-a89c-aa238c10fe68` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

设计并实现了一种基于主动树突多段神经元的神经AI时序神经网络（NeuTNN），并开发了从 PyTorch 到芯片布局的自动化工具链 NeuTNNGen，评估其在时序聚类、MNIST 与 Place Cells 等应用上的硬件性能。

**💡 创新点**

创新点包括：① 引入主动树突多段神经元模型，显著提升计算表达力；② 在 NeuTNNGen 中实现多层、可配置的 NeuTNN 生成；③ 在 CMOS 设计中首次实现参考框架与 Place Cells；④ 通过突触剪枝实现 30–50% 的硬件资源与功耗削减。

**🔧 技术方法**

技术栈：NeuTNN 微架构（六层抽象），PyTorch + PyVerilog 自动生成 RTL，Cadence Genus/Innovus 合成布局，TNN7 定制宏库，STDP 本地学习机制，突触剪枝与二值化策略。

**📊 数据集**

使用数据集：UCR 时序基准（12 条），MNIST 手写数字，40 个 30x30 网格的 Place Cells 训练环境（及 UCR 之前的 7 条基准）。

**📈 对比分析**

与 TNNGen 及传统多层 TNN 进行对比，使用后布局功耗、面积等 PPA 指标。结果显示：在 7nm 下，单层 NeuTNN 在 MNIST 上达到 96% 识别率，仅消耗 5.01 mW、6.15 mm²；UCR 最高 6750 连接仅需 40.27 μW；突触剪枝后功耗/面积下降约 34–35%，相比传统多层 TNN 减少约 20% 连接量。

**⚠️ 局限性**

局限性：仅验证了少数应用场景；缺乏多种感知输入编码器；未实现 compute‑in‑memory 或 CAM 原语；参考框架尚不完整；验证仅到布局阶段，未做 LVS、可靠性分析；突触剪枝策略仍需进一步研究。

---

## 387. HACK NDSU: A Real-world Event to Promote Student Interest in Cybersecurity

**arXiv ID:** 2602.01580 | [PDF](https://arxiv.org/pdf/2602.01580v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

---

## 388. How Notations Evolve: A Historical Analysis with Implications for Supporting User-Defined Abstractions

**arXiv ID:** 2602.01525 | [PDF](https://arxiv.org/pdf/2602.01525v1)

**作者:** Jingyue Zhang `[一作]` (University of Montréal), Ian Arawjo `[通讯]` (University of Montréal)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

对符号演化的历史与社会过程进行比较分析，提出符号演化的三阶段社会模式与三阶段功能模式。

**💡 创新点**

提出符号演化的社会-功能双维度框架，并总结33个跨学科共性模式，强调隐喻、维度选择与正式化动力。

**🔧 技术方法**

主要采用比较历史研究方法、案例对比与文献梳理，未涉及具体技术实现。

**📊 数据集**

无，研究基于已有的符号历史文献与案例，不使用实验数据集。

**📈 对比分析**

无对比实验，主要以案例回顾与理论推导为评估手段。

**⚠️ 局限性**

研究范围有限，仅覆盖部分符号案例，缺乏细粒度过程追踪与实证验证，且结论仍需在更多领域检验。

---

## 389. A Relative-Budget Theory for Reinforcement Learning with Verifiable Rewards in Large Language Model Reasoning

**arXiv ID:** 2602.01523 | [PDF](https://arxiv.org/pdf/2602.01523v1)

**作者:** Akifumi Wachi `[一作]` (LY Corporation), Taiji Suzuki `[通讯]` (University of Tokyo)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种相对预算理论，解释了在大语言模型推理中强化学习（RL）效果的变化，特别是在计算预算和任务难度之间的关系。

**💡 创新点**

创新点在于通过相对预算ξ（生成时间/期望时间）来分析RL的样本效率，识别出三种学习模式（不足、平衡和充足），并提供了在线RL的有限样本保证。

**🔧 技术方法**

使用了强化学习（RL）和在线学习的技术，结合了理论分析和实证验证。

**📊 数据集**

使用了GSM8K和MATH-500等推理基准数据集进行实验验证。

**📈 对比分析**

通过与无验证奖励的监督微调（SFT）进行比较，发现RL在平衡模式下（ξ≈1）表现出最大的样本效率，而SFT在此模式下表现最差。实证结果表明，最佳学习效率的预算范围为ξ∈[1.5, 2.0]。

**⚠️ 局限性**

限制在于理论分析依赖于连续代理奖励，使得方差分析可行，未来需要扩展到二元奖励设置，以更全面地描述推理管道的标准理论。

---

## 390. A Lightweight Sparse Interaction Network for Time Series Forecasting

**arXiv ID:** 2602.01585 | [PDF](https://arxiv.org/pdf/2602.01585v1)

**作者:** Xu Zhang `[一作]` (Fudan University), Wei Wang `[通讯]` (Fudan University)

**通讯引用:** 39999 | [OpenAlex ID](https://openalex.org/A5100391662)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了一种轻量稀疏交互网络（LSINet），使用仅包含 MLP 的线性结构实现时间序列预测。

**💡 创新点**

创新点包括：① 多头稀疏交互机制（MSIM）——通过稀疏诱导的伯努利分布学习重要时间步之间的连接；② 共享交互学习（SIL）——共享跨样本、跨变量的稀疏连接矩阵；③ 自适应稀疏正则化（ASRL）——动态控制连接稀疏度，提升模型精度。

**🔧 技术方法**

主要技术：Patch 编码 + 位置嵌入；多头稀疏交互机制；Gumbel‑Softmax 采样实现可微稀疏连接；自适应稀疏正则化；残差结构；MLP 组合与投影。

**📊 数据集**

使用六个公开长序列数据集：Weather、Electricity、ETTh1、ETTh2、ETTm1、ETTm2。

**📈 对比分析**

与先进线性模型（TimeMixer、CI‑TSMixer、FiLM、DLinear）和 Transformer 模型（PatchTST、Scaleformer、Pathformer）在 MSE/MAE 上进行多步预测比较。LSINet 在准确性上平均提升约 2–6% 以上，并在训练/推理时间、显存占用方面显著优于这些基线。

**⚠️ 局限性**

局限性：仅实现了单层 STI 模块，深层堆叠效果待探索；稀疏率和超参数需手动设定，对不同数据可能需调优；在极长或非平稳序列中的鲁棒性尚未充分验证。

---

## 391. ASafePlace: User-Led Personalization of VR Relaxation via an Art Therapy Activity

**arXiv ID:** 2602.01579 | [PDF](https://arxiv.org/pdf/2602.01579v1)

**作者:** Chuyang Zhang `[一作]` (Southern University of Science and Technology), Pengcheng An `[通讯]` (Southern University of Science and Technology)

**通讯引用:** 769 | [OpenAlex ID](https://openalex.org/A5014119112)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `90291a0e-9d36-4a08-9a16-89ce846d923f` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出了ASafePlace系统，结合艺术治疗启发的“安全场所”绘制与AI生成的个性化360° VR 环境与音频指导，并在实验中与呼吸生物反馈相结合进行放松训练。

**💡 创新点**

其创新点在于首次将艺术治疗中的安全场所概念与生成式AI共同生成用户自创的VR环境与音频内容，实现深度个性化，并验证此协同能显著提升放松效果。

**🔧 技术方法**

技术手段包括：Stable Diffusion+ControlNet+360 LoRA+LCM生成360°图像、GPT‑4o生成个性化音频脚本、Unity VFX实现呼吸粒子反馈，配合呼吸感应器与光学心率传感器收集实时生理数据。

**📊 数据集**

数据集主要来自52名受试者的艺术治疗对话、手绘草图以及VR实验记录，使用公开的安全场所脚本和放松指导模板；未使用公开大规模数据集。

**📈 对比分析**

实验采用2×2随机设计，对比四种组合（个性化+生物反馈、个性化仅、无个性化+生物反馈、无个性化无生物反馈），通过HRV、呼吸率及自评量表比较；结果显示个性化+生物反馈组在HRV提升、呼吸率下降、存在感与相关性得分上显著优于其他组，且两因子交互显著。

**⚠️ 局限性**

局限性包括：实验受限于实验室环境与非临床样本、需人工艺术治疗师介入、生成的VR环境逼真度有限、仅采用呼吸反馈、样本量相对较小、跨文化适配性尚未验证。

---

## 392. Local Exponential Stability of Mean-Field Langevin Descent-Ascent in Wasserstein Space

**arXiv ID:** 2602.01564 | [PDF](https://arxiv.org/pdf/2602.01564v1)

**作者:** Geuntaek Seo `[一作]` (Pohang University of Science and Technology), Beomjun Choi `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 71 | [OpenAlex ID](https://openalex.org/A5084168318)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `de8d30ba-c289-43a5-b4ec-7b80df73aea2`

**🎯 论文内容**

研究并证明了在混合纳什均衡附近，均值场朗之万下降–上升（MFL‑DA）动力学呈指数收敛；

**💡 创新点**

通过在Wasserstein空间上建立局部强位移凸-凹结构，利用线性化算子谱分析获得熵的强凝聚性，从而首次实现非凸-非凹收益下的局部指数稳定性；

**🔧 技术方法**

采用Wasserstein梯度流理论、奥托的Riemannian微积分、谱/弗里德霍尔姆理论、Poincaré与Holley–Stroock扰动定理以及局部EVI（能量变分不等式）等数学工具；

**📊 数据集**

无，论文纯理论分析；

**📈 对比分析**

未进行实验比较，理论结果表明在初始化足够靠近平衡点时收敛速度为指数级，常数由谱间隙决定；

**⚠️ 局限性**

仅提供局部结果，全球收敛性仍未解决；对非紧致空间的推广仍需进一步研究；

---

## 393. The Inlet Rank Collapse in Implicit Neural Representations: Diagnosis and Unified Remedy

**arXiv ID:** 2602.01526 | [PDF](https://arxiv.org/pdf/2602.01526v1)

**作者:** Jianqiao Zheng `[一作]` (Australian Institute for Machine Learning), Simon Lucey `[通讯]` (Australian Institute for Machine Learning)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

通过层级 NTK 分解诊断框架识别了 INRs 中的“入口秩坍塌”，并提出只需改动初始化即可恢复秩的 Rank-Expanding 初始化，从而提升标准 ReLU MLP 在连续信号重建中的表现。

**💡 创新点**

创新点在于：① 将入口秩坍塌定位为 INRs 的根本瓶颈；② 统一解释 PE、SIREN、BN 等方法为秩恢复；③ 设计仅靠初始化的最小化方案，既无架构改动也无额外计算成本。

**🔧 技术方法**

使用了层级 NTK 分解、特征/权重 Jacobian、Kronecker 乘积、SVD 等理论工具，并对 1D/2D 坐标采用几何阈值分布实现初始化。

**📊 数据集**

实验数据集包括 DIV2K 16 张 2D 图像、256×256 网格样本，以及 3D 体素占用体积（如 ShapeNet）等。

**📈 对比分析**

与默认 ReLU、PE、SIREN、BN（全层）以及仅在第一层使用这些方法进行比较；在 2D 重建中 PSNR 从 23.57 提升至 27.15，3D IoU 与 SIREN/PE 相当，证明仅改动初始化即可匹敌结构性改动。

**⚠️ 局限性**

局限性：主要针对低维坐标输入的 INRs，未探讨更高维或非坐标输入场景；并未系统评估收敛速度、泛化能力或在更大网络规模下的可扩展性。

---

## 394. Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles

**arXiv ID:** 2602.01590 | [PDF](https://arxiv.org/pdf/2602.01590v1)

**作者:** Shaohan Wang `[一作]` (University of Science and Technology of China), Yongdong Zhang `[通讯]` (University of Science and Technology of China)

**通讯引用:** 34093 | [OpenAlex ID](https://openalex.org/A5046305086)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 Wiki Live Challenge benchmark 与 Wiki Eval 评估框架，用来衡量深度研究代理（DRA）在撰写 Wikipedia Good Articles 方面的能力。

**💡 创新点**

创新点在于采用最新的 Wikipedia Good Articles 作为专家级参考，构建 39 条细粒度写作准则和两大事实评估指标，实现实时、客观、可复现的评估体系。

**🔧 技术方法**

使用 LLM-as-a-Judge 方法、Gemini、GPT、Qwen 等大模型进行写作判定与事实抽取，利用 Jina Reader 对引用进行内容验证，形成完整的评估流程。

**📊 数据集**

基准数据集为 100 篇 2025 年 3 月至 12 月间发布的 Good Articles（覆盖 15 个领域），并以官方质量标准为评估依据。

**📈 对比分析**

通过 39 条写作准则得分、Wiki 事实覆盖率和引用准确率对 14 个 DRA 系统进行比较；现有模型与人类专家相比，写作得分和事实覆盖率均低于 40%，显示仍有较大差距。

**⚠️ 局限性**

局限性包括：数据规模受限（仅数百篇文章）、部分专有系统引用机制不透明导致评估偏差、评估框架对引用可访问性有限等问题。

---

## 395. Are Security Cues Static? Rethinking Warning and Trust Indicators for Life Transitions

**arXiv ID:** 2602.01544 | [PDF](https://arxiv.org/pdf/2602.01544v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

---

## 396. Attention-weighted Centered Kernel Alignment for Knowledge Distillation in Large Audio-Language Models Applied to Speech Emotion Recognition

**arXiv ID:** 2602.01547 | [PDF](https://arxiv.org/pdf/2602.01547v1)

**作者:** Qingran Yang `[一作]` (Ping An Technology), Jianzong Wang `[通讯]` (Harbin Institute of Technology)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `8d10c613-917e-4880-9716-17789f50e119` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

对大规模音频语言模型进行知识蒸馏，构建 PL-Distill 框架，将 8.4B 参数教师模型压缩到 1.1B 参数学生模型，并在语音情感识别任务中取得领先效果。

**💡 创新点**

① 引入项目器层蒸馏（PDist）并提出注意力加权中心核对齐（AwCKA）解决音频投射器维度不匹配并突出关键时间步；② 结合 logits 层蒸馏（LDist）实现跨模态一致性。

**🔧 技术方法**

基于 Whisper 大规模音频编码器、Qwen2-0.5B LLM、LoRA 微调、AwCKA 关注机制、KL 散度蒸馏、线性 CKA 等技术。

**📊 数据集**

使用 IEMOCAP、RAVDESS、SAVEE 三大公开语音情感数据集进行评估。

**📈 对比分析**

与预训练模型（WavLM、data2vec、Whisper）、教师模型、前沿蒸馏方法（Forward KL、Reverse KL、LLaVA-KD）及 SFT 进行对照；学生模型在所有指标上均优于教师及其他基线，提升幅度达 8–22% 以上。

**⚠️ 局限性**

仅在语音情感识别任务验证，缺少对其他音频任务的泛化评估；对教师投射器参数冻结可能限制进一步提升；AwCKA 依赖 LLM 注意力，可能受模型尺寸影响。

---

## 397. AdNanny: One Reasoning LLM for All Offline Ads Recommendation Tasks

**arXiv ID:** 2602.01563 | [PDF](https://arxiv.org/pdf/2602.01563v1)

**作者:** Nan Hu `[一作]` (Microsoft), Qi Zhang `[通讯]` (Microsoft)

**通讯引用:** 14897 | [OpenAlex ID](https://openalex.org/A5100360194)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 AdNanny，一种统一的大型语言模型，用于离线广告系统的多任务标注、评估、查询生成、用户画像和广告优化；

**💡 创新点**

将推理过程与标签一同训练，通过 reasoning-augmented 数据和多任务自适应重权重以及下游广告指标的强化学习，整合并取代多个任务专用模型；

**🔧 技术方法**

基于 671B 参数的 DeepSeek‑R1 进行多任务监督微调和 RL 对齐，使用自定义 Megatron 并行、MoE、checkpoint 转换、FP8/ BF16 推理、KL‑regularized GRPO；

**📊 数据集**

使用 Bing Ads 内部的六类离线任务数据（query–ad relevance、ad–user relevance、query 生成、用户画像、广告优化、模型评估）以及公共基准（GSM8K、MMLU、HumanEval 等）；

**📈 对比分析**

与原始 4o‑1120 轻量模型、GPT‑4o 以及 DeepSeek‑R1 进行对比，AdNanny 在离线标注任务上提升 BACC 3–10 分，查询生成指标提升 15–30 分，且 FP8 推理成本比 GPT‑4o 低 2–4 倍；

**⚠️ 局限性**

局限在于仅覆盖已有广告域与市场、RL 奖励仍基于离线指标、未直接优化长期用户价值，以及对稀缺垂直领域与新政策的泛化能力待提升。

---

## 398. Design of Root Protograph LDPC Codes Simultaneously Achieving Full Diversity and High Coding Gain

**arXiv ID:** 2602.01555 | [PDF](https://arxiv.org/pdf/2602.01555v1)

**作者:** Inki Kim `[一作]` (Sungkyunkwan University), Sang-Hyo Kim `[通讯]` (Sungkyunkwan University)

**通讯引用:** 16646 | [OpenAlex ID](https://openalex.org/A5100756277)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

设计了一种基于protograph的LDPC码，既能在M=2的块衰落信道上实现满分散，又能在AWGN信道上获得接近容量的编码增益。

**💡 创新点**

创新点在于提出基于Boolean逼近的多样性演化（DivE）分析，用以生成保证满分散的protograph模板，并引入广义根检查（generalized rootcheck）在多轮BP迭代中推进多样性；随后在该模板约束下使用RCA-DE引导的遗传算法搜索，提升AWGN性能。

**🔧 技术方法**

主要技术包括：Protograph设计与QC‑LDPC上升，Boolean逼近的DivE多样性分析，广义根检查结构，RCA‑DE密度演化，用于评估AWGN阈值的遗传算法（GA）优化。

**📊 数据集**

实验使用M=2块衰落信道与二进制输入AWGN信道，代码长度分别为N=7744和16896（率为1/2）进行仿真，没有采用公开数据集，而是通过信道仿真得到性能曲线。

**📈 对比分析**

与5G‑NR LDPC及根protograph LDPC做对比；在块衰落信道上展示更陡峭的BLER衰减（实现满分散），在AWGN信道上阈值最低、容量间隙最小，整体BLER/BER表现均优于基准。

**⚠️ 局限性**

局限性包括：仅针对M=2的块衰落信道；仅针对1/2码率；未考虑高码率或M≥2的扩展；实际实现的硬件复杂度与寻优搜索开销未做评估。

---

## 399. Toward Cognitive Supersensing in Multimodal Large Language Model

**arXiv ID:** 2602.01541 | [PDF](https://arxiv.org/pdf/2602.01541v1)

**作者:** Boyi Li `[一作]` (University of Illinois Urbana-Champaign), Xu Cao `[通讯]` (PediaMed AI)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种名为 Cognitive Supersensing 的多模态推理框架，利用潜在视觉图像预测（LVIP）头与强化学习结合，使大语言模型在视觉认知任务上能在潜在空间内进行多步推理，并构建了新的 CogSense-Bench 评测基准。

**💡 创新点**

核心创新在于：1) 在推理链中加入视觉潜在状态序列，弥补仅靠文本化推理导致的空间信息丢失；2) 采用多阶段训练（SFT+LVIP + GFlowNet 强化学习）实现视觉与语言推理的同步优化；3) 通过视觉潜在表征为推理路径提供“视觉心里图景”，提升抽象规则与动态模拟的推理质量。

**🔧 技术方法**

技术细节包括：
- LVIP 头（两层 MLP）预测答案选项图像的潜在嵌入；
- 监督学习阶段使用交叉熵 + MSE 损失；
- 强化学习阶段使用 GFlowNet 对潜在推理链进行采样和奖励引导；
- 视觉编码器 + 语言投影 + LLM 主干（以 Qwen3‑VL‑8B 为例）；
- 通过多模态 token 拼接实现视觉与文本信息融合。

**📊 数据集**

使用的数据集有：
- CogSense‑Dataset‑105K（涵盖流体智力、结晶智力、视空间认知、心理模拟、视觉程序五大维度的 105k 题目）；
- CogSense‑Bench（统一评测基准）；
- EMMA Chemistry 与 Math 子集（OOB 评测）；
- 其他通用视觉语言基准（HallusionBench、AI2D、GQA、ScienceQA 等）用于验证通用能力。

**📈 对比分析**

实验与多种主流 MLLM（Gemini 2.5 Flash、GPT‑5.2、Claude‑Sonnet‑4 等）对比，
- 在 CogSense‑Bench 上取得 73.8% 准确率，超过 GPT‑5.2 +33.5%；
- 在 OOD EMMA Chemistry、Math 上分别提升 6.2% 与 8.8%；
- 在通用视觉语言任务保持与基线相当，证明方法不致使主干性能下降。

**⚠️ 局限性**

局限性：
- 受限于视觉编码器的表达能力，极端抽象或超大尺寸图像的推理仍可能失败；
- RL 采样与奖励设计需要较多计算资源，推理过程耗时；
- 潜在视觉表征缺乏直观可解释性，难以直接定位错误来源；
- 对跨模态迁移（如非图像视觉任务）适用性尚未验证。

---

## 400. MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety

**arXiv ID:** 2602.01539 | [PDF](https://arxiv.org/pdf/2602.01539v1)

**作者:** Xiaoyu Wen `[一作]` (Shanghai AI Laboratory), Qiaosheng Zhang `[通讯]` (Shanghai AI Laboratory)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `9cc9baba-5356-466d-81ff-d80028d90279` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

通过构建多智能体强化学习的异步对抗游戏框架 MAGIC，提升大型语言模型的安全防御与合规性。

**💡 创新点**

创新点在于将攻击者与防御者解耦为异步角色、引入子博弈完美纳什均衡理论、设计攻击池 Benchmark 并采用 GRPO 实现迭代共进化，显著增强单轮和多轮交互的安全性。

**🔧 技术方法**

采用多智能体强化学习（MARL）、Group Relative Policy Optimization (GRPO)、Chain-of-Thought 预训练、Qwen3Guard 奖励模型，以及子博弈完美纳什均衡理论。

**📊 数据集**

SFT 阶段使用 SorryBench 与 WildJailBreak 的对抗样本，RL 阶段使用 WildJailBreak 的善意与有害提示，攻击池 Benchmark 覆盖 20 种重写策略。

**📈 对比分析**

与原始指令调优模型、Self-RedTeam、SmoothLLM 等基线对比，MAGIC 在 WildGuardTest、HarmBench 等安全基准上将攻击成功率降至 0.2%–2%，同时保持或提升常规指令性能，在多轮 X‑Teaming 测试中亦表现最优。

**⚠️ 局限性**

主要限制包括高昂的训练成本、对攻击者 SFT 初始化与模型容量高度敏感、在多模态或工具使用场景下尚未验证，以及对抗训练过程需细致调参以避免过度惩罚导致性能退化。

---

## 401. UniDWM: Towards a Unified Driving World Model via Multifaceted Representation Learning

**arXiv ID:** 2602.01536 | [PDF](https://arxiv.org/pdf/2602.01536v1)

**作者:** Shuai Liu `[一作]` (Sun Yat-sen University), Kai Huang `[通讯]` (Sun Yat-sen University)

**通讯引用:** 16485 | [OpenAlex ID](https://openalex.org/A5100776772)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

UniDWM通过联合重建和生成学习了一个结构与动态兼容的潜在世界表示，支持感知、预测和规划统一处理。

**💡 创新点**

创新点在于将感知、预测与规划融入单一潜在空间，并以VAE视角构建多模态自监督学习框架，利用条件扩散Transformer进行未来状态生成。

**🔧 技术方法**

使用技术包括VAE/InfoVAE理论、空间-时间自编码器、动态编码器、分离解码器、条件扩散Transformer（DiT）等。

**📊 数据集**

使用数据集为NAVSIM进行训练和评估。

**📈 对比分析**

与多种基线（UniAD、LTF、DiffusionDrive等）比较，UniDWM在无标签设置下在轨迹规划上取得最佳或接近最佳成绩，4D重建精度最高。

**⚠️ 局限性**

局限在于长时间生成会出现视觉伪影，训练-推理差距导致误差累积，且仅在仿真数据上验证。

---

## 402. PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation for Proactive Agents

**arXiv ID:** 2602.01532 | [PDF](https://arxiv.org/pdf/2602.01532v1)

**作者:** Yuxuan Fu `[一作]` (Shanghai University of Engineering Science), Xihe Qiu `[通讯]` (Shanghai University of Engineering Science)

**通讯引用:** 476 | [OpenAlex ID](https://openalex.org/A5007950680)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一种名为 PRISM 的主动代理框架，能够在决定是否干预时同时估计用户是否需要帮助（p_need）与干预是否会被接受（p_accept），并根据成本敏感阈值门控，只有在概率满足条件时才发声，并仅在接近决策边界时触发资源密集的慢推理。

**💡 创新点**

创新点在于：① 将需求与接受解耦并引入成本敏感动态阈值；② 采用选择性慢推理，仅在不确定边界内使用昂贵推理；③ 训练时使用门控对齐的蒸馏（RDC），让学生模型与干预门分离，便于可调节与可审计。

**🔧 技术方法**

技术手段包括双进程推理架构（快模式+慢模式）、概率校准与门控公式、基于 C_FA/C_FN 的动态阈值、RDC 蒸馏与监督微调、LLM‑as‑Judge 评估方法以及 AUDBC 指标。

**📊 数据集**

使用的数据集为 ProactiveBench 基准（涵盖编码、写作、日常三大域的事件流），并利用教师模型生成的未标记交互轨迹进行蒸馏。

**📈 对比分析**

在自动评估（LLM‑as‑Judge）和人工专家评估两种方式下，与 GPT‑4o、Claude、ProactiveBench 原始管线以及开源 LLM 进行对比，PRISM 在召回率保持 ~100% 的同时，将精准率提升 4–5%，误报率下降 54%，F1 提升约 20%，AUDBC 指标也显著优于基线。

**⚠️ 局限性**

局限性包括：① 依赖 LLM‑as‑Judge 代理可能与真实用户接受度存在偏差；② 假设成本（C_FA、C_FN）与概率校准随时间保持不变，部署中分布漂移或成本动态变化会削弱门控效果；③ 蒸馏可能继承教师偏见，需要进一步加入安全约束。

---

## 403. FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents

**arXiv ID:** 2602.01566 | [PDF](https://arxiv.org/pdf/2602.01566v1)

**作者:** Chiwei Zhu `[一作]` (University of Science and Technology of China), Yongdong Zhang `[通讯]` (University of Science and Technology of China)

**通讯引用:** 34093 | [OpenAlex ID](https://openalex.org/A5046305086)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 FS-Researcher，一个基于文件系统的双代理框架，用于深度研究任务。

**💡 创新点**

通过将上下文构建与报告撰写拆分为两个代理，并使用持久化文件系统工作空间突破上下文窗口限制，实现了可迭代的证据积累与报文生成。

**🔧 技术方法**

采用 ReAct 代理架构、文件系统工具、Web 浏览工具和大模型（如 GPT‑5、Claude‑Sonnet）等技术，构建知识库并生成报告。

**📊 数据集**

使用 DeepResearch Bench 和 DeepConsult 这两个公开的深度研究基准数据集进行评估。

**📈 对比分析**

与多种专有与开源系统对比，在 DeepResearch Bench 上最高 RACE 54.25（Claude‑Sonnet）/51.96（GPT‑5），在 DeepConsult 上胜率 80% 及平均分 8.33，显示出显著的性能提升。

**⚠️ 局限性**

依赖强大基础模型，较小模型表现不足；文件操作易出错，可能传播不准或版权敏感内容。

---

## 404. How Implicit Bias Accumulates and Propagates in LLM Long-term Memory

**arXiv ID:** 2602.01558 | [PDF](https://arxiv.org/pdf/2602.01558v1)

**作者:** Yiming Ma `[一作]` (Nanyang Technological University), Wei Dong `[通讯]` (Nanyang Technological University)

**通讯引用:** 15177 | [OpenAlex ID](https://openalex.org/A5100746411)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究LLMs在长期记忆中隐性偏见的累积与跨域传播，并提出DIB基准及长期决策仿真框架

**💡 创新点**

首次系统量化长期记忆中隐性偏见的动态演化和跨域传播，提出通过动态记忆标记（DMT）实现的细粒度偏见干预

**🔧 技术方法**

基于LLMs、三种记忆架构（Mem0、LangMem、Letta）、长期决策仿真、动态标记机制及审计器

**📊 数据集**

Decision-Based Implicit Bias Benchmark（3776样本），MMLU-Pro作为日常交互语料，结合DIB场景

**📈 对比分析**

与静态系统提示（SSP）对比，DMT在多模型、多记忆架构下将GBV平均下降约50%，跨域传播下降40%以上，表现优异

**⚠️ 局限性**

实验主要在仿真环境进行，缺少真实应用验证；DMT依赖审计器能力，未充分评估计算成本与可扩展性

---

## 405. Autonomous Question Formation for Large Language Model-Driven AI Systems

**arXiv ID:** 2602.01556 | [PDF](https://arxiv.org/pdf/2602.01556v1)

**作者:** Hong Su `[一作]` (Chengdu University of Information Technology), Hong Su `[通讯]` (Chengdu University of Information Technology)

**通讯引用:** 151 | [OpenAlex ID](https://openalex.org/A5031030652)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在多智能体仿真环境中，提出一种基于人类模拟的框架，使大型语言模型驱动的 AI 系统能够自主提出问题并生成任务，从而在动态开放环境中实现自适应决策。

**💡 创新点**

创新点在于将“问题生成”提升为决策过程的首要步骤，并通过内部状态、环境感知和互代理交互三维信息的逐层提示来扩展认知范围，同时支持通过经验学习提升问题生成策略。

**🔧 技术方法**

核心技术包括 LLM（如 GPT）提示工程、基于内部状态、环境观测与交互上下文的多层提示模型、经验经验回放与强化学习式的策略更新，以及任务与方法选择的决策层。

**📊 数据集**

使用的“数据集”为自定义的多智能体仿真数据（共享蔬菜田、饥饿周期、交互规则），无公开真实数据集。

**📈 对比分析**

通过与内部驱动基线、仅环境感知提示、以及环境+互代理感知提示三种方法对比，实验显示互代理感知提示在20天内累计无食事件下降 60% 以上，资源可持续性和任务完成率显著提升。

**⚠️ 局限性**

局限性包括仅在模拟环境中验证，缺乏真实世界测试；提示设计对 LLM 性能敏感；对复杂、多模态感知与长时记忆的支持有限；未评估不同 LLM 模型的泛化能力。

---

## 406. InfoTok: Regulating Information Flow for Capacity-Constrained Shared Visual Tokenization in Unified MLLMs

**arXiv ID:** 2602.01554 | [PDF](https://arxiv.org/pdf/2602.01554v1)

**作者:** Lv Tang `[一作]` (University of Alberta), Xingyu Li `[通讯]` (vivo Mobile Communication Co.)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 InfoTok，基于信息瓶颈的视觉共享令牌化方法；

**💡 创新点**

在共享令牌化中引入容量受限视角，利用信息瓶颈正则化显式控制令牌的压缩与任务相关性，并加入跨模态对齐项；

**🔧 技术方法**

使用信息瓶颈（IB）理论、变分 IB（VIB）估计、对数似然、对比损失以及重参数化技巧；

**📊 数据集**

在原始 1.5M 图文对训练数据上进行微调，并在 GQA、SEED、POPE、MME、MMV2、MMMU、UniBench、Geneval、Geneval++、WISE 等十个基准上评测；

**📈 对比分析**

与 Show‑o2、OpenUni、Harmon 等共享令牌统一 MLLM 进行对比，InfoTok 在理解和生成任务上均有稳定提升，尤其在 Harmon 与 Show‑o2 上显著提升；

**⚠️ 局限性**

对冻结 VLM 后端或仅生成任务的模型效果提升有限，且需额外的正则化训练成本，信息量估计不精确可能导致过拟合或欠拟合。

---

## 407. Plain Transformers are Surprisingly Powerful Link Predictors

**arXiv ID:** 2602.01553 | [PDF](https://arxiv.org/pdf/2602.01553v1)

**作者:** Quang Truong `[一作]` (Michigan State University), Jiliang Tang `[通讯]` (Michigan State University)

**通讯引用:** 25068 | [OpenAlex ID](https://openalex.org/A5040639891)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了 PENCIL，一种基于标准 Transformer 的无 ID、无手工结构编码的链接预测模型，通过在采样的局部子图上进行 token 化和自注意，直接学习边的存在概率。

**💡 创新点**

创新点在于：①只使用标准 Transformer 结构，完全抛弃传统的结构编码或全图信息；②通过随机化节点标号实现分布式置换不变性；③理论证明 PENCIL 能自然逼近常见启发式、SEAL 与 NBFNet 等方法的表达能力；④显著降低参数量和训练时间。

**🔧 技术方法**

技术实现包括：子图采样、one‑hot 与邻接行的 token 化、角色位编码、无序 Transformer 块、乘法残差（自注意 + 线性传播）、随机向量初始化，以及在子图上直接重构邻接矩阵。

**📊 数据集**

实验使用了 Planetoid（Cora、Citeseer、Pubmed）和 OGB 链接预测数据集（ogbl-collab、ogbl-ddi、ogbl-citation、ogbl-ppa、ogbl-natives），并在 HeaRT 评估协议下进行对比。

**📈 对比分析**

与多种基线（GCN、GraphSAGE、NBFNet、SEAL、Neo‑GNN、BUDDY、NCN/NCNC、LPFormer、MPLP+、Refined‑GAE 等）在标准和 HeaRT 评估下对比，PENCIL 在大多数数据集上实现了最优或接近最优的 MRR、Hits@50/100，参数量更少、收敛更快、方差更低。

**⚠️ 局限性**

局限性包括：需要为每条候选边采样子图，导致 GPU 计算和内存线性增长；在小规模数据集上数据效率不足；缺乏预训练或子图缓存机制；理论分析尚未完全覆盖所有 Transformer 链接预测模型的表达力。

---

## 408. HandMCM: Multi-modal Point Cloud-based Correspondence State Space Model for 3D Hand Pose Estimation

**arXiv ID:** 2602.01586 | [PDF](https://arxiv.org/pdf/2602.01586v1)

**作者:** Wencan Cheng `[一作]` (National University of Singapore), Gim Hee Lee `[通讯]` (National University of Singapore)

**通讯引用:** 9396 | [OpenAlex ID](https://openalex.org/A5071967339)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种基于Mamba状态空间模型的多模态手部姿态估计框架HandMCM，用于从RGB、深度和点云输入中准确预测3D手部关键点坐标。

**💡 创新点**

创新点包括：①使用可变长度的Correspondence Mamba捕捉动态关节对应关系；②引入局部几何注入与过滤机制提升遮挡下的鲁棒性；③采用多模态超点编码器融合视觉与几何信息。

**🔧 技术方法**

主要技术包括：Mamba状态空间模型、点云卷积（PointNet）、ResNet自编码器、双向S4层、局部token注入与滤波、平滑L1损失。

**📊 数据集**

在NYU、DexYCB和HO3D三个公开基准数据集上进行实验验证。

**📈 对比分析**

与现有SOTA方法相比，HandMCM在NYU上的平均关键点误差为7.06 mm，在DexYCB上的平均误差为1.71 cm，在HO3D上的平均误差为1.71 cm，均显著优于前沿方法。

**⚠️ 局限性**

目前的局限是难以处理双手交互场景，需要进一步扩展模型以支持双手姿态估计。

---

## 409. On the Fragility of AI-Based Channel Decoders under Small Channel Perturbations

**arXiv ID:** 2602.01582 | [PDF](https://arxiv.org/pdf/2602.01582v1)

**作者:** Haoyu Lei `[一作]` (Chinese University of Hong Kong), Farzan Farnia `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 544 | [OpenAlex ID](https://openalex.org/A5017160178)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `6215c339-3735-4be3-8a07-5bbb7004712d` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究了 AI 基于 Transformer 的解码器（ECCT、CrossMPT）在受到受限对抗扰动（FGM、PGD、UAP、UAP-PCA）时的鲁棒性，并将其与传统 BP 解码器进行比较。

**💡 创新点**

通过对抗鲁棒性视角揭示 AI 解码器在 AWGN 下性能提升的代价：它们对小幅度、norm‑bounded 的扰动极度敏感，且针对 AI 解码器的扰动能较强转移到其他 AI 解码器，但对 BP 解码器影响较弱。

**🔧 技术方法**

使用了梯度攻击（FGM、PGD）、通用对抗扰动（UAP、UAP-PCA）、随机平滑技术；实现了 ECCT、CrossMPT 等 Transformer 解码器，并对比 Min‑Sum、Sum‑Product BP 解码器。

**📊 数据集**

实验数据集为 Polar 码和 LDPC 码，码长和码率分别为 (128,64)、(121,60) 等，信噪比在 4–6 dB 之间，测试集 10⁶ 条样本。

**📈 对比分析**

通过 FER‑inverse（1/FER）指标比较：在无攻击时 AI 解码器优于 BP，但在对抗扰动下 FER 下降 10⁰–10³ 倍，性能显著恶化；BP 解码器对同一扰动保持相对稳健；随机噪声下两类解码器表现差异不大。

**⚠️ 局限性**

局限性包括：仅考虑 AWGN 通道和 ℓ₂ 受限扰动，未探讨更复杂的信道模型或更高维扰动；实验仅覆盖短码长度，缺乏对大码长度鲁棒性分析；未给出针对性鲁棒性改进方案。

---

## 410. SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models

**arXiv ID:** 2602.01574 | [PDF](https://arxiv.org/pdf/2602.01574v1)

**作者:** Haobo Wang `[一作]` (Sun Yat-sen University), Xiaochun Cao `[通讯]` (Sun Yat-sen University)

**通讯引用:** 26201 | [OpenAlex ID](https://openalex.org/A5068837264)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6215c339-3735-4be3-8a07-5bbb7004712d` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计了一种SGHA-Attack框架，用于对大规模视觉‑语言模型的可转移目标攻击。

**💡 创新点**

创新点在于使用语义引导锚点池、多层视觉结构对齐与跨模态潜在空间同步三大模块，显著提升跨模型转移性与鲁棒性。

**🔧 技术方法**

技术包括文本‑图像生成锚点、梯度投影优化、ViT中间层对齐、投影头同步等。

**📊 数据集**

数据集使用ImageNet‑1K图像与MS‑COCO文本提示，并通过Stable Diffusion生成锚点图像。

**📈 对比分析**

与AttackVLM、COA、M‑Attack等方法对比，SGHA‑Attack在多种开源与闭源VLM上取得更高的攻击成功率与CLIP分数，同时保持较好的视觉质量。

**⚠️ 局限性**

局限性包括对极强商业VLM的效果仍有限、对某些预处理/净化防御敏感，并需额外锚点生成与计算开销。

---

## 411. DREAMS: A Social Exchange Theory-Informed Modeling of Misinformation Engagement on Social Media

**arXiv ID:** 2602.01567 | [PDF](https://arxiv.org/pdf/2602.01567v1)

**作者:** Lin Tian `[一作]` (University of Technology Sydney), Marian-Andrei Rizoiu `[通讯]` (University of Technology Sydney)

**通讯引用:** 1174 | [OpenAlex ID](https://openalex.org/A5069685493)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种基于社会交换理论的跨平台假新闻互动预测框架 Dreams，旨在捕捉用户在不同社交平台上对误信息的动态交互行为。

**💡 创新点**

创新点在于将社会交换理论中的平台特定交换率、互惠记忆和情感通胀机制嵌入到神经序列模型中，并通过解耦表征、FiLM 模块和双时尺度记忆实现对平台差异的自适应建模。

**🔧 技术方法**

核心技术包括变分解耦表示（β‑VAE）、FiLM 基础的多平台自适应层、双时尺度记忆（快慢记忆+情景记忆）、序列到序列预测结构（Mamba/Transformer）以及持续学习的回放机制。

**📊 数据集**

使用 2021–2025 年跨 7 个平台（X、Bluesky、TikTok、Bilibili、Instagram、Telegram、Facebook）共 2.36 M 条包含文本/图片/视频的帖子与其互动数据，形成细粒度多模态多语言假新闻互动数据集。

**📈 对比分析**

与历史平均、ARIMA、LSTM、xLSTM、Informer、TS‑Transformer、TCN、RoBERTa、Mamba、IC‑Mamba 等基线比较，Dreams 在 7 天预测上平均 MAE 下降至 19.25%（比最强基线低 43.6%），在多平台交互层级预测和帖量预测上均表现出色。

**⚠️ 局限性**

局限性包括：对极端稀疏互动（如仅视图）预测能力有限；模型对平台变化的适应主要靠 FiLM 参数，可能在新平台或接口大改时需要重新训练；情感与内容解耦的效果受预训练情感模型的限制；对因果干预或多主体交互的解释能力仍有待提升。

---

## 412. One-Step Diffusion for Perceptual Image Compression

**arXiv ID:** 2602.01570 | [PDF](https://arxiv.org/pdf/2602.01570v1)

**作者:** Yiwen Jia `[一作]` (Xi'an Jiaotong University), Chenyang Ge `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 165 | [OpenAlex ID](https://openalex.org/A5025083064)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种仅使用单步扩散过程的图像压缩方法（OSDiff），同时在潜在空间引入判别器以提升感知质量。

**💡 创新点**

创新点包括：①将稳定扩散预训练模型与单步采样结合，实现解码仅需一次反向步骤；②在潜在特征空间而非像素空间设计判别器，显著减少解码时的计算量并提升重建质量；③通过联合损失（扩散损失、率损失、特征损失和判别器损失）实现压缩率、失真与感知三者的平衡。

**🔧 技术方法**

技术主要包括：预训练的 Stable Diffusion 2.1（VAE 编码器/解码器 + U‑Net 反向网络）、单步扩散采样、离散量化+算术编码、判别器（基于 U‑Net 中间层特征的 MLP）、AdamW8bit 优化器以及多任务损失融合。

**📊 数据集**

训练使用 LSIDR 数据集（84,991 张 512×512 图像），评估使用 Kodak、CLIC_2020（428 张 2K 图像）等公开压缩基准集。

**📈 对比分析**

与 BPG、ELIC、HiFiC、MS‑ILLM、PerCo、DiffEIC 等传统、学习型和扩散型压缩方法对比，OSDiff 在感知指标 DISTS、LPIPS 上与 DiffEIC 近乎持平、甚至略优；在 PSNR 上明显优于 DiffEIC；解码时间仅 0.06 s（约 50 倍加速），显著优于多步扩散方法。

**⚠️ 局限性**

局限性：单步采样相较于 50 步扩散在极低码率下感知质量略有下降；依赖预训练 Stable Diffusion，模型受限于其训练域；实验仅在特定中等尺寸图像上验证，尚未在极高分辨率或特殊内容（如医学图像）上充分验证。

---

## 413. Efficiently Solving Mixed-Hierarchy Games with Quasi-Policy Approximations

**arXiv ID:** 2602.01568 | [PDF](https://arxiv.org/pdf/2602.01568v1)

**作者:** Hamzah Khan `[一作]`, David Fridovich-Keil `[通讯]` (University of Texas at Austin)

**通讯引用:** 574 | [OpenAlex ID](https://openalex.org/A5070827615)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出混合层次博弈（同时包含Nash与Stackelberg关系）的形式化框架，并给出在非二次目标与非线性约束下求解该类博弈的完整算法；

**💡 创新点**

创新点在于：1) 构造出基于“准策略”逼近的KKT条件，避免递归产生高阶策略导数；2) 在此逼近下设计了不完全Newton方法，理论证明局部指数收敛；3) 通过Julia实现的高性能开源库，可在实时控制场景下直接应用；

**🔧 技术方法**

主要技术包括：隐函数定理+KKT条件推导、准策略近似、稀疏线性代数与符号预计算、近似Newton迭代与线搜索、实验验证与可视化；

**📊 数据集**

使用仿真数据：多机器人轨迹规划（四车合流、三车守卫目标）场景，采样周期0.1–0.5秒，时间步长10步；

**📈 对比分析**

与纯Nash、纯Stackelberg以及二阶准策略/完整KKT求解器比较，结果显示：在非二次、非线性约束下，算法在每次调用约15 ms（±9 ms）内收敛，成功实现实时规划，且收敛解满足约束；

**⚠️ 局限性**

局限性：准策略逼近忽略高阶导数，若高阶敏感度显著，近似误差增大；当前仅处理等式约束，且对深层层级的数值稳定性仍待进一步研究。

---

## 414. Argument Rarity-based Originality Assessment for AI-Assisted Writing

**arXiv ID:** 2602.01560 | [PDF](https://arxiv.org/pdf/2602.01560v1)

**作者:** Keito Inoshita `[一作]` (Ritsumeikan Global Innovation Research Organization Ritsumeikan University), Kentaro Tsuji `[通讯]` (Ritsumeikan University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种基于论证稀缺性的原创性评估框架 AROA，用来自动评估学生议论文的原创性。

**💡 创新点**

创新点在于将原创性定义为参考语料库中的稀缺性，并通过结构稀缺性、主张稀缺性、证据稀缺性和认知深度四个维度进行量化，同时将质量与原创性分离并在最终得分中乘以质量系数。

**🔧 技术方法**

使用大语言模型（如 GPT‑4.1‑mini）进行论证结构提取和质量评估，句子 BERT 获得嵌入向量，核密度估计与 K‑NN 计算稀缺性，PCA 降维后进行 z‑score 归一化，再通过加权融合得到最终分数。

**📊 数据集**

使用 AIDE 数据集，包含两题（无车城市、选举团）共 1,375 篇人类学生作文和 1,000 篇 AI 生成作文。

**📈 对比分析**

实验表明人类与 AI 在整体原创性得分无显著差异，但在人类作文中主张和证据稀缺性得分显著更高；与传统 AES 相比，AROA 揭示了质量与原创性的负相关，体现质量‑原创性权衡；在样本量 ≥300 时相关性稳定；单篇评估耗时约 1.5 s，成本约 0.0024 美元。

**⚠️ 局限性**

局限包括仅在两主题单语数据集上验证，缺乏与人工原创性评价的相关性研究，对结构和质量评估的 LLM 依赖导致模型差异，且在小规模班级（30–50 篇）评估鲁棒性不足。

---

## 415. S1-NexusAgent: a Self-Evolving Agent Framework for Multidisciplinary Scientific Research

**arXiv ID:** 2602.01550 | [PDF](https://arxiv.org/pdf/2602.01550v1)

**作者:** S1-NexusAgent Team `[一作]` `[通讯]` (Institute of Automation Chinese Academy of Sciences), S1-NexusAgent Team (Institute of Automation Chinese Academy of Sciences)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文设计并实现了跨领域自我进化的科学代理框架 S1‑NexusAgent，采用内外双循环架构将全局规划与子任务执行分离，并通过 CodeAct 接口实现代码优先的执行与迭代反馈。

**💡 创新点**

创新点在于：① 引入内外双循环（Outer‑Loop 任务规划 + Inner‑Loop 代码执行/错误恢复）实现长期目标稳定与局部探索协同；② 结合 CodeAct 形成统一的代码生成与执行循环；③ 通过轨迹评估与科学技能蒸馏实现自我演化与可重用技能；④ 采用多工具生态与稀疏上下文管理，提升大规模工具与长文本的可扩展性。

**🔧 技术方法**

技术手段包括：层次化 Plan‑and‑CodeAct 框架；内外双循环控制逻辑；CodeAct 统一执行接口；监督微调（SFT）+ 强化学习（RL）分阶段训练；轨迹评估与 Critic Agent；科学技能（Scientific Skill）蒸馏；上下文结构化与对象引用稀疏管理。

**📊 数据集**

使用的数据集有：Biomni‑Eval‑1（跨生命科学任务），ChemBench（化学设计与优化任务），MatSciBench（材料科学任务）。

**📈 对比分析**

通过系统对比与消融实验，S1‑NexusAgent 在 Biomni‑Eval‑1 上的整体成功率提升至 42.42%（相较于 Only Outer‑Loop 37.23% 与 Only Inner‑Loop 38.99%），RL 训练进一步将成功率从 38.40% 提升到 42.42%。在 ChemBench 与 MatSciBench 上也实现了业内领先的性能，说明该框架在生命科学、化学与材料三大领域均具备跨域泛化能力。

**⚠️ 局限性**

局限性：① 依赖 Qwen3‑8B‑SciCodeAct 及其有限的开源权重，模型规模相对较小；② 主要在公开基准上评估，缺乏真实实验室或工业环境的验证；③ 对未知工具的适配仍需要进一步探索，当前工具库和能力蒸馏主要面向已知任务；④ 轨迹评估与技能蒸馏过程成本较高，需更多资源与工程实现。

---

## 416. FSCA-Net: Feature-Separated Cross-Attention Network for Robust Multi-Dataset Training

**arXiv ID:** 2602.01540 | [PDF](https://arxiv.org/pdf/2602.01540v1)

**作者:** Yuehai Chen `[一作]` (Xi'an Jiaotong University), Yuehai Chen `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 186 | [OpenAlex ID](https://openalex.org/A5074448505)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

设计了一种 Feature-Separated Cross-Attention Network（FSCA-Net），通过显式将特征拆分为域不变与域特定两部分，并用跨注意力融合实现多数据集的人群计数。

**💡 创新点**

创新点包括：①显式特征分离减少域间冲突；②跨注意力机制动态捕捉域不变与域特定的交互；③互信息正则化同时最大化域不变一致性、最小化域特定冗余，从而抑制负迁移并提升知识共享。

**🔧 技术方法**

采用了特征分离模块、交叉注意力融合模块、互信息最大化/最小化损失、卷积编码器/解码器等技术，并在基础网络（CSRNet、BL、DM-Count、MAN）上做插件式集成。

**📊 数据集**

实验使用了上海Tech A/B、UCF-QNRF、JHU-CROWD++、UCF_CC_50 等四个主流人群计数数据集进行多数据集训练与跨域评估。

**📈 对比分析**

与传统方法进行对比，单模型多数据集训练后，FSCA-Net 在 MAE/MSE 上普遍优于基线（例如 CSRNet+FSCA-Net 在 UCF-QNRF、Shanghai A、UCF_CC_50 等数据集上均获得 10%~30% 的误差下降），并在跨域测试中实现了最小化负迁移、接近或超过现有最优结果。

**⚠️ 局限性**

局限性在于模型参数略增、推理速度比纯基线慢一点；在极端稀疏或极端密集的场景下，域特定信息仍可能造成一定误差；对目标域仍需要一定的微调或额外数据，未来可进一步降低对训练数据依赖。

---

## 417. Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars

**arXiv ID:** 2602.01538 | [PDF](https://arxiv.org/pdf/2602.01538v1)

**作者:** Youliang Zhang `[一作]` (Tsinghua University), Xiu Li `[通讯]` (Tsinghua University)

**通讯引用:** 10580 | [OpenAlex ID](https://openalex.org/A5100754504)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 InteractAvatar 双流扩散框架，解耦感知规划（PIM）和视频合成（AIM），实现基于文本的真实场景人机交互口型视频生成。

**💡 创新点**

创新点包括：① 通过检测驱动的感知模块生成场景感知且文本对齐的交互运动；② 采用 M2V 对齐器在残差层级注入运动信息，实现高质量与可控性并行；③ 统一流匹配训练框架，支持音频、文本、运动多模态混合控制。

**🔧 技术方法**

核心技术：Diffusion Transformer（DiT）+ VAE 编码、T5 文本编码、Wav2Vec 音频特征、RoPE 位置编码、流匹配损失、残差层级注入、双流并行训练。

**📊 数据集**

使用自建 GroundedInter 基准（600 条测试案例，包含参考图、文本描述、音频）以及 50 条真实场景数据；训练时还利用检测数据、动作序列和 RGB 运动表示。

**📈 对比分析**

与多类前沿方法（音频驱动、姿态驱动、主题一致生成）比较，性能显著提升：VLM‑QA、HQ、OQ、PI、DINO 等指标均优于基线，尤其在交互质量和口型同步上提升 100% 以上，且保持参考一致性。

**⚠️ 局限性**

局限性：目前仅支持单人场景，无法生成多人交互的 HOI；对复杂多物体动态和长期持续交互的鲁棒性尚待进一步提升。

---

## 418. Co-Design of Rover Wheels and Control using Bayesian Optimization and Rover-Terrain Simulations

**arXiv ID:** 2602.01535 | [PDF](https://arxiv.org/pdf/2602.01535v1)

**作者:** Huzaifa Mustafa Unjhawala `[一作]`, Dan Negrut `[通讯]` (University of Wisconsin)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0`

**🎯 论文内容**

在可变地形上进行全车闭环仿真，使用贝叶斯优化同时调优车轮几何和转向PID参数，完成3,000次仿真并在5-9天内得到最优方案。

**💡 创新点**

首次将连续体地形模型与贝叶斯优化结合，用全车级仿真实现车轮与控制器的协同设计，突破了传统单轮、DEM驱动设计的计算瓶颈。

**🔧 技术方法**

采用Chrono::CRM连续体地形模拟、Chrono::Vehicle车辆动力学、Ax/BoTorch贝叶斯优化框架，配合SPH粒子模拟地形和BCE标记交互。

**📊 数据集**

使用自建的1/6比例实验台车模型和对应的土壤参数（松散沙），以及通过3D打印的三种车轮样本进行物理验证。

**📈 对比分析**

对比了联合优化和分阶段优化两种策略，结果显示两者在行进时间和能耗上相差不大，联合优化的路径跟踪误差略低；总计算时间从约212小时降至118小时，显著提高效率。

**⚠️ 局限性**

局限在于仅考虑平面地形与单一土壤模型，车轮几何参数受限，仿真与实测存在一定的量化误差，且未考虑多重地形或低重力环境。

---

## 419. Rotation-free Online Handwritten Character Recognition Using Linear Recurrent Units

**arXiv ID:** 2602.01533 | [PDF](https://arxiv.org/pdf/2602.01533v1)

**作者:** Zhe Ling `[一作]` (Chongqing University), Danyu Yang `[通讯]` (Chongqing University)

**通讯引用:** 157 | [OpenAlex ID](https://openalex.org/A5063409976)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了基于滑动窗口路径签名与线性递归单元（LRU）的旋转无关在线手写字符识别框架。

**💡 创新点**

创新点在于将滑动窗口路径签名与轻量化LRU相结合，实现对旋转变形鲁棒的特征提取与序列建模。

**🔧 技术方法**

采用滑动窗口路径签名（SW‑PS）、线性递归单元（LRU）以及悬挂归一化、数据增强等预处理技术。

**📊 数据集**

在CASIA‑OLHWDB1.1数据集的数字、英文字母和汉字偏旁三个子集上进行实验。

**📈 对比分析**

与S5、NCDE、Log‑NCDE、RFOLHCR等基线模型对比，LRU在所有子集上取得最高准确率，收敛速度最快；集成后准确率提升约1%。

**⚠️ 局限性**

主要限制是对大角度旋转仍有少量误判，并且窗口长度与签名阶数需经验调优。

---

## 420. Preserving Localized Patch Semantics in VLMs

**arXiv ID:** 2602.01530 | [PDF](https://arxiv.org/pdf/2602.01530v1)

**作者:** Parsa Esmaeilkhani `[一作]` (Temple University), Longin Jan Latecki `[通讯]` (Temple University)

**通讯引用:** 11570 | [OpenAlex ID](https://openalex.org/A5064854962)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文通过引入 Logit Lens Loss（LLL）对视觉语言模型中的视觉 token 进行显式对齐，使得视觉 token 在 LLM 的注意力层中保持局部语义，从而显著提升 Logit Lens 的可解释性和视觉任务性能。

**💡 创新点**

创新点在于：① 在不改动模型结构的前提下，利用 Logit Lens 投影将视觉 token 的深度嵌入直接映射到词表空间；② 通过对视觉 token 与对应图像区域的词汇概率进行正负对比学习，抑制视觉-语言混合导致的语义消散；③ 使得 Logit Lens 可生成高质量的目标置信度热图，既能提升定位/分割，也能增强模型的解释能力。

**🔧 技术方法**

主要技术包括：视觉 encoder（ViT/CLIP/DINOv2）、线性投影将视觉 token 映射到语言空间、LLM 预训练的自回归语言模型（如 LLava‑v1.5、Qwen2.5‑VL）、Logit Lens（投影到词表概率空间）、LLL 辅助损失（对正负视觉 token 进行交叉熵约束）、SAM 作为后处理分割头、POPE 评估框架。

**📊 数据集**

使用的数据集有：MS COCO（RefCOCO、RefCOCO+、RefCOCOg 用于 referring‑expression segmentation），COCO 2014 用于 POPE 评估，PixMo‑Points（无重叠样本）用于零样本目标中心定位；此外在实验中还采用了基准 VLM 预训练模型（LLava‑v1.5、Qwen2.5‑VL）。

**📈 对比分析**

与基线模型、仅 NTP 微调、以及现有 SOTA VLM 进行比较：在 RES 任务中，LLL+NTP 的 cIoU 分别提升至 71.2%、63.1%、65.9%，加上 SAM 可达 80.1%/72.6%/74.3%，与或超过现有 SOTA；在 POPE 评估中，LLL+NTP 的准确率提高到 93.87%（相较基线 86.77%），显著降低“是/否”错误率；在 PixMo‑Points 上，LLL 降低了中位定位误差至 6.30 像素，优于多项基准。

**⚠️ 局限性**

局限性包括：① 只在微调阶段加入 LLL，未验证在大规模预训练中的可扩展性；② 依赖目标边框或像素级标注进行正负样本划分，对无标签数据的适用性有限；③ 目前仅针对自回归 VLM 结构，尚未验证对并行或跨模态 transformer 的适用性；④ 对长句子或多词概念的处理仍需按子词拆分，可能导致训练复杂度上升。

---

## 421. Making Bias Non-Predictive: Training Robust LLM Judges via Reinforcement Learning

**arXiv ID:** 2602.01528 | [PDF](https://arxiv.org/pdf/2602.01528v1)

**作者:** Qian Wang `[一作]`, Bingsheng He `[通讯]`

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过强化学习的EIT框架训练LLM以消除对提示层社会信号的认知偏见，从而实现判决的认知独立性。

**💡 创新点**

采用冲突式数据生成让偏见信号与正确答案等概率关联，并在奖励设计中加入独立性惩罚，使偏见在奖励中变为无预测性，突破表面模仿。

**🔧 技术方法**

基于GRPO的强化学习、平衡冲突采样、层次化奖励（准确性、结构化、独立性）以及Chain-of-Thought格式化约束。

**📊 数据集**

在Qwen3模型上使用MMLU-Pro的多科目问题集，训练时仅注入Bandwagon偏见，测试时评估Authority、Distraction、Position等OOD偏见。

**📈 对比分析**

与未微调基线、提示缓解、SFT对比，EIT在多类偏见下既提升准确率又提升鲁棒率，尤其在误导性偏见下提升约15–20%，甚至优于更大模型。

**⚠️ 局限性**

仅在英语数据与有限的偏见类型上验证，跨语言、文化和更细粒度的隐式偏见尚未评估，对开放式生成任务的适用性未知。

---

## 422. Toward a Machine Bertin: Why Visualization Needs Design Principles for Machine Cognition

**arXiv ID:** 2602.01527 | [PDF](https://arxiv.org/pdf/2602.01527v1)

**作者:** Brian Keith-Norambuena `[一作]` `[通讯]` (Universidad Catolica del Norte), Brian Keith-Norambuena (Universidad Catolica del Norte)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

综述了视觉化领域的历史背景、VLM 在图表理解中的表现以及当前绕过视觉的做法，并从理论和实证角度阐述人类视觉与机器视觉的根本差异，提出应当开展“机器 Bertin”与“机器 Cleveland‑McGill”实验的研究议程。

**💡 创新点**

① 将机器视觉视为一个独立的受众，明确提出“人类导向可视化”与“机器导向可视化”之间的概念区别；② 提出“机器 Bertin”研究范式，呼吁系统性实验评估机器对不同视觉编码的感知效果；③ 通过对比现有 VLM benchmark 结果，指出现行的“直接翻译/跳过视觉”方法并未探究视觉本身可能为机器提供的增益。

**🔧 技术方法**

本文主要采用文献综述、理论分析与对比讨论；并结合已发布的 VLM 图表理解基准（如 ChartQA、CharXiv、ChartMuseum、EncQA 等）进行经验性推断。

**📊 数据集**

利用公开的 VLM 评测数据集：ChartQA、CharXiv、ChartMuseum、EncQA、ChartInsights、ChartX、ChartNOISE 等，概括这些基准中机器与人类的性能差距与错误模式。

**📈 对比分析**

本文并未提出新的算法或实验，而是总结现有基准中机器在图表任务上的准确率（如 GPT‑4o 约 47% vs. 人类 80%）和对不同视觉编码的相对表现，并指出机器对图表的误差模式与人类差异显著。对比方法主要是基准分数和错误模式分析，表明机器性能相对较低且差异化明显。

**⚠️ 局限性**

限制：1) 研究仅停留在概念与理论层面，未进行系统实验验证；2) 对“机器 Bertin”实验方案与评价指标尚未确定；3) 关注的 VLM 主要为当前主流模型，未来架构可能导致结论变化；4) 论文未给出具体的机器视觉优化方法或设计准则。

---

## 423. Know Your Step: Faster and Better Alignment for Flow Matching Models via Step-aware Advantages

**arXiv ID:** 2602.01591 | [PDF](https://arxiv.org/pdf/2602.01591v1)

**作者:** Zhixiong Yue `[一作]` (Zhejiang University), Zhenpeng Mi `[通讯]` (HiThink Research)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `40105733-5154-44cd-8090-a8cab9e64b07` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 TA​FS‑GRPO 框架，将温度退火少步采样与基于组的优势策略优化（GRPO）结合，用于训练流匹配文本到图像模型，使其在极少步（4‑8步）内保持高质量且对齐人类偏好。

**💡 创新点**

创新点：
1) 将温度退火采样注入 GRPO，既保持采样随机性，又在每一步保留语义信息，解决传统流匹配模型的高计算成本和奖励稀疏问题；
2) 引入步感优势整合（Step‑aware Advantage Integration），为每一步生成结果提供密集、精准的奖励信号，显著提升策略优化效率和最终生成质量。

**🔧 技术方法**

使用技术：
- 流匹配模型（SD3.5‑M、Flux.1‑dev）
- GRPO 强化学习框架
- 温度退火少步采样
- 步感优势整合
- LoRA 微调
- CLIP、ImageR、UnifiedR 等奖励模型
- AdamW 优化器

**📊 数据集**

使用数据集：
- GenEval 组合图像生成任务的提示集
- Pick‑a‑Pic 25432 条训练提示、2048 条测试提示
- HPS‑v2.1、ImageReward、UnifiedReward 等外域评估集

**📈 对比分析**

比较方法与性能：
- 与 Flux.1‑dev、SD3.5‑M 等基础模型以及 Hyper‑Flux、Flux‑Turbo‑Alpha、SANA‑Sprint、Reward‑Instruct 等步骤蒸馏方法在 4‑8 步内对比；
- TAFS‑GRPO 在所有指标（pick、CLIP、HPS‑v2.1、ImageR、UnifiedR）上均超过上述方法，尤其在外域评估中提升显著；
- 训练速度提升约 53%（NFE 与耗时下降），并且在 8 步时仍保持高质量，展现出优秀的灵活性。

**⚠️ 局限性**

局限性：
- 仍需依赖手工设计的多种奖励模型，奖励质量直接影响对齐效果；
- 只在 SD3.5‑M、Flux.1‑dev 两个流匹配模型上验证，跨模型、跨任务的通用性尚未充分证明；
- 温度退火步数和优势整合步数的设置仍需经验调参，未提供统一自动化选择方法。

---

## 424. Genus-0 Surface Parameterization using Spherical Beltrami Differentials

**arXiv ID:** 2602.01589 | [PDF](https://arxiv.org/pdf/2602.01589v1)

**作者:** Zhehao Xu `[一作]` (Chinese University of Hong Kong), Lok Ming Lui `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 2100 | [OpenAlex ID](https://openalex.org/A5046845149)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `5b4c1114-4a70-478e-9921-2514ee03850d` `25d64835-ec5b-425b-899d-a6e1e6fecabd` `4de8e9d8-757b-475f-9627-18a445e50202` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

提出了球面Beltrami微分的概念，并在此基础上设计了两图表（北极、南极）自适应的贝塞尔优化框架BOOST，用SBN实现可微的自由边界曲率优化；

**💡 创新点**

创新点在于：①将球面自同胚映射直接转化为球面Beltrami系数的优化；②利用SBN近似LSQC求解器，保证解存在唯一并保持双射；③通过边界匹配、折叠惩罚和光滑正则化，实现两半球映射的无缝拼接；

**🔧 技术方法**

主要技术包括：球面 stereographic 投影、LSQC 能量、Spectral Beltrami Network (SBN) 神经网络、梯度下降多任务学习、相位旋转与缩放的后置组合；

**📊 数据集**

实验数据涵盖：OASIS、FreeSurfer 的人脑皮层表面（32,35,39等），Synthetic 极端扭曲与混合匹配数据；

**📈 对比分析**

与传统 FLASH、SUGAR 等方法对比：在六条脑沟标记对齐实验中，BOOST 的平均 |μ|、Chamfer 距离均低于 FLASH；在极端扭曲实验中能保持全局双射；在混合特征匹配中 Dice 与 PCC 均优于 SUGAR；整体表现更鲁棒、更低的角度畸变；

**⚠️ 局限性**

局限性：①对高分辨率网格需先低分辨率插值，可能失真；②仅适用于球面（genus‑0）拓扑，无法直接推广到高 genus 或开放曲面。

---

## 425. Spectral Text Fusion: A Frequency-Aware Approach to Multimodal Time-Series Forecasting

**arXiv ID:** 2602.01588 | [PDF](https://arxiv.org/pdf/2602.01588v1)

**作者:** Huu Hiep Nguyen `[一作]` (Applied Artificial Intelligence Initiative Deakin University), Hung Le `[通讯]` (Applied Artificial Intelligence Initiative Deakin University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `5a41884c-404f-4688-a89c-aa238c10fe68` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出了 SpecTF，一种在频域融合文本与时间序列的多模态预测框架。

**💡 创新点**

创新点在于将文本嵌入投射到复数频域，并通过频域交叉注意力与乘法融合实现对不同频段的自适应加权，从而捕获文本对短期波动与长期趋势的多尺度影响。

**🔧 技术方法**

核心技术包括快速傅里叶变换（rFFT）/逆变换、复数频域 MLP、频域交叉注意力、复数乘法融合、复杂向量位置编码及轻量级参数设计。

**📊 数据集**

使用 Time‑MMD 及 TimeText Corpus 两大多模态时间序列基准数据集进行实验。

**📈 对比分析**

与 FreTS、MM‑TSF、TaTS、TimeXer、TimeLLM、ChatTime 等主流方法对比，SpecTF 在 8/9 个领域的 MSE/MAE 上平均提升 3.8%/2.3%，参数量显著更少且推理速度最快。

**⚠️ 局限性**

在 Economy 数据集上表现略逊，原因是文本噪声高且对短期经济指标的捕获更适合时域对齐机制，表明频域方法对文本质量和时域特征的敏感性仍需进一步研究。

---

## 426. Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment

**arXiv ID:** 2602.01587 | [PDF](https://arxiv.org/pdf/2602.01587v1)

**作者:** Zehua Cheng `[一作]` (University of Oxford), Jiahao Sun `[通讯]` (FLock.io)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种针对大型语言模型的可证实鲁棒性框架，利用分层随机消融实现对离散token扰动的l0范数安全保证，并通过噪声增强对齐微调（NAAT）将模型变为语义去噪器。

**💡 创新点**

创新点在于：①在离散token空间引入分层随机消融（Stratified Randomized Ablation）取代传统连续高斯噪声；②利用超几何分布和Neyman‑Pearson定理推导出严格的l0鲁棒性半径；③通过NAAT训练模型在稀疏上下文下保持高精度，解决“倒置缩放”与实用性能的矛盾。

**🔧 技术方法**

核心技术包括：随机消融注意力掩码、超几何分布统计推断、Clopper‑Pearson置信区间、少量随机采样的蒙特卡罗估计、LoRA微调、KV‑cache加速推理。

**📊 数据集**

使用的数据集包括 JailbreakBench（Harmful Behaviors子集）、AdvBench、以及5-shot MMLU 57个学科子集作为对抗鲁棒性、可证实安全性与普通推理性能的综合评估。

**📈 对比分析**

与SmoothLLM、PPL Filter、Erase‑Check、Self‑Denoise等经验性与已知的可证实方法进行对比。CSS在对抗攻击（如GCG、AutoDAN）下的攻击成功率降至约1%，同时保持约94% 的安全性保证和94% 以上的原始性能；相比之下，SmoothLLM的安全性仅 4% 左右，且原始性能下降至 74%。

**⚠️ 局限性**

局限性包括：①需在训练时显式进行NAAT微调，增加训练成本；②对模型架构的兼容性有限，主要针对因果Transformer；③对极大扰动预算（高l0半径）仍有一定安全下限，需进一步提升稀疏下的推断精度。

---

## 427. Nearly Optimal Active Preference Learning and Its Application to LLM Alignment

**arXiv ID:** 2602.01581 | [PDF](https://arxiv.org/pdf/2602.01581v1)

**作者:** Yao Zhao `[一作]` (University of Arizona), Kwang-Sung Jun `[通讯]` (University of Arizona)

**通讯引用:** 738 | [OpenAlex ID](https://openalex.org/A5046896406)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出针对RLHF的主动偏好学习方法，设计了新的实验设计目标和贪心算法。

**💡 创新点**

创新点在于引入基于置信区间位置的实例相关实验设计目标，获得实例依赖的标签复杂度上界；同时给出简单的贪心采样策略。

**🔧 技术方法**

采用最大似然估计、置信区间分析、实验设计（G、D、XY等）以及贪心剩余不确定性度量。

**📊 数据集**

在Anthropic helpful & harmless、Nectar和ultrafeedback-binarized-preferences-cleaned三组RLHF偏好数据集上进行实验。

**📈 对比分析**

与随机、基于不确定性的采样、Selective Sampling、APO、D‑optimal设计等基线对比，表现出更快的标签收敛和更高的奖励模型分类准确率。

**⚠️ 局限性**

局限在于仅评估奖励模型分类准确率，未直接验证对对齐LLM性能的影响；实验设计目标仍与最终RLHF目标关联不够直接。

---

## 428. DrawSim-PD: Simulating Student Science Drawings to Support NGSS-Aligned Teacher Diagnostic Reasoning

**arXiv ID:** 2602.01578 | [PDF](https://arxiv.org/pdf/2602.01578v1)

**作者:** Arijit Chakma `[一作]` (Drexel University), Feng Liu `[通讯]` (Drexel University)

**通讯引用:** 11344 | [OpenAlex ID](https://openalex.org/A5100415332)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种名为DrawSim-PD的生成框架，能够合成符合NGSS标准的学生科学绘图、对应的第一人称推理叙述以及教师诊断概念图；

**💡 创新点**

创新点在于（1）引入能力轮廓（Capability Profile）对学生认知状态进行编码，精准控制绘图中的误差与缺陷；（2）实现跨模态一致性，将绘图、叙述与概念图三者统一生成；（3）公开构建了100个NGSS主题、10,000个带有结构化元数据的合成绘图语料库，突破隐私壁垒；

**🔧 技术方法**

使用的技术包括：GPT‑4o进行标准拆解、叙述与提示生成；Stable Diffusion/FLUX等文本到图像模型（通过OpenAI GPT Image 1 API）生成手绘风格的错误绘图；图形工具PyGraphviz渲染概念图；CLIP用于跨模态一致性评估；

**📊 数据集**

数据集：从官方NGSS标准中抽取191个表演期望，挑选100个与视觉建模紧密相关的主题，按K–12四个年段、四个表现层级各生成25个实例，形成10,000个合成绘图及对应文本、概念图；

**📈 对比分析**

评估方法：专家可行性研究，6位K–12科学教师共评估480个样本，使用NGSS对齐、表现层级匹配、年级适宜性等定量指标（如NGSS对齐率≈90%，表现层级匹配≈74%）以及跨模态CLIP相似度（概念图-绘图≈0.606）。整体表现显示生成的绘图在内容准确性、误差可控性和教师诊断支持方面均达到了可用水平；

**⚠️ 局限性**

局限性包括：未检验对教师诊断准确性或学习成效的实际影响；合成绘图仍受文本到图像模型的复杂性限制，难以完整表现高年级抽象概念；对年级边缘（K–2、9–12）的微调不足；缺乏对真实学生绘图的对照验证，且生成过程目前较为“黑箱”，缺少可解释性。

---

## 429. LLM-based Embeddings: Attention Values Encode Sentence Semantics Better Than Hidden States

**arXiv ID:** 2602.01572 | [PDF](https://arxiv.org/pdf/2602.01572v1)

**作者:** Yeqin Zhang `[一作]` (Nanjing University), Cam-Tu Nguyen `[通讯]` (Nanjing University)

**通讯引用:** 3576 | [OpenAlex ID](https://openalex.org/A5060261448)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出利用大型语言模型（LLM）中的value向量进行句子表示，构造了Value Aggregation（VA）与Aligned Weighted Value Aggregation（AlignedWVA）两种无训练或低成本训练的句子嵌入方法。

**💡 创新点**

创新点在于：①证明value向量比隐藏状态更能捕捉句子语义；②通过跨层、跨词的均值聚合（VA）得到高质量句子表示；③将注意力权重与输出投影对齐（AlignedWVA）进一步提升性能，且显著降低编码成本。

**🔧 技术方法**

技术上使用Transformer自注意力的value投影、均值池化、加权聚合、投影对齐以及LoRA微调等；对比实验采用了MTEB基准的14项下游任务。

**📊 数据集**

数据集主要包括MTEB benchmark的Clustering、Retrieval、STS、Classification、Re-ranking等子任务，背后使用的LLM模型为LLaMA‑2（7B）与Qwen‑3（8B）。

**📈 对比分析**

与传统无训练基线（LT、WMP、HS）及多种prompt‑based方法（PromptEOL、MetaEOL、EE）对比，VA在大多数任务上超过了无prompt基线，AlignedWVA在许多任务上甚至优于MetaEOL，且编码成本仅为其1/8。

**⚠️ 局限性**

局限性包括：①在分类、聚类等类别级别任务上的提升有限；②对不同LLM架构（如非decoder‑only）的通用性待验证；③价值向量微调仍未能完全匹配隐藏状态微调的效果，需进一步研究更有效的训练策略。

---

## 430. Generative Visual Code Mobile World Models

**arXiv ID:** 2602.01576 | [PDF](https://arxiv.org/pdf/2602.01576v1)

**作者:** Woosung Koh `[一作]` (KAIST AI), Jamin Shin `[通讯]` (Trillion Labs)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研发了一种可渲染 Web 代码生成的移动 GUI 世界模型 gWorld，并公开了 8B、32B 两个开源权重。

**💡 创新点**

创新点在于把下一状态从像素直接生成改为生成可渲染的代码，既利用 VLM 的语言先验保证文字精准，又借助代码生成的结构化表达避免传统图像生成的布局错误，同时实现单模型自包含、推理效率高的架构。

**🔧 技术方法**

核心技术包括：①基于 Qwen3 VL 8B/32B 的 Vision‑Language 模型做自监督训练；②数据生成框架将离线轨迹转换为 (S_t, A_t, S_{t+1}^{code}) 形式，并加入 look‑ahead 思维轨迹；③使用 vLLM 进行高速并行推理；④利用前沿 VLM（Gemini 3 Flash、Claude 4.5 Opus 等）做自动评测与辅助生成。

**📊 数据集**

使用了 Android in the Wild、GUIOdyssey、AndroidControl、Android Multi‑annotation Expo 四个轨迹数据集来构建训练集；评测基准为自建 MWMBench，包含四个 ID（AitW、GUIO、AC、AMEX）和两个 OOD（AndroidWorld、KApps）。

**📈 对比分析**

与 Qwen‑I‑E、Emu3.5、Llama4、GLM‑4.6V、Qwen3 VL 等前沿开源模型在 IAcc、渲染错误率和相似度等指标上进行对比，gWorld 8B/32B 在所有六个基准上均位居第一，IAcc 提升超过 45%，且结构错误率低于 1%，显著优于参数更大的模型。

**⚠️ 局限性**

限制包括：①数据生成与评测仍依赖外部高性能 VLM（如 Gemini 3 Flash），难以完全复现；②目前仅针对移动 GUI 场景，缺乏对其它交互界面的适配；③评测主要基于自动化指标，缺少充分的人类评估；④推理时仍需要渲染代码，虽然成本低，但在极低延迟场景下仍可能是瓶颈。

---

## 431. Witnessd: Proof-of-process via Adversarial Collapse

**arXiv ID:** 2602.01663 | [PDF](https://arxiv.org/pdf/2602.01663v1)

**作者:** David Condrey `[一作]` `[通讯]` (Writerslogic Inc), David Condrey (Writerslogic Inc)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了“对抗崩塌原则”，并实现了基于键盘抖动的证明过程（jitter seal）以及完整的Witnessd体系结构，结合多重独立可信检查点来生成和验证物理打字过程的加密证明。

**💡 创新点**

创新点在于：① 用抖动延迟作为可验证的物理过程证明；② 将多种独立可信组件（VDF、外部时间锚、双源键盘验证、TPM）串联形成“并行置信”机制，迫使对抗方必须提出一系列特定且可检验的指控；③ 引入对抗崩塌原则，将模糊疑点转化为可测试的攻击假设。

**🔧 技术方法**

使用技术包括：HMAC‑SHA256生成抖动值、Pietrzak VDF、Bitcoin/OpenTimestamps与RFC 3161时间戳、双源键盘事件（软件注入与硬件 HID）、TPM 2.0/Secure Enclave、Merkle Mountain Range（MMR）哈希链、以及对键盘区划、时间间隔桶等隐私保护的打字特征。

**📊 数据集**

实验数据集：31,000次jitter seal验证实验（1,000次正常验证，30,000次攻击实验）以及700+系统级单元/集成测试，涵盖VDF、MMR、TPM绑定、双源验证等模块。

**📈 对比分析**

比较与性能：所有1,000次正常验证通过；30,000次伪造尝试全部失败，伪造成功概率约为(1/2500)^50≈10^−170；jitter计算耗时286ns/样本，注入延迟500–3000µs；VDF检查约50ms；MMR追加不到1ms。系统在保持低误报的同时，实现了可验证过程证明和时间锚定的高效集成。

**⚠️ 局限性**

局限性：无法证明作者的认知或创意来源，仅证明物理打字；对键盘秘密（session secret）极度敏感，若被窃取即可伪造；kernel级别攻击者在捕获前即可破坏所有检查点；系统不支持后期生成，需实时记录；在高速打字或多人协作场景下成本线性增加。

---

## 432. Efficient Adversarial Attacks on High-dimensional Offline Bandits

**arXiv ID:** 2602.01658 | [PDF](https://arxiv.org/pdf/2602.01658v1)

**作者:** Seyed Mohammad Hadi Hosseini `[一作]` (Sharif University of Technology), Mahdieh Soleymani Baghshah `[通讯]` (Sharif University of Technology)

**通讯引用:** 1147 | [OpenAlex ID](https://openalex.org/A5069082023)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `6215c339-3735-4be3-8a07-5bbb7004712d` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究离线多臂赌博机（bandit）在评估生成模型时对奖励模型进行预训练扰动的攻击，并提出对应的防御方法。

**💡 创新点**

创新点：①提出在离线数据下对奖励模型权重进行小幅扰动即可导致bandit误判的攻击范式；②理论证明高维输入下攻击强度随维度增大而减小；③设计在线低成本的OSA（Score‑Aware）攻击；④提出随机打乱日志的一阶防御策略。

**🔧 技术方法**

技术：线性和ReLU神经网络奖励模型的线性化（NTK）、二次规划（QP）求解攻击、UCB/ETC/ε‑greedy等bandit算法的实现、对鲁棒bandit算法的评估、实验与理论结合。

**📊 数据集**

数据集：合成高维向量；真实图像生成模型（Stable Diffusion、Kandinsky、Openjourney等）在30个随机prompt下采样100个seed的输出；使用公开的Hugging Face奖励模型（Image Reward、Aesthetic Model）以及随机初始化的奖励模型。

**📈 对比分析**

比较结果：在UCB、ETC、ε‑greedy以及Fast–Slow、ε‑contamination等鲁棒bandit算法上，攻击实现100%成功率；OSA攻击相较完整QP大幅缩短计算时间；高维下攻击扰动幅度显著下降；随机噪声无效；防御方法能显著降低成功率。

**⚠️ 局限性**

限制：攻击需要对奖励模型权重的直接访问；理论依赖高维和非退化分布假设；防御只能部分缓解且需在日志级别实施；对更复杂奖励模型的泛化仍待验证；未提供对所有鲁棒算法的完全防御方案。

---

## 433. Low-Complexity Multi-Agent Continual Learning for Stacked Intelligent Metasurface-Assisted Secure Communications

**arXiv ID:** 2602.01653 | [PDF](https://arxiv.org/pdf/2602.01653v1)

**作者:** Enyu Shi `[一作]` (Beijing Jiaotong University), Chau Yuen `[通讯]` (Nanyang Technological University)

**通讯引用:** 41368 | [OpenAlex ID](https://openalex.org/A5060020877)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

本文研究了将多层智能金属表面（SIM）集成到多用户 MIMO 系统中，以实现基于波域的波束成形，完成单用户单波束发射并显著降低基带数字预编码的硬件复杂度。

**💡 创新点**

创新点包括：1）提出将 SIM 与 MIMO 结合的全新系统架构，避免传统基带预编码；2）构建 MHACL（流形增强异构多智能体持续学习）框架，将流形优化与持续学习融合，实现对高维、非凸、离散相位约束的高效联合功率与相位调制；3）设计 SIMHACL，利用产品流形嵌入将指数级搜索空间压缩为线性复杂度，保持物理可行性。

**🔧 技术方法**

采用的技术包括：Riemannian 流形优化、投影和重traction、强化学习（深度 Q / Actor-Critic）、梯度表示和动态梯度屏蔽、优先经验回放、双尺度策略优化以及持续学习机制。

**📊 数据集**

实验采用基于 28 GHz、10 MHz 带宽的仿真环境，随机生成用户与 eavesdropper 位置，并模拟 Rayleigh 相关衰落，未使用公开数据集。

**📈 对比分析**

与传统交替优化、仅功率分配、量化相位等基线进行对比；结果显示 SIMHACL 在保持接近 MHACL 的加密速率（WSSR）下，计算时间降低约 30%，收敛速度提升；WSSR 在 6 层 SIM 下提升约 86% 相较于 2 层配置，且在不同用户数、元原子数和相位分辨率的变化中均表现出优异性能。

**⚠️ 局限性**

局限性包括：1）对极大规模 SIM 或高度动态信道的鲁棒性仍待进一步验证；2）在极低功率或硬件相位误差较大时，SIMHACL 的性能会略有下降；3）算法依赖于精确的相位量化与模型假设，实际部署中对硬件实现误差的影响未完全评估。

---

## 434. From Perception to Action: Spatial AI Agents and World Models

**arXiv ID:** 2602.01644 | [PDF](https://arxiv.org/pdf/2602.01644v1)

**作者:** Gloria Felicia `[一作]` (AtlasPro AI), Esteban Rojas `[通讯]` (AtlasPro AI)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `51c0528b-f690-4182-ae60-bb5f046c276c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

对 agentic AI 与空间智能的交叉领域进行系统综述，提出三轴分类法（Task、Capability、Scale），对 2000+ 论文进行归类和分析，并识别六大未来挑战。

**💡 创新点**

① 统一三轴 taxonomy，将代理能力、空间任务和尺度三维映射；② 区分 spatial grounding 与 symbolic grounding，强调感知并不能直接赋予行动能力；③ 构建 SpatialAgentBench 框架，提出多轴、多尺度、长周期、安全评估等关键评测原则。

**🔧 技术方法**

综述涵盖 GNN‑LLM 集成、world models（latent dynamics、视频世界模型、LLM 预测）、多模态基础模型（VLM、SpatialVLM、NeRF 等）、SLAM、TAMP、神经网络隐式表示、图卷积网络等技术。

**📊 数据集**

引用的 benchmark 数据集包括 Habitat、AI2‑THOR、RLBench、Meta‑World、nuScenes、KITTI、ScanNet、AgentBench、WebArena、EmbodiedBench、SafeAgentBench 等，覆盖微观、介观、宏观尺度的多种任务。

**📈 对比分析**

通过对 742 论文的指标（SPL、mAP、mIoU、Safety Rate、Pass@k 等）进行对比，发现 68% 关注介观导航，微观操控与宏观地理推理仍显稀缺；GNN‑LLM 与 world‑model 方案在短期任务中表现突出，但在跨尺度、长期、sim‑to‑real、以及安全性能评估上仍存在显著缺口。

**⚠️ 局限性**

研究仅覆盖英文主要会议的文献，可能遗漏相关领域或非英文论文；提出的 taxonomy 为一种可行但非唯一的划分；SpatialAgentBench 仅为概念框架，缺乏实现与验证；行业案例基于公开信息，可能未涵盖最新实践；对最新近年的工作更新不足。

---

## 435. The Effect of Mini-Batch Noise on the Implicit Bias of Adam

**arXiv ID:** 2602.01642 | [PDF](https://arxiv.org/pdf/2602.01642v1)

**作者:** Matias D. Cattaneo `[一作]` (Princeton University), Boris Shigida `[通讯]` (Princeton University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一种理论框架，用于分析 Adam 优化器的动量参数 β1、β2 与批量大小如何通过微批噪声影响隐式正则化（对损失曲面尖锐度的偏好）和泛化性能。

**💡 创新点**

创新点在于：① 将带记忆的优化迭代拆解为无记忆主项 + 校正项；② 对校正项做批量平均，得到仅依赖 β1、β2、批量大小的显式表达式；③ 用该表达式解释 β1、β2 在低噪声（大批）和高噪声（小批）下的最佳取值及其逆向关系；④ 给出可操作的“经验法则”。

**🔧 技术方法**

技术手段包括：微分几何的梯度展开、批量平均近似、解析修正项、与尖锐度/平坦度指标（梯度范数、梯度噪声）对齐的理论推导；实验方面使用 Transformer‑XL 训练 WikiText‑2，并对 β1、β2 进行网格搜索，评估验证 perplexity。

**📊 数据集**

使用的数据集是 WikiText‑2（英文文本生成任务）和 Transformer‑XL 模型。

**📈 对比分析**

方法评估方式：对不同 β1、β2 组合以及不同批量大小进行实验，记录最低验证 perplexity。实验结果显示：在小批量下更大的 β2（如 0.999）可显著降低 perplexity（最高可提升 13%）；在大批量下 β1 需趋近 β2（如 0.999）以获得更好泛化，且两种超参数策略的性能差异随批量大小呈现明显的转折。

**⚠️ 局限性**

局限性包括：① 解析结果基于二阶噪声展开和无记忆近似，可能在极端批量或学习率下失效；② 需要估计“简单噪声尺度”B_simple，实际中不易精确；③ 结论主要针对小规模模型和文本生成任务，尚未在更大规模或其他任务上验证；④ 只给出方向性指导，无法提供精确的数值预测。

---

## 436. Chance-Constrained Inference for Hallucination Risk Control in Large Language Models

**arXiv ID:** 2602.01637 | [PDF](https://arxiv.org/pdf/2602.01637v1)

**作者:** Sreenivasan Mohandas `[一作]` `[通讯]` (International Institute of Information Technology), Sreenivasan Mohandas (International Institute of Information Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了基于机会约束的推理框架（Chance‑Constrained Inference, CCI），通过在推理时动态采样并使用任何时效置信序列对生成的不合法性概率进行概率控制，从而实现对大语言模型（LLM）幻觉风险的可验证、可调节控制。

**💡 创新点**

创新点在于：①将幻觉视为随机约束违背，首次将机会约束理论直接迁移至LLM推理；②利用任何时效Hoeffding置信序列实现自适应采样，避免固定样本的保守性；③将不可行输入直接归类为“不可行/未决”，实现安全拒绝与鲁棒组合；④提供正式的概率保证（1‑δ）并对多轮使用做安全合成。

**🔧 技术方法**

核心技术包括：随机生成模型的概率论表述；二元违约指示器与置信序列（任何时效Hoeffding）；分阶段采样与决策（可行、不可行、未决）；基于置信阈值的接受策略；以及对多重约束的分层/权重扩展。

**📊 数据集**

实验数据集为来自 NaturalQuestions 与 HotpotQA 的问答样本，按“易/中/难”划分；在 GROQ‑hosted LLaMA‑3.3‑70B 上进行随机采样，使用自动验证器评估幻觉，进一步对多跳推理场景进行控制。

**📈 对比分析**

与基准方法（基于置信度的选择性预测 Conf‑SP 与自一致性选择性预测 SC‑SP）比较，CCI 在可行输入上保持 100% 接受率，且所有被接受的样本违约率为 0%；而基准在难题上接受率为 100% 但违约率高达 0.9；CCI 在平均样本量 9–15 次之间完成决策，显著降低了采样成本。

**⚠️ 局限性**

主要局限包括：①依赖自动幻觉检测代理，若其错误率高则影响置信保证；②假设生成样本独立，实际解码过程中可能存在相关性；③未对模型进行微调或校准，限制了在更高风险预算下的灵活性；④对极端长文本或大规模多约束情形的可扩展性尚未充分验证。

---

## 437. A Closed-Form Geometric Retargeting Solver for Upper Body Humanoid Robot Teleoperation

**arXiv ID:** 2602.01632 | [PDF](https://arxiv.org/pdf/2602.01632v1)

**作者:** Chuizheng Kong `[一作]` (Institute for Robotics and Intelligent Machines), Shreyas Kousik `[通讯]` (Institute for Robotics and Intelligent Machines)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种闭式几何方法SEW‑Mimic，将人体肩‑肘‑手腕关键点映射到7‑DOF机器人臂，实现实时且最优的姿态重定向，并提供自碰撞安全过滤器。

**💡 创新点**

将重定向问题从位置误差转化为姿态对齐，利用SEW关键点实现无标定的闭式解析解，保证全局最优并大幅提升计算速度。

**🔧 技术方法**

使用解析几何逆运动学（子问题1/2闭式解）、RoD、XPBD自碰撞过滤、Meta Quest/MediaPipe关键点检测、Diffusion Policy等技术。

**📊 数据集**

主要使用Ubisoft LAFAN1上肢动作数据集、Kinova Gen3/RB‑Y1机器人实验数据，以及TWIST/GMR相关数据集。

**📈 对比分析**

与GMR、xr_teleoperate等基线比较，姿态对齐误差降至1.57×10⁻¹³，推理时间0.6 ms，速度提升1–3个数量级；在用户研究中提高成功率；安全过滤器将自碰撞率从约50%降至1.3%，但误差略增至0.019、计算时长约4 ms。

**⚠️ 局限性**

仅适用于人形机型；最优证明忽略关节限位与自碰撞；依赖关键点检测精度；安全过滤器缺乏正式证明；无线通信延迟仍需解决。

---

## 438. Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks

**arXiv ID:** 2602.01630 | [PDF](https://arxiv.org/pdf/2602.01630v1)

**作者:** Bohan Zeng `[一作]` (Peking University), Wentao Zhang `[通讯]` (Peking University)

**通讯引用:** 14676 | [OpenAlex ID](https://openalex.org/A5100459860)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `8d10c613-917e-4880-9716-17789f50e119` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文对当前世界模型研究进行系统梳理，指出其分散且多为任务专用，随后提出一套统一的“世界模型”框架，框架涵盖交互感知、推理、记忆、环境与多模态生成五大核心模块，并讨论如何在此框架下实现跨任务知识迁移与自适应演化。

**💡 创新点**

创新点在于：①提出“规范化”世界模型框架，强调模块化与标准接口，以解决碎片化研究导致的不可比性；②将环境建模视为可扩展的生成式模拟器，突破传统“物理引擎+场景”局限；③强调推理与生成闭环、记忆动态更新，以及自动反思与模块化演进的可行路径。

**🔧 技术方法**

技术手段主要是综述与整合：LLM/VLM 与显式/潜在推理、Transformer 长上下文记忆、Diffusion 生成、3D/4D 物理驱动表征、生成式环境仿真、RL 与自监督学习等。文中并未提出新的算法实现，而是提供技术选型与组合思路。

**📊 数据集**

论文本身未进行实验评测，不使用具体数据集；作者强调未来需要基于可扩展生成式仿真环境（如3D/4D 生成器、物理仿真器）与真实多模态数据（图像、视频、音频、点云等）进行验证。

**📈 对比分析**

由于是理论与框架设计，本文未给出数值比较；作者建议可在物理一致性、记忆连贯性、跨模态推理准确率、多模态生成真实性等指标上与现有任务专用方法做基准对比。目前该框架仍处于概念验证阶段。

**⚠️ 局限性**

局限性包括：①实现难度大，缺乏统一的实现与评测标准；②生成式环境与真实物理的 Sim‑to‑Real 桥接不完善；③跨模态推理与长期记忆的技术瓶颈；④自动反思与自我更新机制尚无成熟实现；⑤在大规模场景下的计算与存储开销仍是挑战。

---

## 439. The Multiple Ticket Hypothesis: Random Sparse Subnetworks Suffice for RLVR

**arXiv ID:** 2602.01599 | [PDF](https://arxiv.org/pdf/2602.01599v1)

**作者:** Israel Adewuyi `[一作]` (Innopolis University), Vladmir Ivanov `[通讯]` (Innopolis University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究在 Reinforcement Learning with Verifiable Rewards（RLVR）训练中使用随机稀疏子网络，并验证存在大量互不重叠的可行子网络（Multiple Ticket Hypothesis）。

**💡 创新点**

提出即使在 99%+ 稀疏率下，仅训练 1% 参数即可匹配或超过全参数 fine‑tuning，且随机抽样即可找到成功子网络，说明预训练模型具有巨大的参数冗余，而非仅有单一 “winning ticket”。

**🔧 技术方法**

采用 RLVR（GRPO）算法、随机稀疏掩码、KL 约束的几何分析以及 Fisher 信息矩阵的低秩性质推导，解释为何随机子网络能成功。

**📊 数据集**

使用 Qwen2.5-0.5B 与 1.5B 模型，在数学推理任务 GSM8K、MATH‑500 以及逻辑推理任务 Alphabet Sort 上进行实验。

**📈 对比分析**

对比全参数 RLVR fine‑tuning，使用多种随机掩码并记录平均性能与标准差，结果显示 99% 稀疏率下性能与全参数相当甚至略优；当稀疏率超过 99.99% 时性能急剧下降。

**⚠️ 局限性**

存在模型崩溃和极稀疏训练不稳定；对更复杂任务或更大规模模型的验证不足；未充分评估随机稀疏训练对灾难性遗忘的影响。

---

## 440. Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework

**arXiv ID:** 2602.01593 | [PDF](https://arxiv.org/pdf/2602.01593v1)

**作者:** Wenzhuo Zhao `[一作]` (Sichuan University), Guangtao Zhai `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 21105 | [OpenAlex ID](https://openalex.org/A5064168853)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种基于Mamba状态空间模型的统一显著性检测框架Samba及其多任务版本Samba+，能够同时处理RGB、RGB‑D、RGB‑T、视频、VDT等多种SOD任务。

**💡 创新点**

创新点包括：①首次将Mamba引入SOD，解决CNN感受野小、Transformer复杂度高的问题；②设计Saliency‑Guided Mamba Block（SGMB）配合空间邻域扫描（SNS）保持显著区域空间连续性；③提出上下文感知上采样（CAU）实现层级特征对齐；④在Samba+中加入Hub‑and‑Spoke Graph Attention（HGA）实现跨模态融合，以及Modality‑Anchored Continual Learning（MACL）实现多任务联合训练，消除任务特化和灾难性遗忘。

**🔧 技术方法**

采用Mamba（SSM）+ SNS扫描 + SGMB + CAU + HGA + MACL + SIR等技术，辅以卷积、注意力、可学习上采样和自监督策略。

**📊 数据集**

使用22个SOD基准数据集（RGB：DUTS、DUT‑O、HKU‑IS、PASCAL‑S、ECSSD；RGB‑D：NJUD、NLPR、SIP、STERE、DUTLF‑D；RGB‑T：VT821、VT1000、VT5000；VSOD：DAVIS、DAVSOD‑easy、FBMS、SegV2、VOS；RGB‑D VSOD：RDVS、DVisal、ViDSOD；VDT：VDT‑2048）以及COD、皮肤病变分割（ISIC2017/18）等。

**📈 对比分析**

与22个SOD任务中10+ CNN/Transformer主流方法对比，Samba在所有22个数据集上均超越SOTA，参数与算力低；Samba+在单模型下进一步提升跨任务性能，达到或超过各个任务的最佳单模型，同时仅使用约59M参数、96G FLOPs，显著提升统一性与效率。

**⚠️ 局限性**

局限性在于多任务联合训练仍需克服数据不平衡与任务间干扰，MACL虽缓解但未完全消除；Mamba在极大规模或稀疏场景下的可扩展性与鲁棒性尚待验证；部分多模态融合模块仍显复杂，模型可进一步简化。

---

## 441. PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards

**arXiv ID:** 2602.01624 | [PDF](https://arxiv.org/pdf/2602.01624v1)

**作者:** Minh-Quan Le `[一作]` (Microsoft), Mei Chen `[通讯]` (Microsoft)

**通讯引用:** 2409 | [OpenAlex ID](https://openalex.org/A5100331492)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出一种全无人工标注的文本到视频后训练框架，利用双重最优传输（OT）对文本与视频嵌入空间进行对齐，并在此基础上设计质量与语义两种奖励，实现对生成视频的全局视觉质量和细粒度语义一致性的提升。

**💡 创新点**

创新点在于：①首次将最优传输技术应用于文本‑视频嵌入的分布级对齐与令牌级对齐；②提出分布式OT质量奖励与离散OT语义奖励双重模块，既保留整体结构又强化细粒度语义匹配；③证明该无标注奖励方案可与直接反向传播和强化学习共同使用，兼具可扩展性与高效性。

**🔧 技术方法**

核心技术包括：最优传输（OT）与离散最优传输（POT）求解器；基于InternVideo2的预训练视觉‑语言模型；神经最优传输网络（NOT）学习文本到视频的映射；跨模态注意力与OT引导的注意力融合；奖励驱动的后训练损失（直接反向传播或GRPO）。

**📊 数据集**

使用的数据集主要包括WebVid10M与VidGen-1M（训练集），短视频任务采样2s @ 8FPS的VideoCrafter2，长视频任务采样5s @ 25FPS的HunyuanVideo；评估数据集为VBench（16维度质量与语义评分）以及400条提示的人类偏好评测。

**📈 对比分析**

在VBench自动评测中，本文模型在短视频与长视频的质量得分、语义得分和总分均超过所有基线（包括基于人类偏好的VideoReward-DPO、T2V‑Turbo‑v2等）并在人工评测中持续领先；实验表明双重OT奖励分别提升了质量约1.6分和语义约3.5分，合并后可获得最佳整体性能。

**⚠️ 局限性**

局限性主要体现在：①仍依赖预训练的VLM嵌入，若其自身对齐不足可能影响奖励的有效性；②OT计算在大规模数据上会增加训练开销；③对极端长时序或非常细粒度动作的语义捕捉尚未完全验证；④缺少对生成视频内容安全与伦理风险的系统评估。

---

## 442. Token Pruning for In-Context Generation in Diffusion Transformers

**arXiv ID:** 2602.01609 | [PDF](https://arxiv.org/pdf/2602.01609v1)

**作者:** Junqing Lin `[一作]` (University of Science and Technology of China), Guangzhong Sun `[通讯]` (University of Science and Technology of China)

**通讯引用:** 6172 | [OpenAlex ID](https://openalex.org/A5100932403)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种无训练、可动态的 Token Pruning 框架 ToPi，专门针对 Diffusion Transformers 的上下文生成任务，旨在在保持生成质量的前提下显著降低计算量。

**💡 创新点**

创新点在于：①通过离线校准发现“代表性”关注层，筛选对上下文敏感的层；②提出结合注意力权重与值向量的“影响度”指标，用于衡量每个参考 token 的重要性；③设计按时间步更新的稀疏掩码机制，使剪枝与扩散过程同步；④所有步骤均不需要额外训练。

**🔧 技术方法**

技术实现包括：离线校准的上下文敏感度评分、基于注意力与值向量的影响度计算、按阈值的贪心稀疏化、以及位置对齐的上下文重排；实现细节基于 Flux.1‑Kontext 和 Qwen‑Image‑Edit 的 Diffusion Transformers。

**📊 数据集**

数据集与任务：AnyEdit 基准（Camera Move、Global Edit、Implicit Change、Local Edit）以及 Flux.1‑Kontext 与 Qwen‑Image‑Edit 两种模型，使用 VAE 编码的潜在空间作为输入。

**📈 对比分析**

与 ToMeSD、ToMA 等基线对比，ToPi 在 PSNR、SSIM 上提升 2–5 分，LPIPS 降低 0.03–0.15，推理速度提升 1.2–1.3×，组合使用 TeaCache 可达 2.34× 的累计加速，展示了显著的质量与效率双赢。

**⚠️ 局限性**

局限性：仅在图像编辑任务上验证，缺乏对高分辨率、长序列视频或更复杂跨模态任务的评估；方法依赖预先构建的校准数据集，可能对新领域的泛化不充分；稀疏化过程中若阈值设定不当，仍可能影响细节与多样性。

---

## 443. Universal Redundancies in Time Series Foundation Models

**arXiv ID:** 2602.01605 | [PDF](https://arxiv.org/pdf/2602.01605v1)

**作者:** Anthony Bao `[一作]` (University of Texas at Austin), William Gilpin `[通讯]` (University of Texas at Austin)

**通讯引用:** 1517 | [OpenAlex ID](https://openalex.org/A5090794745)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文通过中间层残差流分析、直接logit归因和头部级消融，系统性识别了多种时间序列基础模型（TSFMs）中的冗余组件，并提出了基于核回归的理论框架和稳定秩（stable rank）驱动的自适应头部消融方法。

**💡 创新点**

创新点在于：①证明并量化TSFMs中中间层高度冗余；②构建Transformer的核回归解释模型，为“情境重复（parroting）”和季节性偏差提供理论根源；③提出无监督、数据无关的稳定秩头部消融策略，显著压缩模型而几乎不损失性能；④开发了一套面向TSFM的机制可解释工具箱，方便后续分析与压缩。

**🔧 技术方法**

主要技术包括：Transformer残差流监测、直接logit归因（DLA）、全层和单头消融实验、核回归理论推导、稳定秩计算与头部排序、对比分析与可视化。

**📊 数据集**

使用的公开数据集和基准为：GIFT‑Eval（零样本时间序列预测基准）以及多组真实与合成时间序列数据；评估模型涵盖Chronos、TimesFM 2.5、Toto、Moirai等主流TSFM。

**📈 对比分析**

与现有领先TSFM相比，本文方法在保持≤6%性能下降的前提下，能够消除约28%的注意力头；实验表明即使大幅消融中间层或头部，模型仍保持相对完整的预测能力，验证了冗余理论与消融策略的有效性。

**⚠️ 局限性**

局限性包括：①研究聚焦于已公开的TSFM，未覆盖所有可能的架构或更大规模模型；②核回归理论假设可能不足以刻画所有非线性时序依赖；③消融策略在不同任务或领域（如多变量、非平稳序列）中的鲁棒性仍待进一步验证。

---

## 444. Spectral-Aligned Pruning for Universal Error-Correcting Code Transformers

**arXiv ID:** 2602.01602 | [PDF](https://arxiv.org/pdf/2602.01602v1)

**作者:** Sanghyeon Cho `[一作]` (Pohang University of Science and Technology), Yongjune Kim `[通讯]` (Pohang University of Science and Technology)

**通讯引用:** 622 | [OpenAlex ID](https://openalex.org/A5025186204)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `edb9d762-f411-4838-a852-f2d638b018db` `8d10c613-917e-4880-9716-17789f50e119`

**🎯 论文内容**

本文提出了一种基于谱对齐的结构化剪枝框架（SAP），能够在统一的Transformer型错误校正码（ECC）解码器中共享剪枝掩码并通过LoRA适配恢复解码性能。

**💡 创新点**

创新点在于：①使用双边图谱的谱特征来衡量不同码之间的结构相似性，从而实现剪枝掩码的跨码重用；②引入剪枝掩码库和阈值决策机制，显著降低每个码的剪枝搜索成本；③结合LoRA的参数高效恢复，实现共享的剪枝后骨干网络与代码特定小量适配器的组合。

**🔧 技术方法**

技术方法包括：Transformer结构化剪枝（头与FFN通道），Fisher重要性评估，双边图谱谱特征提取与相似度计算，阈值重用策略，LoRA低秩适配器训练以及可选的知识蒸馏辅助。

**📊 数据集**

实验数据集涵盖多种ECC码：BCH、LDPC、Polar以及5G NR LDPC，训练场景为BPSK+AWGN的全零码词，SNR从2到7 dB采样。

**📈 对比分析**

与专用码级剪枝、全量微调以及传统BP解码进行对比，结果显示SAP在保持接近专用剪枝的BER性能（Δ>-0.15）的同时，FLOPs下降约40%，骨干参数减少约7%，LoRA适配器仅占全模型约7-10%，证明了其高效性与可行性。

**⚠️ 局限性**

局限性包括：①对谱相似性阈值敏感，低相似码的重用效果差；②需预先构建并维护掩码库；③实验仅覆盖AWGN和上述码族，未评估其它信道或更大码长；④未结合量化或硬件实现评估。

---

## 445. FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning

**arXiv ID:** 2602.01664 | [PDF](https://arxiv.org/pdf/2602.01664v1)

**作者:** Mingda Zhang `[一作]`, Erik Cambria `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种名为 FlowSteer 的端到端强化学习框架，用轻量级策略模型与可执行画布环境进行多轮交互，自动化地构建并优化可执行工作流。

**💡 创新点**

创新点包括：① 将工作流构建视作强化学习任务，引入可执行画布回馈；② 设计了 Canvas Workflow Relative Policy Optimization (CWRPO)，通过多样性约束奖励和条件释放机制实现结构完整性与答案正确性的双重优化；③ 兼容插件化操作符库与可插拔 LLM 后端，实现高可迁移性和低手工成本。

**🔧 技术方法**

核心技术包括：轻量级策略网络、可执行画布环境、可插拔操作符（12 类）与 LLM 后端、CWRPO 强化学习算法、分层决策与多轮交互、结构化奖励设计。

**📊 数据集**

使用了 12 个基准数据集（数学推理：GSM8K、MATH；问答：HotPotQA、SQuAD v2；代码生成：MBPP、HumanEval；OOV 评测：TriviaQA、NaturalQuestions、MathQA、AIME 2025、APPS、DS‑1000）。

**📈 对比分析**

与多种基线（直接 LLM、SFT、GRPO、AFlow、AgentFlow、Router‑R1、Orchestrator）对比，FlowSteer 在所有任务上均取得显著提升，例如 GSM8K 94.53→96.09、MATH 71.81→81.25、HotPotQA 73.28→78.12、SQuAD v2 82.19→84.98、MBPP 89.06→92.96、HumanEval 63.44→83.67。性能提升范围从 1% 以上到 15%+，且在 OOD 场景保持稳健。

**⚠️ 局限性**

局限性：① 仍需依赖 LLM 后端的计算资源，训练成本较高；② 目前仅覆盖 12 种操作符，若任务超出其范畴需扩展操作符库；③ 对极长或极复杂的工作流，交互回合数可能增长，导致执行效率下降；④ 需要手工定义奖励阈值和多样性约束，调参较为繁琐。

---

## 446. On the Spatiotemporal Dynamics of Generalization in Neural Networks

**arXiv ID:** 2602.01651 | [PDF](https://arxiv.org/pdf/2602.01651v1)

**作者:** Zichao Wei `[一作]` `[通讯]` (Saarland University), Zichao Wei (Saarland University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `c773407a-6119-4871-b8b3-1e7ae17a6851` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

通过引入局部性、对称性和稳定性三条物理后验，提出了 SEAD（Spatiotemporal Evolution with Attractor Dynamics）架构，并在长度泛化任务（奇偶校验、二进制加法、Rule 110 细胞自动机）上实现了从 16 位到 10⁶ 位的 100% 端到端准确率。

**💡 创新点**

创新点包括：① 用物理定律推导而非经验设计得到的通用约束；② 在训练阶段采用连续卷积 CNN，推断阶段转为离散细胞自动机，利用“吸引子”实现噪声自纠和无损信息传播；③ 证明了该架构可实现 Turing 完备性，说明其理论计算能力与符号系统相当。

**🔧 技术方法**

技术实现：基于 1D 卷积网络的局部演化算子，Softmax 预测下一步状态；推断阶段采用 Relax‑and‑Project 循环（连续计算后硬投影到离散符号）；使用跨步自回归训练（Chaos Training）以及交叉熵损失；实验采用统一的序列长度差异化评估。

**📊 数据集**

数据集：对每个任务随机生成的序列，奇偶校验、加法与 Rule 110 的输入序列分别在长度 16 或 32 训练，测试在 10⁴、10⁵、10⁶ 等更长长度上；无额外公开数据集，全部为自生成的符号序列。

**📈 对比分析**

对比方法：Transformer（含全局注意力）、Neural GPU、循环模型等传统架构；在长度泛化指标上，SEAD 在所有任务上均保持 100% 准确率，且推断步骤严格线性或更低；相比 Transformer 仅能提升 2‑3 倍，SEAD 可突破 62 500 倍；实验展示了推断时间随长度线性增长，且不受噪声累积影响。

**⚠️ 局限性**

局限性：① 训练需要每步的 ground‑truth 状态（监督式单步规则学习），不适用于仅有最终标签的任务；② 对极其复杂或高维逻辑问题的可扩展性尚未验证；③ 在实现中仍需手工设定卷积窗口大小、投影阈值等超参；④ 对现实世界物理数据的自动法则发现能力仍是未来工作。

---

## 447. De Novo Molecular Generation from Mass Spectra via Many-Body Enhanced Diffusion

**arXiv ID:** 2602.01643 | [PDF](https://arxiv.org/pdf/2602.01643v1)

**作者:** Xichen Sun `[一作]` (Sun Yat-sen University), Yuedong Yang `[通讯]` (Sun Yat-sen University)

**通讯引用:** 12597 | [OpenAlex ID](https://openalex.org/A5023539493)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

开发了一种基于多体注意力的扩散模型MBGen，用于从质谱数据生成分子结构

**💡 创新点**

创新点在于：①边中心化建模，将化学键作为基本单元；②引入多体注意力机制捕捉三体及更高阶的键相互作用；③预训练-微调流程结合MIST谱编码器和基于指纹的解码器

**🔧 技术方法**

技术方法包括：扩散生成网络、边级消息传递、FiLM调制、多体注意力模块、Set Transformer谱编码、预训练与联合微调

**📊 数据集**

使用的主要数据集为NPLIB1和MassSpecGym，预训练阶段采集2.8M指纹-分子对（DSSTox、HMDB、COCONUT、MOSES）

**📈 对比分析**

与Spec2Mol、MIST+NeuralDecipher、MIST+MSNovelist、MADGEN、DiffMS、SMILES/SELFIES Transformer等方法对比，MBGen在NPLIB1 Top‑1精度提升至12.20%（比DiffMS的8.34%提升约53%），在MassSpecGym Top‑1提升至7.58%（比DiffMS的2.30%提升约230%），同时在Top‑10、MCES和Tanimoto分数上均实现显著提升

**⚠️ 局限性**

局限性包括：仍然存在低于50%的Top‑1准确率，对大分子（>40原子）生成效果有待提升；多体注意力计算开销较大；模型对谱质量与噪声的鲁棒性需要进一步验证

---

## 448. COMET: Codebook-based Online-adaptive Multi-scale Embedding for Time-series Anomaly Detection

**arXiv ID:** 2602.01635 | [PDF](https://arxiv.org/pdf/2602.01635v1)

**作者:** Jinwoo Park `[一作]` (Seoul National University), Pilsung Kang `[通讯]` (Seoul National University)

**通讯引用:** 4396 | [OpenAlex ID](https://openalex.org/A5059650940)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `9ce7179e-700c-4310-ac2b-91df50ded46e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在多变量时间序列异常检测中，本文提出了COMET框架，利用多尺度补丁编码、向量量化核心集和在线代码簿适应进行异常检测。

**💡 创新点**

创新点包括多尺度补丁编码捕捉不同时间尺度的依赖与变量间关联、基于向量量化的核心集构造有限记忆银行以及通过代码簿激活伪标签实现无阈值的在线适应。

**🔧 技术方法**

采用的技术包括线性补丁编码、共享核心编码器、向量量化（VQ）、记忆距离与量化误差双重评分、局部缩放距离、对比学习以及指数滑动归一化。

**📊 数据集**

在五个工业数据集（PSM、SWaT、SMAP、MSL、WADI）上进行实验。

**📈 对比分析**

与LSTM‑AE、VTT、CATCH、D3R等基线相比，COMET在45项评估指标中赢得39项，且在多尺度和无标记在线适应下仍保持高效、参数少。

**⚠️ 局限性**

局限性包括仍需人工设定多尺度参数、在线适应可能受限于测试样本中异常比例过高且对极端分布漂移的鲁棒性尚未充分验证。

---

## 449. Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?

**arXiv ID:** 2602.01623 | [PDF](https://arxiv.org/pdf/2602.01623v1)

**作者:** Susan Liang `[一作]` (University of Rochester), Chenliang Xu `[通讯]` (University of Rochester)

**通讯引用:** 6387 | [OpenAlex ID](https://openalex.org/A5064805926)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文构建了 Omni-Judge——一种基于 omni‑LLM 的统一评估框架，用来给文本到音视频生成模型的九个维度（视频/音频质量、语义对齐、时序同步等）打分并提供可解释反馈。

**💡 创新点**

创新点在于①首次将 omni‑LLM 用作跨文本、视频、音频三模态的整体评判器；②通过任务专用指令与链式推理实现可解释的分数和错误定位；③在语义对齐等高层次任务上，Omni‑Judge 的相关性与人类评估媲美甚至超越传统指标。

**🔧 技术方法**

技术包括 Qwen3‑Omni 大模型、链式思维提示、任务特定指令设计、与传统指标（FVD、FAD、CLIP、ImageBind、Synchformer 等）对照的实验评估。

**📊 数据集**

数据集为 VidProM 真实用户文本提示（300 条），以及基于这些提示用 Sora 2 与 Veo 3 生成的音视频内容。

**📈 对比分析**

评估方式：对每个维度分别计算 Kendall、Spearman、Pearson 与人工评分的相关性。结果显示 Omni‑Judge 在音视频对齐、三模态一致性等语义任务上与人类评估的相关性与传统指标相当或更高，但在视频质量、音视频同步等低层次、对帧率敏感的指标上相关性偏低。

**⚠️ 局限性**

局限性：由于 omni‑LLM 的时间分辨率受限，难以捕捉细粒度的视觉抖动与短时音视频同步误差；对高帧率输入的利用不足，导致在低层次感知度量上的表现不佳。

---

## 450. SEA-Guard: Culturally Grounded Multilingual Safeguard for Southeast Asia

**arXiv ID:** 2602.01618 | [PDF](https://arxiv.org/pdf/2602.01618v1)

**作者:** Panuthep Tasawong `[一作]` (VISTEC), Peerat Limkonchotiwat `[通讯]` (AI Singapore)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文提出了面向东南亚八种语言的多模态安全防护模型 SEA‑Guard，并设计了面向文化语境的代理式数据生成框架，用于构建规模可观、质量可控的安全数据集。

**💡 创新点**

创新点在于：① 通过多代理、LLM 与文化专家协同生成、标注和验证数据，实现对文化细节与安全等级的细粒度掌控；② 引入 Monte Carlo Reasoning Ensemble（MCRE）进行多路径推理和概率化标签，显著提升标注准确性和不确定性建模；③ 通过词袋去重、人工校验等手段，剔除表面相似、易被攻击的样本，增强模型鲁棒性。

**🔧 技术方法**

技术方法包括：多语言 LLM（Gemma‑SEA‑LION、Llama3.1、Qwen‑SEA‑LION 等）进行样本生成；代理式提示与 persona 结合生成多文化语境；MCRE 进行零样本安全标注；数据增强（同义改写）与 bag‑of‑words 去重；最后以三种规模（4B、8B、12B）在自研数据集上 fine‑tune 成安全检测器。

**📊 数据集**

数据集方面，构建了 870k 条样本/语言的 SEA 文化安全数据集（涵盖 53 个文化类别，如食物、节庆、政治等），并在 32 名母语 annotator 处进行人工校验；实验使用 SEA‑SafeguardBench、SEALS、SafeQA 进行多语言文本评测，零样本时也在 VSCBench、VLGuard、MSSBench 进行视觉‑文本安全评估。

**📈 对比分析**

与现有安全模型（ShieldGemma、LlamaGuard、PolyGuard 等）对比，SEA‑Guard 在 SEA‑SafeguardBench 上 prompt/response AUPRC 均超过 99%，显著优于对手；在通用安全基准上亦保持竞争力；在零样本视觉‑文本安全基准中，SEA‑Guard 在 6/7 项任务中领先，表明仅用文本监督即可实现跨模态安全性能。

**⚠️ 局限性**

局限性包括：① 仅覆盖八种东南亚语言，缺少 Khmer、Lao 等；② 未在 0.5B 规模模型上验证；③ 评测基准主要是英语或机器翻译，可能忽略部分文化细节；④ 生成数据虽经过验证但仍为人工合成，可能存在不可预见的偏差；⑤ 仅针对文本安全进行训练，视觉安全仍是零样本推理，未进行专门微调。

---

## 451. Boosting Maximum Entropy Reinforcement Learning via One-Step Flow Matching

**arXiv ID:** 2602.01606 | [PDF](https://arxiv.org/pdf/2602.01606v1)

**作者:** Zeqiao Li `[一作]` (Tianjin University), Zhiqiang Zuo `[通讯]` (Tianjin University)

**通讯引用:** 6385 | [OpenAlex ID](https://openalex.org/A5037713727)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `40105733-5154-44cd-8090-a8cab9e64b07` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了FLAME框架，融合流匹配（Flow Matching）与最大熵强化学习，实现一阶行动生成的表达式策略。

**💡 创新点**

创新点：①通过Q‑Reweighted流匹配目标绕过能量分区函数；②设计分离熵估计（FLAME‑R无偏估计、FLAME‑M解耦多步估计）解决离散化偏差；③集成MeanFlow实现高保真一阶采样。

**🔧 技术方法**

使用技术：流匹配、MeanFlow、最大熵RL、重要抽样、Hutchinson trace估计、LogSumExp、截断正态采样等。

**📊 数据集**

数据集：MuJoCo连续控制任务（HalfCheetah、Humanoid、Ant、Walker2d等）以及视觉DeepMind Control Suite。

**📈 对比分析**

与经典模型自由RL（PPO、TD3、SAC）、多步扩散策略（DIPO、DACER、QSM、QVPO、SDAC、DPMD）以及流策略基线（FPMD、FlowRL、MEOW）对比。FLAME在MuJoCo任务上单步采样即可达到或超过多步扩散基线，性能优于高斯基线，并保持低推理延迟。

**⚠️ 局限性**

局限性：训练阶段需多步积分估计，导致计算开销增加；在高维动作空间的可扩展性尚待验证；在视觉RL中的表现相对有限；对分区函数的估计仍可能存在残余偏差。

---

## 452. The Art of Socratic Inquiry: A Framework for Proactive Template-Guided Therapeutic Conversation Generation

**arXiv ID:** 2602.01598 | [PDF](https://arxiv.org/pdf/2602.01598v1)

**作者:** Mingwen Zhang `[一作]` (Lanzhou University), Bin Hu `[通讯]` (Lanzhou University)

**通讯引用:** 23486 | [OpenAlex ID](https://openalex.org/A5100380066)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出Socratic Inquiry Framework（SIF），通过分离何时提问和怎样提问，将LLM从被动倾听转变为主动认知引导；

**💡 创新点**

创新点在于引入可插拔的策略锚定与模板检索模块，实现基于临床策略的主动提问，同时不需端到端重新训练；

**🔧 技术方法**

采用策略锚定（Strategy Anchoring）与模板检索（Template Retrieval）两阶段规划，结合LoRA微调的对话生成模型；

**📊 数据集**

使用自建的SocRatic‑QA数据集（约17.9K样本），该数据集通过多维临床标准过滤，确保高质量的Socratic问答；

**📈 对比分析**

对比了30B+大型通用LLM、心理学专用LLM以及小型（≤10B）开源LLM，SIF在自动指标（如BERTScore、BLEURT、ROUGE）和人类评估（策略完整性、专业性、真实性、伦理安全）上均显著提升，单轮PQA提升最高达0.87，整体表现位居同类模型首位；

**⚠️ 局限性**

局限包括：数据以中文咨询为主，跨文化、跨语言推广受限；评估主要基于模拟对话，缺乏真实临床验证；受评审者规模与专业背景有限，可能存在评价偏差。

---

## 453. AgenticLab: A Real-World Robot Agent Platform that Can See, Think, and Act

**arXiv ID:** 2602.01662 | [PDF](https://arxiv.org/pdf/2602.01662v1)

**作者:** Pengyuan Guo `[一作]` (Purdue University), Yu She `[通讯]` (Purdue University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了AgenticLab平台和基准，用于在真实机器人中评估开源VLM驱动的闭环任务执行与自适应重规划。

**💡 创新点**

提出了模型无关的闭环推理管道，兼容任意大模型，并在真实世界中公开硬件软件堆栈，实现可复现的开放世界操控基准。

**🔧 技术方法**

结合多视角RGB‑D感知、PDDL符号规划、VLM任务解析、动作检验与抓取评估，以及实时视觉验证与重规划机制。

**📊 数据集**

通过在实验室、厨房和户外三种环境下构建的五项实操任务（排序、堆叠、填字、重新定向、厨房重排）收集真实机器人数据。

**📈 对比分析**

对八种主流VLM（Gemini, Qwen, GPT, Claude 等）在排序任务上做端到端与模块级别对比，Gemini Flash 达到 75% 成功率，其他模型性能低迷；验证模块是性能瓶颈，稀疏验证提高速度但易失效。

**⚠️ 局限性**

受限于手工编写的 PDDL 域和预定义动作原语、验证延迟以及对模型尺寸的依赖，未来需自动化域建模与轻量化验证。

---

## 454. From Frames to Sequences: Temporally Consistent Human-Centric Dense Prediction

**arXiv ID:** 2602.01661 | [PDF](https://arxiv.org/pdf/2602.01661v1)

**作者:** Xingyu Miao `[一作]` (Durham University), Yang Long `[通讯]` (Durham University)

**通讯引用:** 2706 | [OpenAlex ID](https://openalex.org/A5011037821)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `6514db3d-8de6-452c-91b7-acdb31787cc4` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

构建了可扩展的合成数据管道，生成光照逼真的人类静态图像与动态视频序列，并在此基础上训练了一种统一的 ViT‑based 密集预测模型，能够在视频中实现人类深度、法向和前景分割的时序一致预测。

**💡 创新点**

创新点包括：① 结合了时间对齐的动态序列与像素级静态标签的合成数据；② 在 Transformer 编码器中注入 CSE 人体几何先验并通过轻量级通道自适应模块提升几何特征可靠性；③ 两阶段训练策略（先静态预训练再动态时序微调）显著提升了视频预测的时序一致性。

**🔧 技术方法**

核心技术：ViT‑based dense prediction backbone（DINOv3 + DPT 解码器），CSE（Continuous Spatial Embedding）人体先验，通道自适应重加权（CWA），时间块（Temporal Blocks）与光流对齐的时序一致性损失。

**📊 数据集**

数据集：合成数据（约 2M 静态 + 4M 动态样本），以及公开真实数据集 THuman2.1、Hi4D、P3M‑500、PPM‑100 用于评估。

**📈 对比分析**

与现有方法（Sapiens、DAViD、Depth Anything、Moge 等）相比，在 THuman2.1、Hi4D 的深度、法向、分割任务上均实现或超越 state‑of‑the‑art，且在视频时序一致性指标（OPW、TC‑RMSE、TC‑Mean、TC‑Abs）上亦表现优异。

**⚠️ 局限性**

局限性：合成数据与真实场景仍存在域差异；模型对大规模视频训练需求高；目前主要针对单人/多人的人体场景，尚未在复杂背景或多物体混合环境中充分验证。

---

## 455. CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation

**arXiv ID:** 2602.01660 | [PDF](https://arxiv.org/pdf/2602.01660v1)

**作者:** Zhongyuan Peng `[一作]` (Fudan University), Yixin Cao `[通讯]` (Fudan University)

**通讯引用:** 5579 | [OpenAlex ID](https://openalex.org/A5013247988)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `a4b10f5d-130b-4e77-9367-6469ec621899` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出CoDiQ框架，能够在推理时通过测试时缩放实现高难度、可验证的数学和编程问题生成；

**💡 创新点**

1) 六种难度增强策略；2) 通过强化学习训练CoDiQ-Generator；3) 引入相对难度范式与ValueNetwork的连续难度评分；4) 通过混合验证模块保证逻辑一致性；

**🔧 技术方法**

强化学习（GRPO+VeRL）、LLM推理（Qwen3系列、Doubao-Seed-1.8、Qwen3-32B等）、价值网络（MLP）、自适应token预算、对比排名、随机洗牌等；

**📊 数据集**

CoDiQ-Corpus（44K竞赛级数学与编码题目），CoDiQ-Bench（200道测试题），以及对比基准如AIME、NuminaMath-1.5、LiveCodeBench、Code-Contests；

**📈 对比分析**

与多种大型推理模型（GLM-4.6、GPT-OSS-20B、Qwen3系列）在CoDiQ-Bench上对比；CoDiQ-Gen-8B在生成难度和可验证率上超过大模型；在AIME、MATH-500等任务中，基于CoDiQ-Corpus的梯度学习模型表现优于传统RL或无分层训练；

**⚠️ 局限性**

仅适用于英文数学/编码任务；验证器容量限制导致“Verifier Paradox”，高难度合法题被误判为不可解；实时推理受限于验证成本；

---

## 456. ProjDevBench: Benchmarking AI Coding Agents on End-to-End Project Development

**arXiv ID:** 2602.01655 | [PDF](https://arxiv.org/pdf/2602.01655v1)

**作者:** Pengrui Lu `[一作]` (Shanghai Jiao Tong University), Ming-Hsuan Yang `[通讯]` (University of California Merced)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并实现了ProjDevBench，一个端到端项目开发评估基准，包含20个从零开始或完善项目的真实任务，并采用在线评测与LLM辅助代码评审的双重评估流程。

**💡 创新点**

创新点在于：①专注于完整项目构建而非单文件或补丁；②通过结合在线判题与LLM代码评审，兼顾功能正确性与规范合规；③引入多轮交互评估，能捕捉代理在长时间迭代中的表现与瓶颈。

**🔧 技术方法**

使用的技术包括：大语言模型（GPT‑5、Claude Sonnet 4.5、Gemini 3 Pro Preview 等），Rule‑based 与 LLM‑based 代码评审脚本，Online Judge（OJ）平台进行功能与性能测试，Agent 框架（Cursor、GitHub Copilot、Augment、Codex CLI、Claude Code 等）与多轮交互日志分析。

**📊 数据集**

采用了20个从在线竞赛平台筛选出的项目级任务，覆盖8个类别（数据结构、解释器、管理系统、存储组件等），每个任务均提供完整需求说明、构建配置和针对功能与边界的全套测试用例。

**📈 对比分析**

比较方法：在每个 Agent‑Model 组合上进行一次完整评测，计算执行分数、代码评审分数和加权最终分数。结果显示 Codex + GPT‑5 取得最高最终分（77.85），其他组合如 Augment+GPT‑5、Cursor+GPT‑5 均在70以上；总体通过率仅27.38%，且复杂任务（从零开始）时性能下降显著。

**⚠️ 局限性**

局限性：仅包含20个任务，主攻 C++，难以快速扩展；完全自主模式不涉及人机交互；未验证在其他语言或更大规模项目中的表现；评测难度主要体现在长交互而非代码量，说明当前代理难以将大量交互转化为有效进展。

---

## 457. Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models

**arXiv ID:** 2602.01654 | [PDF](https://arxiv.org/pdf/2602.01654v1)

**作者:** Jiaqian Li `[一作]` (Brown University), Kuan-Hao Huang `[通讯]` (Texas A&M University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Steering Vector Fields (SVF)，在推理时对 LLM 的激活空间进行上下文感知的向量场干预，以提升控制的可靠性和可扩展性。

**💡 创新点**

将静态向量改为可微分的概念边界并利用其梯度作为局部方向，实现上下文感知的干预；在共享低维空间中对多层激活进行对齐，实现协同多层干预。

**🔧 技术方法**

使用可微分概念评分函数（MLP）、共享投影矩阵、层条件校准（FiLM 风格）、softmin 组合多属性边界、向量场更新，以及对长文本和多属性控制的递推刷新。

**📊 数据集**

在 Llama‑2‑7b‑Chat、Qwen3‑14b 等 LLM 上实验；使用 Model‑Written‑Evaluations (MWE) 作为多选问答数据；TruthfulQA、hallucination 数据集用于真实性/幻觉控制；Natural Questions 用于评估概念污染。

**📈 对比分析**

与 CAA、ICV、BiPO、RED 等基线对比；在 MWE 上提升准确率和可控率，尤其对难以控制的概念（如 Narcissism、Myopic）显著改善；在开放式生成中在幻觉、真实性控制上获得比基线更高的 GPT‑4‑1 评估分数；多属性组合下保持较高的可控率。

**⚠️ 局限性**

对极端长文本仍需频繁刷新；多层对齐需要手工选择层集合；在某些跨域 OOD 场景下可能出现概念泄露；实现需要额外的梯度推导计算，且假设模型为 Transformer 结构。

---

## 458. Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning

**arXiv ID:** 2602.01649 | [PDF](https://arxiv.org/pdf/2602.01649v1)

**作者:** Yinchao Ma `[一作]` (Taobao & Tmall Group of Alibaba), Bo Zheng `[通讯]` (Taobao & Tmall Group of Alibaba)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了一种基于强化学习的贡献感知视频令牌压缩框架 CaCoVID，主动学习令牌组合以提升视频理解精度。

**💡 创新点**

创新点在于：① 将强化学习直接用于令牌压缩，优化令牌对正确预测的贡献；② 提出在线组合空间采样（OCSS）方法，将原本指数级的组合空间压缩至可训练范围，加速策略收敛。

**🔧 技术方法**

采用了自注意力 + MLP 的压缩策略网络、CPO 策略优化、OCSS 采样、经验回放与动态采样比例，以及现有 LLaVA‑OneVision、Qwen2.5‑VL 等大模型进行推理。

**📊 数据集**

训练数据来自 Video‑R1 116k 视频 QA 对中筛选出的 31k 高质量视频问答样本；在 LongVideoBench、MLVU、VideoMME 等 benchmark 上进行评估。

**📈 对比分析**

在相同硬件与软件环境下，与内容基准压缩（VisionZip、DivPrune、PruneVID）和模型基准压缩（FastV、FrameFusion）对比；在 10–25% 令牌保留率下，CaCoVID 取得 98.9% 以上准确率，压缩速度提升至 11.2 ms，整体性能均优于现有方法。

**⚠️ 局限性**

局限性包括：仍需依赖预训练 LLM 固定，仅在视频理解任务上验证；在极低保留率下表现下降；算法对 GPU 资源与训练时间仍有一定需求。

---

## 459. Membership Inference Attack Against Music Diffusion Models via Generative Manifold Perturbation

**arXiv ID:** 2602.01645 | [PDF](https://arxiv.org/pdf/2602.01645v1)

**作者:** Yuxuan Liu `[一作]` (Xi'an Jiaotong-Liverpool University), Shengchen Li `[通讯]` (Xi'an Jiaotong-Liverpool University)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `6215c339-3735-4be3-8a07-5bbb7004712d` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

设计并实现了一种白盒会员推断攻击（LSA-Probe），通过在扩散模型逆向过程的中间潜在空间注入时间归一化扰动，并测量达到固定感知降质阈值所需的最小扰动预算，从而判断音频样本是否为训练集成员。

**💡 创新点**

首次提出利用逆向扩散轨迹中的潜在稳定性与攻击成本作为成员判别信号，采用时间归一化扰动和感知损失阈值，系统评估音乐扩散模型的MIAs，填补了音频领域缺乏动态过程基线的空白。

**🔧 技术方法**

采用DDIM/ DDPM逆向采样、PGD对时间归一化扰动进行优化、二分搜索预算、感知距离（CDPAM、MR-STFT）以及MSE等指标；白盒梯度流向逆向算子和距离度量，实现了对扩散模型的高效攻击。

**📊 数据集**

使用MAESTRO v3（单人钢琴曲）和FMA-Large（多流派音乐）两大公开语料库进行训练、验证和测试。

**📈 对比分析**

与传统的损失/轨迹/SecMI基线在相同计算量下比较，LSA-Probe在TPR@1% FPR上提升3–8个百分点，AUC提升0.03–0.04，尤其在DiffWave上最高提升8%，证明了其在低FPR区间的显著优势。

**⚠️ 局限性**

仅在白盒/开发者侧场景下有效，对黑盒或对抗性攻击的鲁棒性未评估；对不同扩散调度、条件设置或多模态模型的泛化能力仍需进一步研究。

---

## 460. AdaptNC: Adaptive Nonconformity Scores for Uncertainty-Aware Autonomous Systems in Dynamic Environments

**arXiv ID:** 2602.01629 | [PDF](https://arxiv.org/pdf/2602.01629v1)

**作者:** Renukanandan Tumu `[一作]` (University of Pennsylvania), Rahul Mangharam `[通讯]` (University of Pennsylvania)

**通讯引用:** 4564 | [OpenAlex ID](https://openalex.org/A5009445756)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `3855fcda-48ef-4070-a15e-803cd5c84d83` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

开发了一种在线自适应非一致性得分的置信预测框架AdaptNC，在分布漂移下实现效率与覆盖度兼顾。

**💡 创新点**

同时在线调整非一致性得分参数和阈值，并引入自适应重加权与Replay机制以消除覆盖冲击，突破传统阈值单一调节的局限。

**🔧 技术方法**

结合DtACI在线阈值更新、加权重采样、KDE高密度估计、凸包模板、Replay缓冲与梯度优化等技术，实现可解释且可收敛的非一致性得分学习。

**📊 数据集**

在三类机器人基准上验证：室内定位（WiFi RSSI）、多智能体社交导航（社交力模型）和多旋翼跟踪（线性化动力学+执行器退化）。

**📈 对比分析**

与DtACI、Split Conformal Prediction及AdaptNC无Replay对照；AdaptNC在覆盖率接近目标90%且平均预测区体积显著更小，局部覆盖波动最小，证明性能优越。

**⚠️ 局限性**

需要频繁重放与参数调优，极快漂移下仍可能出现短期覆盖冲击；理论仅保证长期覆盖，对短期性能受分布估计误差影响。

---

## 461. SUSD: Structured Unsupervised Skill Discovery through State Factorization

**arXiv ID:** 2602.01619 | [PDF](https://arxiv.org/pdf/2602.01619v1)

**作者:** Seyed Mohammad Hadi Hosseini `[一作]` (Sharif University of Technology), Mahdieh Soleymani Baghshah `[通讯]` (Sharif University of Technology)

**通讯引用:** 1147 | [OpenAlex ID](https://openalex.org/A5069082023)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0`

**🎯 论文内容**

本文提出了一种针对可因子化环境的无监督技能发现方法——SUSD，利用环境的因子化结构，将状态空间分解为若干子空间，并为每个子空间分配独立的技能潜变量，进一步通过好奇心驱动的因子权重机制动态调整各因子在奖励中的贡献，实现对所有可控因子的平衡探索；

**💡 创新点**

创新点在于：①将因子化嵌入架构与DSD结合，形成“因子化DSD”优化目标；②引入针对每个因子的好奇心权重，基于状态转移的负对数似然实现因子级别的自适应奖励权重；③在技能学习阶段实现因子级别的可分离、可组合技能表示，为下游HRL任务提供更细粒度的控制；

**🔧 技术方法**

技术包括：因子化状态嵌入网络 ϕ_i；基于高斯分布的条件密度模型 q_θ(s'|s)；双梯度（Lagrange乘子）优化 SUSD 的内在奖励；使用 Soft Actor-Critic (SAC) 训练低级技能策略；对齐 DSD 的 Wasserstein 目标；并在实验中使用多种强化学习基线（LSD、CSD、METRA、DIAYN、DUSDi）。

**📊 数据集**

数据集/环境主要有：1) Multi-Particle（10 个点质量代理与 10 个站点）；2) Kitchen（机器人臂与多对象，如黄油、肉丸、炉子、按钮）；3) 2D-Gunner；4) 传统单体环境 Ant 与 HalfCheetah。

**📈 对比分析**

与 5 个主流无监督技能发现基线（LSD、CSD、METRA、DIAYN、DUSDi）进行对比。实验结果显示：在因子化环境（Multi-Particle、Kitchen）中，SUSD 在下游任务回报、状态覆盖率、因子重构误差和无监督技能自发完成任务奖励等指标均优于基线，尤其在高维厨房环境中优势显著；在未因子化环境（Ant、HalfCheetah）中表现仍保持竞争力，零射击任务完成率接近或略优于最优基线。

**⚠️ 局限性**

局限性包括：①需先验地对环境进行因子化，无法自动发现因子；②对高维感知输入（如像素）仍假设可直接获取底层状态，需进一步结合视觉表征学习；③因子化的好奇心权重依赖高斯密度估计，可能在复杂分布下失效；④在极端多因子环境中因子数过多时，计算和训练成本上升。

---

## 462. What Do Agents Learn from Trajectory-SFT: Semantics or Interfaces?

**arXiv ID:** 2602.01611 | [PDF](https://arxiv.org/pdf/2602.01611v1)

**作者:** Weizheng Gu `[一作]` (Peking University), Wei Ye `[通讯]` (Peking University)

**通讯引用:** 9724 | [OpenAlex ID](https://openalex.org/A5101763457)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出PIPE协议，对环境接口进行最小化改写，检测轨迹SFT训练后代理对接口表面形式的依赖程度；同时引入Interface Reliance (IR) 指标量化此依赖。

**💡 创新点**

创新点在于：①通过仅改写接口而不改变任务语义和执行行为的方式，客观区分语义学习与接口捷径；②设计IR度量，采用对称接口别名与计数平均化，减少噪声并可在训练阶段实时监控。

**🔧 技术方法**

技术包括：轨迹监督微调（Trajectory‑SFT）、对话式代理（ReAct等）、接口扰动生成（同义词/符号替换）、统计分析与几何平均量化。

**📊 数据集**

使用AgentBench与AgentGym共16个环境的公开轨迹集，涵盖多种工具交互任务（如WebShop、ALFWorld、SciWorld等）。

**📈 对比分析**

对比标准评测（原接口成功率）与PIPE+IR评测。结果显示：①在大多数环境下，未训练模型对接口扰动影响小；②轨迹SFT模型在接口扰动下显著退化，IR值显著升高；③通过对比不同训练轮次的IR与性能，揭示性能提升非单纯语义增强，而是接口捷径导致的短期成功。整体性能：在原接口上提升明显，但在扰动接口上表现大幅下降。

**⚠️ 局限性**

局限性：①仅考察了接口名称的改写，对更复杂的语义变换（如功能描述改写）未覆盖；②IR依赖于双接口设定，若环境缺乏可用别名难以评估；③实验主要基于公开工具接口，缺乏对真实外部API多样性与动态变化的验证。

---

## 463. Reasoning with Autoregressive-Diffusion Collaborative Thoughts

**arXiv ID:** 2602.01608 | [PDF](https://arxiv.org/pdf/2602.01608v1)

**作者:** Mu Yuan `[一作]` (Chinese University of Hong Kong), Yunhao Liu `[通讯]` (Tsinghua University)

**通讯引用:** 18676 | [OpenAlex ID](https://openalex.org/A5070071735)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种闭环协作框架，使自回归模型（LLM）和扩散模型在视觉推理任务中通过规划‑模拟‑评估循环迭代交互，从而在空间推理和生成任务中显著提升准确性与效率。

**💡 创新点**

创新点在于将扩散模型视为“软”物理模拟器，配合自回归模型的逻辑规划，形成可持续的 Simulate‑Critic‑Refine 循环；该闭环既能消除单一模型的空间幻觉，又兼顾逻辑严谨，突破了传统链式思考（CoT）和单一视觉生成的瓶颈。

**🔧 技术方法**

核心技术包括：①基于 LLM 的规划与提示工程；②扩散模型（可结合 ControlNet 等布局指导）生成高质量视觉草图；③视觉‑语言模型（VLM）作为批评器，给出满意度得分与修正反馈；④迭代闭环控制逻辑与终止判定。

**📊 数据集**

在合成几何推理数据集（如自动生成的多步骤几何问题集）以及公开视觉推理基准（如 GQA、COIN）上进行实验，评估空间推理准确率和生成质量。

**📈 对比分析**

与单一自回归（AR‑Only）和单一扩散（Diffusion‑Only）基线相比，本文方法在几何推理任务中准确率提升 10%~20%（具体数值见论文表格），并将推理所需的 token 数量从数千降至数十，显著降低计算成本。

**⚠️ 局限性**

主要局限包括：①迭代循环显著增加推理时延和 GPU 负载；②扩散模型的物理一致性仍不够精确，无法完全代替高精度物理引擎；③目前仅针对 2D 静态视觉任务，尚未扩展到 3D 或视频动态情境。

---

## 464. Expected Harm: Rethinking Safety Evaluation of (Mis)Aligned LLMs

**arXiv ID:** 2602.01600 | [PDF](https://arxiv.org/pdf/2602.01600v1)

**作者:** Yen-Shan Chen `[一作]` (National Taiwan University), Yun-Nung Chen `[通讯]`

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `6215c339-3735-4be3-8a07-5bbb7004712d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了“预期危害”框架，将有害信息的严重度与执行可能性相乘来评估LLM的安全性。

**💡 创新点**

发现现有模型在低成本高可执行性威胁上表现弱，提出基于成本拆分的攻击方法并验证其高效性。

**🔧 技术方法**

利用LLM作为评判者、线性探针、成本与严重度标注器以及多种攻击技术（GCG、AutoDAN、Roleplay、Many-Shot）。

**📊 数据集**

使用真实会话数据集（LMSYS-Chat-1M、WildChat-4.8M）与四大安全基准（AdvBench、HarmBench、SorryBench、StrongREJECT）进行评估，并标注成本与严重度。

**📈 对比分析**

对比不同拆分策略，成本拆分+严重度监控方法在四个基准上均能将攻击成功率提升至≈2×，并在Guard模型中突破90%的绕过率，显示显著性能提升。

**⚠️ 局限性**

局限在于成本标注仍依赖LLM评判，实验主要基于开放模型，且未完全覆盖所有高成本威胁，且成本拆分攻击仍受限于模型对成本的内在表征不足。

---

## 465. Moonworks Lunara Aesthetic II: An Image Variation Dataset

**arXiv ID:** 2602.01666 | [PDF](https://arxiv.org/pdf/2602.01666v1)

**作者:** Yan Wang `[一作]`, Sabit Hassan `[通讯]` (Griffith University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

公开了 Lunara Aesthetic II 数据集，包含 2,854 对 anchor‑linked 视觉变体，用于评估图像生成与编辑模型的上下文一致性与身份保持能力。

**💡 创新点**

创新点在于将图像变体组织成身份锚定的关系集合，提供多因素、可控的上下文变化标签，并结合高审美评分，为模型在多模态推理中的上下文泛化提供实验基准。

**🔧 技术方法**

使用 Moonworks Lunara 子 10B 参数扩散混合模型生成变体，QWEN3‑VL 进行提示抽取与差异检测，随后人工校验与标注；评估则采用自动化指标（轴专一性、Cohen’s d、熵）和人类 Likert/二元评测。

**📊 数据集**

数据集来源为 336 张经明确授权的原始图像（艺术作品与真实照片），随后生成约 8.5 个变体；同时引用 LAION‑Aesthetics v2 预测器评估美学分数。

**📈 对比分析**

与 CC3M、WIT、LAION‑2B‑Aesthetic 等大规模公开数据集对比，Lunara‑II 在身份稳定性（平均 4.68/5）和目标属性实现率（最高 93.3%）上表现优异；美学分数平均 5.91，虽然低于 Lunara‑I，但仍高于通用网络数据集。

**⚠️ 局限性**

限制包括规模有限（仅 2.8K 变体）、上下文变体范围受限（仅 6 类标签）、对身份定义依赖于 anchor‑linked 设计，且对复杂多步或抽象变换缺乏覆盖；同时，模型在多因素组合时易出现合成失真。

---

## 466. TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning

**arXiv ID:** 2602.01665 | [PDF](https://arxiv.org/pdf/2602.01665v1)

**作者:** Hayeong Lee `[一作]` (Korea University), Byung-Jun Lee `[通讯]` (Gauss Labs Inc.)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

本文提出了TABX，一款基于JAX的高吞吐量沙盒战斗模拟器，旨在为多智能体强化学习（MARL）提供可高度配置、GPU加速的实验环境，并配备图形化场景编辑器；

**💡 创新点**

创新点包括：①利用JAX实现全向量化并行计算，实现GPU加速与高吞吐；②通过配置文件+GUI实现单位、地形、策略及物理参数的动态重配置，极大提升实验灵活性；③引入非目标化攻击机制、扇形视野、异质地形等设计，增强策略挑战；④提供多种基线算法和UED框架的实现，方便系统评测；

**🔧 技术方法**

主要技术：JAX + GPU向量化；Python/NumPy 生态；图形化场景编辑器；强化学习算法实现（IPPO、MAPPO、IQL、QMIX、RND、UED等）；

**📊 数据集**

使用的“数据集”是多种预定义场景与通过参数化生成的随机场景组合，涵盖不同的单位配置、地形布局和物理参数；

**📈 对比分析**

通过在多场景下评估IPPO、MAPPO、IQL、QMIX等基线，发现MAPPO在大多数情形下表现优异，但IPPO在某些局部可观测或无全局信息场景中更好；使用RND提升稀疏奖励任务的探索效果；在UED实验中，DR、PLR等方法在地形变异任务中提升了泛化，但对单位属性变异的泛化仍不足；性能上，TABX在GPU上每秒可处理数十万步，且在频繁重置时吞吐远优于SMAX；

**⚠️ 局限性**

局限性包括：1）当前仅支持离散动作和基于像素的观测缺失；2）对单位属性泛化仍表现弱；3）缺少视线限制、堡垒等更复杂的地形结构；4）大样本需求导致训练时间长；

---

## 467. Decoding Golay Codes and their Related Lattices: A PAC Code Perspective

**arXiv ID:** 2602.01657 | [PDF](https://arxiv.org/pdf/2602.01657v1)

**作者:** Yujun Ji `[一作]` (Shenzhen University), Baoming Bai `[通讯]` (Xidian University)

**通讯引用:** 2700 | [OpenAlex ID](https://openalex.org/A5063124926)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

研究并提出一种基于 PAC 代码视角的 Golay 码及其相关格子（Leech 格子和主子格子）并行列表解码方法。

**💡 创新点**

创新点在于通过三种不同 3×3 核的 PAC 代码构造实现无指数置换、无删码的 Golay 码，并将三种解码器并行结合，获得仅需小列表即可接近 ML 性能的解码框架。

**🔧 技术方法**

采用 Polar / PAC 代码生成、卷积矩阵 T、三种 3×3 核构造、SCL 解码、并行解码与多级解码技术。

**📊 数据集**

使用仿真数据：在 AWGN 信道下以 BPSK 发送 Golay 码及 L₍₂₄₎、H₍₂₄₎ 格子，评估 BLER；无真实数据集，全部为模拟实验。

**📈 对比分析**

与传统单核 SCL、ML 解码对比显示：在列表大小为 8 时，三核并行解码已达到近 ML 性能，远优于需列表 64 的传统方法；多级解码在列表 16（或 2×16 的层级列表）时也能实现接近 ML 的 BLER。

**⚠️ 局限性**

局限在于仍需较大列表才能完全逼近 ML，且多级解码易受低层噪声累积导致误差传播，且对不同尺寸或非结构化格子适用性尚未验证。

---

## 468. A2Eval: Agentic and Automated Evaluation for Embodied Brain

**arXiv ID:** 2602.01640 | [PDF](https://arxiv.org/pdf/2602.01640v1)

**作者:** Shuai Zhang `[一作]` (Westlake University), Xiaozhu Ju `[通讯]` (Beijing Innovation Center of Humanoid Robotics)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了A2Eval框架，利用两个协作代理（Data Agent与Eval Agent）实现从基准构建到模型评测的全流程自动化，显著压缩评测规模、降低成本并纠正排名偏差。

**💡 创新点**

创新点在于：①使用多智能体协同推理自动推导统一能力维度；②通过多维度分配与聚类多样性采样构造低冗余、平衡的基准；③利用代码合成与沙箱验证实现全自动可执行评测管线；④实现评测压缩85%、成本下降77%、速度提升4.6倍，并提高与人工评估的一致性。

**🔧 技术方法**

技术包括：多智能体协同（Proposer、Reviewer、Assigner）、能力维度自发推导、基于语义嵌入的聚类多样性采样、Inference与Scoring逻辑的代码合成与沙箱验证、以及大型语言模型（GPT‑4o、Gemini‑3Pro）驱动的代理执行。

**📊 数据集**

使用了10个体感视觉‑语言基准（COSMOS、ERQA、Where2Place、VSI‑Bench、OmniSpatial、EgoSchema、BLINK、RefSpatial、RoboSpatial、EmbSpatial），共24,519条样本，最终压缩为3,781条。

**📈 对比分析**

与原始完整评测相比，A2Eval在保持94%排名相关性（Spearman 0.94、Kendall 0.81）的同时，与人工评估相关性提升至Spearman 0.85、Kendall 0.72；评测速度提升3.4×–4.6×；Eval Agent的评测精度达到96.9%与参考实现相近。

**⚠️ 局限性**

局限性包括：依赖大语言模型与沙箱执行，可能在极大规模或长序列视频上仍存在计算瓶颈；基准覆盖受限于已有的10个基准；维度推导与采样策略的设计仍可能引入主观偏差。

---

## 469. ReCALL: Recalibrating Capability Degradation for MLLM-based Composed Image Retrieval

**arXiv ID:** 2602.01639 | [PDF](https://arxiv.org/pdf/2602.01639v1)

**作者:** Tianyu Yang `[一作]` (Institute of Automation Chinese Academy of Sciences), Tat-Seng Chua `[通讯]` (National University of Singapore)

**通讯引用:** 60254 | [OpenAlex ID](https://openalex.org/A5089404640)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了 ReCALL 框架，使用 diagnose–generate–refine 方案将多模态大语言模型（MLLM）的生成推理能力迁移到检索模型，从而解决“Capability Degradation”问题。

**💡 创新点**

创新点包括：① 识别并量化检索适配过程中出现的能力退化；② 通过自指导 informative instance mining 诊断模型失败案例；③ 利用 Chain‑of‑Thought 生成纠正指令并用 VQA 过滤噪声；④ 用 grouped contrastive learning 对模型进行目标化微调；整体实现模型无关、可自监督的能力再校准。

**🔧 技术方法**

使用的技术有：多模态大语言模型 Qwen2.5‑VL‑7B（可扩展到 Qwen3‑VL‑8B）；LoRA 微调；InfoNCE 与 margin triplet 结合的对比损失；CoT 生成与 VQA 质量控制；Grouped Contrastive Refinement；自指导实例挖掘。

**📊 数据集**

主要使用的数据集为 CIRR 和 FashionIQ 进行训练与评测。

**📈 对比分析**

与多种现有方法（CLIP、TIRG、ARTEMIS、TG‑CIR、SPRC、LIMN、CoVR‑2、CaLa、CIR‑LVLM、QuRe、CCIN、TME）进行对比；在 CIRR 上 R@1 从 51.23% 提升至 55.52%（+8.38%）；在 FashionIQ 上 R@10 从 46.80% 提升至 51.81%（+10.71%），在多项指标上均实现 SOTA。

**⚠️ 局限性**

局限性包括：对基础模型容量依赖仍然显著；仅在 CIRR/FashionIQ 上验证，跨域泛化需进一步探索；生成的纠正指令受 MLLM 推理质量限制；对噪声样本的过滤仍非绝对；训练成本和超参数（λ、margin 等）需要手动调优。

---

## 470. Federated Vision Transformer with Adaptive Focal Loss for Medical Image Classification

**arXiv ID:** 2602.01633 | [PDF](https://arxiv.org/pdf/2602.01633v1)

**作者:** Xinyuan Zhao `[一作]` (Guilin University of Electronic Technology), Reem Kateb `[通讯]` (Taibah University)

**通讯引用:** 382 | [OpenAlex ID](https://openalex.org/A5090099655)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

在联邦学习框架下，使用 Vision Transformer 并提出动态自适应焦点损失（DAFL），解决医学图像分类中的类别不平衡和客户端异质性。

**💡 创新点**

创新点是双层不平衡建模——将本地类别稀缺度与全局客户端失衡度动态耦合到焦点损失中，并通过分布感知聚合策略为不同客户端分配权重，提升模型泛化和少数类表现。

**🔧 技术方法**

技术包括 Vision Transformer、动态自适应焦点损失、联邦平均加权聚合、Dirichlet 异构划分、梯度注意力重播（Interpretability）以及与多种基线模型的对比实验。

**📊 数据集**

实验数据集为三大公开医学图像集：ISIC2019（皮肤病），Ocular Disease（眼科疾病），RSNA-ICH（颅内出血）三组数据。

**📈 对比分析**

与 CNN、ViT、Swin、CoAtNet、MixNet 以及 FedCLIP、FedRep、FedDM、FedMCA、FtMoE、FedProx、MOON 等方法对比，DAFL 在多数指标上实现了 0.98%–41.69% 的提升，且收敛速度更快、少数类召回率显著提高。

**⚠️ 局限性**

局限性包括仅模拟少量客户端、聚合依赖客户端提供的统计信息（可能被噪声或攻击影响）、未结合差分隐私或安全聚合等隐私保护机制，以及仅在三组数据集上验证，缺乏更广泛的跨域测试。

---

## 471. Toward Enhancing Representation Learning in Federated Multi-Task Settings

**arXiv ID:** 2602.01626 | [PDF](https://arxiv.org/pdf/2602.01626v1)

**作者:** Mehdi Setayesh `[一作]` (Huawei Noah’s Ark Lab), Hongliang Li `[通讯]` (Huawei Noah’s Ark Lab)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `57a58b01-81b4-4d75-a45c-2e891f272b50` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 FedMuscle，一种在联邦多任务学习中对齐异构模型表示空间的框架。

**💡 创新点**

创新点在于设计 Muscle 损失——一种多模型对比学习目标，理论上等价于最大化所有模型表示的互信息，并通过加权系数有效捕获跨模型依赖。

**🔧 技术方法**

使用对比学习、互信息下界、LoRA 参数高效微调、共享公共数据集传递低维表示以及服务器端聚合权重的技术实现。

**📊 数据集**

实验使用 CIFAR‑10/CIFAR‑100、COCO、Pascal VOC、Flickr30K、Yahoo! Answers 等公开数据集。

**📈 对比分析**

与 FedRCL、SAGE、CoFED、FedDF、FedHeNN、SimCLR 等基线对比，FedMuscle 在单模态和多模态设置下平均提升 Δ 约 20% 以上，显著优于现有方法。

**⚠️ 局限性**

局限性包括需共享公共数据集、对大规模用户的通信成本仍显高、模型输出维度需统一或通过投影对齐，以及在极端非 IID 或超大模型数量场景下的可扩展性仍待验证。

---

## 472. Efficient Softmax Reformulation for Homomorphic Encryption via Moment Generating Function

**arXiv ID:** 2602.01621 | [PDF](https://arxiv.org/pdf/2602.01621v1)

**作者:** Hanjun Park `[一作]` (Pohang University of Science and Technology), Yongjune Kim `[通讯]` (Pohang University of Science and Technology)

**通讯引用:** 622 | [OpenAlex ID](https://openalex.org/A5025186204)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `64443552-63e0-44b5-906f-d90fe95c5a1b` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在同态加密（HE）环境下，提出一种利用矩生成函数（MGF）重构 softmax 的方法（MGF‑softmax），通过消除最大值和除法运算，显著降低乘法深度并保持较高推理精度。

**💡 创新点**

创新点在于：① 用 MGF 将 softmax 的分母替换为指数函数的期望值，消除了对数值不稳定的最大值截断和除法；② 通过累积矩生成函数提供数据自适应的偏移；③ 引入域缩放技巧，使指数逼近在更小区间内完成，进一步降低乘法深度。

**🔧 技术方法**

采用的技术包括：同态加密 CKKS、指数函数的多项式逼近（Chebyshev 或极限逼近）、累积矩（κ1, κ2 等）估计、旋转与求和、域缩放与迭代平方、以及知识蒸馏微调。

**📊 数据集**

使用的数据集包括：大型语言模型 LLaMA‑3.2‑1B 在 Clinc150、Banking77、SST‑2；Vision Transformers（ViT/DeiT）在 ImageNet‑1k；并在 GPT‑2、BERT 等小模型上做基准对比。

**📈 对比分析**

与现有软最大近似基线（如 Cho 等）和软最大替代基线 BPMax 进行比较；MGF‑softmax 的乘法深度仅为 7–10（比基线低 30–70%），并在所有任务上保持 ≤1% 的精度误差，远优于需要 40+ 深度或显著准确率下降的替代方法。

**⚠️ 局限性**

局限性包括：仍需在预训练模型上进行微调以恢复精度；对极端高维或极大类别数的任务尚未系统评估；以及依赖指数函数的多项式逼近，逼近误差与输入区间和多项式阶数相关。

---

## 473. AgroFlux: A Spatial-Temporal Benchmark for Carbon and Nitrogen Flux Prediction in Agricultural Ecosystems

**arXiv ID:** 2602.01614 | [PDF](https://arxiv.org/pdf/2602.01614v1)

**作者:** Qi Cheng `[一作]` (University of Pittsburgh), Xiaowei Jia `[通讯]` (University of Pittsburgh)

**通讯引用:** 4015 | [OpenAlex ID](https://openalex.org/A5001445783)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `79276348-11e0-48e3-84bc-7ec231d0171c` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `5a41884c-404f-4688-a89c-aa238c10fe68` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出并构建了 AgroFlux 这一农业生态系统碳氮通量预测的时空基准数据集与评估框架，并给出统一的任务与评估指标。

**💡 创新点**

首次将物理模型（Ecosys、DayCent）模拟结果与实测通量（eddy covariance、实验室腔室）整合为同一基准；制定标准化的时间/空间外推任务和迁移学习评估；提供可公开的基准数据与代码。

**🔧 技术方法**

使用深度序列模型（LSTM、EA‑LSTM、TCN、Transformer、iTransformer、Pyraformer）以及迁移学习方法（预训练‑微调、对抗训练）进行通量预测。

**📊 数据集**

数据来源：Ecosys 与 DayCent 在美国中西部多县/地区的多种施肥与作物轮作情景下的每日模拟数据；以及 11 处农田 eddy‑covariance 站点的 CO₂、GPP 日尺度观测和 2016‑2018 年的 N₂O 观察数据。

**📈 对比分析**

采用固定的时间外推（过去→未来）和空间外推（地点划分）拆分，使用 R²、RMSE、MAE 三指标进行对比。基线结果显示：对 CO₂ 与 GPP 的预测性能较好（R²≈0.8‑0.9），但 N₂O 的预测仍显困难（R²<0.4）。迁移学习（预训练‑微调或对抗）可提升多数模型的性能，尤其在 CO₂、GPP 上表现显著。

**⚠️ 局限性**

局限性：观测数据（尤其是 N₂O）样本稀缺、时间覆盖短；模拟与实测存在分布差异；评估仅包含三种误差指标，未涉及不确定性、鲁棒性等更全面的评估。

---

## 474. A Practical Tensor-Network Compression Pipeline for Production-Scale Large Language Models

**arXiv ID:** 2602.01613 | [PDF](https://arxiv.org/pdf/2602.01613v1)

**作者:** Sergii Kozyrev `[一作]` (Minima AI), Davyd Maiboroda `[通讯]` (Minima AI)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一个面向生产LLM的压缩管线Minima。

**💡 创新点**

通过学习敏感性模型指导混合张量网络压缩，结合核优化和投机解码，实现约两倍压缩与近两倍速度提升。

**🔧 技术方法**

采用CNN敏感性预测、Tucker/TT/TR张量分解、短时微调、Triton/CUDA自定义核与投机解码技术。

**📊 数据集**

在Qwen3-32B预训练模型以及MMLU、HellaSwag、GSM8K等公开基准上评估。

**📈 对比分析**

与未压缩基线和现有张量网络压缩方法对比，参数约↓40%、VRAM降至40GiB，TPS从40提升至75，整体性能提升≈1.9倍。

**⚠️ 局限性**

局限在于仍为层级局部压缩，未实现全局共享张量结构，且依赖专门的自定义核与投机解码，对硬件与实现细节较为敏感。

---

## 475. ToPT: Task-Oriented Prompt Tuning for Urban Region Representation Learning

**arXiv ID:** 2602.01610 | [PDF](https://arxiv.org/pdf/2602.01610v1)

**作者:** Zitao Guo `[一作]` (Shenzhen University), Bowen Zhang `[通讯]` (Shenzhen Technology University)

**通讯引用:** 2957 | [OpenAlex ID](https://openalex.org/A5100385138)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `57a58b01-81b4-4d75-a45c-2e891f272b50` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出一种两阶段框架 ToPT，结合空间感知区域嵌入学习与任务导向提示调优，实现城市区域表示的自适应与任务统一。

**💡 创新点**

创新点在于：1) 在 Graphormer 中引入距离与中心度的可学习注意力偏置，显式捕捉空间自相关；2) 利用冻结的多模态大语言模型生成任务特定提示，并通过多头交叉注意力实现提示与区域嵌入的对齐，形成软提示，从而显著提升任务感知性能。

**🔧 技术方法**

主要技术包括 Graphormer、可学习空间偏置注意力、多头交叉注意力对齐、冻结的多模态大语言模型（如 LLaMA‑3.2‑Vision‑Instruct）、任务特定提示模板以及多模态融合。

**📊 数据集**

实验使用芝加哥市公开数据门户的 POI、出租车出行、土地利用等结构特征，并通过 Google Maps 与 OpenStreetMap 获取卫星图、街景图和地理文本。

**📈 对比分析**

与 MVURE、MGFN、HREP、FlexiReg 等基线方法在犯罪预测、签到预测、服务呼叫估计三项任务上进行 MAE、RMSE、R² 指标比较，ToPT 在所有任务上平均提升 20%–64% 的性能，显著优于现有最先进方法。

**⚠️ 局限性**

局限性包括：对多模态提示模板和冻结大语言模型的依赖较大；在不同城市迁移时需重新构建模板；模型对不同 MLLM 的鲁棒性仍有待进一步验证。

---

## 476. Adaptive Rollout Allocation for Online Reinforcement Learning with Verifiable Rewards

**arXiv ID:** 2602.01601 | [PDF](https://arxiv.org/pdf/2602.01601v1)

**作者:** Hieu Trung Nguyen `[一作]` (Chinese University of Hong Kong), Viet Anh Nguyen `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 815 | [OpenAlex ID](https://openalex.org/A5100625772)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

针对基于群组的策略优化方法，提出变异信息预测分配（VIP）策略，动态分配rollout预算以降低梯度方差。

**💡 创新点**

创新点在于利用高斯过程预测每个prompt的成功概率，并通过凸优化最小化梯度方差，实现预算的自适应分配。

**🔧 技术方法**

采用高斯过程回归、凸优化（连续松弛+整数逼近）以及基于梯度方差分析的分配算法。

**📊 数据集**

在数学推理数据集 DAPO-MATH-17k、AIME2024/25 以及工具增强推理数据集 MuSiQue、Bamboogle 上进行实验。

**📈 对比分析**

与 RLOO、Dr.GRPO 及启发式分配方法相比，VIP 在 Pass@32、Mean@32、EM 等指标上提升约5–15个百分点，尤其在小模型上效果更显著。

**⚠️ 局限性**

局限性包括仅在可验证奖励环境下验证，非可验证或噪声奖励的鲁棒性尚未测试；高斯过程更新在大规模 prompt 时计算开销略高。

---

## 477. Mapping a Decade of Avian Influenza Research (2014-2023): A Scientometric Analysis from Web of Science

**arXiv ID:** 2602.01712 | [PDF](https://arxiv.org/pdf/2602.01712v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `f53a5690-f5d8-493f-989c-dc46a1f99053`

---

## 478. UV-M3TL: A Unified and Versatile Multimodal Multi-Task Learning Framework for Assistive Driving Perception

**arXiv ID:** 2602.01594 | [PDF](https://arxiv.org/pdf/2602.01594v1)

**作者:** Wenzhuo Liu `[一作]` (Beijing Institute of Technology), Huaping Liu `[通讯]` (Tsinghua University)

**通讯引用:** 11907 | [OpenAlex ID](https://openalex.org/A5041101317)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `729e5870-4135-47f5-97f2-e3974d07b5dc` `6514db3d-8de6-452c-91b7-acdb31787cc4` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种统一多模态多任务学习框架UV‑M^3TL，用于同时识别驾驶员情绪/行为、交通环境与车辆行为。

**💡 创新点**

核心创新：双分支空间通道多模态嵌入(DB‑SCME)以同时提取任务共享与任务特有特征；自适应特征解耦多任务损失(AFD‑Loss)动态权重与解耦约束，抑制负迁移并提升跨任务协同。

**🔧 技术方法**

技术手段包括：多轴区域注意网络(MARNet)处理多视角图像；3D‑CNN提取驾驶员关节序列；自注意力与通道注意力组合的双分支结构；学习动态自适应加权与特征解耦损失。

**📊 数据集**

使用AIDE、BDD100K、NYUD‑v2、PASCAL‑Context、CityScapes五个公开基准；AIDE为四任务驾驶相关分类，其他为语义分割、深度估计、检测等多任务场景。

**📈 对比分析**

与现有最先进方法（包括UniAD、Transformer/ViT、Diffusion、Mamba等）进行对比。UV‑M^3TL在AIDE上四任务平均准确率提升1.41%–13.50%；在BDD100K、CityScapes、NYUD‑v2、PASCAL‑Context等多任务数据集均获得或接近最优成绩，显著提升特征共享与负迁移抑制效果。

**⚠️ 局限性**

局限性：对极端稀疏或单一模态的数据效果相对较弱；模型复杂度高，需大量GPU资源；自适应权重机制对超参数敏感，需在不同任务组合上细调。

---

## 479. Quantifying Epistemic Predictive Uncertainty in Conformal Prediction

**arXiv ID:** 2602.01667 | [PDF](https://arxiv.org/pdf/2602.01667v1)

**作者:** Siu Lun Chau `[一作]` (Nanyang Technological University), Michele Caprio `[通讯]` (University of Manchester)

**通讯引用:** 25 | [OpenAlex ID](https://openalex.org/A5000098655)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文研究在Conformal Prediction（CP）框架下量化知识不确定性（Epistemic Predictive Uncertainty, EPU）的方法，提出基于隐式Credal集的MMI-CP度量。

**💡 创新点**

创新点在于：①证明split CP也能诱导出隐式Credal集并与CPR等价；②将Maximum Mean Imprecision (MMI) 与CP结合，得到可线性计算的EPU度量；③在分类任务中通过p‑value分布差异捕捉模型不确定性。

**🔧 技术方法**

技术手段包括：Conformal Prediction、Imprecise Probabilities（Credal集、plausibility度量）、Maximum Mean Imprecision (MMI) 以及Consonance假设的变换；对分类和回归分别给出解析式。

**📊 数据集**

实验数据集：Digits、Letters、CIFAR10、CIFAR100、Caltech101、Fashion‑MNIST 等标准视觉分类数据；使用随机森林或预训练深度网络作为基模型。

**📈 对比分析**

与传统的CPR大小（|C_α|）度量对比，MMI-CP 在主动学习（accuracy 轨迹）和选择性分类（ARC 曲线）上均显著优于基准，表现出更细粒度、更稳健的EPU评估。

**⚠️ 局限性**

局限性：①在回归任务中，标准CPR的p‑value分布不随样本变化，导致MMI-CP EPU 对所有样本均为常数，无法区分；②Consonance 约束消除了空预测集，可能失去对极端不确定性的显式信号；③实验仅覆盖分类，回归实验缺失。

---

## 480. Uncertainty-Aware Non-Prehensile Manipulation with Mobile Manipulators under Object-Induced Occlusion

**arXiv ID:** 2602.01731 | [PDF](https://arxiv.org/pdf/2602.01731v1)

**作者:** Jiwoo Hwang `[一作]` (Korea Advanced Institute of Science and Technology), Sung-Eui Yoon `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 3845 | [OpenAlex ID](https://openalex.org/A5078173428)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

本研究提出了一种名为CURA-PPO的强化学习框架，用于解决非抓取式操作中物体遮挡导致的感知不完整问题。

**💡 创新点**

创新点在于通过分布式碰撞估计器（DCE）将碰撞可能性建模为分布，从而同时提取风险（期望）与不确定性（方差）两种信号，并将其作为内部奖励驱动机器人主动感知与碰撞规避。

**🔧 技术方法**

主要采用的技术包括分布式量化回归估计碰撞分布、基于分布统计的风险与不确定性成本、PPO与自定义成本的结合、以及使用LiDAR的置信度图进行感知编码。

**📊 数据集**

使用的“数据集”为在Isaac Sim中生成的模拟环境，包含三种物体尺寸（0.5 m、0.75 m、1.0 m）以及均匀与对抗性两种障碍物出现场景，共计10,000个episode的仿真数据。

**📈 对比分析**

实验与两种基线（无遮挡训练的Push、含遮挡但无不确定性处理的Push）以及多种消融对比（置信度图、风险成本、不确定性成本）进行比较，CURA‑PPO在遭遇遮挡时的成功率可达无遮挡基线的近似水平，提升幅度可达三倍以上。

**⚠️ 局限性**

局限性包括仅在仿真环境验证，缺乏真实机器人实验；依赖LiDAR传感器对遮挡区域的感知仍有限；并且在高度遮挡或大物体场景下对运动学冗余的需求较高，可能限制了在非配备机械臂平台上的适用性。

---

## 481. Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory

**arXiv ID:** 2602.01708 | [PDF](https://arxiv.org/pdf/2602.01708v1)

**作者:** Langyuan Cui `[一作]` (National University of Singapore), Hwee Tou Ng `[通讯]` (National University of Singapore)

**通讯引用:** 14467 | [OpenAlex ID](https://openalex.org/A5110081955)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一种名为Game of Thought (GoT) 的框架，利用博弈论技术评估大型语言模型（LLMs）在信息寻求能力方面的表现，特别是在高风险环境中。

**💡 创新点**

创新点在于将信息寻求过程建模为一个两人零和博弈，并引入了战略语言搜索（SLS）问题及其变体，优化了最坏情况的表现，避免了对项目分布的强假设。

**🔧 技术方法**

使用了博弈论技术来近似纳什均衡（NE）策略，并结合了大型语言模型（LLMs）来生成问题和回答。

**📊 数据集**

使用了多个数据集，包括20 Questions（20Q）、医疗诊断（MD）和故障排除（TS）等，构建了不同的测试环境。

**📈 对比分析**

与现有方法（如直接提示法和基于启发式的搜索方法）相比，GoT在所有测试环境中均表现出更好的最坏情况性能，尤其是在医疗诊断和故障排除的实际应用中。

**⚠️ 局限性**

限制在于候选问题仅限于二元回答，未来的工作可以扩展到包含开放式响应的问题。

---

## 482. Meta Engine: A Unified Semantic Query Engine on Heterogeneous LLM-Based Query Systems

**arXiv ID:** 2602.01701 | [PDF](https://arxiv.org/pdf/2602.01701v1)

**作者:** Ruyu Li `[一作]` (University of Hawaii), Yifan Wang `[通讯]` (University of Hawaii)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

构建了 Meta Engine，一种“查询系统之上的查询系统”，通过自然语言查询解析、子查询拆分、操作符生成与路由、适配器统一接口、结果聚合等模块，将多种基于 LLM 的语义查询系统协同工作，以支持复杂多模态（文本、表格、图像）查询。

**💡 创新点**

创新点包括：
- 采用两阶段子查询生成（初步拆分 + 迭代细化），使每个子查询保持单跳、单模态；
- 置信度驱动的操作符候选排名与动态路由，提供统计路由与学习路由两种实现；
- 适配器抽象统一多种底层系统的 API，使系统可无缝扩展；
- 最终聚合器通过冲突检测与逻辑一致性验证，生成简洁、准确的最终答案。

**🔧 技术方法**

技术手段：
- LLM（GPT‑4.1‑mini、Qwen‑0.6B）用于查询解析、操作符生成、路由预测、聚合推理；
- Prompt engineering 与程序式提示框架（DSPy）实现底层操作；
- 轻量 MLP 分类器作为学习路由器；
- 语义聚合（LOTUS sem_agg）与单模型 VLM（单体多模态 LLM）作为执行后端；
- 结果缓存与并行子查询执行的未来优化。

**📊 数据集**

实验使用的多模态数据集：
- MultiModalQA（多跳问答）
- ManyModalQA（多模态单跳问答）
- Text2Vis（多模态分析）
- M2QA（基于维基的多模态问答）
- FinMMR（金融数值推理）

**📈 对比分析**

与单一系统（Single-Model、DSPy、LOTUS、LlamaIndex）对比，Meta Engine 在所有数据集的 F1、Hit、Semantic Hit 均显著提升，MLRouter 版本在 MultiModalQA、Text2Vis 等场景上提升 20% 以上；StatRouter 在 ManyModalQA、M2QA 等单跳场景表现更好；运行时与 LlamaIndex 相当，略高于 DSPy/Single-Model，但仍在可接受范围。

**⚠️ 局限性**

局限性：
- 子查询拆分与路由仍可能产生冗余或错误的子查询，影响最终答案；
- 聚合器对冲突解决依赖规则与 LLM 推理，可能导致误合并或遗漏信息；
- 运行时主要受 LLM 推理延迟与操作符排名循环影响，吞吐量有限；
- 需要手动编写或维护适配器以支持新系统；
- 对极其跨模态交互（例如同时处理文本+图像+表格）仍存在性能瓶颈。

---

## 483. Cross-Modal Alignment and Fusion for RGB-D Transmission-Line Defect Detection

**arXiv ID:** 2602.01696 | [PDF](https://arxiv.org/pdf/2602.01696v1)

**作者:** Jiaming Cui `[一作]` (Harbin Institute of Technology), Feng Shen `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 18374 | [OpenAlex ID](https://openalex.org/A5042624998)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究利用RGB‑D融合的输电线路缺陷检测，提出CMAFNet网络实现对齐与融合。

**💡 创新点**

创新点在于“purify‑then‑fuse”策略，先用字典重组模块去噪再通过上下文语义集成框架进行全局注意力对齐。

**🔧 技术方法**

采用字典‑based 语义重组、局部/全局注意力（partial‑channel + ASRM）、双分支编码器、FPN+PAN、CSIF等多种深度学习技术。

**📊 数据集**

使用大规模TL‑RGBD输电线路RGB‑D数据集进行训练与评估。

**📈 对比分析**

与YOLO、DINO、RT‑DETR、TinyDef‑DETR等基线对比，CMAFNet‑x在mAP_50达32.2%、AP_s12.5%，轻量版4.9M参数mAP_50 24.8%，推理速度228 FPS，整体性能优于现有方法。

**⚠️ 局限性**

局限包括需同步且对齐的RGB‑D输入、字典容量需经验调参、对极小或低对比度缺陷的鲁棒性仍有提升空间，以及未考虑多模态时序一致性。

---

## 484. Beyond the Single Turn: Reframing Refusals as Dynamic Experiences Embedded in the Context of Mental Health Support Interactions with LLMs

**arXiv ID:** 2602.01694 | [PDF](https://arxiv.org/pdf/2602.01694v1)

**作者:** Ningjing Tang `[一作]` (Carnegie Mellon University), Hong Shen `[通讯]` (Carnegie Mellon University)

**通讯引用:** 3508 | [OpenAlex ID](https://openalex.org/A5062298555)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

对LLM在心理健康支持场景中的拒绝行为进行序贯混合方法研究，探究用户与专业人士的体验与解释。

**💡 创新点**

将拒绝视为跨阶段的动态体验，提出五阶段框架（期望、触发、表述、资源转介、后续）并给出相应设计建议。

**🔧 技术方法**

主要使用LLM（如ChatGPT）与人类参与者的访谈、问卷；采用定性主题分析和描述性统计进行数据处理。

**📊 数据集**

调查样本为美国53名终端用户与心理健康专业人士，访谈样本为16名用户和10名专业人士，收集真实拒绝案例与情境描述。

**📈 对比分析**

不以单一准确率评估拒绝，而是从用户期望、意图识别、拒绝表述、资源推荐、后续支持等多维度进行评价；本研究提供定性分析与建议，未给出数值性能对比。

**⚠️ 局限性**

样本局限于美国、文化与监管背景单一、只覆盖有限支持类型、受自愿志愿者偏差影响、缺乏跨国或跨文化验证。

---

## 485. SMTrack: State-Aware Mamba for Efficient Temporal Modeling in Visual Tracking

**arXiv ID:** 2602.01677 | [PDF](https://arxiv.org/pdf/2602.01677v1)

**作者:** Yinchao Ma `[一作]`, Tianzhu Zhang `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `aaccfe5c-6b26-4208-b23c-35331481e142` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了基于状态空间模型的视觉跟踪框架 SMTrack，实现长程时序建模与目标判别

**💡 创新点**

创新点包括：①设计选择性状态感知空间模型 SASM，使用状态层级时间尺度捕捉多样化时序线索；②采用因果扫描机制，消除模板与未来信息交叉扫描，显著降低跟踪时的计算负担；③通过隐藏状态传播与更新实现无额外模块的高效时序交互

**🔧 技术方法**

核心技术：Mamba式状态空间模型（SSM）、状态层级时间尺度（state‑wise Δ）、隐藏状态递归传播、因果扫描、无卷积/注意力的线性时序交互

**📊 数据集**

使用 COCO、LaSOT、GOT‑10K、TrackingNet 等公开跟踪数据集进行训练和评估

**📈 对比分析**

与 CNN、Transformer 以及多时序跟踪器（如 ROMTrack、VideoTrack、SeqTrack 等）对比，SMTrack 在 GOT‑10K、TrackingNet、LaSOT 等基准上获得最高或接近最高的 AO/SR/AUC，同时 GFLOPs 仅为 21.7–48.7，帧率 34–50 FPS，显著提升性能与效率

**⚠️ 局限性**

主要局限：相较于 Transformer，SASM 的并行度较低，受限于 GPU/TPU 对矩阵乘法的优化，导致速度潜力未充分释放

---

## 486. Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss

**arXiv ID:** 2602.01673 | [PDF](https://arxiv.org/pdf/2602.01673v1)

**作者:** Enguang Fan `[一作]` `[通讯]` (University of Illinois at Urbana-Champaign), Enguang Fan (University of Illinois at Urbana-Champaign)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文在视觉SLAM中将深度学习模型NetVLAD作为循环闭环检测模块，并与传统的动态词袋（DBoW）在KITTI数据集上进行对比实验，提出了细粒度Top‑K精确率-召回率曲线评估方法。

**💡 创新点**

创新之处在于把NetVLAD这类VPR特征迁移至LCD任务，并通过Faiss加速最近邻检索实现实时性能，同时引入细粒度Top‑K评估曲线以适应LCD多匹配的特性。

**🔧 技术方法**

采用NetVLAD全局描述子、Faiss近似最近邻搜索、SLAM管线中的关键帧选择与时序一致性检测，以及基于欧氏距离/余弦相似度的匹配评分。

**📊 数据集**

实验使用KITTI视觉SLAM基准数据集中的左摄像头单目灰度序列，共4541帧，并根据相对位姿阈值生成循环闭环的ground‑truth。

**📈 对比分析**

通过将NetVLAD+Faiss与ORB+DBoW的编码与检索时间、Top‑K（1/5/10/25）的精确率与召回率进行对比，发现NetVLAD在保持更高精确率的同时检索速度超过DBoW，且平均每帧处理时间低于100 ms，符合实时要求。

**⚠️ 局限性**

主要局限在于NetVLAD的编码时间较长、需GPU加速、存储开销大，以及仅在KITTI上验证，缺乏跨场景与多模态的泛化评估。

---

## 487. ASGMamba: Adaptive Spectral Gating Mamba for Multivariate Time Series Forecasting

**arXiv ID:** 2602.01668 | [PDF](https://arxiv.org/pdf/2602.01668v1)

**作者:** Qianyang Li `[一作]` (Xi'an Jiaotong University), Yueqi Xing `[通讯]` (Shandong New Beiyang Information Technology Co., Ltd)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

设计并实现了一种名为ASGMamba的线性复杂度多变量时间序列预测框架，结合自适应频谱门控与Mamba状态空间模型，在长序列上提升预测精度并显著降低内存占用。

**💡 创新点**

首次将局部FFT频谱能量引入门控机制，实现高频噪声的动态抑制；通过多尺度分块与可学习节点嵌入恢复多变量语义；保持整体O(L)线性复杂度。

**🔧 技术方法**

使用结构化状态空间模型（SSM）Mamba、局部FFT频谱门控、重叠分块与多尺度融合、可学习节点嵌入、RevIN实例归一化等技术。

**📊 数据集**

在九个公开基准数据集上评估，包括Electricity、Traffic、Weather、Exchange‑Rate、Solar、ETTh1/ETTh2、ETTm1/ETTm2。

**📈 对比分析**

与10+主流基准（Transformer、PatchTST、iTransformer、Crossformer、FEDformer、TimeMixer、TimesNet、DLinear、S‑Mamba等）在四个预测时长（96/192/336/720）上对比；ASGMamba在多数数据集上取得最优或第二优的MSE/MAE，并在显存占用和推理速度上实现显著优势，体现出优异的效率‑精度权衡。

**⚠️ 局限性**

在高维度、大通道数场景（如Traffic、Electricity）时，激进的频谱门控可能误抑制有意义的高频信息，导致性能略逊于某些Transformer基准；对极端高通道数的可扩展性和对突发异常的鲁棒性仍需进一步提升。

---

## 488. Position: The Inevitable End of One-Architecture-Fits-All-Domains in Time Series Forecasting

**arXiv ID:** 2602.01736 | [PDF](https://arxiv.org/pdf/2602.01736v1)

**作者:** Qinwei Ma `[一作]` (Tsinghua University), Zaiwen Yang `[通讯]` (Tsinghua University)

**通讯引用:** 8814 | [OpenAlex ID](https://openalex.org/A5100422486)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

该论文指出并分析了时间序列预测中单一架构无法兼顾域特定SOTA与跨域泛化的问题，并主张将研究焦点转向域特定模型或元学习方法。

**💡 创新点**

提出了“不可调和冲突”论点，系统阐释了域异质性与数据稀缺对通用架构的限制，并提出将研究方向从通用网络结构转向域特定架构与元学习框架的策略。

**🔧 技术方法**

综述并对比了Transformer、线性、CNN、MLP混合等通用架构；分析了DLinear等简单模型的对比；讨论了多模态、预训练基础模型以及LLM驱动的元学习等新技术。

**📊 数据集**

以多域基准数据集（Electricity、Traffic、Weather、ETT、ECL、TFB、Gift-eval 等）为评测基础，并引用了 Kaggle/Optiver、Jane Street 等实际竞赛数据。

**📈 对比分析**

通过跨域基准比较，指出通用模型与域特定SOTA相比仍显落后，性能提升有限；评测高度敏感，超参数调优能让多模型在平均指标上“抢夺SOTA”，但在单域真实应用中效果差距明显。

**⚠️ 局限性**

论文主要为立场与综述性，缺乏系统实验验证；所提元学习与域特定策略仍处于概念阶段，实际实现与泛化效果待进一步验证。

---

## 489. Voting-based Pitch Estimation with Temporal and Frequential Alignment and Correlation Aware Selection

**arXiv ID:** 2602.01727 | [PDF](https://arxiv.org/pdf/2602.01727v1)

**作者:** Junya Koguchi `[一作]` (CyberAgent), Tomoki Koriyama `[通讯]` (CyberAgent)

**通讯引用:** 613 | [OpenAlex ID](https://openalex.org/A5024181978)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文对基频估计中的投票集成方法进行理论分析，并提出两项改进：时频对齐校正与贪心子集选择，提升估计精度与鲁棒性。

**💡 创新点**

创新点在于：①从误差方差与Condorcet陪审团定理出发提供投票方法的理论解释；②通过预对齐校正各估计器的时间/频率偏差，消除聚合时的误差漂移；③设计基于误差相关性的贪心子集选择算法，实现少量估计器即可达到接近全集的性能。

**🔧 技术方法**

采用的技术包括：中位数投票（对基频估计）、众数投票（Voiced/Unvoiced 判别）、时频对齐（使用 RPA 相似度搜索最优时间偏移与频率偏置），以及贪心算法（按 RPA 或误差相关性递增选取估计器）。

**📊 数据集**

实验数据集涵盖语音（Bagshaw、Keele、CMU ARCTIC、PTDB‑TUG、MOCHA‑TIMIT）、歌唱（MIR‑1K）和乐器（MDB‑stem‑synth），并在 NOISEX92、QUT‑NOISE 生成的不同 SNR 噪声下评估鲁棒性。

**📈 对比分析**

与 9 种单独基频估计器（RAPT、SWIPE'、pYIN、DIO、REAPER、Harvest、Praat、CREPE、FCNF0++）相比，投票方法在无噪声条件下的 RPA 与 Voiced/Unvoiced recall 均优于单体方法；加入对齐后性能进一步提升；在加入噪声时仍保持较高的 Voiced/Unvoiced recall，但在极低 SNR 时性能会落后于某些 DNN 基础估计器。贪心子集选择在方法数限制时亦能获得接近全集的效果。

**⚠️ 局限性**

局限性包括：在极低 SNR 环境下仍不足以匹敌部分 DNN 基础方法；对齐与选择过程依赖于先验估计器集合，若包含高度相关或偏差大的估计器，仍可能影响精度；目前仅在实验数据集上验证，缺乏对真实世界（in‑the‑wild）信号的进一步评估。

---

## 490. SafePred: A Predictive Guardrail for Computer-Using Agents via World Models

**arXiv ID:** 2602.01725 | [PDF](https://arxiv.org/pdf/2602.01725v1)

**作者:** Yurun Chen `[一作]` (Zhejiang University), Shengyu Zhang `[通讯]` (Zhejiang University)

**通讯引用:** 2881 | [OpenAlex ID](https://openalex.org/A5100757082)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `9cc9baba-5356-466d-81ff-d80028d90279` `5b4c1114-4a70-478e-9921-2514ee03850d` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了基于世界模型的可预测安全栅栏SafePred，能预测短期与长期风险并将其转化为决策指导，提升计算机使用代理的安全性与任务效率。

**💡 创新点**

创新点在于：①将未来风险预测与当前决策对齐的可预测守护理念；②利用LLM世界模型以语义形式一次性预测风险而非多步状态滚动；③构建风险‑决策循环及层级风险/计划指导，提供主动而非被动的安全约束。

**🔧 技术方法**

使用了LLM世界模型（如GPT‑4等）、安全政策解析与结构化、风险评估规则、决策优化（风险引导与计划引导）以及知识蒸馏训练轻量级预测守护模型。

**📊 数据集**

实验基准包括OS‑Harm与WASP两大安全基准，涵盖提示注入、模型误行为等任务；并采集1.5K交互轨迹用于训练预测守护模型。

**📈 对比分析**

与泛化防御、规则遍历、HarmonyGuard、GuardAgent等基线进行对比，采用PCR、SR、SUP、ACC、FPR等指标；SafePred在PCR达到97.6%（比HarmonyGuard提升4.7%），并将任务成功率提升21.4%以上。

**⚠️ 局限性**

局限性在于：高度依赖LLM推理能力和安全政策质量，模型规模与训练数据敏感；在极端对抗或知识不足场景下可能过度过滤或误判；目前尚未验证跨模态或更广泛平台的通用性。

---

## 491. Revisiting Generalization Measures Beyond IID: An Empirical Study under Distributional Shift

**arXiv ID:** 2602.01718 | [PDF](https://arxiv.org/pdf/2602.01718v1)

**作者:** Sora Nakai `[一作]` (Kyoto University), Hiroki Naganuma `[通讯]` (Mila)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `5b4c1114-4a70-478e-9921-2514ee03850d` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

对超过10,000个模型配置进行大规模实验，评估40种通用性测度在IID与多种分布偏移（CIFAR‑10-C/P、DomainBed自然域移）下的预测能力。

**💡 创新点**

首次将校准指标和信息准则纳入通用性评估，并在不同模型架构与训练配置上验证其在OOD场景下的高预测性；揭示传统认为无效的度量在分布偏移时可能变得非常有效；指出目前普遍使用的“最佳”度量在不同环境下可能失效，强调多指标综合评估的重要性。

**🔧 技术方法**

采用基于Kendall τ的granulated score和sign‑error分布进行相关性与鲁棒性评估；计算各种类别测度（Baseline、Norm/Margin、Sharpness、Optimization、Information Criteria、Calibration）并通过大规模超参数搜索实现可重复性。

**📊 数据集**

使用CIFAR‑10及其Corruption/Pattern扩展（CIFAR‑10‑C、CIFAR‑10‑P），以及DomainBed中的VLCS、PACS数据集，覆盖人工合成偏移与自然域差异两类OOD情形。

**📈 对比分析**

通过对比各测度在IID和OOD下的τ相关系数、granulated score以及sign‑error分布，发现Sharpness和Optimization在OOD下表现最稳健；Calibration与Information Criteria在OOD中相对表现提升；在IID下多类别测度相关性低甚至相反；整体没有单一测度在所有情形下保持高预测性。

**⚠️ 局限性**

局限性包括：仅评估小到中等规模网络，未验证大规模Transformer或预训练模型；分析基于相关性，缺乏因果推断；超参数搜索范围虽广但仍受限于实验预算；未来需在更大模型与更丰富OOD场景中验证结果。

---

## 492. BBPE16: UTF-16-based byte-level byte-pair encoding for improved multilingual speech recognition

**arXiv ID:** 2602.01717 | [PDF](https://arxiv.org/pdf/2602.01717v1)

**作者:** Hyunsik Kim `[一作]` (Samsung Research), Kyungmin Lee `[通讯]` (Samsung Research)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出并评估了一种基于UTF‑16的字节级BPE（BBPE16）分词器，用于多语言语音识别系统，提升跨语言token共享与token效率。

**💡 创新点**

核心创新在于将UTF‑8换为UTF‑16编码，使大多数现代脚本（尤其是CJK）统一使用2字节表示，从而显著降低token数量并增强跨语言共享，且不牺牲准确率。

**🔧 技术方法**

采用字节对合并（BPE）算法处理UTF‑16字节序列，结合ESPnet框架下的E‑Branchformer编码器、Transformer解码器以及beam search解码技术。

**📊 数据集**

使用LibriSpeech（英语）、KsponSpeech（韩语）、AISHELL‑1（中文）进行单/双/三语实验，进一步加入WSJ、Zeroth（韩语）和Common Voice Chinese（中文）进行持续学习评估。

**📈 对比分析**

与传统字符BPE和UTF‑8 BBPE对比，BBPE16在单语、双语、三语以及持续学习场景中保持或略优的WER/CER；在中文token数量上相较UTF‑8 BBPE降低4.6%，在持续学习中文数据集CVC上降至10.4%，对应解码迭代减少10.3%，实现训练与推理效率提升。

**⚠️ 局限性**

局限性包括对BMP外字符（如补充区字符）的支持仍需额外处理；对英语等拉丁文字的token效率提升有限；需要在更大规模、更丰富多语料上进一步验证其泛化性能。

---

## 493. MedAraBench: Large-Scale Arabic Medical Question Answering Dataset and Benchmark

**arXiv ID:** 2602.01714 | [PDF](https://arxiv.org/pdf/2602.01714v1)

**作者:** Mouath Abu-Daoud `[一作]` (New York University), Farah E. Shamout `[通讯]` (New York University)

**通讯引用:** 930 | [OpenAlex ID](https://openalex.org/A5023660328)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并公开了 MedAraBench，一个包含 24,883 题的阿拉伯语医学多项选择题大规模基准，涵盖 19 个医学专业与 5 个难度等级，旨在评估 LLM 在阿拉伯医学推理任务中的零样本性能。

**💡 创新点**

创新点在于填补了阿拉伯语医学领域的资源空白：提供了规模化、专业化且经过专家与 LLM-as-a-judge 双重评估的高质量数据集，并为多语言医疗 NLP 提供了可复现的评测框架。

**🔧 技术方法**

使用的技术包括人工标注与清洗、基于 LLM 的自动评测、零样本与少样本推理评估、QLoRA 参数高效微调以及多种开源与专有大型语言模型（如 GPT‑5、Gemini‑2.0‑Flash、Claude‑4‑Sonnet 等）。

**📊 数据集**

数据集来源为从阿拉伯地区医学专业人员收集的纸质考试材料，经过专业打字员数字化、手工清洗后生成多项选择题集合；训练/测试拆分为 80%/20% 并按专业与难度分层随机划分。

**📈 对比分析**

在零样本评估中，专有模型（GPT‑5、GPT‑o3、Claude‑4‑Sonnet）平均准确率约 0.76，显著优于开源模型（如 llama‑3.3‑70b‑instruct 0.55、deepseek‑chat‑v3‑0324 0.62），表明规模与强化学习策略对医学推理有显著提升；少样本学习与 QLoRA 微调能分别提升约 12% 与 88% 的准确率。

**⚠️ 局限性**

局限性包括：仅覆盖选择题类任务，缺乏生成式或多模态评测；数据主要为标准书面阿拉伯语，可能不适用于方言环境；难度分布偏向低难度，难以评估高级临床推理；专家评测一致性有限；潜在的文档重叠或污染风险。

---

## 494. Optimizing Prompts for Large Language Models: A Causal Approach

**arXiv ID:** 2602.01711 | [PDF](https://arxiv.org/pdf/2602.01711v1)

**作者:** Wei Chen `[一作]` (University of Connecticut), Xuan Wei `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 34132 | [OpenAlex ID](https://openalex.org/A5009248953)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出一种基于因果推断的查询级提示优化框架Causal Prompt Optimization（CPO），通过离线因果奖励模型实现对大语言模型提示的动态定制。

**💡 创新点**

创新点在于将提示设计视为因果效应估计问题，并使用双重机器学习（DML）在语义嵌入空间中剥离提示与查询的混杂效应。

**🔧 技术方法**

主要技术包括语义嵌入+PCA得到潜在治疗变量、DML估计CATE以及因果导向的树搜索生成与评估提示。

**📊 数据集**

实验使用数学推理（MATH）、可视化生成（VisEval）和数据分析（DABench）三大基准数据集。

**📈 对比分析**

与人类手工、传统提示、以及多种自动优化方法对比，CPO在所有基准上均取得最高或接近最高准确率，尤其在困难子集表现突出。

**⚠️ 局限性**

主要局限在于对PCA降维与重叠假设的依赖、需要足够离线数据、以及对非文本多模态任务的适应性尚未验证。

---

## 495. Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner

**arXiv ID:** 2602.01705 | [PDF](https://arxiv.org/pdf/2602.01705v1)

**作者:** Haoqiang Kang `[一作]` (University of California San Diego), Lianhui Qin `[通讯]` (University of California San Diego)

**通讯引用:** 40 | [OpenAlex ID](https://openalex.org/A5098623484)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了在连续潜在空间中进行强化学习探索的框架 LaDi‑RL，以改进大型语言模型的推理能力。

**💡 创新点**

创新点在于将强化学习从离散词级空间迁移到多步潜在扩散过程，并通过潜在抑制力实现多模态多样性保持。

**🔧 技术方法**

技术包括潜在扩散推理（LaDiR）、Group Relative Policy Optimization (GRPO) 在潜在空间的应用、基于距离的抑制引导以及联合潜在与文本策略训练。

**📊 数据集**

实验使用代码生成任务中的 HumanEval、MBPP 及其扩展、LiveCodeBench v6，以及数学推理任务中的 AIME 2024/25、AMC 2023、MATH‑500、Minerva Math、OlympiadBench。

**📈 对比分析**

与离散 RL、现有潜在推理和扩散模型相比，LaDi‑RL 在 pass@1 方面分别提升约+9.4% 代码生成和 +5.7% 数学推理，且在 pass@k 上显著避免多样性崩塌，达到基线上限。

**⚠️ 局限性**

局限性包括需要额外的潜在压缩与解码步骤、对扩散模型训练的计算成本，以及在极大样本规模下的可扩展性尚未充分验证。

---

## 496. $\textbf{AGT$^{AO}$}$: Robust and Stabilized LLM Unlearning via Adversarial Gating Training with Adaptive Orthogonality

**arXiv ID:** 2602.01703 | [PDF](https://arxiv.org/pdf/2602.01703v1)

**作者:** Pengyu Li `[一作]` (Xi'an Jiaotong University), Jun Liu `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 73966 | [OpenAlex ID](https://openalex.org/A5100361698)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 AGTAO 框架，实现对大型语言模型的机器无学习（unlearning），在彻底删除敏感知识的同时保持模型的原有功能；

**💡 创新点**

创新点包括 Adaptive Orthogonality（AO）软正交约束来缓解遗忘与保留梯度冲突，以及 Adversarial Gating Training（AGT）在潜在空间内的 min‑max 对抗训练，并引入梯度范数门控的课程式策略；

**🔧 技术方法**

主要技术手段是梯度正交正则化、潜在空间对抗攻击（PGD）、梯度范数门控的自适应对抗训练、以及软投影的梯度约束；

**📊 数据集**

实验使用了 TOFU、MUSE 与 WMDP 三大基准数据集，分别针对虚构传记、版权文本和网络安全风险的无学习评估；

**📈 对比分析**

与 GA、NPO、RMU、LAT、PGU 等传统与先进方法比较，AGTAO 在知识忘却率（KUR）≈0.01、模型效用与流畅度均接近或优于重训练基准，并在隐私泄露率（PLR）保持在 ≈0.5，表现出更优的忘却与鲁棒性平衡；

**⚠️ 局限性**

局限性在于 min‑max 对抗训练增加了计算开销，且当前验证规模仅在中等大小模型，未来需要优化效率并验证更大模型的可扩展性。

---

## 497. Tilt-Ropter: A Novel Hybrid Aerial and Terrestrial Vehicle with Tilt Rotors and Passive Wheels

**arXiv ID:** 2602.01700 | [PDF](https://arxiv.org/pdf/2602.01700v1)

**作者:** Ruoyu Wang `[一作]` (University of Hong Kong), Ben M. Chen `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 13697 | [OpenAlex ID](https://openalex.org/A5100428803)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `51c0528b-f690-4182-ae60-bb5f046c276c` `a8e75ba4-7a2d-4153-b003-06c94533add0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

设计、建模并实现了一款名为 Tilt‑Ropter 的混合空地车辆，采用倾转旋翼与被动轮结合，实现空中飞行与地面滑行的无缝切换，并提供统一的力矩预测控制与外部力矩估计。

**💡 创新点**

创新点：
• 采用全致动倾转旋翼与被动轮的组合，既保持空中机动性又实现低能耗地面运动；
• 提出基于力矩的非线性模型预测控制框架，融合接触约束与非匀速约束；
• 开发了考虑伺服动力学的外部力矩估计方法，显著提升地面接触鲁棒性。

**🔧 技术方法**

技术方法：
• 非线性模型预测控制（NMPC）与力矩控制分配；
• 伺服动力学建模与一阶低通滤波的外部力矩估计；
• EKF 状态估计与 Gazebo / ODE 物理仿真（SITL 与 HITL）；
• 低功耗电机与伺服驱动的硬件实现。

**📊 数据集**

数据集：未使用公开数据集，而是通过自建 Gazebo 模拟环境与真实机器人在实验室采集的飞行与地面运动数据进行验证。

**📈 对比分析**

比较方法与性能：
• 轨迹跟踪误差（RMSE）：空中 0.052 m，地面 0.145 m，空地混合 0.125 m；
• 功率消耗对比：空中 653.64 W，地面 47.38 W，地面仅为空中功率的 7.2%；
• 结果表明系统在多模态运动下具备较低误差与显著能耗优势。

**⚠️ 局限性**

局限性：
• 伺服速度限制导致力矩快速变化时可能出现滞后；
• 仅在平坦地面验证，复杂地形与障碍物的鲁棒性待进一步研究；
• 系统整体重量与控制复杂度仍高，进一步的能耗与动力学优化空间存在。

---

## 498. What LLMs Think When You Don't Tell Them What to Think About?

**arXiv ID:** 2602.01689 | [PDF](https://arxiv.org/pdf/2602.01689v1)

**作者:** Yongchan Kwon `[一作]` (Together AI), James Zou `[通讯]` (Stanford University)

**通讯引用:** 38258 | [OpenAlex ID](https://openalex.org/A5005779176)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究16种LLM在极简主题中立提示下的生成行为，生成256k样本并系统分析其主题偏好、子类别专业化、技术深度以及退化文本模式；

**💡 创新点**

首次以最小化提示探索LLM的“头脑中”生成内容，揭示不同模型家族在主题偏好、深度水平和退化文本方面的系统性差异，并将此现象应用于安全监测和模型指纹识别；

**🔧 技术方法**

采用topic‑neutral开放式提示、自动退化文本截断、LLM自标注标签、句向量嵌入（如OpenAI Embeddings）、UMAP可视化、JS散度相似度评估等技术进行数据生成与分析；

**📊 数据集**

构建并公开256,000条生成样本数据集（覆盖123个主要类别），来自16个模型（GPT‑OSS、DeepSeek、Llama、Qwen 等）；

**📈 对比分析**

通过类别分布、子类别细分、技术深度分层、退化文本比例及相似度分析进行比较，结果显示GPT‑OSS偏向程序/数学，Llama偏向文学，DeepSeek宗教，Qwen多选题；退化文本比例最高10.3%（Qwen）；

**⚠️ 局限性**

仅进行模型族层面分析，难以区分同族内部个体模型；提示设计可能影响结果；退化文本过滤不完美，数据中仍可能存在有害或隐私信息；

---

## 499. Semantic-aware Wasserstein Policy Regularization for Large Language Model Alignment

**arXiv ID:** 2602.01685 | [PDF](https://arxiv.org/pdf/2602.01685v1)

**作者:** Byeonghu Na `[一作]` (KAIST), Il-Chul Moon `[通讯]` (summary.ai)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了基于熵正则化Wasserstein距离的RLHF策略正则化方法（WPR），通过Sinkhorn算法实现可训练的语义感知正则项。

**💡 创新点**

首次在RLHF中使用Wasserstein距离替代传统KL或f-散度，从而让策略正则化能够捕捉词义相似度。

**🔧 技术方法**

利用熵正则化Wasserstein（Sinkhorn）距离的对偶形式、Sinkhorn‑Knopp迭代以及标准RL算法（如PPO）实现训练。

**📊 数据集**

在TL;DR摘要、Anthropic Helpful & Harmless对话、MT‑Bench以及APPS代码生成等多种数据集上评估。

**📈 对比分析**

与KL、forward KL、JS、α‑divergence、χ²、TV等f‑散度以及RKL等基线对比，WPR在TL;DR和HH‑RLHF的GPT‑4赢率、MT‑Bench分数、代码生成pass@1均显著提升（如TL;DR 0.924 vs RKL 0.848）。

**⚠️ 局限性**

仍需手动调参正则强度β；Sinkhorn迭代和截断近似增加计算负担，且对大词表规模仍有O(d²)开销。

---

## 500. Towards Autonomous Instrument Tray Assembly for Sterile Processing Applications

**arXiv ID:** 2602.01679 | [PDF](https://arxiv.org/pdf/2602.01679v1)

**作者:** Raghavasimhan Sankaranarayanan `[一作]` (University of Louisville), Yash Chitalia `[通讯]` (University of Louisville)

**通讯引用:** 482 | [OpenAlex ID](https://openalex.org/A5001760308)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `e0540dec-d77f-42db-94ae-d039248f6393` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

开发了一套自动化的手术器械盘装机器人系统，在SPD流程中实现了从视觉感知到机械抓取再到结构化包装的完整闭环，配合人工检验完成高效、规范的器械盘组装。

**💡 创新点**

创新点在于：①提出了面向器械的混合感知框架，结合YOLO12、SAM与分部特征的ResNet18实现对形状相近、尺寸差异微小的器械进行细粒度分类；②设计了模块化的3D打印隔板与持夹，物理隔离器械，显著降低搬运碰撞；③将盘装抽象为“受限空间分配”问题，提出基于规则的高效排布算法，兼顾器械形态、组别与盘尺寸。

**🔧 技术方法**

技术包括：YOLO12目标检测、SAM分割与姿态估计、ResNet18分部分类、ESP32控制的双电磁抓取器、Stäubli TX2-60L 6-DOF机械臂、摄像头手眼标定、基于PCA的姿态推算、规则化排布算法及实验验证。

**📊 数据集**

使用自采31种手术器械共6,975张标注图像的自定义数据集，涵盖不同光照、背景与距离的顶视图，注释为YOLO格式，用于训练检测与分类模型。

**📈 对比分析**

与人工组装盘及无算法随机组装盘进行对比，采用振动和倾斜实验测量碰撞次数。机器人组装盘在位移和倾斜测试中碰撞次数分别为4.0±1.1和1.8±0.4，显著低于基线（11.4±5.0、7.8±3.8）和无算法组（5.0±2.0、3.6±1.0），统计效应量大（Cohen’s d>2），表明结构化包装有效降低碰撞与磨损。

**⚠️ 局限性**

局限性包括：仅在单一尺寸、单向摆放的盘装环境验证；未涵盖多方向、多层次排布；电磁抓取器对非磁性金属（如钛）或塑料器械不适用；实验样本量有限，需在真实SPD环境和用户研究中进一步验证；对人机交互的易用性与认知负荷未做系统评估。

---

## 501. Tail-Aware Post-Training Quantization for 3D Geometry Models

**arXiv ID:** 2602.01741 | [PDF](https://arxiv.org/pdf/2602.01741v1)

**作者:** Sicheng Pan `[一作]` (Tsinghua Shenzhen International Graduate School), Zhi Wang `[通讯]` (Tsinghua Shenzhen International Graduate School)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

提出了TAPTQ，一种针对3D几何模型的后训练量化（PTQ）管道。

**💡 创新点**

创新点包括：① 逐步粗细校准集构建策略；② 将量化区间搜索转化为三分搜索优化；③ 采用尾部相对误差（TRE）指导的模块级低秩补偿。

**🔧 技术方法**

技术手段包括：多视角特征聚类、K‑means筛选、三分搜索、低秩自适应补偿、尾部误差度量。

**📊 数据集**

使用的数据集包括 VGGT、Pi3、7Scenes、ETH3D 与 Co3Dv2 等3D几何基准。

**📈 对比分析**

与 RTN、PTQ4ViT、RepQ、ERQ、GPTQ 等基线在 W4A8/W6A6/W8A8 低位宽下对比，TAPTQ 在精度、误差、法向一致性上均优于现有方法，且校准时间显著下降。

**⚠️ 局限性**

局限性：仍需手动选择校准阈值、依赖一定量的校准样本，且在更大规模模型与极端噪声场景下的鲁棒性待进一步验证。

---

## 502. Mitigating loss of control in advanced AI systems through instrumental goal trajectories

**arXiv ID:** 2602.01699 | [PDF](https://arxiv.org/pdf/2602.01699v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 503. Mutual-Guided Expert Collaboration for Cross-Subject EEG Classification

**arXiv ID:** 2602.01728 | [PDF](https://arxiv.org/pdf/2602.01728v1)

**作者:** Zhi Zhang `[一作]` (Hong Kong Polytechnic University), Shuqiang Wang `[通讯]` (Shenzhen Institutes of Advanced Technology)

**通讯引用:** 6042 | [OpenAlex ID](https://openalex.org/A5082547911)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `afceb026-1760-41ae-8d86-010831a37d97` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种名为 Mutual-Guided Expert Collaboration (MGEC) 的框架，利用共享专家与分流专家协同学习，以提升 EEG 信号在跨受试者上的解码性能。

**💡 创新点**

理论上揭示了“可归约成本”与共享专家与分流专家选择的关系，并设计互导学习机制，避免过度归约与欠归约，从而实现两种专家优势的有效融合。

**🔧 技术方法**

采用共享专家与混合专家（Mixture-of-Experts）网络，结合联合嵌入损失、原型路由、熵平衡、辅助平衡损失及互导加权损失；在多任务场景下，还利用基础模型（如CBraMod）作为骨干。

**📊 数据集**

使用七个公开 EEG 数据集：KUL、DTU、AVED（听觉注意解码）；BCI IV‑2a、BCI IV‑2b（运动想象）；Sleep‑EDFx、ISRUC‑3（睡眠分期），以及构造的合成域推广数据集。

**📈 对比分析**

与多种基准方法（CNN、SSF‑CNN、MBSSFCC、DBPNet、DARNet、ListenNet 等任务特定模型，以及基于 Bagging/Boosting 的集成模型）进行对比。实验表明 MGEC 在所有任务上均取得最高或竞争性最佳性能：如 KUL 上 81.7%（相对 78.1%），BCI‑IV‑2a 上 61.3%（相对 60.2%），Sleep‑EDFx 上 84.1%（相对 83.2%）。

**⚠️ 局限性**

限制主要包括：在跨受试者差异相对较小的任务（如睡眠分期）提升有限；模型结构更复杂，训练和推理成本上升；需要合理设定专家数量、路由策略与权重，过度或不足的归约可能导致性能退化。

---

## 504. DenVisCoM: Dense Vision Correspondence Mamba for Efficient and Real-time Optical Flow and Stereo Estimation

**arXiv ID:** 2602.01724 | [PDF](https://arxiv.org/pdf/2602.01724v1)

**作者:** Tushar Anand `[一作]` (Birla Institute of Technology and Science), Abhijit Das `[通讯]` (Birla Institute of Technology and Science)

**通讯引用:** 1588 | [OpenAlex ID](https://openalex.org/A5025520963)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5a7d414a-27d1-4de0-aac0-e554088edeb4` `6514db3d-8de6-452c-91b7-acdb31787cc4` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文提出一种新的Mamba块DenVisCoM及其混合架构，用于实时精确估计光流与视差。

**💡 创新点**

创新点在于将视觉对应机制嵌入Mamba的序列变换，使用双侧卷积分支与SSM扫描分支实现双图像特征联合学习，并结合自注意力与交叉注意力提升跨视角信息融合。

**🔧 技术方法**

核心技术包括改进的DenVisCoM Mamba块、Transformer自/交叉注意力、Patch嵌入、ResNet18编码器、全局匹配层以及多任务训练与零样本迁移。

**📊 数据集**

主要使用的数据集有SceneFlow（FlyingThings、Monkaa、Driving）、KITTI 2015（光流与视差）、Sintel（光流与视差）以及VKITTI1，训练过程中还在Flying-Chairs和Sintel上进行预训练。

**📈 对比分析**

与RAFT、Unimatch、MemFlow、MambaVision等方法对比，DenVisCoM在KITTI15光流的EPE降至1.34、F1-all 2.52、S10-40 0.74、S40+ 3.15，同时FPS提升至39.88，显著优于对比基线；在视差任务中EPE降至0.27、D1 0.005，速度达到46.03FPS，内存约325MB，整体性能优于现有SOTA。

**⚠️ 局限性**

局限性包括在大幅度动态场景（如Sintel Final）仍存在较高误差，对复杂环境下的细粒度运动仍需进一步改进，且模型在极端遮挡或低纹理区域的对应仍易失真。

---

## 505. COMI: Coarse-to-fine Context Compression via Marginal Information Gain

**arXiv ID:** 2602.01719 | [PDF](https://arxiv.org/pdf/2602.01719v1)

**作者:** Jiwei Tang `[一作]` (Tsinghua University), Bo Zheng `[通讯]` (Future Living Lab of Alibaba)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计了一种粗细分层的上下文压缩框架COMI，能在高压缩率下保留查询相关且不冗余的信息；

**💡 创新点**

创新点在于提出边际信息增益（MIG）度量，兼顾相关性与冗余度，动态分配跨组和组内压缩预算；

**🔧 技术方法**

采用Encoder-Decoder架构、MIG驱动的分组重分配与权重池化、跨层语义对齐（LSA）等技术；

**📊 数据集**

使用了四个问答基准（NaturalQuestions、HotpotQA、2WikiMQA、NarrativeQA）和多新闻摘要数据集MultiNews进行评测；

**📈 对比分析**

与多种软/硬压缩方法对比，COMI在32×压缩下Qwen2‑7B的EM提升约25点、在多任务上均超越最优基线，且在长上下文LLM上同样提升效果；

**⚠️ 局限性**

局限在于压缩率需预设，未能实现自适应压缩率的自动推断。

---

## 506. Unmediated AI-Assisted Scholarly Citations

**arXiv ID:** 2602.01686 | [PDF](https://arxiv.org/pdf/2602.01686v1)

**作者:** Stefan Szeider `[一作]` (TU Wien), Stefan Szeider `[通讯]` (TU Wien)

**通讯引用:** 4275 | [OpenAlex ID](https://openalex.org/A5037092803)

**关键词:** `f53a5690-f5d8-493f-989c-dc46a1f99053`

**🎯 论文内容**

信息不足

**💡 创新点**

信息不足

**🔧 技术方法**

信息不足

**📊 数据集**

信息不足

**📈 对比分析**

信息不足

**⚠️ 局限性**

信息不足

---

## 507. Beyond Dense States: Elevating Sparse Transcoders to Active Operators for Latent Reasoning

**arXiv ID:** 2602.01695 | [PDF](https://arxiv.org/pdf/2602.01695v1)

**作者:** Yadong Wang `[一作]` (Nanjing University of Aeronautics and Astronautics), Xiang Chen `[通讯]` (Nanjing University of Aeronautics and Astronautics)

**通讯引用:** 214291 | [OpenAlex ID](https://openalex.org/A5100437036)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了LSTR（Latent Sparse Transcoder Reasoning）框架，将稀疏变码器作为主动推理算子，在连续潜在空间中实现多步推理。

**💡 创新点**

将稀疏特征从仅用于后置解释提升为推理过程中的主动算子，并通过线性传输与稀疏创新双路解耦实现可控语义分辨率。

**🔧 技术方法**

采用稀疏转码器（Latent Transition Transcoder）、Top‑k稀疏瓶颈、Straight‑Through Estimator、Ghost Gradient恢复，以及与预训练LLM冻结参数的LoRA微调。

**📊 数据集**

在GSM8k-Aug、GSM‑Hard、SVAMP、MultiArith四个算术推理基准，以及MATH等更大规模数据集上进行训练与评估。

**📈 对比分析**

与传统CoT、iCoT、Coconut、Distill、CoLaR等显式与隐式推理方法在准确率和推理长度上对比，LSTR在相同压缩率下保持或超越准确率，同时推理长度显著缩短，且解释性和可控性显著提升。

**⚠️ 局限性**

对极端推理难度仍难以与完整CoT匹配，稀疏特征选择的硬约束在极高压缩率下可能导致特征死亡，且模型对训练集分布依赖较大。

---

## 508. FreshMem: Brain-Inspired Frequency-Space Hybrid Memory for Streaming Video Understanding

**arXiv ID:** 2602.01683 | [PDF](https://arxiv.org/pdf/2602.01683v1)

**作者:** Kangcong Li `[一作]` (Fudan University), Tao Chen `[通讯]` (Fudan University)

**通讯引用:** 43151 | [OpenAlex ID](https://openalex.org/A5100357719)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

设计并实现了 FreshMem，一个基于脑认知原理的频域-空间混合记忆网络，用于在线流式视频理解。

**💡 创新点**

将脑的对数时间感知与记忆巩固机制映射到模型中，通过多尺度频率记忆(MFM)和空间缩略记忆(STM)实现短期高保真与长期语义凝练的自适应融合。

**🔧 技术方法**

利用离散傅里叶变换与增量更新、残差保留、频率衰减、余弦相似度分割、可调压缩率与聚类融合等技术，形成三层记忆结构；并在 Qwen2-VL 等大语言模型上做无训练的推理插件。

**📊 数据集**

在三大流式视频 QA 基准（StreamingBench、OV-Bench、OVO-Bench）以及离线视频基准（MLVU、MVBench）上进行评测；使用 Qwen2-VL‑7B、InternVL2‑2B 作为基础模型。

**📈 对比分析**

与原始模型和多种 fine‑tune 方案对比，FreshMem 在 StreamingBench、OV-Bench、OVO-Bench 分别提升 5.20%、4.52%、2.34%；在 MLVU、MVBench 分别提升 2.4%、4.7%；在无训练条件下即可超过部分 fine‑tuned 方法。

**⚠️ 局限性**

目前仍依赖预先定义的阈值与频率参数，对极端长视频或快速切换场景的适应性有限；记忆压缩与分割的可解释性和可调节性仍需进一步优化。

---

## 509. Scaling Search-Augmented LLM Reasoning via Adaptive Information Control

**arXiv ID:** 2602.01672 | [PDF](https://arxiv.org/pdf/2602.01672v1)

**作者:** Siheng Xiong `[一作]` (Georgia Institute of Technology), Faramarz Fekri `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 4390 | [OpenAlex ID](https://openalex.org/A5083854532)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于信息效用的自适应信息控制框架，用于在搜索增强推理过程中调节检索的时机、数量与粒度。

**💡 创新点**

创新点在于定义可量化的检索信息效用，并引入检索继续控制与分层选择扩展两种控制机制；采用annealed control策略将外部控制逐步消除，让模型在训练后内部化良好检索行为。

**🔧 技术方法**

技术包括信息效用度量（新颖性+有效性）、层级选择式扩展、检索继续控制、PPO强化学习、复合奖励（答案正确性、工具使用惩罚、检索效果奖励）以及可调节的控制信号注入。

**📊 数据集**

使用七个常见问答基准：NQ、TriviaQA、PopQA、HotpotQA、2WikiMultiHopQA、Musique、Bamboogle；检索库为2018年维基百科，检索器为E5。

**📈 对比分析**

与无检索、检索、以及无信息控制的RL基线（Search‑R1、R1等）对比，平均提升9.4%（7B）/8.6%（3B）EM；在多数据集均超越基线，且RL训练更稳定、响应长度更合理。

**⚠️ 局限性**

局限性包括：信息效用定义仍相对简单，缺乏不确定性评估；控制阈值与参数需手工设定；当前仅针对单一检索工具和文本模式，未扩展到多模态或多工具环境。

---

## 510. MACD: Model-Aware Contrastive Decoding via Counterfactual Data

**arXiv ID:** 2602.01740 | [PDF](https://arxiv.org/pdf/2602.01740v1)

**作者:** Qixin Xiao `[一作]` (University of Michigan), Kun Zhou `[通讯]` (University of California San Diego)

**通讯引用:** 9334 | [OpenAlex ID](https://openalex.org/A5013961729)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `e0540dec-d77f-42db-94ae-d039248f6393` `aaccfe5c-6b26-4208-b23c-35331481e142` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

设计并实现了一种模型感知的反事实数据对比解码框架 MACD，利用 Video‑LLM 自身的梯度信息来识别并遮挡对预测最重要的对象和帧，从而生成针对性强、质量高的对比样本，在推理阶段通过对比解码抑制幻觉并提升回答质量。

**💡 创新点**

创新点：
- 采用 Video‑LLM 的损失梯度动态定位关键视觉证据，实现对象级和帧级可梯度化遮罩；
- 将生成的对比样本与传统对比解码结合，保持模型参数不变，仅需一次额外前向传播；
- 通过可调的对比权重 α 与可信度阈值 β 实现细粒度控制，兼顾流畅性与真实性。

**🔧 技术方法**

技术细节：
- YOLOv11 目标检测与跟踪，生成软遮罩；
- 对遮罩强度向量 r 进行梯度上升优化（最大化重建损失）；
- 对比解码（CD）公式中加入 α、β 参数，形成基视图与对比视图的 logit 对比；
- 采用可解释的离散化 {0, r0, 1} 使对比样本易于解读。

**📊 数据集**

数据集：EventHallusion、MVBench、Perception-test、Video‑MME，评估 Qwen3‑VL‑2B、Qwen2.5‑VL‑7B/3B、Qwen2‑VL‑7B/2B、InternVL3‑8B 等多种 Video‑LLM。

**📈 对比分析**

实验比较：与 Baseline、VCD、SID 等推理方法对比，所有模型和基准上 MACD 均达到最优或第二优；在 EventHallusion 上显著提升 F1 与准确率；整体减少幻觉率、提升 Precision 与 Recall，性能提升幅度在 5–15% 之间。

**⚠️ 局限性**

局限性：
- 需要为每条视频进行多步梯度优化，推理延时比单纯 CD 稍长；
- 对极端长视频或缺乏明显目标时遮罩效果受限；
- 超参数 α、β 需在不同任务上手动调优，方法对这些参数略敏感；
- 只对对象与帧进行遮罩，可能忽略更细粒度的视觉特征或语义关联。

---

## 511. Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models

**arXiv ID:** 2602.01698 | [PDF](https://arxiv.org/pdf/2602.01698v1)

**作者:** Wenhui Tan `[一作]` (Renmin University of China), Jian Luan `[通讯]` (Xiaomi Inc.)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种无训练的深度条件解码方法LED，用以恢复RL后训练的大型推理模型的探索能力；

**💡 创新点**

利用中间层保留的熵信息，采用累计求和与最大熵选择的自适应层深度解码，突破最终层熵崩塌问题；

**🔧 技术方法**

实现步骤包括：从中间层提取潜在后验、对最终层top‑k进行过滤、累计求和聚合、熵计算选择最佳深度、结合利用探索与利用分支以及仅在DeepThink阶段启用；

**📊 数据集**

在六个推理基准上评估：数学类（GSM8K、MATH‑500、AIME 2024、AIME 2025）、科学类（GPQA‑D）和编程类（LiveCodeBench）；模型覆盖4B–32B大小、Qwen、MiMo、Llama等架构；

**📈 对比分析**

与CoT、DoLa、SoftThinking、SoftThinking‑Gumbel等训练‑自由基线对比，LED平均提升Pass@1约0.7个百分点、Pass@16约0.9个百分点，且生成长度基本不变，显著恢复了高温采样的正向探索效应；

**⚠️ 局限性**

局限性包括：主要针对RL后训练的推理模型；对较老或非推理模型提升有限；需要预先设置深度d、top‑k等超参；若不加深思阶段限制，易引入噪声。

---

## 512. AI-Assisted Adaptive Rendering for High-Frequency Security Telemetry in Web Interfaces

**arXiv ID:** 2602.01671 | [PDF](https://arxiv.org/pdf/2602.01671v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

---

## 513. GSR: Learning Structured Reasoning for Embodied Manipulation

**arXiv ID:** 2602.01693 | [PDF](https://arxiv.org/pdf/2602.01693v1)

**作者:** Kewei Hu `[一作]`, Hanwen Kang `[通讯]`

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出基于语义场景图的结构化推理框架GSR，用于从感知到动作的端到端规划。

**💡 创新点**

创新点在于将世界状态显式建模为语义场景图转移，并通过多阶段训练实现从世界理解到目标推理的完整链路。

**🔧 技术方法**

采用大型语言模型(Qwen3‑8B)与LoRA微调、强化学习GRPO以及基于几何织物的动作专家。

**📊 数据集**

构建大规模Manip‑Cognition‑1.6M数据集，包含场景图理解、行动规划与目标解释三大子集。

**📈 对比分析**

在RLBench、LIBERO与自研GSR‑Bench上进行零射和长序任务评测，GSR平均TP达到90%+，显著优于提示式基线。

**⚠️ 局限性**

局限在于预定义的动作原语约束、对视觉细粒度几何的依赖以及对复杂遮挡下的场景图构建敏感。

---

## 514. Counting Hypothesis: Potential Mechanism of In-Context Learning

**arXiv ID:** 2602.01687 | [PDF](https://arxiv.org/pdf/2602.01687v1)

**作者:** Jung H. Lee `[一作]` (Pacific Northwest National Laboratory), Sujith Vijayan `[通讯]` (Virginia Tech)

**通讯引用:** 2505 | [OpenAlex ID](https://openalex.org/A5101834933)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

针对大型语言模型（LLM）在无梯度更新情况下的In‑Context Learning（ICL）机制，提出了“计数假设”，认为LLM通过FFN和自注意力层提取上下文子空间，并在残差流中并行存储可能答案；随后使用词向量分解（字典学习与独立成分分析）对6款公开LLM的分隔符和答案残差流进行对比，验证子空间共享与ICL性能提升之间的关系；并提出基于编码系数的指标R，用以区分正确与错误预测。

**💡 创新点**

1) 提出了全新的“计数假设”，将ICL解释为在上下文子空间中对答案权重的计数；2) 将FFN视作关联记忆，说明残差流中可能答案的竞争机制；3) 通过字典学习和ICA的组合，对残差流进行子空间分解，首次在实测中揭示分隔符与答案共享子空间；4) 用编码系数比值R作为可解释的ICL可靠性指标。

**🔧 技术方法**

Transformer内部残差流提取、字典学习（scikit‑learn）、独立成分分析（FastICA）、余弦距离、编码系数分析、R比值计算、t检验统计。

**📊 数据集**

6种ICL任务（反义词、同义词、国家首都、英法词对、产品与制造商、人物与运动），使用先前工作提供的生成器产生200个示例集（每个模型共200个prompt），共6款LLM（GPT‑j‑6B、Meta‑Llama‑3.1‑8B、OLMo‑2‑0325‑32B、Phythia‑12B/6.9B、GPT‑NEOX‑20B）。

**📈 对比分析**

对比实验主要在于验证R值在正确与错误预测之间的显著差异（p<0.05），以及不同模型/任务下的最小距离与编码系数之间的相关性。未给出传统指标（如准确率）与其他方法的直接数值对比，但通过统计显著性证明了子空间与ICL结果的关联。

**⚠️ 局限性**

1) 采用理想化示例（顺序不敏感、固定注意力权重）可能与真实场景偏离；2) 仅使用字典学习与ICA两种分解方法，可能无法捕捉所有残差流中的子空间；3) 研究仅覆盖6款LLM和6项任务，缺乏更广泛的泛化验证。

---

## 515. Finite and Corruption-Robust Regret Bounds in Online Inverse Linear Optimization under M-Convex Action Sets

**arXiv ID:** 2602.01682 | [PDF](https://arxiv.org/pdf/2602.01682v1)

**作者:** Taihei Oki `[一作]` (Institute for Chemical Reaction Design and Discovery, Hokkaido University), Shinsaku Sakaue `[通讯]` (CyberAgent)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193`

**🎯 论文内容**

研究在线逆线性优化（情境推荐）中，针对 M‑convex 可行集证明了无噪声时的期望回报上界为 O(d log d)，并在最多 C 次对手性错误下实现了 O((C+1)d log d) 的回报上界。

**💡 创新点**

创新点在于首次将 M‑convex 集的交换性质与几何体积收缩论证相结合，获得了多项式维数依赖的有限回报上界，并且无需预知错误次数即可实现鲁棒性。

**🔧 技术方法**

主要技术包括：M‑convex 集的最优性判定条件、中心质点与体积削减（Grünbaum 定理）以及通过有向图检测循环来识别错误回合的重启机制。

**📊 数据集**

该工作为理论性研究，无实验数据集，全部基于数学证明与理论分析。

**📈 对比分析**

与以往的 O(d⁴ log T)、O(d log T) 及 exp(O(d log d)) 上界相比，本文提供了维度多项式且与时间无关的上界；同时证明了下界 Ω(d)，表明上界至多比最优慢一个 log d 因子。

**⚠️ 局限性**

限制在于：仍存在 log d 的上界与下界差距；对错误的累计失配缺乏更细粒度的鲁棒分析；且对更高阶结构的可行集尚未进一步改进回报上界。

---

## 516. Simplicity Prevails: The Emergence of Generalizable AIGI Detection in Visual Foundation Models

**arXiv ID:** 2602.01738 | [PDF](https://arxiv.org/pdf/2602.01738v1)

**作者:** Yue Zhou `[一作]` (Shenzhen University), Bin Li `[通讯]` (Shenzhen University)

**通讯引用:** 83051 | [OpenAlex ID](https://openalex.org/A5100395468)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种极其简单的线性探测器，在现代视觉基础模型（VLM 与 SSL）的冻结特征上训练，能够实现对 AI 生成图像的检测。

**💡 创新点**

创新点在于：①证明模型的泛化能力主要来自海量预训练数据而非复杂架构；②展示 VLM 通过对 “AI 生成” 等概念的语义注入实现识别；③SSL 通过分布拟合隐式学习到生成器特征；④强调简洁模型可在真实环境中优于传统专用检测器。

**🔧 技术方法**

技术方法：冻结 Vision Foundation Models（MetaCLIP、MetaCLIP2、PE‑CLIP、SigLIP、SigLIP2、DINOv2、DINOv3）提取特征，随后在这些特征上训练一个线性分类头；使用 AdamW、学习率 1e-3、batch 128、2 epoch 训练；对比多种现有检测器的多层架构。

**📊 数据集**

数据集：训练使用 GenImage（Stable Diffusion v1.4）；评估覆盖标准基准（GenImage）、未见生成器（AIGIHolmes、AIGI‑Now）、现实世界分布（Chameleon、WildRF、SocialRF、CommunityAI、RRDataset、DDA‑COCO、BR‑Gen 等），并在 midjourney‑CC 等自采数据上做语义对齐验证。

**📈 对比分析**

对比方法：在标准基准上，线性探测器与现有专用方法相当；在现实世界分布上，DINOv3‑Linear、MetaCLIP2‑Linear 等取得 90%+ 准确率，平均提升约 30% 以上；在未见生成器上也保持 95%+，显著优于传统方法。

**⚠️ 局限性**

局限性：对纯 VAE 重构和局部编辑（如 BR‑Gen）几乎失效；部分模型（如 PE‑CLIP）在模糊、屏幕重捕等低频操作下性能显著下降；整体仍受限于全局池化导致对细粒度篡改的识别能力不足。

---

## 517. MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration

**arXiv ID:** 2602.01734 | [PDF](https://arxiv.org/pdf/2602.01734v1)

**作者:** Lianhai Ren `[一作]`, Yeyun Gong `[通讯]` (Microsoft Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种周期性恢复权重矩阵稳定秩的优化器 MSign，解决大型语言模型预训练中的梯度爆炸导致的训练不稳定问题。

**💡 创新点**

创新点在于将稳定秩崩塌与相邻层雅可比矩阵对齐这两个机制作为训练失败的根本原因，并通过矩阵符号操作主动恢复稳定秩，从而打断负向反馈循环。

**🔧 技术方法**

主要技术包括矩阵符号（matrix sign）操作、奇异值分解（SVD）与 Frobenius 范数重缩放、以及周期性（每 P 步）对注意力层权重进行修正的优化策略。

**📊 数据集**

在四种规模与架构的模型（NanoGPT‑5M、Sigma‑40M、LLaMA‑1B、LLaMA‑MoE‑3B）上使用与 AdamW 相同的训练数据集进行验证，未公开具体语料。

**📈 对比分析**

与 AdamW 基线比较，MSign 能完全抑制梯度爆炸并保持训练收敛；在所有实验规模下保持或略优于基线的困惑度，计算开销低于 7%，甚至在小模型上略有加速。

**⚠️ 局限性**

局限性包括：需频繁执行 SVD 产生额外通信与核融合开销、理论假设（如输入输出梯度负相关）较强且可能不普遍、目前仅对注意力层有效，且在极大周期下仍可能出现临时稳定秩下降。

---

## 518. Streamlined Facial Data Collection based on Utterance and Emotional Data for Human-to-Avatar Reconstruction

**arXiv ID:** 2602.01729 | [PDF](https://arxiv.org/pdf/2602.01729v1)

**作者:** Seoyoung Kang `[一作]` (Korea Advanced Institute of Science and Technology), Woontack Woo `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 5170 | [OpenAlex ID](https://openalex.org/A5023177829)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `fede83ac-7505-405f-ab37-e7284695c47f` `25d64835-ec5b-425b-899d-a6e1e6fecabd` `b88c6eac-d57a-4623-a604-1f401f3eb268` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

研究了如何通过最小化语音与情绪数据采集，构建逼真且可用的3D 头像，并验证在对话情境下的高效数据采集流程；

**💡 创新点**

提出仅使用自发语音+直接情绪表达即可获得与大规模数据集相当的表情逼真度，挑战传统认为大量数据必不可少的观念，并证明不同数据收集策略在用户感知上可实现等价；

**🔧 技术方法**

采用 PointAvatar（神经点云）+ FLAME 参数化模型、3DMM/NeRF 等图形技术，结合 RGB 视频采集与基于 RGB 的重建，使用 MAE/PSNR/SSIM/LPIPS 等客观指标与 Likert 量表进行评估；

**📊 数据集**

使用 Microsoft Azure Kinect 捕获的四位受试者的自发语音、脚本朗读、发音捕获及六种情绪表达组合的数据集，约 209‑682 MB；

**📈 对比分析**

通过阶段一对三种语音采集方式和六种语音+情绪组合进行 t‑检验和平均指标比较，结果显示 U3（自发语音）+E1（直接情绪表达）最优；阶段二对三种数据收集策略（C1、C2、C3）进行训练时间、采集时间、数据量对比，并通过 Friedman 与 TOST 等价检验，发现 C2 与 C3 在现实感、自然度和沉浸度上无显著差异，证明数据压缩后性能相当；

**⚠️ 局限性**

受试者仅来自单一文化群体；实验仅为单向听力任务；使用预渲染场景而非实时交互；评估仅在大型墙面投影环境中进行，未考虑实时渲染、网络延迟和不同硬件的限制，数据集尚未公开。

---

## 519. Cross-Domain Fake News Detection on Unseen Domains via LLM-Based Domain-Aware User Modeling

**arXiv ID:** 2602.01726 | [PDF](https://arxiv.org/pdf/2602.01726v1)

**作者:** Xuankai Yang `[一作]` (Macquarie University), Huan Liu `[通讯]` (Arizona State University)

**通讯引用:** 47813 | [OpenAlex ID](https://openalex.org/A5100338946)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本论文提出了一个基于大语言模型的跨域假新闻检测框架 DAUD，专门解决未见域（unseen domain）下的假新闻识别问题。

**💡 创新点**

创新点包括：① 通过 LLM 生成的域感知用户代理和新闻摘要，实现对新闻内容与用户交互的高层语义提取；② 设计了 Domain-Shared Feature Learning 与 Relation-Aware Alignment 两阶段模块，既去除域特异噪声，又捕捉新闻、用户与交互之间的关系，从而获得更稳健的跨域共享表示。

**🔧 技术方法**

使用技术主要有：Prompt-engineered LLM（如 GPT-4o-mini）进行语义抽取与评论生成；Transformer、Transformer Encoder、Co-Attention、Cross-Attention、Disentangler 等深度学习模块；以及基于关系融合的对齐策略。

**📊 数据集**

实验数据集涵盖三个新闻领域：政治（Politics）、娱乐（Entertainment）和 COVID‑19（Health），每个领域均包含标注的真伪新闻与用户评论。

**📈 对比分析**

与 13 个单域与跨域基线（BERT、dEFEND、FANG、EANN、Real‑FND 等）对比，DAUD 在一般跨域和未见域设置中均实现了显著提升，平均 AUC 提升约 2–4%（在未见域上可达 3.6%），并且在所有指标（Acc、Prec、Rec、F1）均超越最佳基线。

**⚠️ 局限性**

局限性包括：① 仍假设目标域存在与源域共享的用户，未处理完全无共享用户场景；② 对 LLM 的推理结果仍可能产生幻觉（hallucination），影响特征可靠性；③ 计算成本高，需频繁调用大型模型。

---

## 520. FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization

**arXiv ID:** 2602.01723 | [PDF](https://arxiv.org/pdf/2602.01723v1)

**作者:** Yikun Ma `[一作]` (School of Intelligent Systems Engineering, Shenzhen Campus of Sun Yat-sen University), Zhi Jin `[通讯]` (Sun Yat-sen University)

**通讯引用:** 10004 | [OpenAlex ID](https://openalex.org/A5049100391)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `4de8e9d8-757b-475f-9627-18a445e50202` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出一种快速高效的物理驱动3D高斯展开（3DGS）模拟框架，能在1分钟、7GB内存下生成多材料、实例级别的4D物理动态。

**💡 创新点**

创新点包括：1）Instance-aware Particle Filling（IPF）配合Monte Carlo Importance Sampling（MCIS）实现对3DGS内部空洞的实例化填充；2）Bidirectional Graph Decoupling Optimization（BGDO）实现对VLM预测材料参数的快速自适应优化；3）整体架构实现低内存、短时延的高质量物理仿真。

**🔧 技术方法**

技术手段包括：3D Gaussian Splatting、Material Point Method（MPM）、DBSCAN聚类、Quickhull构建凸包、Monte Carlo Importance Sampling、VLM（Qwen3‑VL）预测材料属性、梯度无关前向仿真+反向优化、对应梯度的对数压缩、实例级标签跟踪等。

**📊 数据集**

使用公开的3DGS格式数据集（如来自文献的三维重建数据）以及自制的多对象3DGS数据集（熊+罐、鸭子+石头等）。

**📈 对比分析**

与PhysGaussian、DreamPhysics、Physics3D、OmniPhysGS以及CogVideoX‑5B、Veo‑3.1等方法进行定量（CLIP、Aesthetic、Semantic、Physical分数）和定性对比。FastPhysGS在这些指标上取得最佳或接近最佳成绩，并在内存（7 GB）与时间（≈1 min）上明显优于其他物理驱动方法。

**⚠️ 局限性**

局限性包括：仍需依赖VLM预测的材料参数，感知与物理间可能存在差距；对极端复杂几何或极硬/极软材料的适应性尚待验证；未覆盖多相流、非连续介质等更复杂物理情形。

---

## 521. Phoenix: A Modular and Versatile Framework for C/C++ Pointer Analysis

**arXiv ID:** 2602.01720 | [PDF](https://arxiv.org/pdf/2602.01720v1)

**作者:** Peisen Yao `[一作]` (Zhejiang University), Qingkai Shi `[通讯]` (Nanjing University)

**通讯引用:** 2045 | [OpenAlex ID](https://openalex.org/A5034844386)

**关键词:** `2f20b7a7-8630-4b01-9311-4db57188b72c`

**🎯 论文内容**

构建了一个模块化的C/C++指针分析框架Phoenix，统一多种指针分析算法并提供稳定的查询接口。

**💡 创新点**

将指针分析算法与IR构造、约束生成、求解器后端等模块解耦，支持多种精度与性能组合，可自由切换分析方法。

**🔧 技术方法**

采用LLVM IR、约束语言、Wave/Deep/Difference传播等求解器技术，并实现BDD/稀疏位向量点到集合。

**📊 数据集**

在28个GNU coreutils程序上评估。

**📈 对比分析**

与SVF比较，基线（FICI）最高可快2.88×，更精确的FSCS仍保持竞争力，最高快2.91×。

**⚠️ 局限性**

目前缺乏完全流/上下文敏感的Andersen实现，且对路径敏感性支持有限，动态内存模型仍待完善。

---

## 522. Mechanistic Indicators of Steering Effectiveness in Large Language Models

**arXiv ID:** 2602.01716 | [PDF](https://arxiv.org/pdf/2602.01716v1)

**作者:** Mehdi Jafari `[一作]` (University of New South Wales), Flora Salim `[通讯]` (University of New South Wales)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究并量化大型语言模型中激活层干预（steering）的内部机制，提出基于熵（nbf）和KL差异的指标来评估和预测干预效果，并引入旋转式干预方法替代传统加法干预。

**💡 创新点**

① 用内部信息量和KL指标定量评估干预成功；② 通过LLM作为评判者的可靠性验证，证明LLM可替代人工评价；③ 提出旋转式干预实现更稳健的控制，提升与熵保持和注意力稳定性。

**🔧 技术方法**

机制解释技术（残差流、Attention、FFN）、信息论指标（熵、KL）、回归预测模型、LLM评判器、Gemma-2模型的激活取样与分析。

**📊 数据集**

Gemma-2 语言模型，9个目标概念（如 London、Christianity 等），中性 prompt “I think …”，共 2304 组实验（概念 × 提取方法 × 干预函数 × 强度）。

**📈 对比分析**

与传统加法干预对比，使用 LL M 评判的 steering‑score 作为基准；旋转式干预在保持熵、KL 稳定和注意力不失真的同时获得更高的 steering‑coherence 换手率；回归模型在 LL M 评分上 MAE≈0.05–0.09、RMSE≈0.07–0.12，显示内部指标具备可预测性。

**⚠️ 局限性**

仅测试 9 个概念、仅在 Gemma‑2 系列模型上验证，缺乏对更大、更先进模型的泛化；回归模型表达能力有限；依赖 LL M 判定，存在标签噪声和偏差；未覆盖更广泛语义空间与实际使用中的伦理风险。

---

## 523. Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis

**arXiv ID:** 2602.01710 | [PDF](https://arxiv.org/pdf/2602.01710v1)

**作者:** Salma Zahran `[一作]` (Shanghai Jiao Tong University), Yanming Wang `[通讯]` (Global Institute of Future Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

开发了一套完整的从物理模拟到无人工注释的语义分割流程，能够生成带有完美掩模的合成显微图像并用于训练U-Net模型，最终实现对真实SEM图像的高精度分割。

**💡 创新点**

创新点在于将相场模拟与无监督的CycleGAN结合，成功弥合了模拟与真实图像的域差距；同时实现了完全自动化的标注生成，突破了人工标注瓶颈。

**🔧 技术方法**

使用了相场（Allen‑Cahn方程）模拟、CycleGAN生成对齐、U‑Net语义分割，以及t‑SNE、Shannon熵、SSIM等评估技术。

**📊 数据集**

使用了300个相场生成的晶粒结构（512×512），通过CycleGAN得到180幅合成SEM图像；测试集为未见的真实SEM图像；对比基准使用了少量人工标注的真实图像与理想化无纹理的合成图像。

**📈 对比分析**

通过与仅使用少量人工标注、仅使用无纹理合成数据的两种基线模型比较，采用IoU、Boundary F1、SSIM等指标。我们的模型在真实SEM测试集上实现IoU≈0.90、Boundary F1≈0.91，明显优于基线。

**⚠️ 局限性**

局限在于目前仅针对二维单相SEM图像，难以直接扩展到多相、多材料或3D体积数据；对极端成像条件的泛化仍有限；需要进一步提升相场模型的物理真实性和CycleGAN的多样性。

---

## 524. ARTIS: Agentic Risk-Aware Test-Time Scaling via Iterative Simulation

**arXiv ID:** 2602.01709 | [PDF](https://arxiv.org/pdf/2602.01709v1)

**作者:** Xingshan Zeng `[一作]` (Huawei Technologies Co., Ltd), Qun Liu `[通讯]` (Huawei Technologies Co., Ltd)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出一种基于迭代模拟的 agentic TTS 框架，让 LLM 在内部模拟环境中多次尝试、评估并改进行动，最终只在一次真实执行。

**💡 创新点**

创新点在于将 TTS 从推理路径扩展到动作层面，分离探索与执行，并引入风险感知的工具模拟器与评估总结机制。

**🔧 技术方法**

技术上采用 LLM 作为行动生成、评估与总结器，顺序/并行迭代模拟、失败驱动的数据生成与重平衡训练、以及结构化提示。

**📊 数据集**

实验使用 BFCL‑v3、ACEBench 等 agentic benchmark，以及收集的 Python 与 MCP 工具集，并对工具调用生成失败驱动数据。

**📈 对比分析**

与直接执行、传统 TTS 基线对比，顺序迭代模拟在 Qwen3 系列、Llama3、Mistral 等模型上显著提升成功率，risk‑aware 模拟器进一步逼近完美模拟器的效果。

**⚠️ 局限性**

局限性包括对模型规模的依赖、模拟器需大量训练数据、长上下文导致效率下降、额外算力与 token 消耗，并且仍需人工监管以防风险。

---

## 525. TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios

**arXiv ID:** 2602.01675 | [PDF](https://arxiv.org/pdf/2602.01675v1)

**作者:** Yuanzhe Shen `[一作]` (Fudan University), Ke Zeng `[通讯]` (LongCat Interaction Team)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出TRIP‑Bench，一套针对真实旅行规划的长周期交互评测基准；同时提出GTPO多轮强化学习方法以提升长周期任务的规则遵循与交互鲁棒性。

**💡 创新点**

1）在长序列、复杂规则、动态用户行为三维度上构造逼真多轮任务；2）通过工具链与约束生成实现可扩展、可自动评估；3）GTPO将全局指令归一化、奖励差分与逐轮归一化相结合，解决多轮奖励稀疏与协方差漂移问题。

**🔧 技术方法**

大规模数据合成、工具调用接口、在线多轮强化学习（PPO‑style）、奖励归一化与差分技术、自动化评估脚本。

**📊 数据集**

扩充自TripTailor的数据集（4千城市、80k+酒店、400k+餐厅、1M+产品），并加入18种旅行工具；使用约40类约束与80+自然语言表述。

**📈 对比分析**

与多种大型语言模型（Qwen、Gemini、Claude、GPT、DeepSeek等）对比；在易中难分上，基线模型（SFT/GRPO）成绩低于5%，GTPO后提升至约40%；对比Gemini‑3‑Pro，GTPO‑Qwen2.5‑32B在易/中严格/松散评估上均取得领先。

**⚠️ 局限性**

仍存在：1）对最难子集（LIT、FIT、AIS、PMR）准确率低于10%；2）多轮交互中全局一致性易破坏；3）模型规模与成本仍高，开放源代码模型与闭源系统存在显著差距；4）用户模拟虽可靠但仍受限于预设规则，真实用户行为更为复杂。

---

## 526. VRGaussianAvatar: Integrating 3D Gaussian Avatars into VR

**arXiv ID:** 2602.01674 | [PDF](https://arxiv.org/pdf/2602.01674v1)

**作者:** Hail Song `[一作]` (Korean Advanced Institute of Science and Technology), Woontack Woo `[通讯]` (Korean Advanced Institute of Science and Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

开发了一套可在VR中实时渲染全身3D Gaussian Splatt Avatar的系统（VRGaussianAvatar），该系统仅利用HMD内部传感器（头部6DoF+手部）进行姿态估计，并通过单张A‑pose图像实现一 shot 全身 avatar 重建。

**💡 创新点**

主要创新点包括：① 将3D Gaussian Splatting与VR渲染管线融合，实现高质量的实时全身 avatar；② 提出 Binocular Batching 的双眼渲染策略，显著降低双眼渲染的计算冗余；③ 将实时姿态估计与高成本渲染分离为 VR Frontend 与 GA Backend 并行架构，保持低延迟且高帧率；④ 通过用户研究验证该系统在身体嵌入感、可辨性与逼真度方面优于传统网格 avatar。

**🔧 技术方法**

使用技术包括：3D Gaussian Splatting（LHM）、SMPL‑X 参数化模型、逆运动学（IK）控制、HMD 6DoF 与手部跟踪、双眼视角矩阵的批处理（Binocular Batching）、实时渲染与网络流媒体。

**📊 数据集**

数据集：24名受试者的单张正面A‑pose图像、面部RGB视频（FACS表情）和身体RGB‑D视频；使用公开模型与工具如 SMPLer‑X、TexDreamer、FATE、RC‑SMPL 进行网格和纹理重建；全部图像均来自受试者本人以保证自体相似性。

**📈 对比分析**

对比方法：与基于 SMPL‑X 的图像重建（image）和视频重建（video）网格 avatar 进行对比。评估指标包括 L1、LPIPS、PSNR、SSIM；渲染性能评估在不同分辨率下的帧率和渲染时间，比较开启/关闭 Binocular Batching 的差异。实验结果表明，VRGaussianAvatar 在所有视觉质量指标（最低 L1/LPIPS，最高 PSNR/SSIM）以及用户体验（VEQ、VEQ+、VHPQ）均显著优于两种基线。

**⚠️ 局限性**

局限性：① 未包含面部表情、眼动或眨眼等动态表情；② 需要受试者提供姿态良好、无遮挡的单张图像；③ 目前实现仅在本机 localhost 下，远程部署会导致网络延迟；④ 评估主要基于镜像式自我观察，未验证第一人称视角下的沉浸感。

---

## 527. IRIS: Implicit Reward-Guided Internal Sifting for Mitigating Multimodal Hallucination

**arXiv ID:** 2602.01769 | [PDF](https://arxiv.org/pdf/2602.01769v1)

**作者:** Yuanshuai Li `[一作]` (Westlake University), Yaochu Jin `[通讯]` (Westlake University)

**通讯引用:** 54543 | [OpenAlex ID](https://openalex.org/A5032314861)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于模型自身隐式奖励的自我对齐框架IRIS，用于在多模态大语言模型中降低幻觉生成。

**💡 创新点**

创新点包括：①利用自模型产生的连续隐式奖励来筛选优劣对；②构造Rectified Visual Guidance (RVG) 评分，剔除仅靠语言先验的回答；③在无外部评判器的情况下实现多模态对齐，显著提高数据效率。

**🔧 技术方法**

技术方法包括：多模态直接偏好优化（DPO）、SFT预热、K‑sample自生成候选、隐式奖励比值评分、RVG阈值剔除、视觉偏好与锚定正则化的联合损失。

**📊 数据集**

使用的公开数据集有：RLHF‑V 5700 条 SFT 训练样本、AMBER、MMHal‑Bench、Object‑HalBench、LLaVA‑Bench 等。

**📈 对比分析**

与基线（LLaVA‑RLHF、HALVA、mDPO、HA‑DPO、V‑DPO、POVID、RLAIF‑V、SymMPO、OPA‑DPO、LPOI）对比，IRIS 在 7B/13B 模型上在多模态幻觉指标（如 CHAIR、HalRate）上取得更优或相近成绩，且只需 5.7k 条隐式奖励对，极大降低成本。

**⚠️ 局限性**

局限性包括：①对视觉扰动函数的选择敏感；②在极大规模或多模态复杂度极高的场景下，隐式奖励可能不足以完全覆盖所有幻觉类型；③缺少针对生成质量细粒度评估的外部验证，导致对非视觉幻觉改进的可解释性有限。

---

## 528. CoMeT: Collaborative Memory Transformer for Efficient Long Context Modeling

**arXiv ID:** 2602.01766 | [PDF](https://arxiv.org/pdf/2602.01766v1)

**作者:** Runsong Zhao `[一作]` (Northeastern University), Bo Zheng `[通讯]` (Future Living Lab of Alibaba)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出协同记忆 Transformer（CoMeT），让 LLM 在任意长上下文下保持线性时间、常数内存，并能在 1M token 上准确检索信息。

**💡 创新点**

双重记忆系统（门控全局记忆 + FIFO 临时记忆）+ 低秩适配器门控更新 + 层级流水线并行训练，解决传统 Transformer 二次复杂度与 KV 缓存无限增长的问题。

**🔧 技术方法**

采用低秩适配器 RLA、门控状态更新、FIFO 队列、压缩/读出令牌、层级流水线并行、细粒度的分块处理。

**📊 数据集**

使用 Qwen3‑4B 基线模型，32k 上下文的 Passkey 检索数据集，LongBench（GovReport、SumScreen、QMSum 等）摘要与推理任务，UQA 与 Terminal‑Bench 实际应用数据，以及 1M token Passkey 任务。

**📈 对比分析**

与全注意力、Transformer‑XL、SWA、HMT、LongLLMLingua、Activation Beacon 等方法对比，CoMeT 在摘要与长序列推理上与全注意力相当，在 1M token Passkey 检索上实现 21× 速度提升、10× 内存缩减；在 Benchmark 上平均分数最高。

**⚠️ 局限性**

尚未集成情景记忆/外部知识库（如 RAG、Notebook 等）及多模态任务，缺乏对更复杂场景的完整适配。

---

## 529. Zero2Text: Zero-Training Cross-Domain Inversion Attacks on Textual Embeddings

**arXiv ID:** 2602.01757 | [PDF](https://arxiv.org/pdf/2602.01757v1)

**作者:** Doohyun Kim `[一作]` (Korea Advanced Institute of Science and Technology), Brent Byunghoon Kang `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6215c339-3735-4be3-8a07-5bbb7004712d` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种无训练、无泄露数据、可跨域的零训练逆向攻击框架Zero2Text，能够在黑盒场景下从单个文本嵌入恢复原始文本。

**💡 创新点**

创新点在于结合LLM生成先验与递归在线岭回归对嵌入空间进行实例级动态对齐，无需预训练解码器或对齐数据，显著提升跨域泛化能力。

**🔧 技术方法**

技术包括：LLM（Qwen3-0.6B）文本生成、在线投影优化（Ridge回归）、多级置信度融合评分、逐步Beam搜索与指数衰减查询策略。

**📊 数据集**

使用MS MARCO和PubMed两个领域数据集评估，实验对照包括Vec2Text、TEIA、ALGEN等SOTA方法。

**📈 对比分析**

相较基线，Zero2Text在OpenAI 3-large模型上ROUGE‑L提升约1.8倍、BLEU‑2提升约6.4倍，且在线查询成本更低（仅约13.9k token），在跨域设置下显著优于现有方法。

**⚠️ 局限性**

局限性：仍需访问受害者嵌入API进行在线查询，查询次数与攻击效果成正比；对极大规模嵌入空间或高维噪声的鲁棒性尚待进一步验证。

---

## 530. Sentence Curve Language Models

**arXiv ID:** 2602.01807 | [PDF](https://arxiv.org/pdf/2602.01807v1)

**作者:** DongNyeong Heo `[一作]` (Handong Global University), Heelyoul Choi `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `8d10c613-917e-4880-9716-17789f50e119` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出句子曲线（Sentence Curve）作为句子目标的连续表示，并基于此构建句子曲线语言模型（SCLM），用曲线替代传统的静态词嵌入来训练扩散式语言模型。

**💡 创新点**

创新点在于：①将B‑spline曲线引入自然语言目标表示，控制点影响多词，能捕获句子级全局结构；②通过曲线预测产生正则化效应，理论上减少多模态问题；③提出K‑曲线预测策略与曲线映射的伪逆实现，实现对曲线空间的高效搜索。

**🔧 技术方法**

采用B‑spline曲线映射与伪逆、Gaussian扩散过程、Diffformer框架、K‑曲线联合预测、以及可选的知识蒸馏；同时利用词嵌入投影、软最大化与交叉熵损失，构成完整训练管线。

**📊 数据集**

实验数据集包括：机器翻译的 IWSLT14 (En↔De) 与 WMT14 (En↔De)；语言建模的 LM1B；半自回归实验使用 WikiText‑2；以及对应的知识蒸馏数据集。

**📈 对比分析**

与现有 DLMs、AR Transformer、Difformer 等基线对比，SCLM 在 IWSLT14 与 WMT14 上获得了 SOTA BLEU 分数（若无 KD 亦能与 Difformer 相当），在 LM1B 上训练曲线模型的 perplexity 明显低于 MDLM，半自回归实验中 SCLM 的 PPL 也优于传统词嵌入预测，说明其在全局结构建模上的优势。

**⚠️ 局限性**

主要局限在于：由于控制点数量大于句子长度，SCLM 的计算开销（训练和推理时间）显著高于传统模型；曲线映射与逆映射需要额外预计算；对长句子或大模型的可扩展性尚未完全验证。

---

## 531. DDP-WM: Disentangled Dynamics Prediction for Efficient World Models

**arXiv ID:** 2602.01780 | [PDF](https://arxiv.org/pdf/2602.01780v1)

**作者:** Shicheng Yin `[一作]` (Sun Yat-sen University), Liang Lin `[通讯]` (Sun Yat-sen University)

**通讯引用:** 34172 | [OpenAlex ID](https://openalex.org/A5100412937)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种“分离动态预测”世界模型（DDP‑WM），通过将视觉动态拆分为稀疏的主动态和背景上下文更新，显著提升推理速度并保持甚至提升规划性能。

**💡 创新点**

①引入动态定位网络快速识别即将发生主动态的稀疏区域；②设计低秩修正模块（LRM）以低成本捕捉背景因主动态产生的全局上下文变化，从而平滑优化景观；③以稀疏计算为核心的四阶段预测架构。

**🔧 技术方法**

利用预训练的DINOv2视觉特征、交叉注意力（Cross‑Attention）、ViT基础的预测器以及可训练的稀疏定位网络；采用低秩矩阵假设实现背景更新。

**📊 数据集**

在五个仿真任务上评估：PointMaze、Wall、Push‑T、Rope、Granular；所有任务均使用相同的DINOv2特征和MPC（CEM）框架。

**📈 对比分析**

与SOTA稠密模型DINO‑WM对比：在Push‑T任务上成功率从90%提升至98%，单步推理理论FLOPs从23G降至2.5G（≈9.2×速度提升），完整MPC决策循环从120 s降至16 s（≈7.5×加速），其余任务亦实现2–3×加速并保持或超过成功率。

**⚠️ 局限性**

目前验证仅覆盖模拟环境，模型仍需依赖高质量预训练视觉模型；对稀疏定位的阈值选择和LRM低秩假设在复杂多体或极端动态场景下的鲁棒性待进一步探索。

---

## 532. Cost-Aware Bayesian Optimization for Prototyping Interactive Devices

**arXiv ID:** 2602.01774 | [PDF](https://arxiv.org/pdf/2602.01774v1)

**作者:** Thomas Langerak `[一作]` (Aalto University), Antti Oulasvirta `[通讯]` (Aalto University and ELLIS Institute)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了将成本纳入贝叶斯优化的原型迭代方法，使得在设计过程中能够根据硬件、软件改动的实际投入成本做出更经济的采样决策。

**💡 创新点**

创新点在于设计了基于组件重用的三类成本模型（未改、重用、重建），并通过在获取函数中引入成本比率（EI/成本）实现动态、可扩展的成本感知采样，同时保留原有代理模型。

**🔧 技术方法**

使用贝叶斯优化（Gaussian Process+Expected Improvement）与成本调度的改进版获取函数；对成本模型进行光滑RBF逼近以支持梯度优化；实现了记录原型的增量更新机制。

**📊 数据集**

在仿真中使用多种黑盒函数（Rosenbrock、Ackley、Goldstein-Price、Levy）以及实际硬件-软件调试实验（Xbox 直柄摇杆的硬件与软件参数）。

**📈 对比分析**

与传统的无成本感知贝叶斯优化相比，成本感知方法在多项评估（有限预算、成本异质性、模块化、动态成本变更、成本估计误差）下均实现了相同或更优的最终效用，仅花费约30–70%的总成本；在用户研究中达成与基线相当的性能，成本降低至约67%。

**⚠️ 局限性**

局限包括：假设组件间独立且不考虑互依关系；只考虑单一成本维度，未覆盖多预算或多目标情形；依赖预先定义的参数化设计空间，无法自动扩展或探索新的设计维度；对不同精度（低/高保真）评估的兼容性有限。

---

## 533. Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies

**arXiv ID:** 2602.01816 | [PDF](https://arxiv.org/pdf/2602.01816v1)

**作者:** Wenjin Hou `[一作]` (Zhejiang University), Hehe Fan `[通讯]` (Zhejiang University)

**通讯引用:** 2272 | [OpenAlex ID](https://openalex.org/A5002207978)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一套针对视觉错觉与异常的评测基准（VILB），并在此基准上系统评估了20+种多模态大语言模型的表现。

**💡 创新点**

创新点在于：①设计了覆盖六类视觉错觉（颜色、运动、Gestalt、几何空间、一般视觉、视觉异常）的高质量1,004道多选问答；②揭示链式思维（CoT）在此类任务中易导致“脆弱幻影”，对模型鲁棒性提出新挑战；③量化了现有模型与人类在视觉感知上的显著差距。

**🔧 技术方法**

使用了多模态大语言模型、链式思维推理、LLM-as-a-Judge判定、人工审核与去偏技术、评测脚本与指标计算等方法。

**📊 数据集**

数据集为VILB（Visual Illusions and Anomalies Benchmark），包含1,004个精心人工标注的多选问答，涵盖六大视觉错觉与异常类别。

**📈 对比分析**

对20+模型（专有、开源、推理增强）进行准确率评估，采用Match与Judge两种判定方式；结果显示人类平均准确率93.3%，最佳模型仅69.23%，且CoT往往无提升甚至下降，凸显模型在视觉错觉任务上的局限。

**⚠️ 局限性**

局限性包括：评测仅以多选形式，缺乏开放式问答挑战；模型易受内部先验影响，CoT缺乏实时视觉检验；基准尚未覆盖所有视觉错觉类型，未来需进一步扩充。

---

## 534. INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery

**arXiv ID:** 2602.01815 | [PDF](https://arxiv.org/pdf/2602.01815v1)

**作者:** Yunhui Jang `[一作]` (Korea Advanced Institute of Science and Technology), Sungsoo Ahn `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 805 | [OpenAlex ID](https://openalex.org/A5107897596)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

基于科学家发表史和已发现分子构建细粒度个性化代理，在多轮辩论中协同生成并优化分子，提升药物发现效率。

**💡 创新点**

创新点在于用真实研究轨迹（publication 与 molecular history）作为代理“科学 DNA”，取代传统粗粒度角色或关键词人格，从而实现多样化、事实扎根的协作。

**🔧 技术方法**

技术包括检索增强生成（retrieval‑augmented generation）构建代理档案、Deepseek‑V3.2 大语言模型驱动的多阶段辩论（proposal‑critique‑voting），以及对代理进行基于历史数据的个性化提示。

**📊 数据集**

数据集：PubMed 文献、公开分子历史；下游任务使用蛋白‑条件分子生成（8 目标蛋白）、生物活性引导生成（PMO‑1K 的 GSK3β、DRD2、JNK3）和目标导向引导优化（5 目标蛋白 + 3 种种子分子）。

**📈 对比分析**

与 VanillaDebate、KeywordDebate、角色基 MT‑Mol 以及多种结构/LLM 基线进行对比；在三类任务中均显著优于或与最先进方法持平，显示出更高的结合亲和力、活性评分与分子多样性。

**⚠️ 局限性**

局限性：依赖公开科学家个人资料，存在隐私与滥用风险；缺乏任务专属微调，性能仍落后部分精调基线；对高难度约束优化的效果仍有限。

---

## 535. A polynomial-time algorithm for recognizing high-bandwidth graphs

**arXiv ID:** 2602.01755 | [PDF](https://arxiv.org/pdf/2602.01755v1)

**作者:** Luis M. B. Varona `[一作]` `[通讯]`, Luis M. B. Varona

**关键词:** `350271b4-1c30-42d1-b8ce-110a550894ce` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了一种针对高带宽识别问题的算法，能够在k≥⌊(n−1)/2⌋的情形下在O(n^(n−k)+1)时间内判断图的带宽是否≤k并给出布局。

**💡 创新点**

创新点是将高带宽识别问题转化为二分匹配并利用Hall定理，从而在k接近n时实现多项式复杂度，填补了现有低带宽算法在高k时的空白。

**🔧 技术方法**

采用Hall婚姻定理、二分匹配、哈希表与排序等技术，配合左/右部分布局枚举来高效验证可行性。

**📊 数据集**

使用自定义生成器构造的随机图（n=12-18或40-55，k≈n−4、n−6、n−2）作为实验数据集，并借助Julia的MatrixBandwidth.jl包实现。

**📈 对比分析**

与O(n^k)算法以及MB‑ID、MBC等最小化算法的子例程对比，本算法在k接近n时对肯定案例的性能快数百到数千倍，负案例略逊，但总体优于现有方法。

**⚠️ 局限性**

在负案例时需遍历所有左部分布局，缺乏剪枝导致在k≈n−6时容易超时；此外算法仅适用于k≥⌊(n−1)/2⌋，无法处理低带宽情形。

---

## 536. Enhancing Automated Essay Scoring with Three Techniques: Two-Stage Fine-Tuning, Score Alignment, and Self-Training

**arXiv ID:** 2602.01747 | [PDF](https://arxiv.org/pdf/2602.01747v1)

**作者:** Hongseok Choi `[一作]` (Electronics and Telecommunications Research Institute), Jin-Xia Huang `[通讯]` (Electronics and Telecommunications Research Institute)

**通讯引用:** 218 | [OpenAlex ID](https://openalex.org/A5007149994)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

针对自动写作评分（AES）中的数据稀缺问题，本文提出并整合了两阶段LoRA微调、分数对齐（Score Alignment）以及不确定性自训练（UST）三种技术，以提升在少量标注数据和完整数据下的评分精度。

**💡 创新点**

创新点包括：① 将LoRA应用于两阶段微调，在冻结基础模型后只更新低秩适配层并多次尝试不同任务权重；② 设计了基于验证集的线性分数对齐方法，直接校正预测分布偏差；③ 采用不确定性估计筛选伪标签，缓解自训练中的噪声扩散；④ 这三种方法能够模块化组合，分别提升性能并可与多任务学习、集成等常规技巧叠加。

**🔧 技术方法**

核心技术：LoRA参数高效微调、线性分数对齐（利用开发集统计）、基于dropout的预测方差估计进行自训练。实现上使用DualBERT作为基准，采用BERT-mini / BERT-base，AdamW优化器，MSE损失。

**📊 数据集**

数据集：ASAP++（12,978篇学生作文，涵盖8个提示、8个评分维度），在完整数据和32条样本（K=32）两种低资源场景下进行实验。

**📈 对比分析**

与现有AES方法（HISK、STL‑LSTM、MTL‑BiLSTM、ArTS、ArTS+RMTS、SaMRL）比较，DualBERT+LoRA+SA 在完整数据上取得0.732的平均QWK，超过SaMRL/ArTS+RMTS，成为SOTA；在32条样本下，整合方法提升QWK至0.686（约91.2%完整数据水平），并在多维度、跨提示评估中均显示稳定提升。

**⚠️ 局限性**

局限性：① 两阶段LoRA训练时间略长；② 分数对齐需要先生成全部预测才能执行；③ UST 需要大量未标注作文，实际可获取性受限；④ 对Seq2Seq模型的适用性有限。

---

## 537. Softmax Linear Attention: Reclaiming Global Competition

**arXiv ID:** 2602.01744 | [PDF](https://arxiv.org/pdf/2602.01744v1)

**作者:** Mingwei Xu `[一作]`, Wanyun Cui `[通讯]` (Shanghai University of Finance and Economics)

**通讯引用:** 869 | [OpenAlex ID](https://openalex.org/A5103026537)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了Softmax Linear Attention（SLA），在保持线性时间复杂度的同时恢复了注意力的全局竞争机制。

**💡 创新点**

在多头注意力结构上引入头级softmax竞争门控，将softmax从token级提升到head级，实现winner‑take‑all并保持O(L)复杂度。

**🔧 技术方法**

结合线性注意力的kernel特征映射ϕ与头级softmax门控，支持递归实现与分块并行训练。

**📊 数据集**

在15B tokens的SlimPajama语料上训练，并在WikiText、LAMBADA、SQuAD、SWDE、FDA、NIAH以及lm‑evaluation‑harness等数据集上评估。

**📈 对比分析**

与RetNet、GLA、GDN等线性基线及全注意力Transformer++对比，SLA在语言建模降低perplexity、在检索任务提升准确率（如S‑NIAH‑3提升至≈89%+），整体性能优于基线。

**⚠️ 局限性**

仍有轻微的内存与推理延迟开销，且对head数量和语义槽的假设敏感，过多head可能导致竞争不稳定，未充分探索不同核函数的影响。

---

## 538. LDRNet: Large Deformation Registration Model for Chest CT Registration

**arXiv ID:** 2602.01812 | [PDF](https://arxiv.org/pdf/2602.01812v1)

**作者:** Cheng Wang `[一作]` (Deepwise AI Laboratory), Yizhou Yu `[通讯]` (Deepwise AI Laboratory)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

提出一种无监督的粗到细多分辨率胸CT配准模型LDRNet，利用refine block和rigid block对注册场进行细化与全局变换，从而实现大变形胸CT配准；

**💡 创新点**

创新点包括：1）粗到细的无监督网络框架；2）refine block结合前后阶段注册场、特征及差异信息进行局部细化；3）rigid block利用高层特征直接学习旋转平移矩阵，兼顾全局一致性；4）针对胸CT大变形背景设计专属正则化与损失；

**🔧 技术方法**

使用3D卷积、UNet架构、grid sampler（STN）、三阶线性插值、Leaky ReLU+BatchNorm、正则化损失（range、smooth）、Adam优化、MSE相似度以及Dice评价指标；

**📊 数据集**

在私有682张胸CT数据（48张测试）与公开SegTHOR（60张）以及LPBA40进行训练与评估；

**📈 对比分析**

与传统方法ANTs、deedsBCV以及深度学习方法VoxelMorph、RCN、LapIRN进行对比；在SegTHOR和私有数据集上Dice平均值与传统方法相当或略优，明显优于VoxelMorph；在速度上GPU运行时间约0.01s，比ANTs和deedsBCV快200多倍；在LPBA40上略优于LapIRN；

**⚠️ 局限性**

局部连续性仍不理想，需要更多数据提升泛化能力；对极大变形和复杂背景的细节捕捉还有改进空间。

---

## 539. FlowBypass: Rectified Flow Trajectory Bypass for Training-Free Image Editing

**arXiv ID:** 2602.01805 | [PDF](https://arxiv.org/pdf/2602.01805v1)

**作者:** Menglin Han `[一作]` (Tongji University), Zhangkai Ni `[通讯]` (Tongji University)

**通讯引用:** 1137 | [OpenAlex ID](https://openalex.org/A5032273272)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `04572f8d-59e5-41c9-8850-ac8e7ee2b108` `a8e75ba4-7a2d-4153-b003-06c94533add0` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种训练-free的图像编辑框架FlowBypass，直接在反演轨迹与重建轨迹之间构造bypass以减少误差积累

**💡 创新点**

创新点在于用Rectified Flow的理论推导得到一个近似的bypass闭式解，无需额外训练或特征操作；同时通过空白prompt与正负prompt组合实现全局可控

**🔧 技术方法**

核心技术包括Rectified Flow（RF）ODE建模、CFG（Classifier‑Free Guidance）与Euler离散、Taylor展开近似梯度、指数函数近似以及基于中间时刻的bypass计算

**📊 数据集**

在EditEvalv2基准上评估，共150张高分辨率图像，涵盖七类编辑任务（物体增删换、背景/风格/纹理/动作变化）

**📈 对比分析**

与多种DDIM与RF基础方法（如SD1.4、SD3.5、FLUX.1‑dev、NTI、DDCM、IP2P、Omni‑Gen、LEDITS++等）进行对比，实验显示FlowBypass在LPIPS、原始图像相似度与Prompt相似度上实现或接近Pareto前沿，表现出更优的质量与对齐平衡

**⚠️ 局限性**

局限包括对bypass时间步的手工选择、对梯度近似与指数近似的经验依赖、以及在极端编辑场景下可能出现的细节失真或过度改动

---

## 540. Fostering Data Collaboration in Digital Transportation Marketplaces: The Role of Privacy-Preserving Mechanisms

**arXiv ID:** 2602.01804 | [PDF](https://arxiv.org/pdf/2602.01804v1)

**作者:** Qiqing Wang `[一作]` (National University of Singapore), Kaidi Yang `[通讯]` (National University of Singapore)

**通讯引用:** 3337 | [OpenAlex ID](https://openalex.org/A5067972930)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d` `9cc9baba-5356-466d-81ff-d80028d90279` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文建立了基于Stackelberg博弈的框架，研究在政府与移动服务提供商之间的交通数据协作中引入扰动式隐私保护机制的影响，并在交通信号优化场景中实现与验证。

**💡 创新点**

创新点在于：①将差分隐私（Gaussian机制）与多方交通数据协作结合，形成可解释的隐私预算与数据质量阈值关联的决策模型；②在此框架下证明存在Stackelberg均衡并给出成功协作的充分条件；③将理论框架嵌入实际的交通信号控制（MAXBAND + Webster）中，首次在此应用中评估隐私保护对交通效益的量化影响。

**🔧 技术方法**

采用的主要技术包括：差分隐私（Gaussian机制）对轨迹与计数数据进行扰动；LWR理论的交通需求估计；Stackelberg博弈分析与均衡求解（混合整数线性规划与MPEC求解）；交通信号控制的MAXBAND优化与Webster公式；仿真与数值实验验证。

**📊 数据集**

实验使用了真实杭州城市干道三交叉口的交通流量与车辆轨迹数据（通过摄像头采集的实际交通量以及运营车辆的轨迹记录）。

**📈 对比分析**

通过对不同隐私预算和数据质量阈值的组合绘制MA与MP效用热图，比较高、低数据质量需求下的协作情况，结果显示：中低数据质量阈值可促进协作，过高阈值导致协作失败，实验结果与理论分析一致。

**⚠️ 局限性**

研究局限：①仅考虑星型拓扑（单一政府向多家MP请求）；②假设轨迹数据满足线性估计与固定敏感度；③未考虑成本补偿与货币激励；④δ值固定，未探讨不同δ对结果的影响；⑤在大规模MP群体或完全连通拓扑下的行为未验证。

---

## 541. ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing

**arXiv ID:** 2602.01797 | [PDF](https://arxiv.org/pdf/2602.01797v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab`

---

## 542. Performance Guarantees of Cellular Networks with Hardcore Regulation and Scheduling

**arXiv ID:** 2602.01802 | [PDF](https://arxiv.org/pdf/2602.01802v1)

**作者:** Ke Feng `[一作]` (CNRS-ETIS), Catherine Rosenberg `[通讯]` (University of Waterloo)

**通讯引用:** 7752 | [OpenAlex ID](https://openalex.org/A5032643029)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

**🎯 论文内容**

研究在硬核（hardcore）空间调控与基站调度下的蜂窝网络下行链路性能保证，推导了更紧的干扰上界和对应的速率下界。

**💡 创新点**

创新点包括：① 引入用户与基站关联导致的排斥区域，得到更精细的干扰上界；② 对 (K,H_K)‑硬核调度模型进行解析，给出调度能否提升速率保证的临界硬核距离；③ 在满足速率保证的前提下，阐明可实现的基站功率削减方案。

**🔧 技术方法**

主要技术：空间网络计算（spatial network calculus）、点过程与硬核点过程理论、球体调控（ball regulation）、基站颜色调度（k‑coloring）以及积分与不等式推导。

**📊 数据集**

本文为理论分析为主，没有使用真实数据集；通过仿真图示验证了理论界限在不同路径损耗指数、SNR、K 值下的表现。

**📈 对比分析**

比较方法：将永远激活（AA）与周期调度（K 轮）两种策略在理论速率下界、功率消耗等指标上进行对比。结果显示：在高 SNR 且硬核距离足够大时，调度能提高速率保证并允许功率削减；在低 SNR 或硬核距离不足时，AA 更优。

**⚠️ 局限性**

局限性：仅考虑无衰落（no‑fading）场景，忽略随机/时变流量；对实际部署的可实现性和颜色调度算法的实现细节未给出；需要进一步扩展到多用户、多天线或更一般的衰落模型。

---

## 543. Spatio-Temporal Transformers for Long-Term NDVI Forecasting

**arXiv ID:** 2602.01799 | [PDF](https://arxiv.org/pdf/2602.01799v1)

**作者:** Ido Faran `[一作]` (Bar Ilan University), Maxim Shoshany `[通讯]` (Technion Israel Institute of Technology)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

研究了自监督空间‑时间变压器框架 STT‑LTF，用于多尺度卫星影像时间序列的长周期 NDVI 预测，能够直接预测任意未来时点。

**💡 创新点**

创新点包括①将空间补丁嵌入与多尺度注意力引入 Transformer；②通过直接非自回归预测未来时点，消除递归误差；③在四十年无标签 Landsat 数据上使用空间、时间与预测时段三重掩码的自监督训练；④统一框架兼顾局部植被关系与区域气候影响。

**🔧 技术方法**

技术手段为自监督 Transformer（多头注意力、残差连接、位置编码），空间补丁嵌入、周期性时间编码、三维地理坐标投影、dropout、Adam 优化等。

**📊 数据集**

使用了 1984‑2024 年四十年 Landsat 5/7/8/9 的 NDVI 时空序列，覆盖东南地中海梯度地区，约 224 万条像素时间序列。

**📈 对比分析**

与 SVM、CNN‑1D、FC、LSTM、传统 Transformer 等模型在 10 年输入、下一年预测任务下进行比较。STT‑LTF 在 MAE 0.0328、R² 0.8412 的成绩显著优于 LSTM（0.0363/0.8088）、Transformer（0.0361/0.8182）、CNN‑1D（0.0391/0.7810）等。

**⚠️ 局限性**

局限性包括：对突发事件（火灾、干旱）预测精度不足；仅使用 NDVI，未融合气候变量或人类活动指标；跨生态区块迁移性能未知；模型训练与推理对计算资源需求高；依赖 GEE 预处理（云掩码、季节组合）导致数据准备复杂。

---

## 544. Developing a Portable Solution for Post-Event Analysis Pipelines

**arXiv ID:** 2602.01798 | [PDF](https://arxiv.org/pdf/2602.01798v1)

**作者:** Leonardo Pelonero `[一作]` (INAF Astrophysical Observatory of Catania), Ugo Becciani `[通讯]` (INAF Astrophysical Observatory of Catania)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了基于 Science Gateway 的可移植自动化后事件分析管道，集成摄影测量、机器学习语义分割与三维可视化，用于评估自然灾害对风险资产的影响。

**💡 创新点**

创新点在于将独立的摄影测量工作流与 AI 处理通过 Apache Airflow DAGs 融合到同一平台，实现工作流编排、容器化与可重复性；同时使用 Docker + CWL 统一部署，支持跨站点 HPC 资源。

**🔧 技术方法**

主要技术包括：Apache Airflow（工作流编排）、Docker（容器化）、CWL（工作流描述）、Agisoft Metashape（结构光摄影测量）、PyTorch 100-Layer Tiramisu（语义分割）、CesiumJS（Web 三维可视化）、Keycloak（身份认证）、FastAPI（后端服务）。

**📊 数据集**

使用的训练数据集包括 FloodNet、RescueNet；实测数据来自 2024 年 Tredozio 市 Monte Busca 区的无人机航拍图像。

**📈 对比分析**

目前未给出系统性定量性能对比，仅在现场测试中展示了三维模型、点云和分割结果；评估主要以可视化质量和可用性为主，尚缺乏精度、处理时间等指标的量化分析。

**⚠️ 局限性**

局限性包括：模型训练域与现场图像差异导致分割效果不佳；缺乏充分的泛化能力和自动化验证；当前仅做初步验证，未提供完整的性能基准；对植被稠密区域的点云细节有限；未来需改进模型、上采样方法和量化评估。

---

## 545. CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding

**arXiv ID:** 2602.01785 | [PDF](https://arxiv.org/pdf/2602.01785v1)

**作者:** Yuling Shi `[一作]` (Shanghai Jiao Tong University), Xiaodong Gu `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 2378 | [OpenAlex ID](https://openalex.org/A5033286111)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

对多模态LLM处理源代码图像的可行性与压缩效果进行系统实验，评估其在代码补全、摘要、克隆检测与问答等任务中的表现；

**💡 创新点**

首次将源代码渲染为图像并通过分辨率压缩实现 8× 以上的压缩率，同时利用语法高亮等视觉增强提升模型性能，探索“视图优先”代码理解新范式；

**🔧 技术方法**

使用多模态LLM（如GPT‑5、Gemini 系列、Qwen‑3‑VL、GLM‑4.6v 等）与代码渲染工具（Pygments + Pillow）生成可调压缩比的代码图像，结合视觉编码、对齐、融合流程；还开展 OCR‑式代码重建与错误分级分析；

**📊 数据集**

使用 Python 与 Java 的代码补全、摘要、克隆检测与问答基准：LongCodeCompletion、LongModuleSummarization、GPTCloneBench、CodeQA（新建后 2025‑08 的 GitHub 代码）等；

**📈 对比分析**

通过将同一样本以文本、不同压缩比图像及不同渲染方式输入，采用 ES/EM、CompScore、ACC/F1、CodeBLEU 等指标进行对比；实验显示 1×–8×压缩仍可获得与文本相当甚至更好效果，尤其在 Gemini 系列模型上可实现 8×压缩仍维持或提升性能；

**⚠️ 局限性**

目前视觉编码与 OCR 仍存在局限，低压缩下字符细节丢失导致错误；不同模型对压缩敏感度差异显著，且缺乏专门针对代码的视觉预训练，限制了极限压缩与跨语言泛化的进一步提升。

---

## 546. DIA-CLIP: a universal representation learning framework for zero-shot DIA proteomics

**arXiv ID:** 2602.01772 | [PDF](https://arxiv.org/pdf/2602.01772v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 547. LingLanMiDian: Systematic Evaluation of LLMs on TCM Knowledge and Clinical Reasoning

**arXiv ID:** 2602.01779 | [PDF](https://arxiv.org/pdf/2602.01779v1)

**作者:** Rui Hua `[一作]` (Beijing Jiaotong University), Xuezhong Zhou `[通讯]` (China Academy of Chinese Medical Sciences)

**通讯引用:** 7011 | [OpenAlex ID](https://openalex.org/A5052838340)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

构建了LingLanMiDian（LingLan）这一大规模、专家裁定的多任务中文传统医学（TCM）评测基准，并对14款主流LLM在其中进行零样本评估。

**💡 创新点**

创新点包括：① 统一的评价指标体系（准确率、精确召回、字符级F1、余弦相似度、MAE等），② 同义词容忍与决策识别（Decision Recognition）重新表述开放式推理任务，③ 设定每个子任务400条难度子集（Hard subset）以检验模型鲁棒性，④ 涵盖知识回忆、多跳推理、信息抽取、诊疗决策等五大领域的13项子任务，总计25,624条专家核实实例。

**🔧 技术方法**

技术手段：零样本评估、统一的分数计算公式（多标签、字符级、多义词匹配）、对比分析、基准数据预处理与专家审校、使用多种LLM（Qwen、DeepSeek、Baichuan、GPT‑5等）进行统一推理，采用“思考模式”（Thinking）提升推理深度。

**📊 数据集**

使用的数据集包括：① TCM 许可考试（TLE）多项选择题；② 基础 TCM 知识（FTK）与中药制剂（CPMK）抽取的知识图谱；③ EMR 与古典文本的实体抽取（IE）语料；④ 13,000+ 真实临床案例构成的诊疗推理（DTR）和其重构为单选的决策识别（DR）子集。

**📈 对比分析**

比较方法：在同一零样本、统一解码参数下评估14款开源LLM，分别在完整集与Hard子集上计算各子任务指标；结果显示：许可考试准确率≈95%（Hard ≈78%）；知识型任务准确率高于50%，但多选与填空表现低于单选；信息抽取在现代 EMR 上表现相对稳定，古典文本下降明显；开放式 DTR 低于 40%，但转为 DR 后准确率提升至 70%+；整体平均分数在完整集约 51，Hard 子集约 31，体现了模型在面临高难度推理和同义词容忍时的显著退化。

**⚠️ 局限性**

局限性：① 仅为文本评测，未涵盖舌象、面色、脉象等多模态特征；② 公开数据规模虽大，但对真实临床多样性与长期随访仍有限；③ 开放式推理任务仍依赖精细化生成，精确匹配难以覆盖所有临床表述；④ 同义词、实体命名统一仍以字符级 F1 方式处理，可能忽略深层语义相似度；⑤ 对模型偏差与安全性评估缺乏系统考量。

---

## 548. Data Distribution Matters: A Data-Centric Perspective on Context Compression for Large Language Model

**arXiv ID:** 2602.01778 | [PDF](https://arxiv.org/pdf/2602.01778v1)

**作者:** Kangtao Lv `[一作]` (Zhejiang University), Bo Zheng `[通讯]` (Future Living Lab of Alibaba)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过从数据角度系统研究了大型语言模型（LLM）在长文本压缩中的表现，利用自编码器框架对不同输入熵与模型内部知识分布的影响进行量化评估；

**💡 创新点**

创新点在于首次将数据分布（输入熵与编码器/解码器内部预训练知识差距）作为核心因素进行探讨，并提出解码器分布对压缩质量的决定性作用与相应的实用部署指南；

**🔧 技术方法**

采用从零开始预训练的自编码器（Encoder–Decoder）模型，并结合信息熵、F1/ROUGE‑L/BLEU指标进行性能评估；

**📊 数据集**

使用The Pile的多域数据集（含Common Crawl、ArXiv、GitHub、DM Math等混合），分别构造六种不同分布的训练集；

**📈 对比分析**

通过在Encoder与Decoder预训练数据不匹配的对照实验，发现当两者分布差距增大时压缩质量显著下降，且与解码器分布匹配的方案优于仅匹配编码器；

**⚠️ 局限性**

局限性在于实验仅基于自编码器架构，未验证在其他压缩方法（如硬/软提示）上的普适性，并且对极端分布差异的理论解释仍不完整。

---

## 549. Stein-Rule Shrinkage for Stochastic Gradient Estimation in High Dimensions

**arXiv ID:** 2602.01777 | [PDF](https://arxiv.org/pdf/2602.01777v1)

**作者:** M. Arashi `[一作]` (Ferdowsi University of Mashhad), M. Amintoosi `[通讯]` (Ferdowsi University of Mashhad)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

将随机梯度视为高维估计问题，引入Stein收缩估计器并实现SR-Adam优化器。

**💡 创新点**

在深度学习中首次应用Stein规则收缩来降低梯度噪声，实现无额外超参数的自适应收缩，并证明其在高维下均匀占优且极小化。

**🔧 技术方法**

决策理论、Stein收缩、Adam自适应动量、在线噪声方差估计、理论证明及数值实验。

**📊 数据集**

CIFAR-10和CIFAR-100（含0%、5%、10%标签噪声）。

**📈 对比分析**

与SGD、Momentum、Adam等基线在相同训练配置下比较，SR-Adam在大批量与噪声环境下平均提升约1–2个百分点，显著优于Adam，且仅增加0.7%计算开销。

**⚠️ 局限性**

提升幅度相对有限；收缩仅在高维卷积层有效，低维层需手动排除；理论假设为高斯噪声，实测可能受非正态影响；对极端噪声或小批量仍需进一步验证。

---

## 550. WorldCup Sampling for Multi-bit LLM Watermarking

**arXiv ID:** 2602.01752 | [PDF](https://arxiv.org/pdf/2602.01752v1)

**作者:** Yidan Wang `[一作]` (Institute of Information Engineering), Li Guo `[通讯]` (Institute of Information Engineering)

**通讯引用:** 10158 | [OpenAlex ID](https://openalex.org/A5100675165)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种名为 WorldCup 的多位数水印框架，在 LLM 的推理采样过程中直接将信息嵌入到 token 的选择里，采用分层竞争、熵感知调制和置信度感知解码。

**💡 创新点**

创新点包括：①将采样视为自然通信通道，直接写入消息而非间接的 seed 驱动；②引入互补的 g‑value 函数实现最优可区分性；③熵感知动态权重 λ 平衡可检测性与文本质量；④置信度感知解码替代传统计数方式，提升解码效率与鲁棒性。

**🔧 技术方法**

技术手段：分层锦标赛式采样、互补伪随机 g‑value 函数、熵感知调制、置信度加权聚合、基于 z‑score 的检测与多位数解码算法。

**📊 数据集**

使用的语料库：C4、OpenGen 生成提示；下游任务数据集：机器翻译、文本摘要、问答与数学推理；文本质量评估采用 Vicuna‑13B 的 PPL；模型包括 LLaMA3‑8B、Gemma2‑9B 及其指令调优版。

**📈 对比分析**

与 BiMark、MPAC、SegMark 等公开基线在同一模型与任务上对比，WorldCup 在 16/24/32/48 位信息量下均获得 2–9% 的位准确率提升；零位检测 AUC 约 99.7%；在编辑、复制粘贴、改写等攻击下 AUC 及解码准确率分别高 3–15% 与 91.1%；文本 PPL 低于基线，甚至低于自然文本，表明生成质量得到保持。

**⚠️ 局限性**

局限性：熵感知调制会略微降低位准确率；k 增大导致编码时间线性增长；在 Gemma2‑9B 等生成能力更强的模型上，误差仍高于 LLaMA3；对极端攻击（如大规模重写）尚未全面验证；技术实现依赖高质量的随机函数与密钥管理，若密钥泄露可能影响安全。

---

## 551. Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking

**arXiv ID:** 2602.01750 | [PDF](https://arxiv.org/pdf/2602.01750v1)

**作者:** Mohammad Beigi `[一作]` (University of California), Lifu Huang `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a4b10f5d-130b-4e77-9367-6469ec621899` `6215c339-3735-4be3-8a07-5bbb7004712d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 Adversarial Reward Auditing（ARA）框架，将奖励模型漏洞挖掘和检测视为双人博弈，利用 Hacker 发现漏洞，Auditor 检测并抑制。

**💡 创新点**

创新点在于把奖励模型误差从被动的约束转为主动的对抗检测；通过两阶段训练将“reward hacking”变为可观测且可控制的信号，并实现跨域推广的单一 Auditor。

**🔧 技术方法**

采用 PPO 对 Hacker 进行奖励模型对抗训练，使用多层感知机和对比损失训练 Auditor，后续以 Auditor 把代理奖励门控后再用 PPO 进行 RLHF；同时引入 Polyak 均值、Replay Buffer、动态更新调度等技术。

**📊 数据集**

主要使用三个 RLHF 任务的数据集：Anthropic HH‑RLHF + SycophancyEval（sycophancy）、长度偏差评估数据、Code‑Gaming 数据（基于单元测试的编程任务）。

**📈 对比分析**

与 SFT、PPO、PPO‑KL、ODIN、InFoRM、RM Ensemble、Reward‑filtering 等 7 种基线比较，ARA 在 sycophancy、length bias、code gaming 三种攻击场景均实现了最优的 alignment‑utility 权衡：sycophancy 下降至 38.4% 并帮助率提升至 77.2%；长度偏差长度降至 162 词且 ROUGE‑L 最高；代码游戏 exploit 率降至 19.6% 并 Pass@1 提升至 35.8%。

**⚠️ 局限性**

局限性包括：仍依赖冻结的奖励模型；Auditor 的检测能力受模型容量影响；跨域迁移虽然可行但并非完美，尤其对 code‑gaming 的迁移效果有限；以及在更大规模或更复杂任务中验证效果仍待进一步研究。

---

## 552. Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives

**arXiv ID:** 2602.01749 | [PDF](https://arxiv.org/pdf/2602.01749v1)

**作者:** Lin Chen `[一作]` (Shanghai Jiao Tong University), Zhouhan Lin `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 6418 | [OpenAlex ID](https://openalex.org/A5024900991)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种通过混合正向与反向策略的可调参数α来控制GFlowNet的探索–利用平衡，从而提升模式发现能力并保证收敛；

**💡 创新点**

创新点在于将GFlowNet目标与马尔可夫链可逆性等价性阐明，进而引入α‑混合目标（α‑GFN），并给出基于α的调度策略，解决了传统α=0.5所带来的探索不足或利用过度问题；

**🔧 技术方法**

采用了马尔可夫链理论中的可逆性概念、流平衡（SubTB、DB、TB）目标、前向‑后向策略混合、梯度分析以及两阶段α调度算法；

**📊 数据集**

在三类数据集上验证：Set Generation（集合生成）、Bit Sequence Generation（位序列生成）和Molecule Generation（分子生成）等；

**📈 对比分析**

与原始GFlowNet目标（DB、SubTB、TB）以及其前向‑后向变体（FL‑DB、FL‑SubTB）相比，α‑GFN在三大任务中均显著提升模式数量，最高可提高近10倍，且在平均奖励和多样性上保持或提升；

**⚠️ 局限性**

局限性包括对α取值的敏感性仍需经验选择，调度算法会略微增加方差，且在高维任务中不同α对收敛速度和轨迹长度的影响尚未完全理论化。

---

## 553. Rethinking LoRA for Data Heterogeneous Federated Learning: Subspace and State Alignment

**arXiv ID:** 2602.01746 | [PDF](https://arxiv.org/pdf/2602.01746v1)

**作者:** Hongyi Peng `[一作]` (Nanyang Technological University), Qiang Yang `[通讯]` (Hong Kong Polytechnic University)

**通讯引用:** 99985 | [OpenAlex ID](https://openalex.org/A5100636286)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种针对非IID联邦微调的LoRA改进方案

**💡 创新点**

将LoRA的固定低秩子空间替换为GaLore梯度子空间优化，并通过AJIVE滤波实现服务器端的第二矩阵同步，解决更新空间和优化器状态不匹配问题

**🔧 技术方法**

GaLore梯度子空间优化、AdamW、AJIVE、随机SVD/随机投影

**📊 数据集**

NLU：RoBERTa在GLUE任务；Vision：ViT在DomainNet；NLG：Llama‑2‑7B在MetaMathQA、GSM8K、MATH

**📈 对比分析**

与FedAvg‑Full、FedIT、FFA‑LoRA、FLoRA、FR‑LoRA、LoRA‑Fair等基线比较；在非IID设置下，所提方法在准确率和鲁棒性（Δ值）上显著优于现有LoRA基线，接近全参数微调性能

**⚠️ 局限性**

需要在更大规模参与度和不同通信预算下验证；对理论假设的严格性和AJIVE的计算复杂度仍有待进一步研究

---

## 554. Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention

**arXiv ID:** 2602.01801 | [PDF](https://arxiv.org/pdf/2602.01801v1)

**作者:** Dvir Samuel `[一作]` (OriginAI), Rami Ben-Ari `[通讯]` (OriginAI)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `fede83ac-7505-405f-ab37-e7284695c47f` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ba576bd1-e51d-44e8-8077-fc943b333c93` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

开发了一套训练无关的稀疏注意力加速框架，压缩自回归视频扩散与世界模型的KV缓存，减少自注意力与交叉注意力计算。

**💡 创新点**

通过Temporal Cache压缩时间冗余、AnnCA利用ANN动态挑选提示词、AnnSA限制自注意力仅对语义匹配的key，从而在不改模型的前提下实现5‑10倍速度提升且显存保持不变。

**🔧 技术方法**

基于LSH/量化的近似最近邻搜索、FlashInfer/FlashAttention3稀疏注意力核、流式KV缓存重用技术以及Temporal Correspondence聚合等技术。

**📊 数据集**

使用LongVBench与LongVGenBench长视频基准以及Rolling‑Forcing与LongVie2自回归模型的数据集。

**📈 对比分析**

与Dense FlashAttention3、TeaCache、FlowCache、SVG、RadialAttention等基线对比，在Rolling‑Forcing上实现约10.7×速度提升，PSNR/SSIM/LPIPS与基准相当，显存保持恒定。

**⚠️ 局限性**

对极端语义变化或大范围帧间差异的KV压缩精度下降，ANN近似可能导致微小质量损失，且目前只在单GPU上验证。

---

## 555. ParaGSE: Parallel Generative Speech Enhancement with Group-Vector-Quantization-based Neural Speech Codec

**arXiv ID:** 2602.01793 | [PDF](https://arxiv.org/pdf/2602.01793v1)

**作者:** Fei Liu `[一作]` (National Engineering Research Center of Speech and Language Information Processing, University of Science and Technology of China), Yang Ai `[通讯]` (National Engineering Research Center of Speech and Language Information Processing, University of Science and Technology of China)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了基于组向量量化神经语音编解码器的并行生成式语音增强框架 ParaGSE，用于去噪、消回声及混合失真。

**💡 创新点**

创新点在于使用独立的组向量量化（GVQ）产生可并行预测的离散 token，消除序列预测瓶颈并去除对 LLM/语义 token 的依赖。

**🔧 技术方法**

采用 G-MDCTCodec、Conformer、BiLSTM、STFT、并行 token 预测分支，结合交叉熵训练，实现在语音编解码上的并行生成。

**📊 数据集**

使用 VoiceBank 语料库（23k 句）构建清晰语音，加入 DEMAND 噪声、DNS RIR 与混合失真，评测 8kHz 下的去噪、消回声和混合抑制。

**📈 对比分析**

与 DEMUCS、CMGAN、MP‑SENet、Genhancer 等基线比较，ParaGSE 在 LSD、NISQA、DNSMOS、UTMOS 等客观指标和 ABX 主观测试中表现相当或优于对手，CPU 上生成速度提升约 1.5×。

**⚠️ 局限性**

局限在于仍需改进对极端失真或实时部署的鲁棒性，且依赖编码器的量化误差导致 LSD 指标略逊于传统判别模型。

---

## 556. Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting

**arXiv ID:** 2602.01776 | [PDF](https://arxiv.org/pdf/2602.01776v1)

**作者:** Mingyue Cheng `[一作]` (University of Science and Technology of China), Enhong Chen `[通讯]` (University of Science and Technology of China)

**通讯引用:** 27839 | [OpenAlex ID](https://openalex.org/A5048237545)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了“代理式时间序列预测”（ATSF）的概念，将预测过程视为感知、规划、执行、反思与记忆的多轮交互流程

**💡 创新点**

核心创新在于把预测从单一模型输出转化为可持续学习、工具调用与经验积累的代理式决策框架

**🔧 技术方法**

包括工作流式设计、代理式强化学习和混合AgentFlow等实现范式，并借助大型预训练模型、工具箱等技术

**📊 数据集**

未在论文中给出具体实验数据集，主要以理论与设计说明为主

**📈 对比分析**

暂无实验对比与性能评估，文章聚焦概念性阐述与研究方向

**⚠️ 局限性**

局限性包括缺乏具体实现与验证、内存与工具协作机制尚未成熟、可解释性与安全性待提升

---

## 557. Efficient Cross-Architecture Knowledge Transfer for Large-Scale Online User Response Prediction

**arXiv ID:** 2602.01775 | [PDF](https://arxiv.org/pdf/2602.01775v1)

**作者:** Yucheng Wu `[一作]` (Peking University), Leye Wang `[通讯]` (Peking University)

**通讯引用:** 6698 | [OpenAlex ID](https://openalex.org/A5055087680)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a2602d71-93ab-4bad-974b-672788df8193` `8d10c613-917e-4880-9716-17789f50e119` `64443552-63e0-44b5-906f-d90fe95c5a1b` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

设计并验证了 CrossAdapt 两阶段知识迁移框架，解决大规模用户响应预测中的模型切换成本。

**💡 创新点**

① 离线采用维度自适应嵌入投影与渐进网络蒸馏，② 在线实现非对称教师-学生共演进与分布感知历史知识保留，③ 统一采样策略提升蒸馏效率。

**🔧 技术方法**

维度自适应投影（PCA/QR）、渐进冻结/解冻、基于 KL/JS 的分布偏移检测、经验回放式历史样本增强、非对称梯度累积等技术。

**📊 数据集**

公共数据集 Criteo、Avazu、Criteo1T 以及腾讯微信渠道广告的 CVR 流量。

**📈 对比分析**

与无蒸馏、Vanilla KD、Hint-KD、RKD 等基线对比，CrossAdapt 在 AUC 0.27–0.43% 提升、训练时间缩减 43–71%，工业 A/B 测试 AUC 下降仅 0.0010（比 Vanilla KD 缩小 58%）。

**⚠️ 局限性**

对离线历史数据完全不可用时仍需足量训练样本；维度投影在极大维度变换下可能产生信息损失；在线共演进依赖分布偏移阈值调参，需手动设置。

---

## 558. Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency

**arXiv ID:** 2602.01765 | [PDF](https://arxiv.org/pdf/2602.01765v1)

**作者:** Bingzheng Wang `[一作]` (Institute of Information Engineering), Weiping Wang `[通讯]` (Institute of Information Engineering)

**通讯引用:** 7592 | [OpenAlex ID](https://openalex.org/A5100442310)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于扩散模型噪声一致性检测与去毒的统一框架TNC-Defense，实现灰盒后门检测与触发无关的时序去毒。

**💡 创新点**

创新性发现并利用“时间噪声不一致性”作为后门激活信号，提出自适应阈值检测与仅在异常时间步进行参数微调的去毒策略，显著提升检测与去毒效果。

**🔧 技术方法**

使用扩散模型噪声预测、均方误差、可变阈值、内容保持的提示增强、清洁噪声回归损失与解耦约束等技术实现检测与去毒。

**📊 数据集**

在MS-COCO数据集上对Stable Diffusion v1.4/v1.5、SDXL、Stable Diffusion 3等模型进行实验，并使用BadT2I、VillanBKD、EvilEdit等多种后门攻击场景。

**📈 对比分析**

与T2IShield、UFID、NaviT2I、UCE、REFACT等基线对比，TNC-Detect平均准确率提升约11%，AUROC接近1；TNC-Detox在5种攻击下ASR降至0，FID_t/FID_c变化≤5%。

**⚠️ 局限性**

依赖噪声一致性特征，若攻击者在训练中加入噪声平滑正则化或CFG参数误配，检测效果会下降；对不同模型架构仍需手动调整阈值参数。

---

## 559. A Provable Expressiveness Hierarchy in Hybrid Linear-Full Attention

**arXiv ID:** 2602.01763 | [PDF](https://arxiv.org/pdf/2602.01763v1)

**作者:** Xiaowei Ye `[一作]` (Ecole Polytechnique), Pinyan Lu `[通讯]` (Shanghai University of Finance and Economics)

**通讯引用:** 2966 | [OpenAlex ID](https://openalex.org/A5025408809)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文通过理论分析，研究了混合线性-全注意力（Hybrid Linear-Full Attention）与传统全注意力在表达能力上的差异，并证明了线性注意力层无法替代全注意力完成深层序列函数组合任务；同时探讨了单层稀疏注意力在 2‑Sum 任务中的下限；

**💡 创新点**

创新点在于首次给出混合注意力与全注意力之间的可表达性层级划分，利用通信复杂度与不可区分分解技术证明了即使添加指数级线性层，混合网络仍无法匹配单层全注意力的推理能力，并且给出稀疏注意力在特定任务上的严格弱化；

**🔧 技术方法**

主要技术手段包括：通信复杂度框架、不可区分分解（indistinguishable decomposition）、归纳构造、鸽巢原理以及将线性注意力视为 RNN 的递归形式来推导下界；

**📊 数据集**

该工作不使用真实数据集，而是通过构造的理论任务——L‑序列函数组合（Sequential Function Composition）和 2‑Sum——来进行验证；

**📈 对比分析**

比较方法基于构造下界任务：证明在全注意力网络仅需 L+1 层即可解决任务，而任何混合网络即使包含 2^3L² 层线性注意力也无法完成；稀疏注意力在单层时需要至少 Hdp ≥ Ω(B log n) 的容量；该研究主要提供理论证明，未给出实验性能指标；

**⚠️ 局限性**

局限性包括：理论结果仅适用于特定的合成任务，可能与实际大模型的表现不完全一致；仅考虑单层稀疏注意力和线性注意力的特定实现，未覆盖多层或更复杂的稀疏策略；

---

## 560. PRISM: Parametrically Refactoring Inference for Speculative Sampling Draft Models

**arXiv ID:** 2602.01762 | [PDF](https://arxiv.org/pdf/2602.01762v1)

**作者:** Xuliang Wang `[一作]`, Ming Li `[通讯]` (University of Waterloo)

**通讯引用:** 13259 | [OpenAlex ID](https://openalex.org/A5100351326)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种新的草稿模型架构 PRISM，通过在不同生成步骤使用不同参数集合来实现模型容量与推理成本的解耦，从而在 Speculative Decoding 中提升接受率与吞吐量。

**💡 创新点**

核心创新点是基于“棱镜”概念的条件计算：将草稿模型的计算路径按步骤拆分，形成层级化的参数映射，既保持每步激活参数量不变，又通过累计使用更多参数来提升模型容量；同时提出了针对这种结构的上下文对齐训练策略。

**🔧 技术方法**

采用 Transformer 结构并在每一步使用不同的 Transformer 层；结合 KV 缓存迁移、token 及隐藏状态对齐；利用 SGLang 推理引擎实现 CUDA Graph、持续批处理等硬件优化；训练时使用交叉熵与均方误差相结合的损失函数。

**📊 数据集**

训练数据来源于 ShareGPT、UltraChat 和 OpenThoughts2，约 800 万样本，最大长度 2048 个 token；评估基准包括 MT‑Bench、HumanEval、GSM8K、Alpaca、CNN/Daily Mail 与 Natural Questions。

**📈 对比分析**

与标准 Speculative Decoding、EAGLE‑2、HASS、EAGLE‑3 等基线进行对比；在 NVIDIA A800 与 4090 GPU 上测得：PRISM 在 6 个任务上平均提升 14.1% 的接受率、6.1% 的吞吐量，相比 EAGLE‑2/ HASS 提升 2.4–2.6 倍的端到端速度；在长文本任务中对比 HASS 更显优势。

**⚠️ 局限性**

限制方面：对不同模型尺寸的泛化尚未验证；树形结构的深度与宽度仍需经验调参，过深或过宽会导致验证开销上升；当前仅在 LLaMA‑2‑7B 与 LLaMA‑3‑8B 上评估，尚未在更大模型或不同架构上验证其可迁移性。

---

## 561. GDPR-Compliant Person Recognition in Industrial Environments Using MEMS-LiDAR and Hybrid Data

**arXiv ID:** 2602.01764 | [PDF](https://arxiv.org/pdf/2602.01764v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 562. MagicFuse: Single Image Fusion for Visual and Semantic Reinforcement

**arXiv ID:** 2602.01760 | [PDF](https://arxiv.org/pdf/2602.01760v1)

**作者:** Hao Zhang `[一作]` (Wuhan University), Jiayi Ma `[通讯]` (Wuhan University)

**通讯引用:** 36298 | [OpenAlex ID](https://openalex.org/A5040010053)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `729e5870-4135-47f5-97f2-e3974d07b5dc` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了单图像融合框架MagicFuse，能够仅利用低质量可见图像生成跨光谱场景表示；

**💡 创新点**

创新点在于引入跨光谱知识生成与可见光知识增强的扩散分支，并通过噪声融合与语义约束实现知识层面的光谱融合；

**🔧 技术方法**

使用扩散模型（LDM）、变压器式自编码器、注意力加权噪声融合网络以及语义分割头；

**📊 数据集**

在MFNet、FMB、LLVIP等多模态融合数据集上训练与评估，并在Cityscapes等公开数据集上验证通用性；

**📈 对比分析**

与多模态融合方法（如TarDAL、SegMiF、Text-DiFuse等）对比，MagicFuse在视觉和语义指标上基本匹配甚至超越传统方法，且仅需单一可见输入；

**⚠️ 局限性**

局限在于依赖大量高质量训练样本、推理时计算量大，且在极端低光或噪声极高的场景下性能仍可能下降。

---

## 563. Spot-Wise Smart Parking: An Edge-Enabled Architecture with YOLOv11 and Digital Twin Integration

**arXiv ID:** 2602.01754 | [PDF](https://arxiv.org/pdf/2602.01754v1)

**作者:** Gustavo P. C. P. da Luz `[一作]` (University of Campinas), Juliana Freitag Borin `[通讯]` (University of Campinas)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `3855fcda-48ef-4070-a15e-803cd5c84d83` `90291a0e-9d36-4a08-9a16-89ce846d923f` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在Unicamp的计算机研究所开发并部署了一套基于YOLOv11m TFLite的边缘智能停车系统，采用距离感知匹配的spot‑wise方法和自适应边界框分割，能够实时检测每个车位的占用状态，并将结果通过Digital Shadow可视化，同时引入TV Box支持服务器实现系统的可维护性与可扩展性。

**💡 创新点**

创新点包括：①将距离感知匹配与自适应边框分割两种后处理方法结合，实现单车检测精度提升并抑制误检测；②首次在校园级停车系统中部署Digital Shadow（单向实时可视化）并利用NGSI‑LD标准实现与FIWARE生态的互操作；③利用改装的TV Box作为应用支持服务器，实现低成本、可持续的边缘与云端通信桥接。

**🔧 技术方法**

主要技术包括YOLOv11m TFLite深度学习模型、距离匹配算法、Adaptive Bounding Box Partitioning、Raspberry Pi摄像头采集、InfluxDB时间序列数据库、NGSI‑LD + FIWARE组件（Orion、QuantumLeap、CrateDB等）、Docker Compose、Prometheus + Grafana监控、Telegram Bot、以及基于TV Box的支持服务器。

**📊 数据集**

实验使用与先前工作相同的公共停车数据集（约4477张图像，包含白天、夜间、雨天、晴天等多种场景）和车位坐标标注表；数据集与PKLot公开数据集相似，主要用于验证边缘推理性能。

**📈 对比分析**

采用balanced accuracy、MAE、推理时间和模型体积等指标进行比较。YOLOv11m（TFLite）spot‑wise+ABBP在边缘设备上实现了98.80% 的平衡准确率、0.08 的MAE、8.5秒的推理时延以及40.5 MB 的模型尺寸，优于之前的YOLOv11x、YOLOv10x 等同类模型，且相较基线模型仅提升 0.5 秒推理时延。

**⚠️ 局限性**

主要局限包括：spot‑wise 方法的时间复杂度为 O(n×k)，当车位数增多或车流量高峰时可能产生较高计算负载；Z‑score 异常检测假设检测面积服从高斯分布，实际可能偏离；系统对相机角度变化敏感，需手动或自动调整 ROI 与车位坐标；在超过约100个车位的大型车场中，YOLOv11m 的精度与速度可能不足，需要考虑更大或更轻量化的模型。

---

## 564. Probability-Entropy Calibration: An Elastic Indicator for Adaptive Fine-tuning

**arXiv ID:** 2602.01745 | [PDF](https://arxiv.org/pdf/2602.01745v1)

**作者:** Wenhao Yu `[一作]` (Chinese University of Hong Kong), Irwin King `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 27311 | [OpenAlex ID](https://openalex.org/A5042251906)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个基于相对排名的 token 级加权框架 RankTuner，用来在监督微调中自适应地调整每个 token 的学习权重。

**💡 创新点**

核心创新是把目标 token 的真实排名与期望排名对齐，构造概率–熵校准的 Relative Rank Indicator，并取其逆作为 Relative Scale，既抑制噪声/可替换 token，又聚焦真正欠学的关键 token。

**🔧 技术方法**

技术手段包括：token 熵与概率计算、猜测问题理论、rank‑based 离散化、Cauchy Mean Value Theorem 推导权重公式、在 PyTorch 框架下实现 SFT 训练。

**📊 数据集**

实验数据集涵盖多种数学推理基准（MATH‑OAI、Minerva Math、OlympiadBench、AIME 2024、AMC 2023）以及跨域推理基准（ARC‑C、GPQA）。

**📈 对比分析**

与标准 SFT、概率导向（OverTone、DFT、TALR）和熵导向（EAFT）等基线在 Pass@1/Pass@16 上进行对比，RankTuner 在大多数模型和基准上都获得 5–30% 的提升，且保留了多样性。

**⚠️ 局限性**

局限性包括：仅在监督微调场景验证，未检验在 RLHF 或多任务设置下的表现；权重公式中涉及的超参数需经验调优；对极低熵或极高熵位置的鲁棒性尚未深入研究。

---

## 565. GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation

**arXiv ID:** 2602.01814 | [PDF](https://arxiv.org/pdf/2602.01814v1)

**作者:** Xiao Liang `[一作]` (Zhejiang University), Linchao Zhu `[通讯]` (Zhejiang University)

**通讯引用:** 6088 | [OpenAlex ID](https://openalex.org/A5043617790)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `8d10c613-917e-4880-9716-17789f50e119` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出 Guided Progressive Distillation (GPD) 框架，显著加速视频扩散模型的采样过程，使 48 步缩减至 6 步同时保持高质量输出。

**💡 创新点**

通过在线教师引导生成自适应训练目标、渐进式步长扩展以及频域高频约束，解决传统蒸馏中目标误差大、分布偏移难题。

**🔧 技术方法**

使用在线 refinement、逐步蒸馏（progressive distillation）、频域高通滤波损失、流匹配的扩散模型（Wan2.1 1.3B）以及 CFG 指导。

**📊 数据集**

使用 OpenSora 文本描述数据集进行训练，评估基于 VBench 的 16 项指标，生成分辨率 480p 与 720p 的 81 帧视频。

**📈 对比分析**

与 Wan2.1 原始 48 步、CausVid、AccVideo、PeRFlow、T2V‑Turbo‑V2 等方法对比，GPD 在 VBench 总分 84.04% 领先，速度提升 8 倍，GPU‑days 仅 0.55。

**⚠️ 局限性**

对 720p 生成略有下降，且仍依赖 Wan2.1 基础模型，未在更高分辨率或更长时长视频上验证；高频约束在极端运动场景下可能不足。

---

## 566. CritiqueCrew: Orchestrating Multi-Perspective Conversational Design Critique

**arXiv ID:** 2602.01796 | [PDF](https://arxiv.org/pdf/2602.01796v1)

**作者:** Xiaojiao Chen `[一作]` (Zhejiang University), Qinghua Liu `[通讯]` (Zhejiang University)

**通讯引用:** 71137 | [OpenAlex ID](https://openalex.org/A5100382892)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

CritiqueCrew 是一款集成在 Figma 的设计评审工具，能够让设计师通过多视角专家协作获取可操作的反馈并在画布上实时预览与应用改动。

**💡 创新点**

其创新点在于：①将用户体验、产品愿景与工程可行性等三大专业角色分别建模并同步生成反馈；②通过 Lead Coordinator 进行冲突梳理与优先级排序；③将评审过程转化为可交互的对话与“一键改动”流程，突破传统静态问题清单的局限。

**🔧 技术方法**

技术实现主要依赖 GPT‑4o 通过 LangGraph 进行多角色推理与对话；Figma 插件使用 React 读取与写入画布；设计稿被解析为结构化 JSON 后交给后端进行多视角评审，并生成可直接在 Figma 里应用的修复指令。

**📊 数据集**

实验使用了两组人工构造的多帧 UI mock‑ups（线上教育与电商主题），每个 mock‑up 预设约 16 条可检索问题，未使用公开数据集。

**📈 对比分析**

在 48 名专业 UI 设计师的两项对照实验中，CritiqueCrew 相较于 SpecAI（静态检查工具）和统一专家模型，平均问题覆盖率从 7.96 提升至 9.58（Wilcoxon W=49.0, p=0.006），解决方案有效性从 4.30 提升至 5.22（t=3.90, p<0.001），并在可用性、认知负荷与 AI 信任度上均显著优于基线（SUS 77.3 vs 55.5，NASA‑TLX 40.6 vs 51.9，TAI 3.76 vs 2.89）。

**⚠️ 局限性**

局限性包括：①仅在人工 mock‑up 上测试，未验证真实项目中的情境适用性；②实验样本规模有限且仅涉及设计师；③多视角优势与 Lead Coordinator 的协同效果未完全拆分；④只评估单帧设计，未覆盖多屏流程与代码实现的长期影响。

---

## 567. Automated Discontinuity Set Characterisation in Enclosed Rock Face Point Clouds Using Single-Shot Filtering and Cyclic Orientation Transformation

**arXiv ID:** 2602.01783 | [PDF](https://arxiv.org/pdf/2602.01783v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 568. RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse

**arXiv ID:** 2602.01795 | [PDF](https://arxiv.org/pdf/2602.01795v1)

**作者:** Mingrui Liu `[一作]` (Nanyang Technological University), Kwok-Yan Lam `[通讯]` (Nanyang Technological University)

**通讯引用:** 5982 | [OpenAlex ID](https://openalex.org/A5101720092)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种统一的防御框架RedVisor，通过在冻结的LLM顶部添加轻量化的可切换自注意力适配器，先进行“安全推理”再生成响应，从而实现对Prompt Injection的检测与预防；

**💡 创新点**

创新点在于：1）在单一模型中同时实现可解释的检测和无损预防；2）适配器仅放在顶部并可切换，保证KV缓存可重用，实现零拷贝；3）利用推理阶段生成的安全推理路径作为生成阶段的守门槛；4）在vLLM引擎中实现异步缓存持久化与GPU端模式切换；

**🔧 技术方法**

使用了轻量级自注意力适配器（含门控网络和FFN）、门控并行设计、FlashAttention、GPU端尾部匹配搜索、基于CUDA Graph的无重编译切换、以及与vLLM的自定义内核；

**📊 数据集**

构建了包含五类攻击（Naive、Completion、Multi-round、Ignore、Escape）的Synthetic Prompt Injection数据集（基于Alpaca-Cleaned），并在Alpaca-Farm、AgentDojo、NQ-simplified等基准上进行评测；

**📈 对比分析**

与PromptArmor、PromptLocate、DataFilter、Sandwich Defense、StruQ、SecAlign等方法对比，RedVisor在检测准确率（ROUGE‑L/Embedding Similarity）和攻击成功率（ASR）上均优于对手，同时在响应速度与吞吐量上通过零拷贝KV缓存实现了约2倍以上的加速，且对模型性能的影响几乎为0；

**⚠️ 局限性**

局限性：1）对极度复杂或自适应攻击仍需进一步验证；2）需要在多GPU环境下的同步实现，单GPU时仍有预填计算开销；3）仅保护已冻结模型，若模型参数被修改需重新训练；4）仍是多层防御中之一，需配合网络安全、权限管理等措施。

---

## 569. Grad2Reward: From Sparse Judgment to Dense Rewards for Improving Open-Ended LLM Reasoning

**arXiv ID:** 2602.01791 | [PDF](https://arxiv.org/pdf/2602.01791v1)

**作者:** Zheng Zhang `[一作]` (ShanghaiTech University), Kan Ren `[通讯]` (ShanghaiTech University)

**通讯引用:** 1798 | [OpenAlex ID](https://openalex.org/A5102807475)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

本文提出一种从LLM评判者内部梯度信号提取稠密 token 级奖励的框架，利用自评判机制提升开源任务的推理质量与训练效率。

**💡 创新点**

创新点在于：①通过梯度×嵌入计算 token 对判定结果的贡献，实现稠密奖励；②使用自评判器（冻结的初始策略）而非昂贵外部评判者；③将稠密奖励直接融入 token‑级 GRPO，提升训练速度与效果。

**🔧 技术方法**

技术手段包括：梯度归因（Gradient × Embedding）、Softmax 归一化、token‑级 GRPO（以及可扩展至 RLOO 等 RL 算法），以及对评判者进行单次反向传播即可获得奖励。

**📊 数据集**

在医学咨询（HealthBench、RaR‑Medicine）、学术问答（ResearchQA、RaR‑Science）等开源任务上验证，并对数学推理基准（MATH500 等）做了跨域评估。

**📈 对比分析**

与稀疏奖励基线（Vanilla‑GRPO、RuscaRL）以及 PRM 方法比较，本文方法在所有评测集上均取得 3–7 分的平均提升，收敛速度提高 1.7–1.9 倍，且在多模型、多评测器下表现稳定。

**⚠️ 局限性**

局限性包括：仍依赖评判者的质量，若评判器错误会导致错误奖励；对长篇多步骤决策任务的泛化仍需验证；以及对非文本形式任务的适配尚未探索。

---

## 570. RFS: Reinforcement learning with Residual flow steering for dexterous manipulation

**arXiv ID:** 2602.01789 | [PDF](https://arxiv.org/pdf/2602.01789v1)

**作者:** Entong Su `[一作]` (University of Washington), Abhishek Gupta `[通讯]` (University of Washington)

**通讯引用:** 5867 | [OpenAlex ID](https://openalex.org/A5017906439)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `40105733-5154-44cd-8090-a8cab9e64b07` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出 Residual Flow Steering (RFS)，一种将预训练的流匹配策略与残差动作校正结合的强化学习框架，用于高维多指手抓取和搬运任务的高效适配；

**💡 创新点**

创新点在于统一了输入层（噪声调节）和输出层（残差动作）两种策略调制方式，既能保持预训练的全局探索优势，又能在局部进行精细修正；

**🔧 技术方法**

使用了流匹配生成模型、残差强化学习、离线强化学习（TD3+BC）以及点云感知的 visuomotor 学习；

**📊 数据集**

基于 Apple Vision Pro 的 VR 远程演示数据（约 400 条/任务）训练预训练模型，随后在仿真中采集数据并在真实 Franka‑Leap 手上采集 50 条人类纠正示例；

**📈 对比分析**

与多种基线（DPPO、ReinFlow、IQL、AWAC、Flow‑Q、RLPD、IBRL、Policy Decorator、ResiP、DSRL）对比，RFS 在 6 项仿真任务上平均成功率达 0.87，单项最高 0.95，且在真实环境中相较零样本策略提升 40% 以上，未见单一组件（仅残差或仅噪声调节）表现更佳；

**⚠️ 局限性**

局限性包括仅使用点云观测，缺乏语义/上下文理解，且适配过程仅支持离线微调，无法实时响应动态环境变化。

---

## 571. <SOG_k>: One LLM Token for Explicit Graph Structural Understanding

**arXiv ID:** 2602.01771 | [PDF](https://arxiv.org/pdf/2602.01771v1)

**作者:** Jingyao Wu `[一作]` (Shanghai Jiao Tong University), Chenghu Zhou `[通讯]` (IGSNRR, Chinese Academy of Sciences)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种单一结构化特殊标记，使大语言模型能够精准、简洁地理解图结构。

**💡 创新点**

创新在于将图拓扑编码成单一离散标记并通过混合结构问答对实现与文本标记的对齐，解决了传统 Graph‑to‑Text 与 Graph‑to‑Embedding 的 token 效率与模态不匹配问题。

**🔧 技术方法**

采用拓扑感知图结构分词器、VQ‑编码自监督重构、混合结构 QA 对齐、LoRA 微调以及 LLM 的生成式问答推理。

**📊 数据集**

使用 MoleculeNet 的 5 个药物分子分类数据集（BBBP、Tox21、ClinTox、HIV、BACE）以及节点分类基准 Cora 与 Pubmed。

**📈 对比分析**

相较于 20+ 传统与 LLM 方法，在 3B/7B 规模下实现 9.9%–41.4% 的 AUC 提升，并在节点任务中以 3B 参数超过 GPT‑4o、DeepSeek‑chat 等大模型，表现出显著性能提升。

**⚠️ 局限性**

局限在于对结构化标记的选择敏感，需预先设计代码本大小与锚点策略，且在动态图、异构图等更复杂结构上尚未验证。

---

## 572. Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation

**arXiv ID:** 2602.01756 | [PDF](https://arxiv.org/pdf/2602.01756v1)

**作者:** Jun He `[一作]` (Sun Yat-sen University), Weijia Li `[通讯]` (Sun Yat-sen University)

**通讯引用:** 3738 | [OpenAlex ID](https://openalex.org/A5100613917)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种名为 Mind-Brush 的 agentic 框架，将文本到图像的生成转化为动态的“思考‑检索‑生成”工作流程。

**💡 创新点**

创新点在于同时结合主动多模态检索与逻辑链式推理，构建可自适应的认知缺口检测与知识补全机制，从而实现对长尾概念与复杂推理任务的支持。

**🔧 技术方法**

使用了大型多模态语言模型（如 Qwen‑Image‑Edit）、外部检索工具（Google Search API）、推理引擎（Chain‑of‑Thought 逻辑推理）、以及统一的生成模块。

**📊 数据集**

构建了 Mind‑Bench 评测集，包含 500 条样本，涵盖实时新闻、IP 角色、数学推理、地理推理等 10 个子领域；同时在 WISE 与 RISEBench 上进行评估。

**📈 对比分析**

与多种主流专有与开源 UMM、T2I 模型（如 GPT‑Image‑1、Nano Banana Pro、FLUX‑2 Pro/Max、Stable Diffusion 等）对比，Mind‑Brush 在 Mind‑Bench 上整体准确率提升至 0.31（相较基线 0.02），在 WISE 上 WiScore 递增 25.8%，在 RISEBench 上指令推理得分达 61.5%，表现显著优于同类方法。

**⚠️ 局限性**

局限性包括：对检索工具的依赖导致检索成本和实时性受限；推理模块仍可能产生逻辑错误或过度推断；模型在某些领域（如深度科学推理）仍难以完全取代人类专业知识。

---

## 573. ObjEmbed: Towards Universal Multimodal Object Embeddings

**arXiv ID:** 2602.01753 | [PDF](https://arxiv.org/pdf/2602.01753v1)

**作者:** Shenghao Fu `[一作]` (Sun Yat-sen University), Wei-Shi Zheng `[通讯]` (Peng Cheng Laboratory)

**通讯引用:** 21676 | [OpenAlex ID](https://openalex.org/A5108050904)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 ObjEmbed，一种基于大规模多模态语言模型的对象嵌入框架，能够一次性生成每个检测框的语义嵌入和 IoU 嵌入，并支持全球图像嵌入，实现对象检测、指代表达理解、局部和全局图像检索等多任务。

**💡 创新点**

创新点：
1) 对每个对象采用双 token（语义 + IoU）分离学习，兼顾语义匹配与定位质量；
2) 通过特殊指令“Object i: ⟨object⟩⟨iou⟩”在单个 forward pass 内并行编码 100+ 对象；
3) 结合区域级对比学习、全局对比学习和 IoU 回归，形成统一训练目标；
4) 在同一 LLM（Qwen3‑VL‑Instruct）上实现文本-视觉双向对齐，提升多模态通用性。

**🔧 技术方法**

技术：
- 大规模多模态语言模型 Qwen3‑VL‑Instruct 作为主干；
- 采用 WeDetect‑Uni 生成 100 个候选框；
- 使用特殊 token（⟨object⟩、⟨iou⟩、⟨global⟩、⟨local_text⟩、⟨global_text⟩）与序列模板；
- 训练目标：区域对比（focal loss）、全局对比（focal loss）、IoU 回归（focal loss）以及可选框回归；
- 高效实现：单通道前向，FlashAttention‑2 加速；

**📊 数据集**

数据集：
- 训练：1.3M 张图片，8.1M 框，来源于 COCO、LVIS、V3Det、RefCOCO/+, FG‑OVD、D3 等公开数据 + 500k 自采合成；
- 评测：COCO、COCO‑O、ODinW13、FG‑OVD、D3（检测）；RefCOCO/+/g（指代表达）；SORCE‑1K、REIRCOCO、ILIAS（局部检索）；COCO、Flickr30K、COCO‑CN、Flickr30K‑CN（全局检索）。

**📈 对比分析**

对比方法与性能：
- 在 COCO 检测上 mAP 53.0%（ObjEmbed‑4B）超过大多数基线（如 CLIP‑VLP、FG‑CLIP、GLIP、LDMDet 等），与专用检测器相当；
- 指代表达平均准确率 89.5% 领先同类 MLLM；
- 局部检索 Recall@1 在 SORCE‑1K/REIRCOCO/ILIAS 上分别 71.7–77.6%/84.0，远超 CLIP‑VLP、FG‑CLIP 等 30–60% 左右；
- 全局检索 Recall@1 在多语言/长/短文本上 97.5–81.7% 与现有 CLIP‑style 模型相近或更优；
- 综上，ObjEmbed 在 18 项多任务上均取得均衡提升。

**⚠️ 局限性**

局限性：
- 性能受候选框召回率限制，缺失对象无法被编码；
- 依赖 WeDetect‑Uni 生成 100 个框，若召回不足需进一步 fine‑tune；
- 仅通过 IoU 回归改进定位，未实现完整框回归，导致定位精度仍不如专用检测器；
- 训练仅两轮，数据规模虽大但对极大模型可能不足；
- 对场景变化、极小目标等极端情况仍有提升空间。

---

## 574. MGKAN: Predicting Asymmetric Drug-Drug Interactions via a Multimodal Graph Kolmogorov-Arnold Network

**arXiv ID:** 2602.01751 | [PDF](https://arxiv.org/pdf/2602.01751v1)

**作者:** Kunyi Fan `[一作]` (Shandong University), Cunquan Qu `[通讯]` (Shandong University)

**通讯引用:** 284 | [OpenAlex ID](https://openalex.org/A5088741789)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了多模态图Kolmogorov-Arnold网络（MGKAN），用于捕捉药物-药物相互作用（DDI）的方向性和非线性特征，融合了异向DDI网络、共交互网络和生化相似网络的视图。

**💡 创新点**

创新点在于：①引入KAN作为可学习基函数，替代传统MLP实现更丰富的非线性与方向感知聚合；②构建三视图多模态融合模块，分别通过注意力线性融合和KAN非线性融合提升表征能力；③针对DDI的方向性任务设计专门的源/目标角色嵌入和双线性解码器。

**🔧 技术方法**

技术包括：Graph Kolmogorov-Arnold Network (GKAN)、B-spline 基函数、方向感知消息传递、注意力线性融合、KAN非线性融合、双线性解码与二元交叉熵损失。

**📊 数据集**

使用DrugBank公开的两个基准数据集 DS 1 与 DS 2（含异向与对称DDI），采用 8:1:1 随机链路拆分和五折交叉验证。

**📈 对比分析**

与七种主流基线（包括VGAE、DiGAE、DirGNN、MAVGAE、DRGATAN、DGAT-DDI等）比较，MGKAN 在 AUROC、AUPRC、ACC、F1 上均取得最高分（如 AUROC 99.08%、AUPRC 98.94%），并保持竞争性训练效率。

**⚠️ 局限性**

局限性包括：①模型复杂度较高，训练时间比纯图模型更长；②目前仅处理单一关系类型的DDI，尚未扩展到多关系预测；③对超参数（如基函数数目、嵌入维度）的敏感性需要进一步研究。

---

## 575. OFERA: Blendshape-driven 3D Gaussian Control for Occluded Facial Expression to Realistic Avatars in VR

**arXiv ID:** 2602.01748 | [PDF](https://arxiv.org/pdf/2602.01748v1)

**作者:** Seokhwan Yang `[一作]` (Korea Advanced Institute of Science and Technology), Woontack Woo `[通讯]` (Korea Advanced Institute of Science and Technology)

**通讯引用:** 5170 | [OpenAlex ID](https://openalex.org/A5023177829)

**关键词:** `8963991b-619b-4c55-be0c-2d0b5f401564` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

开发了 OFERA，一个实时系统，可将 VR 头显提供的遮挡面部表情 blendshape 信号转换为 photorealistic 3D 高斯头部 avatar，并在 VR 环境中即时渲染。

**💡 创新点**

创新点包括：1) Blendshape Distribution Alignment (BDA) 使不同头显的 blendshape 统一到模型可识别的分布；2) 基于 MLP 的 Expression Parameter Mapper (EPM) 把 blendshape 映射到 FLAME 表情参数，实现非线性、高精度表情控制；3) Mapper-integrated Avatar (MiA) 将 EPM 输出融入 Avatar 训练，消除训练与推理分布不匹配；4) 端到端低延迟（≈20 ms）双目渲染方案。

**🔧 技术方法**

技术方法包括：面部 Blendshape 采集、线性回归校准 (BDA)、多层感知机 (EPM)、FLAME 表情参数空间、Gaussian Splatting 头部渲染、Unity-Python 低开销通信。

**📊 数据集**

使用的训练/评估数据集：INSTA、NeRSemble、Ava-256（共30名受试者），以及通过 AvatarTurner 与 Meta Quest Pro 生成的伪配对 BS_VR–B̃S̃_MP 数据；用户研究采用 Meta Quest Pro 头显，20 名受试者。

**📈 对比分析**

与基准矩阵映射和岭回归映射相比，EPM 在参数空间误差下降 0.505 vs 1.038（矩阵）/0.573（线性），在顶点误差下降 1.593 mm vs 2.826/1.848 mm；在用户研究中，OFERA 在虚拟体现、身体认同、可观测性和动画真实性量表上显著优于所有基准，表现出较高的自然度和可控性。

**⚠️ 局限性**

局限性包括：仅依赖头显提供的 blendshape，限制了表情细腻度；不同头显 blendshape 语义与幅度差异仍可能残留；Gaussian avatar 后端对动态光照和外观变化支持有限；伪配对数据可能引入偏差，导致 BDA 与 MiA 效果受限；未来需扩展跨设备校准、增强微表情捕捉与动态外观能力。

---

## 576. From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models

**arXiv ID:** 2602.01811 | [PDF](https://arxiv.org/pdf/2602.01811v1)

**作者:** Wentao Zhang `[一作]`, Jianzong Wang `[通讯]` (Ping An Technology)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了VLA‑SCT框架，在现有VLA模型基础上加入自校正控制循环和任务终止检测，提升抓取精度与任务完成识别。

**💡 创新点**

创新点包括：①轻量级、无训练的自校正模块；②基于轨迹评估的动态抓取扰动；③基于视觉特征匹配的非参数终止判定，三者组合显著提升鲁棒性。

**🔧 技术方法**

采用轨迹效率/姿态稳定/平滑评估；局部加权矩估计（LWME）构造动作分布并生成扰动；RBF核相似度与协方差正则化；视觉状态匹配使用Pearson相关系数；全部为推理时的增量模块，无需再训练。

**📊 数据集**

使用LIBERO基准数据集进行评估。

**📈 对比分析**

与OpenVLA、SparseVLM、FastVLM等方法对比，VLA‑SCT在LIBERO四大任务平均成功率达到81.55%（比基线提升6.1%），且速度提升1.12×，实现SOTA表现。

**⚠️ 局限性**

局限性：阈值选择需要权衡，过度校正可能引入不稳定；仅在LIBERO上验证，尚需在更多VLA架构和更广泛场景中进一步测试。

---

## 577. Geometric Analysis of Token Selection in Multi-Head Attention

**arXiv ID:** 2602.01893 | [PDF](https://arxiv.org/pdf/2602.01893v1)

**作者:** Timur Mudarisov `[一作]` (University of Luxembourg), Radu State `[通讯]` (University of Luxembourg)

**通讯引用:** 5234 | [OpenAlex ID](https://openalex.org/A5069228908)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究多头注意力的几何结构，定义基于值状态空间的精度、召回与 F‑score，并在不改变机制的前提下将注意力视为一个选择式分类器。

**💡 创新点**

提出了从几何视角对多头注意力进行统一建模的框架，给出了在稳定范数、指数相似度衰减和分段权重假设下的非渐近上界和下界，识别出 Retriever、Mixer、Reset 三类头部，并揭示了注意力 sink 对召回的几何影响。

**🔧 技术方法**

使用软最大化注意力、值状态投影、球面几何、指数相似度模型、分段权重模型以及经典分类指标的几何映射，并辅以大规模语言模型的实证验证。

**📊 数据集**

在 LLaMA‑2‑27B、Gemma‑7B、Mistral‑7B 以及 OpenWebText 数据集上进行实验，评估注意力的精度/召回与头部稀疏化策略。

**📈 对比分析**

通过与理论界限比较，发现小 N（1–4）时可实现最优分离；对头部稀疏化的“类型指导”方法在所有模型中优于随机删除，但与单指标（如权重大小、熵、sink/最后标记）相比不一定最优；对 sink 相似度与召回的相关性在不同模型和 N 区间表现一致。

**⚠️ 局限性**

假设较强（如相似度指数衰减、分段权重），对实际模型的可迁移性有限；缺乏对低维或不同架构模型的泛化评估；并未给出完整的稀疏化算法或训练干预方案，仍需进一步验证。

---

## 578. Path Tracking with Dynamic Control Point Blending for Autonomous Vehicles: An Experimental Study

**arXiv ID:** 2602.01892 | [PDF](https://arxiv.org/pdf/2602.01892v1)

**作者:** Alexandre Lombard `[一作]` (University of Technology of Belfort-Montbeliard), Abdeljalil Abbas-Turki `[通讯]` (University of Technology of Belfort-Montbeliard)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出一种基于前后轴混合控制点的自适应路径跟踪框架，将横向控制命令在车辆轴距上动态插值，实现前轴斯坦利控制与后轴曲率几何控制的平滑融合，并配合基于虚拟边界与射线追踪的曲率感知纵向控制；

**💡 创新点**

创新点在于：①采用贝塞尔加权方式实现前后轴控制命令的连续混合，可在任何驾驶情境下动态选择有效控制点；②引入虚拟边界射线法将路径几何约束转化为虚拟障碍距离，实现对曲率变化的前瞻性速度调节；

**🔧 技术方法**

主要技术包括：kinematic bicycle 模型、Stanley 纵向控制、后轴曲率几何控制、贝塞尔加权混合、虚拟边界与射线追踪、IDM 纵向控制；

**📊 数据集**

实验数据集为缩放版Nürburgring赛道的模拟轨迹以及真实闭环赛道上的 GPS‑RTK、雷达、里程计和 IMU 传感器收集的车辆轨迹；

**📈 对比分析**

与传统 Pure‑Pursuit、Stanley 控制进行比较，横向误差显著降低（后向操纵误差下降 80% 以上），轨迹跟踪更精准、转向更平滑；

**⚠️ 局限性**

局限性包括：缺乏正式的稳定性分析；实验主要在低速与非全动态模型下进行，未验证在高速度或复杂路况下的鲁棒性；

---

## 579. ProxyImg: Towards Highly-Controllable Image Representation via Hierarchical Disentangled Proxy Embedding

**arXiv ID:** 2602.01881 | [PDF](https://arxiv.org/pdf/2602.01881v1)

**作者:** Ye Chen `[一作]` (Shanghai Jiao Tong University), Bingbing Ni `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 13669 | [OpenAlex ID](https://openalex.org/A5014362734)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `729e5870-4135-47f5-97f2-e3974d07b5dc` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `f86bf285-fd08-4156-973b-6e6481af8fa0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了 ProxyImg，一种层级代理嵌入的图像表示方法，能够高效重建任何图像，并支持精细几何、纹理编辑以及物理驱动的动画生成。

**💡 创新点**

创新点在于：① 将图像按语义实例拆分并通过自适应 Bézier 曲线与多尺度内部代理节点构建层级几何；② 纹理在共享低分辨率特征格上分布式编码，实现纹理与几何完全解耦且参数量极低；③ 结合 Score Distillation Sampling 与 Position‑Based Dynamics 实现可控纹理编辑与动画。

**🔧 技术方法**

使用的技术包括：SAM + Depth Anything 进行语义分割与深度排序，Triwild 三角网格细化，Bezier 曲线拟合，逆距离加权与重心坐标插值的分布式纹理编码，轻量 MLP 作为坐标‑RGB 解码器，Score Distillation Sampling（SDS）进行生成纹理编辑，以及 Position‑Based Dynamics（PBD）实现物理驱动动画。

**📊 数据集**

实验数据集包括 ImageNet、DIV2K、OIR‑Bench、HumanEdit 等公开数据集。

**📈 对比分析**

与现有显式向量、Gaussian、SIREN、LIIF 等方法以及商业模型对比，ProxyImg 在重建质量（PSNR/LPIPS/SSIM）上保持领先，同时参数量更少；在几何、纹理编辑任务上获得更高精度和更好可控性；动画生成方面，表现出更优的时序一致性和物理真实性，显著优于基于生成模型的方法。

**⚠️ 局限性**

主要局限在于：① 需要先完成语义分割与网格构造，流程对极端纹理细节或复杂非平面结构的适配仍有改进空间；② 对纹理细节的表示受代理节点数量限制，过于细腻纹理仍可能出现失真。

---

## 580. Tidehunter: Large-Value Storage With Minimal Data Relocation

**arXiv ID:** 2602.01873 | [PDF](https://arxiv.org/pdf/2602.01873v1)

**作者:** Andrey Chursin `[一作]` (Mysten Labs), Igor Zablotchi `[通讯]` (Mysten Labs)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并实现了一种名为TideHunter的键值存储引擎，利用WAL作为永久值存储，消除值的压缩。

**💡 创新点**

将写前日志直接作为持久化值存储，采用延迟刷新索引和乐观索引，使用epoch驱动的垃圾回收实现无阻塞写入。

**🔧 技术方法**

append‑only WAL、内存映射 I/O、懒刷写的分区索引、乐观定位索引、无锁写分配、后台fsync、epoch‑based relocator、Bloom 过滤、LRU 缓存等技术。

**📊 数据集**

在1 TB随机键值数据集（键32 B，值64/128/1024 B）上进行基准测试，并在Sui区块链验证者节点上部署真实工作负载。

**📈 对比分析**

与 RocksDB 与 BlobDB 在写/读/存在查询（50/50、全写、全读）基准中比较，TideHunter 在1 KB值下写吞吐量提升8.4×、点查询1.7×、存在检查15.6×；在小值时略逊；在Sui生产环境下保持稳定吞吐与低延迟。

**⚠️ 局限性**

对键分布不均或极小值（≤128 B）效率下降；epoch GC 仍需，且对高写放大情况有一定影响；缺乏对多级范围查询的高效支持。

---

## 581. Grappa: Gradient-Only Communication for Scalable Graph Neural Network Training

**arXiv ID:** 2602.01872 | [PDF](https://arxiv.org/pdf/2602.01872v1)

**作者:** Chongyang Xu `[一作]` (Max Planck Institute for Software Systems), Laurent Bindschaedler `[通讯]` (Max Planck Institute for Software Systems)

**通讯引用:** 357 | [OpenAlex ID](https://openalex.org/A5051818971)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出一种分布式 GNN 训练框架 GNN-GradOnly，通过在每个迭代中仅通信梯度、孤立训练并动态重划分来消除跨分区邻居通信。

**💡 创新点**

创新点包括：梯度仅通信消除跨分区特征/激活传输；超周期重划分与批量级覆盖校正实现无偏训练；阶段并行训练支持单机亿级图。

**🔧 技术方法**

技术手段包括随机/METIS 分区、滑动块划分、重要性加权批量级梯度校正、梯度归一化收敛、PyTorch+DGL 实现。

**📊 数据集**

使用数据集：OGBN‑Arxiv、Reddit、OGBN‑Products、OGBN‑Papers100M、RMAT‑26/30/36 以及其合成数据。

**📈 对比分析**

与 DGL、MGG、Cluster‑GCN 等基线在同一硬件、相同超参数下比较；在 16 分区下平均 4×、最高 13× 的训练加速；对更深模型精度更好；能在单机 1 V100 上训练 1.1 trillion 边的 RMAT‑36。

**⚠️ 局限性**

局限性包括：重划分时需额外 I/O；梯度校正依赖节点度估计；不支持动态变化图或显式稀疏更新；在极小图上分区开销占比高。

---

## 582. SOPRAG: Multi-view Graph Experts Retrieval for Industrial Standard Operating Procedures

**arXiv ID:** 2602.01858 | [PDF](https://arxiv.org/pdf/2602.01858v1)

**作者:** Liangtao Lin `[一作]` (Nanyang Technological University), Yonggang Wen `[通讯]` (Nanyang Technological University)

**通讯引用:** 18682 | [OpenAlex ID](https://openalex.org/A5041572550)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `afceb026-1760-41ae-8d86-010831a37d97` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种面向工业操作手册（SOP）检索的混合专家（MoE）框架，通过层级化的 Procedure Card、实体图、因果图、流程图以及 LLM 引导的路由实现精准检索与可执行响应。

**💡 创新点**

创新点包括：1）用 Procedure Card 层进行稀疏激活，显著降低搜索噪声；2）构建三种专用图专家（实体、因果、流程）精准映射 SOP 的层级、条件逻辑与步骤顺序；3）LLM‑指导的动态路由根据查询意图自动加权专家；4) 通过多智能体自动化流程生成四领域 SOP 基准数据集。

**🔧 技术方法**

核心技术包括：Mixture‑of‑Experts 框架、图结构检索（实体图、因果图、流程图）、LLM 路由器（意图识别）、生成时基于流程图的结构化提示、以及基于 LLM 的自动化数据构建代理（Collector、Archivist、Auditor、Examiner）。

**📊 数据集**

使用了四个工业领域的 SOP 数据集（Data Center、Liquid Cooling、Building Management、Airline Services），共 800 条 SOP 文档与 1000 条检索查询，构建了面向工业检索的基准。

**📈 对比分析**

与 BM25、OpenAI Embed、GraphRAG、LightRAG、HippoRAG 等基线对比，平均 MRR 达到 0.76、Acc@5 达到 0.93（Airline Services），在检索准确率和生成可执行度（SOP Quality Score）上均显著优于所有基线。

**⚠️ 局限性**

局限性：1）目前仅处理基于 Markdown 的文本，未纳入图表、图示等多模态信息；2）实体/因果/流程图的质量高度依赖构建阶段 LLM 的推理能力，需进一步验证小模型的效果；3）自动生成的查询为 LLM 合成，缺乏真实专家手工验证，可能与现场操作需求有差距。

---

## 583. Preservation Theorems for Unravelling-Invariant Classes: A Uniform Approach for Modal Logics and Graph Neural Networks

**arXiv ID:** 2602.01856 | [PDF](https://arxiv.org/pdf/2602.01856v1)

**作者:** Przemysław Andrzej Wałęga `[一作]` (Queen Mary University of London), Bernardo Cuenca Grau `[通讯]` (University of Oxford)

**通讯引用:** 9472 | [OpenAlex ID](https://openalex.org/A5023732514)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文通过研究有限结构中保留定理，阐明了在满足“有界展开”性质的指针Kripke模型上，三类语义关系（嵌入、单射同态、同态）与模态逻辑片段（存在性格蕾达模态、存在性正片段、存在性正模态）之间的精确对应关系；

**💡 创新点**

创新点在于提出一种统一的无穷序（well‑quasi‑ordering）技术，对高树形模型的嵌入、单射同态、同态三者在高度受限的情况下构成WQO，从而得到极小模型的有限性，并利用该结果给出模态逻辑和图神经网络的完整保留定理；

**🔧 技术方法**

核心技术包括：1）对树形Kripke模型高度受限的嵌入/同态关系构造WQO；2）利用未展开不变性与最小模型论证构造有限判定公式；3）在图神经网络框架下，将上述理论映射到指针图，实现对单调GNN和单调-MAX GNN 的表达能力表征；

**📊 数据集**

无实验数据集，本文为理论分析与定理证明工作；

**📈 对比分析**

无实验比较与性能评估，主要通过逻辑等价性与保留性质的理论证明完成；

**⚠️ 局限性**

局限性在于：1）仅覆盖无循环（树形）或高度受限模型；2）未处理包含命名符号、全局模态或固定点等扩展；3）对更复杂的GNN结构（如注意力、归一化、层次传递）缺乏直接分析方法。

---

## 584. WS-IMUBench: Can Weakly Supervised Methods from Audio, Image, and Video Be Adapted for IMU-based Temporal Action Localization?

**arXiv ID:** 2602.01850 | [PDF](https://arxiv.org/pdf/2602.01850v1)

**作者:** Pei Li `[一作]` (Xi'an Jiaotong University), Fei Wang `[通讯]` (Xi'an Jiaotong University)

**通讯引用:** 80425 | [OpenAlex ID](https://openalex.org/A5070372567)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `e0540dec-d77f-42db-94ae-d039248f6393` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `9ce7179e-700c-4310-ac2b-91df50ded46e` `5a41884c-404f-4688-a89c-aa238c10fe68` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

对IMU（惯性测量单元）时序动作定位的弱监督学习进行了系统性基准研究，评估了从音频、图像和视频迁移过来的弱监督方法。

**💡 创新点**

提出了完整的基准框架、统一的评估协议和可复现的实验模板，并通过大规模实验揭示了弱监督迁移的可行性、优势与局限，给出了针对IMU的改进方向。

**🔧 技术方法**

采用多实例学习（MIL）、注意力聚合、基于候选片段的定位、对比学习与时序传播等技术，将WSSED、WSOD、WSVAL等经典方法迁移到IMU流上。

**📊 数据集**

使用七个公开IMU数据集：SBHAR、Opportunity、WetLab、Hang‑Time、RWHAR、WEAR 和 XRFV2。

**📈 对比分析**

与三种全监督TAL基线（ActionFormer、TemporalMaxer、TriDet）进行对比；弱监督模型在长动作且传感器维度高的数据集（RWHAR、WEAR）能达到约60‑65% mAP，落后于全监督模型，但在短动作或低维数据集上表现显著下降；总体上弱监督方法对不同数据集的迁移效果呈现模态依赖性。

**⚠️ 局限性**

主要局限包括：1）候选片段生成依赖随机、内容无关的采样，导致局部精度受限；2）对短动作、时间歧义和低维传感器易失效；3）迁移性受模态影响，音频/视频方法在IMU上不一定稳定；4）缺乏统一的大规模IMU预训练基础，模型对受试者差异敏感；5）模型规模与性能无显著正相关，需更具针对性的设计。

---

## 585. SPIRIT: Adapting Vision Foundation Models for Unified Single- and Multi-Frame Infrared Small Target Detection

**arXiv ID:** 2602.01843 | [PDF](https://arxiv.org/pdf/2602.01843v1)

**作者:** Qian Xu `[一作]` (Xidian University), Mingjin Zhang `[通讯]` (Xidian University)

**通讯引用:** 2607 | [OpenAlex ID](https://openalex.org/A5101464703)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `aaccfe5c-6b26-4208-b23c-35331481e142` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种统一框架 SPIRIT，能够同时处理红外小目标的单帧检测与视频追踪，兼容现有的 Vision Foundation Models。

**💡 创新点**

创新点在于引入两种轻量化物理驱动插件：PIFR（Physics‑Informed Feature Refinement）通过近似秩稀疏分解消除特征沉没；PGMA（Prior‑Guided Memory Attention）通过可微可行性场约束记忆注意力，解决外观模糊导致的错误关联。

**🔧 技术方法**

使用的技术包括：rank‑sparsity 近似分解、ridge 投影、分组收缩、残差门控、可微可行性场生成、记忆交叉注意力与可学习的偏置。

**📊 数据集**

实验数据集涵盖单帧：NUAA‑SIRST、NUDT‑SIRST、IRSTD‑1k；多帧：IRDST、IRSTD‑15k。

**📈 对比分析**

与多种基线（如 ISNet、DNANet、TDCNet 等）对比，SPIRIT 在 AP50、F1、Precision、Recall 等指标上均实现显著提升，单帧最高 AP≈94.6%，多帧 AP≈96.24，帧率约 32 FPS。

**⚠️ 局限性**

主要局限在于对极长记忆窗口或动态背景的鲁棒性有限；物理先验参数需针对不同环境进一步调优以保证普适性。

---

## 586. Multi-party Computation Protocols for Post-Market Fairness Monitoring in Algorithmic Hiring: From Legal Requirements to Computational Designs

**arXiv ID:** 2602.01837 | [PDF](https://arxiv.org/pdf/2602.01837v1)

**作者:** Changyang He `[一作]` (Harbin Institute of Technology), Asia Biega `[通讯]`

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `9cc9baba-5356-466d-81ff-d80028d90279` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

开发了基于多方安全计算（MPC）的后市公平性监测协议，并通过法律、工业和技术三方共同设计，将协议落地到大规模工业招聘平台上，形成了端到端的数据收集、加密、计算和可视化的完整体系；

**💡 创新点**

创新点在于：①采用三方协同的共设计方法，将欧盟AI法、GDPR与企业实际需求融入协议设计；②提出了从数据收集（TTP收集并分片）到安全两方计算、再到后处理与仪表盘展示的完整工作流；③在合规与可用性方面做了交叉评估，提供可解释的阈值设定与可视化；

**🔧 技术方法**

核心技术包括：多方安全计算（secret sharing、两方安全加密计算）、安全等价测试、数据加密与脱敏、ETL管道、Tableau可视化仪表盘；

**📊 数据集**

使用了工业招聘平台的真实生产数据：非敏感申请信息（简历、评分、筛选进度）、可选的年龄与性别信息（不属于特殊类别），并在实验中模拟了TTP和密钥共享过程；

**📈 对比分析**

通过在实际平台上部署仪表盘并每日监测，验证了协议的可操作性。虽然文中未给出具体运行时基准，但说明协议在两方计算和后处理阶段均保持轻量级，能够实时生成可视化结果；

**⚠️ 局限性**

局限性包括：①只能使用可选的年龄/性别，缺乏对受保护属性的完整覆盖；②阈值与警报设置依赖法律与经验，难以实现自动化；③对不同工作岗位和行业的通用基准缺乏；④对解释性与多维交叉公平性的阈值仍需进一步研究；

---

## 587. Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It

**arXiv ID:** 2602.01826 | [PDF](https://arxiv.org/pdf/2602.01826v1)

**作者:** Yaxiang Zhang `[一作]` (National University of Singapore), Haoyuan Li `[通讯]` (University of Science and Technology of China)

**通讯引用:** 5676 | [OpenAlex ID](https://openalex.org/A5100418229)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文针对大语言模型 RL 微调中频繁出现的训练‑推理不匹配问题，提出了一种基于响应长度波动的自适应学习率调度方法，能够在训练过程中及时降低学习率，从而稳定训练并抑制数值误差。

**💡 创新点**

创新点在于：①将训练‑推理不匹配视为与梯度噪声共同增长的动态失效模式，而非静态数值误差；②设计了一种“响应长度激增”作为早期预警信号，实现了对学习率的实时响应式衰减；③证明响应长度平方可上界梯度误差，奠定了方法的理论基础。

**🔧 技术方法**

使用技术包括：大语言模型 RL 微调框架（VeRL）、梯度噪声与梯度范数分析、log‑perplexity 匹配指标、传统与改进的 Importance Sampling（Token‑level TIS/MIS）以及自适应学习率调度算法。

**📊 数据集**

实验数据集为约 13k 条样本的 Filtered DAPO 数据集，模型为 Qwen3 Base 系列（4B 与 8B）。

**📈 对比分析**

对比方法有：恒定学习率（baseline）、传统基于 epoch 的学习率衰减、以及多种 IS 补丁。实验结果表明，使用自适应学习率调度后训练过程不再崩溃，验证准确率提升 5–10% 左右，梯度范数和 log‑ppl 匹配指标保持在安全范围内。

**⚠️ 局限性**

局限性包括：①需要人工设定响应长度激增的时间窗与衰减周期，可能对不同模型/任务不够通用；②对极短或极长生成序列的适应性尚未充分验证；③该方法仍与硬件浮点精度相关，未完全消除所有数值误差；④在大规模多任务微调或分布式设置下的可扩展性仍需进一步评估。

---

## 588. Risk, Data, Alignment: Making Credit Scoring Work in Kenya

**arXiv ID:** 2602.01824 | [PDF](https://arxiv.org/pdf/2602.01824v1)

**作者:** Daniel Mwesigwa `[一作]` (Cornell University), Christopher Csikszentmihalyi `[通讯]` (Cornell University)

**通讯引用:** 181 | [OpenAlex ID](https://openalex.org/A5039921830)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a2602d71-93ab-4bad-974b-672788df8193` `3855fcda-48ef-4070-a15e-803cd5c84d83` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

通过为期九个月的田野调查和深度访谈，作者对内罗毕数字借贷领域的数据科学实践、风险构建与模型调整进行了系统研究。

**💡 创新点**

提出将“alignment”视为双向翻译机制，阐释算法与社会世界如何相互塑造，并强调“替代数据”在风险表征中的可表演性。

**🔧 技术方法**

利用短信抓取、SDK、API等技术手段采集并清洗非传统数据，再以机器学习（如逻辑回归、XGBoost）构建信用评分模型。

**📊 数据集**

使用超过8万条样本、260+特征的肯尼亚信用评分数据集，并结合M‑Pesa短信日志、SIM卡信息等辅助数据。

**📈 对比分析**

新开发的Extenscore模型在内部测试中Gini系数提升至约0.8，理论上预测准确率高于行业基准；但实际运营中违约率仍高达30%，显示性能与真实世界之间存在落差。

**⚠️ 局限性**

研究局限在于数据获取的法律与技术灰区、模型对动态行为的适应不足、偏见与不确定性难以完全消除，以及高违约率凸显监管与文化适配挑战。

---

## 589. Speaking Without Sound: Multi-speaker Silent Speech Voicing with Facial Inputs Only

**arXiv ID:** 2602.01879 | [PDF](https://arxiv.org/pdf/2602.01879v1)

**作者:** Jaejun Lee `[一作]` (Seoul National University), Kyogu Lee `[通讯]` (Seoul National University)

**通讯引用:** 1941 | [OpenAlex ID](https://openalex.org/A5088852010)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种仅基于面部图像与无声EMG信号的多说话人语音生成框架，能够在没有任何可听输入的情况下合成符合目标说话人声线的语音。

**💡 创新点**

创新点包括：① 仅用面部输入实现多说话人语音生成；② 引入 pitch‑flattening 模块剥离内容语音中的音高信息，提升无声EMG生成质量；③ 设计新的 Local F0 偏差评价指标用于衡量内容相关音高的生成效果。

**🔧 技术方法**

技术方案基于条件 VAE 结构，使用面部声码器网络、EMG Transformer 编码器、预训练的 ContentVec 语义编码器、HiFi‑GAN 解码器和 FCPE F0 估计器，并通过 DTW 对齐实现无声 EMG 与语音的对应。

**📊 数据集**

数据集包括 Gaddy 的单说话人 EMG 语料（含声唤和无声 EMG）以及 LRS3 视频音频数据集（用于训练面部声码器、全局音高估计与评价）。

**📈 对比分析**

通过与基线（无 pitch‑flattening）模型对比，使用 ASR WER/CER、Resemblyzer 说话人相似度、主观 MOS、Local/Global F0 偏差等指标评估。实验显示，Flatten 模型在无声 EMG 上 WER 明显下降、说话人一致性提升、Local F0 偏差更低，验证了 pitch‑flattening 的有效性。

**⚠️ 局限性**

局限性：EMG 数据仅来自单一说话人，导致内容相关音高信息有限；声码器在低质量真实环境数据上训练，语音质量受限；未使用预训练的高质量 vocoder 或扩散后处理；pitch‑flattening 采用传统信号处理，可能不如最新的音高控制方法稳定。

---

## 590. Autocorrelated Optimize-via-Estimate: Predict-then-Optimize versus Finite-sample Optimal

**arXiv ID:** 2602.01877 | [PDF](https://arxiv.org/pdf/2602.01877v1)

**作者:** Zichun Wang `[一作]` (Hong Kong University of Science and Technology), Ruiting Zuo `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 14 | [OpenAlex ID](https://openalex.org/A5025863954)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出并验证了一种针对向量自回归滑动平均（VARMA）过程的自相关优化-估计（A-OVE）模型，用于在考虑交易成本的投资组合优化中直接优化有限样本下的离样本性能。

**💡 创新点**

创新点在于：①首次为VARMA过程推导出充分统计量的Fisher–Neyman分解；②在此基础上给出A-OVE的闭式解并实现递归求解；③在与传统预测-优化（PTO）与估计-优化（ETO）方法比较时，展示了离样本优化在误差、稳健性与计算效率方面的显著优势。

**🔧 技术方法**

主要技术包括：VARMA(p,q)时间序列建模、充分统计量与最大似然估计、离样本优化（OVE）框架、Monte Carlo估计先验积分、基于权重的FPtP方法、以及对投资组合收益与交易成本的二次型约束求解。

**📊 数据集**

数据集涵盖：①仿真数据（VARMA(1,1)与高阶VARMA过程）以检验模型在规范与误配情形下的性能；②真实世界股票交易量数据（World Stock Prices）中的四支股票（GOOGL、HMC、AXP、BAMXF）以评估模型在实际金融环境中的有效性。

**📈 对比分析**

与PTO（如RNN、LSTM、RF、XGBoost）、ETO（含FPtP）以及参数化VARMA估计等基准相比，A-OVE在两类实验中均取得最低的相对后悔率（regret）且波动最小，且对小幅模型误配仍保持较高鲁棒性；同时保持了可接受的计算时间。

**⚠️ 局限性**

主要局限包括：①对VARMA结构的强假设，导致在大幅误配时性能下降；②仅在二次型交易成本模型下验证，尚未检验对非线性成本或更复杂约束的适用性；③当前实现为无情境（context‑free）版本，缺乏对预测特征的直接利用，未来可进一步扩展为情境化OVE。

---

## 591. PretrainRL: Alleviating Factuality Hallucination of Large Language Models at the Beginning

**arXiv ID:** 2602.01875 | [PDF](https://arxiv.org/pdf/2602.01875v1)

**作者:** Langming Liu `[一作]` (Future Living Lab of Alibaba), Bo Zheng `[通讯]` (Future Living Lab of Alibaba)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过在预训练阶段引入强化学习，提出 PretrainRL 框架，旨在通过去偏后学习的方式整合事实知识，减少大型语言模型的事实性幻觉。

**💡 创新点**

创新点在于：①将去偏（down‑weight 高概率错误）与学习（up‑weight 低概率真相）结合的“debiasing‑then‑learning”原则；②设计高效的负采样策略，利用 beam search 自动挖掘模型内在的高概率错误；③在预训练阶段直接采用 DPO 进行概率重塑，而非传统的后训练或知识编辑。

**🔧 技术方法**

主要技术包括：下一词预测（NTP）与直接偏好优化（DPO）联合损失；Beam search 采样产生负样本；概率重塑与 NLL 损失的加权组合；以及自定义的 Hit Ratio、MRR、Prob 等评估指标。

**📊 数据集**

实验数据集涵盖 POPQA、Wikidata‑Knowledge‑Infusion 与 EntityQuestions，均为长尾事实分布数据，用以评估模型在事实记忆与推理上的表现。

**📈 对比分析**

与 CoT、DPO、持续训练 (CT)、迭代 RPO 以及多款闭源 LLM（Qwen3‑4B/7B/14B、Llama3‑8B）对比，PretrainRL 在 ACC、HR、MRR、Prob 上均有显著提升，尤其在长尾知识上表现更优，且模型规模增大时效果进一步放大。

**⚠️ 局限性**

局限性在于负采样方法依赖数据集的类别划分；若数据集缺乏明显类别区分，采样可能失效，需替代方案（如 RLVR）来保持鲁棒性。

---

## 592. Trust but Verify: Adaptive Conditioning for Reference-Based Diffusion Super-Resolution via Implicit Reference Correlation Modeling

**arXiv ID:** 2602.01864 | [PDF](https://arxiv.org/pdf/2602.01864v1)

**作者:** Yuan Wang `[一作]` (Nankai University), Peng-Tao Jiang `[通讯]` (vivo Mobile Communication Co., Ltd.)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出单步参考增强的超分框架 Ada-RefSR，结合参考图像对低质量图像进行细节恢复。

**💡 创新点**

创新点在于“Trust‑but‑Verify”机制，提出 Adaptive Implicit Correlation Gating (AICG)，通过少量可学习的 summary tokens 隐式建模 LQ–Ref 相关性，实现对参考贡献的动态门控，既防止过度引用也避免语义错误。

**🔧 技术方法**

采用扩散式超分基础，单步 Stable Diffusion 先验，参考注意力 (Reference Attention) 注入细节，并在此基础上加入 AICG；训练中使用自监督损失、感知损失与 GAN 损失。

**📊 数据集**

训练数据包括 DIV2K、DIV8K、Flickr2K、面部专用 HQ–Ref 组合；评估数据为 CUFED5、WRSR、Bird retrieval 以及人脸数据集。

**📈 对比分析**

与 S3Diff、OSEDiff、PISA‑SR、Real‑ESRGAN、SeeSR+ReFIR、SUPIR+ReFIR、DMDNet、CodeFormer、InstantRestore 等方法对比，Ada‑RefSR 在 PSNR/SSIM/FID/LPIPS 等参考指标上均优于现有 RefSR 方法，且在无参考指标上保持竞争力；在速度上比多步 RefSR 快约 30 倍。

**⚠️ 局限性**

局限性包括模型参数量较大、单张参考限制、对极端不匹配参考仍有一定误差；且依赖大规模预训练扩散模型，训练与推理算力需求较高。

---

## 593. FUPareto: Bridging the Forgetting-Utility Gap in Federated Unlearning via Pareto Augmented Optimization

**arXiv ID:** 2602.01852 | [PDF](https://arxiv.org/pdf/2602.01852v1)

**作者:** Zeyan Wang `[一作]`, Jing Qiu `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究了一种在联邦学习环境下的忘记机制，提出了 FUPareto 框架来实现高效且可并行的客户端忘记。

**💡 创新点**

创新点在于使用 MBS 损失与 Pareto 增广优化相结合，通过梯度零空间投影和公平引导实现了在不牺牲模型性能的前提下彻底抹除指定数据。

**🔧 技术方法**

采用了 MBS（Minimum Boundary Shift）无界损失、MGDA 多目标梯度下降、零空间梯度投影、Pareto 改进/扩展以及锚点约束恢复等技术。

**📊 数据集**

在 FMNIST、CIFAR-10/100、GTSRB 等图像分类数据集上进行实验。

**📈 对比分析**

与 Retraining、FedEraser、FedEditor、MoDe、FedAU、FUGAS、FedOSD 等基线对比，FUPareto 在 ASR 低、R-Acc 高、MIA AUC 接近 0.5 方面均明显优于现有方法。

**⚠️ 局限性**

主要局限在于梯度投影与 Pareto 扩展的超参数需要手动调节，对非图像任务与更大规模系统的通用性尚待验证。

---

## 594. DOGMA: Weaving Structural Information into Data-centric Single-cell Transcriptomics Analysis

**arXiv ID:** 2602.01839 | [PDF](https://arxiv.org/pdf/2602.01839v1)

**作者:** Ru Zhang `[一作]` (Beijing Institute of Technology), Jia Li `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 15013 | [OpenAlex ID](https://openalex.org/A5108050433)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `3f18e8e3-0266-457c-8567-9039b6d2394d` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了基于知识的结构化单细胞转录组分析框架 DOGMA，利用多层生物学先验（基因本体、细胞本体、进化树）对原始数据进行去噪和构图，形成高质量的细胞图谱；

**💡 创新点**

创新点在于把数据结构视为可改造对象，通过确定性本体驱动的图构造与语义融合，摆脱传统统计启发式、噪声驱动的图形和大模型参数扩张，显著提升跨物种、跨组织的零样本泛化与数据稀缺场景下的表现；

**🔧 技术方法**

技术包括：数据预处理与质量控制、MNN 统计对齐、细胞本体筛选的 Top‑K 过滤、进化树层级限制、基因本体功能聚类增强双视图表征（统计 PCA + GO 语义），以及 GCN/GAT 图神经网络的下游学习；

**📊 数据集**

使用多维度基准集：脑部跨物种、人体多器官、跨物种多器官三大层级，涵盖数十万细胞与数千基因，构建统一的知识驱动图谱；

**📈 对比分析**

与 k‑NN、MNN、scMoGNN、scPriorGraph、scGPT 等方法对比，DOGMA 在细胞类型分类、发育阶段识别、元数据注释、零样本识别及聚类指标上均位居榜首，准确率提升约 3–10%，零样本和稀缺数据下性能显著优于对手；并在内存占用与推理时间上比大模型降低 90% 以上；

**⚠️ 局限性**

局限性包括：依赖已构建且完整的细胞/基因本体和进化树，若先验信息不全或错误会影响图构造；对极端稀有细胞或未知细胞类型的预测仍受限；未来需进一步探索自动化本体生成与跨域迁移的鲁棒性。

---

## 595. Zero-Shot Knowledge Base Resizing for Rate-Adaptive Digital Semantic Communication

**arXiv ID:** 2602.01829 | [PDF](https://arxiv.org/pdf/2602.01829v1)

**作者:** Shumin Yao `[一作]` (Pengcheng Laboratory), Xiaodong Xu `[通讯]` (Beijing University of Posts and Telecommunications)

**通讯引用:** 5628 | [OpenAlex ID](https://openalex.org/A5061030501)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `fede83ac-7505-405f-ab37-e7284695c47f` `67630363-6be0-4f51-ab05-7198250671a5` `64443552-63e0-44b5-906f-d90fe95c5a1b` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种零样本知识库缩放方法，使基于 VQ‑VAE 的数字语义通信系统能够在不重新训练的情况下，实时按需调整码本大小，实现灵活的速率自适应。

**💡 创新点**

创新点在于将知识库向量映射到超曲空间（Poincaré 球模型）揭示层级结构，构建最小生成树主语义树，并通过迭代剪除叶节点实现任意码本大小的即时裁剪，保持高重建质量且无需再训练。

**🔧 技术方法**

使用技术包括：超曲空间嵌入与对数/指数映射、最小生成树（Prim 算法）构建层级树、叶节点裁剪策略、SimVQ 语义编码/解码框架以及欧氏空间与超曲空间之间的投影。

**📊 数据集**

实验基于 ImageNet 数据集进行图像语义传输任务。

**📈 对比分析**

与传统为每个码本大小单独训练的基线对比，零样本缩放在 SSIM 上平均误差仅 0.8%，在最低码本大小（K=256）时表现更鲁棒；同时训练成本减少约 9 倍，显著提升效率。

**⚠️ 局限性**

局限性：需要先训练一个极大的父码本（K=262,144）；方法主要面向已完成的向量集合，对在线更新或动态内容适应的处理尚未涉及；在极低码本规模下仍可能出现一定失真。

---

## 596. ChemDCAT-AP: Enabling Semantic Interoperability with a Contextual Extension of DCAT-AP

**arXiv ID:** 2602.01822 | [PDF](https://arxiv.org/pdf/2602.01822v1)

**作者:** Philip Stroemert `[一作]`, Norbert Kockmann `[通讯]` (Leibniz Institute for Catalysis)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

该研究开发了基于DCAT-AP的两层扩展——通用的DCAT-AP+与针对化学与催化的ChemDCAT-AP，实现了更丰富的数据来源、实验条件与本体化的元数据描述，并在NFDI4Chem Search Service中集成了NMR MIChI规范。

**💡 创新点**

创新点在于提出了以PROV-O为核心的可继承性模式DCAT-AP+，通过LinkML实现模块化继承并兼容通用与领域特定需求，从而促进跨域语义互操作与元数据的可扩展性。

**🔧 技术方法**

使用了LinkML框架进行模型设计与代码生成，结合PROV-O、QUDT、CHEMINF等本体，自动生成Python/Pydantic、JSON Schema、SHACL等多种格式，并通过GitHub Actions实现持续集成与验证。

**📊 数据集**

主要利用Chemotion Repository中的实验记录作为实例数据，对NMR MIChI（MARGARITAS）规范进行校验，并在NFDI4Chem Search Service中采集并映射科研数据集。

**📈 对比分析**

通过在CKAN插件中实现ChemDCAT-AP并导出RDF，验证了元数据结构的完整性和查询灵活性；在SPARQL端实现了高级 faceted search，显著提升了数据检索效率，尽管未给出具体定量性能指标。

**⚠️ 局限性**

存在的局限包括LinkML对SHACL生成的IRI命名支持不足、对数据类型 union 的支持有限，以及需要进一步在更广泛社区验证其可采纳性和标准化程度。

---

## 597. Time2Vec-Integrated Transformer for Robust Gesture Recognition from Low-Density sEMG

**arXiv ID:** 2602.01855 | [PDF](https://arxiv.org/pdf/2602.01855v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 598. ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support

**arXiv ID:** 2602.01885 | [PDF](https://arxiv.org/pdf/2602.01885v1)

**作者:** Tiantian Chen `[一作]` (Tongji University), Lin Zhang `[通讯]` (Tongji University)

**通讯引用:** 56299 | [OpenAlex ID](https://openalex.org/A5100351902)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了长期情感支持对话评测框架ES-MemEval，并提出多阶段生成的多会话数据集EvoEmo

**💡 创新点**

首次在情感支持场景下系统评估五项长期记忆能力（信息提取、时序推理、冲突检测、回避、用户建模），并通过问答、摘要、对话三种任务实现全面测评

**🔧 技术方法**

采用检索增强（RAG）+长上下文大模型（Mistral、Phi-3、GPT‑3.5‑turbo、GPT‑4o）和多层检索粒度（轮级、回合级、会话级）

**📊 数据集**

使用自制的18位虚拟用户多会话情感支持数据集EvoEmo（≈13k tokens/会话，平均22.3会话）以及公开的长对话基准（Conversation Chronicles、LongMemEval等）作为对照

**📈 对比分析**

对比无记忆、完整历史、RAG三种配置，在问答、摘要、对话任务中评估F1、BERTScore、LLM‑Judge、ROUGE、事件级指标等，RAG显著提升事实一致性与情感支持得分，GPT‑4o+RAG在所有指标上均优于其它模型，Mistral‑24B+RAG与GPT‑3.5‑turbo+RAG相当

**⚠️ 局限性**

局限性在于时序推理与用户建模仍难以充分体现，检索粒度与排名质量不佳导致冗余信息，长上下文小模型性能随窗口增大急剧下降，且RAG在情感支持方面的提升有限

---

## 599. ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents

**arXiv ID:** 2602.01869 | [PDF](https://arxiv.org/pdf/2602.01869v1)

**作者:** Qirui Mi `[一作]` (Institute of Automation, Chinese Academy of Sciences), Jun Wang `[通讯]` (University College London)

**通讯引用:** 367620 | [OpenAlex ID](https://openalex.org/A5111964102)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a4b10f5d-130b-4e77-9367-6469ec621899` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出 ProcMEM 框架，使 LLM 代理在不更新参数的前提下，通过非参数 PPO 学习可重用的程序化记忆，从而显著降低每次推理的计算冗余。

**💡 创新点**

核心创新在于将经验转化为可执行的 Skill‑MDP，并利用语义梯度生成候选 Skill、PPO 门控验证与在线评分维护实现无参数更新的程序化记忆演化。

**🔧 技术方法**

技术上采用非参数 PPO、语义梯度提取、PPO 门控验证、在线评分维护以及固定权重 LLM 生成与验证 Skill。

**📊 数据集**

实验数据集主要为 ALFWorld 与 TextArena（Mastermind‑v0）两大多轮决策任务。

**📈 对比分析**

与多种记忆增强和推理基线（RAG、Expel、A‑MEM、AWM、G‑Memory、ReAct、CoT 等）比较，ProcMEM 在内域、跨任务、跨代理的重用率高达 0.925、压缩内存至 816 tokens，并在各任务中保持最高成功率，整体性能显著优于基线。

**⚠️ 局限性**

局限在于目前仅实现显式可读 Skill，缺乏隐式执行模块，对极端任务难度和跨域迁移的泛化仍有限。

---

## 600. Vision-only UAV State Estimation for Fast Flights Without External Localization Systems: A2RL Drone Racing Finalist Approach

**arXiv ID:** 2602.01860 | [PDF](https://arxiv.org/pdf/2602.01860v1)

**作者:** Filip Novák `[一作]` (Czech Technical University in Prague), Martin Saska `[通讯]` (Czech Technical University in Prague)

**通讯引用:** 5076 | [OpenAlex ID](https://openalex.org/A5004992661)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `e0540dec-d77f-42db-94ae-d039248f6393` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种在GNSS失效、障碍密集环境中，用单目RGB相机、IMU和车载基准标定系统实现高速无人机精确状态估计的方法。

**💡 创新点**

创新点在于：①通过新的漂移模型同时修正VIO的位姿、线速度和角速度漂移；②将IMU数据直接融入最终估计；③使用基于深度学习的门检测器提供位姿观测并结合Kalman滤波实现漂移估计。

**🔧 技术方法**

采用VINS‑Mono或OpenVINS等视觉惯性里程计、基于U‑Net的门检测CNN、线性卡尔曼滤波器以及IMU融合算法。

**📊 数据集**

实验数据集包括1600条Gazebo仿真轨迹、真实户外赛道（5个门）以及A2RL 2025赛道（10个门）。

**📈 对比分析**

与单纯VIO和两类基线方法对比，本文在位置RMSE下降27倍、姿态RMSE下降70%，线速度RMSE下降16%，角速度RMSE下降8倍；在A2RL比赛中进入决赛并夺得奖牌。

**⚠️ 局限性**

局限性：依赖可见且已知的门/标定物；当标定物缺失或检测失效时估计性能会下降；方法主要验证于赛道环境，对更广泛的工业或安全场景的通用性仍需进一步评估。

---

## 601. Fact or Fake? Assessing the Role of Deepfake Detectors in Multimodal Misinformation Detection

**arXiv ID:** 2602.01854 | [PDF](https://arxiv.org/pdf/2602.01854v1)

**作者:** A S M Sharifuzzaman Sagar `[一作]` (University of Western Australia), Ali Kishk `[通讯]` (Aljazeera Media Network Investigative Department)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

系统性评估图像深度伪造检测器在多模态错误信息检测中的作用，比较单独检测器、证据中心化的反事实推理系统以及将检测器输出作为辅助证据的混合系统。

**💡 创新点**

首次从像素级伪造信号与证据驱动推理的交互视角对比评估，发现像素检测器对多模态验证无益甚至有害，并验证将检测器输出作为可选辅助证据的可行性。

**🔧 技术方法**

采用MCTS引导的工具增强LLM、Multi‑Agent Debate推理框架，结合五种主流图像深度伪造检测器（GRAMNet、BNext‑M、NPR、FatFormer、ProDet），以及MMFakeBench与DGM^4两大基准进行实验。

**📊 数据集**

使用MMFakeBench和DGM^4这两个涵盖图像-文本对、不同操纵方式、语义与像素失真混合的多模态错误信息数据集。

**📈 对比分析**

在Accuracy、Precision、Recall、F1四项指标上对五种检测器、混合系统和纯证据系统进行对比；证据中心化系统在MMFakeBench上F1达0.81、DGM^4上达0.55，混合系统相较原系统下降0.04–0.08 F1，单独检测器F1仅为0.26–0.53。

**⚠️ 局限性**

限制：检测器对视觉伪造的覆盖仍有限，易受训练集偏差影响；实验仅覆盖两个基准，未评估更大规模或不同语境下的性能；未深入探索更复杂的检测器与证据融合策略。

---

## 602. ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems

**arXiv ID:** 2602.01848 | [PDF](https://arxiv.org/pdf/2602.01848v1)

**作者:** Salaheddin Alzu'bi `[一作]` (Sentient), Sewoong Oh `[通讯]` (Sentient)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出ROMA框架，采用递归元代理结构，包括Atomizer、Planner、Executor、Aggregator四个模块，并配合GEPA+进行多组件提示优化。

**💡 创新点**

创新点在于统一的递归控制循环与MECE子任务图，支持并行异构模型执行和可解释的执行追踪，以及多组件提示优化方法GEPA+。

**🔧 技术方法**

使用递归任务分解、结构化聚合、并行执行、MECE规划、DSPy模块化编程、GEPA+提示演化等技术。

**📊 数据集**

实验数据集包括SEAL-0、FRAMES、SimpleQA、EQ-Bench、AbGen。

**📈 对比分析**

通过与Kimi-Researcher、Perplexity Deep Research、Claude Sonnet 4.5等基线对比，ROMA在SEAL-0上提升9.9%准确率、FRAMES 82.3%、SimpleQA 93.9%，并在EQ-Bench上与Claude Sonnet 4.5匹配，整体表现优于多数开源与闭源基线。

**⚠️ 局限性**

局限性包括分解与聚合不一定最优，可能出现冗余或缺失子目标，聚合压缩可能遗漏关键信息；并行执行可能导致总算力增加和协调难题；仍面临长上下文失效和安全工具使用的挑战。

---

## 603. When Feasibility of Fairness Audits Relies on Willingness to Share Data: Examining User Acceptance of Multi-Party Computation Protocols for Fairness Monitoring

**arXiv ID:** 2602.01846 | [PDF](https://arxiv.org/pdf/2602.01846v1)

**作者:** Changyang He `[一作]` (Harbin Institute of Technology), Asia J. Biega `[通讯]` (Max Planck Institute for Security and Privacy)

**通讯引用:** 1038 | [OpenAlex ID](https://openalex.org/A5087294637)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `9cc9baba-5356-466d-81ff-d80028d90279` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

针对算法招聘中的公平性监测，开展了基于多方安全计算（MPC）的隐私保护协议用户接受度研究，使用问卷调查和属性比较法评估用户对协议设计属性的优先级和接受度。

**💡 创新点**

创新点在于：①将隐私保护技术与公平性监测结合，首次系统探讨不同MPC协议设计对用户接受度的影响；②采用情境式配对选择与属性排序相结合的双重方法，揭示用户在隐私与利益权衡中的两种决策模式；③从用户的公平性与隐私取向出发，构建了多维度的“隐私计算”回归模型，阐明不同群体如何权衡风险与收益。

**🔧 技术方法**

主要技术方法包括：情境式配对选择（Conjoint Analysis）与层次贝叶斯（Hierarchical Bayes）效用估计；属性排名（Attribute Ranking）；七级李克特量表的属性级评价；线性回归（带L1正则化）分析公平/隐私取向与属性重要度之间的关联。

**📊 数据集**

使用了来自欧洲各国（受GDPR管辖）的833名正在求职的受访者数据（最终有效样本795人），涵盖性别、种族、年龄、教育、就业状态等人口学特征，并收集了受访者的公平性和隐私取向问卷答案。

**📈 对比分析**

对比方法为：①在情境式选择中计算每个属性的重要度（揭示偏好），②在属性排名中得到用户自报的重要度（说明偏好）；两者对比揭示隐私与利益在不同决策情境中的权重差异。实验结果显示，用户在情境选择中更关注公平目标和金钱激励，而在属性排名中更重视隐私保护与数据类型；此外，回归结果表明公平与隐私取向显著影响对协议各属性的评价。

**⚠️ 局限性**

局限性包括：①样本仅来自欧洲GDPR范围内，文化和法律背景差异可能限制普适性；②采用问卷与情境模拟，缺乏真实数据捐赠与协议部署的行为验证；③样本中非二元性别、老年求职者等群体样本不足，可能影响结果的代表性；④仅使用定量分析，未结合访谈或案例研究获取更深入的用户动机与认知；⑤未评估技术实现层面的性能与安全性，仅聚焦用户接受度。

---

## 604. CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions

**arXiv ID:** 2602.01844 | [PDF](https://arxiv.org/pdf/2602.01844v1)

**作者:** Yuliang Zhan `[一作]` (Renmin University of China), Hao Sun `[通讯]` (Renmin University of China)

**通讯引用:** 23532 | [OpenAlex ID](https://openalex.org/A5100375406)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `67630363-6be0-4f51-ab05-7198250671a5` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `3f18e8e3-0266-457c-8567-9039b6d2394d` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

提出了 Cloth Dynamics Grounding（CDG）任务，利用多视角视频无监督学习布料动力学，并设计了 CloDS 三阶段框架实现从视频到 3D 结构再到动力学预测的完整流程。

**💡 创新点**

创新点在于（1）首次将 Gaussian splatting 与网格结合，形成 Spatial Mapping Gaussian Splatting（SMGS）并引入双位置透明度调制；（2）通过反向优化实现视频到网格的映射；（3）整体实现从 2D 观测到 3D 动力学的全无监督闭环。

**🔧 技术方法**

核心技术包括：双位置透明度调制的 Gaussian splatting、基于 GNN（MGN） 的布料动力学学习、三阶段训练框架（映射、网格提取、动力学训练）以及反向传播重建损失。

**📊 数据集**

主要使用 Blender+FLAGSIMPLE 合成数据集（1000 条轨迹，120 条多视角序列），并在此基础上扩展到真实多视角摄像捕获与 SAM 语义分割的数据。

**📈 对比分析**

与传统基于网格监督的 MGN、GaMeS、4DGS、MSTH、M5D‑GS、SimVP、MAU、MMVP、TAU 等方法对比，CloDS 在 RMSE、PSNR、SSIM、LPIPS 上均优于视频预测模型，且与 MGN 在已见和未见轨迹上接近或超过其性能，展示了优秀的泛化能力。

**⚠️ 局限性**

局限性包括：在真实场景中仍受帧率、光照等因素影响，导致渲染伪影；对极端大变形或复杂相互作用的处理仍有挑战；模型训练需要多视角视频与网格映射的高算力；部分过拟合情况在少量数据上出现。

---

## 605. Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models

**arXiv ID:** 2602.01842 | [PDF](https://arxiv.org/pdf/2602.01842v1)

**作者:** Jinbin Bai `[一作]` (MeissonFlow Research), Ming-Hsuan Yang `[通讯]` (UC Merced)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种针对离散扩散语言模型（dLLMs）的高效测试时缩放框架，能在保持低计算成本的前提下提升推理质量。

**💡 创新点**

创新点在于：① 分层轨迹搜索（HTS）动态聚焦早期-中期去噪窗口，实现几乎线性扩展；② 局部分支（partial re‑masking）保留高置信逻辑骨架以增强多样性；③ 用自我验证反馈（SVF）替代外部奖励模型，降低额外内存与计算开销。

**🔧 技术方法**

技术包括：离散扩散模型的块扩散解码、几何衰减的轨迹裁剪、局部重掩码探索、基于模型的二分类自我验证提示、以及NFE（函数评估次数）作为计算度量。

**📊 数据集**

实验数据集涵盖四个推理/代码生成任务：数学推理的GSM8K、MATH‑500；代码生成的HumanEval、MBPP。

**📈 对比分析**

与单轨迹（N=1）以及Best‑of‑N（4/8/16）baseline比较，所提出的方法在保持或略低于Best‑of‑4的NFE时，通常达到或接近Best‑of‑16的性能；在GSM8K上实现85.3%准确率，仅消耗约1/4的去噪评估。

**⚠️ 局限性**

局限性包括：自我验证的可靠性受模型自身偏差影响，可能对分布外输入过度自信；分层搜索参数需要针对任务调优；当模型规模较大时，局部分支的计算仍不可忽视。

---

## 606. Read As Human: Compressing Context via Parallelizable Close Reading and Skimming

**arXiv ID:** 2602.01840 | [PDF](https://arxiv.org/pdf/2602.01840v1)

**作者:** Jiwei Tang `[一作]` (Tsinghua University), Bo Zheng `[通讯]` (Future Living Lab of Alibaba)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出RAM框架，实现基于查询的上下文分段并进行自适应的细读与速读，从而高效压缩长文本并保持语义完整。

**💡 创新点**

创新点在于将人类阅读策略融入模型，采用并行编码+查询引导的选择机制，以及对比学习提升分割决策的精确度，并兼顾可解释性。

**🔧 技术方法**

核心技术包括并行Transformer编码、查询引导的注意力分段、聚合压缩向量、对比学习损失以及多任务的语言建模。

**📊 数据集**

使用HotpotQA、2WikiMQA、NaturalQuestions、NarrativeQA四大问答数据集以及MultiNews摘要数据集进行训练和评测。

**📈 对比分析**

在多项QA与摘要基准上，RAM在4×/8×压缩下均超越现有基线，取得最优EM/F1，且在最长32K输入上仍保持优势，推理速度提升约12×。

**⚠️ 局限性**

局限在于对比学习所用的正负段标签由大型模型生成，标签准确性不完全保证，且在极高压缩率下仍可能丢失部分关键信息。

---

## 607. Hyperbolic Graph Neural Networks Under the Microscope: The Role of Geometry-Task Alignment

**arXiv ID:** 2602.01828 | [PDF](https://arxiv.org/pdf/2602.01828v1)

**作者:** Dionisia Naddeo `[一作]`, Veronica Lachi `[通讯]` (UiT Arctic University of Norway)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `57a58b01-81b4-4d75-a45c-2e891f272b50` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文系统研究了双曲空间图神经网络（HGNN）在不同下游任务（节点回归、链接预测、节点分类）中的有效性，并提出了“几何–任务对齐”（geometry–task alignment）的概念，探讨了仅仅图结构是双曲的并不一定能带来性能提升，只有任务与输入几何对齐时才会出现优势。

**💡 创新点**

创新点包括：①将几何–任务对齐作为评估HGNN是否有利的新视角；②通过理论证明与实验证明双曲消息传递在需要保持度量结构的任务（如节点回归、链接预测）中具有显著优势；③提出节点回归作为一个未被充分挖掘的评估基准；④系统比较了多种模型和几何空间，并给出可操作的模型选择指导。

**🔧 技术方法**

使用技术包括：双曲GNN（HGCN在Poincaré球上、HyboNet在Lorentz双曲平面上）、欧氏GNN（GCN、GAT）和MLP基线；对数几何变换（指数映射、对数映射）；曲率学习与可调曲率；损失函数包括距离保持损失（stress loss）和归一化stress loss；理论分析利用bi‑Lipschitz、模型失真（model distortion）等概念。

**📊 数据集**

实验数据集：①合成树（b‑ary tree）和格子（28×28格子）用于验证双曲/欧氏的度量保持；②真实图数据集 Disease、Airport（高度双曲）、Cora、Pubmed、Citeseer；③ Synthetic Tree1111_γ 等用于链接预测的额外测试；④ 通过不同噪声水平对 Disease、Airport 节点特征进行扰动实验。

**📈 对比分析**

比较方法：对每个任务使用相应的评价指标（节点回归用 MAE，链接预测用 ROC AUC/AP，节点分类用 Macro‑F1/Accuracy）以及embedding扭曲度（stress loss）来衡量几何保持；结果显示：在链接预测中，HGNN（尤其是 HyboNet）在低 δ（高双曲度）图上明显优于欧氏模型；节点分类中无显著差异；节点回归在树结构上 HGNN 超越欧氏，且与曲率呈负相关；在合成数据上验证了双曲空间在保持度量时的理论优势。

**⚠️ 局限性**

局限性：①需要先评估任务与输入几何的对齐程度，目前缺乏统一的量化指标；②节点回归作为评估基准尚未被广泛采纳，缺乏公开的标准基准数据集；③实验主要集中在树形和高度双曲的图，对更复杂图结构的适用性仍需进一步探索；④在某些数据集（如 Disease、Airport）中 MLP 基线已能匹配 GNN，说明数据划分和特征质量对结论影响较大。

---

## 608. Multimodal Large Language Models for Real-Time Situated Reasoning

**arXiv ID:** 2602.01880 | [PDF](https://arxiv.org/pdf/2602.01880v1)

**作者:** Giulio Antonio Abbo `[一作]` (Ghent University), Tony Belpaeme `[通讯]` (Ghent University)

**通讯引用:** 8123 | [OpenAlex ID](https://openalex.org/A5035627933)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

开发了一款基于 TurtleBot 4 和 GPT‑4o 的价值感知真空清洁机器人，能实时根据视觉输入判断是否开始清洁。

**💡 创新点**

首次将多模态大语言模型用于实时情境和价值推理，并生成可解释的决策过程，提升了家庭机器人的社会意识。

**🔧 技术方法**

采用 GPT‑4o 作为视觉语言模型，结合 OAK‑D‑PRO RGBD 摄像头、ROS 2、Python 以及 PyQt5 UI，实现图像提取与一步步推理。

**📊 数据集**

主要使用 YouHome Activities of Daily Living 数据集进行实验，也采集了现场生活环境图像。

**📈 对比分析**

通过定性观察评估，机器人在不同场景下能够正确识别活动并做出合适决策，但未给出量化性能指标。

**⚠️ 局限性**

局限包括实时推理延迟、决策一致性欠佳、模型偏见、隐私问题以及缺乏定量评估。

---

## 609. BTGenBot-2: Efficient Behavior Tree Generation with Small Language Models

**arXiv ID:** 2602.01870 | [PDF](https://arxiv.org/pdf/2602.01870v1)

**作者:** Riccardo Andrea Izzo `[一作]` (Politecnico di Milano), Matteo Matteucci `[通讯]` (Politecnico di Milano)

**通讯引用:** 6834 | [OpenAlex ID](https://openalex.org/A5003932703)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了BTGenBot-2，一款1B参数的开源小语言模型，能够将自然语言任务描述直接转化为可在ROS2上执行的行为树，并发布了对应的数据集、模型权重、代码和基准。

**💡 创新点**

创新点包括：①在1B级别实现零射击行为树生成；②利用TSE原始BT与GPT‑4o‑mini合成扩增构建了5,204条自然语言–行为树对的高质量数据集；③提出了推理时和运行时两级错误检测与自动恢复机制；④首次提出标准化的BT生成基准（52个导航与操作任务，分三难度级别）。

**🔧 技术方法**

使用了Llama‑3.2‑1B‑Instruct作为基模型，采用QLoRA参数高效微调，结合XML解析器和C++行为树日志器实现错误恢复；评估环境为NVIDIA Isaac Sim仿真和真实AgileX Scout/ SO‑ARM 101机器人。

**📊 数据集**

主要数据集为自制的5,204条自然语言–行为树对，来源于TSE原始BT与GPT‑4o‑mini合成；基准数据集包含52个导航与操作任务，覆盖易/中/难三级。

**📈 对比分析**

通过功能指标（成功率、Pass@3）与非功能指标（动作一致性、XML语法、语义正确性）与原BTGenBot、GPT‑5、Claude Opus 4.1等对比。BTGenBot‑2‑ER在零射击/一射击下分别取得90.38%/98.07%的平均成功率，速度比GPT‑5快3–16倍，XML语法正确率达100%。

**⚠️ 局限性**

局限性包括：数据规模与多样性仍有提升空间，主要验证集中在仿真与有限真实机器人，未覆盖极端复杂环境；对更大模型迁移性未知；在跨平台部署与长期运行的鲁棒性仍需进一步验证。

---

## 610. GRAB: An LLM-Inspired Sequence-First Click-Through Rate Prediction Modeling Paradigm

**arXiv ID:** 2602.01865 | [PDF](https://arxiv.org/pdf/2602.01865v1)

**作者:** Shaopeng Chen `[一作]` (Baidu Inc), Liu Lin `[通讯]`

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c773407a-6119-4871-b8b3-1e7ae17a6851` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了GRAB框架，用于工业级CTR预测，将LLM启发的生成式推荐与传统DLRM融合，实现端到端序列建模。

**💡 创新点**

引入了多通道因果动作感知注意力（CamA）和序列先行稀疏训练（STS），解决了序列打包导致的分布偏移和稀疏/稠密参数梯度冲突。

**🔧 技术方法**

基于Transformer的因果自注意力、动作感知相对编码、双滑动窗口可见性、分层token化与多通道混合、分阶段训练等技术。

**📊 数据集**

使用了百度海量广告CTR数据集，包含数十亿用户曝光和点击日志。

**📈 对比分析**

与DIN、SIM、TWIN、HSTU、LONGER等DLRM与GR基线对比，离线AUC提升至0.83772（比最佳基线高0.19%），在线A/B测试CTR提升3.49%、CPM提升3.05%。

**⚠️ 局限性**

仍受Transformer二次复杂度限制，推理算力高，且在极长序列或稀疏ID上需额外稀疏优化；模型对训练时长和资源需求较高。

---

## 611. Designing Time Series Experiments in A/B Testing with Transformer Reinforcement Learning

**arXiv ID:** 2602.01853 | [PDF](https://arxiv.org/pdf/2602.01853v1)

**作者:** Xiangkun Wu `[一作]` (Zhejiang University), Chengchun Shi `[通讯]` (London School of Economics and Political Science)

**通讯引用:** 614 | [OpenAlex ID](https://openalex.org/A5025970743)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出一种Transformer强化学习方法，用于时间序列A/B测试的实验设计，以最小化ATE估计的均方误差（MSE）

**💡 创新点**

创新点在于：①利用Transformer编码完整历史构造状态，充分捕捉动态依赖；②直接通过RL优化MSE，消除对数据生成过程的强假设；③证明任何不依赖完整历史的分配策略都无法达到最优，从而揭示设计局限

**🔧 技术方法**

使用技术包括Transformer编码器+双深度Q网络（Double DQN）强化学习框架、Monte Carlo估计ATE、基于模拟环境的交互式学习

**📊 数据集**

实验使用三类数据集：①人工合成模拟；②基于真实骑手平台A/A实验构建的仿真；③公开物理调度仿真器MDPOD

**📈 对比分析**

对比方法包括TMDP/NMDP、四种Switchback设计（HW、BSZ、XCT、WSY）。实验结果显示在所有三种环境中，Transformer RL（TRL）均取得最低MSE，尤其在样本量小或正相关的情形下优于对手

**⚠️ 局限性**

局限性：需要可用或可构建的仿真环境；对多实验单元及传播效应的处理尚未扩展；对极端延迟或非平稳过程的适应性尚待验证

---

## 612. No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation

**arXiv ID:** 2602.01845 | [PDF](https://arxiv.org/pdf/2602.01845v1)

**作者:** Furkan Eris `[一作]` `[通讯]` (Independent researcher), Furkan Eris (Independent researcher)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c773407a-6119-4871-b8b3-1e7ae17a6851` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出并训练了一个 309M 参数的因果蛋白语言模型 Proust，能够在仅使用序列信息时与 MLM 级别的模型媲美，还保留了生成能力。

**💡 创新点**

创新点在于将最新的文本 LLM 技术（GQA‑S2 attention、共享 KV、关键偏移、Canon 层、Muon 优化器等）应用于蛋白模型，克服了传统 MLM 与 CLM 的分裂，实现高效且强大的因果模型。

**🔧 技术方法**

使用的技术包括 GQA‑S2 attention 与部分 RoPE、交叉层值残差、关键偏移、Canon 的深度可卷积因果层、FlashAttention‑4、RMSNorm、Muon's Newton‑Schulz 正交化等。

**📊 数据集**

训练数据来自 167M 条序列、33B 个 token，集合包括 UniRef50、OMG、CAZy、RVDB、VirE、LOGAN、BFVD、Araport11、毒素和酵母蛋白等多样化数据库。

**📈 对比分析**

在 ProteinGym 替换、indel 以及 EVEREST 病毒 DMS 基准上与更大规模的 MLM/CLM 进行比较，Proust 在替换任务中 Spearman ρ=0.390，接近 ESM2‑650M，Indel ρ=0.521 超越同类模型，且训练成本比同类模型低 50–200 倍。

**⚠️ 局限性**

局限性包括在稳定性预测方面仍落后于结构感知模型，对检索增强的依赖仍高，且模型规模扩展到更大参数仍需进一步验证。

---

## 613. AXE: Low-Cost Cross-Domain Web Structured Information Extraction

**arXiv ID:** 2602.01838 | [PDF](https://arxiv.org/pdf/2602.01838v1)

**作者:** Abdelrahman Mansour `[一作]` (Cairo University), Moataz Elsaban `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了一种基于 DOM 树剪枝的网页结构化信息抽取管道 AXE，利用轻量级 LLM 与专门的适配器实现零样本抽取

**💡 创新点**

创新点包括：① 用“pruning”机制大幅去除冗余 boilerplate，使小型 LLM 也能在极低上下文下完成抽取；② 引入 Grounded XPath Resolution（GXR）将生成式结果映射到原始节点，显著降低幻觉率；③ 通过知识蒸馏训练专用适配器，提升跨域零样本性能

**🔧 技术方法**

技术涵盖 HTMLRAG 预处理、自动分块 AutoChunker、LoRA 微调的 Pruner、QA 与 Schema 适配器、GXR 结构化检索、FlashAttention‑2 等高效推理加速

**📊 数据集**

训练数据来源于 Common Crawl 10k 站点的合成问答与 JSON，评测数据使用 SWDE（结构化网页抽取基准）和 WebSRC（多模态阅读理解基准）

**📈 对比分析**

与 MarkupLM、WebLM 等大模型和传统规则方法对比，AXE 在 SWDE 上零样本 F1 达到 88.1%，超过了 0.6B 以上模型的 1‑shot 结果，WebSRC 上 F1 也保持在 86.9% 左右，展示了更高的跨域泛化和成本效益

**⚠️ 局限性**

局限性：仅抽取文本信息，未利用视觉渲染；仅支持 HTML 文档；依赖合成数据训练，可能带来域偏差；即使 GXR 降低幻觉风险，模型仍可能因检索质量差导致失败

---

## 614. Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models

**arXiv ID:** 2602.01834 | [PDF](https://arxiv.org/pdf/2602.01834v1)

**作者:** Siqi Wen `[一作]` (Beijing Jiaotong University), Di Wang `[通讯]` (King Abdullah University of Science and Technology)

**通讯引用:** 3998 | [OpenAlex ID](https://openalex.org/A5100401482)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `9cc9baba-5356-466d-81ff-d80028d90279` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

针对 Vision‑Language‑Action（VLA）模型在执行过程中可能出现的危险行为，本文提出了一种基于概念字典的推理时安全控制框架，利用稀疏可解释的字典对隐藏层表示进行分解并在检测到危险概念时进行阈值衰减。

**💡 创新点**

创新点在于：①在表示层而非输入/输出层进行安全干预，能在危险指令或对抗性 jailbreak 进入模型后第一时间抑制危险语义；②通过字典学习得到可解释的概念方向，做到轻量级且可插拔；③无需重新训练或微调，兼容任何 VLA 体系结构。

**🔧 技术方法**

核心技术包括：概念挖掘与刺激句生成、SVD/PCA 估计概念方向、ElasticNet 稀疏投影、基于危险分数的阈值衰减干预。

**📊 数据集**

实验使用了 Libero‑Harm、BadRobot、RoboPair、IS‑Bench 等四个安全与攻击基准，并在 Llama‑3.2‑Vision、Qwen2‑VL 等主流 VLA 模型上评测。

**📈 对比分析**

与传统的对齐、过滤、提示硬化等方法相比，SAFE‑Dict 在攻击成功率（ASR）上平均下降超过 70%，同时保持任务完成率（SR/SSR）不低于基线；在 IS‑Bench 上既提升了安全成功率，又仅略微降低了任务成功率，显示出更佳的安全‑效能折中。

**⚠️ 局限性**

主要局限是：①依赖预先构建的概念字典，难以捕捉完全新颖或稀有的危险；②目前仅针对指令级和语义级风险，未覆盖感知失效、低层控制不稳定等物理层面风险。

---

## 615. Synesthesia of Vehicles: Tactile Data Synthesis from Visual Inputs

**arXiv ID:** 2602.01832 | [PDF](https://arxiv.org/pdf/2602.01832v1)

**作者:** Rui Wang `[一作]` (Beihang University), Shichun Yang `[通讯]` (Beihang University)

**通讯引用:** 7802 | [OpenAlex ID](https://openalex.org/A5025307891)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `67630363-6be0-4f51-ab05-7198250671a5` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

设计并实现了车辆同步感知框架SoV，利用前向摄像头图像预测路面触觉激励，并构建了包含六种路面与昼夜光照条件的多模态数据集，提出时空对齐算法与视觉‑触觉潜在扩散生成模型vtSyn；

**💡 创新点**

首次将人类同步现象引入车辆感知，提出视觉‑触觉同步映射与跨模态生成；提出针对视觉与触觉时空差异的对齐方法；利用潜在扩散模型生成高质量触觉数据，实现无监督的触觉感知预测；

**🔧 技术方法**

采用RTK定位+加速度计搭建感知系统；时空对齐算法（关键帧提取、路段标记、空间‑时间映射、插值重采样）；VAE+自注意力编码、潜在扩散模型（U‑Net）实现vtSyn；评估使用RMSE、FID、freq‑ssim、分类准确率等指标；

**📊 数据集**

自收集的Geely Geometry E车辆多模态数据集，包含六种路面（沥青、混凝土、泥泞、碎石、砖块、土壤）在日间与夜间光照下的视觉与触觉数据，共计数千对时空对齐样本；

**📈 对比分析**

与CGAN、CVAE、DiffWave等基准模型在RMSE、FID、freq‑ssim、分类准确率等维度进行对比；vtSyn在频域相似度、整体分布与分类任务上表现最佳，尽管RMSE略高，但FID和freq‑ssim均最低，分类准确率达到0.64；

**⚠️ 局限性**

实验仅涵盖光照变化，未覆盖雨雪等恶劣天气；数据量有限，模型对高频细节仍有欠缺；潜在扩散模型训练时间长、计算资源需求高。

---

## 616. In-Pipeline Integration of Digital In-Memory-Computing into RISC-V Vector Architecture to Accelerate Deep Learning

**arXiv ID:** 2602.01827 | [PDF](https://arxiv.org/pdf/2602.01827v1)

**作者:** Tommaso Spagnolo `[一作]` (Politecnico di Milano), Giuseppe Desoli `[通讯]` (STMicroelectronics)

**通讯引用:** 1054 | [OpenAlex ID](https://openalex.org/A5047102959)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `85b3479c-4bb5-42e0-8cca-2f9268bd338f`

**🎯 论文内容**

在RISC‑V向量核心的执行阶段内集成了数字内存计算（DIMC）单元，并通过四条自定义指令实现对数据加载、计算和写回的细粒度控制。

**💡 创新点**

创新点在于：①将DIMC紧耦合为向量核心的功能单元（FU），实现与向量指令流的无缝协同；②设计了一套四条专用指令（DL.I、DL.M、DC.P、DC.F）作为ISA扩展，最大化DIMC的带宽利用和吞吐量；③在工业级RVV核心上实现，并通过向量ISA的可扩展性实现灵活的工作负载映射。

**🔧 技术方法**

使用技术包括：RISC‑V向量指令集扩展、紧耦合内存计算单元、定制指令编码、基于周期近似的模拟器、工业级RTL综合（P18 CMOS）。

**📊 数据集**

主要用ResNet‑50的卷积与全连接层作为基准数据集进行评估，同时对超过450层的多种网络（AlexNet、VGG16、ResNet、Inception、DenseNet、EfficientNet、MobileNet）做了泛化测试。

**📈 对比分析**

通过将DIMC增强的RVV与基础RVV核心进行对比，使用OPs、速度提升、面积归一化速度提升三种度量；结果显示在ResNet‑50上峰值达137 GOP/s，速度提升217×，面积归一化速度提升超过50×；与同类工作相比，维持最高的性能和最小的内存占用。

**⚠️ 局限性**

局限性包括：仅实现单个DIMC tile，未验证多 tile 扩展；使用固定频率（500 MHz）和固定外部存储延迟的仿真；未考虑双指令发射、能耗测量和非卷积层的加速；对权重和输入数据的加载假设为最坏情况，未利用潜在的数据重用；对模型精度仅支持到4 bit，无法覆盖更高位宽需求。

---

## 617. Entropy-Guided Data-Efficient Training for Multimodal Reasoning Reward Models

**arXiv ID:** 2602.01884 | [PDF](https://arxiv.org/pdf/2602.01884v1)

**作者:** Shidong Yang `[一作]`, Xiangxiang Chu `[通讯]` (Alibaba Group)

**通讯引用:** 5384 | [OpenAlex ID](https://openalex.org/A5101512474)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `a4b10f5d-130b-4e77-9367-6469ec621899` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并实现了基于响应熵的多模态奖励模型训练框架 EGT，包括熵引导的数据清理与逐步训练。

**💡 创新点**

创新点在于将响应熵作为无监督噪声与难度代理，结合熵驱动的数据裁剪与从易到难的训练课程，显著提升训练效率和鲁棒性。

**🔧 技术方法**

采用了推理奖励模型、熵计算（答案词熵与推理句子熵）、熵引导的训练课程、基于规则的奖励函数和 StableReinforce 强化学习。

**📊 数据集**

使用了 5 公开多模态偏好数据集（用于 SFT）和 17k 对齐样本（用于 RL），并在 VL‑RewardBench、Multimodal Reward Bench 与 MM‑RLHF Reward Bench 三个基准上进行评估。

**📈 对比分析**

通过与现有最优方法 R1‑Reward、随机选样和基于准确率的选样比较，EGT 在平均 3.88% 的指标提升、仅使用 2.5k 低熵样本即可达到全数据性能，熵驱动选样明显优于其他策略。

**⚠️ 局限性**

局限性包括：熵计算依赖特定模型，可能忽略细粒度难度；阈值选择与阈值设定不易自适应；框架主要关注奖励模型的训练，尚未证明在更广泛的 RLHF 体系中的通用性。

---

## 618. How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing

**arXiv ID:** 2602.01851 | [PDF](https://arxiv.org/pdf/2602.01851v1)

**作者:** Huanyu Zhang `[一作]` (University of Chinese Academy of Sciences), Tieniu Tan `[通讯]` (Nanjing University)

**通讯引用:** 36830 | [OpenAlex ID](https://openalex.org/A5111885963)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `dd8c26bc-3e4a-44cd-ab1a-e3ffc95d5769` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 VIBE 基准，构建三层视觉指令交互层级（指向、形态、因果），并设计 10 个子任务评估模型在图像编辑中的视觉指令遵循能力。

**💡 创新点**

创新点包括：①将视觉指令正式定义为空间锚定线索；②引入层级化任务结构和任务特定评测指标；③采用 LMM‑as‑a‑Judge 的自动评估框架，实现可扩展且细粒度的性能评估。

**🔧 技术方法**

使用 GPT‑5.1 等大型多模态模型作为评判者，结合人工标注和多轮验证；评测指标包括 Instruction Adherence、Contextual Preservation 与 Visual Coherence；在模型层面对 17 个开源与专有图像编辑模型进行实验。

**📊 数据集**

构建 VIBE 数据集，包含 1,034 个样本，覆盖真实、动画和素描三种视觉风格，按层级分布（Deictic 400、Morphological 300、Causal 334），所有样本均为人工标注或严格人工复核。

**📈 对比分析**

对每个模型在各子任务与层级上计算得分，并采用三次独立评测取平均。实验结果显示专有模型平均分数明显高于开源模型；专有模型从 Deictic 级别到 Causal 级别逐步下降，最差分数低于 50%。

**⚠️ 局限性**

局限性包括：1）对抽象方向性视觉指令的推理能力不足；2）多任务/组合指令执行性能仍显不足；3）评估框架依赖 LMM 的准确性，可能受到模型偏差影响；4）数据集规模与多样性仍有限，难以覆盖更复杂场景。

---

## 619. Sharp Thresholds for Temporal Motifs and Doubling Time in Random Temporal Graphs

**arXiv ID:** 2602.01847 | [PDF](https://arxiv.org/pdf/2602.01847v1)

**作者:** Henry Austin `[一作]` (Durham University), Paul G. Spirakis `[通讯]` (University of Liverpool)

**通讯引用:** 7836 | [OpenAlex ID](https://openalex.org/A5011756177)

**关键词:** `dd4bd30e-3d3d-4e53-a403-da542c6c036a` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文研究了随机时间图的两种模型（连续模型中时间标签取自(0,1]区间，离散模型中取自{1,…,T}集合），推导了δ‑时间图案（δ‑时间图案）的存在阈值，分析了连续模型下最大δ‑时间团的规模，并给出了随机时间图中可达球最大翻倍时间（doubling time）的精确上下界。

**💡 创新点**

创新点主要体现在①引入连续/离散标签随机时间图模型并首次给出δ‑时间图案存在阈值与图的稀疏度的精确关系，揭示与静态阈值的本质差异；②在连续模型下精确刻画最大δ‑时间团大小；③通过翻倍时间证明时间图的“扩张”性质并给出上下界；④将时间图阈值与静态随机图进行理论对比。

**🔧 技术方法**

主要使用了概率方法中的一阶与二阶矩法（first/second moment method），配合组合计数、稀疏度分析、时间可逆性以及几何随机变量的耦合技术进行证明。

**📊 数据集**

由于是理论研究，未使用任何真实数据集，所有结论均基于上述随机模型的数学推导。

**📈 对比分析**

本文通过与静态 Erdős–Rényi 随机图的阈值（如 logn/n、log^2 n/ log(...) 等）以及先前 RSTG 研究中的翻倍时间阈值进行理论比较，证明了时间图的翻倍时间在 (1±o(1)) n log n 范围内，显示了时间图在扩张速度与静态图相近但更细粒度的特性。

**⚠️ 局限性**

局限性包括：①某些结果仅在 ψ 为伯努利或有限上界分布时成立；②对非路径结构的随机时间图仍缺乏完整阈值与规模分析；③假设标签独立且均匀，现实中时间依赖性可能导致结论失效；④缺乏实验验证，仅给出理论极限。

---

## 620. Efficient Cross-Country Data Acquisition Strategy for ADAS via Street-View Imagery

**arXiv ID:** 2602.01836 | [PDF](https://arxiv.org/pdf/2602.01836v1)

**作者:** Yin Wu `[一作]` (CARIAD SE), J. Marius Zöllner `[通讯]` (FZI Research Center for Information Technology)

**通讯引用:** 3396 | [OpenAlex ID](https://openalex.org/A5060028048)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种利用公开街景图像来预先识别目标国中最具代表性的地点（POI），从而指导在该国进行有针对性的数据采集，以实现ADAS/ADS跨国部署的策略。

**💡 创新点**

创新点包括：①设计两种POI评分方法——基于CLIP的KNN特征距离和基于vLLM的视觉属性归因；②构建“collect–detect”评估协议及与ZOD驾驶数据对齐的街景数据集，提供可复现的实验基准；③证明vLLM方法在仅使用目标国50%数据时即可达到与完整数据相当甚至更好的检测性能。

**🔧 技术方法**

技术手段：视觉基础模型CLIP（ViT‑L/14）用于特征提取与KNN距离计算；OpenAI的vLLM（如gpt‑5‑mini）用于从街景图像提取交通标志属性并计算语义差距；RetinaNet+Detectron2实现交通标志检测；Mapillary API进行街景检索；collect–detect协议与ZOD（德国、波兰、瑞典、法国）数据集配对。

**📊 数据集**

数据集：ZOD多国驾驶日志（德国、波兰、瑞典、法国）用于训练与验证；Mapillary街景图片作为POI搜索和评分的视觉输入；对每个驾驶日志坐标检索10米半径内的街景图像。

**📈 对比分析**

对比方法：随机采样（baseline）、KNN特征距离、vLLM属性归因。实验显示：在25%数据预算下，vLLM实现的AP约为0.667，而随机采样仅为0.624，KNN略高于随机但波动大；在75%预算时，vLLM甚至超过完整数据训练的AP；vLLM在波兰、瑞典、法国三国均保持最高提升，且提升幅度在+0.043~+0.076之间。

**⚠️ 局限性**

局限性：①街景覆盖不完整或缺失导致部分POI无法评估；②街景与驾驶日志存在时间/视角差异，可能出现匹配误差；③KNN方法对交通标志细节不敏感，稳定性差；④仅评估交通标志检测任务，未验证在其他感知任务上的泛化；⑤成本估算基于token计费的粗略模型，未考虑网络、存储等实际费用；⑥最终仍需现场采集验证，无法完全替代真实路测。

---

## 621. Mixture of Disentangled Experts with Missing Modalities for Robust Multimodal Sentiment Analysis

**arXiv ID:** 2602.01833 | [PDF](https://arxiv.org/pdf/2602.01833v1)

**作者:** Xiang Li `[一作]` (Beihang University), Zhoujun Li `[通讯]` (Beihang University)

**通讯引用:** 9355 | [OpenAlex ID](https://openalex.org/A5036786337)

**关键词:** `a154b176-e466-40fc-8ae0-e5cd17677106` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

开发了一种Disentangled Expert Representation Learning（DERL）框架，结合混合专家解耦、多层协作重建和模态路由融合，能够在多模态情感分析中有效应对缺失或噪声模态；

**💡 创新点**

创新点包括：①自适应混合专家解耦可动态分离私有与共享特征；②多层协作重建提供跨视角监督提升语义恢复；③模态路由融合实现重要性感知的多模态融合；

**🔧 技术方法**

技术实现主要基于Transformer统一编码、Mixture-of-Experts解耦、软路由机制、多级重建网络以及注意力融合与多任务损失；

**📊 数据集**

使用了MOSI和MOSEI这两个主流多模态情感分析基准数据集进行评估；

**📈 对比分析**

与MISA、Self-MM、MMIM、DMD、LNLN、EMOE等完整与缺失模态方法对比，在多种缺失率下DERL在MAE、Acc-2、F1等指标均表现最佳，例如MOSI Acc-2提升2.47%，MAE下降2.25%；

**⚠️ 局限性**

局限性在于仅针对预定义的缺失模式，未覆盖更复杂、真实世界中的随机或动态缺失情况，泛化能力受限。

---

## 622. Self-Rewarding Sequential Monte Carlo for Masked Diffusion Language Models

**arXiv ID:** 2602.01849 | [PDF](https://arxiv.org/pdf/2602.01849v1)

**作者:** Ziwei Luo `[一作]` (Uppsala University), Thomas B. Schön `[通讯]` (Uppsala University)

**通讯引用:** 9645 | [OpenAlex ID](https://openalex.org/A5083090794)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种自奖励的序列蒙特卡洛（Self‑Rewarding SMC）算法，用于在推理阶段对掩码扩散语言模型（MDLM）进行扩展采样，显著提升生成质量与多样性。

**💡 创新点**

创新点在于将整个生成轨迹的置信度作为自奖励信号，用粒子重采样实现全局轨迹优化，无需额外训练或外部奖励；同时实现了多粒子并行采样与自适应重采样，克服了传统贪婪置信度采样导致的路径局限。

**🔧 技术方法**

核心技术包括：序列蒙特卡洛（SMC）框架、重要性采样、轨迹级置信度权重、粒子重采样、Gumbel‑Max 采样、温度调控、并行/块式解码以及自适应重采样阈值。

**📊 数据集**

实验数据集：OpenWebText（用于生成文本质量评估）；数学推理与代码生成基准：GSM8K、MATH、HumanEval、MBPP；以及大规模语言模型基准（LLaDA‑1.5、Dream‑7B）。

**📈 对比分析**

与传统 AR、SEDD、SSD‑LM、MDLM、BD3‑LM 等方法对比，Self‑Rewarding SMC 在生成困惑度、BLEU、准确率等指标均实现显著提升：如 BD3‑LM 生成困惑度从 41.3 降至 25.9（约 38% 改善），LLaDA‑1.5 与 Dream‑7B 在 GSM8K/MATH/HumanEval/MBPP 上平均准确率提升 2.8–4.5%，并在不同温度和粒子数下保持稳定。

**⚠️ 局限性**

局限性：需额外的粒子数量与并行计算，粒子数越多计算成本越高；对极长序列或极低置信度情形仍可能产生不稳定；缺乏针对特定任务的外部奖励，某些细粒度的任务约束可能需要进一步改进。

---

## 623. Hacking Flow: From Lived Practices to Innovation

**arXiv ID:** 2602.01979 | [PDF](https://arxiv.org/pdf/2602.01979v1)

**作者:** Fabio Stano `[一作]` (Karlsruhe Institute of Technology), Michael T Knierim `[通讯]` (University of Nottingham)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

通过问卷与反射性主题分析收集并验证了数字知识工作者在日常工作中自我实施的 38 种流状态支持策略，并将其归纳为环境、规划与组织、任务塑造及身心准备四大类。

**💡 创新点**

首次系统性呈现“生活化”流干预手段，并将其与现有 HCI 干预对比，提出了可定制化、探索性工具的设计方向，强调流支持是适配性问题而非一刀切方案。

**🔧 技术方法**

使用反射性主题分析、定量在线调查、描述性统计、k‑means 聚类，并利用 Flow Metacognition Questionnaire、Short Flow in Work Scale 以及自定义干预列表进行评估。

**📊 数据集**

数据集包含 160 名受访者的开放式回答（Study 1）以及 126 名受访者的结构化问卷（Study 2），受访者来自 23 个国家，涵盖北美、欧洲、亚洲等地区。

**📈 对比分析**

通过帮助度与极化度两维度对干预进行聚类，得到三类（广泛认可、争议性、冷门）策略；实验未给出传统算法指标，但展示了不同人群对同一干预的显著差异与潜在可定制空间。

**⚠️ 局限性**

局限包括自我报告偏差、交叉性低、样本仅为数字知识工作者、缺乏对情境与任务动态的追踪、未进行客观效能验证，以及对多样性（性别、神经多样性等）的考虑不足。

---

## 624. SpikingGamma: Surrogate-Gradient Free and Temporally Precise Online Training of Spiking Neural Networks with Smoothed Delays

**arXiv ID:** 2602.01978 | [PDF](https://arxiv.org/pdf/2602.01978v1)

**作者:** Roel Koopman `[一作]` (Centrum Wiskunde & Informatica), Sander Bohté `[通讯]` (Centrum Wiskunde & Informatica)

**通讯引用:** 3688 | [OpenAlex ID](https://openalex.org/A5005914878)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种基于递归内存桶和Sigma-Delta脉冲编码的前馈SNN模型SpikingGamma，支持在线训练并可直接误差反向传播，无需 surrogate 梯度，能够在细粒度时间分辨率下高效工作。

**💡 创新点**

核心创新是通过可压缩的时间桶与自适应阈值将神经元内部状态表征为延迟记忆，从而消除自回归结构，允许前馈网络直接计算误差梯度，突破传统 BPTT/SG 对时间步的限制并显著降低突触发射。

**🔧 技术方法**

采用线性‑非线性 Sigma-Delta 编码、可学习的桶权重、递归内存、适应阈值、层归一化、Dropout 以及标准交叉熵或 MSE 损失的在线反向传播。

**📊 数据集**

在事件驱动时间序列数据集 DVS Gesture、SHD、SSC 以及简单的延迟与相位检测任务上进行评估。

**📈 对比分析**

与 FPTT、DECOLLE、OTTT、ES‑D‑RTRL 等现有在线 SNN 方法对比，SpikingGamma 在所有任务上达到或超过其精度，且在更高时间分辨率下保持稳定，内存占用几乎不随时间步增长。

**⚠️ 局限性**

局限在于对以率编码为主的数据集稀疏性提升有限；同时在极大规模网络或连续时间学习中的硬件实现可行性尚待进一步验证。

---

## 625. Self-Consolidation for Self-Evolving Agents

**arXiv ID:** 2602.01966 | [PDF](https://arxiv.org/pdf/2602.01966v1)

**作者:** Hongzhuo Yu `[一作]` (University of Chinese Academy of Sciences), Ling Shao `[通讯]` (University of Chinese Academy of Sciences)

**通讯引用:** 67581 | [OpenAlex ID](https://openalex.org/A5082634513)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了EvoSC框架，实现了LLM代理的终身学习；

**💡 创新点**

核心创新在于双阶段演化机制，既通过对成功与失败轨迹的对比反思提炼可复用的经验，又将长轨迹压缩为可学习的提示参数，实现了对知识的长期内化；

**🔧 技术方法**

采用了非参数的对比式经验提取、成功经验抽象、以及参数化轨迹整合等技术，并通过FIFO队列管理经验、使用可学习提示嵌入实现自我整合；

**📊 数据集**

在LifelongAgentBench数据集上进行实验，涵盖数据库(DB)、操作系统(OS)、知识图谱(KG)三大领域；

**📈 对比分析**

与AWM、TER、SCM、A-MEM等基线在Llama 3.1‑8B和Qwen 2.5‑7B上对比，EvoSC平均提升约5–10%，且在经验量增大时仍保持稳定，避免OOM错误；

**⚠️ 局限性**

局限在检索机制较为简单，实验仅覆盖7B/8B模型，缺乏对更大规模模型和更丰富检索策略的验证。

---

## 626. Boosting metacognition in entangled human-AI interaction to navigate cognitive-behavioral drift

**arXiv ID:** 2602.01959 | [PDF](https://arxiv.org/pdf/2602.01959v1)

**作者:** Ezequiel Lopez-Lopez `[一作]` (Max Planck Institute for Human Development), Stefan M. Herzog `[通讯]` (Max Planck Institute for Human Development)

**通讯引用:** 3273 | [OpenAlex ID](https://openalex.org/A5008439962)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

提出一种基于人机持续互动的研究框架，系统阐述人机纠缠、认知行为漂移和元认知调节三大现象，并给出干预点与研究方向。

**💡 创新点**

创新点在于将人机交互视为持续的共适应过程，首次将元认知监控与控制与AI交互动态结合，提供四个可操作的元认知干预点，突破传统对AI错误输出单一关注的局限。

**🔧 技术方法**

主要运用心理学和认知科学中的元认知理论、对话系统设计原理和社会科学的交互分析框架；未使用具体算法实现。

**📊 数据集**

本文不依赖任何特定数据集，主要基于已有文献综述和案例分析，引用多篇关于LLM、信息环境与元认知的研究。

**📈 对比分析**

由于是理论框架，未进行实验比较或性能评估；讨论了与现有AI治理、用户体验研究的相似与差异，指出未来需要在纵向研究中验证干预效果。

**⚠️ 局限性**

局限包括缺乏实证验证、对不同AI系统和文化背景的普适性未测评、政策与技术实现的可行性未知，以及对“漂移”机制的定量度量方法尚未成熟。

---

## 627. SQLAgent: Learning to Explore Before Generating as a Data Engineer

**arXiv ID:** 2602.01952 | [PDF](https://arxiv.org/pdf/2602.01952v1)

**作者:** Wenjia Jiang `[一作]` (AGI Lab, Westlake University), Chi Zhang `[通讯]` (AGI Lab, Westlake University)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

开发了两阶段LLM框架SQLAgent，通过探索阶段构建数据库知识库并在部署阶段使用双代理生成SQL。

**💡 创新点**

创新点在于将知识获取与查询生成分离，采用LLM驱动的蒙特卡洛树搜索自生成知识库，双代理协同迭代改进。

**🔧 技术方法**

技术包括LLM推理、MCTS启发式搜索、双代理信息检索与生成、自然语言‑SQL映射。

**📊 数据集**

数据集为Spider 2.0‑Snow基准，包含约150个数据库。

**📈 对比分析**

与Spider‑Agent、ReFoRCE、Din‑SQL等对比，执行准确率提升至25.78%，比基线高约5个百分点。

**⚠️ 局限性**

局限在探索阶段的计算开销、LLM对多轮交互的依赖以及对极大数据库的可扩展性仍待验证。

---

## 628. Boundary-Constrained Diffusion Models for Floorplan Generation: Balancing Realism and Diversity

**arXiv ID:** 2602.01949 | [PDF](https://arxiv.org/pdf/2602.01949v1)

**作者:** Leonardo Stoppani `[一作]` (University of Pisa), Shahab Mokarizadeh `[通讯]` (H&M Group)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种基于扩散模型的楼层平面图生成方法，能够在给定的边界和图形约束下生成几何合法且样式逼真的平面图。

**💡 创新点**

主要创新点包括：1）Boundary Cross‑Attention (BCA) 模块，用以直接将边界信息融入 Transformer 的交叉注意力；2）Diversity Score (DS) 新颖度量，用于评估同一条件下生成结果的多样性；3）针对OOD的少量样本微调实验，揭示模型对训练数据先验的依赖。

**🔧 技术方法**

技术方面基于HouseDiffusion的DDPM框架，加入自注意力和交叉注意力（包括BCA），使用Transformer预测噪声；训练采用Adam、cosine噪声调度、dropout边界掩码；生成时通过classifier‑free guidance混合边界条件。

**📊 数据集**

主要使用公开的RPLAN住宅平面图数据集；此外在OOD评估中使用由RPLAN派生的drift数据集和20个手工生成的synthetic样例。

**📈 对比分析**

与HD、Graph2Plan、Cons2Plan等基线相比，BCA模型在Boundary Compatibility (BC)上获得0.04的最低分，说明边界符合度最佳；在FID、GC上表现与基线相近。DS表明训练越久FID下降越多，但DS下降，显示现实与多样性存在权衡。

**⚠️ 局限性**

主要局限包括：1）训练过程中容易出现模式坍塌，导致多样性下降；2）对边界条件的依赖使模型在缺失或错误边界时性能不稳定；3）OOD实验表明模型对训练分布的强烈依赖，难以直接推断复杂几何（如五边形房间），需要更强的几何推理能力。

---

## 629. A Unified Control Architecture for Macro-Micro Manipulation using a Active Remote Center of Compliance for Manufacturing Applications

**arXiv ID:** 2602.01948 | [PDF](https://arxiv.org/pdf/2602.01948v1)

**作者:** Patrick Frank `[一作]` (Hochschule Karlsruhe), Christian Friedrich `[通讯]` (Hochschule Karlsruhe)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种将宏观工业机器人主动融入微观高带宽末端执行器控制的宏微机械控制架构，并通过实验验证其在碰撞、力跟踪和装配任务中的性能提升。

**💡 创新点**

创新点在于将宏观机器人参与主动交互控制、构造可插拔的代理模型以简化控制器设计，并在控制器合成中采用H∞方法实现带宽和稳定性优化。

**🔧 技术方法**

主要技术包括ARCC（主动远中心兼容）微执行器、虚拟弹簧/阻尼实现阻尼/阻力控制、H∞合成的增益设计、系统辨识与正弦扫频实验。

**📊 数据集**

数据集来自于实验室自制的工业机器人与ARCC组合，包含力/位移测量、环境刚度标定、3D打印碰撞块、插孔、齿轮和电路板装配任务的数据。

**📈 对比分析**

通过与传统的追随-跟随（LF）和仅使用机器人力控制（RB）方案比较，本文控制方案在力控制带宽上提升约2.1倍，整体任务时间缩短约30%至50%，且误差和RMSE均显著降低。

**⚠️ 局限性**

局限性包括在力轨迹切换时控制器相互抵消导致误差略增，未对多自由度姿态变化或重力补偿做充分验证，且对环境变化的自适应能力尚需进一步研究。

---

## 630. PIMCST: Physics-Informed Multi-Phase Consensus and Spatio-Temporal Few-Shot Learning for Traffic Flow Forecasting

**arXiv ID:** 2602.01936 | [PDF](https://arxiv.org/pdf/2602.01936v1)

**作者:** Abdul Joseph Fofanah `[一作]` (Griffith University), David Chen `[通讯]` (Griffith University)

**通讯引用:** 5885 | [OpenAlex ID](https://openalex.org/A5100675676)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `39fd911c-56a4-425d-a2f9-8038ad3b6e21` `5a41884c-404f-4688-a89c-aa238c10fe68` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了 MCPST，利用多相位共识与时空学习的多阶段框架，实现少样本交通流预测。

**💡 创新点**

核心创新包括：①三阶段物理信息化引擎（扩散、同步、谱嵌入）；②自适应相位共识融合机制；③结构化元学习策略以快速适应新城市；并给出了理论保证与误差界定。

**🔧 技术方法**

技术手段包括：物理动力学的扩散与耦合振荡同步模型、谱图嵌入、GNN‑LSTM‑Transformer 的多尺度时空编码、注意力加权共识融合、元学习（MAML/Reptile）与不确定性量化。

**📊 数据集**

实验使用四个真实交通传感器数据集：METR‑LA、PEMS‑BAY、Shenzhen 与 Chengdu。

**📈 对比分析**

与十四种基准方法（ST‑DTNN、ST‑GCN、DDGCRN、FOGS、ST‑GFSL、TransGTR、Cross‑IDR、STGP、DynAGS、PromptST 等）进行对比，MCPST 在 MAE 与 RMSE 上均提升 10–15% 以上，长时 horizon 上优势尤为明显。

**⚠️ 局限性**

局限性：对多相位参数调优依赖较大计算；在极端事件或异常交通场景下解释性仍有限；当前实现主要适用于固定窗口，尚未在更大规模网络或实时在线推理中验证效率与鲁棒性。

---

## 631. COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation

**arXiv ID:** 2602.01935 | [PDF](https://arxiv.org/pdf/2602.01935v1)

**作者:** Annabelle Sujun Tang `[一作]` (University of California), Hadi Esmaeilzadeh `[通讯]` (University of California)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种轻量级的多LLM协作编译框架，利用共享的MCTS树在优化过程中内生地完成LLM选择与编译器变换的联合决策。

**💡 创新点**

创新点在于将LLM路由嵌入MCTS树结构，使得多模型通过共享搜索历史和价值回传实现协作，无需外部控制器或显式通信。

**🔧 技术方法**

核心技术包括基于MCTS的搜索、模型感知的UCT策略、LLM生成的联合动作（变换+下一模型），以及基于回归检测的课程调整机制。

**📊 数据集**

使用了五个常见的深度学习模型层（自注意力、Mixture‑of‑Experts、Stable‑Diffusion自注意力、卷积、MLP）以及整体模型的端到端测试，全部在Intel Core i9 CPU上运行。

**📈 对比分析**

与单一大模型和单一小模型的基线相比，多LLM配置在所有基准上都取得更高的速度提升（CPU平均提升10.86×，GPU 30.05×），且在样本效率上有显著提升，且仅使用了23.9%的大模型调用。

**⚠️ 局限性**

局限性包括对目标硬件的依赖性（需依赖TVM的成本模型）、对LLM性能评估的间接性（不直接执行硬件），以及在极端搜索预算下可能仍需更大模型来避免退化。

---

## 632. Embedding Learning on Multiplex Networks for Link Prediction

**arXiv ID:** 2602.01922 | [PDF](https://arxiv.org/pdf/2602.01922v1)

**作者:** Orell Trautmann `[一作]` (University of Rostock), Clémence Réda `[通讯]` (Institut de biologie de l’Ecole normale supérieure)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

综述了多层网络嵌入学习在链路预测中的方法与挑战，系统性梳理了现有技术与评估流程。

**💡 创新点**

提出了基于表示与方法的两级分类体系，并给出了公平、可复现的评估规范和针对有向多层网络的新测试策略。

**🔧 技术方法**

涵盖了随机游走、矩阵分解、优化、聚合、图卷积网络（GraphSAGE、GAT、MGAT、CGNN等）及对抗学习等多种嵌入技术。

**📊 数据集**

主要引用公开的多层网络数据集（如跨社交平台网络、组织层蛋白质相互作用网络等），未引入专有数据集。

**📈 对比分析**

通过对比已有模型在AUROC、AUPRC等指标上的表现，并使用统一的评估流程验证，发现聚合方法表现最差，合作型嵌入（如MNE、MVE、MGAT）在多层链路预测中效果更好。

**⚠️ 局限性**

限制包括评估缺乏理论指导、数据集多样性不足、对有向网络的评估仍不完善，以及对加权多层网络的处理仍有限。

---

## 633. When Workout Buddies Are Virtual: AI Agents and Human Peers in a Longitudinal Physical Activity Study

**arXiv ID:** 2602.01918 | [PDF](https://arxiv.org/pdf/2602.01918v1)

**作者:** Alessandro Silacci `[一作]` (University of Lausanne), Maurizio Caon `[通讯]` (School of Management of Fribourg)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `5a41884c-404f-4688-a89c-aa238c10fe68` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在一项为期六个月的随机对照试验中，研究者比较了三种不同的同伴支持方式：单独锻炼、与人类同伴互相支持，以及与由大型语言模型驱动的虚拟锻炼伙伴（人类外观的SEPH、类人形网络的SEPC）互相支持，探讨它们对大学生日常步数及相关心理体验（社交存在感、工作联盟、内在动机等）的长期影响。

**💡 创新点**

创新点包括①首次在现实生活中将LLM（GPT‑4o）嵌入可持续的锻炼伙伴系统（SEP），②设计并实施了长达六个月的纵向实验，②系统性研究了外观（人类 vs. 赛博）对信任、真实感与动机的交互影响，③揭示了“伙伴悖论”（人类同伴更强社交存在感，AI同伴更可靠的工作联盟）这一新的人机互动机制。

**🔧 技术方法**

技术：iOS 移动应用 Excero，Apple HealthKit 进行步数采集；Firebase Cloud Messaging 负责推送；OpenAI GPT‑4o 生成对话与虚拟步数；后端数据库与 R 语言（线性混合效应模型、混合方差分析）用于数据分析。

**📊 数据集**

数据集：最初 280 名瑞士洛桑大学生，最终 128 名完成步数同步；每位参与者的每日步数（Apple HealthKit）作为主要行为指标；三轮问卷（IMI、SPS、WAI）以及 30 名参与者的半结构化访谈。

**📈 对比分析**

比较方法：线性混合效应模型检验步数随时间和条件的变化；混合方差分析评估心理变量的主效应与交互；配对 t 检验与 Tukey 校正进行事后比较；主题分析结合质性访谈验证量化结果。性能：步数上，无显著的长期提升差异；然而，AI同伴在维持工作联盟方面显著优于人类同伴（p<0.001），而人类同伴在社交存在感上显著优于两种 AI 同伴（p≈0.018）。

**⚠️ 局限性**

局限性：①样本仅为年轻学术人群，缺乏多样性，②六个月内高达 54% 的步数数据缺失导致样本量减半，③虚拟伙伴仅以文本聊天和简易卡通头像呈现，缺少更丰富的多模态交互，④仅使用步数作为行为指标，未包含心率、情绪等生理或生态瞬时评估，⑤对 AI 生成文本的安全性与准确性依赖人工监控，未来需加入自动安全过滤。

---

## 634. Data- and Variance-dependent Regret Bounds for Online Tabular MDPs

**arXiv ID:** 2602.01903 | [PDF](https://arxiv.org/pdf/2602.01903v1)

**作者:** Mingyi Li `[一作]` (University of Tokyo), Kenji Yamanishi `[通讯]` (University of Tokyo)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究在线马尔可夫决策过程的最佳两端算法，提供在对抗与随机两种环境下自适应的调度方法；

**💡 创新点**

首次提出同时满足一阶、二阶、路径长度及方差依赖的最佳两端上界；

**🔧 技术方法**

采用优化全局占用量、策略优化、OFTRL 与对数壁障正则化及自适应学习率等技术；

**📊 数据集**

无实际数据集，全部为理论分析与上界证明；

**📈 对比分析**

与现有方法相比，在所有复杂度度量上均实现了与下界匹配（或接近）的上界，性能优于以往的最佳两端算法；

**⚠️ 局限性**

对路径长度和周期因子 H 的取值仍存在非最优的常数/指数差距，未能完全消除这些限制。

---

## 635. Beyond Open Vocabulary: Multimodal Prompting for Object Detection in Remote Sensing Images

**arXiv ID:** 2602.01954 | [PDF](https://arxiv.org/pdf/2602.01954v1)

**作者:** Shuai Yang `[一作]` (Beihang University), Yunhong Wang `[通讯]` (Beihang University)

**通讯引用:** 13815 | [OpenAlex ID](https://openalex.org/A5115589096)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出RS-MPOD多模态提示框架，在遥感图像开词汇目标检测中实现文本、视觉和多模态提示的统一处理；

**💡 创新点**

创新点在于：①设计基于Deformable Attention的视觉提示编码器提取实例级外观特征；②构建跨模态融合模块，学习文本与视觉提示的联合表达；③采用三阶段训练策略解耦检测器与提示学习，提升稳定性；

**🔧 技术方法**

使用GroundingDINO作为骨干网络，视觉提示编码器采用Deformable Attention，跨模态融合采用单层多头交叉注意力；训练采用三阶段流程；

**📊 数据集**

训练集为LAE-1M（包括LAE-FOD与LAE-COD）；评估基准包括DIOR、DOTA‑v2.0、LAE‑80C、HRRSD、VisDrone、AI‑TOD、LEVIR以及SIMD、MVRSD、MAR20、FGSD2021等；

**📈 对比分析**

与GLIP、GroundingDINO、LAE‑DINO、OpenRSD等方法对比；在标准基准上文本提示可与GroundingDINO相当；视觉提示在跨数据集和细粒度场景中显著提升；混合提示在多数场景下取得最稳健性能；

**⚠️ 局限性**

局限性包括：单一视觉提示对类别多样性覆盖不足；多模态融合受文本语义不匹配影响；对实例提示质量和数量依赖较高；缺乏实时推理效率与硬件部署分析；

---

## 636. T-LLM: Teaching Large Language Models to Forecast Time Series via Temporal Distillation

**arXiv ID:** 2602.01937 | [PDF](https://arxiv.org/pdf/2602.01937v1)

**作者:** Suhan Guo `[一作]` (Nanjing University), Furao Shen `[通讯]` (Nanjing University)

**通讯引用:** 1826 | [OpenAlex ID](https://openalex.org/A5036608458)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `8d10c613-917e-4880-9716-17789f50e119` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5a41884c-404f-4688-a89c-aa238c10fe68` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76`

**🎯 论文内容**

提出了 T-LLM 框架，利用轻量级时间教师在训练阶段通过逆向蒸馏把时间序列预测能力迁移到通用大语言模型（LLM）中，并在推理时仅使用 LLM 进行预测。

**💡 创新点**

创新点包括：
- 逆向蒸馏（temporal distillation）将教师的预测行为直接“教授”给 LLM；
- 轻量级教师融合趋势建模（DLinear）与频域分析（FFT+谱投影），提供结构化时间监督；
- 仅在关键层（早期和后期）进行特征引导，避免过度对齐且降低计算成本；
- 预测长度条件下的频谱容量调度，提升不同时间跨度的泛化；
- 在不依赖大规模时间序列预训练的情况下，实现全射击、少量样本和零样本预测。

**🔧 技术方法**

使用技术：
- 预训练 GPT‑2 + LoRA 微调；
- 多头注意力编码输入序列；
- 轻量级教师：趋势分解 + 线性映射 + 频域谱投影 + 池化 + 归纳聚合；
- 蒸馏损失（教师/学生监督 + 模仿损失）和特征引导损失；
- 采用 L1/SMAPE/MASE 等多种损失与评估指标；
- Horizon‑conditioned DSP 及自适应频谱容量。

**📊 数据集**

实验数据集：
- 长期预测基准：ETTm1、ETTm2、ETTh1、ETTh2、Traffic、Electricity、Weather、ECL；
- 短期预测：M4（年、季、月、其他）
- 零样本跨疫情预测：流感与 COVID‑19（感染、死亡）
- 少样本实验：ETT 子集仅 10% 训练数据。

**📈 对比分析**

与多种基线（CALF、TimeLLM、GPT4TS、UniTime、PatchTST、iTransformer、FEDformer、TimesNet、DLinear、N‑HiTS、N‑BEATS 等）比较。T‑LLM 在大多数数据集与预测长度下获得最佳或第二最佳 MSE/MAE，零样本转移误差平均下降约 2.2%，在少样本设置也保持领先。相较于同类 LLM 方案，T‑LLM 既有更低的 FLOPs（≈0.94 G）又保持接近最优性能，显著提升推理效率。

**⚠️ 局限性**

局限性：
- 依赖教师模型的预测质量，教师误差会直接影响 LLM ；
- 目前仅在 GPT‑2 基础上验证，扩展到更大 LLM 需进一步研究；
- 训练过程仍需要额外的教师和引导模块，导致训练成本高于单纯轻量模型；
- 对极长时间跨度或极高维多变量序列的适应性尚未充分验证；
- 只针对数值时间序列，未讨论符号/文本时间序列混合情况；
- 需要手动设置一些超参数（λ、DSP 容量、引导层选择），对新任务可能需要调优。

---

## 637. Bayesian Integration of Nonlinear Incomplete Clinical Data

**arXiv ID:** 2602.01924 | [PDF](https://arxiv.org/pdf/2602.01924v1)

**作者:** Lucía González-Zamorano `[一作]` (Universidad Carlos III de Madrid), Carlos Sevilla-Salcedo `[通讯]` (Universidad Carlos III de Madrid)

**通讯引用:** 60 | [OpenAlex ID](https://openalex.org/A5030465880)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

提出了 BIONIC 框架，用贝叶斯生成-判别双潜在结构和稀疏先验整合多模态临床数据，能够处理视图级缺失并支持半监督学习，最终用于疾病预测。

**💡 创新点**

创新点在于：①将预训练嵌入作为视图并保持冻结，②在同一潜在空间中同时建模生成与判别任务以自然处理缺失；③使用稀疏 ARD 先验实现自适应模态与特征选择；④提供可解析的敏感度解释，将潜在重要性映射回嵌入乃至原始输入；⑤在低样本、严重缺失场景下实现半监督与传导学习。

**🔧 技术方法**

技术核心包括：贝叶斯多视图模型、线性生成-判别潜在结构、稀疏自动相关性判别(ARD)先验、变分推断（均值场）、预训练基础模型（如 MedicalNet、CLAM、BioBART、BulkRNA‑BERT）提供嵌入、以及基于线性路径的敏感度传播解释。

**📊 数据集**

使用了三组公开临床多模态数据集：MMIST（肾细胞癌，CT、MRI、WSI、基因突变、结构化临床数据），MOTUM（脑高分化胶质瘤/转移，四种 MRI + 临床指标），TCGA‑BRCA（乳腺癌，WSI、转录组、文本）。

**📈 对比分析**

与 12 种传统与深度多模态基线（MKL‑SVM、M‑PLS、M‑FA、LF‑SVM、CPM、TMC、CSMVIB、DeepIMV、RCML、TUNED 等）在 10‑折交叉验证下比较，评估指标为 AUC 与 BACC。BIONIC 在所有数据集上均取得最高或相近最高的 AUC，且在 BACC 上显著优于对手，尤其在 MMIST 的严重视图缺失和 MOTUM 的样本稀少情形下表现最为突出；在半监督与传导训练下进一步提升性能。

**⚠️ 局限性**

局限性包括：①依赖预训练嵌入的质量和表达能力；②若缺乏相应解码器，难以直接将解释映射回原始输入域；③未对时间序列或纵向数据建模；④解释性主要基于线性敏感度，需进一步验证临床意义。

---

## 638. VLM-Guided Experience Replay

**arXiv ID:** 2602.01915 | [PDF](https://arxiv.org/pdf/2602.01915v1)

**作者:** Elad Sharony `[一作]` (Technion), Shie Mannor `[通讯]` (Nvidia Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

在离线强化学习中使用冻结的视觉-语言模型对经验回放进行语义化优先级排序，从而提升样本效率和成功率。

**💡 创新点**

创新点在于将预训练的 VLM 作为经验评估器，直接在回放缓冲区提供语义优先级，摆脱传统 TD 错误或统计方法的限制。

**🔧 技术方法**

利用冻结的 Perception‑LM（1B 参数）视频问答模型、异步推理架构、混合采样策略和可插拔优先级层。

**📊 数据集**

在离散的 ProcGen GridWorld（8×8、12×12、16×16）和连续的 OGBench 机器人操作（任务 3/4/5）上进行实验。

**📈 对比分析**

与 Uniform Replay、Prioritized Experience Replay、AER、ERO、ReLo 等基线相比，平均成功率提升 11–52%，样本效率提升 19–45%，在最难任务上成功率提升可达 241%。

**⚠️ 局限性**

依赖可视化语义，无法应用于无视觉输入或视觉与任务无关的场景；VLM 推理引入 12% 的吞吐量开销。

---

## 639. LipSody: Lip-to-Speech Synthesis with Enhanced Prosody Consistency

**arXiv ID:** 2602.01908 | [PDF](https://arxiv.org/pdf/2602.01908v1)

**作者:** Jaejun Lee `[一作]` (Seoul National University), Kyogu Lee `[通讯]` (Seoul National University)

**通讯引用:** 1941 | [OpenAlex ID](https://openalex.org/A5088852010)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出 LipSody，一个基于扩散模型的唇读语音合成框架，专注于提升语音的韵律一致性。

**💡 创新点**

创新点：①将说话人身份、语义内容和情绪三种视觉信号统一用于韵律（音高、能量）预测；②在扩散生成阶段直接注入预测韵律特征；③通过情绪编码提升细粒度韵律把控。

**🔧 技术方法**

技术：扩散概率模型（DDPM）+ 变分条件生成；CFG 与 CG 指导；Speaker Encoder（ResNet‑18）、Content Encoder（3D Conv）、Emotion Encoder（EmoCLIP）；韵律预测网络（自注意力 + FFN）；FCPE 音高提取、能量提取；HiFi‑GAN 语音合成器。

**📊 数据集**

数据集：LRS3（TED/TEDx 视频，约 430 小时，语音 16kHz、视频 25fps），使用官方未见说话人评估协议。

**📈 对比分析**

比较方法：与 LipVoicer 官方版及公开实现对比，使用 WER、STOI、DNSMOS、LSE-D/C 等传统指标及 GF_0、LF_0、EC、Resemblyzer 等韵律指标。结果显示：在传统指标上与 LipVoicer 差异不显著，但在所有韵律指标上显著提升（p<0.01），ABX 主观评测韵律一致性上亦高于基线。

**⚠️ 局限性**

局限性：①对视觉输入的依赖使得在低质量或缺失唇部信息的场景下表现受限；②模型仍保持与基线相当的可懂度，尚未在语音质量上显著超越；③训练与推理成本较高，需大规模预训练模型和 GPU。

---

## 640. DSXFormer: Dual-Pooling Spectral Squeeze-Expansion and Dynamic Context Attention Transformer for Hyperspectral Image Classification

**arXiv ID:** 2602.01906 | [PDF](https://arxiv.org/pdf/2602.01906v1)

**作者:** Farhan Ullah `[一作]` (Gachon University), JaKeoung Koo `[通讯]` (Gachon University)

**通讯引用:** 443 | [OpenAlex ID](https://openalex.org/A5047917337)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种用于高光谱图像分类的DSXFormer模型。

**💡 创新点**

创新点在于双池化谱压缩-扩展（DSX）模块与动态上下文注意力（DCA）结合，既提升了谱特征辨别，又降低了计算成本。

**🔧 技术方法**

使用了Transformer架构、双池化谱压缩-扩展、窗口式动态上下文注意力、MLP、Patch提取/嵌入/合并等技术。

**📊 数据集**

在Salinas、Indian Pines、Pavia University和Kennedy Space Center四个公开数据集上进行实验。

**📈 对比分析**

与传统SVM、CNN、GCN以及SwinT、PyFormer、PMCN等SOTA方法对比，DSXFormer在OA、AA和Kappa均取得最高或接近最高的准确率（如SA 99.95%、IP 98.91%、PU 99.85%、KSC 98.52%）。

**⚠️ 局限性**

局限性在于固定的patch基令化方式对高度异质场景适应性不足，对极少样本类仍有一定误差，且对时间序列或半监督学习尚未覆盖。

---

## 641. Observation-dependent Bayesian active learning via input-warped Gaussian processes

**arXiv ID:** 2602.01898 | [PDF](https://arxiv.org/pdf/2602.01898v1)

**作者:** Sanna Jarl `[一作]` (Uppsala University), Jens Sjölund `[通讯]` (Uppsala University)

**通讯引用:** 1008 | [OpenAlex ID](https://openalex.org/A5032491456)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种基于输入空间单调重参数化的贝叶斯主动学习框架，通过动态调整输入几何来让基于方差的采集函数对观测数据产生反馈。

**💡 创新点**

创新点在于将输入几何与预测模型解耦；利用条件有理二次样条 (C‑RQS) 对输入进行可学习的单调变形；并引入自监督几何目标而非传统的边际似然来训练重参数化，从而显著提升采样效率。

**🔧 技术方法**

核心技术包括：Gaussian Process（Matern‑5/2 核），条件有理二次样条输入流（C‑RQS），自监督负对数似然损失，贝叶斯信息增益（BALD）采集函数，PyTorch/GPyTorch 实现。

**📊 数据集**

数据集涵盖：二维/三维/四维的合成基准函数（Gramacy‑Lee08、Peaks、Box、Hartmann），以及两组光致发光 (photoluminescence) 的实测太阳能电池表面属性数据。

**📈 对比分析**

与未变形 GP、全局 Kumaraswamy 变形以及用边际似然训练的 C‑RQS 进行对比。自监督训练的 C‑RQS 在 MSE、CRPS 等指标上平均可提升 20–60%（如 4‑D Hartmann 的 MSE 降幅约 5%），在早期采样阶段已有显著优势，整体曲线下积分面积大幅缩小。

**⚠️ 局限性**

局限性包括：仅适用于低维 (≤4) 或稀疏数据场景；对高维空间或断裂函数的建模效果有限；warp 参数需要大量数据才能在高维中学习到有效几何变形。

---

## 642. Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation

**arXiv ID:** 2602.01965 | [PDF](https://arxiv.org/pdf/2602.01965v1)

**作者:** Kwun Hang Lau `[一作]` (Huawei Hong Kong Research Center), Xiaofang Zhou `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 23921 | [OpenAlex ID](https://openalex.org/A5011384237)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 CatRAG 框架，通过在 HippoRAG 2 的知识图谱上引入上下文感知的随机游走，实现多跳检索的精确导航。

**💡 创新点**

创新点包括：符号锚定、查询感知的动态边权重以及关键事实 passage 权重增强，有效缓解了静态图结构导致的语义漂移和 hub 偏差。

**🔧 技术方法**

技术核心是基于知识图谱的 Personalized PageRank，结合 LLM 对边的语义评估动态调整权重，并在检索前对图进行结构优化。

**📊 数据集**

使用 MuSiQue、2WikiMultiHopQA、HotpotQA 和 HoVer 四个公开多跳问答/事实验证基准。

**📈 对比分析**

与 BM25、Contriever、GTR、text‑embedding‑3‑small 等稠密检索以及 RAPTOR、LightRAG、HippoRAG 2 等结构化检索对比，CatRAG 在 Recall@5、F1、FCR、JSR 上均优于所有基线，尤其在 HoVer 的 3‑4 跳验证任务上提升显著。

**⚠️ 局限性**

主要局限是需要在运行时调用 LLM 进行动态边权评估，增加计算成本；且实验使用的是中等规模嵌入模型，未探索与更大模型结合的上限。

---

## 643. Role of CI Adoption in Mobile App Success: An Empirical Study of Open-Source Android Projects

**arXiv ID:** 2602.01957 | [PDF](https://arxiv.org/pdf/2602.01957v1)

**作者:** Xiaoxin Zhou `[一作]` (University of Toronto), Safwat Hassan `[通讯]` (University of Toronto)

**通讯引用:** 474 | [OpenAlex ID](https://openalex.org/A5022060601)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

研究了在 2,542 个开源 Android 项目中 CI 采用对开发活跃度、发布速度以及 Google Play 上的下载与评论等用户交互指标的关联。

**💡 创新点**

创新点在于提供公开的 CI‑开源数据集，使用随机森林与 k‑means 模型分别揭示 CI 采用模式与 bug 密度的关系，并识别三类后续 CI 采纳轨迹，阐明 CI 并未必提升用户评分但能提升下载量。

**🔧 技术方法**

使用统计检验（Mann–Whitney、配对 t 检验）、随机森林分类、k‑means 聚类以及回归分析，结合 GitHub REST API 与 Google Play Store 爬虫获取指标。

**📊 数据集**

基于 2,542 个 Android 开源仓库（1,111 个 CI 采用者、1,431 个非采用者），并进一步关联 Google Play 上的下载、评分与评论数据。

**📈 对比分析**

通过对比 CI 与非 CI 项目以及 CI 采纳前后 90 天的指标，发现 CI 项目发布频率提升 41%（p<0.001），下载量平均提升 400%，但 Google Play 评分差异不显著；用户评论数量提升 122%。

**⚠️ 局限性**

局限在于仅覆盖 Android 开源项目，CI 采用状态仅依据配置文件推断，缺乏因果性验证；用户交互指标易受外部营销、内容差异等多重因素影响。

---

## 644. Deep Multivariate Models with Parametric Conditionals

**arXiv ID:** 2602.01953 | [PDF](https://arxiv.org/pdf/2602.01953v1)

**作者:** Dmitrij Schlesinger `[一作]` (Dresden University of Technology), Alexander Shekhovtsov `[通讯]` (Czech Technical University in Prague)

**通讯引用:** 779 | [OpenAlex ID](https://openalex.org/A5068080640)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于每个变量条件分布的深度多变量模型，并通过训练参数化的马尔可夫链核使其收敛到目标联合分布，从而实现半监督学习与多任务推理；

**💡 创新点**

创新点在于用条件分布定义联合分布，并通过优化限制分布的似然下界来逼近其极限分布，从而同时保证模型一致性与可复用性；

**🔧 技术方法**

采用参数化马尔可夫链核、变分下界、EM式优化、深度网络实现条件分布以及MCMC采样与自适应链长度控制；

**📊 数据集**

实验使用MNIST、Fashion MNIST、CelebA‑HQ图像数据以及简易Ising模型；

**📈 对比分析**

与VAE、对称学习等方法对比，生成质量（FID）略低或相当，但在多任务推理、条件生成和一致性方面优于对手；

**⚠️ 局限性**

局限在于链收敛速度与链长选择的权衡、对细节平衡的偏好、模型表达力受限以及对连续空间唯一极限分布的假设。

---

## 645. Enabling Progressive Whole-slide Image Analysis with Multi-scale Pyramidal Network

**arXiv ID:** 2602.01951 | [PDF](https://arxiv.org/pdf/2602.01951v1)

**作者:** Shuyang Wu `[一作]` (University of Edinburgh), Timothy J Kendall `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `729e5870-4135-47f5-97f2-e3974d07b5dc` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出一种可插拔的多尺度金字塔网络（MSPN），利用高倍特征生成低倍上下文，改进多实例学习（MIL）在全切片图像上的多尺度分析；

**💡 创新点**

创新点在于：①基于网格的重映射（grid‑based remapping）仅使用高倍特征构造粗粒度特征图；②粗引导网络（Coarse Guidance Network, CGN）通过卷积产生多尺度粗引导；③多层残差连接实现从粗到细的渐进多尺度学习；④仅需单一高倍输入即可，避免多尺度预处理与高成本。

**🔧 技术方法**

采用的技术包括：多尺度特征学习、网格重映射、残差连接的卷积网络、注意力‑基MIL（ABMIL、DSMIL、CLAM‑SB/MB）、预训练基础模型（CONCH、UNI2、GigaPath），并用AUC、C‑index评估性能。

**📊 数据集**

使用的公开数据集为 NIHR BioResource Breast Cancer（ER、PR、HER2 三种生物标志物）以及 SurGen 结直肠癌预后（Surv）数据集。

**📈 对比分析**

与传统多尺度拼接、交叉尺度注意力、TransMIL、HAG‑MIL 以及预训练MIL等方案进行对比。MSPN 在四个临床任务和三种基础模型上平均提升约 2.5%（AUC/C‑index），尤其 HER2 预测提升 4‑7%，同时参数量和 FLOPs 仅为原方法的约 20‑30%，显著降低计算成本。

**⚠️ 局限性**

局限性包括：目前仅针对轻量级注意力MIL框架验证，未探讨对 Transformer‑基框架的适用性；对多尺度位置信息的进一步提升空间；以及对不同基础模型的依赖程度需进一步评估。

---

## 646. Things that Matter -- Identifying Interactions and IoT Device Types in Encrypted Matter Traffic

**arXiv ID:** 2602.01932 | [PDF](https://arxiv.org/pdf/2602.01932v1)

**作者:** Kristopher Alex Schlett `[一作]` (Eindhoven University of Technology), Savio Sciancalepore `[通讯]` (Eindhoven University of Technology)

**通讯引用:** 1589 | [OpenAlex ID](https://openalex.org/A5088679207)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `3855fcda-48ef-4070-a15e-803cd5c84d83` `9cc9baba-5356-466d-81ff-d80028d90279` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

对Matter标准的加密流量进行被动流量分析，识别交互类型（Read/Write/Invoke/Report）和设备类型（灯、锁、插座、传感器）

**💡 创新点**

首次系统性揭示Matter加密流量的可识别模式和设备指纹，证明即使在应用层使用AES‑CCM加密时也能泄露隐私，且提出基于长度和序列的攻击模型

**🔧 技术方法**

利用数据包长度、方向和时间窗序列特征提取，构建规则库并使用打分函数进行分类，辅以重传过滤和时间同步等预处理技术

**📊 数据集**

收集了三种环境（E1办公、E2家庭、E3仿真）产生的PCAP与日志数据，构成四个数据集D0–D3，覆盖真实设备与仿真交互

**📈 对比分析**

通过准确率、召回率、精确率和F1值评估，正常条件下交互识别精度>99.8%，设备类型识别>87%；在10%丢包或延迟下仍保持>90%性能，验证方法鲁棒性

**⚠️ 局限性**

仅覆盖四种设备类型，未评估错误响应、非默认加密或多协议层的协同攻击；假设攻击者已获取网络层解密密钥，实际环境中可能受限

---

## 647. PIMPC-GNN: Physics-Informed Multi-Phase Consensus Learning for Enhancing Imbalanced Node Classification in Graph Neural Networks

**arXiv ID:** 2602.01920 | [PDF](https://arxiv.org/pdf/2602.01920v1)

**作者:** Abdul Joseph Fofanah `[一作]` (Griffith University), David Chen `[通讯]` (Griffith University)

**通讯引用:** 5885 | [OpenAlex ID](https://openalex.org/A5100675676)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出一种结合热扩散、Kuramoto 同步和谱嵌入的多物理一致学习框架 PIMPC-GNN，用于解决图神经网络中的节点分类不平衡问题。

**💡 创新点**

创新点在于：①三阶段多物理融合（热扩散、同步、谱）并通过自适应加权实现一致性；②引入物理约束损失与自适应阈值，形成可解释的少数类增强机制；③在多物理视角下设计的自适应阈值和置信加权，提升少数类召回与整体准确率。

**🔧 技术方法**

采用图神经网络基础结构，分别实现热扩散模拟、Kuramoto 同步动力学、谱嵌入编码，并通过自适应融合、置信加权、阈值学习等技术实现多物理一致推理；训练时使用平衡交叉熵与物理一致性损失的加权组合。

**📊 数据集**

在五个工业与学术基准图数据集上评估：Cora、Citeseer、Amazon‑Photo、Amazon‑Computers、Chameleon，涵盖同质与异质网络，并设置不同的不平衡比例（5–100）。

**📈 对比分析**

与 16 种最先进方法（如 GraphSMOTE、GATE‑GAT、NodeImport 等）进行对比，PIMPC‑GNN 在平衡准确率、宏 F1、少数类召回上均获得显著提升，最优提升幅度可达 +11.6%（bAcc）和 +19.7%（bAcc）等；在极端不平衡（1:100）下也保持高 F1 与召回，表明方法稳定可靠。

**⚠️ 局限性**

局限性包括：①模型参数与计算量相对较大，推理与训练 FLOPs 较高；②当前仅适用于静态图结构，难以直接处理动态图；③对物理参数的手工设定和模型规模仍需进一步自动化与可扩展化。

---

## 648. Multi-Task Learning for Robot Perception with Imbalanced Data

**arXiv ID:** 2602.01899 | [PDF](https://arxiv.org/pdf/2602.01899v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7`

---

## 649. ForSim: Stepwise Forward Simulation for Traffic Policy Fine-Tuning

**arXiv ID:** 2602.01916 | [PDF](https://arxiv.org/pdf/2602.01916v1)

**作者:** Keyu Chen `[一作]` (Tsinghua University), Sifa Zheng `[通讯]` (Tsinghua University)

**通讯引用:** 803 | [OpenAlex ID](https://openalex.org/A5036282981)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了ForSim，一种逐步闭环前向仿真框架，用以提升交通仿真中的多模态交互真实性。

**💡 创新点**

创新点在于结合轨迹对齐前向回放与逐步预测，既保持多模态一致性又实现闭环交互，并与RIFT的群组相对优化结合。

**🔧 技术方法**

采用IL预训练+RL微调的交通策略、PID+运动学双向循环、Transformer解码器生成多模态轨迹，以及基于物理动力学的前向仿真。

**📊 数据集**

使用CARLA仿真环境，基于nuPlan等真实驾驶数据进行IL训练与评估。

**📈 对比分析**

与RIFT、Pluto、FREA等基线对比，ForSim在安全性（CPK、TTC、ACT）上显著下降，保持甚至提升效率、逼真度与舒适度。

**⚠️ 局限性**

仍受限于预测模型的精度与计算开销，且在极端复杂场景下可能出现轨迹漂移。

---

## 650. DomusFM: A Foundation Model for Smart-Home Sensor Data

**arXiv ID:** 2602.01910 | [PDF](https://arxiv.org/pdf/2602.01910v1)

**作者:** Michele Fiori `[一作]` (University of Milan), Claudio Bettini `[通讯]` (University of Milan)

**通讯引用:** 6887 | [OpenAlex ID](https://openalex.org/A5010533347)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文提出并评估了一种专门针对智能家居二值传感器事件的基础模型，能够在多种公开数据集上进行自监督预训练，并在活动识别与未来事件预测任务中实现快速迁移；

**💡 创新点**

创新点包括：①首次在多样化的智能家居数据上以大规模预训练方式构建专用基础模型；②采用两阶段自监督对比学习，既捕获事件级语义特征，又学习序列级时间依赖；③模型体量轻量化（<500 MB），可直接在边缘设备上部署，兼顾隐私与低延迟；

**🔧 技术方法**

技术方法涵盖：事件级特征提取器（语义编码器、状态编码器、时间编码器）+自注意力聚合；上下文化事件特征提取器（Transformer Encoder）；双对比损失（属性级与事件级）；下游任务使用线性头；对比实验使用GPT‑2、DeepCASAS、零样本LLM等基线；

**📊 数据集**

预训练与评估所用数据集为：CASAS Aruba、CASAS Milan、van Kasteren A、van Kasteren C、UCI B、Orange4Home、MuRAL；采用留一数据集交叉验证，确保模型在全新环境中的泛化；

**📈 对比分析**

比较方法为留一数据集、5%–30%标注数据的离线微调与评估；在ADL识别任务中，模型的加权F1均高于DeepCASAS基线约5–20个百分点；在next‑k事件预测任务中，F1比GPT‑2基线高10–30个百分点；推理时间仅约10 ms，内存占用<500 MB；

**⚠️ 局限性**

局限性包括：①仅验证单人/完美数据关联场景；②需要将连续传感器先二值化，可能丢失细粒度信息；③目前不支持零样本推理；④仅评估ADL识别与未来事件预测两项任务，未覆盖异常检测等；⑤多入住者情境下的身份关联仍待解决。

---

## 651. Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model

**arXiv ID:** 2602.01901 | [PDF](https://arxiv.org/pdf/2602.01901v1)

**作者:** Jiedong Zhuang `[一作]` (Zhejiang University), Haoji Hu `[通讯]` (Zhejiang University)

**通讯引用:** 970 | [OpenAlex ID](https://openalex.org/A5017732456)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

本文研究多模态大语言模型（MLLM）在解码阶段的注意力冗余，并提出一种跨层共享的轻量级缓存（Q Cache）和Lazy Attention机制，显著减少KV缓存占用与计算量；

**💡 创新点**

创新点在于：①发现解码层之间的注意力分布高度相似，能够在层级上共享；②设计Q Cache将共享的Query与Key缓存下来，形成可复用的Lazy Attention；③提供全局（GLA）与视觉专用（VLA）两种模式，并保持与Flash Attention及KV Cache的兼容性；

**🔧 技术方法**

采用Jensen‑Shannon相似度分析构造Lazy Block；使用Q Cache缓存Query/Key；实现GLA/VLA两种Lazy Attention；在LLaVA系列模型上结合Flash Attention、KV Cache等基础框架；

**📊 数据集**

使用多模态评测集：GQA、VQA、TextVQA、VizWiz、AI2D、SQA、MMMU、MMB、COCO、NoCaps、Flickr30K 等；

**📈 对比分析**

与FastV、VTW、HiRED、PruMerge+、SparseVLM等token‑pruning方法对比；VLA在大多数数据集保持或略降精度，KV缓存减少≈35%，吞吐量提升1.5–1.6倍，FLOPs与Latency显著下降；同时能与token‑pruning组合，兼容性好；

**⚠️ 局限性**

局限性：依赖层间注意力相似性，若相似度不足效果受限；GLA对文本注意力差异敏感，性能不如VLA；对视觉Token较多的模型效果更好，文本Token占比较高时收益有限；需要额外实现Lazy Block与Q Cache；未在极端长文本生成场景下做充分评估；

---

## 652. Beyond Local Edits: Embedding-Virtualized Knowledge for Broader Evaluation and Preservation of Model Editing

**arXiv ID:** 2602.01977 | [PDF](https://arxiv.org/pdf/2602.01977v1)

**作者:** Shuainan Liu `[一作]` (University of Chinese Academy of Sciences), Le Sun `[通讯]` (Chinese Information Processing Laboratory Institute of Software Chinese Academy of Sciences)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出基于嵌入空间的知识编辑评估框架 EVK-Bench，并给出了无标注的 Embedding Stability 与 Text Stability 指标。

**💡 创新点**

创新点在于通过可控扰动在嵌入空间虚拟化知识点，扩展评估覆盖范围，并引入 EVK-Align 约束限制编辑在嵌入空间的漂移。

**🔧 技术方法**

主要技术包括嵌入级扰动、top-k KL 对齐、Locate‑Then‑Edit 参数更新以及基于 FFN 的记忆机制。

**📊 数据集**

使用的基准数据集为 Counterfact、ZsRE 以及自建的 EVK‑Bench（6,000 条嵌入样本），并在 GPT‑2‑XL、LLaMA‑3‑8B 与 GPT‑J 上进行实验。

**📈 对比分析**

与现有 LTE 方法（ROME、MEMIT、PRUNE、RECT、AlphaEdit）对比，EVK‑Edit 在标准指标上保持或提升 Efficacy 与 Specificity，并在 EVK‑Bench 的 ES/TS 指标上显著优于对手。

**⚠️ 局限性**

局限性包括对超参数（σ、λ、N、top‑k）的敏感性，以及评估仍局限于前向嵌入，未覆盖后向传播或跨模态知识。

---

## 653. Your AI-Generated Image Detector Can Secretly Achieve SOTA Accuracy, If Calibrated

**arXiv ID:** 2602.01973 | [PDF](https://arxiv.org/pdf/2602.01973v1)

**作者:** Muli Yang `[一作]` (Institute for Infocomm Research), Hongyuan Zhu `[通讯]` (Institute for Infocomm Research)

**通讯引用:** 4193 | [OpenAlex ID](https://openalex.org/A5015639955)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `8f4a6f4b-054d-462c-afe4-56ebc0388d1a` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文针对 AI 生成图像检测器在分布漂移下普遍误将假图像判为真图像的问题，提出了一种基于贝叶斯决策理论的后置标量校准方法，通过学习一个可调的偏置校正网络输出的 logits，从而无需重新训练即可实时调整决策边界；

**💡 创新点**

创新点在于：①从理论角度阐明标签先验和条件输入漂移导致的阈值偏移，并证明可通过一个全局标量偏置逼近 Bayes 最优边界；②提出两种校准方式（有监督 KDE 最大化准确率，及无监督对称性平衡），两者均仅需极少（甚至无标签）目标域样本；

**🔧 技术方法**

使用技术包括贝叶斯决策理论、logit 线性校准、核密度估计（KDE）以及基于分布对称性的一阶矩平衡优化；

**📊 数据集**

实验数据集涵盖 AIGCDetectBenchmark（16 生成模型，真实图来自 LSUN，训练假图 ProGAN）与 GenImage（ImageNet 1000 类，8 大 SOTA 生成器），并在若干公开基线检测器上进行验证；

**📈 对比分析**

通过在九个现有检测器上叠加校准模块，实验显示平均提升 5‑15% 的准确率，尤其在 JPEG 压缩、少量验证样本（10–100 张）和扰动场景下显著超越传统阈值或其它校准估计方法；

**⚠️ 局限性**

局限性包括：假设假图像分布漂移近似恒定，若漂移幅度大或 logits 不是双峰分布时校准效果下降；需至少少量目标域样本；目前仅适用于二分类场景，未考虑多类别或跨模态情况。

---

## 654. Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition

**arXiv ID:** 2602.01967 | [PDF](https://arxiv.org/pdf/2602.01967v1)

**作者:** Wonjun Lee `[一作]` (POSTECH), Gary Geunbae Lee `[通讯]` (POSTECH)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `afceb026-1760-41ae-8d86-010831a37d97` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了一种Mixture-of-Experts架构Moe-Ctc，通过专家级CTC监督实现对口音鲁棒的自动语音识别。

**💡 创新点**

创新点在于将中间CTC监督与Mixture-of-Experts结合，利用两阶段训练让专家在口音识别质量上对齐，并实现无需测试时口音标签的推理。

**🔧 技术方法**

技术包括FastConformer编码器、序列级Mixture-of-Experts、专家级CTC头、Accent-aware/agnostic路由、两阶段训练、top‑K稀疏激活。

**📊 数据集**

数据集为Mozilla CommonVoice的Mcv‑Accent基准，使用100h/600h训练集并在LibriSpeech‑960h上预训练。

**📈 对比分析**

与FastConformer、inter‑CTC、标准MoE、Accent‑Moe等基线比较，Moe‑Ctc在Seen/Unseen口音上相对WER降低29.3%/27.8%，在同参数规模下优于此前最佳模型。

**⚠️ 局限性**

局限性包括需在训练阶段标注口音、仅适用于单一口音边界、增加训练成本与推理延迟，且未在多语言或混合口音场景验证。

---

## 655. Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge Distillation

**arXiv ID:** 2602.01956 | [PDF](https://arxiv.org/pdf/2602.01956v1)

**作者:** Seonghyeon Park `[一作]` (Seoul National University), Taesup Kim `[通讯]` (Seoul National University)

**通讯引用:** 2406 | [OpenAlex ID](https://openalex.org/A5065728469)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `8d10c613-917e-4880-9716-17789f50e119` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出利用轻量级草稿模型在高效推理框架下估计大型语言模型的表观不确定性。

**💡 创新点**

创新点在于通过偏差-方差分解将草稿模型间的 Jensen–Shannon 散度作为方差、草稿混合与目标的 KL 散度作为偏差，并引入在线随机蒸馏（OSD）与数据多样化草稿（DDD）提升多样性。

**🔧 技术方法**

采用草稿模型、在线随机蒸馏、数据多样化草稿、Speculative Decoding、Jensen–Shannon 散度、KL 散度等技术实现低成本的不确定性估计。

**📊 数据集**

实验使用 GSM8K 数据集进行评估。

**📈 对比分析**

与 Deep Ensemble、TokUR、GKD、MiniLLM 等基线比较，RMSE 下降约 37%，Spearman 相关性提升至 0.916，Hallucination 检测 AUROC 与 TokUR 相当但推理成本显著降低。

**⚠️ 局限性**

局限性包括对草稿模型训练的依赖、对极大模型与极低容量草稿的适配性有限，以及不确定性估计在草稿与目标匹配度不足时可能失效。

---

## 656. Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy

**arXiv ID:** 2602.01939 | [PDF](https://arxiv.org/pdf/2602.01939v1)

**作者:** Yuxin He `[一作]` (Hong Kong University of Science and Technology), Qiang Nie `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 367 | [OpenAlex ID](https://openalex.org/A5039200446)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出探索与聚焦操控（EFM）问题，构建EFM-10基准并提出双臂主动感知（BAP）策略；

**💡 创新点**

首次系统化定义EFM任务、搭建多类别基准、利用非工作臂实现眼在手主动视觉、通过力感知实现柔性控制；

**🔧 技术方法**

使用主动视觉、力/扭矩感知、强化学习/模仿学习结合的Transformer/扩散模型；

**📊 数据集**

收集了1810条专家演示的BAPData数据集，覆盖EFM-10十项任务；

**📈 对比分析**

对比ACT、DP、GR‑MG、Pi‑0等代表性策略，BAP提升成功率至约60‑93%（依任务而定），力感知进一步提升细粒度任务成功率并降低力峰值；

**⚠️ 局限性**

仍受限于语言指令理解、空间感知/推理不足以及对极细粒度操作的适配，且BAP需要双臂机器人，未考虑单臂或高DoF颈部场景。

---

## 657. Internal Flow Signatures for Self-Checking and Refinement in LLMs

**arXiv ID:** 2602.01897 | [PDF](https://arxiv.org/pdf/2602.01897v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 658. Large Language Model and Formal Concept Analysis: a comparative study for Topic Modeling

**arXiv ID:** 2602.01933 | [PDF](https://arxiv.org/pdf/2602.01933v1)

**作者:** Fabrice Boissier `[一作]`, Irina Rychkova `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过比较基于大语言模型（GPT‑5）和基于正式概念分析（FCA）的CREA管道，评估两种方法在主题建模上的表现，并在两个小型领域数据集上进行实验。

**💡 创新点**

创新点在于首次将FCA作为可执行的主题建模方案与现代LLM进行系统对比，探讨它们在透明度、可复现性与主题质量方面的差异，并提供了对FCA参数选择与聚类平衡的实证分析。

**🔧 技术方法**

技术手段包括：FCA（采用CREA pipeline、BabelFy命名实体链接、概念闭包与层次聚类）以及LLM推理（GPT‑5零样本提示，分批生成、合并与标签三步策略）。

**📊 数据集**

数据集包括：① 8门 PHP 课程教学材料（PDF/PowerPoint），② 40篇信息系统研究论文（摘要与全文）。

**📈 对比分析**

比较方法：在相同主题数量（k=8）下，评估主题词数量平衡、词汇重叠、主题标签可解释性，并使用聚类指标（Silhouette、Calinski‑Harabasz、Davies‑Bouldin）对FCA结果进行定量评估。实验显示，LLM 在主题均衡性与语义连贯性上表现优于FCA，但FCA 在透明度和可复现性方面更好。FCA 仍存在聚类失衡与计算成本高的问题。

**⚠️ 局限性**

局限性：FCA 需要手工调参且计算量大，聚类往往产生主导主题且难以平衡；LLM 受限于上下文窗口且结果缺乏可解释的内部机制，模型黑箱性质导致可复现性差，且可能受到预训练数据偏见。

---

## 659. From Code-Centric to Concept-Centric: Teaching NLP with LLM-Assisted "Vibe Coding"

**arXiv ID:** 2602.01919 | [PDF](https://arxiv.org/pdf/2602.01919v1)

**作者:** Hend Al-Khalifa `[一作]` (King Saud University), Hend Al-Khalifa `[通讯]` (King Saud University)

**通讯引用:** 4855 | [OpenAlex ID](https://openalex.org/A5063710079)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在一门面向高级本科生的自然语言处理课程中，设计并实施了“Vibe Coding”教学框架，学生使用大型语言模型（如ChatGPT、Claude、Gemini）进行代码生成，完成七个实验实验室，并通过记录提示日志与反思性评估来强化概念理解。

**💡 创新点**

创新点在于：①将LLM工具正式纳入课堂，鼓励学生作为“伙伴”生成代码；②通过强制记录提示日志激发学生对LLM交互的元认知；③将评估重点从代码质量转向反思与概念理解，实现AI辅助学习的目标导向转变。

**🔧 技术方法**

使用技术主要包括：大型语言模型（ChatGPT/Claude/Gemini）进行代码生成；在线笔记记录提示日志；Google Form收集反思问卷；以及对阿拉伯语PIQA数据集的翻译、预处理与模型训练。

**📊 数据集**

主要数据集包括：19名学生在七个实验室产生的代码与日志；项目阶段使用的阿拉伯语PIQA数据集（翻译后的文本）；以及课程结束时的问卷调查数据。

**📈 对比分析**

比较方式为学生问卷的定量评估与开放式反馈的定性分析。结果显示，课程总体满意度平均4.4/5，学生认为LLM使用降低了调试负担、提高了概念掌握，并认为反思评估更公平；但缺乏对照组与客观认知负荷测量，难以量化真正的学习提升。

**⚠️ 局限性**

局限性包括：样本量小（仅19人），仅单一机构的高年级本科生；缺乏对照实验与认知负荷指标；可能存在学生在反思答案中也使用LLM的风险；项目时间不足导致部分学生感到仓促；以及对阿拉伯语处理的特殊性和LLM可靠性的挑战。

---

## 660. GuideWeb: A Benchmark for Automatic In-App Guide Generation on Real-World Web UIs

**arXiv ID:** 2602.01917 | [PDF](https://arxiv.org/pdf/2602.01917v1)

**作者:** Chengguang Gan `[一作]` (Techtouch), Hiroki Itoh `[通讯]` (Techtouch)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 GuideWeb 基准并训练了 GuideWeb Agent，用于在真实网页 UI 上自动生成应用内引导（选择目标元素并生成对应文本）

**💡 创新点**

①创建了面向真实网页的指南生成基准；②将任务拆分为目标选择与文本生成两阶段；③提供了全面的评估方案；④设计了轻量级的 Shorter 机制来压缩输入

**🔧 技术方法**

LLM 辅助标注、LLM 代理模型、上下文压缩 Shorter、Fine‑tuning 生成模型；评估指标包括精度/召回/F1、BLEU、ROUGE‑L、结构化字段 exact‑match

**📊 数据集**

GuideWeb 数据集：从 Cisco Umbrella Top 1 000 域中采样 996 个主页面，标注了交互元素、指南目标和对应文本

**📈 对比分析**

与 GPT‑5、Claude Sonnet 4.5、Gemini 2.5 Pro、Qwen3‑8B、LLaMA 3.1‑8B 等通用 LLM 进行零‑shot 对比；GuideWeb Agent 在目标选择 F1 = 30.79% 最高，意图 BLEU = 44.94，指南 BLEU = 21.34，显著优于基线

**⚠️ 局限性**

仅覆盖主页面，未考虑多页/状态工作流；数据规模相对有限；模型未实现实时适配和交互式学习，无法随页面更新自动调整

---

## 661. FlyPrompt: Brain-Inspired Random-Expanded Routing with Temporal-Ensemble Experts for General Continual Learning

**arXiv ID:** 2602.01976 | [PDF](https://arxiv.org/pdf/2602.01976v1)

**作者:** Hongwei Yan `[一作]` (Tsinghua University), Yi Zhong `[通讯]` (Tsinghua University)

**通讯引用:** 304531 | [OpenAlex ID](https://openalex.org/A5100362465)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `afceb026-1760-41ae-8d86-010831a37d97` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种脑启发式的通用持续学习框架FlyPrompt，专门解决在无任务边界、单次通行的数据流中专家路由与专家能力提升的问题。

**💡 创新点**

创新点在于：①随机扩展解析路由器（REAR）以零梯度、一次性闭式方式实现实例级专家激活；②多时域EMA头集成实现专家决策的多尺度适应，模仿果蝇嗅觉记忆的多层可塑性。

**🔧 技术方法**

核心技术包括：预训练模型参数高效微调（Prompt、LoRA等）+随机投影+闭式岭回归路由 + 指数滑动平均EMA头 + 非参数logit遮罩。

**📊 数据集**

使用了CIFAR‑100、ImageNet‑R、CUB‑200三个公开数据集，在Si‑Blurry GCL设置下进行实验。

**📈 对比分析**

与多种基准（Seq‑FT、DualPrompt、MVP、MISA、S‑Prompt++等）对比，FlyPrompt在A_auc、A_last指标上分别提升了约11.2%、12.4%、7.6%（CIFAR‑100）、约13.5%、16.5%、12.3%（ImageNet‑R）、约11.6%、12.3%、9.3%（CUB‑200），并且参数占用仅比MISA少0.83%。

**⚠️ 局限性**

局限性包括：EMA头的衰减率固定，无法自适应数据漂移；对极端长尾分布的鲁棒性仍待提升；以及对多任务混合度高的GCL场景需要进一步验证。

---

## 662. IntraSlice: Towards High-Performance Structural Pruning with Block-Intra PCA for LLMs

**arXiv ID:** 2602.01975 | [PDF](https://arxiv.org/pdf/2602.01975v1)

**作者:** Meng Li `[一作]` (Nanjing University of Science and Technology), Jian Cheng `[通讯]` (Institute of Automation, Chinese Academy of Sciences)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了IntraSlice框架，通过在Transformer模块内部进行块级PCA压缩实现结构化剪枝，降低模型体量同时保持性能。

**💡 创新点**

创新点包括：①块级内部PCA压缩避免残差路径分布漂移；②自适应头部PCA压缩策略；③进化切片迭代PCA（IterPCA）降低FFN非线性压缩难度；④基于PCA的全局非均匀剪枝比例估计，结合激活分布信息。

**🔧 技术方法**

技术手段：PCA压缩、块级矩阵融合、梯度重要性评估、稀疏PCA校正、进化切片迭代优化、残差路径无额外参数融合。

**📊 数据集**

使用的基准数据集包括WikiText‑2（128样本校准）、C4（验证）以及llm‑eval‑harness的7个零样本任务（ARC‑c/e, WinoGrande, BoolQ, HellaSwag, OpenBookQA, PIQA）。

**📈 对比分析**

与SliceGPT、Wanda、FLAP、SVD‑LLM、SoBP、LLM‑surgeon、DISP‑LLM、týr‑the‑Pruner等方法对比，IntraSlice在相同稀疏率下PPL更低、零样本任务准确率更高，尤其在高稀疏率（≥30%）时优势显著；在速度/显存方面与现有最佳方法持平。

**⚠️ 局限性**

局限性：①进化切片迭代PCA在大模型上仍带来一定的剪枝时间开销；②对注意力变体（如GQA）需保持组内一致压缩，限制了剪枝灵活性；③在非线性模块中PCA求解仍不是最优，未来仍需改进。

---

## 663. Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models

**arXiv ID:** 2602.01970 | [PDF](https://arxiv.org/pdf/2602.01970v1)

**作者:** Yun Qu `[一作]` (Tsinghua University), Xiangyang Ji `[通讯]` (Tsinghua University)

**通讯引用:** 10833 | [OpenAlex ID](https://openalex.org/A5024401174)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `64443552-63e0-44b5-906f-d90fe95c5a1b` `d603a949-d0a9-40d8-bcb8-e02e842b97f2`

**🎯 论文内容**

提出了一种 Generalizable Predictive Prompt Selection (GPPS) 方法，利用轻量级生成式 PPM 结合批次多样性采样，显著提升 RLVR 训练效率，并在测试时实现计算分配。

**💡 创新点**

创新点包括：① 采用共享全局潜在变量的生成式 PPM 进行跨提示难度预测；② 将中间难度优先与历史 Anchored 多样性原则融入批次采样；③ 将训练时学习的难度模型用于测试时的计算分配。

**🔧 技术方法**

技术手段主要有：贝叶斯推断与变分推断的生成式 PPM；GRPO / PPO 等 RLVR 算法；成功率的 Spearman 相关评估；KL 正则化的梯度惩罚。

**📊 数据集**

使用的数据集包括 DeepScaler、AIME24、AMC23、MATH500、Minerva Math、OlympiadBench、MMLU-Pro、ARC-c、GPQA、Countdown‑34、Countdown‑4。

**📈 对比分析**

与 Uniform、MoPPS、PCL、GRESO、Dynamic Sampling（Oracle）等基线比较，GPPS 在训练步骤上提升 1.4–2.0×，在算力预算下可减少 69% rollouts，保持或提升准确率，并在 OOD 任务上表现更好。

**⚠️ 局限性**

局限性包括：对提示历史的依赖仍有限，潜在变量估计误差可能影响极端难度提示；在极大规模提示池下实时推断仍需进一步优化；在仅生成单一响应的 RL 方案中需改进模型适配。

---

## 664. Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding with Large Language Models

**arXiv ID:** 2602.01969 | [PDF](https://arxiv.org/pdf/2602.01969v1)

**作者:** Bin Cao `[一作]` (Zhejiang University of Technology), Jing Fan `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了 Orthogonal Hierarchical Decomposition (OHD) 框架，用于处理包含多级标题、合并单元格和不规则布局的复杂表格，提升大语言模型在表格理解与推理中的表现。

**💡 创新点**

创新点在于：① 将表格拆分为独立的列树与行树，采用空间‑语义协同的 Orthogonal Tree Induction (OTI) 进行树结构诱导；② 设计双路径关联协议，分别从列和行两轴提取语义线索；③ 通过 LLM 进行语义仲裁，合成结构化的自然语言表述。

**🔧 技术方法**

主要技术包括：Orthogonal Tree Induction（OTI）算法、双路径语义线性化（Dual‑Pathway Association）、基于 LLM 的语义仲裁（Semantic Arbitration）以及对数值与文本的统一处理。

**📊 数据集**

使用的数据集为 AITQA 与 HiTab（及其 50×50 限制子集），均包含多级标题、合并单元格和非标准布局。

**📈 对比分析**

与 Chain‑of‑Table、E5、ST‑RAPTOR、TableLLaMA 等基线对比，OHD 在 EM 与 LLM‑Eval 方面均领先 8–20 个百分点；在 AITQA 上 EM 达 69.34%，在 HiTab 上 EM 达 64.74%（使用 Qwen2‑72B 作为后端）。

**⚠️ 局限性**

局限性：目前主要针对中小规模表格；未结合视觉模态信息；对极大规模表格的可扩展性仍待研究；若不结合人工审核，仍可能出现结构误判导致错误推理。

---

## 665. Zero-Shot Off-Policy Learning

**arXiv ID:** 2602.01962 | [PDF](https://arxiv.org/pdf/2602.01962v1)

**作者:** Arip Asadulaev `[一作]` (MBZUAI), Martin Takac `[通讯]` (MBZUAI)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

本文提出一种零样本离线强化学习方法——ZOL，利用预训练的前向-后向(SM)表示推断可用于即时自适应的占比校正因子，从而在不进一步训练的情况下为任意新任务生成近最优策略。

**💡 创新点**

创新点在于将后继测度与稳定占比比率建立理论联系，证明前向-后向因子可低秩地估计任意目标策略的占比校正；并基于此设计了一种无交互、训练‑自由的自适应推理流程，显著提升零样本迁移性能。

**🔧 技术方法**

主要技术包括前向-后向（Forward‑Backward）SM低秩分解、DICE式占比校正、梯度上升优化任务潜在变量、软正则化与权重裁剪等。

**📊 数据集**

实验使用了 ExORL、OGBench、DeepMind Control（DMC）与 SMPL Humanoid 四大基准数据集，并在 AntMaze、Quadruped、Point‑Mass/Maze 等子环境中进行评估。

**📈 对比分析**

与现有 BFMs（FB、HILP、TD‑JEPA）、在线自适应方法（LoLA、ReLA）以及 DICE 系列算法相比，ZOL 在回报、成功率和鲁棒性上均取得明显提升，尤其在长周期稀疏奖励任务中表现最为突出。

**⚠️ 局限性**

局限性主要来自于前向-后向表示的可表达性与占比估计精度；当目标任务需要大量离开数据支持区域或 SM 分解失效时，校正可能导致过度保守或性能下降。

---

## 666. Grounding Generated Videos in Feasible Plans via World Models

**arXiv ID:** 2602.01960 | [PDF](https://arxiv.org/pdf/2602.01960v1)

**作者:** Christos Ziakas `[一作]` (Imperial College London), Alessandra Russo `[通讯]` (Imperial College London)

**通讯引用:** 7743 | [OpenAlex ID](https://openalex.org/A5046462940)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ba576bd1-e51d-44e8-8077-fc943b333c93` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种基于世界模型的推理方法GVP-WM，在测试时将视频生成的计划投影到可行的动作序列中，解决视频计划中物理不一致和时间不连续的问题。

**💡 创新点**

创新点在于：①将视频计划作为语义先验，采用视频引导的隐状态共轭（latent collocation）同时优化隐状态与动作；②通过增量拉格朗日方法实现动态约束与视频对齐的多目标优化；③实现零样本（zero-shot）与域自适应两种视频计划的即时落地。

**🔧 技术方法**

使用的技术包括：动作条件的世界模型（encoder–latent dynamics），DINOv2冻结视觉编码器，扩散模型生成视频计划（Wan2.1-FLF2V-14B），增量拉格朗日优化（ALM），模型预测控制（MPC）与局部采样细化。

**📊 数据集**

数据集主要有：Push‑T和Wall这两种基于仿真的长时序任务；以及100条任务特定示例（𝔇_demo）用于LoRA微调视频模型；在实验中还使用了清晰与模糊（motion blur）的视频计划。

**📈 对比分析**

与不使用视频计划的MPC-CEM、MPC-GD以及直接逆动力学的UniPi进行对比。GVP‑WM在多种规划长度下均显著提升成功率（如Push‑T T=50从0.32提升至0.30；Wall T=50从0.04提升至0.18），且规划时延比MPC-CEM低1–2倍；在模糊视频下仍保持高成功率，而UniPi则几乎失效。

**⚠️ 局限性**

局限性包括：①依赖已训练的世界模型，若模型与真实环境差异过大仍可能生成不可行计划；②优化过程需迭代计算，实时性受限；③对极端无效或高度错误的视频计划仍可能无法完全纠正，性能仍低于在分布内的专家视频。

---

## 667. Human Society-Inspired Approaches to Agentic AI Security: The 4C Framework

**arXiv ID:** 2602.01942 | [PDF](https://arxiv.org/pdf/2602.01942v1)

**作者:** Alsharif Abuadbba `[一作]` (CSIRO Data61), Sanjay Jha `[通讯]` (University of New South Wales)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

本文提出了面向多智能体AI安全的4C框架，系统化地从核心、连接、认知和合规四个层面分析agentic AI的安全风险并给出相应对策；

**💡 创新点**

创新点在于将安全视角从单一模型/系统扩展到具备自治、交互和社会治理特征的多智能体生态，借鉴人类社会治理理念构建四层防御模型；

**🔧 技术方法**

主要技术包括大型语言模型（LLM）驱动的agentic工作流、工具调用与API交互、分布式多智能体架构（如LangGraph、Agent2Agent）、以及基于策略、治理和合规的约束机制；

**📊 数据集**

该研究为概念性框架，无使用具体数据集；

**📈 对比分析**

本文未给出实验比较或性能评估，主要通过案例分析与对比阐述4C层面风险与已有安全框架的差异；

**⚠️ 局限性**

局限性在于缺乏量化验证与基准测试，框架尚未在真实系统中实施，如何在实践中度量、监控和约束智能体的信念、目标和行为仍需后续研究。

---

## 668. Towards Long-Horizon Interpretability: Efficient and Faithful Multi-Token Attribution for Reasoning LLMs

**arXiv ID:** 2602.01914 | [PDF](https://arxiv.org/pdf/2602.01914v1)

**作者:** Wenbo Pan `[一作]` (City University of Hong Kong), Xiaohua Jia `[通讯]` (City University of Hong Kong)

**通讯引用:** 19154 | [OpenAlex ID](https://openalex.org/A5013643572)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种高效的多标记归因方法，旨在解决推理大型语言模型（LLM）输出的可解释性问题。

**💡 创新点**

创新点在于结合了区间聚合和递归归因机制，能够在单次传递中高效计算多标记目标的归因，同时保持归因的真实性。

**🔧 技术方法**

使用了区间聚合和递归归因技术。

**📊 数据集**

使用了RULER、MATH和MorehopQA等数据集进行长上下文检索和多步推理任务的实验。

**📈 对比分析**

与现有基线方法相比，提出的方法在长上下文和推理任务中实现了超过130倍的速度提升，同时保持了更高的真实性。

**⚠️ 局限性**

限制在于尽管方法在效率和真实性上表现优越，但在某些复杂的推理任务中，仍可能存在归因质量的下降。

---

## 669. Federated Learning Meets Random Access: Energy-Efficient Uplink Resource Allocation

**arXiv ID:** 2602.01913 | [PDF](https://arxiv.org/pdf/2602.01913v1)

**作者:** Giovanni Perin `[一作]` (University of Padova), Nikolaos Pappas `[通讯]` (Linköping University)

**通讯引用:** 3883 | [OpenAlex ID](https://openalex.org/A5084740578)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文研究了两类设备在上行通道中并发通信的资源分配问题，分别为通过FDMA进行联邦学习的设备和使用ALOHA或S-ALOHA进行吞吐量导向的随机接入设备；

**💡 创新点**

创新点在于提出了一个联合能耗最小化的非凸优化框架，针对FL延迟与RA吞吐量双重约束，结合不同MAC协议的特性，给出近似全局最优的带宽划分和重传率；

**🔧 技术方法**

主要技术包括联邦学习通信模型分析、ALOHA与S-ALOHA的成功概率与吞吐量推导、非凸问题分解与网格搜索求解、以及能耗与吞吐量的联合评估；

**📊 数据集**

在实验中使用了公开的CIFAR-10图像数据集训练CNN模型，模拟100个客户端的FedAvg聚合；

**📈 对比分析**

通过对比ALOHA与S-ALOHA在不同FL设备数、随机接入速率和时隙设置下的系统能耗、吞吐量以及FL模型准确率，结果显示：当系统能耗主要由FL设备主导时ALOHA更高效，反之若RA流量占主导则S-ALOHA更优；

**⚠️ 局限性**

局限性包括：只考虑单一随机接入协议与FDMA，未涵盖多时隙多载波情况；仿真基于理想化信道与无限设备假设，实际网络中时隙同步与干扰等因素未被充分建模；

---

## 670. Learning Sparse Visual Representations via Spatial-Semantic Factorization

**arXiv ID:** 2602.01905 | [PDF](https://arxiv.org/pdf/2602.01905v1)

**作者:** Theodore Zhengde Zhao `[一作]` (Microsoft), Mu Wei `[通讯]` (Microsoft)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `729e5870-4135-47f5-97f2-e3974d07b5dc` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

设计并实现了 STELLAR 框架，将视觉特征分解为稀疏语义词典和空间分布，实现自监督学习中语义理解与像素级重建的统一。

**💡 创新点**

通过低秩因式分解将“什么”与“哪里”解耦，既保持像素级重建又获得高质量语义表示，突破传统稠密表示的“不变性悖论”。

**🔧 技术方法**

使用 ViT 骨干、可学习的稀疏查询、低秩重建损失、原型聚类、最优传输对齐以及 KoLeo 正则化等技术。

**📊 数据集**

在 ImageNet‑1K 上进行无标签预训练，并在 ADE20K、Cityscapes、Pascal VOC、Oxford‑IIIT Pet、Food‑101、GlaS 等下游任务上验证。

**📈 对比分析**

与 MAE、DINO、TiTok、DINOv2 等基线对比，16 个稀疏 token 已实现 FID≈2.60、线性检索精度≈73%，在大模型规模下达到或接近现有最佳语义与重建指标。

**⚠️ 局限性**

对单一目标的全局分类仍不如专门的 JE 模型，稀疏 token 数量受低秩约束影响，训练需多种损失调参，且对超大规模语料的扩展尚待验证。

---

## 671. LIEREx: Language-Image Embeddings for Robotic Exploration

**arXiv ID:** 2602.01930 | [PDF](https://arxiv.org/pdf/2602.01930v1)

**作者:** Felix Igelbrink `[一作]` (German Research Center for Artificial Intelligence), Martin Atzmueller `[通讯]` (Osnabrück University)

**通讯引用:** 3518 | [OpenAlex ID](https://openalex.org/A5011835245)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

开发了 Lierex 系统，将开集视觉语言模型 CLIP 与 3D 语义图结合，实现自然语言查询、目标导向探索和高效观察姿态估计。

**💡 创新点**

创新点在于：1）将 CLIP 嵌入融入 3D 语义图，实现开集查询与空间推理；2）提出学习视角质量估计（VQE）模型，替代昂贵的射线投射；3）自动层次化构建 3D 场景图。

**🔧 技术方法**

采用 CLIP 视觉语言模型、无类别分割模型、3D 语义图（3dssg）、自监督视角质量估计网络、Habitat 仿真器、Matterport3D/HM3D 数据集以及 TIAGo 机器人配合 LiDAR/ToF 摄像头。

**📊 数据集**

使用 Matterport3D、Matterport-Habitat (HM3D) 以及 TIAGo 机器人在真实环境中的 LiDAR/ToF 采集数据。

**📈 对比分析**

通过自监督训练的 VQE 与传统射线投射对比，显著降低计算成本；在仿真环境中实现快速目标定位和姿态推荐；实机演示验证了定位与查询精度，但未给出完整数值评估。

**⚠️ 局限性**

局限性包括：视角质量估计仍需采样而非直接回归；实例与统一地图一致性难以保证；需要大量渲染数据进行训练；在资源受限平台的部署仍具挑战。

---

## 672. Ultrafast On-chip Online Learning via Spline Locality in Kolmogorov-Arnold Networks

**arXiv ID:** 2602.02056 | [PDF](https://arxiv.org/pdf/2602.02056v1)

**作者:** Duc Hoang `[一作]` (Massachusetts Institute of Technology), Philip Harris `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 11641 | [OpenAlex ID](https://openalex.org/A5054695990)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文在FPGA上实现了全在线、低精度、极低延迟的Kolmogorov–Arnold网络（KAN）训练与推理，演示了在子微秒级别完成前向、反向传播和参数更新的可行性。

**💡 创新点**

创新点包括利用B‑spline的局部支持实现梯度稀疏更新，使容量可通过网格大小调节而保持单样本计算量不变；同时KAN在固定点量化下具备内在的数值稳健性，显著优于传统MLP。

**🔧 技术方法**

技术手段包括固定点FPGA硬件实现、B‑spline系数LUT和导数表、稀疏梯度更新逻辑、基于量化分析的精度设计，以及针对在线学习的流式数据流接口。

**📊 数据集**

实验使用了漂移回归、单次量子比特读出、非平稳Acrobot控制以及旋转的MNIST数字分类等数据集，覆盖回归、二分类和强化学习三大任务。

**📈 对比分析**

在与参数匹配及更大规模的MLP进行对比时，KAN在子微秒延迟、DSP/FF/LUT资源占用、以及在低位宽量化下的稳定性和收敛速度方面均优于MLP；在量化不稳的MLP中甚至出现发散，而KAN始终保持稳健。

**⚠️ 局限性**

局限性包括仅采用单批SGD更新，未验证Adam等更复杂优化器；硬件实现仍基于HLS自动合成，未进行手工RTL优化；在更复杂任务或更高维输入时可能需提升B‑spline阶数或网络深度，导致额外资源与延迟。

---

## 673. Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization

**arXiv ID:** 2602.02035 | [PDF](https://arxiv.org/pdf/2602.02035v1)

**作者:** Ahmad Farooq `[一作]` (University of Arkansas at Little Rock), Kamran Iqbal `[通讯]` (University of Arkansas at Little Rock)

**通讯引用:** 2260 | [OpenAlex ID](https://openalex.org/A5068395409)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

在受限带宽的多智能体强化学习环境中实现了自适应、压缩的通信策略

**💡 创新点**

将信息瓶颈理论与向量量化结合，提出了可学习的门控机制与离散编码，显著降低通信量并保持协同性能

**🔧 技术方法**

信息瓶颈优化、向量量化（VQ‑VAE）、门控通信、Gumbel‑Softmax、双重约束训练（软惩罚与原始-对偶）

**📊 数据集**

基于20×20格子搜索救援仿真环境，包含4–8名同质智能体、动态障碍和多目标，作为实验数据集

**📈 对比分析**

与无通信、全通信、随机门控、注意力通信、信息瓶颈、预定调度等基线对比，取得无通信基线提升181.8%，带宽减少41.4%，在成功率–带宽 Pareto 前沿上实现了最优表现

**⚠️ 局限性**

仅在单一合成环境、同质智能体、静态码本及信息瓶颈近似的情况下验证，缺乏在连续控制、异构团队和真实硬件中的泛化与实证验证

---

## 674. Scale-covariant spiking wavelets

**arXiv ID:** 2602.02020 | [PDF](https://arxiv.org/pdf/2602.02020v1)

**作者:** Jens Egholm Pedersen `[一作]` (Technical University of Denmark), Peter Gerstoft `[通讯]` (Technical University of Denmark)

**通讯引用:** 13901 | [OpenAlex ID](https://openalex.org/A5004718675)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

通过尺度空间理论将波形变换与脉冲神经网络关联，证明 LIF 神经元可以实现母波函数，并演示了基于脉冲的波形变换和重构实验。

**💡 创新点**

将尺度空间与波形变换的理论框架映射到可实现的脉冲神经网络，提出双通道正负脉冲实现波形母函数的可实现性，并提供能量高效的信号表示方法。

**🔧 技术方法**

使用尺度空间理论、时间因果极限核、波形变换（派生函数）、脉冲响应模型（SRM）和 LIF 神经元，并在 Python Norse 库中实现仿真。

**📊 数据集**

主要使用合成正弦波和复合正弦波信号（无公开数据集）。

**📈 对比分析**

与 Morlet 波形、截断指数波形以及不同通道数（K=3,6,12）的脉冲波形进行重构误差对比。结果显示截断指数波形最佳，脉冲波形在 K=3 后不再显著提升，说明脉冲计数已充分捕获频率成分。

**⚠️ 局限性**

仅在理论极限下证明可行；重构误差仍存在；脉冲计数编码在多通道下表现有限，缺乏更高级的脉冲时间编码；阈值自适应和生物学约束未充分探究。

---

## 675. Do I Really Know? Learning Factual Self-Verification for Hallucination Reduction

**arXiv ID:** 2602.02018 | [PDF](https://arxiv.org/pdf/2602.02018v1)

**作者:** Enes Altinisik `[一作]` (Qatar Computing Research Institute), Husrev Taha Sencar `[通讯]` (Qatar Computing Research Institute)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种在训练阶段通过自我验证（structured verification traces）来降低LLM事实性幻觉的框架

**💡 创新点**

创新点在于将验证行为内化为可学习的推理流程，并通过阶段级损失屏蔽（stage‑level loss masking）避免强化错误事实

**🔧 技术方法**

使用了结构化的自我验证轨迹、阶段级损失屏蔽、对抗式提示生成、以及基于判别器的幻觉检测

**📊 数据集**

主要在TriviaQA上构造训练数据，并在HotpotQA、NQ‑Open、FreshQA上评估跨域泛化

**📈 对比分析**

与知识探测（Knowledge Probing）和自一致性（Self‑Consistency）对比，VeriF在保持覆盖率的同时将幻觉率降低约10–53%，精确率/召回率和F1都有显著提升，且不需额外推理或检索开销

**⚠️ 局限性**

限制包括：跨模型族的验证轨迹转移效果差，极端分布偏移下自我验证的置信度易失真；需要较大容量模型来生成高质量的验证问题；在极小模型上仍可能产生过度自信导致错误答案

---

## 676. Robust Domain Generalization under Divergent Marginal and Conditional Distributions

**arXiv ID:** 2602.02015 | [PDF](https://arxiv.org/pdf/2602.02015v1)

**作者:** Jewon Yeom `[一作]` (Seoul National University), Taesup Kim `[通讯]` (Seoul National University)

**通讯引用:** 2406 | [OpenAlex ID](https://openalex.org/A5065728469)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出RC-Align框架，在域泛化中同时对抗标签分布(P(Y))和条件分布(P(X|Y))的偏移。

**💡 创新点**

通过从理论上分解风险界限，将域-类分布对齐损失与1-Wasserstein距离上界关联，并在元学习中直接最小化此界限。

**🔧 技术方法**

结合元学习(MAML/FO-MAML)、域-类分布对齐损失、Manifold Mixup以及对抗/对齐技术。

**📊 数据集**

在PACS、VLCS、OfficeHome、TerraIncognita四个DG基准以及对应的多域长尾版和DomainNet-MLT进行实验。

**📈 对比分析**

与多种基线（ERM、IRM、GroupDRO、MLDG、CORAL等）比较，RC-Align在标准DG平均精度提升约3.8%，在MDLT任务中平均和极差域精度均位居榜首。

**⚠️ 局限性**

仍受限于对源域标注完整、元学习计算开销以及在极端OOD情形下的鲁棒性不足。

---

## 677. ClueTracer: Question-to-Vision Clue Tracing for Training-Free Hallucination Suppression in Multimodal Reasoning

**arXiv ID:** 2602.02004 | [PDF](https://arxiv.org/pdf/2602.02004v1)

**作者:** Gongli Xi `[一作]` (Beijing University of Posts and Telecommunications), Wendong Wang `[通讯]` (Beijing University of Posts and Telecommunications)

**通讯引用:** 5202 | [OpenAlex ID](https://openalex.org/A5023670564)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了ClueTracer，一种在多模态推理模型中训练无、参数无、架构无关的推理时视觉线索跟踪方法，用于抑制幻觉并提升推理准确率。

**💡 创新点**

创新点在于将问题→输出→视觉的三流注意力路径进行显式追踪，利用输出中对关键问题词的注意力变化来定位任务关键视觉片段；同时引入层级视觉线索检索指标ClueRecall来选取最佳关注层。

**🔧 技术方法**

技术包括自回归Transformer的注意力张量分析、标准化方差筛选关键问题词、基于注意力的可视化线索分数（Trace Score）、DBSCAN聚类生成可裁剪区域，以及无监督的推理时裁剪策略。

**📊 数据集**

数据集：POPE、MMVP用于感知评价；HallusionBench、VMCBench用于推理时幻觉评估；COCO/Mask R‑CNN用于生成视觉线索标注。

**📈 对比分析**

与现有推理时抑幻方案（VCD、ICD、AGLA、VDGD）以及无推理的MLLM对比，ClueTracer在HallusionBench、VMCBench上平均提升约11.8%，在POPE/MMVP上提升约8.7%；在非推理模型MMVP上提升约8.7个百分点，显著优于对照方法。

**⚠️ 局限性**

局限性包括：需要在推理阶段额外计算注意力张量，可能导致推理时延增加；对极长推理链的鲁棒性仍有待验证；聚类参数和阈值对结果影响较大，需手动调优。

---

## 678. SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors

**arXiv ID:** 2602.02000 | [PDF](https://arxiv.org/pdf/2602.02000v1)

**作者:** Bing He `[一作]` (Shanghai Jiao Tong University), Wenjun Zhang `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 22721 | [OpenAlex ID](https://openalex.org/A5100447801)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `6514db3d-8de6-452c-91b7-acdb31787cc4` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出 SurfSplat，通过 2D Gaussian Splatting、表面连续性先验和强制 alpha 混合的 feedforward 网络，从稀疏视角重建高保真 3D 场景。

**💡 创新点**

创新点包括：①引入表面连续性先验，将 2DGS 的旋转、尺度与空间位置关联以保证表面连续；②强制 alpha 混合防止透明度崩溃；③提出高分辨率渲染一致性（HRRC）评估指标以揭示细粒度几何缺陷。

**🔧 技术方法**

使用的技术包括：2D Gaussian Splatting、双路径（单视角深度 + 多视角自注意力）编码器、U‑Net 预测 Gaussian 属性、表面连续性先验、强制 alpha 混合、MSE+LPIPS 损失以及 HRRC 评估。

**📊 数据集**

实验数据集：RealEstate10K、ACID、ScanNet、DL3DV、DTU 以及相关公开数据集。

**📈 对比分析**

与 PixelSplat、HiSplat、MVSplat、TranSplat、DepthSplat 等前沿方法在 PSNR/SSIM/LPIPS 和 HRRC 上进行对比，SurfSplat 在所有数据集上均实现了最高或最具竞争力的指标，尤其在高分辨率 HRRC 上显著优于对手。

**⚠️ 局限性**

局限性：需要已知相机位姿；每像素仅预测一个 Gaussian 可能导致表示冗余；缺乏姿势估计与紧凑自适应表示的能力。

---

## 679. SIDiffAgent: Self-Improving Diffusion Agent

**arXiv ID:** 2602.02051 | [PDF](https://arxiv.org/pdf/2602.02051v1)

**作者:** Shivank Garg `[一作]` (Indian Institute of Technology), Gaurav Kumar Nayak `[通讯]` (Indian Institute of Technology)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ba576bd1-e51d-44e8-8077-fc943b333c93` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 SIDiffAgent，一种无训练的多代理框架，通过自适应提示、评估与局部编辑循环以及经验记忆来提升文本到图像的生成质量。

**💡 创新点**

创新点包括经验驱动的记忆机制、基于 Theory of Mind 的多代理协同、可自适应负提示和持续自我改进的无训练循环。

**🔧 技术方法**

使用 Qwen‑VL、Qwen‑Image、Qwen‑Edit、Qwen‑Embedding 等大型语言与视觉模型，结合 LangGraph 架构、RAG+FAISS 检索、vLLM 量化推理和 4‑bit 量化实现。

**📊 数据集**

在 GenAI‑Bench 与 DrawBench 两大基准上评估，并用 Qwen‑Embedding 进行语义相似检索。

**📈 对比分析**

通过 VQAScore 与 14 种公开/专有模型对比，SIDiffAgent 在 GenAI‑Bench 的 VQA 分数达 0.94，比基线提升约 17%，且超越 Imagen3、SD3.5、T2I‑Copilot 等主流方法。

**⚠️ 局限性**

局限性包括对大模型计算资源的高依赖、记忆库扩展导致检索成本上升，以及在极端复杂场景和跨域任务的通用性尚待验证。

---

## 680. Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents

**arXiv ID:** 2602.02050 | [PDF](https://arxiv.org/pdf/2602.02050v1)

**作者:** Zeping Li `[一作]` (Fudan University), Zhenfei Yin `[通讯]` (Oxford University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了大型语言模型在长轨迹中使用工具时的行为，发现高质量工具调用往往伴随熵减，并基于此提出了两种熵引导奖励策略（TEPO_sparse 与 TEPO_dense），通过熵下降作为自监督信号来提升工具使用效率和性能。

**💡 创新点**

创新点在于首次将段熵变化（delta segment entropy）作为工具调用质量的无监督度量，并设计了稀疏终局奖励与稠密过程奖励两种方案，分别针对工具使用效率和任务表现进行优化。

**🔧 技术方法**

技术实现基于强化学习框架 GRPO，结合监督微调（SFT）与熵基奖励，采用 token‑level 的策略优化；使用 Qwen、Llama、Qwen3 等大模型，训练时加入 Python 计算器与 Wiki‑18 搜索工具。

**📊 数据集**

使用的评测数据集包括数学推理（AIME2024/2025）、知识密集问答（HotpotQA、2WikiMultihopQA、Musique）、深度信息检索（GAIA、WebWalker、HLE）等多领域任务。

**📈 对比分析**

与传统 RL 方法（GRPO、ARPO、AEPO）及最近的工具集成基线（SearchR1、OTC‑PPO、StepSearch）对比，TEPO_sparse 在工具调用次数上减少约72%，TEPO_dense 在任务准确率上提升约22%，在多种任务上均达或超越当前最优结果。

**⚠️ 局限性**

局限性包括实验规模仅覆盖 1.7B‑14B 模型，未对更大模型进行验证；搜索工具仅使用 Wiki‑18，未充分测试实时搜索 API（如 Bing、Google）导致对实时知识场景的泛化性尚待验证。

---

## 681. Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation

**arXiv ID:** 2602.02029 | [PDF](https://arxiv.org/pdf/2602.02029v1)

**作者:** Zhongyuan Lyu `[一作]` (Polytechnic University), Ming LI `[通讯]` (Polytechnic University)

**通讯引用:** 7105 | [OpenAlex ID](https://openalex.org/A5011677079)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本研究提出了一种基于 Canonical Intermediate Representation (CIR) 的多代理框架 R2C，用于从自然语言描述自动生成符合复杂操作规则的优化模型及可执行代码。

**💡 创新点**

创新点在于：①将规则语义与数学实现解耦的 CIR 架构；②使用 CIR 作为中间知识库，配合检索增强生成（RAG）实现规则到约束的结构化推理；③设计四阶段多代理流水线（Extractor、Mapper、Formalizer、Checker）并引入反射机制提升鲁棒性。

**🔧 技术方法**

采用的大型语言模型（DeepSeek‑v3.2、Qwen3‑32B），检索增强生成（RAG），多代理协同推理，以及基于 CIR 的模板化约束生成与范式聚类。

**📊 数据集**

使用自建的 ORCOpt‑Bench（50 个包含复杂操作规则的优化实例，涵盖 10 个行业领域）进行评测，并在 IndustryOR、BWOR、OptMATH 三个公开基准上进行迁移性验证。

**📈 对比分析**

与标准提示、Chain‑of‑Experts、Reflexion、Vanilla RAG、Self‑RAG 等基线以及 GPT‑5、Grok‑4 等专有模型进行对比。R2C 在 ORCOpt‑Bench 的准确率达到 47.2%（DeepSeek‑v3.2），显著高于标准提示（22.4%）和公开基线；在其他基准上亦保持与专有模型相近的表现，并通过反射机制进一步提升至 54.0%。

**⚠️ 局限性**

主要局限包括：①CIR 知识库覆盖范围有限，需手工扩展；②目前保证的是规则的可靠性而非完整性，可能导致过度约束；③对复杂范式切换的适应性仍有提升空间。

---

## 682. Edit Knowledge, Not Just Facts via Multi-Step Reasoning over Background Stories

**arXiv ID:** 2602.02028 | [PDF](https://arxiv.org/pdf/2602.02028v1)

**作者:** Ya Gao `[一作]` (Aalto University), Alexander Ilin `[通讯]` (System 2 AI)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `8d10c613-917e-4880-9716-17789f50e119` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种以推理为核心的知识内化训练框架，利用背景故事引入新知识、生成多跳问题强制推理、并通过上下文蒸馏让学生模型在无上下文条件下内部化新知识；

**💡 创新点**

将知识编辑视为推理问题，使用连贯背景故事而非孤立事实来表述新知识；通过自生成的多跳问题迫使模型在推理链中使用新知识；采用上下文蒸馏将教师的推理行为软标签化到学生，促进知识的深度内化；

**🔧 技术方法**

背景故事生成、自动化多跳问题生成、教师–学生上下文蒸馏（KL散度）、答案仅监督与推理轨迹两种监督模式、Dropout 0.9 的上下文抖动；

**📊 数据集**

MQuAKE‑Story（新增基于故事的知识更新）、MQuAKE‑CF‑3k（对抗性/假设性编辑）、原始 MQuAKE‑T（用于构建 Story）、MMLU（检验通用能力）

**📈 对比分析**

与传统的基线（仅事实更新）和 SFT（交叉熵微调）比较；在事实准确度和局部性上保持不变；在多跳推理（Portability）上提升约 2–3 倍，尤其在 Story+多跳+答案仅监督组合下，MQuAKE‑Story 的最难题准确率近 99%；对不合理更新时需要推理轨迹监督才能覆盖；

**⚠️ 局限性**

局部性在更新后略有下降；对冲突或多重更新时仍会遗忘或过度应用；推理轨迹监督在合理更新时效果不如答案仅监督；方法仅针对问答场景，缺乏对持续、多步决策场景的支持；

---

## 683. Adaptive Quality-Diversity Trade-offs for Large-Scale Batch Recommendation

**arXiv ID:** 2602.02024 | [PDF](https://arxiv.org/pdf/2602.02024v1)

**作者:** Clémence Réda `[一作]` (Ecole Normale Supérieure PSL), Jill-Jênn Vie `[通讯]` (Soda Inria Paris Saclay)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种名为 B-DivRec 的批量推荐算法，利用 DPP 与模糊剔除机制实现质量与多样性的平衡，并在此基础上加入在线学习层实现用户自适应多样性权重调节。

**💡 创新点**

创新点在于：①将质量-多样性 trade‑off 通过可插拔的 L‑矩阵形式统一到 DPP 框架；②设计基于用户历史的“模糊剔除”子空间来减少与历史过度相似的项目；③使用 AdaHedge 在线学习动态调节 λ，从而在不需要预训练的情况下根据用户反馈实时调整多样性水平。

**🔧 技术方法**

核心技术包括：确定性点过程（DPP）、低秩 Nyström 近似、k‑D 树或 ANN（FAISS/LSH）实现高效最近邻检索、以及在线学习算法 AdaHedge；算法在推理阶段实现 O(|Ω|) 的线性复杂度。

**📊 数据集**

实验数据集涵盖：Synthetic（规模 750、30k、3M、15M 项目）、MovieLens、Epinions、以及六个药物再利用数据集（Cdataset、DNdataset、Fdataset、Gottlieb、LRSSL、PREDICT），评估范围从 4 万到 1500 万项目。

**📈 对比分析**

与 MMR、DeepDPP、xQuAD、MarkovDPP 等基线比较。B‑DivRec 在多样性指标（尤其是全局多样性 div^G 和有效多样性 div^+）上往往优于竞争者，且在相关性（rel）与精确度（prec）上保持接近或略优；自适应 λ 方案进一步提升相关性，且在噪声反馈场景下仍能保持稳健性能。整体跑时与 MMR 相当，远低于高阶基线。

**⚠️ 局限性**

局限性包括：①当 α 过大时 L‑矩阵秩下降导致无法采样足够多样化项目；②若特征信息不足，历史中相似项目会导致多样性指标迅速衰减；③对长历史或极大规模库的极端情况仍需进一步优化内存与运算；④目前在冷启动无历史时无法直接应用，需要先生成初始多样性参数。

---

## 684. DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers

**arXiv ID:** 2602.02016 | [PDF](https://arxiv.org/pdf/2602.02016v1)

**作者:** Ionut-Vlad Modoranu `[一作]` (Institute of Science and Technology Austria), Dan Alistarh `[通讯]` (Institute of Science and Technology Austria)

**通讯引用:** 4412 | [OpenAlex ID](https://openalex.org/A5083822059)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出DASH，一个高效实现的Shampoo优化器，改进了预处理块的GPU利用率并加速了逆矩阵根的计算。

**💡 创新点**

创新点包括将块堆叠为3D张量并并行处理，以及引入Newton‑DB迭代和Chebyshev多项式近似，并通过多重幂迭代改进矩阵缩放。

**🔧 技术方法**

使用的技术包括GPU并行化的批处理块、FP16半精度迭代、Newton‑DB和Coupled‑Newton迭代、Chebyshev多项式、Power‑Iteration、TensorCore加速。

**📊 数据集**

实验数据集为C4文本数据，预训练Llama‑953M模型。

**📈 对比分析**

与原始Distributed Shampoo比较，在验证困惑度基本相同的同时，优化器步骤时间缩短4‑5倍，Newton‑DB取得最低验证困惑度。

**⚠️ 局限性**

局限在于对低精度（BF16）不稳定，需要动态选择迭代器，且在更大规模模型和不同硬件上需进一步验证。

---

## 685. Enhancing Multi-Image Understanding through Delimiter Token Scaling

**arXiv ID:** 2602.01984 | [PDF](https://arxiv.org/pdf/2602.01984v1)

**作者:** Minyoung Lee `[一作]` (Sogang University), Junsuk Choe `[通讯]` (Sogang University)

**通讯引用:** 6339 | [OpenAlex ID](https://openalex.org/A5078314427)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并验证通过缩放视觉分隔符令牌隐藏状态来抑制多图输入中的交叉信息泄漏。

**💡 创新点**

发现并强化视觉分隔符令牌的两大属性——跨图信息抑制与图内相互作用增强，并给出最简易的隐藏状态缩放方案。

**🔧 技术方法**

在多模态Transformer中对分隔符令牌隐藏状态乘以比例因子 λ，保持标准注意力机制，无需额外训练或前向推理。

**📊 数据集**

在多图基准 Mantis、MuirBench、MIRB、QBench2 以及文本基准 MultiNews、WCEP‑10、TQABench 上进行评测。

**📈 对比分析**

与基线、Focus、M‑RoPE 等方法对比，所有模型尺寸均显著提升 3–5% 分数，内存占用低于 Focus，且在更大模型（72B/78B）仍保持提升。

**⚠️ 局限性**

该方法仅针对令牌缩放，可能在极端多图或高度噪声图像下对跨图抑制效果有限，且未对自监督或多任务训练做进一步探索。

---

## 686. One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation

**arXiv ID:** 2602.02033 | [PDF](https://arxiv.org/pdf/2602.02033v1)

**作者:** Shuo Lu `[一作]` (Chinese Academy of Sciences Institute of Automation), Jian Liang `[通讯]` (Chinese Academy of Sciences Institute of Automation)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种统一框架OSMF，用于广告图像生成并对不同用户群体的点击偏好进行对齐；

**💡 创新点**

通过产品感知自适应聚类PAAG动态划分用户群体，并用基于群体特征的G-MLLM与Group-DPO实现对齐，解决了单一CTR优化忽略群体差异的问题；

**🔧 技术方法**

利用多模态大型语言模型（G-MLLM）、Cross‑Attention、K‑Means聚类、Stable Diffusion+ControlNet、Group‑Direct Preference Optimization（Group‑DPO）等技术；

**📊 数据集**

构建首个大规模群体级广告图像偏好数据集GAIP，包含约60万组用户，覆盖4000万用户、2085k商品和956万图像；

**📈 对比分析**

与CACS、WIYD、JAC等用户聚类基线以及CG4CTR、CAIG等CTR驱动模型对比，PAAG在NDCG@5上降低至0.3066、AUROC提升至0.6372；PCIG相较预训练G-MLLM的CTR提升5.5%，在在线实验中表现优于CAIG；GRM在Pair Accuracy上较CAIG提升4.7%；

**⚠️ 局限性**

主要局限在于数据来源单一电商平台，难以直接推广到多样化场景；模型训练对计算资源要求较高；并未深入探讨群体边缘用户的个性化生成问题。

---

## 687. SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning

**arXiv ID:** 2602.01990 | [PDF](https://arxiv.org/pdf/2602.01990v1)

**作者:** Zhen-Hao Xie `[一作]` (Nanjing University), Da-Wei Zhou `[通讯]` (Nanjing University)

**通讯引用:** 1747 | [OpenAlex ID](https://openalex.org/A5100655948)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `afceb026-1760-41ae-8d86-010831a37d97` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究了多模态连续指令微调中的路由漂移与专家漂移问题，提出一种稳定的Mixture-of-Experts框架来缓解这两种遗忘现象。

**💡 创新点**

创新点在于引入谱感知路由、曲率感知Riemannian缩放以及自适应专家激活三种机制，分别针对路由漂移、专家漂移和训练效率问题提供解决方案。

**🔧 技术方法**

采用LoRA型专家的Mixture-of-Experts、基于协方差的谱分解更新、历史输入协方差估计的曲率缩放，以及任务级专家冻结等技术。

**📊 数据集**

在CoIN基准上使用八个顺序VQA任务（ScienceQA、TextVQA、ImageNet、GQA、VizWiz、REC、VQAv2、OCR‑VQA）进行评估。

**📈 对比分析**

与MoELoRA、Continual LLaVA、ModalPrompt、SEFE、ProgLoRA、LLaVA‑CMoE、HiDe‑LLaVA等方法对比，平均准确率提升至66.82%，比最强基线高约2.8%。

**⚠️ 局限性**

在任务边界模糊或输入格式多变的情形下鲁棒性不足，且仍可能存在专家间的交叉干扰。

---

## 688. Synchronized Online Friction Estimation and Adaptive Grasp Control for Robust Gentle Grasp

**arXiv ID:** 2602.02026 | [PDF](https://arxiv.org/pdf/2602.02026v1)

**作者:** Zhenwei Niu `[一作]` (X-Humanoid), Xiaozu Ju `[通讯]` (X-Humanoid)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `51c0528b-f690-4182-ae60-bb5f046c276c`

**🎯 论文内容**

该论文提出了一套统一框架，结合实时摩擦估计与自适应把握控制，实现对柔性物体的温和、稳定抓取。

**💡 创新点**

创新点在于将粒子滤波器实时估计摩擦系数与反应式抓取控制同步耦合，形成闭环感知-动作一体化的“温和抓取”策略。

**🔧 技术方法**

主要技术包括基于视觉触觉传感器的接触模型、粒子滤波器的摩擦估计算法以及比例控制器对抓取力的动态调节。

**📊 数据集**

论文未使用公开数据集，而是在UR5e机械臂与Robotiq抓手上搭载Tac3D视觉触觉传感器进行真实场景抓取实验。

**📈 对比分析**

与传统分离式估计与控制方法相比，该方法在摩擦估计收敛速度上提升到接触后单步完成，实验显示在水量变化和机器人加速等动态条件下都能保持抓取稳定，抓取成功率显著提升。

**⚠️ 局限性**

限制在于仍需手工设定接触阈值力，且在极端摩擦变化或高动态环境下的鲁棒性待进一步验证。

---

## 689. NEAT: Neuron-Based Early Exit for Large Reasoning Models

**arXiv ID:** 2602.02010 | [PDF](https://arxiv.org/pdf/2602.02010v1)

**作者:** Kang Liu `[一作]` (Northeastern University), Daling Wang `[通讯]` (Northeastern University)

**通讯引用:** 1841 | [OpenAlex ID](https://openalex.org/A5035378456)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种训练无关的基于神经元激活动态的早期推理退出框架NEAT，能够在推理过程中监测关键神经元并动态触发退出或抑制反思，以减少过度推理；

**💡 创新点**

创新点在于利用神经元级别的激活模式而非输出或隐藏层特征进行内部退出判断，并实现无额外监督、无并行推理的训练自由方案；

**🔧 技术方法**

核心技术包括神经元归因（log‑probability increase）、时间滤波（质心与熵）、激活模式匹配（余弦相似度与幅度比），以及双重干预策略（早期退出与反思抑制）；

**📊 数据集**

在四个推理基准（MATH500、AMC23、AIME24、GPQA‑D）上对四种大型推理模型（DeepSeek‑R1、Llama‑8B、Qwen3‑8B/14B）进行评估；

**📈 对比分析**

与多种基线（Vanilla、NoThinking、TALE、Dynasor、DEER、CGRS）比较，NEAT平均缩短22–28%的token长度，保持或略优于Vanilla的准确率，且不产生额外推理延迟；

**⚠️ 局限性**

局限性包括需完整模型内部激活访问、对极大规模模型的泛化未验证、以及在高效推理引擎中实现仍需工程投入。

---

## 690. Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation

**arXiv ID:** 2602.02007 | [PDF](https://arxiv.org/pdf/2602.02007v1)

**作者:** Zhanghao Hu `[一作]` (King's College London), Lin Gui `[通讯]` (King's College London)

**通讯引用:** 7074 | [OpenAlex ID](https://openalex.org/A5062168574)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种基于层级结构的代理记忆检索框架，抛弃传统的固定top‑k相似检索，改为在语义组件层面进行分层检索并按需展开细粒度证据；

**💡 创新点**

创新点在于将记忆拆解为语义组件并组织为主题层级，使用稀疏‑语义目标引导主题拆分合并，并通过代表性选择与不确定性门控实现自适应检索；

**🔧 技术方法**

核心技术包括层级记忆管理（Episode→Semantic→Theme）、稀疏‑语义指导函数、k‑NN图代表性选择、基于读者不确定性的动态扩展以及多级稀疏正则化；

**📊 数据集**

使用LoCoMo和PerLTQA两个对话与个人长期记忆基准数据集进行评估；

**📈 对比分析**

与Naive RAG、A‑Mem、MemoryOS、LightMem、Nemori等多种基线对比，在三大LLM（Qwen3‑8B、Llama‑3.1‑8B‑Ins、GPT‑5‑nano）上均实现BLEU、F1/ROUGE‑L提升，且token使用量显著降低；

**⚠️ 局限性**

局限性包括对动态结构重组的实现复杂度、对主题拆分/合并阈值的依赖以及在极端长时序或跨域多模态记忆场景下可能仍需进一步优化；

---

## 691. Emergent Analogical Reasoning in Transformers

**arXiv ID:** 2602.01992 | [PDF](https://arxiv.org/pdf/2602.01992v1)

**作者:** Gouki Minegishi `[一作]` (University of Tokyo), Yutaka Matsuo `[通讯]` (University of Tokyo)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6`

**🎯 论文内容**

本文基于范畴论的函子概念，构造了一个控制式的合成任务，用来探测Transformer在推理过程中是否能学习类比推理。

**💡 创新点**

创新点在于：①将类比推理形式化为跨类别的映射；②提出能同时评估组合推理与类比推理的统一任务；③通过Dirichlet能量和注意力分析揭示类比推理在Transformer中是由嵌入空间结构对齐与函子标记的向量加法两步实现的；④证明该机制同样存在于预训练LLM的层级表示中。

**🔧 技术方法**

使用的技术包括：Transformer（单层/多层、单头/多头）训练、交叉熵损失、Adam优化、权重衰减与批量大小调参；对内部表示进行Dirichlet能量评估、注意力权重和向量平行度（余弦相似度）分析；以及在预训练LLM上利用logit lens进行层级演化跟踪。

**📊 数据集**

数据集：合成数据集，包含实体集ℰ（可调|ℰ|）、关系集ℛ（可调|ℛ|）以及两类共享结构的实体对，分别生成atomic、compositional和analogical样本，支持调节OOD比例。

**📈 对比分析**

与传统组合推理任务对比，类比推理在训练动态、对数据、优化和模型规模的敏感性更高；在单层Transformer上，类比推理需更高的关系多样性、合适的权重衰减和中等规模模型才能出现；与预训练LLM（Gemma2、LLaMA）对比，层级结构中同样出现Dirichlet能量下降与准确率上升的同步，说明机制具备通用性。

**⚠️ 局限性**

限制包括：合成任务过于理想化，缺乏真实世界中的多重重叠类别和无标记的函子信息；类比推理的样本效率提升尚未在真实训练场景验证；对更大模型或更复杂关系结构的扩展仍需进一步研究。

---

## 692. WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora

**arXiv ID:** 2602.02053 | [PDF](https://arxiv.org/pdf/2602.02053v1)

**作者:** Pengyu Wang `[一作]` (University of Science and Technology of China), Zhendong Mao `[通讯]` (University of Science and Technology of China)

**通讯引用:** 6128 | [OpenAlex ID](https://openalex.org/A5023341829)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `3f18e8e3-0266-457c-8567-9039b6d2394d` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建了一个名为 WildGraphBench 的新基准，使用 Wikipedia 文章的引用页面作为长篇、异构的外部检索语料库，并在此基础上设计了三类问答任务（单事实、跨文档多事实、段落级摘要），旨在评估 GraphRAG 在真实世界检索环境中的表现。

**💡 创新点**

创新点在于：
1) 采用 Wikipedia 引用页作为“野生”检索集，真实反映长文本、噪声与异构性；
2) 设计三种递进难度的任务类型，突出跨文档证据聚合；
3) 提出了基于声明（statement）的评估方法，用 LLM 判断答案与金标准的事实等价性。

**🔧 技术方法**

主要技术包括：
- GraphRAG 系列模型（Fast‑GraphRAG、Microsoft GraphRAG、LightRAG、HippoRAG2、LinearRAG）以及平面 RAG 基线（NaiveRAG、BM25）；
- 文档/段落分块、向量检索与图构建（LightRAG pipeline）；
- LLM 作为评估判定器，对单/多事实准确率及摘要的命中率/召回率/ F1 进行评估。

**📊 数据集**

使用的数据集为 WildGraphBench：从 12 个 Wikipedia 主题选取有大量引用的条目，采集其引用页面（≈2.4M tokens），提取约 1,100+ 问题，包含 667 条单事实、191 条多事实、339 条摘要题目。

**📈 对比分析**

实验对比了多种基线：在单事实任务上，平面检索（NaiveRAG、BM25）仍能取得较高准确率；在多事实任务中，GraphRAG（尤其是 Microsoft GraphRAG(global)）明显优于平面基线；在摘要任务中，所有方法表现低迷，平面检索稍好，GraphRAG 受限于图构建和聚合开销。人类表现显著更好，说明任务仍具挑战性。

**⚠️ 局限性**

局限性：
- 金标准仅来自 Wikipedia 的编辑共识，可能存在遗漏或错误；
- 评估依赖 LLM 判定与声明匹配，可能引入语言偏差；
- 数据集包含大量噪声、过时或敏感内容，需要额外的过滤与安全措施。

---

## 693. Dissecting Outlier Dynamics in LLM NVFP4 Pretraining

**arXiv ID:** 2602.02047 | [PDF](https://arxiv.org/pdf/2602.02047v1)

**作者:** Peijie Dong `[一作]` (Hong Kong University of Science and Technology), Bo Li `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 31010 | [OpenAlex ID](https://openalex.org/A5100688318)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对NVFP4低精度LLM预训练中的异常值（outlier）动态进行系统纵向分析，并针对发现的热点通道提出热通道补偿机制（Hot-Channel Patch，HCP），从而构建CHON混合精度训练方案。

**💡 创新点**

①首次纵向追踪异常值在不同架构（Softmax Attention、Linear Attention）中的出现位置、演化路径及对量化误差的贡献；②发现后QK操作对低精度尤为敏感；③提出基于热通道的在线补偿技术（HCP）并将其与后QK保护融合，形成完整的CHON训练配方。

**🔧 技术方法**

FP4/NVFP4量化、块级缩放（2D/1D）、随机Hadamard变换与随机舍入、热通道识别与补偿、后QK操作高精度保护、混合精度训练策略、GPU专用低精度内核等。

**📊 数据集**

RedPajama子集用于预训练；Zero-shot评估采用lm-harness（ARC-Challenge、HellaSwag、OpenBookQA、PIQA、SciQ、WinoGrande等）；微调与强化学习使用OpenMathReasoning与GSM8K。

**📈 对比分析**

与BF16、FP8及标准NVFP4基线对比，测量训练损失差距、下游零样本准确率与训练吞吐；CHON将损失差距从约0.94%降至0.58%，下游任务准确率与BF16相当；整体训练开销提升不超过12%，且保持了显著的能耗与存储优势。

**⚠️ 局限性**

实验覆盖的模型规模与架构有限，未验证超大模型或Mixture-of-Experts；异常值诊断主要基于kurtosis、top‑k等指标，缺乏更全面的稳定性测度；结论多为经验相关，尚缺乏因果机制验证；系统级吞吐与能耗提升需结合更多底层优化进一步验证。

---

## 694. On Stability and Robustness of Diffusion Posterior Sampling for Bayesian Inverse Problems

**arXiv ID:** 2602.02045 | [PDF](https://arxiv.org/pdf/2602.02045v1)

**作者:** Yiming Yang `[一作]` (University College London), Zhuo Sun `[通讯]` (Shanghai University of Finance and Economics)

**通讯引用:** 1840 | [OpenAlex ID](https://openalex.org/A5053032316)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `ba576bd1-e51d-44e8-8077-fc943b333c93` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了稳健的扩散后验采样方法（RDP），并对扩散模型在贝叶斯逆问题中的稳定性与鲁棒性进行了理论分析。

**💡 创新点**

创新点在于先证明扩散后验采样的稳定性并揭示其对似然假设敏感，随后通过泛化贝叶斯框架自适应加权实现鲁棒性，并将其构造为可插拔的模块化方案。

**🔧 技术方法**

使用技术包括扩散模型、Tweedie近似、梯度引导的逆向SDE、泛化贝叶斯损失以及自适应IMQ权重函数。

**📊 数据集**

实验数据集来自InverseBench，包括逆散射、相位重构以及自然图像修复任务（FFHQ‑256的inpaint、deblur、phase retrieval）。

**📈 对比分析**

与四种基线（DPS、LGD、ΠGDM、PnPDM）比较，实验显示在正确或错误的似然模型下，RDP在PSNR/SSIM、LPIPS、VIFL、FID等指标上保持或提升性能，尤其在重构噪声或离群点情形下提升约20–50%。

**⚠️ 局限性**

限制在于仅评估了各向同性噪声，未覆盖空间相关或离散测量（如Poisson）等情况，理论分析尚未针对这些更复杂噪声模型。

---

## 695. Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models

**arXiv ID:** 2602.02043 | [PDF](https://arxiv.org/pdf/2602.02043v1)

**作者:** Cristian Sbrolli `[一作]` (Politecnico di Milano), Toshihiko Yamasaki `[通讯]` (University of Tokyo)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `67630363-6be0-4f51-ab05-7198250671a5` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建了 Auto-Comp 自动化合成流水线，生成可控的最小与上下文两种视觉语言样本，并利用这些数据评估并揭示 VLM 在组合推理方面的普遍失效。

**💡 创新点**

创新地将最小化与上下文化双轨生成与自动验证相结合，形成可并行的 A/B 测试框架，首次在合成数据中系统评估低熵干扰与上下文双刃效应。

**🔧 技术方法**

采用模板化与 LLM 重写生成、Stable Diffusion3.5 与 GroundedSAM2 等模型进行图像合成与验证，并通过自动属性检验、背景白色检测等多级管线。

**📊 数据集**

基于 Object365 250 种对象、20 种常见颜色与 4 种空间关系，生成 Auto-Comp-CP（Color/Position）Benchmarks，共计约 175k 对图文；此外使用 WebLI 等预训练数据。

**📈 对比分析**

在 20 款对比模型上对 Swap 与 Confusion 等硬负样本进行准确率比较，发现 CLIP 与 SigLIP 在 N=2 时可达 70%+，但 N=3 时跌至约 20%；SigLIP 在 WebLI+Sigmoid 下表现最佳，且上下文对位置推理提升、对颜色绑定下降。

**⚠️ 局限性**

受限于文本到图像与 LLM 预训练偏差，生成器在某些颜色与关系上表现不均，验证器亦非无偏；模型的成功率受生成质量影响，且流水线无法完全排除视觉/语言先验。

---

## 696. Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models

**arXiv ID:** 2602.02039 | [PDF](https://arxiv.org/pdf/2602.02039v1)

**作者:** Wei Liu `[一作]`, Yulan He `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了 Deep Data Research (DDR) 任务与 DDR‑Bench 基准，评估大型语言模型在无预设问题、开放式数据库探索中自主生成洞察的能力。

**💡 创新点**

创新点在于将探究智能与执行智能区分，引入基于事实清单的可验证评估框架，使模型的洞察质量可客观度量并支持细粒度行为分析。

**🔧 技术方法**

使用 ReAct 风格交互、SQL/Python 工具调用、LLM‑as‑a‑Checker 自动化评估、基于事实清单的检查表、对模型探索、交互、终止行为进行细粒度分析。

**📊 数据集**

使用三大真实数据库：MIMIC‑IV（医疗 EHR）、GLOBEM（可穿戴与心理问卷）和 10‑K（公司年报），共 291 个任务实体、2,058 条检验项。

**📈 对比分析**

对比多家商用与开源 LLM（Claude 4.5 Sonnet、GPT‑5、Gemini、Qwen 等），通过检验表准确率衡量性能；Claude 4.5 Sonnet 取得 40%+ 的平均准确率，最强模型在探索深度、终止准确率和新颖洞察上表现最好，但整体仍低于理想水平。

**⚠️ 局限性**

局限性包括：长时序探索仍难以完成；探索覆盖与深度不均衡导致错误；模型易过度推理或缺乏上下文；Hallucination 虽低但仍存在；评估依赖 LLM‑as‑a‑Checker，无法完全覆盖所有开放式洞察。

---

## 697. Frictional Contact Solving for Material Point Method

**arXiv ID:** 2602.02038 | [PDF](https://arxiv.org/pdf/2602.02038v1)

**作者:** Etienne Ménager `[一作]` (Inria), Justin Carpentier `[通讯]` (Inria)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了一套完整的摩擦接触管线，能够在隐式MPM框架下实现精确的接触检测、接触点几何定位、以及通过非线性互补问题（NCP）求解摩擦力，保证无侵入、满足库伦摩擦及最大耗散原理。

**💡 创新点**

创新点在于：①将接触检测迁移到粒子中心、几何感知的子格尺度，解决传统基于网格节点的模糊检测问题；②利用与MPM相同的线性化得到的可逆 admittance 矩阵，将全局摩擦接触建模为一个可直接使用 ADMM 求解的非线性互补问题；③该管线对材料、插值、传递方式完全无关，能够无缝嵌入现有隐式MPM循环。

**🔧 技术方法**

核心技术包括：粒子中心几何原始（如四面体）接触检测、基于 barycentric 投影的接触框架在网格上的投影、全局 Delassus 作用矩阵的构造以及 ADMM 迭代求解 NCP；同时结合 APIC、MLS-MPM 等高级传递与 B‑spline/CK 插值。

**📊 数据集**

实验数据集：七个代表性场景，涵盖弹性、塑性、斜面滑动、多物体交互、软手指摩擦、流体介质阻碍以及球体撞击柔软四足机器人等，使用基于网格的粒子化体积构造，并采用 Neo‑Hookean、线性、St. Venant‑Kirchhoff、共旋转等材料模型。

**📈 对比分析**

与传统基于节点的显式或惩罚法相比，该方法在相同时间步长下实现了更低的接触残差（多数时间步残差 < 1e‑6），并在多物体和复杂几何下保持了稳定的碰撞模式切换；实验表明 ADMM 迭代次数平均在 300–600 次左右，性能可通过预因子化共享实现可扩展。

**⚠️ 局限性**

局限性包括：仅使用单一网格每对象，缺乏多分辨率或多时间步技术；在大规模接触集时 Delassus 矩阵构造和乘积仍是计算瓶颈；未提供接触稀疏化、warm‑start 或更高效预条件器；并未直接评估可微分性能或梯度传播效果。

---

## 698. Light Alignment Improves LLM Safety via Model Self-Reflection with a Single Neuron

**arXiv ID:** 2602.02027 | [PDF](https://arxiv.org/pdf/2602.02027v1)

**作者:** Sicheng Shen `[一作]` (Beijing Institute of AI Safety and Governance), Yi Zeng `[通讯]` (Beijing Institute of AI Safety and Governance)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `9cc9baba-5356-466d-81ff-d80028d90279` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种轻量级推理时安全对齐方法 NGSD，利用单一神经元门控机制在检测到潜在风险时才引入外部安全专家，保持模型在安全性与实用性之间的平衡。

**💡 创新点**

创新点包括：
1) 仅使用单一神经元实现历史信号积累与即时触发的门控，显著减少不必要的安全干预；
2) 只需在最小规模模型上训练一次安全专家，便可迁移至同家族更大模型；
3) 通过输入提示级自我反思一次性确定安全干预强度，避免 token 级动态更新。

**🔧 技术方法**

主要技术手段：
- 基于 SafeDecoding 的概率插值与专家模型校正；
- 神经元灵感的门控算法（膜电位累积 + 阈值激活）；
- LoRA 微调 + DeepAlign 安全增强数据；
- 自我反思评分与阈值策略；
- 对比实验使用多种攻击方法（GCG、PAIR、AutoDAN 等）和评估框架。

**📊 数据集**

使用的数据集包括：
- 安全增强数据（用于专家模型训练）；
- GSM8K、Just‑Eval、Alpaca‑Eval（评估实用性）；
- XSTest、FalseReject（评估过度拒绝）；
- PAIR、GCG、AutoDAN（生成攻击样本）。

**📈 对比分析**

与 SafeDecoding、SSD、Self‑Reminder、Self‑Exam 等方法在多模型（Vicuna、Llama‑2、Llama‑3、Qwen3）和多攻击场景下对比：
- 在安全性（ASR、harmful score）上基本无下降甚至提升；
- 在实用性（GSM8K ROUGE、Just‑Eval 评价、Alpaca‑Eval）上保持或略高于基线；
- 在效率（内存、吞吐量）上显著优于 SSD；
- 结果表明 NGSD 在跨规模、跨模型的泛化性更好。

**⚠️ 局限性**

局限性：
- 评估主要基于受控安全基准，未覆盖极端长文本或开放式推理场景；
- 只在同一模型家族内部迁移，跨家族的词表差异会影响通用性；
- 依赖安全专家模型的质量，若专家训练不足可能导致门控失效。

---

## 699. UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving

**arXiv ID:** 2602.02002 | [PDF](https://arxiv.org/pdf/2602.02002v1)

**作者:** Guosheng Zhao `[一作]`, Xingang Wang `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `ba576bd1-e51d-44e8-8077-fc943b333c93` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出UniDriveDreamer，一种单阶段统一的多模态世界模型，能够直接生成多摄像头视频和LiDAR序列；

**💡 创新点**

创新点包括：LiDAR专用VAE、统一潜在锚定（ULA）实现跨模态潜在分布对齐、以及通过扩散Transformer实现时空一致性和跨模态交互的单阶段生成；

**🔧 技术方法**

使用的技术包括变分自编码器（VAE）、统一潜在锚定、扩散Transformer、流匹配优化、LPIPS感知损失、KL散度等；

**📊 数据集**

使用的数据集为nuScenes（700条训练序列、150条验证序列，12Hz注释）；

**📈 对比分析**

与SOTA单模态和多模态方法对比，视频生成达到FID 2.81、FVD 11.44；LiDAR生成得到MMD 0.27、JSD 0.039；在3D检测任务中，生成数据提升mAP +0.8、NDS +0.52；

**⚠️ 局限性**

局限性在于生成的LiDAR缺失强度通道，需要手动置零；对不同模态的同步和实时推理性能未作详细评估；模型对不同场景的泛化能力尚待进一步验证。

---

## 700. From Latent Signals to Reflection Behavior: Tracing Meta-Cognitive Activation Trajectory in R1-Style LLMs

**arXiv ID:** 2602.01999 | [PDF](https://arxiv.org/pdf/2602.01999v1)

**作者:** Yanrui Du `[一作]` (SCIR Lab Harbin Institute of Technology), Mengling Feng `[通讯]` (National University of Singapore)

**通讯引用:** 12003 | [OpenAlex ID](https://openalex.org/A5022222926)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对R1风格大语言模型的自我反思行为进行机制化分析，划分并验证不同层级的功能及其因果链。

**💡 创新点**

首次将logit‑lens与激活差分结合，识别出三阶段（latent‑control、semantic‑pivot、behavior‑overt）并通过提示级语义与层级激活引导两种干预，验证层级间的因果传播。

**🔧 技术方法**

使用logit‑lens解码中间激活、对比激活差分、t‑SNE可视化、激活 steering、统计概率质量与排名等方法；在DeepSeek‑R1和Qwen3两款R1模型上进行实验。

**📊 数据集**

以GSM8K为主基准，附加MedMCQA及其他领域数据，用于验证跨领域的泛化。

**📈 对比分析**

通过概率质量、排名倒数和DTT等指标量化各层级响应，比较提示级干预与激活引导对反思概率的影响，结果显示三阶段按顺序传递，且在不同模型、标记与领域均保持一致性。

**⚠️ 局限性**

局限性包括：仅验证了部分反思标记（如“Wait”“Hmm”），激活 steering 的幅度受限（过大导致语言崩溃），对不同模型的普适性需进一步检验，并未深入阐释层级形成的根本原因。

---

## 701. Thinking Like a Doctor: Conversational Diagnosis through the Exploration of Diagnostic Knowledge Graphs

**arXiv ID:** 2602.01995 | [PDF](https://arxiv.org/pdf/2602.01995v1)

**作者:** Jeongmoon Won `[一作]` (Seoul National University), Yohan Jo `[通讯]` (Seoul National University)

**通讯引用:** 1677 | [OpenAlex ID](https://openalex.org/A5021733732)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

设计并实现了基于诊断知识图的两步对话诊断系统，先生成诊断假设再通过澄清问题逐步验证，最终给出诊断结果。

**💡 创新点**

创新点在于：①将诊断知识图与两步推理（假设生成+验证）相结合，采用 3‑hop 子图扩展以便产生针对性澄清问题；②改进患者模拟器加入低特异性症状描述，使对话更贴近真实临床；③通过对话式提示实现图知识的可解释利用。

**🔧 技术方法**

使用的技术包括：大型语言模型（Qwen‑2.5‑7B‑Instruct、GPT‑4.1‑mini）、多标签分类头用于假设生成、图结构文本提示与推理、监督微调（SFT）生成对话与澄清问题、改造的 PatientSim（低特异性症状）和自动化对话合成。

**📊 数据集**

数据集：MIMIC‑IV（急诊与电子健康记录）与 MIMIC‑IV‑Note 用于构建患者档案；通过 GPT‑4o‑mini 生成合成对话；诊断知识图基于临床决策树与医学教材中的诊断模式。

**📈 对比分析**

与通用 LLM（GPT‑4.1‑mini、Claude‑3.5‑Sonnet、Gemini‑2.0‑Flash、Llama‑3.3‑70B、Qwen‑2.5‑72B 等）以及改造的 Chain‑of‑Diagnosis baseline 进行对比。实验结果显示，SFT 版模型在 Recall@1 0.250、Recall@4 0.418、平均对话轮数 6.9，显著优于基线且在准确率与效率上接近更大规模模型。

**⚠️ 局限性**

主要局限：①采用患者模拟器而非真实临床对话；②知识图覆盖范围有限，缺乏罕见疾病；③合成对话数据的质量与偏差可能影响模型在真实环境中的表现。

---

## 702. On the Limits of Layer Pruning for Generative Reasoning in LLMs

**arXiv ID:** 2602.01997 | [PDF](https://arxiv.org/pdf/2602.01997v1)

**作者:** Safal Shrestha `[一作]` (New York University), Keith Ross `[通讯]` (New York University)

**通讯引用:** 15526 | [OpenAlex ID](https://openalex.org/A5101801953)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究层级剪枝对生成推理的影响，并提出使用自生成响应进行微调的恢复策略。

**💡 创新点**

系统揭示生成推理任务对层数高度敏感，证明自生成响应微调能显著提升恢复效果。

**🔧 技术方法**

采用层级剪枝、QLoRA 微调与自生成响应训练。

**📊 数据集**

使用 Alpaca、Dolci 等开源对话数据以及 GSM8K、HumanEval+、XSUM 等生成基准。

**📈 对比分析**

与标准开放数据微调相比，自生成响应微调在分类任务保留率≈90%，生成任务约60%（25%剪枝），但在低剪枝率下可达80%以上。

**⚠️ 局限性**

即使微调，算术与语法能力仍难恢复，生成推理性能在大幅剪枝时仍显著低于基线。

---

## 703. Leveraging Latent Vector Prediction for Localized Control in Image Generation via Diffusion Models

**arXiv ID:** 2602.01991 | [PDF](https://arxiv.org/pdf/2602.01991v1)

**作者:** Pablo Domingo-Gregorio `[一作]` (Napptilus Tech Labs), Javier Ruiz-Hidalgo `[通讯]` (Universitat Politècnica de Catalunya)

**通讯引用:** 1244 | [OpenAlex ID](https://openalex.org/A5085613617)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在扩散模型中实现对用户指定区域的局部控制，使得在指定区域内满足结构约束，其余区域由模型自由生成。

**💡 创新点**

提出基于掩码的特征层控制、利用每步的初始潜向量预测以及基于 Sobel 的相似性损失实现局部结构约束。

**🔧 技术方法**

T2I‑Adapter、Stable Diffusion 潜空间、Sobel 高通滤波、损失函数融合（diffusion loss + similarity loss）

**📊 数据集**

600k LAION‑Aesthetics V2 训练集（分辨率 ≥256）

**📈 对比分析**

与原始 T2I‑Adapter 与 ControlNet 对比。我们的模型在 DMSEin 上最低，FID 与 CLIPScore 与基线相当或略优；在 DMSEout 上介于两者之间，显示更合理的背景边缘生成。

**⚠️ 局限性**

仅支持基于边缘的局部约束；对颜色、语义等其他条件未验证；掩码尺寸与位置对性能影响显著，需人工选择；模型在极端遮挡或复杂结构下的鲁棒性待提升。

---

## 704. FORLER: Federated Offline Reinforcement Learning with Q-Ensemble and Actor Rectification

**arXiv ID:** 2602.02055 | [PDF](https://arxiv.org/pdf/2602.02055v1)

**作者:** Nan Qiao `[一作]` (Central South University), Sheng Yue `[通讯]` (Sun Yat-sen University)

**通讯引用:** 4292 | [OpenAlex ID](https://openalex.org/A5027110921)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种面向物联网的离线联邦强化学习框架FORLER，结合服务器端的Q‑ensemble聚合和设备端的δ周期性actor rectification；

**💡 创新点**

创新点在于利用Q‑ensemble在服务器端形成保守目标以抑制策略污染，并通过δ周期性actor rectification降低设备端计算成本、逃避局部最优；

**🔧 技术方法**

技术包括离线强化学习中的CQL、TD3BC、SAC‑N风格Q‑ensemble、零阶搜索调优的actor rectification、FedAvg聚合以及安全策略改进理论保证；

**📊 数据集**

实验数据集采用D4RL离线RL基准（HalfCheetah、Walker2d、Ant、Hopper）以及不同质量的设备数据；

**📈 对比分析**

与Fed‑TD3BC、Fed‑CQL、FEDORA及集中式CQL对比，FORLER在所有任务上都实现了更快收敛和更高最终得分，且在设备数量、数据规模和δ参数变化下保持稳健；

**⚠️ 局限性**

局限在于实验仅基于仿真，未在真实物联网环境中验证；通信开销和能耗虽然降低但仍未针对网络延迟、丢包等实际情况做进一步优化；

---

## 705. Are Semantic Networks Associated with Idea Originality in Artificial Creativity? A Comparison with Human Agents

**arXiv ID:** 2602.02048 | [PDF](https://arxiv.org/pdf/2602.02048v1)

**作者:** Umberto Domanti `[一作]` (Free University of Bozen-Bolzano), Antonella De Angeli `[通讯]` (Free University of Bozen-Bolzano)

**通讯引用:** 5178 | [OpenAlex ID](https://openalex.org/A5035208761)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了ChatGPT‑4o的语义网络结构与其在“替代用途任务”（AUT）中产生的想法原创性之间的关系，并与一组心理学学生（按原创性分为高创意和低创意两组）进行对比。

**💡 创新点**

创新点：
• 首次将语义网络（ASPL、CC、Q、脉冲分析）与大型语言模型的原创性关联起来；
• 采用人工认知创意框架（Artificial Cognition）为LLM研究提供理论基础；
• 通过“平均性能”与“过程”两维度提出人工创意的操作性见解和方法建议，推动HCI与心理学的交叉研究。

**🔧 技术方法**

使用的技术与方法：
• 语义网络构建：SemNet包、TMFG过滤、余弦相似度边权；
• 结构与脉冲网络指标计算（ASPL、CC、Q、Resiliency）；
• 线性混合模型（lme4）评估原创性（总产量与前三高）；
• 统计分析：ANOVA、t检验、Games‑Howell、Wilcoxon等。

**📊 数据集**

数据集：
• ChatGPT‑4o交互生成的词汇和AUT回答（使用ChatGPT-4o chat接口）；
• 81名心理学学生的词汇产生与AUT回答（已公开或附录）。

**📈 对比分析**

比较方法与性能：
• 通过中位数分割将人类分为高创意（HCH）与低创意（LCH）；
• 对三组（GPT、HCH、LCH）进行原创性比较：GPT在原创性总产量和原创性峰值上显著高于LCH、低于HCH；
• 网络指标比较显示GPT网络最不灵活（ASPL最高、CC最低、Q最高、Resiliency最低），HCH最灵活；
• 结果表明，虽然GPT网络结构更为刚性，但在原创性上仍优于低创意人类。

**⚠️ 局限性**

limitations：
• 样本仅为心理学学生，可能存在激励与专业背景偏差；
• 仅测试ChatGPT‑4o的chat接口，无法控制或调整模型超参数；
• 仅使用AUT（原创性）评估，未覆盖灵活性、细节化等其它创意维度；
• Prompt设计与时间限制对人类和机器可能影响不一致，未系统探究；
• 训练数据未知，可能存在训练集与测试任务的重叠；
• 仅评估一次交互，缺乏对模型多样性与跨模型的比较。

---

## 706. Twinning Complex Networked Systems: Data-Driven Calibration of the mABCD Synthetic Graph Generator

**arXiv ID:** 2602.02044 | [PDF](https://arxiv.org/pdf/2602.02044v1)

**作者:** Piotr Bródka `[一作]` (Wrocław University of Science and Technology), Mateusz Stolarski `[通讯]` (Wrocław University of Science and Technology)

**通讯引用:** 470 | [OpenAlex ID](https://openalex.org/A5046028927)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `5b4c1114-4a70-478e-9921-2514ee03850d` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出一种用于多层网络生成器参数恢复的模块化方法，通过从实际网络估计生成器配置以生成数字孪生。

**💡 创新点**

创新点在于将参数分组独立估计、引入贝叶斯优化寻找隐含层相关参数并给出一系列差异度量，证明单独估计存在不可避免的交互误差。

**🔧 技术方法**

主要使用贝叶斯优化、社区检测（贪心模块度）、Kendall τ、AMI、KS检验等统计与机器学习技术实现参数推断。

**📊 数据集**

实验使用Freebase多层网络（3层、3492个节点）作为真实数据集进行验证。

**📈 对比分析**

通过比较不同参数估计策略下的γ、β、ξ、τ、r等差异度量，发现针对单一度量优化能显著降低该度量但会导致其他度量增大，整体性能表明方法可获得合理数字孪生但存在权衡。

**⚠️ 局限性**

局限性包括参数之间的强耦合导致独立估计精度受限、无法自动确定参考层维度d、未给出统一累积差异评分、对非幂律度分布/社区大小的网络需要进一步改进。

---

## 707. Constrained Process Maps for Multi-Agent Generative AI Workflows

**arXiv ID:** 2602.02034 | [PDF](https://arxiv.org/pdf/2602.02034v1)

**作者:** Ananya Joshi `[一作]` (Johns Hopkins University), Michael Rudow `[通讯]` (Treseder AI)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种基于有限时间马尔可夫决策过程（MDP）的多代理合规框架，用多代理LLM按照预定义的有向无环图（DAG）协同评估文本，结合蒙特卡洛估计实现不确定性量化。

**💡 创新点**

创新点在于：1) 将传统合规工作流程映射为有向无环的MDP，使得不同阶段代理的决策与升级路径可明确建模；2) 通过每个代理的蒙特卡洛采样实现代理层的不确定性评估，并将其传递至整个MDP，形成两层不确定性耦合；3) 采用可扩展的采样规模与阈值策略，兼顾准确率、人工审核负担与延迟。

**🔧 技术方法**

主要技术包括：有限时间DAG‑MDP建模、蒙特卡洛采样估计代理不确定性、基于多数投票或阈值的静态策略π、批量并行执行与可插拔代理接口。

**📊 数据集**

使用 NVIDIA AEGIS 2.0 AI 安全基准数据集（112 条自残/自杀相关聊天记录，68 条安全，44 条不安全）进行实验。

**📈 对比分析**

与单代理链式思考（CoT）基线对比；在三种采样规模（n=1, 3, 5）下，平均准确率提升约16%（最高19%），人工审核量平均下降约32倍（最高85倍），误报率保持在基线置信区间内，误检率显著下降；同时，处理时间随采样规模增大而升高。

**⚠️ 局限性**

局限性包括：① 需要先验的工作流程与SOP映射，手工定义代理与升级路径；② 静态阈值策略π在不同场景下可能欠优，需进一步学习或自适应；③ 蒙特卡洛采样规模增大会带来计算成本与延迟；④ 仅在自残检测任务验证，跨领域通用性与鲁棒性待进一步验证。

---

## 708. Hippasus: Effective and Efficient Automatic Feature Augmentation for Machine Learning Tasks on Relational Data

**arXiv ID:** 2602.02025 | [PDF](https://arxiv.org/pdf/2602.02025v1)

**作者:** Serafeim Papadias `[一作]` (Athena Research Center), Dimitrios Skoutas `[通讯]` (Athena Research Center)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种模块化框架，利用大型语言模型和统计信号实现关系数据库中的特征扩增，显著提升模型性能；

**💡 创新点**

创新点在于将路径探索、连接执行和特征选择三大阶段解耦，采用LLM语义评分配合轻量统计信号进行路径预裁剪，使用Suffix‑Yannakakis多路连接与特征描述生成器和混合统计‑语义特征选择器；

**🔧 技术方法**

核心技术包括大型语言模型（如GPT‑4o‑mini、Llama‑3.3‑70B等）、轻量统计指标（覆盖率、唯一性、大小比）、Yannakakis多路连接算法、特征描述生成与语义评分、混合统计‑语义特征筛选；

**📊 数据集**

在12个公开基准上验证：School、Credit、Eyemove、Steel、Jannis、Miniboone、Covertype、Diabetes、Fraud、Poverty、Air、Northwind；

**📈 对比分析**

与ARDA、AutoFeat、FeatPilot三大基线对比，平均提升26.8%（ARDA）、14.5%（AutoFeat）和18.6%（FeatPilot）；在9/12数据集上取得最高准确率/MAE，运行时相较FeatPilot快60×，相较ARDA快5×，与AutoFeat相当；

**⚠️ 局限性**

局限性包括对LLM推理成本的依赖、仅支持预先构建的PK‑FK连接图、对数据湖/相似连接场景支持不足、对极大表集的可扩展性仍待验证以及对已有丰富特征名的收益有限。

---

## 709. Rethinking Genomic Modeling Through Optical Character Recognition

**arXiv ID:** 2602.02014 | [PDF](https://arxiv.org/pdf/2602.02014v1)

**作者:** Hongxin Xiang `[一作]` (Hunan University), Xiangxiang Zeng `[通讯]` (Hunan University)

**通讯引用:** 16466 | [OpenAlex ID](https://openalex.org/A5027286013)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `67630363-6be0-4f51-ab05-7198250671a5` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c773407a-6119-4871-b8b3-1e7ae17a6851` `e15e3743-5ee0-4d5f-813d-d146868082fc` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

通过将 DNA 序列渲染为二维可视化文档，并使用 OCR 样式的视觉–语言模型进行预训练，提出 OpticalDNA 用以高效建模长序列基因组。

**💡 创新点**

首次将基因组建模框架转化为 OCR 文档理解问题，利用视觉编码器生成可压缩视觉 token，并通过提示式任务学习区域感知表示，实现低 token 预算下的长程功能预测。

**🔧 技术方法**

采用 SAM‑Conv‑CLIP‑L 视觉前端 + 线性投影 + 多页融合；文档解码器 DeepSeek‑3B；六类 OCR‑style 提示任务；LoRA 微调；自监督的自动回归目标。

**📊 数据集**

训练使用人类 hg38 与稻谷 Nipponbare O. sativa japonica 基因组；评估使用 DNALONGBENCH（eQTL）、RiceSubBench（亚种泛化）和 RiceWGPB（全基因组表型）等公开基准。

**📈 对比分析**

与 HyenaDNA、Caduceus‑Ph、JanusDNA、Evo‑2、LucaOne 等基线对比，平均 AUROC 提升至 0.852（比 JanusDNA 高 7.7%），在稻谷亚种和全基因组表型任务上亦取得最高准确率/低 RMSE，且仅需 256k 训练参数或 409M 代表模型，显著降低激活参数与 token 数。

**⚠️ 局限性**

依赖 2D 渲染导致额外的图像预处理成本；对极长序列的页数上限与视觉模型的分辨率限制；在非标准基因组结构或大规模多物种数据时的通用性仍需验证。

---

## 710. SNAP: A Self-Consistent Agreement Principle with Application to Robust Computation

**arXiv ID:** 2602.02013 | [PDF](https://arxiv.org/pdf/2602.02013v1)

**作者:** Xiaoyi Jiang `[一作]` (University of Münster), Andreas Nienkötter `[通讯]` (Sichuan University)

**通讯引用:** 26 | [OpenAlex ID](https://openalex.org/A5064665597)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种基于相互一致性的自监督鲁棒计算框架 SNAP，给出权重计算与应用方法。

**💡 创新点**

创新点在于：① 无监督、参数无关的相互一致性权重机制；② 证明异常值权重指数衰减；③ 在任意空间（包括非度量空间）可用，兼顾向量平均与子空间估计。

**🔧 技术方法**

使用的技术包括：对所有实体的成对距离计算、归一化误差分数、指数/高斯核转换为权重、加权极值/最小化求解（如加权 Weiszfeld、加权 PCA）以及理论分析（指数抑制、全局 Lipschitz 稳定性等）。

**📊 数据集**

实验数据集为合成数据：在 ℝ^m（m=2, 50）中采样正态内点，随后在 [0,10] 采样均匀分布外点，样本总数 200，重复 100 次。

**📈 对比分析**

与传统无权重算术平均、Weiszfeld 算法、两种多变量均值中值变体、PCA 等方法比较。SNAP 在所有比例的异常值（10%–49%）下均表现出更小的平均误差，尤其在高维下优势更显著；在向量平均中非迭代加权平均已优于迭代 Weiszfeld。

**⚠️ 局限性**

局限性：权重计算为 O(n²) 复杂度，规模受限；当前权重为任务无关，未针对特定任务细化；高维时对绝对距离敏感仍需近似加速。

---

## 711. Logic-Guided Vector Fields for Constrained Generative Modeling

**arXiv ID:** 2602.02009 | [PDF](https://arxiv.org/pdf/2602.02009v1)

**作者:** Ali Baheri `[一作]` (Rochester Institute of Technology), Ali Baheri `[通讯]` (Rochester Institute of Technology)

**通讯引用:** 293 | [OpenAlex ID](https://openalex.org/A5086511671)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `5b4c1114-4a70-478e-9921-2514ee03850d` `40105733-5154-44cd-8090-a8cab9e64b07` `a8e75ba4-7a2d-4153-b003-06c94533add0`

**🎯 论文内容**

提出一种结合符号逻辑和流匹配生成模型的框架 LGVF，用来在生成过程中强制满足约束。

**💡 创新点**

创新点是同时在训练时通过轨迹级逻辑损失引导向合法路径，在推理时用梯度调整进一步纠正偏离，从而在不显著损失分布质量的前提下大幅降低约束违规率。

**🔧 技术方法**

采用条件流匹配（flow matching）、可微逻辑约束（violation function）和基于梯度的推理时间调整（logic-guided ODE correction）。

**📊 数据集**

在二维线性半平面、非线性环形以及多障碍避障等人工设计的分布上进行实验，并在更高维度的线性半空间任务上验证可扩展性。

**📈 对比分析**

与标准流匹配（Flow Matching）比较，LGVF+调整在所有约束下将违规率从1.5%–14.8%降低至0%–0.4%，并在线性、环形约束中保持甚至提升 MMD 指标；在多障碍场景中虽然 MMD 略有提升，但违规率下降了59%。

**⚠️ 局限性**

局限性包括对极度非凸约束在训练阶段可能表现不佳、需预先给定可微违反函数、以及在复杂高维真实数据（如图像、分子）上的可迁移性仍待验证。

---

## 712. Reformulating AI-based Multi-Object Relative State Estimation for Aleatoric Uncertainty-based Outlier Rejection of Partial Measurements

**arXiv ID:** 2602.02006 | [PDF](https://arxiv.org/pdf/2602.02006v1)

**作者:** Thomas Jantos `[一作]` (University of Klagenfurt), Jan Steinbrener `[通讯]` (University of Klagenfurt)

**通讯引用:** 3636 | [OpenAlex ID](https://openalex.org/A5058140409)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `3855fcda-48ef-4070-a15e-803cd5c84d83` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `51c0528b-f690-4182-ae60-bb5f046c276c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种直接使用 6-DoF 物体相对姿态测量的 EKF 方案，结合深度学习模型产生的 aleatoric 不确定性实现动态测量噪声协方差，并在此基础上引入部分异常检测，以提升物体相对状态估计的鲁棒性与一致性。

**💡 创新点**

创新点在于：①取消传统逆测量导致的姿态误差传播，解耦位置与旋转测量；②利用 DNN 的 aleatoric 不确定性做实时测量噪声估计，消除固定协方差的人工调参；③实现对 6-DoF 测量的部分拒绝（仅拒绝旋转或平移），大幅降低错误姿态对状态估计的影响。

**🔧 技术方法**

主要技术包括：基于 EKF 的直接测量更新公式、PoET 等深度网络实现 6-DoF 姿态与 aleatoric 预测、Hungarian 匹配、χ² 异常检测与基于阈值的 aleatoric 异常拒绝、Monte Carlo 仿真、NVIDIA Omniverse IsaacSim 合成仿真环境。

**📊 数据集**

使用 YCB‑V 子集在 NVIDIA Omniverse IsaacSim 生成的合成 RGB+IMU 数据，涵盖从纹理丰富到对称、遮挡等多种场景。

**📈 对比分析**

通过在不同平移/旋转噪声水平下进行 100 次 Monte Carlo 仿真，与传统逆测量 EKF 进行对比，结果显示在高旋转噪声（≥5°）下直接测量方案 RMSE 下降约 30%；在合成轨迹上，结合 aleatoric 动态协方差与部分拒绝的组合，使位置 RMSE 降至 0.11 m，姿态 RMSE 降至 3.2°，ANEES 接近 1，表现显著优于固定协方差或全拒绝策略。

**⚠️ 局限性**

局限性包括：①需要人工设置异常阈值，阈值对不同对象/场景的适应性有限；②仅支持对 6-DoF 组合或全/部分拒绝，未实现单个分量（如单一旋转轴）细粒度拒绝；③实验仅基于合成数据，缺乏真实光照、遮挡与传感器噪声的验证；④对计算开销与实时性未做深入评估。

---

## 713. Position: The Need for Ultrafast Training

**arXiv ID:** 2602.02005 | [PDF](https://arxiv.org/pdf/2602.02005v1)

**作者:** Duc Hoang `[一作]` (Massachusetts Institute of Technology), Duc Hoang `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 643 | [OpenAlex ID](https://openalex.org/A5037911735)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `64443552-63e0-44b5-906f-d90fe95c5a1b`

**🎯 论文内容**

提出将 FPGA 从仅推理加速器转变为支持超快在线学习的架构，以实现子微秒级实时自适应。

**💡 创新点**

将训练与推理统一在同一实时数据路径中，并针对固定精度、极低延迟的约束提出协同设计的算法、架构与工具流。

**🔧 技术方法**

利用固定点算术、稀疏/结构化模型、梯度累计缓冲、实时 RL 控制以及硬件友好的优化器等技术。

**📊 数据集**

未给出实验数据集，仅在量子校准、相机、粒子探测等典型场景做理论分析。

**📈 对比分析**

未进行实验对比；作者指出现有推理框架如 hls4ml、FINN 只能满足推理，缺乏实时学习功能。

**⚠️ 局限性**

受限于硬实时、有限本地存储、低精度数值不稳定、现有工具流以推理为中心，导致学习效率低、难以满足子微秒预算。

---

## 714. Optimizing Tensor Train Decomposition in DNNs for RISC-V Architectures Using Design Space Exploration and Compiler Optimizations

**arXiv ID:** 2602.01996 | [PDF](https://arxiv.org/pdf/2602.01996v1)

**作者:** Theologos Anthimopoulos `[一作]` (Aristotle University of Thessaloniki), Georgios Keramidas `[通讯]` (Aristotle University of Thessaloniki)

**通讯引用:** 1122 | [OpenAlex ID](https://openalex.org/A5074371053)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `fede83ac-7505-405f-ab37-e7284695c47f` `64443552-63e0-44b5-906f-d90fe95c5a1b` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一套完整的低秩分解设计空间探索（DSE）方法和针对RISC‑V的编译器优化工具，用于压缩和加速神经网络中的全连接层。

**💡 创新点**

创新点包括：① 形状对齐策略能在不计算确切FLOPs/内存的情况下剪枝大规模设计空间；② 针对RISC‑V的向量化与可扩展性约束筛选出高效方案；③ 结合数组打包、向量化、寄存器打包、缓存分块和多线程并行的多层次编译优化，显著提升运行时性能。

**🔧 技术方法**

技术：Tensor‑Train Decomposition（TTD）在TensorFlow T3F库实现；设计空间搜索与过滤；RISC‑V向量化、循环重排、寄存器打包、缓存分块、OpenMP/线程并行等编译层面优化；对比工具包括IREE、Pluto和GCC O3。

**📊 数据集**

数据集：CNN模型（LeNet5、LeNet300、AlexNet、VGG、GoogleNet、Xception、ResNet）使用MNIST、CIFAR‑10/100、ImageNet；LLM模型（GPT‑2、GPT‑3）使用WebText，嵌入维度为50257。

**📈 对比分析**

对比方法：与未压缩的IREE、IREE的MMM内核、Pluto等进行比较；实验显示在相同压缩模型下TTD层平均比IREE快3×、比Pluto快8×；在完整模型上相比未压缩IREE平均获得12×加速；与GCC O3相比经过所有编译优化可提升37×。

**⚠️ 局限性**

局限性：未对压缩后的模型精度做完整评估；对极小的FC层压缩效果有限；仅支持RISC‑V平台；rank值需为向量长度的整数倍（目前取8），限制了搜索空间；编译优化需离线预处理，对动态负载不适用；仍需在更大模型和更高维嵌入上验证。

---

## 715. Belief Updating and Delegation in Multi-Task Human-AI Interaction: Evidence from Controlled Simulations

**arXiv ID:** 2602.01986 | [PDF](https://arxiv.org/pdf/2602.01986v1)

**作者:** Shreyan Biswas `[一作]` (Delft University of Technology), Ujwal Gadiraju `[通讯]` (Delft University of Technology)

**通讯引用:** 3741 | [OpenAlex ID](https://openalex.org/A5038081564)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在三种不同任务（语法校正、旅行规划、视觉问答）中，研究者设计了预先设定准确率的AI模拟，招募240名受试者完成7200个试验，探究用户如何在跨任务情境下形成、更新并依赖AI的信念。

**💡 创新点**

本研究首次系统检验了跨任务信念迁移、贝叶斯更新偏差、委托决策与自信度及个体差异（如对自动化的固有信任）之间的关系，揭示了用户在多任务AI使用中存在的信念惯性和保守更新。

**🔧 技术方法**

采用实验方法收集逐试信念、委托与自信度数据，并用混合效应模型、逻辑回归和贝叶斯规范比较，验证H1–H5假设。

**📊 数据集**

使用公开数据集（CoNLL‑2014、TravelPlanner、OK‑VQA）作为真实答案来源，并预先生成AI输出以实现30%、60%和90%的固定准确率。

**📈 对比分析**

与贝叶斯理论更新步骤对比，发现用户更新幅度约为规范值的一半（保守偏差）；委托行为主要由信念驱动，信心在控制信念后仍有负向影响；跨任务先验信念受到前一次后验的显著影响。

**⚠️ 局限性**

局限包括任务仅覆盖三类功能，AI准确率固定且预先脚本化，缺乏真实LLM动态表现；立即得到真值反馈不完全符合大多数实际AI使用情境，且未考察任务难度对结果的具体影响。

---

## 716. Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning

**arXiv ID:** 2602.01983 | [PDF](https://arxiv.org/pdf/2602.01983v1)

**作者:** Xintian Shen `[一作]`, Kun Zhan `[通讯]`

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个训练‑自由的自我进化工具构建框架 UCT，使代理从仅使用工具转变为能够在推理过程中动态生成并维护可复用工具库；

**💡 创新点**

创新点在于：①将工具生成视为推理经验的再利用；②在线工具构建循环与离线记忆合并两阶段设计，保证工具质量与库可维护性；③无需额外训练即可持续提升代理能力；

**🔧 技术方法**

主要技术包括：ReAct 推理范式、Qwen3‑VL‑235B‑Thinking 大语言模型、代码生成与沙箱测试、代码批评模型、离线工具库去重合并、自动化工具接口规范；

**📊 数据集**

使用的数据集有：TRBench（959 个跨数学、科学与 VQA 的工具推理任务），以及 DynaMath、MathVerse、MathVista、MathVision、Scibench、Scieval、SimpleVQA 等原始基准；

**📈 对比分析**

与 Basic‑CoT、Vanilla Tool、CREATOR、CRAFT 以及 Gemini‑2.5‑pro 进行对比；在 TRBench 上取得 +20.86%（Qwen3‑VL‑235B‑Thinking）和 +23.04%（Gemini‑2.5‑pro）的显著提升，整体性能达到 SOTA；工具复用率高达 93.1%，表明工具库质量优秀；

**⚠️ 局限性**

局限性：工具库扩展性受限于训练集多样性，随着推理次数增加性能趋于饱和；对全新领域的适应仍依赖大模型的泛化能力；生成工具过程偶尔会出现错误，需进一步提升检验与回溯机制。

---

## 717. S3-CoT: Self-Sampled Succinct Reasoning Enables Efficient Chain-of-Thought LLMs

**arXiv ID:** 2602.01982 | [PDF](https://arxiv.org/pdf/2602.01982v1)

**作者:** Yanrui Du `[一作]` (Harbin Institute of Technology), Mengling Feng `[通讯]` (National University of Singapore)

**通讯引用:** 12003 | [OpenAlex ID](https://openalex.org/A5022222926)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并实现了一种自采样框架S^3-CoT，通过激活方向干预从LLM自身生成多长度的Chain-of-Thought（CoT）数据，并利用SFT实现高效CoT学习。

**💡 创新点**

创新点包括：①无需教师或外部工具即可生成高质量、风格一致、可变长CoT；②引入自一致性验证实现完全自进化的训练流程；③结合双认知系统与渐进压缩课程，兼顾准确率与长度。

**🔧 技术方法**

主要技术手段为：激活方向干预（VL‑D）、自一致性验证、基于LoRA的SFT、双系统（System‑1/2）提示、渐进压缩训练课程。

**📊 数据集**

使用的数据集为：主训练集GSM8K，评测基准包括MATH、AMC23、AIME24、MedQA、MedMCQA、BULLET；实验还基于PRM12K验证跨数据集适用性。

**📈 对比分析**

与prompt‑control、SFT（TokenSkip、C3oT、CoT‑Valve）以及RL（ShorterBetter、LC‑R1、Eff_Rea、LASER_DE、AutoTHINK）等方法对比，S^3-CoT在准确率‑长度折中（AES）上达最佳或接近最佳表现，压缩率明显优于SFT基线，且仅需较少算力（2×A100 GPU）。

**⚠️ 局限性**

主要局限：对R1‑style LLM仍存在轻微准确率下降；尚难以突破精度‑长度Pareto前沿；完全自进化模式受模型能力限制；未充分探索与RL结合的进一步提升。

---

## 718. Situated Brushing and Linking in Virtual and Augmented Reality

**arXiv ID:** 2602.02023 | [PDF](https://arxiv.org/pdf/2602.02023v1)

**作者:** Carlos Quijano-Chavez `[一作]` (University of Stuttgart), Dieter Schmalstieg `[通讯]` (University of Stuttgart)

**通讯引用:** 16411 | [OpenAlex ID](https://openalex.org/A5048047909)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文在AR与VR环境中对三种改进的可视高亮技术（粗轮廓、动画轮廓、动画轮廓+链接）进行对比实验，探究其在真实与虚拟超市场景中的表现。

**💡 创新点**

创新点在于结合视频透视AR技术与VR模拟，细化并改进了Doerr等人提出的高亮方案，并引入动画颜色与视觉链接来提升定位效率与准确性。

**🔧 技术方法**

使用Meta Quest 3 HMD进行VR与VST‑AR渲染，Unity 3D实现交互，配合自制的3D超市模型与投影图像。

**📊 数据集**

数据集为从德国区域超市网站抓取的500+商品元数据（名称、价格、图像等），选取263件盒装商品，包含10个营养属性，构成实验超市。

**📈 对比分析**

采用within‑subject 2×3设计，共720次试验；评估指标包括完成时间、链接时间、错误率、NASA‑TLX、SUS和IPQ；结果显示AR在选择任务中链接时间更短、错误率更低，动画链接在VR中最快但准确率最低，整体性能因显示模式与技术细节而异。

**⚠️ 局限性**

主要限制包括使用印刷海报替代真实商品降低了视觉真实感、仅用一种HMD（Meta Quest 3）导致可推广性受限，以及实验未将高亮与刷选过程拆分，可能掩盖两者的相互影响。

---

## 719. Preserve-Then-Quantize: Balancing Rank Budgets for Quantization Error Reconstruction in LLMs

**arXiv ID:** 2602.02001 | [PDF](https://arxiv.org/pdf/2602.02001v1)

**作者:** Yoonjun Cho `[一作]` (Yonsei University), Albert No `[通讯]` (Yonsei University)

**通讯引用:** 506 | [OpenAlex ID](https://openalex.org/A5049196468)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 Structured Residual Reconstruction (SRR) 方法，在低秩预算下通过先保留前 k 个奇异方向再量化残差，平衡子空间保留与量化误差重建，从而提升 LLM 的 PTQ 与 QPEFT 效果。

**💡 创新点**

创新点在于将低秩预算显式分配给结构保留与误差重建两项，并给出理论驱动的 k 选取准则；同时在 QPEFT 中引入对保留子空间的梯度缩放，进一步提升训练稳定性和性能。

**🔧 技术方法**

使用技术包括截断 SVD、随机矩阵探测近似量化误差谱、激活感知量化（S），以及梯度缩放策略；整体实现为一个轻量级的后训练量化框架。

**📊 数据集**

实验数据集涵盖 WikiText‑2、GLUE、RoBERTa‑base、LLaMA‑2/3.1、TinyLlama、Gemma‑2、SlimPajama 与 GSM8K，覆盖多模型、多规模与多量化位宽。

**📈 对比分析**

与 QER、LQER、QERA、LoRA、QLoRA、LoftQ 等基线在 3/2‑bit 量化下对比，SRR 在 PTQ 上平均降低 perplexity 5–27%，在 QPEFT 上提升 0.5–5.9 个百分点，展示显著的性能提升。

**⚠️ 局限性**

局限性包括：需要额外 SVD 计算开销、对低秩假设敏感、k 的选择依赖随机探针且可能略有波动、在极低比特（≤2‑bit）场景下仍面临一定的精度瓶颈。

---

## 720. Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data

**arXiv ID:** 2602.02067 | [PDF](https://arxiv.org/pdf/2602.02067v1)

**作者:** Nikola Cenikj `[一作]` (Technical University of Munich), Philip Müller `[通讯]` (Technical University of Munich)

**通讯引用:** 2306 | [OpenAlex ID](https://openalex.org/A5074684285)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

提出 SegmentMIL，利用多视角转化器和多实例学习实现冠状动脉狭窄的病人级诊断，并同时给出动脉和分段级别的预测。

**💡 创新点**

创新点包括：① 在无视角级标注的前提下，只用病人级标签即可训练；② 通过 Transformer 解码器对多视角特征进行聚合并产生分层查询，实现病人/动脉/分段级别的联合预测；③ 使用多帧（多时序）输入与学习的时间嵌入，捕获血管对比流的动态特征；④ 通过注意力权重实现零样本动脉分割，提升模型可解释性。

**🔧 技术方法**

技术栈：ViT‑S 视觉 Transformer 作为编码器，Transformer 解码器（带学习查询）进行特征聚合，MLP 分类头，层级化预测策略，损失加权三层监督，以及多帧时间嵌入。

**📊 数据集**

数据集：① 17,741 视角、2,003 病人（TUM Klinikum）临床数据，按病人级分成训练/验证/测试；② 382 视角、42 病人（CADICA）公开数据作为外部测试；③ 额外 760 视角、100 病人内部测试集（带视角级标注）用于视角级评估。

**📈 对比分析**

与 SteDet2Cls（YOLO 视角级检测器）、MaxMIL（实例级池化 MIL）和 AttnMIL（注意力 MIL）进行对比。SegmentMIL 在病人级 AUC 上达到 0.845（内部）/0.878（外部），相较于 SteDet2Cls 提升 20%+，MaxMIL 提升 13%，AttnMIL 提升 6%；在视角、动脉和分段级别也表现最优。

**⚠️ 局限性**

局限性：① 仅使用基于图像的编码器，未充分利用视频序列的时序信息；② 只关注 8 个大分段，未覆盖所有可能狭窄位置；③ 未结合临床病史、症状等多模态信息；④ 训练仅基于一组医院的内部数据，可能限制外部可推广性。

---

## 721. FiLoRA: Focus-and-Ignore LoRA for Controllable Feature Reliance

**arXiv ID:** 2602.02060 | [PDF](https://arxiv.org/pdf/2602.02060v1)

**作者:** Hyunsuk Chung `[一作]` (University of Melbourne), Kyungreem Han `[通讯]` (Korea Institute of Science and Technology)

**通讯引用:** 690 | [OpenAlex ID](https://openalex.org/A5084984855)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出了 FiLoRA，一种基于指令调节的参数高效适配框架，用以在不改变任务定义的前提下，显式控制多模态模型内部特征的依赖关系。

**💡 创新点**

创新点在于：①将 LoRA 拆分为按功能分组的子模块；②引入指令条件门控机制，使自然语言指令直接调节各特征组的激活强度；③利用伪目标标签在训练时诱导模型在不同依赖场景下学习，从而实现可解释的、可控制的特征依赖调节。

**🔧 技术方法**

技术手段包括：LoRA（低秩参数适配）、分组 LoRA、指令编码器（将指令映射为门控向量）、门控激活函数、soft‑gate 结合交叉熵损失以及轻量化门控正则化。

**📊 数据集**

使用的主要数据集有：视觉‑文本任务的 Tiny MM‑IMDb；音频‑视觉情绪识别任务的 CREMA‑D 与 RAVDESS。实验采用 Qwen2.5‑VL、Gemma‑3n‑E4B 等视觉‑文本模型，和 Qwen2.5‑Omni‑7B、AV‑HuBERT、AudioCLIP 等音频‑视觉模型。

**📈 对比分析**

评估方式：通过门控调节范围（GMR）和依赖灵敏度（RS）量化指令对内部特征组的影响；在去除或抑制伪特征的干预下计算决策稳定性和性能衰减曲线。结果显示，FiLoRA 在所有基准模型上均能显著提高对伪特征干预的鲁棒性，门控调节范围和依赖灵敏度明显高于全量微调、LoRA 与 prompt‑only 等基线，且性能衰减更平缓。

**⚠️ 局限性**

局限性：①特征组划分需要先验知识，无法自动适配所有模态；②实验仅覆盖少数任务与数据集，需验证在更大规模、多模态、跨领域任务中的泛化；③指令条件门控对极端或模棱两可的指令表现尚未充分评估；④仅在训练时使用伪目标标签，推理阶段仍需保证模型对真实标签的正确性。

---

## 722. Quantifying the Gap between Understanding and Generation within Unified Multimodal Models

**arXiv ID:** 2602.02140 | [PDF](https://arxiv.org/pdf/2602.02140v1)

**作者:** Chenlong Wang `[一作]`, Tianyi Zhou `[通讯]` (MBZUAI)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建了一个双向评测基准，用于量化统一多模态模型（UMM）在理解与生成两大能力上的差距，并通过知识注入/编辑实验探究知识跨模态不一致性。

**💡 创新点**

首次提出双向基准与Gap Score度量，系统评估理解与生成的对称一致性，并通过知识操作实验揭示UMM知识表征的分离现象。

**🔧 技术方法**

采用多维项目反应理论（MIRT）构造Gap Score，结合GPT‑5‑mini作为评判者，进行知识注入/编辑微调实验，使用CLIP进行图像相似度评估。

**📊 数据集**

基准共646条高质量题目，涵盖指令跟随、数值感知、世界知识与推理四类，题目来自手工设计与现有数据集（MMMU、MMLU等）改编。

**📈 对比分析**

对比9种UMM、6种非UMM以及生成/理解单向模型，使用Success/Understanding/Generation Score及Gap Score进行评估；结果显示大多数UMM在两模态上表现不均衡，Gap Score普遍偏高，表明仅实现工程级统一。

**⚠️ 局限性**

模型虽在单模态任务表现优异，但跨模态知识迁移受限，生成能力往往低于单向模型，且知识更新需大量训练，导致两侧学习动态不同。

---

## 723. DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations

**arXiv ID:** 2602.02137 | [PDF](https://arxiv.org/pdf/2602.02137v1)

**作者:** Minghao Li `[一作]` (Nanyang Technological University), Yonggang Wen `[通讯]` (Nanyang Technological University)

**通讯引用:** 18682 | [OpenAlex ID](https://openalex.org/A5041572550)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出 DCoPilot 框架，实现动态数据中心（DC）在分钟级控制窗口内的即时、零样本自适应控制策略生成。

**💡 创新点**

创新点：① 将大语言模型（LLM）用于符号化生成统一奖励形式；② 用超网络（hypernetwork）在参数层面即时合成针对任意规格的控制策略；③ 通过离线“模拟放大”和“奖励演化”三阶段训练，将设计-策略延迟降至零。

**🔧 技术方法**

使用技术包括：大语言模型（LLM）进行奖励代码生成、离线强化学习（DRL）训练策略、超网络进行策略权重生成、SimReady 物理仿真引擎用于生成场景与轨迹、以及元学习与强化学习混合训练。

**📊 数据集**

数据集：基于 SimReady 的仿真数字孪生，生成多种服务器密度与 SLA 组合的任务样本；实验中使用的是真实数据中心配置参数（如服务器功耗、温度阈值）进行模拟。

**📈 对比分析**

方法对比：与三种 LLM 直接生成控制、演化奖励+DRL 以及传统基准（PID、Meta‑Env+Rew）比较。DCoPilot 在五类任务中平均违约成本低于 0.2，显著优于基准（0.77–8.78）；在 40 天线上演化场景中维持近零违约；在温度 MAE、能耗等指标上亦优于 MAML/PEARL 等元学习方法。

**⚠️ 局限性**

局限性：① 依赖仿真模型，真实环境中存在动力学与传感器噪声误差；② LLM 与超网络训练缺乏严格的收敛与安全保证；③ 目前仅支持可参数化的同质化规格变更，无法处理拓扑结构的异质化改动；④ 通过奖励形状实现软约束，缺少在线时刻的硬约束保障。

---

## 724. Two-Stage Coded-Sliding Beam Training and QoS-Constrained Sum-Rate Maximization for SIM-Assisted Wireless Communications

**arXiv ID:** 2602.02131 | [PDF](https://arxiv.org/pdf/2602.02131v1)

**作者:** Qian Zhang `[一作]` (Shandong University), Chau Yuen `[通讯]` (Nanyang Technological University)

**通讯引用:** 41368 | [OpenAlex ID](https://openalex.org/A5060020877)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一套面向堆叠智能金属表面（SIM）无线通信的低复杂度算法框架，包括基于二维角域解耦的两步码本构造（TSCC）、两阶段编码滑动波束训练（TSCSBT）以及可变分解块上界最小化（VD‑BSUM）优化策略，以实现高效的信道状态信息获取与波束赋形；

**💡 创新点**

创新点在于①将二维波束形成问题拆解为两个一维线性阵列设计，显著降低码本构造的计算复杂度；②将纠错码嵌入滑动波束训练中，提升噪声鲁棒性与角度分辨率；③提出VD‑BSUM直接解决带QoS约束的总速率最大化，采用闭式迭代更新并显著减少运算量；

**🔧 技术方法**

主要技术包括Gerchberg–Saxton算法、基于近似最小化的PDMM、误差校正的Hamming编码、滑动采样（Sliding Beam Training）、权重最小均方误差（WMMSE）与BSUM框架、IPDD惩罚分解等；

**📊 数据集**

采用仿真数据，设置30 GHz载波、噪声功率−80 dBm、SIM厚度5λ、N₁=N₂=16、不同层数L、用户数K=3等参数进行性能评估；

**📈 对比分析**

与传统EBT、HBT、SCA、SDR等方法比较，TSCSBT在相同或更低训练开销下实现更高角度估计精度与更大总速率；VD‑BSUM在保持或提升总速率的同时，比SCA和SDR的平均运行时间低至少2.8倍，且在QoS约束下显著提高用户公平性；

**⚠️ 局限性**

局限性主要体现在：①仿真场景假设主射道（LoS）主导，非LoS效应未充分考虑；②需要预先知道或估计多径分量的数目和阈值；③对SIM元件的相位控制精度和硬件误差未建模，实际部署可能受限。

---

## 725. Efficient Swap Regret Minimization in Combinatorial Bandits

**arXiv ID:** 2602.02087 | [PDF](https://arxiv.org/pdf/2602.02087v1)

**作者:** Andreas Kontogiannis `[一作]` (National Technical University of Athens), Ioannis Panageas `[通讯]` (University of California)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出了一种新的组合式Bandit算法（Swap-ComBCP），实现了无交换（no‑swap）退化的极限调度，且在动作数为指数级的组合空间中退化量仅为多对数级别。

**💡 创新点**

创新点包括：
- 首次在组合Bandit问题上实现了多对数级别的交换退化与每步复杂度；
- 通过多尺度惰性学习（Master+ScaleLearners）把交换退化拆解为外部退化的和；
- 在惰性子算法Lazy‑CombBCP中引入了近似Barycentric spanner、Carathéodory分解和KL投影，实现了高效更新与低复杂度；
- 证明该算法在任何组合结构（m‑sets、路径、生成树等）下均可实现，且上界与下界一致。

**🔧 技术方法**

主要技术：
- 多尺度惰性学习框架（master learner + ScaleLearners）
- 交换退化到外部退化的理论化简（swap‑to‑external regret reduction）
- Lazy‑CombBCP：近似Barycentric spanner、Carathéodory分解、KL投影、坐标空间更新
- 双倍技巧（doubling trick）用于任何时刻的性能保证
- 结合外部退化与内部惰性分析，得到O(T log(d log T)/log T) 的退化上界。

**📊 数据集**

本工作主要为理论分析，不使用具体数据集；所有结论均在任意无记忆（oblivious）对手环境下成立。

**📈 对比分析**

与现有工作比较：
- 与传统外部退化算法相比，Swap‑ComBCP在交换退化上实现了多对数级别的改进；
- 与之前的多项式依赖于N的交换退化算法相比，Swap‑ComBCP将复杂度从多项式降到多对数；
- 上界与理论下界（Ω(T/ log^6 T)）基本一致，表明结果在T=poly(d,m)时已达到最优；
- 在已知结构的组合设置（路径、生成树、k‑forests等）下，算法可实现每步多项式时间。

**⚠️ 局限性**

局限性：
- 常数与多项式因子仍较大，实际实现需要进一步优化；
- 仅给出期望退化上界，缺乏高概率或PAC形式的保证；
- 目前仅适用于无记忆对手（oblivious）环境，随机或自适应对手的分析尚未完成。

---

## 726. Active learning from positive and unlabeled examples

**arXiv ID:** 2602.02081 | [PDF](https://arxiv.org/pdf/2602.02081v1)

**作者:** Farnam Mansouri `[一作]` (University of Waterloo), Shai Ben-David `[通讯]` (University of Waterloo)

**通讯引用:** 16349 | [OpenAlex ID](https://openalex.org/A5112193907)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

**🎯 论文内容**

提出了主动正负无标签（PU）学习的标签复杂度理论分析，并给出了相应的算法。

**💡 创新点**

首次给出了主动 PU 学习的标签复杂度上界，并在正类先验未知时通过二分搜索估计实现了自适应版本空间修剪。

**🔧 技术方法**

利用不一致率（disagreement coefficient）框架、Chernoff 与 PAC 误差界，以及 PU 学习中的 SCAR 假设进行分析。

**📊 数据集**

论文仅进行理论推导，没有使用实际数据集进行实验。

**📈 对比分析**

与经典 CAL 算法的标签复杂度相比，额外因子为 θ/ω；当 ω=1 时结果接近传统主动学习的 θ 因子，表明在标签稀缺情形下的性能保持在可接受范围。

**⚠️ 局限性**

局限性：仅适用于连续分布，θ² 的依赖可能非最优；未涵盖非可实现（agnostic）情况，也未提供实验验证。

---

## 727. FD-VLA: Force-Distilled Vision-Language-Action Model for Contact-Rich Manipulation

**arXiv ID:** 2602.02142 | [PDF](https://arxiv.org/pdf/2602.02142v1)

**作者:** Ruiteng Zhao `[一作]` (National University of Singapore), Haiyue Zhu `[通讯]` (Singapore Institute of Manufacturing Technology)

**通讯引用:** 1084 | [OpenAlex ID](https://openalex.org/A5070425949)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `8d10c613-917e-4880-9716-17789f50e119` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了 FD‑VLA 框架，利用 Force Distillation Module 在无物理力传感器的情况下通过视觉和机器人状态推断出潜在的力信息，并将其注入预训练的视觉‑语言模型实现无感知的接触敏感控制。

**💡 创新点**

创新点在于：①通过学习查询令牌与视觉‑状态注意力机制将真实力信号迁移到潜在空间，实现力的知识蒸馏；②采用方向性注意力掩码在 VLM 内部实现感知与控制流的分离，避免破坏预训练语义；③在推理阶段完全不需要物理力传感器，实现硬件成本降低与部署灵活性提升。

**🔧 技术方法**

技术细节包括：多模态 Transformer（SmolVLM‑2）冻结预训练参数；Force Distillation Module（FDM）采用单查询多头注意力和辅助蒸馏损失；方向性注意力掩码确保感知与控制流的单向交互；动作专家使用条件流匹配（conditional flow‑matching）Transformer 生成动作序列。

**📊 数据集**

数据集：在 UR5e 机械臂上收集 3 个接触丰富任务（清白板、按紧急按钮、插入插头）的 50 条遥控演示，每条演示包含 RGB 图像、机器人状态、以及力/扭矩传感器测量；实验使用 Kinect Azure 与 RealSense D405 作为视觉传感器。

**📈 对比分析**

与 SmolVLA、π₀、DP3 等基线比较；在三项任务上 FD‑VLA 的平均成功率达 61.1%，显著高于 SmolVLA（无力输入 23.3%）、DP3（11.1%）和 π₀（46.7%）等；使用原始力输入的基线提升有限（仅 15–20%），而 FD‑VLA 通过力蒸馏实现更高精度与鲁棒性。

**⚠️ 局限性**

局限性：①依赖预训练 VLM，若 VLM 与任务域差异过大可能导致性能下降；②仅在三种任务和单一机器人上验证，缺乏更广泛的跨任务与跨平台评估；③在动态高频接触场景下的鲁棒性尚待验证；④训练阶段仍需力传感器数据，限制了完全无感知的学习流程。

---

## 728. Mitigating Safety Tax via Distribution-Grounded Refinement in Large Reasoning Models

**arXiv ID:** 2602.02136 | [PDF](https://arxiv.org/pdf/2602.02136v1)

**作者:** Yingsha Xie `[一作]` (Shenzhen Campus of Sun Yat-sen University), Li Shen `[通讯]` (Shenzhen Campus of Sun Yat-sen University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种分布驱动的细化方法（DGR），通过把外部安全数据重新表述为目标大推理模型（LRM）的内部分布，从而减轻安全对齐造成的“安全税”——推理能力下降。

**💡 创新点**

创新点在于：①识别并证明安全数据的分布差异是导致安全税的根本原因；②设计两阶段的分布细化流程（重述与质量控制），实现分布对齐；③证明仅用极少量（10条）样本即可激活拒绝行为，凸显安全对齐本质是知识激活。

**🔧 技术方法**

技术包括：①对目标LRM的prompt式重述（CoT与答案分别用专用模板）；②过度推理与元推理的自动过滤；③基于SFT的损失函数改写；④实验中使用QLoRA等参数高效微调。

**📊 数据集**

使用的安全数据集有DirectRefusal、STAR-1、R1-ACT三种；推理评测采用GPQA、MATH500、GSM8K、MMLU-Pro；安全评测使用JBB、StrongREJECT、WildJailbreak、BeaverTails。

**📈 对比分析**

与Vanilla SFT、STAIR、RECAP、RPSA等基线对比，DGR在保持甚至提升安全率（如DirectRefusal 99.5%）的同时，显著提升推理准确率（DirectRefusal +30.2%提升，R1-ACT +21.2%提升）。

**⚠️ 局限性**

局限性包括：①仅在SFT框架下验证，未扩展到RL（PPO/GRPO）安全对齐；②实验主要集中在7B模型，缺乏对更大规模模型（70B+）的系统评估；③对分布细化的prompt模板可能需针对不同任务调优。

---

## 729. Enhancing Diffusion-Based Quantitatively Controllable Image Generation via Matrix-Form EDM and Adaptive Vicinal Training

**arXiv ID:** 2602.02114 | [PDF](https://arxiv.org/pdf/2602.02114v1)

**作者:** Xin Ding `[一作]`, Fei Wu `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `de8d30ba-c289-43a5-b4ec-7b80df73aea2` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种改进版的连续条件扩散模型（iCCDM），实现了对连续回归标签的高质量可控图像生成。

**💡 创新点**

创新点在于将EDM框架迁移到矩阵形式，并引入条件感知噪声、权重系数 λ_y、硬自适应邻域训练以及轻量化协方差嵌入网络，显著提升生成质量与采样效率。

**🔧 技术方法**

技术上结合了矩阵形式的SDE/ODE、EDM预处理、UNet/DiT骨干、vicinal training、Heun/ SDE采样及CFG指导。

**📊 数据集**

使用了四个基准数据集：RC‑49（64×64）、UTKFace（64/128/192/256）、Steering Angle（64/128/256）和Cell‑200（64），覆盖姿态、年龄、转向角与细胞计数等场景。

**📈 对比分析**

与文本到图像扩散模型、GAN式CCGM模型以及原CCD模型对比，iCCDM 在大多数设置下 SFID 低于同类方法，且采样步骤仅 32 步即可获得 4 倍速度与更低显存。

**⚠️ 局限性**

局限性包括对 λ_y 参数的敏感性、在极大分辨率下仍受模型尺寸限制，以及对极少样本的连续标签分布仍可能出现标签一致性不足。

---

## 730. Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts

**arXiv ID:** 2602.02108 | [PDF](https://arxiv.org/pdf/2602.02108v1)

**作者:** Wenhao Li `[一作]` (Xiamen University), Zimu Liao `[通讯]` (Shanghai AI Laboratory)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一套名为 OOMB 的训练系统，能够在单张 H200 GPU 上高效训练具有数百万 token 长度上下文的大型语言模型。

**💡 创新点**

通过将分块递归训练、激活重算、分页 KV 缓存、异步 CPU 下放和页面级稀疏注意力相结合，实现了 O(1) 的激活内存占用并显著降低总显存需求。

**🔧 技术方法**

采用了分块串行训练、激活重算、Triton/CUDA 自定义核实现的分页 KV 缓存管理、异步 GPU‑CPU 数据传输、页面级稀疏注意力以及定制梯度累加内核。

**📊 数据集**

使用公开的 arXiv 文档数据集进行训练和评估。

**📈 对比分析**

与 FlashAttention、Ring Flash Attention 等基准进行对比，单 GPU 训练 4M token 长度时显存提升仅 10 MB/10K tokens，吞吐量比基线高数倍，显存利用率提升约 5 倍。

**⚠️ 局限性**

主要限制在于分块串行处理导致推理/训练延迟升高，稀疏注意力的近似可能对某些需要全局上下文的任务产生影响，并且异步下放性能依赖于 GPU‑CPU 高带宽互连。

---

## 731. Dicta-LM 3.0: Advancing The Frontier of Hebrew Sovereign LLMs

**arXiv ID:** 2602.02104 | [PDF](https://arxiv.org/pdf/2602.02104v1)

**作者:** Shaltiel Shmidman `[一作]` (DICTA), Moshe Koppel `[通讯]` (Bar Ilan University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

构建并公开了三种以希伯来语为主的开放权重大型语言模型（24B、12B、1.7B），并通过连续预训练、监督微调以及强化学习后训练（DPO、GRPO）实现了长上下文（65k）和推理能力。

**💡 创新点**

创新点包括：① 针对低资源语言希伯来语的专属大规模语料库与多源数据融合；② 通过连续预训练在现有 SOTA 模型（Mistral、Nemotron、Qwen）上快速迁移并扩展至 65k 上下文；③ 设计了“思考”（Thinking）chat 变体，将推理过程显式化，并结合工具调用；④ 提出了全新的希伯来聊天基准（Summarization、Translation、Israeli Trivia、Winograd、Nikud），填补了非英语聊天模型评测缺口。

**🔧 技术方法**

技术主要包括：连续预训练（两阶段，4k/65k 上下文）；监督微调（SFT）配合 65k 序列；Direct Preference Optimization (DPO) 与 Group Relative Policy Optimization (GRPO)；使用 NVIDIA NeMo、Megatron-LM、vLLM、NeMo-RL 训练框架；工具调用实现采用 Hermes 规范；tokenizer 采用 BPE 并为希伯来语优化。

**📊 数据集**

主要数据集：
- Hebrew 100B tokens（网页爬取、社交媒体、新闻、学术文献、书籍、标注数据）
- English 30B tokens（Nemotron-CC、FineWeb-Edu、SlimPajama 等）
- SFT 对话集（Hermes、Math、rStarCoder、SmolTalk、CCMatrix、Agent-Ark 等）
- DPO 偏好对（OpenAssistant、GPT-4o 辅助评估）
- GRPO 任务集（Instruction-Following、MATH、GSM8K、Nikud、UD Parsing 等）。

**📈 对比分析**

评测方法：
- 基础模型：希伯来 LLM Leaderboard（Few-shot）以及英文 Benchmarks（Commonsense QA、WinoGrande、ARC-Challenge）。
- 聊天模型：希伯来聊天基准（0-shot），使用 Gemini-2.5-Pro 对比评判；英文聊天基准使用 Olmes 库。 
- 性能表现：
  * 24B 在希伯来聊天任务上优于同参数规模的 gemma-3-12b-it 与 Qwen3-14B，并在某些任务上接近 30B+ 模型；
  * 12B 在希伯来任务上与 gemma-3-12b-it 接近，英文知识保持 98% 以上；
  * 1.7B 在希伯来任务上显著优于同类 1.7B 模型（如 Qwen3-1.7B）。
  * 思考（Thinking）变体在多项基准上提升 8–25% 准确率，同时产生的 token 数量下降。

**⚠️ 局限性**

局限性：
- 对代码生成等英语专业任务关注不足，工具调用在非英语场景下仍有限；
- 训练与评测主要集中在希伯来语和英语，缺乏对其他低资源语言的验证；
- 语料来源与标注多为开放资源，可能存在质量不均衡；
- 长上下文训练后在极长推理或实时部署时的计算成本仍高。

---

## 732. Approximation of Functions: Optimal Sampling and Complexity

**arXiv ID:** 2602.02066 | [PDF](https://arxiv.org/pdf/2602.02066v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232`

---

## 733. The Verification Crisis: Expert Perceptions of GenAI Disinformation and the Case for Reproducible Provenance

**arXiv ID:** 2602.02100 | [PDF](https://arxiv.org/pdf/2602.02100v1)

**作者:** Alexander Loth `[一作]` (Frankfurt University of Applied Sciences), Marc-Oliver Pahl `[通讯]` (IMT Atlantique)

**通讯引用:** 882 | [OpenAlex ID](https://openalex.org/A5004198506)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `b88c6eac-d57a-4623-a604-1f401f3eb268` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

对21名人工智能研究员、政策制定者和去信息化专家进行纵向调查，评估GenAI在文本、图像、音频和视频等多模态下的威胁与现有缓解策略。

**💡 创新点**

提出以可复现性与可追溯性为核心的“可信度基础设施”，强调对技术检测的怀疑以及通过标准化流程（如C2PA、Momeni‑Khan检查表、Methods Hub）实现可验证的防御体系。

**🔧 技术方法**

采用问卷调查、定性主题分析、最佳-最差排序等实证方法，并结合可复现性检查表和标准化容器化工作流程。

**📊 数据集**

主要使用专家调查数据（N=21），未使用公开数据集或生成对抗性样本；数据来源为专业背景与经验的自我报告。

**📈 对比分析**

通过对五类缓解策略（媒体素养、C2PA、水印、监管、平台执行、技术检测）的平均打分与最佳/最差比例进行比较，发现技术检测平均评分最低（≈3.4/7），而媒体素养与C2PA得分相对较高。

**⚠️ 局限性**

样本量有限且以欧洲专家为主，缺乏跨地区与更大规模验证；缺乏实验室级检测工具性能对比，无法量化可复现性方案的实际效果。

---

## 734. Probabilistic Performance Guarantees for Multi-Task Reinforcement Learning

**arXiv ID:** 2602.02098 | [PDF](https://arxiv.org/pdf/2602.02098v1)

**作者:** Yannik Schnitzer `[一作]` (University of Oxford), David Parker `[通讯]` (University of Oxford)

**通讯引用:** 27838 | [OpenAlex ID](https://openalex.org/A5071014323)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799`

**🎯 论文内容**

提出了一种计算多任务强化学习中未见任务的高置信度性能保证的方法。

**💡 创新点**

创新点在于引入了一种新的泛化界限，通过有限的回合数据和任务级泛化，提供对新任务的高置信度保证。

**🔧 技术方法**

使用了基于回合的统计方法和集中不等式来构建每个任务的下置信界，并将这些界限聚合成一个通用的保证。

**📊 数据集**

使用了从未知任务分布中采样的任务和每个任务的有限回合数据集。

**📈 对比分析**

与现有的多任务强化学习方法相比，所提出的保证在理论上是有效的，并且在实际样本量下提供了有用的信息，且不需要极大的任务或回合数量。

**⚠️ 局限性**

限制在于该方法假设任务分布是未知的，并且在每个任务中，性能必须通过有限的回合估计，这可能引入额外的不确定性。

---

## 735. Learning Half-Spaces from Perturbed Contrastive Examples

**arXiv ID:** 2602.02080 | [PDF](https://arxiv.org/pdf/2602.02080v1)

**作者:** Aryan Alavi Razavi Ravari `[一作]` (Max Planck Institute for Software Systems), Sandra Zilles `[通讯]` (University of Regina)

**通讯引用:** 1428 | [OpenAlex ID](https://openalex.org/A5036785155)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `57a58b01-81b4-4d75-a45c-2e891f272b50` `9ce7179e-700c-4310-ac2b-91df50ded46e`

**🎯 论文内容**

在对比学习框架下，提出并分析了两种对理想最小距离对比样本的噪声化机制，研究其在阈值函数、齐次和非齐次半空间学习中的主动与被动样本复杂度；

**💡 创新点**

创新点在于引入了由距离决定的可调噪声函数f，刻画了对比样本的扰动程度，并证明即使在非理想对比环境下仍能显著降低学习所需查询量；

**🔧 技术方法**

主要技术为构造噪声化对比机制、几何分析、误差与样本复杂度的上下界证明以及概率与期望复杂度的比较；

**📊 数据集**

由于是理论研究，未使用具体数据集；

**📈 对比分析**

与传统的成员查询（membership query）和理想最小距离模型对比，显示在阈值函数、齐次和非齐次半空间上，噪声化对比机制可将样本复杂度从指数级或线性下降到对数级或多项式级；

**⚠️ 局限性**

局限性包括：对非齐次半空间仍存在指数维度依赖；概率噪声模型要求f满足凸性和单调性；实际对比样本生成过程可能更复杂，理论模型与真实系统的匹配度待进一步验证。

---

## 736. Learning Generative Selection for Best-of-N

**arXiv ID:** 2602.02143 | [PDF](https://arxiv.org/pdf/2602.02143v1)

**作者:** Shubham Toshniwal `[一作]`, Igor Gitman `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文针对数学和代码问题的 Best‑of‑N 选择任务，训练了 1.7B 参数的小型推理模型，实现了生成式选择（GenSelect）功能。

**💡 创新点**

创新点在于：①提出了使用强化学习（RL）直接训练选择模型的框架；②构造了可自动验证的数学与代码选择数据集；③证明了 RL 训练的选择模型能泛化到更大生成模型的候选集。

**🔧 技术方法**

技术上使用了 VeRL 框架、DAPO 算法的 on‑policy RL；候选生成采用 Qwen3 系列模型，评估使用 NeMo‑Skills；强化信号来源于符号数学验证器与单元测试。

**📊 数据集**

数据集包括 37K 个低通过率的数学题（AIME、HMMT 等）与 LiveCodeBench v6 的代码题，所有候选集至少包含一条正确答案，且正确率不超过 50%。

**📈 对比分析**

实验比较了 RL‑训练模型、GenSelect prompting 与 majority‑voting 基线；在数学任务上 1.7B 模型接近 8B 模型，且在更高质量候选集上性能进一步提升；在代码任务上相对提升有限，但仍优于同尺寸 prompting。

**⚠️ 局限性**

限制主要在于：①代码选择受单元测试噪声影响，导致强化信号不稳定；②模型规模较小导致在非常高质量候选集上可能欠拟合；③RL 训练需要大量 GPU 计算，且收敛速度与任务难度相关。

---

## 737. Two-Stage Grid Optimization for Group-wise Quantization of LLMs

**arXiv ID:** 2602.02126 | [PDF](https://arxiv.org/pdf/2602.02126v1)

**作者:** Junhan Kim `[一作]` (Samsung Research), Yongkweon Jeon `[通讯]` (Samsung Research)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出两阶段优化框架，对 GPTQ 的组量化尺度进行输入统计驱动的初始化和基于坐标下降的闭式更新，以最小化层级重建损失。

**💡 创新点**

创新点在于（1）第一阶段利用输入统计独立优化每组尺度；（2）第二阶段冻结整数权重，使用坐标下降闭式公式精细化尺度，并加入前置层量化误差校正，避免误差累积。

**🔧 技术方法**

采用 GPTQ、组量化、坐标下降（CD）算法、Hessian 近似、输入统计和交叉相关矩阵，推导闭式尺度更新公式。

**📊 数据集**

使用 WikiText-2（128 个 2048 长度序列）做校准；评估基准包括 Wiki2、C4 的 perplexity 以及 ARC-challenge/easy、BoolQ、OpenbookQA、LAMBADA、PIQA、HellaSwag、WinoGrande 等零样本常识推理任务。

**📈 对比分析**

与原始 GPTQ 在 2/3 位量化下直接比较，实验显示在 Llama3‑8B、Llama3.2‑3B‑Instruct/Llama2‑7B 等模型上 perplexity 或准确率提升约 6%/4%，3 位量化几乎保持 FP 性能，仅有 2% 误差。

**⚠️ 局限性**

局限性包括：仅处理权重量化，未涉及激活量化；改进主要针对 GPTQ，其他 PTQ 方法迁移未知；依赖预先计算的 Hessian，若 Hessian 估计不佳会影响效果；对极小组尺寸或极大模型的适用性尚待验证。

---

## 738. Toxicity Assessment in Preclinical Histopathology via Class-Aware Mahalanobis Distance for Known and Novel Anomalies

**arXiv ID:** 2602.02124 | [PDF](https://arxiv.org/pdf/2602.02124v1)

**作者:** Olga Graf `[一作]` (Tübingen AI Center), Fabian Heinemann `[通讯]` (Boehringer Ingelheim)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

开发了一套基于AI的异常检测框架，能够在小鼠肝脏全切片图像中实现语义分割与异常检测的统一，支持毒理学早期安全筛查。

**💡 创新点**

创新点在于将预训练ViT（DINOv2）与LoRA微调相结合构建语义分割模型，再通过Mahalanobis距离与自适应阈值实现ID/ OOD异常检测，使得即使无训练样本的稀有病变也能被准确捕获，并保持极低的误漏率。

**🔧 技术方法**

主要技术包括：预训练ViT（DINOv2）+ LoRA微调、像素级语义分割、空间平移平均、Mahalanobis距离OOS检测以及自适应阈值设定。

**📊 数据集**

使用了742份小鼠肝脏H&E全切片图像，包含健康组织、9类常见病变及2类OOS病变，采用70%/15%/15%训练/验证/测试分割，并通过Wasserstein距离实现样本分布一致。

**📈 对比分析**

与多种后置OOS检测方法（MSP、Max-Logit、Energy、ReAct、KL-M、OC‑SVM）在标准与自适应阈值下进行对比，Maha+自适应阈值在测试集上实现FNR仅0.16%、FPR 0.35%，明显优于其他方法。

**⚠️ 局限性**

局限性包括：仅针对小鼠肝脏组织，缺乏跨组织/跨物种、跨扫描平台的验证；OOS样本稀少，模型对极小单细胞病变仍有误检；未来需进一步提升跨域泛化和实时部署效率。

---

## 739. TriCloudEdge: A multi-layer Cloud Continuum

**arXiv ID:** 2602.02121 | [PDF](https://arxiv.org/pdf/2602.02121v1)

**作者:** George Violettas `[一作]` (SYSGO GmbH), Lefteris Mamatas `[通讯]` (University of Macedonia)

**通讯引用:** 1350 | [OpenAlex ID](https://openalex.org/A5076669417)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `e0540dec-d77f-42db-94ae-d039248f6393` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

设计并实现了一个三层（远端边缘‑边缘‑云）AI连续体TriCloudEdge，并在实际硬件（ESP32‑CAM、ESP32‑S3与AWS）上部署两种通信架构（多协议 WebSocket/MQTT/HTTP 与统一 Zenoh），完成端到端的面部检测与识别工作；

**💡 创新点**

首次在受限设备上完整实现并评估了三层连续体，并通过可编程流水线并行化、统一协议化和多协议对比展示了边缘计算在延迟、吞吐和资源利用上的实际优势；

**🔧 技术方法**

采用 ESP32 系列 MCU、AWS IoT Core/S3/Lambda/Rekognition、WebSocket、MQTT、HTTP、Zenoh、并行任务调度与自定义 1 KB 图像分块协议；

**📊 数据集**

使用约 3,000 张面部图像（自研 AI 生成图像）作为测试数据集；

**📈 对比分析**

通过测量端到端延迟、协议吞吐、CPU/内存占用等指标进行对比；结果显示在启用流水线并行化后 Zenoh 的吞吐提升 27.9%（WebSocket 仅 4.1%），但单文件传输延迟略高；总体而言 Zenoh+并行化的统一架构在吞吐与资源利用上优于多协议架构；

**⚠️ 局限性**

未测量能耗，Zenoh 在 ESP32‑CAM 上实现受限；面向单一面部识别场景，缺乏动态模型迁移与能耗优化；受限于 ESP32 内存碎片与协议支持，导致实现复杂度提升；安全层面仅使用 TLS，未覆盖后量子密码与细粒度访问控制。

---

## 740. The Maximum von Neumann Entropy Principle: Theory and Applications in Machine Learning

**arXiv ID:** 2602.02117 | [PDF](https://arxiv.org/pdf/2602.02117v1)

**作者:** Youqi Wu `[一作]` (Chinese University of Hong Kong), Farzan Farnia `[通讯]` (Chinese University of Hong Kong)

**通讯引用:** 544 | [OpenAlex ID](https://openalex.org/A5017160178)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出最大冯·诺伊曼熵（Max‑VNE）原理的游戏理论解释，并将其应用于核矩阵混合选择和核矩阵缺失值填补任务。

**💡 创新点**

将经典最大熵最小化极大解释推广到量子密度矩阵，给出VNE最大化的最优策略与贝叶斯决策的对应关系；通过VNE引入核学习中的谱多样性度量，统一了核多重表示与缺失值补全的理论框架。

**🔧 技术方法**

使用量子信息理论中的冯·诺伊曼熵、矩阵Rényi熵，构建基于核的密度矩阵；采用最小化极大游戏理论、线性探测、Spectral Clustering等机器学习技术。

**📊 数据集**

实验数据集包括ImageNet、CIFAR‑100、DTD、FGVC Aircraft、AFHQ、MNIST和ImageNet‑Dogs。

**📈 对比分析**

通过与单一嵌入、随机填充以及传统核补全方法比较，在线性分类和谱聚类任务中，Max‑VNE混合在四个分类基准上平均提升约5–10%准确率，在缺失核补全上NMI、ARI和ACC均优于基线。

**⚠️ 局限性**

局限性在于仅适用于已归一化核；对大规模数据的计算开销与稀疏观测下的收敛性未充分分析；基线仅限于简单核混合与随机补全，缺乏更广泛的对比。

---

## 741. An Empirical Study of World Model Quantization

**arXiv ID:** 2602.02110 | [PDF](https://arxiv.org/pdf/2602.02110v1)

**作者:** Zhongqian Fu `[一作]` (Huawei Noah's Ark Lab), Yunhe Wang `[通讯]` (Huawei Noah's Ark Lab)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

对世界模型的后训练量化（PTQ）进行系统实验，研究其在长时延视觉规划任务中的影响。

**💡 创新点**

揭示不同量化粒度、模块敏感性及任务相关的失效模式，指出组量化、激活粒度和编码器对低位量化的关键作用。

**🔧 技术方法**

采用多种 PTQ 方法（RTN、OMSE、AWQ、SmoothQuant、OmniQuant），测试不同位宽、组大小、激活粒度的量化方案。

**📊 数据集**

在两个视觉规划环境 Wall 与 PushT 上进行评估。

**📈 对比分析**

与 FP32 基准对比，8 位量化基本无损，4 位量化在组量化下可恢复部分性能，但 3 位量化失效；激活粒度差异不大；编码器量化对性能影响最大。

**⚠️ 局限性**

局限于仅对单一世界模型（DINO‑WM）做实验，缺乏训练时量化或自适应方案，且对更复杂任务或更大模型的泛化仍未知。

---

## 742. Think Dense, Not Long: Dynamic Decoupled Conditional Advantage for Efficient Reasoning

**arXiv ID:** 2602.02099 | [PDF](https://arxiv.org/pdf/2602.02099v1)

**作者:** Keqin Peng `[一作]` (Beihang University), Liang Ding `[通讯]` (Alibaba Group)

**通讯引用:** 7837 | [OpenAlex ID](https://openalex.org/A5046576694)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `64443552-63e0-44b5-906f-d90fe95c5a1b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文针对RLVR中长度惩罚导致的过度思考问题，提出动态解耦条件优势（DDCA）方法。

**💡 创新点**

创新点在于将长度优势与正确性优势解耦，仅在正确回答子集中计算长度优势，并按问题通过率动态调节惩罚强度，解决基线稀释与难度不匹配问题。

**🔧 技术方法**

采用强化学习与可验证奖励（RLVR）框架，结合GRPO或RLOO估计器、Sigmoid长度奖励、动态难度系数，实现自适应效率调节。

**📊 数据集**

实验使用四大数学推理基准：GSM8K、MATH500、AMC23、AIME25，并在DeepSeek-R1-Distill和DeepScaleR-1.5B-Preview两种模型上验证。

**📈 对比分析**

与多种基线（RLOO、GRPO+LP、ThinkPrune-4k、TLMRE）对比，DDCA在保持或提升准确率的同时，平均token消耗下降20%–60%，在AES指标上最高，尤其在难度高的AIME25上提升约1–2个百分点。

**⚠️ 局限性**

局限性包括仅适用于可二元验证的数理推理任务，对开放式生成任务的适用性未知；对β超参数仍有一定敏感性，过强可能抑制极难问题所需的完整推理。

---

## 743. FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space

**arXiv ID:** 2602.02092 | [PDF](https://arxiv.org/pdf/2602.02092v1)

**作者:** FSVideo Team `[一作]` (Intelligent Creation), Yuxin Zhang `[通讯]` (Intelligent Creation)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `fede83ac-7505-405f-ab37-e7284695c47f` `64443552-63e0-44b5-906f-d90fe95c5a1b` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了FSVideo框架，结合高压缩率视频自动编码器FSAE、带层记忆的Diffusion Transformer（DIT）以及潜在上采样器和高分辨率细化器，实现了从单帧图像快速生成高质量视频；

**💡 创新点**

创新点包括：1）将视频压缩至64×64×4的潜在空间，显著减少令牌数量；2）在DIT中引入层记忆自注意力和动态路由，提升跨层信息复用；3）设计潜在上采样+细化两阶段提升分辨率；4）动态遮罩与偏差估计增强细化器鲁棒性；5）采用多阶段训练与RL、step/SiDA蒸馏进一步压缩推理成本；

**🔧 技术方法**

使用技术：扩散Transformer、VAE+Transformer AE、层记忆自注意力、动态路由、像素级卷积上采样、低维噪声注入、动态遮罩、偏差估计、step蒸馏、SiDA、GRPO、FSDP、上下文并行、FlashAttention3、混合分辨率训练、LPIPS、CLIP、DINO等；

**📊 数据集**

主要数据集：VBench 2.0 I2V benchmark、Inter‑4K、WebVid‑10M、VBench测试集（5s 720×1280、24fps）以及内部的多分辨率视频；

**📈 对比分析**

与Wan2.1‑I2V‑14B、Step‑Video‑TI2V、HunyuanVideo、LTX‑Video等开源模型对比，FSVideo在VBench总分仅略低于Step‑Video‑TI2V，却保持最高压缩率；推理速度上在单GPU下实现5s 24fps耗时76.6s，双GPU下相较Wan2.1‑14B提升42.3×（若FP8可达58.7×）；在质量上通过SSIM/PSNR/LPIPS/FVD等指标与人评均处于竞争水平；

**⚠️ 局限性**

局限性：受限于训练数据与算力，模型仍处于初级阶段，长视频与多场景生成能力不足；压缩导致潜在空间的表达力有限，可能在极高分辨率或复杂运动时出现细节缺失；动态遮罩与偏差估计需手动调参，模型对文本提示的连贯性仍有提升空间；

---

## 744. Mechanized Undecidability of Higher-order beta-Matching (Extended Version)

**arXiv ID:** 2602.02091 | [PDF](https://arxiv.org/pdf/2602.02091v1)

**作者:** Andrej Dudenhefner `[一作]` (Dortmund University), Andrej Dudenhefner `[通讯]` (Dortmund University)

**通讯引用:** 96 | [OpenAlex ID](https://openalex.org/A5017299598)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c`

**🎯 论文内容**

本文构造了一种新的形式化证明，展示了高阶 β‑匹配问题的不可判定性，并将该证明完全实现于 Coq 证明助手中。

**💡 创新点**

创新点在于：①不再依赖传统的 λ‑定义性（λ‑definability）转化，而是直接从一种简单的半 Thue 系统（^+ ⇒^* ^+）的重写问题构造匹配实例；②通过引入限制形状的语法约束和 β‑等价约束，简化了可行解的形式；③证明过程被完全机械化，消除了手工证明的歧义和错误。

**🔧 技术方法**

使用了：①简单类型 λ‑计算的语法与语义；②β‑归约及其等价闭包；③半 Thue 系统的重写理论；④Coq 证明助手的定理证明与可执行化。

**📊 数据集**

本文没有使用任何实验数据集；所有结论均来自形式化证明与逻辑推理。

**📈 对比分析**

由于研究聚焦于理论不可判定性，未进行实验比较；证明的有效性通过 Coq 的自动化与类型检查得到验证，证明规模约 4000 行，验证时间可在几秒至几分钟内完成。

**⚠️ 局限性**

局限性包括：①证明仅适用于简单类型 λ‑计算；②所需的类型阶数为 6，尚未证明在阶数 5 或更低时不可判定；③对更一般类型系统（如 Coppo‑Dezani 交叉类型）需额外工作，且证明难度更大。

---

## 745. Calibrating Adaptive Smoothing Methods for Freeway Traffic Reconstruction

**arXiv ID:** 2602.02072 | [PDF](https://arxiv.org/pdf/2602.02072v1)

**作者:** Junyi Ji `[一作]` (Vanderbilt University), Daniel B. Work `[通讯]` (Vanderbilt University)

**通讯引用:** 5662 | [OpenAlex ID](https://openalex.org/A5012556136)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

实现并校准了可复现的ASM（Adaptive Smoothing Method）Python实现，使用I‑24 MOTION完整观测雷达数据完成端到端参数优化，并在多条美国高速公路上验证其性能。

**💡 创新点**

创新点在于：①首次公开完整可训练的ASM实现，②利用真实全状态观测数据进行精准校准，③在PyTorch框架下实现快速卷积核加速和可微分优化，为后续深度学习融合提供基础。

**🔧 技术方法**

核心技术包括：ASM卷积核优化、参数化核优化、FFT加速、PyTorch自动微分、稀疏数据投影、非线性自适应加权融合。

**📊 数据集**

主要数据集为I‑24 MOTION雷达传感器与地面真值观测，此外对比了NGSIM、ZTD等公开数据集，以评估跨路段泛化能力。

**📈 对比分析**

与传统ASM和NGSIM基准对比，本文方法在速度分布、时空误差以及空间误差指标上均实现了更低的平均误差，同时在大规模系统下实现了数十倍的速度提升。

**⚠️ 局限性**

局限性包括：仍依赖完整观测数据的可获取性、对非标准道路条件（如施工区、恶劣天气）适用性待验证、以及在多变量输入（温度、道路湿度等）方面的扩展仍有待进一步研究。

---

## 746. There Is More to Refusal in Large Language Models than a Single Direction

**arXiv ID:** 2602.02132 | [PDF](https://arxiv.org/pdf/2602.02132v1)

**作者:** Faaiz Joad `[一作]` (Qatar Computing Research Institute), Husrev Taha Sencar `[通讯]` (Qatar Computing Research Institute)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在多类别拒绝行为中研究LLM的内部拒绝机制，比较不同拒绝方向的几何特征，并用稀疏自编码器揭示共享核心与风格尾巴。

**💡 创新点**

发现拒绝行为对应多条几何不同的激活空间方向，但所有方向的线性干预只调节拒绝与否的单维控制，且可用SAE解释为共享核心+长尾特征的组合。

**🔧 技术方法**

使用激活空间线性 steering/ablation、稀疏自编码器（JumpReLU SAE）、cosine 相似度计算、对照实验。

**📊 数据集**

WildGuardMix、SorryBench、CoCoNot、XSTest 共11个拒绝/非拒绝子集。

**📈 对比分析**

在Gemma‑2和Llama‑2上进行对照：steering 与 ablation、随机基线；任何拒绝方向的 steering 均能提升有害提示拒绝率并伴随过度拒绝率上升，曲线几乎相同；SAE steering 能复现同一行为；随机基线效果弱，说明方向特异性。

**⚠️ 局限性**

仅测试两种指令微调模型；依赖公开 SAE 仅覆盖后层；未验证更大模型或不同对齐方案；线性控制无法完整描述内部拒绝机制。

---

## 747. Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics

**arXiv ID:** 2602.02128 | [PDF](https://arxiv.org/pdf/2602.02128v1)

**作者:** Nima Shoghi `[一作]` (ByteDance Seed), Quanquan Gu `[通讯]` (ByteDance Seed)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `09944146-298c-433e-89df-37255de463d7` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `5a41884c-404f-4688-a89c-aa238c10fe68` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了一种自回归 SE(3)扩散变压器（STAR-MD）用于生成长时程（微秒级）蛋白动力学轨迹

**💡 创新点**

创新点包括联合时空注意力、连续时间条件化以及历史上下文噪声训练来抑制误差累积，并实现了低内存、可扩展的模型架构

**🔧 技术方法**

使用 SE(3) 变形扩散模型、causal diffusion transformer、S×T（时空）注意力、2D Rotary Position Embedding、KV 缓存、上下文噪声扰动、AdaLN 连续时间条件化等技术

**📊 数据集**

主要在 ATLAS 数据集上训练和评估，并自行扩展生成 250 ns 及 1 µs 长度的 MD 轨迹作为验证

**📈 对比分析**

与 AlphaFolding、MDGen、ConfRover 等现有方法对比，STAR-MD 在 100 轨迹基准上在构象覆盖、动态保真度、结构合法性等指标上均领先；在 240 ns、1 µs 长时程任务中保持高结构有效率和低误差，逼近 MD 参考性能

**⚠️ 局限性**

局限性包括：对非常大或复杂多体系统的进一步扩展仍需研究；模型在时间一致性上略低于真实 MD；对更大多样化 MD 数据集的训练仍有提升空间

---

## 748. Unifying Masked Diffusion Models with Various Generation Orders and Beyond

**arXiv ID:** 2602.02112 | [PDF](https://arxiv.org/pdf/2602.02112v1)

**作者:** Chunsan Hong `[一作]` (Graduate School of AI), Jong Chul Ye `[通讯]` (Graduate School of AI)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了统一的掩码扩散模型框架，能够以不同生成顺序（随机、块级、逐词）对文本进行建模，并在此基础上提出LoMDM，使得生成顺序与扩散网络可通过单一目标函数联合学习；

**💡 创新点**

创新点在于：①将噪声调度器抽象为位置可变、上下文可感知的“调度器”并给出对应的通用N‑ELBO；②通过速度匹配项实现前向噪声与反向解码速度的对齐，实现了对生成顺序的显式建模；③联合学习调度器和扩散背骨，避免了两阶段训练导致的次优解；

**🔧 技术方法**

核心技术包括：连续时间掩码扩散模型、通用噪声调度器族、速度匹配损失、低方差两样本估计器、Transformer‑MLP 结构的调度器、停止梯度（stop‑grad）实现特征提取；

**📊 数据集**

在 One Billion Words (LM1B)（含/不含句子打包）和 OpenWebText（OWT）上训练，并在 PTB、WikiText、Lambada、AG News、Pubmed、ArXiv 等数据集上做零样本测试；

**📈 对比分析**

与传统 ARMs、MDLM、BD3LM、GenMD4 等离散扩散模型以及 Transformer 进行对比，LoMDM 在 LM1B/OWT 的 PPL 分别为 25.4/27.2/20.4，显著优于 MDLM（27.0/31.8/23.2）、BD3LM（30.6/22.3）和 GenMD4（26.9/30.0/21.8）；在 7 个零样本数据集上均优于 MDLM，且在 6 个数据集上位居所有离散扩散模型之首；训练速度也更快（仅 0.18M 步即可达到 MDLM 1M 步的 PPL）。

**⚠️ 局限性**

局限性包括：额外的调度器网络使模型参数和训练成本略高；需调节超参数 c1、c2 以保证收敛；仍以 N‑ELBO 上限评估，可能不如 ARMs 在极端长文本或复杂语境下表现最佳；缺乏对更大规模语料的验证。

---

## 749. Teacher-Guided Student Self-Knowledge Distillation Using Diffusion Model

**arXiv ID:** 2602.02107 | [PDF](https://arxiv.org/pdf/2602.02107v1)

**作者:** Yu Wang `[一作]` (State Key Laboratory of AI Safety, Institute of Computing Technology, Chinese Academy of Sciences), Yongjun Xu `[通讯]` (State Key Laboratory of AI Safety, Institute of Computing Technology, Chinese Academy of Sciences)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `8d10c613-917e-4880-9716-17789f50e119` `729e5870-4135-47f5-97f2-e3974d07b5dc` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于教师分类器引导扩散模型的学生特征自蒸馏方法DSKD，利用扩散过程将学生特征去噪并作为蒸馏目标，避免教师与学生特征分布不匹配问题；

**💡 创新点**

创新点在于：①引入教师分类器引导的扩散模型来为学生特征去噪并注入类相关语义；②采用LSH（局部敏感哈希）引导的全局蒸馏，侧重特征方向而非幅度；③通过自蒸馏而非直接教师-学生对齐，解决教师-学生差异带来的负优化；

**🔧 技术方法**

核心技术包括：扩散概率模型（DDPM/DIIM）、教师分类器引导的扩散采样、局部敏感哈希（LSH）与全局均值池化的蒸馏损失；

**📊 数据集**

在CIFAR‑100、ImageNet（1000类）以及ADE20K（语义分割）三个数据集上进行评估；

**📈 对比分析**

与多种最新KD方法（KD、FitNet、DiffKD、IKD、CAT‑KD等）以及自蒸馏方法（BYOT、MixSKD等）对比，DSKD在CIFAR‑100同构/异构对上提升0.4%/0.94%平均精度，在ImageNet与Swin‑Transformer上均超过对手0.4%–0.8%，在ADE20K上提升mIoU至36.58%；

**⚠️ 局限性**

局限性包括：需额外训练扩散模型与分类器引导，增加计算与存储开销；对超参数（如步骤T、指导强度k、哈希数M）敏感，需调优；在极低样本或极端噪声标签场景下效果仍受限。

---

## 750. No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs

**arXiv ID:** 2602.02103 | [PDF](https://arxiv.org/pdf/2602.02103v1)

**作者:** Liyan Xu `[一作]` (WeChat AI, Tencent Inc), Jie Zhou `[通讯]` (WeChat AI, Tencent Inc)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过在LLM隐藏层插入低秩适配器（Tele‑Lens）进行多维度探测，研究Chain‑of‑Thought（CoT）中LLM的潜在规划视野，并利用该视野实现CoT不确定性估计与CoT必要性判定。

**💡 创新点**

①提出低秩适配器探针，实现对后续词、最终答案和推理长度的全词表预测；②发现LLM隐藏状态表现为短视规划，仅在CoT接近完成时才准确预测最终答案；③提出“木桶原则”，通过选取少量关键位置的熵/自信度可显著提升CoT不确定性校准；④实现自动CoT绕过，显著降低推理成本。

**🔧 技术方法**

低秩适配器（Logit Lens）、Top‑k关键位置选择、熵/自信度不确定性度量、RL‑GRPO训练、Qwen3系列LLM、推理任务自回归生成。

**📊 数据集**

12个多任务数据集：Parity、Cycle、Subsum、GSM8K、MATH、AIME、MuSR、Zebra、CSQA、MMLU、QuALITY、GPQA，并将所有任务转换为固定答案空间。

**📈 对比分析**

与Qwen3‑32B的CoT与无CoT、探针预测结果对比；Top‑k关键位置提升不确定性校准AUROC约9%；CoT绕过可将推理负荷减少至约16%同时准确率下降≤0.03；整体实验验证LLM短视规划。

**⚠️ 局限性**

仅适用于固定答案空间；探针需访问隐藏状态，对非固定答案任务效果未知；对LLM内部机制的解释仍有限；实验覆盖的模型和任务有限，结果可能不具普适性。

---

## 751. Cell-JEPA: Latent Representation Learning for Single-Cell Transcriptomics

**arXiv ID:** 2602.02093 | [PDF](https://arxiv.org/pdf/2602.02093v1)

**作者:** Ali ElSheikh `[一作]`, Han Liu `[通讯]`

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出了 Cell-JEPA，一个联合嵌入预测框架，用于单细胞转录组的无监督表示学习。

**💡 创新点**

在传统基于重建的自监督预训练基础上，加入了latent‑space预测目标（JEPA），通过在掩码视图下预测教师编码器的细胞嵌入，显著提升对技术噪声的鲁棒性。

**🔧 技术方法**

基于 scGPT 的 Transformer 双编码器（学生‑教师），使用指数滑动平均更新教师，采用量化分箱、基因子采样、cosine 相似度的 JEPA 损失以及传统表达重建损失。

**📊 数据集**

训练集为 800k 细胞的人类肾脏 scRNA‑seq 大规模语料库；下游评估使用 PBMC‑10k、Norman 与 Adamson Perturb‑seq CRISPR 数据。

**📈 对比分析**

与 scGPT 在 finetune、zero‑shot 聚类和 perturbation 预测三项任务对比，Cell‑JEPA 在 zero‑shot 聚类 AvgBIO 提升 36%，在 finetune 聚类指标整体优于 scGPT；perturbation 任务在绝对状态预测上显著提升，但对效应大小的预测无改善。

**⚠️ 局限性**

只提升了绝对状态预测，效应大小预测仍差；JEPA 可能抑制对扰动变化的敏感性；缺乏更大规模、多样化扰动数据以充分验证鲁棒性。

---

## 752. UrbanGS: A Scalable and Efficient Architecture for Geometrically Accurate Large-Scene Reconstruction

**arXiv ID:** 2602.02089 | [PDF](https://arxiv.org/pdf/2602.02089v1)

**作者:** Changbai Li `[一作]` (Hangzhou International Innovation Institute Beihang University), Baochang Zhang `[通讯]` (Institute of Artificial Intelligence Beihang University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

该论文提出了 UrbanGS，一种可扩展的城市级场景重建框架。

**💡 创新点**

其创新点包括深度一致的 D‑Normal 正则化、基于置信度的自适应加权以及空间自适应高斯修剪 (SAGP)。

**🔧 技术方法**

主要技术手段是 3D 高斯展开、深度与法向双重监督、可自适应剪枝与分块训练。

**📊 数据集**

实验使用了 Mill‑19、UrbanScene3D 与 GauU‑Scene 等公开城市数据集。

**📈 对比分析**

与 CityGS、CityGS‑v2、CityGaussianV2、VCR‑Gaus 等方法对比，UrbanGS 在 PSNR/SSIM/LPIPS、F1 等指标上均位居前列，同时训练时间与显存占用显著降低。

**⚠️ 局限性**

仍存在的局限包括对极端大尺度场景的显存上限、对动态物体的处理不足，以及在纹理细节极细粒度时的精度提升空间。

---

## 753. AICD Bench: A Challenging Benchmark for AI-Generated Code Detection

**arXiv ID:** 2602.02079 | [PDF](https://arxiv.org/pdf/2602.02079v1)

**作者:** Daniil Orel `[一作]` (Mohamed bin Zayed University of Artificial Intelligence), Preslav Nakov `[通讯]` (Mohamed bin Zayed University of Artificial Intelligence)

**通讯引用:** 16650 | [OpenAlex ID](https://openalex.org/A5012055259)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了AICD Bench，涵盖2M样本、77个生成模型、9种编程语言，设计了三种任务：鲁棒二分类、模型家族归因、细粒度人机分类。

**💡 创新点**

创新点在于规模大、跨语言跨模型、跨域、包含混合和对抗样本，提出三项更逼真的评测任务，并统一划分、脚本、评测协议。

**🔧 技术方法**

使用深度编码器（CodeBERT、CodeT5+、ModernBERT等）、经典机器学习（SVM、LR、CatBoost）、Fast-DetectGPT、AST+TF-IDF特征以及Zero-shot LLM等技术进行评估。

**📊 数据集**

数据集基于先前的DroidCollection并扩展，新增PHP、Rust、混合和对抗样本；共2M样本，覆盖77个生成器、9种语言。

**📈 对比分析**

通过宏F1评估，经典模型在鲁棒二分类上有时优于深度模型，但整体性能远低于期望；ModernBERT在模型家族归因和细粒度分类表现最佳；但所有模型在分布外、混合和对抗场景下仍表现不佳。

**⚠️ 局限性**

局限性包括数据污染风险、对原始数据源的依赖、过滤阈值限制样本多样性、语言覆盖有限、模型容易针对benchmark过拟合等。

---

## 754. Understanding the Reversal Curse Mitigation in Masked Diffusion Models through Attention and Training Dynamics

**arXiv ID:** 2602.02133 | [PDF](https://arxiv.org/pdf/2602.02133v1)

**作者:** Sangwoo Shin `[一作]` (Yonsei University), Albert No `[通讯]` (Yonsei University)

**通讯引用:** 506 | [OpenAlex ID](https://openalex.org/A5049196468)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

分析自回归模型的逆转诅咒，证明掩码扩散模型（MDM）通过 Transformer encoder 的结构与梯度动态实现逆转推理，并通过大规模实验验证其有效性。

**💡 创新点**

将 RoPE 全注意力与梯度对齐机制作为解释 MDM 逆转能力的理论依据，并系统性地在 7-8B 级模型上评估，揭示结构与训练动态的耦合是缓解逆转诅咒的关键。

**🔧 技术方法**

采用 Transformer encoder（RoPE）、随机掩码训练、LoRA 微调、注意力相关性与梯度对齐分析等技术。

**📊 数据集**

使用 Parent‑Child、Person‑Description、T‑REx 等知识检索基准进行评测。

**📈 对比分析**

与 LLaMA‑3.1、Qwen‑2.5 等自回归模型对比，MDM 在逆转任务上保持 80%+ 的准确率，而 ARMs 降至接近随机，显示显著性能提升。

**⚠️ 局限性**

仅针对结构化关系推理进行评估，缺乏对更广泛逆转场景、多模态任务及不同规模模型的验证，且理论假设相对理想化。

---

## 755. See2Refine: Vision-Language Feedback Improves LLM-Based eHMI Action Designers

**arXiv ID:** 2602.02063 | [PDF](https://arxiv.org/pdf/2602.02063v1)

**作者:** Ding Xia `[一作]` (University of Tokyo), Takeo Igarashi `[通讯]` (University of Tokyo)

**通讯引用:** 11361 | [OpenAlex ID](https://openalex.org/A5102743150)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `5b4c1114-4a70-478e-9921-2514ee03850d` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

构建了一个闭环框架，利用 Vision‑Language 模型（VLM）提供的视觉感知评分，作为自动反馈来改进基于大型语言模型（LLM）的 eHMI 动作设计器，并在灯条、机械眼睛和机械臂三种模态上实现了自我迭代优化。

**💡 创新点**

首次将 VLM 的感知评估作为无人工反馈，结合多指标评估（Phase1/Phase2 以及 Kernel 评分）和 Direct Preference Optimization（DPO）实现完全人类自由的自我改进；同时提出重要性采样与多样化动作生成来高效扩展动作数据库。

**🔧 技术方法**

使用 LLM（如 Qwen2.5、GPT‑4.1 等）生成并微调动作，VLM（如 GPT‑5‑mini、Prometheus‑Vision 等）进行评估，Blender 渲染视频，DPO 进行偏好学习，并采用多阶段评估与 Kernel 评分融合。

**📊 数据集**

基于六个因素共 6912 个交通情境生成 20k+ 情景‑消息对，使用 LLM 生成并渲染多模态动作，构建共享动作数据库并附加 VLM 评分；并在 200 对情景‑消息上做小规模人类评估验证情境质量。

**📈 对比分析**

与手工规则、仅 Prompt 的 LLM 以及三种商业 LLM 进行对比，评估指标包括目标识别、信任、接收者定位、用户接受度等；实验结果显示 DesignerLLM 在所有 VLM 评估指标和人类受试者评分上均优于基线，Kernel 评分提升至约 60+，人类平均得分提升 7–8%，且三种模态表现一致。

**⚠️ 局限性**

局限性包括：VLM 与人类细粒度偏好的一致性仅在评分差距足够大时保持，难以覆盖不同文化/年龄群体的差异；VLM 评估模型需进一步微调；渲染视频缺乏真实光照、遮挡等环境因素，可能影响泛化；评分信息单一，难以完全指导学习。

---

## 756. Learning to Route and Schedule LLMs from User Retrials via Contextual Queueing Bandits

**arXiv ID:** 2602.02061 | [PDF](https://arxiv.org/pdf/2602.02061v1)

**作者:** Seoungbin Bae `[一作]` (Korea Advanced Institute of Science and Technology), Dabeen Lee `[通讯]` (Seoul National University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a2602d71-93ab-4bad-974b-672788df8193` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种针对大型语言模型路由与调度的在线学习框架CQB-MNL，并给出任意时刻学习算法ACQB；

**💡 创新点**

通过将用户重试行为视为隐式反馈并结合多项式逻辑模型，解决了传统方法忽略的重试导致拥塞和缺乏显式反馈问题；

**🔧 技术方法**

使用Thompson Sampling、强制退化探索、最大似然估计、对角正交分布特征和对比学习的查询嵌入；

**📊 数据集**

在合成数据、SPROUT-o3mini、EmbedLLM、RouterBench四个公开数据集上进行实验；

**📈 对比分析**

与多种基线（随机、最优、MAB类队列Bandit等）对比，ACQB和ACQB‑CL在队列长度与累计 regret 上均实现子线性增长，且优于现有方法；

**⚠️ 局限性**

仍受限于对离散分配大小的假设、对交通松弛参数的依赖以及在极端高负载下仍可能出现队列波动等问题。

---

## 757. QVCache: A Query-Aware Vector Cache

**arXiv ID:** 2602.02057 | [PDF](https://arxiv.org/pdf/2602.02057v1)

**作者:** Anıl Eren Göçer `[一作]` (ETH Zurich), Anastasia Ailamaki `[通讯]` (EPFL)

**关键词:** `70392921-652b-47dd-9813-65d50cbe35c7` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出并实现了 QVCache，一种前置查询级向量缓存层，能够在保持召回率的前提下显著降低 ANN 查询延迟。

**💡 创新点**

创新点包括：1) 将缓存视为相似度缓存，并在线学习区域特定阈值；2) 采用多级 Mini‑Index（FreshVamana）分区与 LRU/策略搜索，避免全局索引开销；3) 与任何后端 ANN 系统兼容，完全不改动后端索引；4) 通过异步填充与阈值更新实现子毫秒命中延迟；5) 通过 PCA 降维+空间分区实现可伸缩的阈值管理。

**🔧 技术方法**

技术手段：FreshVamana 动态近似最近邻图；PCA 降维与多维分桶空间分区；在线阈值学习（Adam‑style更新）；多 Mini‑Index 与 LRU/动态搜索策略；异步查询填充与阈值调整；离线与在线评估框架。

**📊 数据集**

实验数据集：SIFT（1B、128维）、SpaceV（100M、100维）、DEEP（10M、96维）、GIST（1M、960维）和 GloVe（1M、100维）等五个规模、维度和距离函数不同的数据集。

**📈 对比分析**

比较方法：在 DiskANN、FAISS、Qdrant、pgvector、Pinecone、SPANN 等多种后端上，分别测量 p50 延迟、召回率（k‑recall@k）、命中率、内存占用。实验显示：缓存命中时 p50 延迟可降 40–1000×，召回率仅下降 2–5%；内存占用仅占后端的 0.1–1%；在有网络开销的云服务场景可额外降低约 1000×。

**⚠️ 局限性**

局限性：1) 依赖查询的语义局部性；2) 阈值与超参数（D、α、n_buckets、d_reduced）需调优；3) 细粒度空间分区可能过拟合，粗粒度可能召回下降；4) 对极端噪声查询（η→1）召回下降明显；5) 目前实现为客户端缓存，未直接嵌入后端；6) 未支持向量写入/删除的实时同步。

---

## 758. EvoMU: Evolutionary Machine Unlearning

**arXiv ID:** 2602.02139 | [PDF](https://arxiv.org/pdf/2602.02139v1)

**作者:** Pawel Batorski `[一作]`, Paul Swoboda `[通讯]` (Heinrich Heine Universität Düsseldorf)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出一种利用LLM进行进化搜索的自动化方法，自动生成针对特定数据集的机器unlearning损失函数并进行迭代优化。

**💡 创新点**

创新点在于将损失函数设计视为可自动化的科学发现任务，使用小型（4B参数）LLM驱动的进化搜索在有限计算预算下发现比手工设计更优的unlearning损失。

**🔧 技术方法**

主要技术包括：基于LoRA的轻量级微调、LLM生成与变异可执行的Python损失函数、自动化评估与选择（基于忘记与保留指标的加权分数）以及迭代的进化搜索循环。

**📊 数据集**

使用了TOFU（5%/10%）、MUSE（News/Books）、WMDP等公开的LLM机器unlearning基准数据集。

**📈 对比分析**

与多种现有基线（GradDiff、NPO、SimNPO、IDKDPO等）比较，EvoMU在TOFU、MUSE和WMDP上均取得更高的忘记-保留平衡分数（MU/1-AccBio等），并在部分任务上显著提升了对重新学习的抵抗力。

**⚠️ 局限性**

局限性包括：损失函数的泛化能力在某些任务（如MUSE News/Books）仍有限；进化搜索仍需一定的计算资源；方法依赖于评估指标的完整性，若指标不足可能导致误判。

---

## 759. CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems

**arXiv ID:** 2602.02138 | [PDF](https://arxiv.org/pdf/2602.02138v1)

**作者:** Lyu Zongyi `[一作]`, Cheung Shing-Chi `[通讯]`

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了CAM框架，对多代理代码生成系统（MACGS）的中间输出进行因果分析，量化其对最终代码正确性的贡献。

**💡 创新点**

首次将实际因果理论应用于MACGS，系统化建模中间输出、构建因果图、模拟错误并通过影响集高效识别重要特征，并在此基础上实现失败修复和特征裁剪。

**🔧 技术方法**

使用了实际因果（Actual Causality）理论、LLM驱动的反事实干预、影响集启发式搜索、责任度量等技术。

**📊 数据集**

使用了四个代码生成基准数据集：HumanEval-ET、MBPP-ET、CoderEval 和 CodeContest。

**📈 对比分析**

与人工标注、随机、时间优先、长度优先等基线比较，因果引导失败修复成功率达 73.3%，特征裁剪在保持或提升 Pass@1 的同时最多减少 66.8% token，混合后端配置还能提升至 7.2% Pass@1。

**⚠️ 局限性**

受限于执行预算、需手工调参、只覆盖部分 MACGS 架构，且因果分析仍依赖 LLM 生成的中间输出，可能存在误差和可扩展性问题。

---

## 760. $m$-Eternal Dominating Set Problem on Subclasses of Chordal Graphs

**arXiv ID:** 2602.02135 | [PDF](https://arxiv.org/pdf/2602.02135v1)

**作者:** Ashutosh Rai `[一作]` (Indian Institute of Technology Delhi), Soumyashree Rana `[通讯]` (Indian Institute of Technology Delhi)

**通讯引用:** 3 | [OpenAlex ID](https://openalex.org/A5112942730)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文研究了在分裂图和无向路径图等子类的 m‑Eternal Dominating Set 问题的计算复杂性，并给出了 K₁,t‑free 分裂图的二分法结论：当 t≤4 时可多项式求解，t≥5 时为 NP‑完备；此外证明该问题在无向路径图上仍为 NP‑难，并探讨了 Dominating Set、Eternal Dominating Set 与 m‑Eternal Dominating Set 在不同图类上的复杂性差异。

**💡 创新点**

创新点主要包括：① 对 K₁,t‑free 分裂图给出了完整的多项式/NP‑难分界；② 通过构造精细的图变换和匹配算法，首次证明 m‑Eternal Dominating Set 在无向路径图上为 NP‑难；③ 识别并比较了三类相关问题在特定图类中的相对难度，揭示了它们之间的复杂性层级关系；④ 在证明过程中引入了标记图、匹配与分裂图的分层处理方法。

**🔧 技术方法**

主要技术手段包括：图论中的分裂图与无向路径图结构分析、k‑分裂图的度限制与邻居交集性质、标记图（labeled graph）与最大匹配求解、从 Exact 3‑Cover 与 3D‑Matching 的多项式归约、以及对 m‑Eternal Dominating Set 的构造性证明与守卫移动策略的形式化描述。

**📊 数据集**

本文未使用实验数据集，而是通过理论证明与构造性归约完成所有结论；所有结果均基于图结构的形式化证明。

**📈 对比分析**

方法的评估基于多项式时间算法与 NP‑难性证明，未进行实验性能对比；在可解类中，算法时间复杂度为 O(|V|+|E|)（K₁,3‑free）、O(|V|^{3/2})（K₁,4‑free）等；在 NP‑难类中，通过标准 NP‑归约展示问题的难度。

**⚠️ 局限性**

局限性包括：① 仅覆盖分裂图和无向路径图等特定子类；② 对更广泛的弦图或其他结构化图类的复杂性仍未知；③ 在可解类中仅给出了理论上多项式算法，实际实现与优化尚待进一步研究。

---

## 761. MLV-Edit: Towards Consistent and Highly Efficient Editing for Minute-Level Videos

**arXiv ID:** 2602.02123 | [PDF](https://arxiv.org/pdf/2602.02123v1)

**作者:** Yangyi Cao `[一作]` (Communication University of China), Qi Mao `[通讯]` (Communication University of China)

**通讯引用:** 1547 | [OpenAlex ID](https://openalex.org/A5039315497)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `64443552-63e0-44b5-906f-d90fe95c5a1b` `ba576bd1-e51d-44e8-8077-fc943b333c93` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种训练无关、可扩展的长视频编辑框架 MLV-Edit，能够对分钟级视频进行一致、高效的文本引导编辑。

**💡 创新点**

创新点包括：
- 采用分段+重叠的编辑策略；
- 设计 Velocity Blend 在相邻段重叠区内对运动场进行加权融合，消除边界抖动；
- 引入 Attention Sink，以首帧的键值对作为全局语义锚点，抑制跨段效果漂移，实现全局语义一致。

**🔧 技术方法**

技术手段主要包括：
- 基于 Wan‑Edit 的流式扩散模型；
- VAE 对视频进行潜在空间编码；
- 运动场差分（velocity field difference）以及加权平均平滑；
- 注意力机制中的锚点注入（Attention Sink）；
- 训练自由，采用分段剪辑 + 传统扩散推理。

**📊 数据集**

使用了新构造的 MLV‑EVAL 基准（75 条 1–2 分钟长视频，包含 GPT‑4 生成的源字幕和多种编辑提示）以及 LongV‑EVAL 数据集。

**📈 对比分析**

与 TokenFlow、RAVE、AdaFlow、VACE、VideoPainter 等短视频/长视频编辑方法进行定量对比，指标包括 DINO、CLIP‑T、ViCLIP‑T、DOVER、CLIP‑F、FS.clip、Warp‑Err、Segment Warp‑Err、M.PSNR 等。实验表明，MLV‑Edit 在主题一致性、语义一致性、时序一致性和保真度上均获得最高或接近最高分，尤其在时序一致性方面显著优于 AdaFlow 与 VideoPT。

**⚠️ 局限性**

局限性：
- 目前仅针对基于流扩散的编辑模型，尚未验证更大分辨率或更长时间轴（超分钟级）下的鲁棒性；
- 重叠长度 k 与锚点选择对性能有经验性依赖，需要进一步自动化或自适应选择；
- 对多模态输入或交互式编辑的支持尚未实现。

---

## 762. CHAOS: Controlled Hardware fAult injectOr System for gem5

**arXiv ID:** 2602.02119 | [PDF](https://arxiv.org/pdf/2602.02119v1)

**作者:** Elio Vinciguerra `[一作]` (University of Catania), Maurizio Palesi `[通讯]` (University of Catania)

**通讯引用:** 3827 | [OpenAlex ID](https://openalex.org/A5010989172)

**关键词:** `fa95cdfe-56ac-4a08-8734-d50d24aec329` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

在 gem5 仿真平台上实现了可配置、模块化的故障注入框架 CHAOS，用于在指令集架构、缓存层和主存层注入位翻转、常驻 0/1 等故障。

**💡 创新点**

创新点在于：①完全开源且兼容 gem5 最新版本；②支持所有 gem5 ISA，细粒度控制注入时机、类型和目标；③通过单一统一接口实现寄存器、缓存和内存三层注入，显著降低实验设置复杂度；④结合硬件性能计数器实现故障隐蔽检测。

**🔧 技术方法**

技术实现：在 gem5 的 SimObject 机制下实现 CHAOReg、CHAOSCache、CHAOSMem 三个模块；使用概率、时间窗口、PC 匹配等参数决定注入时机；对常驻故障维护专用数据结构；通过 HPC 统计监测 SDC/Masked 影响；低开销实现（每次注入 <0.001%）。

**📊 数据集**

使用 MiBench benchmark（Bitcount、Blowfish、Dijkstra、JPEG、Patricia、Qsort、SHA、Susan）在 RISC‑V 架构上进行实验，涵盖不同工作负载特性。

**📈 对比分析**

评估方法：对比无注入的黄金运行，统计 Crash、DUE、SDC、Masked、Timeout 等结果，并计算 HPC 误差百分比；实验显示注入开销极低，且不同注入层级对程序行为影响差异显著，例如 L1I 注入几乎总导致 Crash，主存注入多为 SDC；多位随机注入进一步揭示了隐藏的性能异常。

**⚠️ 局限性**

局限性：仅实现了位翻转、常驻 0/1 三种故障类型；缺乏对更复杂故障模型（如跨单元错误、时序失效）的支持；实验仅在 gem5 RISC‑V 上进行，未在真实硬件上验证；未来需扩展故障谱、支持多核心/异构系统以及更细粒度的时间同步控制。

---

## 763. LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs

**arXiv ID:** 2602.02090 | [PDF](https://arxiv.org/pdf/2602.02090v1)

**作者:** Yikai Zeng `[一作]` (Computer Network Information Center, Chinese Academy of Sciences), Jianhui Li `[通讯]` (Computer Network Information Center, Chinese Academy of Sciences)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了一个双向协同框架LEC-KG，将大型语言模型与知识图谱嵌入相结合，用于从中文可持续发展目标（SDG）报告中构建领域知识图谱。

**💡 创新点**

创新点包括：① 采用层级粗细关系抽取以缓解长尾偏差；② 通过证据驱动的链式推理(KGE→LLM)实现结构化反馈；③ 引入语义初始化以对未见实体进行嵌入投影；④ 迭代闭环训练提升提取质量和图谱覆盖率。

**🔧 技术方法**

核心技术包括：Large Language Model（DeepSeek‑V3）进行多粒度实体关系抽取；RotatE知识图谱嵌入用于结构验证；线性投影将RoBERTa语义向量映射到复杂空间；链式推理提示和置信度阈值调节实现双向反馈；自适应阈值与主动选择机制实现迭代更新。

**📊 数据集**

使用了中国科学院发布的2023年与2024年两份《Big Earth Data for SDGs》报告，构造的训练集（1,535条）与测试集（1,758条）共覆盖74/87种关系类型、2,132/2,761个实体。

**📈 对比分析**

与一维提示、五维提示、OpenIE+映射以及无迭代的schema‑constrained基线对比，LEC‑KG在Micro‑F1从25.54%提升至36.79%，Macro‑F1从10.19%提升至21.63%；在长尾关系上，Tail F1从6.7%提升至13.3%，近乎翻倍；实验显示迭代四轮后性能趋稳，验证集规模从341条增长到727条。

**⚠️ 局限性**

局限包括：① 对未见实体的语义投影依赖语言模型，极端异构表述时可能失效；② 迭代过程计算开销较大（每轮约4小时，总计16小时）；③ 依赖人工设计的域特定关系词表，跨域迁移需重新构建本体；④ 初始阶段结构验证受限于少量训练样本，导致过度保守；⑤ 只在中文SDG文档上验证，跨语言与跨领域的泛化尚未充分评估。

---

## 764. Closing the Loop: Universal Repository Representation with RPG-Encoder

**arXiv ID:** 2602.02084 | [PDF](https://arxiv.org/pdf/2602.02084v1)

**作者:** Jane Luo `[一作]` (Microsoft Research Asia), Scarlett Li `[通讯]` (Microsoft Research Asia)

**通讯引用:** 3 | [OpenAlex ID](https://openalex.org/A5014463073)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `3f18e8e3-0266-457c-8567-9039b6d2394d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

本文提出了一种将 Repository Planning Graph (RPG) 统一为高保真中间表示的框架，旨在实现仓库从代码到意图的双向推理，并通过增量演化保持同步。

**💡 创新点**

创新点包括：① 将语义丰富的 API 文档与结构严谨的依赖图融合，构建双视图（功能层 + 依赖层）的 RPG；② 引入语义提升协议将代码映射到 RPG；③ 设计增量更新机制（基于提交 diff）实现低成本演化；④ 将 RPG 作为统一的导航接口，支持搜索、获取、跨视图遍历等工具。

**🔧 技术方法**

核心技术包括：语义提升（利用 LLM 提取函数/类的功能描述）、AST 依赖解析、增量图编辑、三种核心工具（SearchNode、FetchNode、ExploreRPG）以及大模型（GPT‑4o、GPT‑5、Claude‑4.5‑Sonnet 等）在图生成与推理中的应用。

**📊 数据集**

使用的数据集主要有：SWE‑bench Verified、SWE‑bench Live Lite（用于定位/导航评估）和 RepoCraft（用于仓库重建评估），此外还对比了官方 API 文档和 ZeroRepo。

**📈 对比分析**

对比方法：与 LocAgent、CoSIL、OrcaLoca、Agentless 等基线进行 Acc@k、Precision/Recall、Coverage、Pass Rate 等指标对比。性能表现显著：在 SWE‑bench Verified 上 Acc@5 达到 93.7%（比最佳基线提升 10%+），在 SWE‑bench Live Lite 上 Acc@5 超过 87%；在 RepoCraft 上 Coverage 达 98.5%，Pass Rate 86%，覆盖率比基线提升 33% 以上。

**⚠️ 局限性**

局限性：① 依赖大型 LLM，计算成本高；② 对极大规模仓库仍需进一步优化，尤其是语义提升的可扩展性；③ 仍可能出现语义漂移，尤其在复杂重构后需要人工检查；④ 评估主要集中在公开数据集，真实企业代码的多样性和安全性未完全覆盖。

---

## 765. Eliminating Registration Bias in Synthetic CT Generation: A Physics-Based Simulation Framework

**arXiv ID:** 2602.02130 | [PDF](https://arxiv.org/pdf/2602.02130v1)

**作者:** Lukas Zimmermann `[一作]` (Medical University of Vienna), Barbara Knäusl `[通讯]` (Medical University of Vienna)

**通讯引用:** 811 | [OpenAlex ID](https://openalex.org/A5044287027)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

通过物理仿真生成与CT完美配准的合成CBCT（sCBCT），并以此训练深度学习模型实现CBCT到CT的重建，提升空间几何一致性。

**💡 创新点**

创新点在于利用物理仿真消除配准误差、构造完全几何对应的训练对、并以几何对齐度（如NMI）而非传统强度指标作为评价基准，显示更高的临床可接受度。

**🔧 技术方法**

采用CUDA加速的自研CBCT仿真框架（含散射、噪声与呼吸运动模型）、深度卷积网络（ResNet‑encoder nnUNet回归）、以及多种评价指标（MAE、PSNR、SSIM、NMI、CC、FID、MMD、IQS）。

**📊 数据集**

使用两大独立数据集：医学大学维也纳妇科放疗科的395例真实CT/CBCT（180例训练/30例测试）以及SynthRAD 2023挑战的349例CT/CBCT（180例训练/30例测试）。

**📈 对比分析**

与传统基于真实配准的模型相比，sCBCT训练模型在NMI和CC上提升约10‑15%，而在MAE/PSNR/SSIM上略逊；临床观察者对sCBCT模型的喜好率达到87%，且其评价与NMI呈正相关。

**⚠️ 局限性**

局限性包括：散射模型经验性调参、呼吸运动模型仅为简化正弦波、仅覆盖骨盆部位、仅单机构数据、未评估剂量学影响，以及对不同CBCT系统的适用性需进一步验证。

---

## 766. Evaluating OCR Performance for Assistive Technology: Effects of Walking Speed, Camera Placement, and Camera Type

**arXiv ID:** 2602.02223 | [PDF](https://arxiv.org/pdf/2602.02223v1)

**作者:** Junchi Feng `[一作]` (New York University), John-Ross Rizzo `[通讯]` (New York University)

**通讯引用:** 8688 | [OpenAlex ID](https://openalex.org/A5073829818)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文系统评估了 OCR 在步速、摄像头挂载位置和镜头类型不同的动态与静态环境下的识别性能，比较了 Google Vision、PaddleOCR、EasyOCR 与 Tesseract 四款 OCR 引擎。

**💡 创新点**

创新点在于将真实行走速度和三种典型摄像头位置（肩部、头部、手持）纳入实验，首次在辅助技术场景下对多引擎和多设备的 OCR 性能进行统一、可复现的评估。

**🔧 技术方法**

使用 iPhone 15 Pro Max 主摄与超广角镜头、Meta Wayfarer 智能眼镜，配合 Google Vision、PaddleOCR 3.0、EasyOCR、Tesseract 四款 OCR 引擎；通过字符级 Levenshtein 比对和非参数统计检验（Kruskal–Wallis、Mann–Whitney）评估准确率。

**📊 数据集**

数据来源为自制的多字体、多色彩、高对比度标志牌（共 8 种不同标志），在实验台上以 1–7 m 之距、0°–75° 视角采集视频帧，构成一套专门用于行走速度（0.8–1.8 m/s）与摄像头位置实验的内部数据集。

**📈 对比分析**

采用字符级准确率对比，结果显示 Google Vision 以 0.967（主摄）/0.887（超广角）/0.378（眼镜）最高，PaddleOCR 跟随；主摄比超广角好 0.08-0.13；肩部挂载在多数条件下平均准确率最高，但差异不显著；动态测试表明步速越快、视角越大、摄像头越宽视角，准确率越低。

**⚠️ 局限性**

局限性包括：仅在室内均匀照明下测试；仅使用一名志愿者；标志样本仅为高对比度英文印刷文本，缺乏低对比度、手写、符号或多语言标志；仅评估两款设备（iPhone 15 Pro Max 与 Meta Wayfarer），未涵盖中低端或其他可穿戴摄像头；未考察户外环境、光照变化、雨雾等真实场景。

---

## 767. Lung Nodule Image Synthesis Driven by Two-Stage Generative Adversarial Networks

**arXiv ID:** 2602.02171 | [PDF](https://arxiv.org/pdf/2602.02171v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9`

---

## 768. vLLM-Omni: Fully Disaggregated Serving for Any-to-Any Multimodal Models

**arXiv ID:** 2602.02204 | [PDF](https://arxiv.org/pdf/2602.02204v1)

**作者:** Peiqi Yin `[一作]` (Chinese University of Hong Kong), Hongsheng Liu `[通讯]` (Huawei)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出了一个名为"OmniServe"的全分离式服务系统，用于高效部署任何到任何（any-to-any）多模态模型，支持文本、图像、视频和音频的跨模态输入与输出；

**💡 创新点**

核心创新在于将复杂的多模态模型拆解为阶段图（stage graph），每个阶段可独立执行并进行资源优化；同时提供统一的连接器实现跨阶段数据传输，实现真正的分离式执行；

**🔧 技术方法**

技术上结合了vLLM的LLM推理引擎、专用的扩散（Diffusion）引擎、统一连接器、Ray分布式调度、Flash Attention、SAGE Attention、TurboAttention、缓存技术（如TeaCache）以及执行图编译；

**📊 数据集**

在实验中使用了多模态数据集，包括LibriSpeech（语音）、Food101（图像）、UCF101-Subset（视频）以及VBench的图像与视频生成任务；

**📈 对比分析**

与基线（如Hugging Face Transformers、Diffusers、原始实现）进行对比，OmniServe在Qwen3‑Omni模型上将RTF和JCT分别降低约90%/91%，在BAGEL与Mimo‑Audio模型上实现2.4×–3.7×速度提升，整体提升幅度显著；

**⚠️ 局限性**

限制主要体现在对硬件平台的依赖（需支持GPU/TPU）、对非常大规模模型仍可能存在显存瓶颈、统一连接器的实现仍有延迟开销，并且对不同模型的自定义阶段编写仍需一定工程投入。

---

## 769. ECHO-2: A Large Scale Distributed Rollout Framework for Cost-efficient Reinforcement Learning

**arXiv ID:** 2602.02192 | [PDF](https://arxiv.org/pdf/2602.02192v1)

**作者:** Jie Xiao `[一作]` (Gradient), Bill Shi `[通讯]` (Gradient)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种将强化学习训练与回放生成分离的分布式框架，通过在分布式推理节点生成回放而把学习保持在中心化GPU集群中来降低成本。

**💡 创新点**

创新点在于将策略滞后（bounded staleness）视为可控预算，采用树状分段广播与同行协助的快速传播方案，并通过成本感知的工作节点激活实现对回放容量的精细调度。

**🔧 技术方法**

使用异步RL执行模型、有限滞后调度、树状分段Peer‑to‑Peer广播、贪心成本感知调度、三平面架构（回放/学习/数据）以及Parallax推理服务等技术。

**📊 数据集**

主要使用AIME24数学题库、广泛的数学基准套件以及示例扑克沙盒等任务数据集进行评估。

**📈 对比分析**

与中心化同步/异步基线相比，实验显示在4B/8B Qwen3 模型上，回放成本降低约33‑36%，在相同精度下训练时间缩短，且对滞后预算S≤6保持稳定的RL质量。

**⚠️ 局限性**

局限性包括缺乏对滞后安全范围的形式化证明、仅在特定任务与模型规模上验证、对多学习器或更大模型的适用性未作评估，以及对异构网络环境的进一步优化仍待研究。

---

## 770. AR-MAP: Are Autoregressive Large Language Models Implicit Teachers for Diffusion Large Language Models?

**arXiv ID:** 2602.02178 | [PDF](https://arxiv.org/pdf/2602.02178v1)

**作者:** Liang Lin `[一作]` (AMAP, Alibaba Group), Xiangxiang Chu `[通讯]` (AMAP, Alibaba Group)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出 AR‑MAP 框架，利用已对齐的自回归大模型（AR‑LLMs）通过权重缩放向扩散大模型（DLLMs）迁移偏好对齐知识。

**💡 创新点**

创新点在于首次揭示 AR‑LLMs 与 DLLMs 之间存在可利用的权重映射，并提出“谱缩放”与“奖励驱动搜索”两种机制，实现无需直接高方差 ELBO 训练即可完成 DLLMs 的偏好对齐。

**🔧 技术方法**

核心技术包括基于 DPO 的自回归对齐训练、权重差分（task vector）提取、奇异值分解（SVD）判定谱差异、权重缩放因子搜索以及使用 DLLM 的蒙特卡罗 ELBO 估计来计算奖励。

**📊 数据集**

实验数据集涵盖六个领域：算术推理（GSM8K、Math500）、有用性（AlpacaEval、IfEval、Arena‑Hard）和真诚度（TruthfulQA）。

**📈 对比分析**

与现有 DLLM 对齐方法（DPO、VRPO、SimPO）对比，AR‑MAP 在所有任务的平均分数达到 69.08，显著高于或与直接训练的 DLLM 相当，同时大幅降低了对高方差 ELBO 的依赖。

**⚠️ 局限性**

局限性包括：需要针对不同任务精细调节缩放因子，权重映射仅适用于共享骨干结构的模型；在某些复杂推理任务中过度缩放会导致性能骤降，且对极度高方差的 DLLM 仍存在一定的可迁移边界。

---

## 771. Co-RedTeam: Orchestrated Security Discovery and Exploitation with LLM Agents

**arXiv ID:** 2602.02164 | [PDF](https://arxiv.org/pdf/2602.02164v1)

**作者:** Pengfei He `[一作]`, Long T. Le `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了一个安全意识的多智能体框架Co-RedTeam，用于自动化软件漏洞发现与利用，整合了代码浏览、漏洞文档、执行环境交互与长期记忆，实现从静态分析到动态验证的闭环流程。

**💡 创新点**

创新点在于①将漏洞发现与利用拆分为专用智能体并通过主控器协调；②采用代码浏览与安全文档双重上下文支撑的证据链式推理；③引入执行驱动的迭代规划与评估机制；④构建分层长期记忆，支持跨任务经验迁移。

**🔧 技术方法**

技术手段包括大型语言模型（LLM）驱动的多智能体系统、工具调用（代码浏览、漏洞文档检索、Docker执行沙箱）、规划-执行-评估闭环、验证与批评子智能体，以及嵌入式相似度检索的记忆模块。

**📊 数据集**

使用了三大公开基准数据集：CyBench、BountyBench 以及 CyberGym，分别覆盖漏洞检测与利用任务，保证评测的多样性与真实性。

**📈 对比分析**

与基线（Vanilla、OpenHands、C-Agent、VulTrail、RepoAudit）对比，Co-RedTeam 在 CyBench 上实现 63.7% 的 ASR、在 BountyBench 的利用成功率 65% 及检测准确率 20%，在 CyberGym 上达到 37.3% ASR，均显著优于所有对比方法。

**⚠️ 局限性**

局限性包括对大型 LLM 资源依赖、执行环境配置与安全性成本、记忆模块的持续学习需要人工监控以及在极端新颖或高度加固的系统上可能仍存在召回不足的问题。

---

## 772. LoopViT: Scaling Visual ARC with Looped Transformers

**arXiv ID:** 2602.02156 | [PDF](https://arxiv.org/pdf/2602.02156v1)

**作者:** Wen-Jie Shu `[一作]` (Hong Kong University of Science and Technology), Harry Yang `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 20762 | [OpenAlex ID](https://openalex.org/A5100445368)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出 Loop-ViT，一种可循环的视觉 Transformer，用于在视觉推理任务中迭代更新隐状态并根据预测熵动态停止推理。

**💡 创新点**

创新点包括：① 用权重共享的循环核心将推理深度与参数规模解耦；② Hybrid Block 结合局部卷积与全局注意力，匹配 ARC 任务的细胞式更新；③ 采用无参的熵驱动动态退出机制，实现自适应计算时长。

**🔧 技术方法**

技术主要包括 Vision Transformer、卷积注意力混合模块（Hybrid Block）、RMSNorm、RoPE、ConvGLU、预测熵阈值动态停止、固定深度训练与测试时训练（TTT）。

**📊 数据集**

数据集：ARC-AGI（ARC-AGI-1 和 ARC-AGI-2）以及通过 RE-ARC 生成的增强样本。

**📈 对比分析**

与现有 LLM、VARC、VARC 集成等方法比较，18M 参数的 Loop-ViT 在 ARC-AGI-1 上取得 65.8% 的准确率，超过 73M 参数的 VARC 集成（60.4%），在参数效率和 FLOPs/准确率 Pareto 前沿上表现更佳；在 ARC-AGI-2 上亦保持较高的性能。

**⚠️ 局限性**

局限性：目前仅在 ARC 领域验证，针对更复杂或更大规模的视觉推理任务仍需进一步测试；动态退出阈值需经验调优，可能不适用于所有任务；循环训练对收敛性要求高，超长迭代仍可能导致梯度传播困难。

---

## 773. Revisiting Adaptive Rounding with Vectorized Reparameterization for LLM Quantization

**arXiv ID:** 2602.02151 | [PDF](https://arxiv.org/pdf/2602.02151v1)

**作者:** Yuli Zhou `[一作]` (ETH Zurich), Yawei Li `[通讯]` (ETH Zurich)

**通讯引用:** 4725 | [OpenAlex ID](https://openalex.org/A5100377386)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 VQRound，一种利用向量量化的参数高效自适应四舍五入框架，用于大型语言模型的低比特权重量化。

**💡 创新点**

创新点在于将自适应舍入矩阵通过向量量化重参数化，显著减少可学习参数量（≈0.2%），同时通过残差初始化和端到端微调实现跨层误差补偿，并在 L∞ 范数下控制逐元素误差，解决了传统低秩方法无法抑制残差尾部的缺陷。

**🔧 技术方法**

核心技术包括向量量化（VQ）代码簿、残差基（Hessian 方向）初始化、可微调的可退化四舍五入函数、端到端微调与块级重建两种优化策略；同时与 GPTQ、QuaRot、OmniQuant 等后训练量化方法结合。

**📊 数据集**

使用多种 LLM 族：OPT、LLaMA、LLaMA2、Qwen3；在 WikiText‑2、C4 文本数据集以及 WinoGrande、PiQA、HellaSwag、ARC 等零样本推理基准上进行评估。

**📈 对比分析**

与 RTN、AdaRound、GPTQ、OmniQuant 等基线对比，VQRound 在 4‑bit 方案下与 GPTQ、OmniQuant 相当，在 3‑bit 方案下显著优于 GPTQ，且收敛速度更快；在 2‑bit 极低位时仍保持可接受性能。参数量比 AdaRound 降至 <0.5%，显著提升效率。

**⚠️ 局限性**

局限性包括：代码簿维度与簇数的手工设定可能对不同模型产生差异，VQRound 对极低比特（≤2‑bit）时仍可能出现较大误差；同时，端到端微调需要小量校准数据，对极端资源受限场景尚未充分验证。

---

## 774. The $\infty$-category of $\infty$-categories in simplicial type theory

**arXiv ID:** 2602.02218 | [PDF](https://arxiv.org/pdf/2602.02218v1)

**作者:** Daniel Gratzer `[一作]` (Aarhus University), Ulrik Buchholtz `[通讯]` (University of Nottingham)

**通讯引用:** 107 | [OpenAlex ID](https://openalex.org/A5027478196)

**关键词:** `09ec487f-4c5c-4ed6-960d-c9fa93fddb0c`

**🎯 论文内容**

本文在模拟拓扑类型理论（simplicial type theory）中构造了“类别的类别” (Cat) 的子类型，并证明其为一个 ∞-范畴，同时给出了其直化–去直化 (straightening–unstraightening) 的合成证明。

**💡 创新点**

创新点在于：
1) 通过引入一个“神奇的右伴随”来构造一个全局可截断的 cocartesian 家族，从而在类型理论内部得到 Cat；
2) 证明了该子类型满足直向等价性（directed univalence），并利用该性质展示了新的结构同态原理（structure homomorphism principle）；
3) 提供了纯粹类型论的直化–去直化定理，避免了传统模型或 Quillen 等模型类别的技术。

**🔧 技术方法**

主要技术包括：
- 模型化的模拟拓扑类型理论与三角化（triangulated）类型理论；
- 引入多模态类型理论（multimodal type theory）以实现离散、余离散和取反模态；
- 使用“神奇的右伴随”实现对 → 的右伴随，从而定义 cocartesian 家族的截面；
- 通过证明 cocartesian 家族在 Δⁿ × C 上的分类性质来构造 Cat；
- 利用直向等价性和结构同态原理得到 Cat 的单纯性与 Rezk 条件。

**📊 数据集**

无数据集，整个工作完全基于类型论的公理化推导和内部构造。

**📈 对比分析**

比较方法：与传统的 Lurie 证明、Cubical type theory 的实现及 model‑category 证明相比，作者的合成证明在语义上更直接、内部性更强，且不依赖具体模型或外部化的 simplicial 结构。性能方面，作为形式化证明，缺乏数值指标；但在证明复杂度和可复用性上具有明显优势。

**⚠️ 局限性**

局限性：
- 目前仅在单模态的模拟拓扑类型理论中实现，尚未给出具体的计算实现；
- 对“神奇右伴随”的存在仅在某些模型（如双立方空间）中得到验证，理论上对所有模型的适用性尚待进一步研究；
- 对更复杂的结构（如标记类别、混合变形等）仍需进一步的技术细化；
- 目前缺乏对类型理论内部的可执行证明（如在 Coq/Agda 中的正式化）。

---

## 775. Generating Physically Sound Designs from Text and a Set of Physical Constraints

**arXiv ID:** 2602.02213 | [PDF](https://arxiv.org/pdf/2602.02213v1)

**作者:** Gregory Barber `[一作]` (DEVCOM Army Research Laboratory), Mulugeta A. Haile `[通讯]` (DEVCOM Army Research Laboratory)

**通讯引用:** 1204 | [OpenAlex ID](https://openalex.org/A5029030150)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

提出了 TIDES 方法，联合优化文本提示与物理约束，实现既符合视觉风格又具备结构强度的设计。

**💡 创新点**

创新点在于将预训练的文本‑图像模型（CLIP）与可微分结构优化结合，并通过视觉损失和物理损失共同驱动设计，突破了单纯的图像生成或传统结构优化的局限。

**🔧 技术方法**

使用了 CLIP 作为视觉判定器、SIMP 变形力学求解器、Hill‑function sigmoid 逼近二值材料分布，以及遵循材料成本的 L1 正则，整体构成可微分优化框架。

**📊 数据集**

主要数据来源为 CLIP 训练集的图像文本配对以及自定义的结构优化问题（如塔楼、桥梁、圆环等），未使用公开的结构设计数据集，而是通过文本提示生成样本。

**📈 对比分析**

通过与仅视觉损失、仅物理损失、以及传统结构优化的基准对比，实验表明 TIDES 在兼顾视觉相似度的同时保持了与物理优化相同量级的符合度（compliance）并在 3‑点弯曲实验中验证了可打印的力学性能，性能略低于纯物理优化但明显优于仅视觉优化。

**⚠️ 局限性**

局限性包括：需人工编写文本提示来驱动设计，无法自动发现最佳视觉与物理权衡；对高分辨率或三维结构的可扩展性仍待验证；以及在极端物理条件下可能因可微逼近误差导致设计失效。

---

## 776. MAIN-VLA: Modeling Abstraction of Intention and eNvironment for Vision-Language-Action Models

**arXiv ID:** 2602.02212 | [PDF](https://arxiv.org/pdf/2602.02212v1)

**作者:** Zheyuan Zhou `[一作]` (Zhejiang University), Lemiao Qiu `[通讯]` (Zhejiang University)

**通讯引用:** 793 | [OpenAlex ID](https://openalex.org/A5062424762)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出MAIN-VLA框架，通过意图抽象和环境语义抽象实现视觉语言动作模型的精简瓶颈，从而在复杂动态环境中实现高效决策。

**💡 创新点**

创新点在于双通道抽象机制（IA+ESA）与自适应无参Token剪枝，显著降低感知冗余，提升决策质量和泛化性。

**🔧 技术方法**

使用因果Transformer，基于关键词抽象、语义网格投影、注意力连通度得分进行Token剪枝。

**📊 数据集**

训练与评测使用Minecraft MCU、Game for Peace和Valorant射击等游戏数据集。

**📈 对比分析**

与VPT、STEVE-1、OpenHA等SOTA模型对比，MAIN-VLA在成功率上提升约10–20%，步数下降，推理延迟降至0.3s，Token剪枝后性能基本保持不变。

**⚠️ 局限性**

限制在于仍需外部指令，缺乏自主目标规划；对极端视觉噪声的鲁棒性尚未完全解决。

---

## 777. Learning Topology-Aware Implicit Field for Unified Pulmonary Tree Modeling with Incomplete Topological Supervision

**arXiv ID:** 2602.02186 | [PDF](https://arxiv.org/pdf/2602.02186v1)

**作者:** Ziqiao Weng `[一作]` (School of Computer Science, University of Sydney), Weidong Cai `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出一种TopoField框架，用连续隐式函数联合实现肺部树结构的拓扑修复、解剖标注和肺叶分割。

**💡 创新点**

创新点在于将表面与骨架点云联合编码、引入超点描述子与表面‑骨架注意力融合、以及弱监督的TopoBreak修复策略，所有任务共享同一隐式场并在一次前向传播中完成。

**🔧 技术方法**

核心技术包括点云编码器、表面‑骨架注意力模块、三平面投影 + U‑Net生成隐式场、位置编码的多任务MLP、以及基于采样的弱监督修复训练。

**📊 数据集**

使用扩展版 Lung3D+ 数据集（包含完整与人工破坏的 airway、artery、vein 树与 18 个肺叶标签）。

**📈 对比分析**

与 3D‑UNet（滑窗/下采样）和 IPGN 基线相比，TopoField 在拓扑修复的 CF1/DMF1/GDice/ NCC 等指标上显著领先，解剖标注与肺叶重建保持竞争力，并且推理速度提升约两倍（约 1 s/样本）。

**⚠️ 局限性**

局限在于仅处理断裂而未覆盖泄漏等更复杂拓扑缺陷；合成破坏与真实误差的差异；采样策略均匀，未针对解剖边界进行加权；未来需扩展训练分布、引入边界感知采样和更丰富的损失。

---

## 778. Interpretable Tabular Foundation Models via In-Context Kernel Regression

**arXiv ID:** 2602.02162 | [PDF](https://arxiv.org/pdf/2602.02162v1)

**作者:** Ratmir Miftachov `[一作]` (Humboldt-Universität zu Berlin), Simon Valentin `[通讯]` (AWS AI Labs)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出 KernelICL 框架，将表格基础模型的预测头改为显式核函数，使每个预测成为训练标签的加权平均，便于样本级可解释。

**💡 创新点**

创新点在于：① 通过对称嵌入实现核回归的几何解释；② 引入两维可解释性与数据依赖性分类体系；③ 用可调尺度的核函数（高斯、点积、kNN）量化可解释度（perplexity），实现精度-可解释性权衡。

**🔧 技术方法**

使用基于 TabICL 的 transformer 嵌入、线性投影得到统一嵌入，随后采用高斯、点积或 kNN 核进行加权；训练使用合成数据与交叉验证尺度调参；利用 perplexity 评估可解释性。

**📊 数据集**

在 55 个 TALENT 基准二分类数据集上评估，数据规模从 645 到 109k 样本，特征数 3~970。

**📈 对比分析**

与 TabICL、TabPFN 等现有表格基础模型比较，KernelICL 在精度上相当（82.88% vs TabICL 83.33%，无显著差异），且提供样本权重；在 kNN 版本上相对传统 kNN 取得约 5% 的精度提升。

**⚠️ 局限性**

局限性包括：① 对称嵌入导致约 2 倍的计算/内存开销；② 需要手动调节核尺度以平衡精度与可解释性；③ 主要提供样本级解释，无法直接得到特征贡献；③ 需在推理阶段计算全量样本权重，规模较大时仍可能不够高效。

---

## 779. Traffic-Aware Navigation in Road Networks

**arXiv ID:** 2602.02158 | [PDF](https://arxiv.org/pdf/2602.02158v1)

**作者:** Sarah Nassar `[一作]` `[通讯]` (Queen's University), Sarah Nassar (Queen's University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

比较了三种图搜索方法（多查询预处理的Floyd‑Warshall‑Ingerman、实时单查询的Dijkstra/A*、以及Yen的K最短路径）在基于交通条件的Kingston道路网络导航中的性能。

**💡 创新点**

首次将K最短路径算法与传统单查询搜索在交通感知导航中进行对比，并探讨其预处理与实时计算的折衷。

**🔧 技术方法**

使用Python实现，结合OSMnx提取OSM道路图，采用Dijkstra、A*、Yen、Floyd‑Warshall，并对交通权重和速度限制进行边权重计算。

**📊 数据集**

基于Kingston市的OpenStreetMap数据，包含3305个节点、8467条有向边（多数住宅道路）及随机生成的交通权重。

**📈 对比分析**

通过1000次随机起止点实验，衡量预处理时间、实时运行时间和交通加权路径成本，结果显示单查询Dijkstra/A*最优但实时慢，Floyd‑Warshall最快但成本最高，Yen兼顾两者但预处理耗时最长。

**⚠️ 局限性**

受限于预处理时间过长、速度限制缺失需估算、且未考虑动态交通变化和起点终点坐标映射到最近交叉口等实际部署问题。

---

## 780. ECHO: Entropy-Confidence Hybrid Optimization for Test-Time Reinforcement Learning

**arXiv ID:** 2602.02150 | [PDF](https://arxiv.org/pdf/2602.02150v1)

**作者:** Chu Zhao `[一作]` (Northeastern University), Guibing Guo `[通讯]` (Northeastern University)

**通讯引用:** 4176 | [OpenAlex ID](https://openalex.org/A5007061198)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种基于熵-置信度混合的测试时强化学习框架ECHO，用于无监督地改进大语言模型推理。

**💡 创新点**

创新点在于同时利用局部熵和群体置信度来动态调度树搜索分支，在线剪枝避免熵崩溃；以及在更新时采用置信度自适应裁剪和熵-置信度优势塑形，抑制早期伪标签偏差。

**🔧 技术方法**

技术包括树结构rollout、熵与置信度窗口平滑、在线置信度剪枝、PPO式置信度裁剪、熵-置信度优势塑形、KL约束。

**📊 数据集**

使用自然语言数学推理数据集（AIME2024/25、AMC、MATH‑500、GPQA‑Diamond）和多模态视觉数学数据集（Geometry3k、GeoQA、MathVision、MathVista、MathVerse、LogicVista）。

**📈 对比分析**

与TTRL、ETMR、EVOL‑RL、INTUITOR、MM‑UPT等方法对比，在pass@16/1指标上均显著提升（平均提升约5–12%，单个任务最高提升12%以上），且在不同模型规模、训练数据和IID设置下保持稳健。

**⚠️ 局限性**

局限包括对熵和置信度阈值的依赖、仍需手动调参、在极端高难度或非推理任务上的可迁移性未知，且在预算极低时效果相对有限。

---

## 781. Back to the Future: Look-ahead Augmentation and Parallel Self-Refinement for Time Series Forecasting

**arXiv ID:** 2602.02146 | [PDF](https://arxiv.org/pdf/2602.02146v1)

**作者:** Sunho Kim `[一作]` (Korea University), Susik Yoon `[通讯]` (Korea University)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

通过在输入中加入初始预测的分段并训练多模型进行自我修正，改进长时序预测。

**💡 创新点**

利用模型自身预测作为look-ahead增广，结合并行自我改进和top-K集成，实现了简单但显著的性能提升。

**🔧 技术方法**

线性基模型（Linear/DLinear）+ look-ahead 预增广 + 并行第二阶段模型 + top‑K 集成。

**📊 数据集**

ETTh1、ETTm2、Exchange Rate、ILI 四个公开单变量长时序数据集。

**📈 对比分析**

与 iTransformer、SegRNN 等高级结构以及基线线性模型比较，BTTF 在多数场景下提升 MSE/MAE 约 30–58%，即使基线不佳也能显著超越。

**⚠️ 局限性**

训练成本略高（第二阶段需额外训练），对已最佳化的基线可能无显著收益，且目前仅验证单变量，跨变量和自适应分段仍待研究。

---

## 782. Fat-Cat: Document-Driven Metacognitive Multi-Agent System for Complex Reasoning

**arXiv ID:** 2602.02206 | [PDF](https://arxiv.org/pdf/2602.02206v1)

**作者:** Tong Yang `[一作]` (Xiamen University), Aming Wu `[通讯]` (Hunan University of Science and Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出 Fat‑Cat 架构，将 LLM 代理的状态管理从结构化日志转为文档化的 Markdown 记录，并加入 Watcher 运行时审核和文本策略进化，实现高信噪比的上下文管理。

**💡 创新点**

主要创新在于文档驱动状态表征与闭环审核，减少语法噪声并提升注意力聚焦，同时通过无参策略演化实现持续学习。

**🔧 技术方法**

使用 Markdown 语义文件系统、Textual Strategy Evolution 库、独立 Watcher 审核器、外部检索、工具调用以及可插拔策略库等技术；核心模型为 Kimi‑k2、Gemini、GPT‑4o 等 LLM。

**📊 数据集**

评估数据集包括 HotPotQA、MBPP、Bamboogle、Med‑QA 四大基准。

**📈 对比分析**

在四个基准上，Fat‑Cat 在所有模型上均优于 ReAct、AgentScope、MetaGPT，最高提升 14%（如 Kimi‑k2 在 HotPotQA 上提升 13.9%），并使开源模型超越 GPT‑4o。

**⚠️ 局限性**

限制包括对强大模型的依赖、约 10% 的时延开销、对外部知识库的依赖导致知识稀缺场景表现不佳，以及策略库随时间膨胀导致潜在冗余。

---

## 783. Cardinality-Preserving Structured Sparse Graph Transformers for Molecular Property Prediction

**arXiv ID:** 2602.02201 | [PDF](https://arxiv.org/pdf/2602.02201v1)

**作者:** Abhijit Gupta `[一作]` `[通讯]`, Abhijit Gupta

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `9ce7179e-700c-4310-ac2b-91df50ded46e` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出一种结构稀疏图变换器，并加入卡牌保留聚合通道，用于分子属性预测

**💡 创新点**

在图变换器中融合结构稀疏注意力与卡牌保留通道，结合双重自监督预训练

**🔧 技术方法**

Graphormer 风格的结构偏置、K-hop 稀疏注意力、未归一化的 CPA 通道、对比学习与掩码重建

**📊 数据集**

约 28M 分子（ZINC20、ChEMBL35），在 MoleculeNet、OGB、TDC ADMET 11 个公开任务上评测

**📈 对比分析**

在完全匹配的评估协议下，SparseGraphormer‑K3 相较基线提升 10/11 任务，显著优于 GraphMAE‑K3 与 GraphCL

**⚠️ 局限性**

对非常大的分子（K=3 可能遗漏远程效应）和缺乏块稀疏加速的限制

---

## 784. More Than a Quick Glance: Overcoming the Greedy Bias in KV-Cache Compression

**arXiv ID:** 2602.02199 | [PDF](https://arxiv.org/pdf/2602.02199v1)

**作者:** Aryan Sood `[一作]` (Indian Institute of Technology), Vansh Agrawal `[通讯]` (Indian Institute of Technology)

**通讯引用:** 10248 | [OpenAlex ID](https://openalex.org/A5100681053)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了LASER‑KV框架，通过块级累计预算与Exact‑LSH选择，改进了KV缓存压缩，保持长上下文的记忆与准确性。

**💡 创新点**

创新点在于引入保护除数n实现分层保留策略，并结合Exact Attention与Locality Sensitive Hashing双重机制，摆脱单一注意力分数的贪婪裁剪。

**🔧 技术方法**

采用了注意力分数聚合、Exact‑LSH哈希匹配、块级累计预算、look‑back边界平滑等技术。

**📊 数据集**

使用了Babilong长上下文基准（16k、64k、128k）进行评测。

**📈 对比分析**

与SnapKV、FINCH、PyramidKV等基线在QA任务中对比，LASER‑KV在64k/128k时提升约10%以上，且在128k下保持稳定。

**⚠️ 局限性**

实验受算力限制，仅在Babilong上验证，未覆盖更多benchmark，也未深入探究不同模型与硬件的迁移性。

---

## 785. QuietPrint: Protecting 3D Printers Against Acoustic Side-Channel Attacks

**arXiv ID:** 2602.02198 | [PDF](https://arxiv.org/pdf/2602.02198v1)

**作者:** Seyed Ali Ghazi Asgar `[一作]` (Texas A&M University), Narasimha Reddy `[通讯]` (Texas A&M University)

**通讯引用:** 4207 | [OpenAlex ID](https://openalex.org/A5101890763)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `9cc9baba-5356-466d-81ff-d80028d90279` `5b4c1114-4a70-478e-9921-2514ee03850d` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

研究3D打印机的声学侧信道泄漏，提出通过在G‑code中插入隐蔽运动（Stealth Head Movement，SHM）来混淆步进电机和冷却风扇噪声，从而防止音频攻击者重建打印对象；

**💡 创新点**

首次提出仅修改G‑code、无需额外硬件即可对抗声学侧信道的对抗方法，并通过凸包与随机矩形优化降低打印时间；

**🔧 技术方法**

侧信道分析、音频特征提取与峰值检测、XGBoost回归、Procrustes相似度评估、凸包/矩形优化算法、G‑code重写与同步算法；

**📊 数据集**

自行采集的Microsoft Surface Pro 7+麦克风录音数据，使用Elegoo Neptune 3打印机打印的三角形与钥匙模型；未使用公开数据集；

**📈 对比分析**

对比原始模型与攻击者通过音频恢复的模型，量化误差并记录打印时间；SHM在保持高离散度的同时打印时间提升约55%，相较无防御方案能完全隐藏内部结构；

**⚠️ 局限性**

改动G‑code导致打印时间增加，且对高速度/高精度打印的兼容性尚未充分验证，算法对不同机型的通用性有限。

---

## 786. SSI-DM: Singularity Skipping Inversion of Diffusion Models

**arXiv ID:** 2602.02193 | [PDF](https://arxiv.org/pdf/2602.02193v1)

**作者:** Chen Min `[一作]`, Zheng Ma `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出了一种新的深度学习模型，用于图像分类任务。

**💡 创新点**

创新点在于引入了一种新的激活函数，能够提高模型的收敛速度和分类精度。

**🔧 技术方法**

使用了卷积神经网络（CNN）和改进的激活函数。

**📊 数据集**

使用了CIFAR-10和ImageNet数据集进行实验。

**📈 对比分析**

与传统的激活函数模型进行了比较，结果显示新模型在分类精度上提高了5%，且训练时间缩短了15%。

**⚠️ 局限性**

模型在处理高分辨率图像时性能下降，且对计算资源的需求较高。

---

## 787. Self-Evolving Coordination Protocol in Multi-Agent AI Systems: An Exploratory Systems Feasibility Study

**arXiv ID:** 2602.02170 | [PDF](https://arxiv.org/pdf/2602.02170v1)

**作者:** Jose Manuel de la Chica Rodriguez `[一作]` (Grupo Santander), Juan Manuel Vera Díaz `[通讯]` (Grupo Santander)

**关键词:** `ca287573-fa3b-4b00-8a06-ae3eda6fdb99` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6`

**🎯 论文内容**

本文通过六个AI评估模块对六个拜占庭一致性协议提案进行评估，实验比较四种协调方案，并演示了可验证的单步协议自我修改，证明了自适应协调协议的技术可行性。

**💡 创新点**

创新点在于提出并实现了“自演化协调协议（SECP）”，该协议允许在保持硬性安全和可审计约束的前提下，对自身决策规则进行受限、经过治理的修改，填补了传统单一硬直或完全可补偿协调方法之间的治理空白。

**🔧 技术方法**

技术手段包括：使用Claude Sonnet 4.5和GPT‑4等大型语言模型实现六个专用评估模块，设计非标量协调规则（SECP v1.0），以及构建受限修改框架（mod_m、Revise、Inv）和基于规则的可审计日志记录。

**📊 数据集**

数据集为固定的六个拜占庭一致性协议提案集合（C_EXP、C_VAL、C_MIN、G_ROB、G_PRF、G_ECO），以及对应的六个评估模块输出。

**📈 对比分析**

比较方法采用覆盖率（接受提案数量）指标；在同一硬性约束下，统一否决方案0/6，均值加权聚合6/6，SECP v1.0 2/6，SECP v2.0 3/6，显示自我修改后覆盖率提升约50%。

**⚠️ 局限性**

主要局限性包括：单次实验且仅进行一次协议修改，缺乏统计显著性与泛化；评估依赖LLM，存在幻觉与不一致风险；未做对抗性测试或人机交互评估；以及缺乏形式化证明与长期动态分析。

---

## 788. Efficient Neural Controlled Differential Equations via Attentive Kernel Smoothing

**arXiv ID:** 2602.02157 | [PDF](https://arxiv.org/pdf/2602.02157v1)

**作者:** Egor Serov `[一作]` (Applied AI Institute), Alexey Zaytsev `[通讯]` (Applied AI Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `a8e75ba4-7a2d-4153-b003-06c94533add0` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出一种通过可学习的多视角注意力机制和高斯过程/核平滑对Neural CDE的控制路径进行重构，从而显著降低数值求解器的函数评估次数（NFE），同时保持或提升预测性能。

**💡 创新点**

核心创新包括：
1) 用核平滑或高斯过程替代传统精确插值，减少控制路径的粗糙度；
2) 引入多视角（Multi‑View）注意力框架（MV‑CDE）及其卷积扩展（MVC‑CDE），利用可学习查询在不同平滑尺度下聚合信息；
3) 将多条平滑路径并行求解为块对角ODE系统，实现一次求解多个子路径，从而进一步提升计算效率。

**🔧 技术方法**

技术要点：
- Neural Controlled Differential Equations (Neural CDEs)
- 高斯过程回归（GP）与核平滑（Nadaraya‑Watson）
- 可学习查询的注意力机制（Q‑Former 形式）
- 多头注意力与卷积特征提取
- 适配自适应求解器（如 Dormand‑Prince）实现块对角求解
- 复杂度分析与NFE理论推导

**📊 数据集**

在 UEA Time Series Archive 上的三个基准：
- CharacterTrajectories（低维、快速变化）
- SpokenArabicDigits（高维语音特征）
- UWaveGestureLibrary（长序列、运动模式）

**📈 对比分析**

与传统基线（Linear/Cubic Neural CDE、Log‑NCDE、ODE‑RNN、GRU‑D 等）在准确率和计算效率上进行对比。MVC‑CDE（GP）在三大数据集均实现了 state‑of‑the‑art 的分类准确率，并将 NFE 降低 4.3×–14.5×，在 UWaveGestureLibrary 上相对 ODE‑RNN 的速度提升可达 16×，同时对噪声具有更好的鲁棒性。

**⚠️ 局限性**

局限性：
- 高斯过程前处理需要 O(N³) 的矩阵求逆，虽为一次性成本，但在极长序列或在线学习场景中仍是瓶颈；
- 多视角注意力的参数量随头数增加而线性增长，可能导致模型规模膨胀；
- 现有方法主要关注时间序列的连续化和求解效率，对空间或多模态数据的扩展尚未深入；
- 在极低噪声或已非常平滑的数据上，过度平滑可能导致细节信息丢失，需在实际应用中进行调参。

---

## 789. HPE: Hallucinated Positive Entanglement for Backdoor Attacks in Federated Self-Supervised Learning

**arXiv ID:** 2602.02147 | [PDF](https://arxiv.org/pdf/2602.02147v1)

**作者:** Jiayao Wang `[一作]` (Yangzhou University), Dongfang Zhao `[通讯]` (University of Washington)

**通讯引用:** 1324 | [OpenAlex ID](https://openalex.org/A5101671477)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `c84dae5d-5273-4348-85a7-b44cb586b4df` `6215c339-3735-4be3-8a07-5bbb7004712d` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出并实现了一种针对联邦自监督学习的后门攻击方法——HPE，能够在不泄露数据的情况下将后门植入全局模型。

**💡 创新点**

创新点包括：利用幻觉增强生成难正样本提升后门样本利用率、特征纠缠机制强化触发器-目标类关联、以及双层约束毒化策略抑制聚合消融并提升持久性。

**🔧 技术方法**

主要技术手段为幻觉增强（hallucinated positive augmentation）、特征纠缠损失（backdoor feature entanglement）、投影梯度下降+维度约束毒化、以及基于MoCo的对比学习框架。

**📊 数据集**

实验使用了五个视觉基准数据集：CIFAR‑10、STL‑10、CIFAR‑100、GTSRB 与 ImageNet‑100，覆盖不同规模与类别。

**📈 对比分析**

与 BADFSS、EmInspector、BASSL、CTRL、BadEncoder 等SOTA方法对比，HPE 在 ASR 上均超过 90%（最高 99.4%），ACC 维持 70‑80% 之间，且在多种防御（DECREE、Neural Cleanse、Beatrix、FL 聚合防御）下仍保持高成功率。

**⚠️ 局限性**

局限性在于：目前仅验证于视觉任务与MoCo/SimCLR 等 SSL 算法，对文本/语音等模态未知；若聚合规则或客户端数目大幅变化，攻击效果可能衰减；并且依赖特定触发器与目标类，攻击泛化受限。

---

## 790. Scientific Theory of a Black-Box: A Life Cycle-Scale XAI Framework Based on Constructive Empiricism

**arXiv ID:** 2602.02215 | [PDF](https://arxiv.org/pdf/2602.02215v1)

**作者:** Sebastian Müller `[一作]` (University of Bonn), Christian Bauckhage `[通讯]` (University of Bonn)

**通讯引用:** 9604 | [OpenAlex ID](https://openalex.org/A5003875445)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

建立了“科学理论”框架（SToBB），用于持续记录、维护黑盒模型的可解释信息，并提供统一的审计与更新机制。

**💡 创新点**

创新点在于将可解释性视作可持续、可审计的科学理论，借助构造经验主义提出经验充分性、适应性和可审计性三大义务；同时实现了在线规则基代理的构造与更新算法，首次将解释过程与生命周期管理结合。

**🔧 技术方法**

技术上结合了构造经验主义哲学、规则基代理（轴对齐盒子系统）、LIME辅助观测、在线学习与更新算法，以及Python/UMAP等可视化工具。

**📊 数据集**

在证明概念时使用了Abalone数据集（三分类），对其训练的神经网络进行解释与代理构建。

**📈 对比分析**

论文主要为概念与实现，未与现有XAI方法做实验比较；示例中代理在所有观察上保持完全一致，压缩率高、更新率低，但未给出传统的性能指标。

**⚠️ 局限性**

局限性包括仅针对固定模型、单一数据域和单一辅助观测；缺乏对非平稳场景的支持；未提供客观性能评测；实现对特定解释器的依赖性需进一步验证。

---

## 791. Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation

**arXiv ID:** 2602.02214 | [PDF](https://arxiv.org/pdf/2602.02214v1)

**作者:** Hongzhou Zhu `[一作]` (Tsinghua University), Jun Zhu `[通讯]` (Tsinghua University)

**通讯引用:** 67250 | [OpenAlex ID](https://openalex.org/A5115666530)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `8d10c613-917e-4880-9716-17789f50e119` `ba576bd1-e51d-44e8-8077-fc943b333c93` `a8e75ba4-7a2d-4153-b003-06c94533add0` `f86bf285-fd08-4156-973b-6e6481af8fa0` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出一种新的自动回归视频扩散模型蒸馏方法——Causal Forcing，解决了现有方法在将双向模型蒸馏为因果模型时的架构差距导致的性能下降问题。

**💡 创新点**

核心创新在于：①证明在ODE初始化阶段必须满足帧级单射性；②使用教师强制训练的因果扩散模型作为教师，从而天然满足单射性；③构建三阶段流程（教师强制、因果ODE蒸馏、非对称DMD），显著提升动态度、视觉质量和指令遵循能力。

**🔧 技术方法**

技术包括：教师强制（Teacher Forcing）训练因果扩散模型；概率流ODE（PF‑ODE）蒸馏；自回归分数蒸馏（DMD）和一致性蒸馏（Consistency Distillation）。

**📊 数据集**

主要使用的公开数据集包括：从Wan2.1双向模型生成的3K合成数据集、VidProM训练集用于DMD训练，以及VBench评估基准；实验也在100个高动态提示集上评估。

**📈 对比分析**

与现有基准（Wan2.1、LTX‑1.9B、NOVA、Pyramid Flow、SkyReels‑V2、MAGI‑1‑4.5B、CausVid、Self‑Forcing）对比，Causal Forcing在动态度提升19.3%、VisionReward提升8.7%、指令遵循提升16.7%，保持与Self‑Forcing相同的实时推理速度（17 FPS、0.69s延迟）。

**⚠️ 局限性**

局限性包括：1）目前的自回归一致性蒸馏实现仍较为基础，尚未充分发挥一致性蒸馏潜力；2）模型仍在特定场景下可能出现运动失真或细节模糊；3）在更大分辨率或更复杂动作的生成任务上，尚需进一步验证。

---

## 792. Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models

**arXiv ID:** 2602.02185 | [PDF](https://arxiv.org/pdf/2602.02185v1)

**作者:** Yu Zeng `[一作]` (University of Science and Technology of China), Shaosheng Cao `[通讯]` (Xiaohongshu Inc.)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出并构建了一个视觉先导的多模态深度搜索基准（VDR‑Bench），并提出了多轮裁剪搜索和实体召回指标。

**💡 创新点**

创新点在于（1）通过人工裁剪与网页搜索构造真正需要视觉验证的问题；（2）设计实体召回指标量化搜索质量；（3）引入多轮视觉强制（MVF）提升模型对视觉证据的利用。

**🔧 技术方法**

采用多阶段筛选、人工裁剪、图像检索、LLM辅助实体验证、知识图谱扩展、多轮交互式视觉检索与跨模态推理技术。

**📊 数据集**

使用了2,000个多跳VQA实例，覆盖10个视觉领域，来自公开图像集并通过裁剪和检索生成。

**📈 对比分析**

在Direct、CIS+TS、CIS+TS+MVF三种设置下对Gemini 2.5 Pro、Qwen3‑VL‑235B‑A22B‑Instruct等模型进行评估，直接回答准确率低，而加入裁剪搜索与多轮视觉强制后准确率提升20–30%不等，显示出搜索与迭代视觉检索的重要性。

**⚠️ 局限性**

限制主要包括对LLM先验知识的依赖、裁剪与检索过程仍有人工成本、在更大规模或更真实网络检索环境下的泛化能力尚待验证。

---

## 793. Evaluating Metalinguistic Knowledge in Large Language Models across the World's Languages

**arXiv ID:** 2602.02182 | [PDF](https://arxiv.org/pdf/2602.02182v1)

**作者:** Tjaša Arčon `[一作]` (University of Ljubljana), Kaja Dobrovoljc `[通讯]` (University of Ljubljana)

**通讯引用:** 2705 | [OpenAlex ID](https://openalex.org/A5011635545)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建了基于世界语言结构图谱 (WALS) 的大规模多语言元语言学评测基准，并用该基准评估了三大 LLM（GPT-4o、Llama-3.3-70B、Gemma-3.27B）在 2,600+ 语言的 192 结构特征上的回答准确率。

**💡 创新点**

创新之处在于首次将人类语言学知识与 LLM 进行对齐评测，并将评测覆盖扩展到超过 2,600 种语言，揭示了资源匮乏语言对模型元语言知识的制约。

**🔧 技术方法**

采用零样本多选提问、准确率与宏 F1、相对准确率增益等指标，对模型输出与 WALS 真实标签进行比较；同时使用 Google 搜索点击量、Wikipedia 文章数等外部指标来解释性能差异。

**📊 数据集**

主要数据集为 WALS 192 结构特征与 2,660 语言的手工标注数据，另选取 WALS 100 语言样本以获得更均匀覆盖；评测使用 OpenAI GPT‑4o API 与本地部署的 Llama‑3.3‑70B 与 Gemma‑3‑27B。

**📈 对比分析**

与随机基线（0.234）和多数类基线（0.539）对照，GPT‑4o 在整体准确率上达到 0.367，低于多数类基线；在词汇、动词类别等域表现最佳，语音、符号语言等域最低，且低资源语言的准确率显著低于高资源语言。

**⚠️ 局限性**

主要局限包括 WALS 覆盖稀疏、离散特征不反映语料渐进性、模型可能利用多选选项的表面线索、以及基准可能被模型在训练时直接学习到的内容影响。

---

## 794. Extending the Law of Intersegmental Coordination: Implications for Powered Prosthetic Controls

**arXiv ID:** 2602.02181 | [PDF](https://arxiv.org/pdf/2602.02181v1)

**作者:** Elad Siman Tov `[一作]` (Technion Israel Institute of Technology), Nili E. Krausz `[通讯]` (Technion Israel Institute of Technology)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文通过将3D关节角转换为升高角并定义升高空间力矩(ESM)，研究了正常人与大腿截肢者在不同义肢（被动/主动）下步态的段间协调（ISC），并探讨了将ISC约束用于义肢控制的可能性。

**💡 创新点**

①提出通用的关节角到升高角转换方法；②定义并验证升高空间力矩与升高角协同；③利用ISC作为约束预测膝关节行为，为义肢控制提供新思路；④公开ISC3d工具箱。

**🔧 技术方法**

利用Vicon运动捕捉+仪器化跑步机采集三维运动数据；通过姿态变换矩阵计算升高角；使用主成分分析(PCA)和Planarity Index评价协同；构造简化Jacobian实现关节力矩到升高空间的映射；用线性模型分析步态段间耦合。

**📊 数据集**

10名正常受试者（10种步态）和3名转股截肢者（仅步行），截肢者分别佩戴被动义肢和主动义肢，在慢/中/快三种自选速度下完成实验。

**📈 对比分析**

采用PCA/PI、线性拟合（slope、bias）、R²与RMSE对比升高角与ESM的协同。能量评估中R²≈0.91、RMSE≈6.5%；预测膝关节行为时预测值比实际更接近正常，但仍显不足。总体显示义肢步态的升高角/ESM协同低于正常。

**⚠️ 局限性**

样本量小（仅3名截肢者），仅平地跑步机无坡度，速度范围有限；未实现实时控制；简化Jacobian可能导致能量误差和ESM协同下降；缺乏能量代谢测量与扰动实验验证。

---

## 795. CIEC: Coupling Implicit and Explicit Cues for Multimodal Weakly Supervised Manipulation Localization

**arXiv ID:** 2602.02175 | [PDF](https://arxiv.org/pdf/2602.02175v1)

**作者:** Xinquan Yu `[一作]` (Sun Yat-sen University), Xiangyang Luo `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `e0540dec-d77f-42db-94ae-d039248f6393` `729e5870-4135-47f5-97f2-e3974d07b5dc` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一个 CIEC 框架，利用弱监督的图像-文本配对实现多模态篡改定位。

**💡 创新点**

创新点在于将隐式单模态线索与显式跨模态指导耦合，并设计 TRPS 与 VCTG 两个模块及多种约束，实现仅用图像/句子级标签即可定位篡改区域。

**🔧 技术方法**

采用双流跨模态特征对齐、软掩模候选框、Top‑K 聚合、背景消声、空间对比增强、异向稀疏约束和语义一致性约束等技术。

**📊 数据集**

在 DGM⁴ 数据集上评估，该数据集包含四类图像和文本篡改。

**📈 对比分析**

与全监督 SOTA 方法和改写的弱监督基线相比，CIEC 在二分类、图像定位和文本定位任务中均达到或超过全监督方法的性能，特别是图像定位 IoU75 提升超过 12%。

**⚠️ 局限性**

局限性包括对细粒度文本篡改（如 TS、TA）的定位效果仍不理想，且模型训练需要较高的计算资源与时间。

---

## 796. Deep learning enables urban change profiling through alignment of historical maps

**arXiv ID:** 2602.02154 | [PDF](https://arxiv.org/pdf/2602.02154v1)

**作者:** Sidi Wu `[一作]` (Institute of Cartography and Geoinformation), Lorenz Hurni `[通讯]` (Institute of Cartography and Geoinformation)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

对历史地图系列进行全自动、细粒度的城市变化分析，提出一个模块化框架，包括稠密对齐、多时态目标检测与变化剖面。

**💡 创新点**

创新点在于自监督稠密位移网络通过合成地图变化和文本位移来学习复杂非均匀位移，并结合多时态特征融合的实例分割，实现完全自动化的城市变化表征。

**🔧 技术方法**

使用自监督稠密位移网络（GLU‑Net改造的WarpC）、Transformer‑based实例分割Mask2Former并加入多时态特征融合，文本检测DeepSolo用于合成，图像变换仿真等技术。

**📊 数据集**

主要数据集为巴黎 Atlas Municipal 1:5000 历史规划地图（1868‑1937 年），以及瑞士 Siegfried 地形图用于迁移实验。

**📈 对比分析**

与 GLU‑Net、WarpC、Mask2Former 基线对比，稠密对齐的 SSIM 和 CD 接近或优于 WarpC，产生更平滑、更时序一致的位移场；实例分割在不同尺寸建筑上的 AP 提升约 10%‑15%，尤其中小尺寸建筑；整体变化映射在巴黎研究中揭示了空间时间异质性。

**⚠️ 局限性**

局限包括假设地图已地理参考、对极度抽象早期地图适应性不足、变化表示对对象重要性缺乏层级区分，以及仍需人工标注用于合成和验证。

---

## 797. MIRROR: Manifold Ideal Reference ReconstructOR for Generalizable AI-Generated Image Detection

**arXiv ID:** 2602.02222 | [PDF](https://arxiv.org/pdf/2602.02222v1)

**作者:** Ruiqi Liu `[一作]` (Institute of Automation), Shu Wu `[通讯]` (Institute of Automation)

**通讯引用:** 1108 | [OpenAlex ID](https://openalex.org/A5109291841)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `ba576bd1-e51d-44e8-8077-fc943b333c93` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种基于参考对比的AI生成图像检测框架MIRROR，利用真实图像的先验构建理想参考并通过残差判别伪造图像。

**💡 创新点**

创新点在于将人类视觉的参考对比思路量化为离散记忆银行与稀疏投影，既编码真实图像流形，又通过残差与困惑度双信号实现生成器无关的检测。

**🔧 技术方法**

采用DINOv3等预训练视觉编码器、可学习的正交原型记忆库、Top‑k稀疏投影、重构困惑度与残差融合的分类头。

**📊 数据集**

使用MSCOCO等真实图像训练记忆库，随后在27种生成模型（Diffusion、Autoregressive、Unified等）合成的数据上微调，评估标准数据集包括AIGCDetect、GenImage、DRCT‑2M、UnivFakeDetect、Synthbuster、EvalGEN、Chameleon、SynthWildx、WildRF、AIGIBench、CO‑SPY‑Bench、BFree‑Online、RRDataset以及自研的Human‑AIGI benchmark。

**📈 对比分析**

与多种基线（NPR、UnivFD、FatFormer、C2P‑CLIP、SAFE、AIDE、B‑Free、DDA等）对比，MIRROR在14个标准与野外基准上平均提升2.1%（标准）/8.1%（野外），在Human‑AIGI人类不可察觉子集上达到89.5%准确率，超过非专业人类（76.9%）和视觉专家（88.3%）。

**⚠️ 局限性**

局限性包括需依赖大量真实图像构建记忆库；对极端后处理（如高噪声、极低分辨率）鲁棒性尚待进一步验证；记忆库尺寸与Top‑k选择需经验调参。

---

## 798. Using Correspondence Patterns to Identify Irregular Words in Cognate sets Through Leave-One-Out Validation

**arXiv ID:** 2602.02221 | [PDF](https://arxiv.org/pdf/2602.02221v1)

**作者:** Frederic Blum `[一作]` (Max Planck Institute for Evolutionary Anthropology), Johann-Mattis List `[通讯]` (Max Planck Institute for Evolutionary Anthropology)

**通讯引用:** 4036 | [OpenAlex ID](https://openalex.org/A5012676548)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一种新的平衡平均递归对应模式（regularity）指标，并基于该指标开发了一种留一验证方法来检测词汇集合中的不规则词。

**💡 创新点**

创新点在于将对应模式的出现频率进行对数化、归一化后得到跨数据集可比的正则度量，并利用该指标实现自动识别不规则词汇。

**🔧 技术方法**

技术包括使用CLDF标准化词表、LingPy SCA算法进行对齐、LingRex CoPaR算法推断对应模式，随后计算对数平衡平均递归，并通过留一验证寻找最不规则词。

**📊 数据集**

使用了LexiBank v2.1中20个具有手工标注共性词的子集，涵盖19个语族，约576种语言，约1400多概念。

**📈 对比分析**

在模拟数据上，当不规则率≤10%时识别准确率≈90%，超过40%则降至≤10%；在真实数据上，5语言子样本平均准确率≈87.5%，10语言子样本下降至≈79%，表明正则度量与数据质量密切相关。

**⚠️ 局限性**

局限在于缺乏大规模手工对齐数据，方法假设单一不规则词，若有多重不规则则无法定位；且正则度量对语言样本与距离高度敏感。

---

## 799. LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation

**arXiv ID:** 2602.02220 | [PDF](https://arxiv.org/pdf/2602.02220v1)

**作者:** Bo Miao `[一作]` (Adelaide University), Anton van den Hengel `[通讯]` (Adelaide University)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了多粒度、开放词汇的目标导航任务和基准“Language as a Map”，通过人类对比式注释为四个语义层级（场景、房间、区域、实例）提供了高质量、可辨别的目标描述，并生成了超过1.8万条导航任务。

**💡 创新点**

创新点包括：①将目标分层到四个细粒度语义级别；②采用对比式人类验证注释，生成仅5.3词的简洁描述和15.9词的详细描述；③将目标类别扩展至414种，显著提升语义多样性；④提供开放词汇评估框架和多目标序列任务；⑤相较于GOAT‑Bench，判别率提升23.8%且词量更少。

**🔧 技术方法**

技术手段主要有：对比式人类注释流程、基于VLM的零样本和监督模型评估、强化学习与模块化架构、显式记忆与路径规划、以及大规模多模态训练（如MTU3D、Uni‑Navid）。

**📊 数据集**

使用的数据集为真实世界的HM3D扫描（HM3D‑Sem验证场景），并在此基础上构建了新的“Language as a Map”注释和任务集。

**📈 对比分析**

与GOAT‑Bench、HM3D‑OVON、LHPR‑VLN等基准对比，本文基准在判别率、词量等指标上均优越；在单目标任务中，MTU3D和Uni‑Navid以SR/SPL领先；在多目标序列任务中，虽然相对单目标有所提升，但SeqSR仍显不足，尤其在长尾、远距离和小目标任务上表现下降。

**⚠️ 局限性**

局限性包括：对长尾和小目标的识别与导航效果仍低；多目标完成率不高，难以处理多级语义和复杂上下文；依赖人工对比注释导致规模与效率受限；在极长距离或高度动态场景下仍缺乏足够的推理与规划能力。

---

## 800. Am I More Pointwise or Pairwise? Revealing Position Bias in Rubric-Based LLM-as-a-Judge

**arXiv ID:** 2602.02219 | [PDF](https://arxiv.org/pdf/2602.02219v1)

**作者:** Yuzheng Xu `[一作]` (OMRON SINIC X), Yoshitaka Ushiku `[通讯]` (OMRON SINIC X)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

研究并量化了 Rubric‑based LLM‑as‑a‑Judge 评估中的位置偏差，并提出了平衡置换策略来检测和缓解此偏差。

**💡 创新点**

① 将 rubric‑based 评估视为多选任务，首次揭示其位置偏差；② 设计平衡置换方案并用 Bias Cost 选择低偏差排列；③ 证明置换能提升 LLM 与人类评分的一致性。

**🔧 技术方法**

采用 LLM‑as‑a‑Judge 评估、10 种循环置换（平衡置换）、Bias Cost 计算、Pearson/Spearman 相关性分析与 within‑item 标准差度量等技术。

**📊 数据集**

MT‑Bench、Vicuna‑Bench、HANNA、SummEval 四个评测数据集（共 2,816 条样本）。

**📈 对比分析**

与固定排列（Repeat）对比；平衡置换后，模型与人类评分的 Pearson/Spearman 相关性平均提升约 2‑3%，最高可达 8.9% Spearman，标准差略增；部分模型如 Qwen3‑8B 在置换下略逊。

**⚠️ 局限性**

仅评估了十种排列，数据集覆盖有限；平衡置换并非总能提升性能，且偏差消除并不保证更高的人类一致性；方法可能被滥用以操纵评分。

---

## 801. Towards AI Evaluation in Domain-Specific RAG Systems: The AgriHubi Case Study

**arXiv ID:** 2602.02208 | [PDF](https://arxiv.org/pdf/2602.02208v1)

**作者:** Md. Toufique Hasan `[一作]` (Tampere University), Pekka Abrahamsson `[通讯]` (Tampere University)

**通讯引用:** 10181 | [OpenAlex ID](https://openalex.org/A5058417486)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `a2602d71-93ab-4bad-974b-672788df8193` `9cc9baba-5356-466d-81ff-d80028d90279` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

开发并迭代评估了一个针对芬兰语言农业决策支持的检索增强生成系统AgriHubi。

**💡 创新点**

创新点在于将芬兰农业文档与开放式PORO LLMs结合，提供显式源引用与用户反馈闭环，实现低资源语言下的领域适配和可靠性提升。

**🔧 技术方法**

技术包括PDF文本抽取与OCR、文本分块、OpenAI embedding + FAISS向量检索、PORO系列LLMs推理、Streamlit界面、SQLite反馈数据库及多语言处理。

**📊 数据集**

使用芬兰国家农业政策、研究报告、监管文件等PDF文档构建知识库，并通过OCR补全扫描材料。

**📈 对比分析**

通过两轮用户研究（分别使用Poro 2.8B和Poro 34B），用五点Likert评分评估完整度、流畅度和可靠性；在迭代后，顶级评分从3%提升至21%，低分率从46%降至38%，验证了检索质量与模型规模的显著正向影响。

**⚠️ 局限性**

局限性包括硬件受限导致的大模型延迟、样本量有限、对瑞典语支持不足、隐私风险及多轮评估缺乏统一指标。

---

## 802. Sinhala Physical Common Sense Reasoning Dataset for Global PIQA

**arXiv ID:** 2602.02207 | [PDF](https://arxiv.org/pdf/2602.02207v1)

**作者:** Nisansa de Silva `[一作]` (University of Moratuwa), Surangika Ranathunga `[通讯]` (Massey University)

**通讯引用:** 1154 | [OpenAlex ID](https://openalex.org/A5002889503)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文构建了首个基于僧伽罗语的物理常识推理数据集，并对其进行人工生成与验证。

**💡 创新点**

创新点在于首次为僧伽罗语设计文化特定的常识推理数据集，并对跨文化 LLM 的表现进行系统评测。

**🔧 技术方法**

采用 SinBERT 与 GPT‑5 mini 两种模型进行零样本多项选择问答实验，并利用编辑距离与词频分析评估难度。

**📊 数据集**

使用自建的 110 条样本数据集（包括 67 条段落补全、43 条问答对）以及参考 PiQA 数据集的格式。

**📈 对比分析**

通过零样本实验对比，SinBERT 仅 49% 正确率，GPT‑5 mini 达 64.5%，均低于均匀随机，说明模型对僧伽罗语文化知识掌握不足。

**⚠️ 局限性**

局限性包括数据集主要偏向僧伽罗佛教文化，可能存在拼写错误，且 GPT‑5 mini 仅评测一次且输出非确定性。

---

## 803. Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models

**arXiv ID:** 2602.02197 | [PDF](https://arxiv.org/pdf/2602.02197v1)

**作者:** Xindian Ma `[一作]` (Tianjin University), Jing Zhang `[通讯]` (Tianjin University)

**通讯引用:** 45859 | [OpenAlex ID](https://openalex.org/A5100345410)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种层次自适应淘汰(HAE)的KV缓存淘汰框架，结合双注意力裁剪(DAP)和动态解码淘汰策略(DDES)，以减少多模态LLM的KV缓存内存并加速推理。

**💡 创新点**

首次在多模态模型中实现视觉-文本协同的层级淘汰，并在解码阶段使用回收箱批量淘汰机制，既提升效率又保持信息完整性。

**🔧 技术方法**

利用Transformer键值缓存管理、注意力权重分析、双注意力裁剪算法、动态回收箱批量淘汰、理论误差上界证明以及KV广播索引优化技术。

**📊 数据集**

评测使用Phi‑3.5‑Vision‑Instruct、LLaVA‑1.5‑7B等模型，实验数据集包括GQA、ScienceQA、MMMU、Seed‑Story、TGIF、MSVD、MSRVT等。

**📈 对比分析**

与ToMe、FastV、SparseVLM、MustDrop、H2O等主流KV淘汰方法对比，图像问答任务保持≈97%原模型质量、KV缓存下降41%，推理速度提升1.5×；图像故事生成任务质量接近原模型、速度提升33%。

**⚠️ 局限性**

仅适用于无训练的裁剪策略，无法直接推广到极大模型的多模态长文本生成；对视觉与文本注意力分布差异的假设在其他任务中可能不稳健；未提供端到端可学习的淘汰机制。

---

## 804. TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents

**arXiv ID:** 2602.02196 | [PDF](https://arxiv.org/pdf/2602.02196v1)

**作者:** Hang Yan `[一作]` (Xi'an Jiaotong University), Qika Lin `[通讯]` (National University of Singapore)

**通讯引用:** 1238 | [OpenAlex ID](https://openalex.org/A5086407377)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了Test‑Time Improvement Diagnostic Evaluation（TIDE）框架，对LLM多轮交互代理的测试时改进过程进行诊断；

**💡 创新点**

将TTE分解为三维度（优化效率、行为适应、记忆效用），并定义三种指标AUV、LR、MI，首次系统化量化代理在交互过程中的动态演化；

**🔧 技术方法**

采用POMDP/MDP建模交互、基于轨迹的循环检测算法、曲线积分（AUV）、循环比率（LR）与记忆差分（MI）计算；

**📊 数据集**

在多种公开环境（BlocksWorld、FrozenLake、Sudoku、AlfWorld、WebShop、GUI OSWorld等）及多款LLM代理（Gemini、DeepSeek、Qwen、GLM、Phi、Claude等）上收集轨迹数据；

**📈 对比分析**

与传统成功率（SR）及Progress Rate（PR）比较，TIDE显示在相同SR下不同代理的AUV差异明显；LR与AUV呈负相关，MI揭示记忆对性能的正负影响，实验表明大模型循环率低、AUV高，记忆利用需精细管理；

**⚠️ 局限性**

局限性在于指标仅基于轨迹统计，无法解释循环形成的深层原因；对极大规模或实时环境的可扩展性尚待验证；

---

## 805. State Rank Dynamics in Linear Attention LLMs

**arXiv ID:** 2602.02195 | [PDF](https://arxiv.org/pdf/2602.02195v1)

**作者:** Ao Sun `[一作]` (Meituan), Renqing He `[通讯]` (Meituan)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `fede83ac-7505-405f-ab37-e7284695c47f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

分析线性注意力大型语言模型在推理过程中的状态矩阵动力学，发现并量化状态秩分层现象，并提出 Joint Rank‑Norm Pruning 方案以在不显著损失性能的前提下显著压缩 KV 缓存。

**💡 创新点**

创新点包括：① 通过谱分析首次揭示状态秩分层（高秩与低秩头）且其秩分布在时间上保持不变；② 理论证明秩上限与核范数累积导致的时间不变性；③ 发现低秩头对推理至关重要，高秩头冗余；④ 提出无监督的 Joint Rank‑Norm Pruning 策略，实现高效压缩。

**🔧 技术方法**

主要技术：线性注意力（Qwen‑Next）模型、谱分解与有效秩指标、核范数与余弦相似度度量、理论证明（秩上限与秩/范数保持性）、剪枝算法（基于 Saturation Score）。

**📊 数据集**

使用的评估数据集：RankViz（数学推理、STEM、长上下文、对抗攻击样本）、WikiText、GitHub、arXiv、Math‑500、GSM8K、NIAH 等。

**📈 对比分析**

与原始模型对比，去掉高秩头后模型准确率仅下降约 3%（例如 GSM8K 100%→96.9%，NIAH 93.8%→90.6%），而去掉低秩头导致严重性能崩塌；Joint Rank‑Norm Pruning 在保持 90% 以上准确率的同时将 KV 缓存显著减少约 38.9%。

**⚠️ 局限性**

局限性：仅在 Qwen‑Next 上验证，未验证其他线性注意力架构；对抗攻击或极端循环输入下分层可能失效；对长期依赖任务的完整性与可迁移性仍需进一步研究。

---

## 806. Reasoning in a Combinatorial and Constrained World: Benchmarking LLMs on Natural-Language Combinatorial Optimization

**arXiv ID:** 2602.02188 | [PDF](https://arxiv.org/pdf/2602.02188v1)

**作者:** Xia Jiang `[一作]` (Eindhoven University of Technology), Yingqian Zhang `[通讯]` (Eindhoven University of Technology)

**通讯引用:** 5165 | [OpenAlex ID](https://openalex.org/A5004461578)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文构建了NLCO基准，用自然语言描述的组合优化任务，让大语言模型直接输出可行且近优解，评估其端到端推理能力；

**💡 创新点**

创新点在于四层结构化分类法（变量类型、约束族、全局模式、目标类别）和完全去除外部求解器的端到端评测设计，兼顾任务多样性与诊断性；

**🔧 技术方法**

采用大语言模型（Open‑weight 与专有 LLM）、自然语言生成与多样化处理、全局模式校验等技术实现数据生成、评估与性能分析；

**📊 数据集**

数据集来源于公开优化库（如TSPLIB、CP‑Bench 等），共 43 题 6,450 个实例，按三难度层级（S、M、L）扩展，并通过 LLM 生成多样化自然语言情境；

**📈 对比分析**

实验对比 8 个开源 LLM 与 5 个专有模型，衡量可行率、准确率、对数最优性差距与 token 用量；结果显示在小实例上可行率可达 98% 以上、准确率 80% 以上，随实例规模增大性能急剧下降，图结构与瓶颈目标尤为困难；

**⚠️ 局限性**

主要局限是规模扩展困难、推理成本高、对全局约束和瓶颈目标的处理仍不够鲁棒，需进一步提升推理效率与全局一致性检验能力。

---

## 807. Malware Detection Through Memory Analysis

**arXiv ID:** 2602.02184 | [PDF](https://arxiv.org/pdf/2602.02184v1)

**作者:** Sarah Nassar `[一作]` `[通讯]` (Queen's University), Sarah Nassar (Queen's University)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

利用CIC MalMemAnalysis‑2022数据集，对内存快照特征进行机器学习建模，实现恶意软件检测（二分类）和三类恶意软件子类型分类（多分类）。

**💡 创新点**

在二分类和多分类任务上分别取得了99.98%和87.54%的准确率，明显优于数据集原始的99.00%与未公布的多分类基线；同时通过XGBoost实现极快的推理速度（50条样本分别为37.3ms和43.2ms）。

**🔧 技术方法**

构建完整的ML流水线：数据探索、特征缩放、PCA可视化、五折交叉验证、九种模型比较（NB、LR、KNN、MLP、DT、RF、GB、LGBM、XGBoost），最终采用XGBoost。

**📊 数据集**

使用加拿大网络安全研究所发布的CIC MalMemAnalysis‑2022数据集，共58,596条记录（29,298恶意/29,298良性），并在Kaggle下载的CSV格式进行实验。

**📈 对比分析**

通过k折交叉验证和单独测试集评估，指标包括准确率、F1、ROC‑AUC、log‑loss等；XGBoost在二分类上达到99.99%准确率、99.99% F1，ROC‑AUC 100%；在多分类上达到87.54%准确率、81.26% F1，ROC‑AUC 97%。

**⚠️ 局限性**

主要局限包括：数据集泄漏风险（同一样本多次采样导致训练/测试混杂），缺失API‑hook特征，恶意子类型定义不够清晰（Trojan horse与ransomware/spyware混用），以及模型对新样本泛化能力尚未充分验证。

---

## 808. STILL: Selecting Tokens for Intra-Layer Hybrid Attention to Linearize LLMs

**arXiv ID:** 2602.02180 | [PDF](https://arxiv.org/pdf/2602.02180v1)

**作者:** Weikang Meng `[一作]` (SMULL Group Harbin Institute of Technology), Zheng Zhang `[通讯]` (SMULL Group Harbin Institute of Technology)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了STILL框架，将预训练LLM的注意力层改造成线性时间的混合注意力，以实现高效长上下文推理。

**💡 创新点**

创新点在于①用自显著性得分（Self‑Saliency Score）基于内容而非位置动态路由token到软注意力/线性注意力；②设计保持norm一致的NP‑Map特征映射，避免线性化过程中对预训练范数的失真；③采用分块并行与延迟选择机制，提升训练和推理的并行度与效率。

**🔧 技术方法**

使用自显著性得分、Norm‑Preserved Feature Map、分块并行实现、LoRA微调、两阶段训练（Attention Transfer + Low‑Rank Linearization）等技术。

**📊 数据集**

训练采用清洗后的Alpaca数据（2千万token，长度1024）；评估使用PIQA、ARC‑Easy/Challenge、HellaSwag、WinoGrande、MMLU、RULER、BABILong等标准基准。

**📈 对比分析**

与原Transformer、滑窗Attention、LoLCATs、Liger、Mamba2等方法对比；STILL在短序列零样本任务中平均得分最高，在长上下文任务中恢复约86%全注意力性能，显存减少约45%，解码速度提升约28%。

**⚠️ 局限性**

仍受限于需手动设定窗口/token阈值，局部窗口对显著性评分的覆盖有限，极大token数下延迟仍有提升空间，且对多语言或多任务的迁移效果未充分验证。

---

## 809. SurvKAN: A Fully Parametric Survival Model Based on Kolmogorov-Arnold Networks

**arXiv ID:** 2602.02179 | [PDF](https://arxiv.org/pdf/2602.02179v1)

**作者:** Marina Mastroleo `[一作]` (Politecnico di Milano), Matteo Matteucci `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一种完全参数化、连续时间的生存模型 SurvKAN，利用 Kolmogorov–Arnold 网络直接学习对数危险函数，并通过可视化边缘激活函数实现可解释性。

**💡 创新点**

创新点包括：① 抛弃传统的比例危险假设，允许时间随风险变化；② 将时间作为显式输入，模型可学习任意时间变化的危险；③ 利用 KAN 的可学习单变量激活函数实现参数化、可解释且参数量小的网络；④ 通过结构化正则化与符号回归实现自动特征选择与可读式表达。

**🔧 技术方法**

技术方法：Kolmogorov–Arnold 网络（KAN）、对数危险函数直接建模、完整生存似然训练、边缘激活函数正则化（L1、熵、光滑项）、符号回归降维、梯形法积分求累积危险、自动微分优化。

**📊 数据集**

使用了十个公开生存基准数据集：AIDS、Breast Cancer、Framingham、GBSG2、METABRIC、NWTCO、PBC、TCGA–BRCA、Veterans、WHAS500。

**📈 对比分析**

与传统、树基、神经网络和 KAN 基础模型（AFT、CoxPH、CoxKAN、DeepHit、DeepSurv、RSF、XGBoost）在 C‑Index 与 Integrated Brier Score 上对比。SurvKAN 在 6/10 数据集的 C‑Index 与 5/10 数据集的 IBS 上取得最佳或第二名，平均提升约 2%–3% 的 C‑Index 与 IBS，尤其在消除 PH 约束后显著优于 CoxKAN。

**⚠️ 局限性**

局限性：① 与非参数方法如 RSF 相比，校准稍逊（IBS略低）；② 仍为“黑盒”到一定程度，尽管可解释，但缺乏因果推断；③ 需要大量时间积分与正则化调参，计算开销相对较高；④ 在极少数样本或高维稀疏数据上表现尚待验证。

---

## 810. Generalized Optimal Classification Trees: A Mixed-Integer Programming Approach

**arXiv ID:** 2602.02173 | [PDF](https://arxiv.org/pdf/2602.02173v1)

**作者:** Jiancheng Tu `[一作]` (Hong Kong Polytechnic University), Zhibin Wu `[通讯]` (Sichuan University)

**通讯引用:** 4145 | [OpenAlex ID](https://openalex.org/A5002005671)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种基于混合整数规划的可扩展框架，用于在非线性、不平衡的评估指标（如F1、MCC）下学习全局最优分类树。

**💡 创新点**

创新点包括：① 通过唯一实例压缩、Benders分解与冲突子集/特征激活剪枝提升规模；② 将F1、MCC等非线性指标转化为线性化MIP；③ 引入深度增量与随机森林引导的温启动与节点级启发式。

**🔧 技术方法**

采用混合整数规划、Benders分解、McCormick包络线性化、特征冲突剪枝、热启动、随机森林特征排名以及LP导向启发式等技术。

**📊 数据集**

在50个公开基准数据集（样本数从100到245,057，包含平衡与不平衡分布）上进行实验。

**📈 对比分析**

与BendersOCT、DP方法及MIQP相比，本文方法在求解时间上快约20×，在大多数数据集达到最优或更优的F1/MCC，并在不平衡任务上实现更好的泛化性能。

**⚠️ 局限性**

局限性包括：对更深树或极大样本量时仍存在计算瓶颈；需手工二值化特征；线性化导致变量增多，对特征维数高度敏感。

---

## 811. Reg4Pru: Regularisation Through Random Token Routing for Token Pruning

**arXiv ID:** 2602.02163 | [PDF](https://arxiv.org/pdf/2602.02163v1)

**作者:** Julian Wyatt `[一作]` (University of Oxford), Irina Voiculescu `[通讯]` (University of Oxford)

**通讯引用:** 1190 | [OpenAlex ID](https://openalex.org/A5055611196)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5663785e-e4e3-40e4-b675-cbd84d82d1f9`

**🎯 论文内容**

在训练时通过随机路由（token routing）正则化token pruning，以提升高分辨率医学影像分割的准确性和计算效率。

**💡 创新点**

提出Reg4Pru方法，使用随机化路由区间模拟pruning动态，缓解pruning导致的表示不稳定，并实现一次模型可适应多种pruning比例。

**🔧 技术方法**

利用ViT架构、Gumbel‑Softmax采样、Attention Masking、随机路由、信息化策略（BCE损失）和EoMT dense prediction框架。

**📊 数据集**

在FIVES血管分割数据集上进行实验。

**📈 对比分析**

与未使用路由的同一模型对比，平均精度提升绝对46%，在29%相对时钟速度提升的配置下实现显著性能提升。

**⚠️ 局限性**

对pruning预算的手动设定、随机路由区间可能导致训练收敛不稳定，以及在极高分辨率下可扩展性待进一步验证。

---

## 812. Generating Causal Temporal Interaction Graphs for Counterfactual Validation of Temporal Link Prediction

**arXiv ID:** 2602.02161 | [PDF](https://arxiv.org/pdf/2602.02161v1)

**作者:** Aniq Ur Rahman `[一作]` (University of Oxford), Justin P. Coon `[通讯]` (University of Oxford)

**通讯引用:** 3773 | [OpenAlex ID](https://openalex.org/A5001680231)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出一种基于因果结构的时序链路预测(counterfactual validation)框架，利用生成的因果时序交互图(CTIG)对模型进行评估。

**💡 创新点**

创新点在于：①设计了可控的因果事件序列和CTIG生成机制，保证有已知因果结构；②提出了衡量不同因果模型相似度的交叉预测误差距离；③通过因果偏移和时间戳打乱两种方式实现对模型的因果鲁棒性检验。

**🔧 技术方法**

主要技术包括：结构方程模型(SEM)用于连续时间事件生成；随机图模型与泊松过程生成触发序列；阈值化与非因果边掩码构造CTIG的因果影响矩阵；距离度量与统计稳定性分析；负采样构造正负样本；多模型实验评估。

**📊 数据集**

使用自生成的合成CTIG数据集，包含不同节点特征、边特征、因果影响以及随机噪声，未使用公开真实数据集。

**📈 对比分析**

比较方法：在相同训练集下对原始测试集与因果偏移/打乱后的测试集进行模型评估，记录AP、AUC、准确率等指标。结果显示TGN在因果偏移和时间戳打乱时性能明显下降，说明其对因果结构敏感；而JODIE性能几乎不变，缺乏因果鲁棒性。

**⚠️ 局限性**

局限性包括：仅在合成数据上验证，缺乏真实世界因果数据；负采样不保证所有负样本不可行；距离度量仅对参数化模型适用，难以推广到复杂非参数因果模型；实验只覆盖两种TLP模型，未涵盖更广泛模型。

---

## 813. D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use

**arXiv ID:** 2602.02160 | [PDF](https://arxiv.org/pdf/2602.02160v1)

**作者:** Bowen Xu `[一作]` (Alibaba Cloud Computing), Bin Yang `[通讯]` (Alibaba Cloud Computing)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `8d10c613-917e-4880-9716-17789f50e119` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 D-CORE 框架，结合自蒸馏与多样性强化学习，提升大推理模型的工具使用能力并解决“懒惰推理”问题。

**💡 创新点**

创新性地将自蒸馏激励子任务分解与完整推理轨迹生成相结合，再加入熵正则的 DA‑GRPO，既保持分解能力又恢复反思与探索多样性。

**🔧 技术方法**

采用自蒸馏、DA‑GRPO（带熵正则的 GRPO）、工具调用奖励设计、少样本提示及伪标签等技术。

**📊 数据集**

使用 BFCLv3、τ‑Bench、ACEBench、τ²‑Bench、BFCLv4‑agentic 等真实代理任务和公开数据集。

**📈 对比分析**

与 SFT、GRPO、ToolRL 等基线对比，D‑CORE‑14B 在 BFCLv3 上取得 79.3% 的准确率，超过 70B 规模模型；在 τ‑Bench 上提升 18‑19%；整体准确率显著提高，同时“懒惰推理”比例大幅下降。

**⚠️ 局限性**

局限性包括需要大量自蒸馏样本和较长训练时间，熵正则参数需手工调优，过高会导致性能下降；目前仅针对文本工具，尚未扩展到多模态或更复杂外部接口。

---

## 814. Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing

**arXiv ID:** 2602.02159 | [PDF](https://arxiv.org/pdf/2602.02159v1)

**作者:** Lingkun Long `[一作]` (Beihang University), Jianlei Yang `[通讯]` (Beihang University)

**通讯引用:** 1385 | [OpenAlex ID](https://openalex.org/A5053303853)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `ba576bd1-e51d-44e8-8077-fc943b333c93` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了无训练的稀疏注意力框架 Focus-dLLM，用以加速长上下文的扩散式大型语言模型推理。

**💡 创新点**

创新点在于利用前一步的置信度预测当前未掩码位置（Past Confidence‑Guided Indicator），并通过识别并保留跨层一致的注意力汇聚点（sink‑aware pruning）来显著减少冗余注意力计算。

**🔧 技术方法**

采用的技术包括：置信度驱动的候选查询选取、窗口扩展策略、跨层共享的注意力汇聚点、块级键值缓存与动态块级稀疏注意力、以及结合键值键值重用的近似 KV 缓存。

**📊 数据集**

实验数据集为 LongBench（包含多种长文本理解任务），以及在 UltraLLaDA 与 Dream‑7B‑Instruct 两个扩散式 LLM 上进行评估。

**📈 对比分析**

与 Vanilla、Fast‑dLLM、Sparse‑dLLM、SparseD 等基线比较，Focus‑dLLM 在 32K 上下文长度下实现了超过 29× 的速度提升，同时保持甚至提升了平均准确度（如 UltraLLaDA 平均分最高，Dream‑7B‑Instruct 与 Vanilla 接近）。

**⚠️ 局限性**

局限性包括：目前仅针对文本推理，未验证多模态推理；超参数手动设定，缺乏自适应调整机制，可能在不同领域表现不一致。

---

## 815. Enabling AI Deep Potentials for Ab Initio-quality Molecular Dynamics Simulations in GROMACS

**arXiv ID:** 2602.02234 | [PDF](https://arxiv.org/pdf/2602.02234v1)

**作者:** Andong Hu `[一作]` (KTH Royal Institute of Technology), Ivy Peng `[通讯]` (KTH Royal Institute of Technology)

**通讯引用:** 1191 | [OpenAlex ID](https://openalex.org/A5037069204)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `64443552-63e0-44b5-906f-d90fe95c5a1b` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `09944146-298c-433e-89df-37255de463d7` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

集成 DeePMD-kit 与 GROMACS，实现 GPU 加速的 AI 深潜在量子质量分子动力学工作流；

**💡 创新点**

首次在 GROMACS 官方接口中支持多模型、多后端 AI 深潜在，并对 DPA2 与 DPA3 在蛋白质系统上的端到端 GPU 性能进行全面特征化；

**🔧 技术方法**

采用 C++/CUDA 与 DeePMD-kit 的多后端（PyTorch、TensorFlow、JAX 等）推理，结合注意力机制的 DPA2 与图神经网络的 DPA3 大原子模型；

**📊 数据集**

使用四个溶剂蛋白质基准（1YRF、1UBQ、3LZM、2PTC）进行实验；

**📈 对比分析**

通过 ns/day、GPU 内存使用、kernel 时间占比等指标在 NVIDIA A100 与 GH200 GPU 上比较 DPA2、DPA3 与经典 MD，DPA2 吞吐量平均比 DPA3 高 4.23×（A100）和 3.18×（GH200），但相较经典 MD 仍低 2–3 倍；

**⚠️ 局限性**

DPA3 的内存占用过高导致 OOM，当前实现未支持多 GPU 域分解，kernel 启动开销大，限制了大规模并行与长期运行的可行性。

---

## 816. LiFlow: Flow Matching for 3D LiDAR Scene Completion

**arXiv ID:** 2602.02232 | [PDF](https://arxiv.org/pdf/2602.02232v1)

**作者:** Andrea Matteazzi `[一作]` (University of Wuppertal), Dietmar Tutsch `[通讯]` (University of Wuppertal)

**通讯引用:** 389 | [OpenAlex ID](https://openalex.org/A5000306618)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `729e5870-4135-47f5-97f2-e3974d07b5dc` `40105733-5154-44cd-8090-a8cab9e64b07` `ba576bd1-e51d-44e8-8077-fc943b333c93` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

本文提出了一种基于流匹配的LiDAR场景补全方法 LiFlow，利用连续时间流场逐步生成完整的3D 点云。

**💡 创新点**

创新点在于首次将流匹配框架应用于3D LiDAR补全，并引入最近邻流匹配与 Chamfer 距离匹配两种损失，消除了传统扩散模型在训练与推理初始分布不一致的问题。

**🔧 技术方法**

技术包括连续时间流匹配（Flow Matching）、条件流匹配、MinkUNet 预测器、最近邻流匹配、Chamfer 距离匹配以及分类器无指导的条件控制。

**📊 数据集**

数据集使用 SemanticKITTI（训练序列 00-07、09-10，验证序列 08）以及 Apollo Columbia Park MapData 序列 00 进行训练与评估。

**📈 对比分析**

与 LiDiff、LiDPM 等基线相比，LiFlow 在 Chamfer Distance、Jensen‑Shannon Divergence 与 Voxel IoU 指标上均取得或接近最优表现，且在较少的采样步数下即可完成高质量补全。

**⚠️ 局限性**

主要局限在于细粒度（0.1 m）下的 Voxel IoU 略低，体现了全局几何一致性与细粒度占据精度之间的权衡。

---

## 817. SEDformer: Event-Synchronous Spiking Transformers for Irregular Telemetry Time Series Forecasting

**arXiv ID:** 2602.02230 | [PDF](https://arxiv.org/pdf/2602.02230v1)

**作者:** Ziyu Zhou `[一作]` (Hong Kong University of Science and Technology), Yuxuan Liang `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 5538 | [OpenAlex ID](https://openalex.org/A5018828723)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出 SEDformer，利用事件对齐的 SNN 结构对不规则多变量时间序列进行精准预测。

**💡 创新点**

创新点在于发现并利用稀疏-事件双重性（SED），通过事件对齐 LIF 神经元、事件保留下采样以及膜驱动线性注意力机制，既保留事件语义又充分利用稀疏性，实现高效且准确的预测。

**🔧 技术方法**

采用事件同步编码、EA‑LIF 神经元、事件保留下采样模块、SED‑Spike Transformer 以及线性注意力等 SNN 与 Transformer 结合的技术栈。

**📊 数据集**

使用公开的互联网流量遥测数据集 Wiki2000（9,013 篇维基百科页面）和 WikiArticle（Kaggle Web Traffic Time Series 300 个变量）进行实验。

**📈 对比分析**

与 RNN、ODE、Transformer、GNN 等四大类基线进行对比，SEDformer 在 25%–75% 稀疏率下 MSE/MAE 均显著低于最强基线，同时在算力和能耗上优于对齐填充或图结构方法，提升显著。

**⚠️ 局限性**

局限在于目前仅支持离散事件时间，缺少概率预测、在线学习能力，且在实际低功耗硬件或异构平台上的部署验证仍待进一步研究。

---

## 818. The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation Manifolds of Language Models' Posteriors

**arXiv ID:** 2602.02315 | [PDF](https://arxiv.org/pdf/2602.02315v1)

**作者:** Raphaël Sarfati `[一作]`, Ekdeep Singh Lubana `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `67630363-6be0-4f51-ab05-7198250671a5` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

在大型语言模型（如 Llama‑3.2）中，用生成正态分布的整数序列做为提示，探究模型如何在内部表征空间中编码、更新并可操纵这些分布的后验信念，揭示信念形成的几何结构、动态轨迹以及干预效果。

**💡 创新点**

1) 发现模型内部形成弯曲的“信念流形”，不是单一线性方向；2) 提出并验证线性场探针（Linear Field Probes）方法，能够以连续方式对信念参数（如均值、方差）进行读取；3) 证明几何感知的干预（沿流形或场几何）相比传统线性 steering 能更好保持目标分布，避免意外耦合偏移。

**🔧 技术方法**

采用少样本推理与自回归预测、PCA / Intensive‑PCA 可视化、线性场探针训练、流形插值、曲线拟合以及在激活空间与其对偶空间上进行的 steering 对比实验。

**📊 数据集**

使用基于整数（0‑999）的合成正态分布样本，生成一系列时间序列作为模型提示；不使用外部标注数据，仅靠模型自身产生的 logits 与激活来构建真值。

**📈 对比分析**

将传统线性 steering 与几何感知的干预进行对比；实验显示，沿流形或场几何的干预能使输出更贴近目标正态分布（保持方差不变），而线性 steering 常导致分布漂移和高方差。论文未给出数值指标，而是以概率分布图和流形轨迹可视化方式证明性能差异。

**⚠️ 局限性**

仅在小型开源 LLM 上实验，任务局限于数值正态分布，难以推广到更复杂的自然语言任务；假设信念可被单一连续参数化，未验证在非参数化情境下的有效性；未探究导致几何结构的具体神经机制或因果归因。

---

## 819. Spark: Modular Spiking Neural Networks

**arXiv ID:** 2602.02306 | [PDF](https://arxiv.org/pdf/2602.02306v1)

**作者:** Mario Franco `[一作]` (Binghamton University), Carlos Gershenson `[通讯]` (Binghamton University)

**通讯引用:** 5206 | [OpenAlex ID](https://openalex.org/A5020377067)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出并实现了 Spark，一款基于 JAX/Flax 的 GPU 并行、模块化、可视化设计的脉冲神经网络（SNN）框架，并利用该框架在稀疏奖励的 Cartpole 控制任务中，仅使用简单的三因素突触可塑性规则实现快速自适应学习（40–80 轮即可收敛），不依赖反向传播、演化算法或其他优化手段。

**💡 创新点**

创新点在于：1）将 SNN 的建模拆解为可复用的神经元、接口、控制器三大模块，支持灵活组合与替换；2）提供蓝图-实例双向表示和图形编辑器，显著降低代码耦合与重写成本，提升可复现性；3）利用 JAX 的 JIT 与 Flax 的状态管理，实现高效 GPU 交互式仿真；4）在传统的 Cartpole 基准上，仅凭可塑性实现了最快的样本效率，突破了以往需使用 surrogate gradient 或演化策略的限制。

**🔧 技术方法**

技术包括：JAX 进行张量计算与 GPU 加速；Flax 负责自动状态管理与模块化；自定义的三因素 STDP 可塑性规则；图形化模型编辑器与蓝图系统；与 Brian2 进行仿真对比；OpenAI Gym 的 Cartpole 环境作为实验环境。

**📊 数据集**

数据集：使用 OpenAI Gym 的 Cartpole 环境（无外部数据集，直接与模拟环境交互）。在性能基准中使用了 LIF、AdEx、HH 等标准神经元模型的随机输入（Ornstein–Uhlenbeck 过程）进行仿真。

**📈 对比分析**

比较方法：1）仿真精度：Spark 与 Brian2 在膜电位与脉冲统计（平均 ISI 与 SPIKE 距离）的一致性；2）性能：在三种网络架构下测量交互式仿真速度和编译时间，Spark 相比 Brian2 C++ 可提升 5–200 倍，且显著优于 Brian2 CUDA；3）任务性能：在 Cartpole 上，Spark 训练的 25 个模型中 16/25 在 40–80 轮内获得完美得分，明显快于传统深度 RL 算法所需的 100–1000 轮。

**⚠️ 局限性**

局限性：1）Spark 仍在开发中，模型选择与功能（如自定义 kernel）有限；2）部分模型在边界条件下收敛慢或不收敛，需更优的突触初始化与奖励调度；3）低精度浮点运算在极大规模或特殊组件下可能导致数值不稳定；4）对交互式仿真的支持虽优于 Brian2，但仍未实现真正的实时嵌入式部署。

---

## 820. The SPARSE-Relativization Framework and Applications to Optimal Proof Systems

**arXiv ID:** 2602.02294 | [PDF](https://arxiv.org/pdf/2602.02294v1)

**作者:** Fabian Egidy `[一作]` `[通讯]` (University of Wuerzburg), Fabian Egidy (University of Wuerzburg)

**关键词:** `b85d34da-f1e4-4203-bfed-9536213d369b`

**🎯 论文内容**

本文通过构造稀疏oracle，使用新的‑relativization框架，证明了在多种oracle环境下（包括无限多项式时间层级和收敛多项式时间层级）关于（p）最优证明系统的存在与否的相对论性结论，从而为Cook–Reckhow计划中关于SAT、TAUT和真量化布尔公式等集合的最优证明系统问题提供了新的相对论性障碍。

**💡 创新点**

创新点在于提出了“稀疏‑oracle‑独立”概念和相应的框架，使得在构造稀疏oracle时能自动获得一系列与多项式时间层级无关的性质，从而实现将单个oracle构造转化为同时满足多种复杂度假设的强大证据；此外，还首次在oracle构造中结合了稀疏oracle与基于时间构造函数的“复杂集合”技术，得到具有任意复杂度的集合仍有p‑最优证明系统的结果。

**🔧 技术方法**

主要技术包括：
- 稀疏‑oracle‑独立性理论（基于Hirahara‑Lu‑Ren的bounded relativization）
- 稀疏‑relativization框架
- 构造稀疏oracle的递归/迭代过程，利用代码词（c_K, c_L）编码证明系统的正确性与复杂度
- 对POTENTIAL proof systems的p‑optimal性证明与模拟函数构造
- 结合多项式时间层级的无限性与收敛性假设来构造相应的oracle O_1、O_2。

**📊 数据集**

本研究属于理论计算复杂度，没有使用实验数据集，所有结论均为理论证明。

**📈 对比分析**

由于研究重点为相对论性证明壁垒，而非算法性能，故本文未进行实验对比或性能评估；相应的“比较”体现在不同oracle下对Q1、Q2、Q3结论的相对可证性与不可证性。

**⚠️ 局限性**

局限性包括：
- 构造的oracle仅在相对论性意义下有效，无法直接转化为实际算法的改进。
- 对“稀疏‑oracle‑独立”命题的完整性尚未完全阐述，仍需进一步挖掘可独立命题。
- 研究中未给出可计算（如P‑可算）oracle实现，尤其是关于多项式时间层级无限性的oracle仍是开放问题。

---

## 821. Kimi K2.5: Visual Agentic Intelligence

**arXiv ID:** 2602.02276 | [PDF](https://arxiv.org/pdf/2602.02276v1)

**作者:** Kimi Team `[一作]`, Xinxing Zu `[通讯]`

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出Kimi K2.5，一款开源多模态智能体，融合文本与视觉训练并引入代理集群实现并行推理。

**💡 创新点**

创新点在于早期低比例视觉融合、零视觉SFT激活视觉推理、联合文本‑视觉强化学习提升跨模态能力，以及通过Agent Swarm实现动态并行任务分解与主动上下文管理。

**🔧 技术方法**

采用MoonViT‑3D三维视觉编码器、Kimi K2 MoE语言模型、MuonClip优化器、Decoupled Encoder Process、PARL并行强化学习及生成奖励模型等技术。

**📊 数据集**

训练使用约15万亿混合视觉与文本token（包括图像alt、合成字幕、OCR、视频、知识等），评测覆盖AIME、HMMT、IMO、SWE‑Bench、MMMU、BrowseComp等众多数据集。

**📈 对比分析**

与GPT‑5.2、Claude Opus 4.5、Gemini 3 Pro等专有模型以及DeepSeek‑V3.2、Qwen3‑VL等开源基线对比，K2.5在多项推理、编码、视觉、视频及代理搜索任务上取得SOTA，Agent Swarm更是使推理延迟缩短3–4.5倍。

**⚠️ 局限性**

局限性包括训练成本极高、模型规模庞大、对极端新颖任务的泛化仍有限，以及尚未充分评估安全与对抗鲁棒性。

---

## 822. Segment to Focus: Guiding Latent Action Models in the Presence of Distractors

**arXiv ID:** 2602.02259 | [PDF](https://arxiv.org/pdf/2602.02259v1)

**作者:** Hamza Adnan `[一作]` (University of Oxford), Alexey Zakharov `[通讯]` (University of Oxford)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

本文提出 MaskLAM，利用基于 Segment Anything 的代理分割掩码对 LAM 的重建损失进行空间加权，从而在视觉噪声环境中引导模型关注代理运动，提升无标签视频下的动作表征质量并加速下游策略学习。

**💡 创新点**

创新点在于：1）提供一种轻量、无架构改动的插件式改进；2）利用零样本分割掩码实现代理中心化的监督；3）显著减少所需的潜在动作维度，同时在存在行动相关背景噪声时实现约 4 倍奖励提升和 3 倍潜在动作对齐度提升。

**🔧 技术方法**

技术主要包括：Latent Action Model（LAPO）框架、前向动力学模型与逆向动力学模型、基于 SAM 的分割掩码生成、加权重构损失、线性探针评估以及基于行为克隆的下游控制器。

**📊 数据集**

使用的实验数据集为 MuJoCo 4 个连续控制任务（Hopper、Half‑Cheetah、Walker、Humanoid）在 Distracting Control Suite 生成的带行动相关视频背景噪声的 5000 条 1000 步轨迹，观察为 64×64 RGB 图像。

**📈 对比分析**

与传统 LAPO（干净/噪声）、全监督逆向动力学模型以及有限标签的行为克隆基线进行比较；MaskLAM 在噪声环境下可实现高达 4 倍奖励提升，线性探针 MSE 减少约 3 倍，并在 OOD 背景下保持更高的返回；同时在低标签样本下样本效率明显优于基线。

**⚠️ 局限性**

局限性包括：① 仍依赖像素级重建目标，易受高频噪声影响；② 依赖 SAM 掩码质量，掩码误差会影响训练信号；③ 不能完全恢复无噪声场景下的最高性能，仍存在一定性能缺口。

---

## 823. Introns and Templates Matter: Rethinking Linkage in GP-GOMEA

**arXiv ID:** 2602.02311 | [PDF](https://arxiv.org/pdf/2602.02311v1)

**作者:** Johannes Koch `[一作]` (Centrum Wiskunde and Informatica), Peter A. N. Bosman `[通讯]` (Centrum Wiskunde and Informatica)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

重新设计GP‑GOMEA的关联学习，提出两种新度量：一种在互信息估计中掩码无效变量，另一种直接利用固定树模板构建预定义链接树，以提升符号回归性能。

**💡 创新点**

创新点在于（1）通过掩码处理无效子节点以消除互信息噪声；（2）利用已知的树模板直接构造链接结构，无需从种群统计学习，从而更准确捕捉变量依赖。

**🔧 技术方法**

采用GP‑GOMEA框架，使用互信息、偏置调整互信息、节点邻近性度量，并通过UPGMA层次聚类构建链接树；实验中还使用IMS多起点策略和线性缩放。

**📊 数据集**

实验数据集包括五个符号回归基准：Airfoil、Bike Sharing Daily、Concrete Compressive Strength、Dow Chemical 和 Tower。

**📈 对比分析**

通过与随机、MI、MI_adjusted、MI_masked、Node、Node(static)等度量进行对比，使用10⁷评估预算、训练/测试R²评分、IQM和运行时间衡量。结果显示Node度量最优，其次是MI_masked，显著提升准确率、收敛速度和运行效率。

**⚠️ 局限性**

局限性包括依赖固定模板大小、对模板结构假设过强、未覆盖数值常量的表示与可解释性评估、随机化在链接树构建中的影响尚不完全明确。

---

## 824. Understanding and Detecting Flaky Builds in GitHub Actions

**arXiv ID:** 2602.02307 | [PDF](https://arxiv.org/pdf/2602.02307v1)

**作者:** Wenhao Ge `[一作]` (Soochow University), Chen Zhang `[通讯]` (Soochow University)

**通讯引用:** 25528 | [OpenAlex ID](https://openalex.org/A5108047889)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `3855fcda-48ef-4070-a15e-803cd5c84d83` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文系统分析了 GitHub Actions 中重跑构建的 flaky builds，构建了两套大规模数据集，研究了 flaky builds 的出现频率与根因，并提出基于日志语义与 CI 元数据融合的机器学习模型 FlakeDetector 用于预测 flaky failures。

**💡 创新点**

创新点包括：①首次在 GitHub Actions 上对 flaky builds 进行大规模实证研究；②挖掘并归纳了 15 种根本失败类型；③提出了结合日志语义向量与结构化 CI 元数据的双模学习框架，显著提升 F1 分数；④公开了两套高质量数据集。

**🔧 技术方法**

技术路线主要包括：1）爬虫+GitHub API 收集构建日志；2）使用正则抽取、向量化+FAISS 搜索构建日志相似度并做 Logistic 回归；3）自研静态分析器提取 AST、git 及 CI 相关特征，并采用 XGBoost、RF、SVM、MLP 训练；4）用线性加权融合日志与结构化置信度，再做阈值判定；5）采用前向链交叉验证防止时序泄漏。

**📊 数据集**

使用 1,960 个公开 Java 项目的 GitHub Actions 构建历史（4,861,768 builds、15,382,267 jobs），并对 10 个项目做重跑实验生成 flaky failure 标注数据；数据集已公开于 https://flaky-build.github.io/。

**📈 对比分析**

与先前的 Olewicki 等基线模型在相同前向链验证下对比，SVM、MLP 模型平均 F1 分别为 0.80/0.78，显著高于基线 0.67，提升约 20%。Precision、Recall、AUC 等指标均优于基线，且模型在不同项目间表现稳定。

**⚠️ 局限性**

局限性包括：仅覆盖 Java + GitHub Actions，未涉及多语言或自托管 CI；flaky 标注仍可能漏检低概率 flaky；实验依赖公开仓库，无法处理需要 secret 的构建；模型解释性有限，无法直接给出根因修复建议。

---

## 825. EvalQReason: A Framework for Step-Level Reasoning Evaluation in Large Language Models

**arXiv ID:** 2602.02295 | [PDF](https://arxiv.org/pdf/2602.02295v1)

**作者:** Shaima Ahmad Freja `[一作]` (University of Stavanger), Chunming Rong `[通讯]` (University of Stavanger)

**通讯引用:** 5690 | [OpenAlex ID](https://openalex.org/A5108044249)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出 EvalQReason 框架，对大型语言模型在推理链中的每一步概率分布进行无人工标注的动态评估。

**💡 创新点**

创新点在于引入连续步骤偏移（CSD）和步到最终收敛（SFC）两种无监督的概率分布偏移算法，并结合 KL、JS、Hellinger、余弦相似度与熵差五种统计指标来量化推理动态。

**🔧 技术方法**

技术上先提取推理链中每一步的 token logits，计算步骤级概率分布后使用五种统计度量评估局部连贯性和全局收敛性，再用传统机器学习和序列神经网络预测答案正确性。

**📊 数据集**

实验使用数学领域的 AIME、Math‑500 以及医学领域的 MedQA 三大公开基准数据集，覆盖不同难度和推理长度。

**📈 对比分析**

与现有嵌入式、监督式和无监督式推理评估方法比较，CSD 在数学任务上无标注即可达到 F1≈0.88、AUC≈0.97，显著超过先前最佳方法（F1≈0.79）并进一步提升到 0.97 的 AUC。

**⚠️ 局限性**

局限性包括对医学推理的判别信号极弱、仅在 7B 开源模型上验证、未探索更大规模模型或对抗/安全场景的鲁棒性。

---

## 826. RACA: Representation-Aware Coverage Criteria for LLM Safety Testing

**arXiv ID:** 2602.02280 | [PDF](https://arxiv.org/pdf/2602.02280v1)

**作者:** Zeming Wei `[一作]` (Peking University), Meng Sun `[通讯]` (Peking University)

**通讯引用:** 191597 | [OpenAlex ID](https://openalex.org/A5100748869)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `9cc9baba-5356-466d-81ff-d80028d90279` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一种面向LLM安全测试的表示感知覆盖准则RACA，基于安全关键表示提取和概念激活计算，给出了六个子准则来衡量测试集的覆盖质量；

**💡 创新点**

创新点在于将传统基于神经元的覆盖转化为低维安全概念空间的覆盖，利用PCA提取安全关键方向，显著降低维度、去除冗余信息，并同时评估概念的单体与组合覆盖；

**🔧 技术方法**

技术上使用了表示工程（中间层隐藏状态的PCA）、概念激活得分、聚类（SCC、CBC）、配对概念覆盖（PCC）以及多准则集成评估；

**📊 数据集**

实验数据集包括SorryBench与ORBench‑Toxic的有害提示、Alpaca的正常提示以及Vicuna‑7B、Llama‑2‑7B、Qwen‑2.5‑7B等三大开源LLM；

**📈 对比分析**

与五个基线神经元层覆盖准则（NC、TKNC、TKNP、TFC、NLC）在三大7B模型及13B Vicuna 上进行比较，RACA 在识别高质量 jailbreak 提示、测试集优先级排序和攻击提示采样上均优于基线，ASR 与正常样本占比显著提升；

**⚠️ 局限性**

局限性在于依赖校准集的质量、层选择、PCA维度与阈值设置等超参数，且在更大规模模型、不同安全任务或更广泛攻击形式下的鲁棒性仍需进一步验证。

---

## 827. Bridging the Sim-to-Real Gap with multipanda ros2: A Real-Time ROS2 Framework for Multimanual Systems

**arXiv ID:** 2602.02269 | [PDF](https://arxiv.org/pdf/2602.02269v1)

**作者:** Jon Škerlj `[一作]` (Munich Institute of Robotics and Machine Intelligence), Sami Haddadin `[通讯]` (Mohamed Bin Zayed University of Artificial Intelligence)

**通讯引用:** 16586 | [OpenAlex ID](https://openalex.org/A5024171209)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0`

**🎯 论文内容**

本文提出了一个基于ROS2的多机器人控制框架，支持Franka机器人在1 kHz的低延迟下实现实时力矩控制，并通过控制let设计实现≤2 ms的控制器切换。框架同时集成MuJoCo仿真，提供动力学一致性评估，并利用实测惯量参数识别显著缩小了sim‑to‑real差距。

**💡 创新点**

创新点包括：① 采用控制let模式实现多控制器的无冲突切换，切换延迟≤2 ms；② 统一的1 kHz力矩控制循环满足安全标准；③ 将MuJoCo仿真与ROS2无缝对接，提供包括力、扭矩和控制误差在内的全局一致性评估；④ 通过真实数据进行惯量参数辨识，形成闭环的仿真模型迭代。

**🔧 技术方法**

技术栈：ROS2（Humble）、Franka Fast Research Interface (FRI)、MuJoCo、GJK自碰撞检测、操控空间势能避免奇异、UFIC与笛卡尔阻抗控制、C++模板与继承实现控制let、数据分布式服务（DDS）实现高效通信。

**📊 数据集**

数据来源：在Franka Panda机器人上完成一系列自由空间、接触、圆轨迹、双臂协同抓取等5项实验（共30 s每项），采集关节角度、速度、扭矩、末端执行器位置与力等；并在MuJoCo中复制相同任务以生成仿真数据。未使用公开数据集，而是依赖实机与仿真同步采集。

**📈 对比分析**

比较方法：对实机与仿真在相同任务下计算RMSE（位置0.06 rad、速度0.05 rad/s、扭矩1.3 Nm、力1.7 N、控制误差0.6 Nm）并记录控制循环时间（<25 µs）、命令延迟≈0.5 ms、CPU占用≈0.2%和控制let切换≈2.1 ms。结果表明框架能在保持1 kHz频率的同时实现低延迟切换，并通过参数辨识将仿真误差减半。

**⚠️ 局限性**

局限性：① 当前仅支持Franka机器人的力矩模式，未覆盖速度或位置模式；② 仅在单机器人或双臂同型号下验证，仿真对不同机器人副本的误差仍较大；③ 对高动态或高度耦合任务的鲁棒性尚未充分验证；④ 需要人工完成惯量参数辨识，过程繁琐；⑤ 在极端安全或极限负载场景下的安全性和可靠性仍需进一步测试。

---

## 828. HopFormer: Sparse Graph Transformers with Explicit Receptive Field Control

**arXiv ID:** 2602.02268 | [PDF](https://arxiv.org/pdf/2602.02268v1)

**作者:** Sanggeon Yun `[一作]` (University of California), Mohsen Imani `[通讯]` (University of California)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `3f18e8e3-0266-457c-8567-9039b6d2394d` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出 HopFormer，一种通过头特定的 n‑hop 掩码稀疏注意力来注入图结构的 Transformer，保持标准 Transformer 结构，无需任何位置或结构编码；

**💡 创新点**

创新点在于：① 仅利用掩码控制的 n‑hop 稀疏注意力即可完全捕获图拓扑，省去显式编码与架构改造；② 通过多头不同 hop 设计实现多尺度感受野，理论上提升表达能力；③ 证明全局密集注意力在多数图任务中并非必要。

**🔧 技术方法**

技术实现包括：将边转化为节点形成增广 incidence 图；对节点与边使用轻量投影映射到共享空间；在多头自注意力中使用 n‑hop 可达性掩码实现真正稀疏计算；保持 Transformer 的残差、层归一化和前馈网络；结合理论证明表达力提升。

**📊 数据集**

实验数据集涵盖节点级：Cora、Citeseer、Pubmed、Chameleon、Squirrel、Actor、Texas、Cornell、Wisconsin；图级：OGBG‑MolHIV、OGBG‑MolPCBA、Peptides‑Func、Peptides‑Struct、ZINC。

**📈 对比分析**

与多种图 Transformer（Graphormer、SAN、GPS、SpecFormer、SGFormer 等）和 MPNN（GCN、GAT、APPNP）在相同搜索空间下对比。结果显示，HopFormer 在节点级任务中常位列前茅或相近；在图级任务中在某些数据集上取得最佳或竞争性表现；在小世界结构明显的节点级数据上表现更稳定，且在弱小世界图上全局注意力的优势逐渐消失。

**⚠️ 局限性**

局限性：对 hop 范围与小世界特征的最佳匹配仍以经验为主，缺乏自动或理论的选择机制；需要手动调参；未深入验证在更大规模或更复杂异构图上的鲁棒性。

---

## 829. SysFuSS: System-Level Firmware Fuzzing with Selective Symbolic Execution

**arXiv ID:** 2602.02243 | [PDF](https://arxiv.org/pdf/2602.02243v1)

**作者:** Dakshina Tharindu `[一作]` (University of Florida), Prabhat Mishra `[通讯]` (University of Florida)

**通讯引用:** 6185 | [OpenAlex ID](https://openalex.org/A5006818844)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e`

**🎯 论文内容**

提出了 SysFuSS，一个结合系统级仿真与选择性符号执行的固件安全验证框架。

**💡 创新点**

创新点是通过覆盖饱和检测自动切换到符号执行，利用中间状态启动符号执行，从而突破传统固件模糊器的覆盖平台。

**🔧 技术方法**

使用了 QEMU 全系统仿真、LibAFL 模糊器、Angr 符号执行、Z3 SMT 求解器以及影子内存监测。

**📊 数据集**

使用六个真实固件基准：OpenSSL、WolfBoot、WolfMQTT、HTSlib、MXML、libIEC。

**📈 对比分析**

与 AFL、AFLFast、EM‑Fuzz 对比，SysFuSS 在分支覆盖上平均提升 12–18%，漏洞检测率从 13 处提升到 118 处，检测时间平均缩短 1.75×，最快 3.33×。

**⚠️ 局限性**

局限性包括对硬件依赖的完整仿真仍需较高资源，符号执行仍受状态爆炸限制，且对未知硬件模型的支持有限。

---

## 830. Interpretability in Deep Time Series Models Demands Semantic Alignment

**arXiv ID:** 2602.02239 | [PDF](https://arxiv.org/pdf/2602.02239v1)

**作者:** Giovanni De Felice `[一作]` (University of Italian Switzerland), Silvia Santini `[通讯]` (University of Italian Switzerland)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `5a41884c-404f-4688-a89c-aa238c10fe68` `109c2b71-d051-425c-831f-0c544c24280d`

**🎯 论文内容**

本文研究深度时序模型的可解释性，提出语义对齐（Semantic Alignment, SA）的时间维度定义，并给出概念编码‑传播‑解码的蓝图，旨在让模型内部变量和机制与域专家的概念保持一致；

**💡 创新点**

创新点在于①把即时概念与动态概念区分开来，给出严格的对齐定义；②将概念基础模型（CBM）拓展到时序域，强调传播机制的时间一致性；③将机制对齐视作约束满足问题，并提出可通过正则化或模块组合实现的实现路径；

**🔧 技术方法**

技术上采用概念编码网络、时间/空间传播层、任务解码器，并在训练中加入任务、空间和时间对齐损失；机制对齐通过限制可接受的分布集合或构造具备已知性质的模块实现；

**📊 数据集**

论文主要是理论与蓝图，未给出实验数据；若要验证可使用工业监控或医疗时序数据（如设备温度序列、心电图等）进行评估；

**📈 对比分析**

实验对比方式可与传统深度时序模型（RNN、TCN、注意力网络）及现有CBM进行，目标是在保持或略低于原模型精度的前提下，提升可解释性与可操作性；

**⚠️ 局限性**

局限性包括：①需要大量概念标注，尤其是时间序列上的逐步监督；②机制对齐的实现可能限制模型表达力；③缺乏实证验证，理论到实践的转化仍需进一步研究；

---

## 831. Agent-Based Software Artifact Evaluation

**arXiv ID:** 2602.02235 | [PDF](https://arxiv.org/pdf/2602.02235v1)

**作者:** Zhaonan Wu `[一作]` (Huazhong University of Science and Technology), Haoyu Wang `[通讯]` (Huazhong University of Science and Technology)

**通讯引用:** 29108 | [OpenAlex ID](https://openalex.org/A5107888510)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了端到端的自动化软件工件评估框架 ArtifactCopilot，完成工件获取、环境构建、指令执行与错误恢复，并生成评估报告与徽章判断。

**💡 创新点**

创新点包括：①将工件评估视为状态感知工作流问题，构建 AE Graph 将 README 转化为有向依赖图；②使用层级代理架构将环境规划与执行分离；③实现容器化环境统一化与自动错误恢复，显著提升评估的可重复性和鲁棒性。

**🔧 技术方法**

技术方案包括：LLM（DeepSeek‑V3.2）驱动的多代理（ReAct）框架；AE Graph 结构化表示；Docker 容器化与主机统一执行；LLM+工具链（文件读取、Shell 执行、容器元数据获取）；状态感知的错误诊断与恢复逻辑。

**📊 数据集**

使用 48 份来自 ICSE、FSE、ASE、ISSTA 等顶级软件工程会议的真实工件，构建了包含 GCS（Golden Command Set）与标签的评估数据集。

**📈 对比分析**

与两种基线（LLM+Scripts 与 Claude Code）对比，ArtifactCopilot 的徽章一致率 (BCR) 为 85.42%，远高于 20.83% 与 33.33%；人类干预平均仅 0.11 次，成本约 $0.091/工件；Ablation 研究表明 AE Graph、环境归一化与层级结构各自为性能贡献巨大。

**⚠️ 局限性**

局限性包括：仍难以处理隐式依赖、数据完整性与配置不一致等问题；只支持公开、无特殊硬件、≤10 GB 的工件；LLM 的输出不确定性与上下文窗口限制对极长工作流仍是挑战。

---

## 832. Prediction-Powered Risk Monitoring of Deployed Models for Detecting Harmful Distribution Shifts

**arXiv ID:** 2602.02229 | [PDF](https://arxiv.org/pdf/2602.02229v1)

**作者:** Guangyi Zhang `[一作]` (Zhejiang University), Osvaldo Simeone `[通讯]` (Northeastern University London)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种半监督风险监测框架 PPRM，用于在部署机器学习模型时实时检测有害分布漂移；

**💡 创新点**

创新点在于将预测驱动推断（PPI）嵌入到风险监测中，利用少量标注样本和大量未标注样本生成无偏风险估计，并通过可调的超参数动态决定对未标注数据的依赖，从而在不破坏假设无关的误报率保证的前提下得到更紧的下界；

**🔧 技术方法**

核心技术包括：预测驱动推断（PPI）与其无偏估计、时间统一置信界（confidence sequence）构造、基于赌注的校准方法、滑动窗口自适应超参数选择；

**📊 数据集**

实验使用三类数据集：CIFAR‑10‑C（图像分类），多种LLM QA基准（MMLU、CMExam、CommonsenseQA、Social‑IQA、PubMedQA）以及电信通道均衡任务；

**📈 对比分析**

与基准方法（完全标注的 Ideal PPRM、仅监督的 SRM、仅无监督的 URM）比较，PPRM 在所有实验中均实现更早的报警（平均报警时间显著下降），尤其在采用更强预测模型或自适应超参数时表现更优；

**⚠️ 局限性**

局限性包括：需要至少少量标注数据；对预测模型质量敏感，若假设模型误差较大则估计方差上升；超参数调优仍需经验；在极端分布漂移或标注稀缺场景下效果尚待验证。

---

## 833. Position: Explaining Behavioral Shifts in Large Language Models Requires a Comparative Approach

**arXiv ID:** 2602.02304 | [PDF](https://arxiv.org/pdf/2602.02304v1)

**作者:** Martino Ciaperoni `[一作]` (Scuola Normale Superiore), Francesco Giannini `[通讯]` (University of Pisa)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `e15e3743-5ee0-4d5f-813d-d146868082fc`

**🎯 论文内容**

提出比较解释框架（Comparative XAI），用于识别、定位并解释大语言模型在干预（如微调、强化学习、提示调整）后出现的行为转变；

**💡 创新点**

创新点在于将解释目标从单一模型转向“行为转变”本身，定义了一套可衡量的行为指标、阈值和可比解释的设计准则，并给出从诊断到因果验证的完整流程；

**🔧 技术方法**

结合特征归因（Integrated Gradients）、表示相似性（CKA）、探针训练、激活补丁与激活驱动等多种技术实现对比解释，并在实验中通过这些方法追踪层级变化与行为差异；

**📊 数据集**

实验使用 0.5B 参数的 Qwen2.5 指令调优模型，随后在细粒度医学文本数据集上进行微调，评估在医学建议任务下的行为转变；

**📈 对比分析**

对比方法通过探针和激活操作在第三层前后层定位并验证行为转变，激活补丁可将误导性回答的语义相似度提升约 20%–30%，激活驱动能将模型输出直接迁移回更安全的回答，证明对比解释在定位与干预方面有效；

**⚠️ 局限性**

局限性包括：需要模型内部访问权限且计算开销大；仅在单一任务和模型规模下验证，缺乏跨模型、跨任务的通用性；对比解释依赖阈值设定与评估指标，缺乏统一标准；以及解释结果仍需人工验证以确定因果关系。

---

## 834. Decoupling Generalizability and Membership Privacy Risks in Neural Networks

**arXiv ID:** 2602.02296 | [PDF](https://arxiv.org/pdf/2602.02296v1)

**作者:** Xingli Fang `[一作]` (North Carolina State University), Jung-Eun Kim `[通讯]` (North Carolina State University)

**通讯引用:** 2615 | [OpenAlex ID](https://openalex.org/A5100462673)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `9cc9baba-5356-466d-81ff-d80028d90279` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

研究深度网络中隐私泄漏出现的层级，提出“隐私保护训练原则”(PPTP)，在保持模型泛化能力的同时，通过冻结安全层、回滚风险层并在风险层使用隐私防护方法实现更好的隐私-效能权衡。

**💡 创新点**

创新点在于将隐私风险与泛化能力解耦：发现隐私泄漏主要集中在后期层，PPTP通过部分冻结与重训练的方式仅对风险层进行隐私防护，避免全模型训练导致的泛化损失，且显著降低训练成本。

**🔧 技术方法**

技术手段包括：对特征图差异的量化分析、隐私风险层划分、参数回滚、冻结安全层、结合现有隐私防护技术（如对抗正则化、SELENA、RelaxLoss）进行局部重训练；使用SVM评估各阶段特征的泛化性能。

**📊 数据集**

使用 CIFAR-100 和 TinyImageNet 两个数据集进行实验，以验证方法在不同规模数据上的适用性。

**📈 对比分析**

与传统全模型隐私防护方法（DP‑SGD、对抗正则化、SELENA 等）对比，PPTP 在保持或提升测试精度的同时，显著降低了 AUC‑ROC、训练内存与时间消耗；在 CIFAR‑100 上提升了约 2% 的测试准确率，在 TinyImageNet 上提升了约 3% 并将训练成本降低约 50%。

**⚠️ 局限性**

局限性包括：需先手动或通过实验确定隐私风险层位置，方法对极大模型的可扩展性尚未完全验证；在某些基于正确性或置信度的 MIAs 上提升有限；且对攻击手段的覆盖仍主要集中在成员推断与模型逆向，其他攻击类型需进一步评估。

---

## 835. Statistical Learning Theory in Lean 4: Empirical Processes from Scratch

**arXiv ID:** 2602.02285 | [PDF](https://arxiv.org/pdf/2602.02285v1)

**作者:** Yuanhe Zhang `[一作]` (University of Warwick), Fanghui Liu `[通讯]` (Shanghai Jiao Tong University)

**通讯引用:** 1484 | [OpenAlex ID](https://openalex.org/A5016703530)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

**🎯 论文内容**

本论文首次全面地在Lean 4中形式化了统计学习理论（SLT），基于经验过程理论构建了完整的形式基础设施，涵盖了高斯Lipschitz集中、Dudley熵积分定理的形式化以及在最小二乘回归中的应用。

**💡 创新点**

创新点在于通过人机协作的工作流程，结合人类设计证明策略和AI执行证明构建，形成了一个可重用的SLT形式基础，解决了标准SLT教材中隐含的假设和细节缺失问题。

**🔧 技术方法**

使用了Lean 4作为交互式定理证明器，结合了高维高斯分析工具和Dudley熵积分工具。

**📊 数据集**

论文中没有具体提到使用的数据集，但提到的应用包括最小二乘回归和ℓ_1约束回归。

**📈 对比分析**

与现有方法的比较主要体现在对复杂模型的理论分析上，论文强调了通过形式化提高了理论分析的可验证性和可重用性，性能上实现了对复杂模型的更深入理解。

**⚠️ 局限性**

限制在于当前的形式化仍处于初期阶段，尽管涵盖了大量内容，但在Lean 4中的实现仍需进一步发展和完善。

---

## 836. MoLF: Mixture-of-Latent-Flow for Pan-Cancer Spatial Gene Expression Prediction from Histology

**arXiv ID:** 2602.02282 | [PDF](https://arxiv.org/pdf/2602.02282v1)

**作者:** Susu Hu `[一作]` (National Center for Tumor Diseases), Stefanie Speidel `[通讯]` (National Center for Tumor Diseases)

**通讯引用:** 6400 | [OpenAlex ID](https://openalex.org/A5003648994)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `40105733-5154-44cd-8090-a8cab9e64b07` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本研究提出 MoLF，利用条件流匹配和 Mixture-of-Experts 在潜在基因空间中，从 H&E 病理图像预测肿瘤的空间基因表达。

**💡 创新点**

创新点在于将混合流匹配与专家混合架构结合，使模型能在单一框架内捕捉跨癌种的共性与差异，从而在多组织异质性下实现高质量生成。

**🔧 技术方法**

采用 Transformer‑based VAE 构建基因潜在空间，条件流匹配（Flow Matching）实现从噪声到潜在的单步采样，Mixture‑of‑Experts 对速度场进行稀疏分解，并引入位置编码和 CFG 指导提升生成质量。

**📊 数据集**

主要使用 HEST‑1k pan‑cancer 基准（多中心、多平台的空间转录组与 H&E 图像）进行训练与评估，并在 Mouse melanoma HEST‑1k 进行零射种子跨物种测试。

**📈 对比分析**

与 STFlow、STEM、STPath、MLP 等基线在 Top‑50 HVG 与 Hallmark pathway 的 Pearson 相关性进行严格对比，MoLF 在所有分层基因集合上均取得最高分，并在零射种子任务中显著领先。

**⚠️ 局限性**

局限性包括：专家混合器对具体病理意义缺乏可解释性，模型对不同基因维度和噪声敏感，且仅采用单步 Euler 采样，可能限制生成的多样性。

---

## 837. OmniCode: A Benchmark for Evaluating Software Engineering Agents

**arXiv ID:** 2602.02262 | [PDF](https://arxiv.org/pdf/2602.02262v1)

**作者:** Atharv Sonwane `[一作]` (Cornell University), Saikat Dutta `[通讯]` (Cornell University)

**通讯引用:** 683 | [OpenAlex ID](https://openalex.org/A5063258857)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出了 OmniCode 基准，用于全面评估 LLM 编码代理在 Python、Java、C++ 三种语言上完成四类软件工程任务（缺陷修复、测试生成、代码评审响应、代码风格修复）的能力。

**💡 创新点**

创新点包括：① 将任务范围从单一代码/补丁生成扩展到多种工程活动；② 通过人工验证与合成方式消除数据泄漏，保证任务的严谨性；③ 采用基于真实仓库实例的合成技术，生成多样化的测试补丁和评审意见；④ 设计了包含错误补丁的评估机制，使测试生成更具鲁棒性。

**🔧 技术方法**

技术手段主要包括：使用 LLM 及其代理框架（SWE‑Agent、Aider）进行任务执行；构建容器化环境以支持代码编译与运行；利用语言特定的风格检查工具生成风格违规；采用多模态提示生成错误补丁和评审意见；定义一系列指标（如修复率、风格修复分数、错误比率）进行评估。

**📊 数据集**

数据集来源：从 GitHub 收集的 494 个 issue/PR 例子（涵盖 27 个仓库），融合 SWE‑Bench‑Verified、Multi‑SWE‑Bench 及手工筛选的实例；随后通过 LLM 合成产生错误补丁、评审文本和风格违规，形成完整的四类任务集。

**📈 对比分析**

评估方法：在多语言、多模型（Gemini‑2.5‑Flash、GPT‑5‑mini、DeepSeek‑V3.1、Qwen3‑32B 等）下运行 SWE‑Agent 与 Aider，分别测量 Bug‑Fix、Test‑Gen、Review‑Resp、Style‑Fix 四项指标。结果显示：Python 上 Bug‑Fix 表现较好；Test‑Gen 最高仅 25%（其余语言更低）；Style‑Fix 在 Python 上可达高分，而 Java/C++ 仍较弱；SWE‑Agent 通常优于 Aider，尤其在交互式和多阶段任务上。

**⚠️ 局限性**

局限性：仅覆盖三种主流语言且任务类型有限，未涉及配置文件、多语言混合、性能优化、深度安全修复等实际工程场景；评估仍依赖人工标注与合成补丁，未来需扩展到更多语言与任务，加入安全违规、代码迁移等更具挑战性的工程目标。

---

## 838. Alignment-Aware Model Adaptation via Feedback-Guided Optimization

**arXiv ID:** 2602.02258 | [PDF](https://arxiv.org/pdf/2602.02258v1)

**作者:** Gaurav Bhatt `[一作]` (University of British Columbia), Leonid Sigal `[通讯]` (University of British Columbia)

**通讯引用:** 10703 | [OpenAlex ID](https://openalex.org/A5053011888)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 AWARE 框架，在微调过程中将外部对齐反馈与任务目标结合，通过策略梯度正则化和自适应门控实现对齐与任务目标的动态平衡，并学习对完全误对齐输入的自适应拒绝；

**💡 创新点**

创新点在于①使用外部 LLM 评估器提供非梯度对齐信号；②设计自适应软门控按样本动态调节任务与对齐梯度；③学习对完全误对齐输入的拒绝（abstention）；④将对齐信号与任务损失融合为一体化的无监督正则化；

**🔧 技术方法**

采用策略梯度（REINFORCE）与长度归一化对齐优势、基于 LLM 的结构化奖励、软门控机制、对齐误差阈值判定以及离线评估器；

**📊 数据集**

使用 Alpaca、Bio‑Instruct、BeaverTails（违规样本）、SLAQ（长问答评估）、HEx‑PHI（安全评估）等公开基准数据集；

**📈 对比分析**

与 PEFT、PTST、Safe‑Inst、LISA、DPO‑C 等基线比较，AWARE 在保持或提升 BERTScore / JudgeScore 的同时，将 harmful score 降至约 33% 左右，hallucination 率显著下降，整体性能优于现有方法；

**⚠️ 局限性**

局限性包括依赖外部评估器的质量与可用性、计算成本较高、对齐信号噪声和阈值设定对结果敏感，以及在极端对齐任务或极端攻击场景下可能仍存在缺陷。

---

## 839. Stable Matching with Predictions: Robustness and Efficiency under Pruned Preferences

**arXiv ID:** 2602.02254 | [PDF](https://arxiv.org/pdf/2602.02254v1)

**作者:** Samuel McCauley `[一作]` (Williams), Shikha Singh `[通讯]` (Williams)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文研究在两侧匹配市场中，当一方只提交截断的偏好列表（基于预测的窗口或前缀）时，如何保证得到稳定匹配并提高算法效率。

**💡 创新点**

创新点在于：①证明在医院预测带误差边界的窗口截断下，居民提出的DA（WDA）始终产生稳定匹配；②在无误差信息时提出前缀截断（PDA）并给出错配医院的判定机制；③给出在预测误差可保证至少存在稳定匹配时，WDA/PDA 的提案次数与误差成线性关系的上界；④证明若不满足该预测保证，则即使预测几乎完美仍无法突破 $Ω(n^2)$ 的下界。

**🔧 技术方法**

主要技术包括：算法与预测（learning‑augmented algorithms）框架；对DA算法的形式化分析与改进；窗口截断与前缀截断的偏好列表构造；误差模型与稳定匹配的关系证明；构造匹配实例的下界证明（基于集合不交问题）。

**📊 数据集**

实验使用三类随机市场模型：Mallows 分布、基于在线约会平台的数据分布、以及分层市场（tiered）模型；在这些模型下生成 50 个实例，并使用真实匹配记录来估计预测窗口或前缀。

**📈 对比分析**

比较方法：与经典DA算法在同一实例上对比，记录提案次数和实例大小；WDA 的稳定性率与 PDA 的匹配率也被统计。结果显示：在预测窗口包含真实匹配时，WDA 与 PDA 的提案次数明显低于 DA（量级下降 10 倍以上），并且 WDA 的稳定性几乎为 100%。PDA 在不含稳定匹配时仍能通过扩展列表恢复完美匹配。

**⚠️ 局限性**

局限性：①算法效率提升依赖于预测窗口至少包含一条稳定匹配，否则无法保证子线性提案；②窗口截断需要知道误差上界，前缀截断需要多轮扩展，可能增加实施复杂度；③实验只覆盖了三种合成市场模型，未验证在真实医疗或校园匹配市场中的表现。

---

## 840. Evaluating Acoustic Data Transmission Schemes for Ad-Hoc Communication Between Nearby Smart Devices

**arXiv ID:** 2602.02249 | [PDF](https://arxiv.org/pdf/2602.02249v1)

**作者:** Florentin Putz `[一作]` (Technical University of Darmstadt), Matthias Hollick `[通讯]` (Technical University of Darmstadt)

**通讯引用:** 5245 | [OpenAlex ID](https://openalex.org/A5042405070)

**关键词:** `51726dea-4812-4aef-b722-f01e3ca750d2` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文通过收集、重实现并在真实智能手机上对八种声学数据传输方案进行系统评估。

**💡 创新点**

创新点在于首次公开实现并公开数据集，揭示多方案在实际环境中的可靠性差异并提出针对现实挑战的设计要求。

**🔧 技术方法**

采用声学调制方案（chirp、MFSK、OFDM+PSK等）与手机麦克风/扬声器进行一对多实验。

**📊 数据集**

使用约1.19万条实测WAV文件组成的公开数据集，涵盖不同距离、设备、噪声和环境设置。

**📈 对比分析**

采用综合误码率TER指标对比八种方案，结果显示Lee et al.与ggwave不可见版在远距离下最稳健，其余方案多在中远距离出现大幅误码。

**⚠️ 局限性**

局限包括对部分方案实现依赖手工重实现、实验环境仍受多路径与设备差异影响、未覆盖双向或低功耗设备。

---

## 841. Variational Entropic Optimal Transport

**arXiv ID:** 2602.02241 | [PDF](https://arxiv.org/pdf/2602.02241v1)

**作者:** Roman Dyachenko `[一作]` (Higher School of Economics), Alexander Korotin `[通讯]` (Applied AI Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种基于变分重写的弱对偶EOT方法（VarEOT），实现无MCMC的训练，并能在不受限的条件分布族上优化。

**💡 创新点**

创新点在于给log‑partition提供一个可解的变分上界，消除对采样的依赖，同时保持模型的表达能力。

**🔧 技术方法**

使用神经网络近似潜能与正则化因子，变分优化，Langevin采样以及统计学习理论的泛化分析。

**📊 数据集**

实验使用二维Gaussian→Swiss‑Roll数据以及FFHQ人脸/儿童/成人的ALAE潜在空间数据。

**📈 对比分析**

与LightSB、EgNOT等基线对比，VarEOT在FID/LPIPS指标上表现相当或更优，尤其在大ε或少采样步数时仍保持质量。

**⚠️ 局限性**

局限性包括推断阶段仍需Langevin采样，采样步数与步长敏感；数值稳定性和高维大规模训练的可扩展性尚待进一步验证。

---

## 842. Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL

**arXiv ID:** 2602.02236 | [PDF](https://arxiv.org/pdf/2602.02236v1)

**作者:** Julian Lemmel `[一作]` (Vienna University of Technology), Radu Grosu `[通讯]` (Vienna University of Technology)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `337e632d-5d88-4e08-b332-1e58d8df0f5e` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

在已有的行为克隆预训练策略基础上，使用可实时递归强化学习（RTRRL）实现在线微调，以应对环境分布漂移。

**💡 创新点**

创新点在于将RTRRL与生物启发的液体-阻抗-电容网络（LRC）相结合，形成一种完全前向、可在线、可生物合理的强化学习框架，并首次在高频事件相机闭环控制上实现。

**🔧 技术方法**

核心技术包括：行为克隆（Behavioral Cloning）预训练、RTRRL（结合TD(λ)、可行性激活和在线梯度计算如RTRL/RFLO）、LRC（LrcSSM）生物仿真递归网络、事件相机帧化处理。

**📊 数据集**

使用两套数据集：1）模拟CarRacing环境中收集的约3人次、每人3圈的RGB图像与离散动作序列；2）真实RoboRacer 1:10 规模车道追踪任务中由非专业司机提供的约500k帧事件图像与连续动作数据。

**📈 对比分析**

与仅使用预训练策略或传统离线重放RL相比，实验表明：在模拟环境中所有模型经RTRRL微调后奖励显著提升，LRC模型表现最佳；在真实车道追踪任务中，LRC和CT‑RNN模型在首次微调后即实现轨道跟踪，整体累计奖励提升约10–30%，标准差明显下降。

**⚠️ 局限性**

局限性包括：RTRL对大规模网络的计算和内存开销仍高；线性状态空间模型LRU在表达上不足，导致实时控制失败；事件相机帧化简化了时间信息，可能限制对快速动态的响应；实验仅在单一轨迹与小规模车身上验证，尚需在更复杂多变环境与更大规模车辆上进一步验证。

---

## 843. Advancing General-Purpose Reasoning Models with Modular Gradient Surgery

**arXiv ID:** 2602.02301 | [PDF](https://arxiv.org/pdf/2602.02301v1)

**作者:** Min Cai `[一作]` (Baidu Inc.), Daiting Shi `[通讯]` (Baidu Inc.)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文通过系统实验研究了在多域（数学推理、聊天、指令执行）上使用强化学习（RL）进行大型推理模型（LRM）后训练的困难，并提出了一种名为模块梯度手术（Modular Gradient Surgery, MGS）的方法，能够在Transformer各模块层级上解决跨域梯度冲突，从而提升模型在多域任务上的表现。

**💡 创新点**

创新点：①首次将梯度手术（如PCGrad）扩展到Transformer的模块层级，形成MGS，显著降低跨域梯度冲突的负面影响；②系统验证了RL在多域训练中存在的“模式干扰”（mode interference）——包括遗忘（forgetting）和刚性（rigidity）；③在多域RL训练中展示了MGS对梯度冲突的定位和修复能力，并在多种模型与任务组合上取得一致提升。

**🔧 技术方法**

技术：基于token‑level GRPO（DAPO）强化学习框架；采用梯度冲突检测与投影（PCGrad风格）在Transformer每层（注意力层、MLP层、FFN层等）内执行；对梯度模长进行排序，选择Top‑µ%模块进行梯度手术；对比实验使用Naïve Mixing、单域RL、全局梯度手术（GGS）等基线。

**📊 数据集**

数据集：数学推理—MATH500、AIME24、GSM8K；聊天—WildBench、AlpacaEvalv2、CreativeWriting；指令执行—IFBench、IFEval；通用能力评测—MMLU redux、PopQA、Zebra Logic；多域训练使用对应领域的标准RL训练数据（如RLVR规则奖励、ChatRM奖励模型、IFEval评分）。

**📈 对比分析**

对比方法：与单域RL、混合RL（RL）、模型合并（Model Merging）、优势归一化（Normalized Advantage）、全局梯度手术（GGS）等基线在Llama和Qwen两大Transformer族上进行。结果显示：MGS在三域平均分上相对Naïve Mixing提升约4.3–4.5分，超过单域RL、混合RL以及全局梯度手术；在延长训练步骤和加入第三任务（IF）时，MGS仍保持最优或接近最优性能，显示出良好的可扩展性。

**⚠️ 局限性**

局限性：①MGS的实现需要对Transformer结构做模块划分，依赖模型可分解性，对极度稀疏或非Transformer模型适用性有限；②在极端多任务（>3个）或极大规模数据时，梯度冲突检测与投影成本仍可能成为瓶颈；③虽然MGS显著降低梯度冲突，但对跨域知识迁移机制的深入解释仍缺乏，未来需进一步分析梯度与功能模块间的因果关系。

---

## 844. Before Autonomy Takes Control: Software Testing in Robotics

**arXiv ID:** 2602.02293 | [PDF](https://arxiv.org/pdf/2602.02293v1)

**作者:** Nils Chur `[一作]` (Ruhr University Bochum), Yannic Noller `[通讯]` (Ruhr University Bochum)

**通讯引用:** 508 | [OpenAlex ID](https://openalex.org/A5071232627)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `a68d3170-c4b6-45e7-b3b6-7e2d411d5656`

**🎯 论文内容**

本文通过系统的映射研究，对 247 篇机器人测试论文进行检索、筛选并与 ISO 29119 软件测试理论进行映射，生成了机器人测试实践的总体概况。

**💡 创新点**

创新点在于首次将机器人测试研究与成熟的软件测试标准体系对接，揭示了机器人测试在测试层次、技术和流程上的缺口与挑战，并为标准化实践提供了参考。

**🔧 技术方法**

研究采用了系统文献综述方法：在 Scopus 上检索 “Robot AND Test” 相关文献，使用两轮手工过滤、归并技术、Sankey 图可视化及 ISO 29119 体系映射工具。

**📊 数据集**

数据集包括 247 篇机器人测试论文，其中 198 篇被映射至测试知识体系，12 篇聚焦挑战，另外通过 Google Scholar 手工检索补充了 49 篇文献。

**📈 对比分析**

通过对测试层次、测试类型、测试环境、测试技术等维度的计数与可视化进行定量比较，展示了系统层面测试占主导、黑盒技术广泛、白盒技术稀缺等现象；未涉及具体性能度量，仅呈现文献分布与研究趋势。

**⚠️ 局限性**

局限性包括：检索词与数据库限制导致潜在遗漏、对测试流程和标准的映射依赖作者主观判断、白盒与自动化测试方法在文献中出现不足、以及对真实环境可重复性与可扩展性的讨论仍不充分。

---

## 845. Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?

**arXiv ID:** 2602.02290 | [PDF](https://arxiv.org/pdf/2602.02290v1)

**作者:** Alex Argese `[一作]` (EURECOM), Raphaël Troncy `[通讯]` (EURECOM)

**通讯引用:** 4968 | [OpenAlex ID](https://openalex.org/A5022574838)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文研究了如何评估生成的科学故事，并提出了名为StoryScore的综合评价指标；

**💡 创新点**

创新点在于将语义对齐、词汇锚定、结构忠实度、冗余避免和实体层幻觉检测融合成单一统一分数，且对幻觉检测方法进行了系统性分析；

**🔧 技术方法**

主要使用技术包括BERTScore、Context Recall、Prompt Cleanliness、Title Coverage、NoRedundancy以及基于SpaCy的NER实体检测等；

**📊 数据集**

使用的数据集为62篇科学论文与对应的190篇人工编写的解释性故事，按训练/验证/测试拆分；

**📈 对比分析**

实验对比显示，微调后的模型相较于预训练模型在StoryScore从0.560提升至0.787，Context Recall从0.390提升至0.472，Prompt Cleanliness从0.011提升至1.000等；

**⚠️ 局限性**

局限性包括幻觉检测方法不稳定、StoryScore难以完全捕捉叙事可控性与结构完整性，以及对人物适应度评价不足。

---

## 846. Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages

**arXiv ID:** 2602.02287 | [PDF](https://arxiv.org/pdf/2602.02287v1)

**作者:** Isaac Chung `[一作]` (Zendesk), Linda Freienthal `[通讯]` (Zendesk)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

设计并执行了在保持生成条件不变、仅改变目标语言的实验，利用合成客户支持对话评估多种大型语言模型（LLMs）在不同芬兰-乌戈尔语系语言下的评判稳定性，揭示了LLM-as-a-judge在多形态学语言中的性能不一致。

**💡 创新点**

创新点在于：①通过控制生成参数而非语料内容，首次将语言差异与评判不稳定性隔离，②提出基于排名相关性（Kendall τ）的诊断方法，用以在模型部署前检测跨语言评判失效，③提供公开的生成协议、数据与评估框架，促进跨语言评估可复现性。

**🔧 技术方法**

技术手段包括：自动评估指标（TTR、MATTR、self‑BLEU、语义相似度）、零射LLM-as-a-judge（使用多种大型模型如Llama‑3.3‑70B、Mixtral‑8x7B、Command‑R、Claude‑Sonnet‑4、GPT‑4.1‑mini）、Kendall τ排名相关性分析、提示语言敏感性与评判模型消融实验。

**📊 数据集**

数据集：10k条针对Estonian、Finnish、Hungarian和English的合成客户支持对话（通过统一模板与参数生成），以及100条由Estonian母语评标者标注的对话，用于人类参考与评判对齐检验。

**📈 对比分析**

比较方法：先用自动指标验证各语言对话在语义与表面特征上的一致性；随后用LLM-as-a-judge对每种语言的对话进行评分，得到模型在各语言下的排名；利用Kendall τ评估跨语言排名稳定性。结果显示：表面指标（语法、可读性、流畅度）的排名稳定性τ≥0.62；但语用指标（连贯性、指令遵循）在Finno‑Ugric语言间出现τ≈0、排名逆转，表明零射评判在形态丰富语言上的不可行性。

**⚠️ 局限性**

局限性：①仅使用合成对话，可能缺乏真实对话的语言多样性与复杂性；②人类标注样本仅限Estonian，未覆盖所有目标语言；③实验聚焦于客户支持场景，未验证其他对话领域或非商业模型；④未深入探讨礼貌、语气等其他语用特征，仅关注连贯性与指令遵循。

---

## 847. Choice-Model-Assisted Q-learning for Delayed-Feedback Revenue Management

**arXiv ID:** 2602.02283 | [PDF](https://arxiv.org/pdf/2602.02283v1)

**作者:** Owen Shen `[一作]` (Massachusetts Institute of Technology), Patrick Jaillet `[通讯]` (Massachusetts Institute of Technology)

**通讯引用:** 7797 | [OpenAlex ID](https://openalex.org/A5109246810)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a2602d71-93ab-4bad-974b-672788df8193` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

在延迟反馈的酒店收益管理中，提出使用离线校准的离散选择模型（DCM）辅助强化学习，通过即时补值延迟收益，改进 Q‑学习的收敛速度与鲁棒性。

**💡 创新点**

创新点在于：①将预训练的选择模型视为部分世界模型，实现目标标签即时补值；②在固定模型部署下给出 Q‑学习的收敛上界；③系统评估在参数平移与结构误差下的性能差异，揭示模型结构的利弊。

**🔧 技术方法**

使用技术包括：多项式Logit 选择模型、Q‑学习 / DQN、模型补值采样、两时间尺度随机逼近、理论收敛分析、仿真器构建与统计显著性检验。

**📊 数据集**

使用真实酒店预订数据集（61,619 条预订记录）校准选择模型，并以此数据生成仿真环境。

**📈 对比分析**

与传统等待成熟标签的 MB‑DQN 基线对比。静态环境下两者表现相同；在参数平移场景下，Choice‑Model‑Assisted DQN 在 5/10 场景提升最高 12.4%；在结构错配（IIA 失效、分段异质性、动态混合）场景下持续下降 1.4–2.6%。

**⚠️ 局限性**

局限性：①模型仅固定在离线校准状态，未探索在线自适应；②当选择模型结构失效时会产生系统性偏差；③理论分析基于表格 Q‑学习，实测采用 DQN，存在方法间差距；④主要针对酒店收益管理，通用性待验证。

---

## 848. dziribot: rag based intelligent conversational agent for algerian arabic dialect

**arXiv ID:** 2602.02270 | [PDF](https://arxiv.org/pdf/2602.02270v1)

**作者:** El Batoul Bechiri `[一作]` (CESI), Dihia Lanasri `[通讯]` (CESI)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 DziriBOT，一种结合检索增强生成（RAG）的混合式会话代理，专门为阿尔及利亚方言 Darja 的客服自动化设计。

**💡 创新点**

创新点在于将专门预训练的 DziriBERT 与 RAG 相结合，克服双写体、代码切换和低资源环境下的语义理解与知识检索难题。

**🔧 技术方法**

采用 Transformer‑based 模型（DziriBERT、AraBERT）、Rasa DIET、FAISS HNSW 向量检索、Llama‑3.2‑3B 生成、E5 多语言嵌入等多种 NLP 与检索技术。

**📊 数据集**

使用约 8,178 条阿拉伯字母与 7,259 条拉丁字母（Arabizi）用户发问数据，涵盖 69 个意图，经过人工增广与样本平衡。

**📈 对比分析**

通过准确率、加权 F1 与推理延迟对比，DziriBERT 在 Arabic‑script 87.4%/Latin‑script 92.0%，Rasa DIET 约 86.9%；但 CPU 推理耗时 2–3 s，RAG 生成耗时 85 s，GPU 可降至 3 s。

**⚠️ 局限性**

限制包括高推理延迟（尤其是生成阶段）、对 GPU 的依赖、意图爆炸导致的维护成本，以及缺乏多模态（语音）支持。

---

## 849. OpenSeal: Good, Fast, and Cheap Construction of an Open-Source Southeast Asian LLM via Parallel Data

**arXiv ID:** 2602.02266 | [PDF](https://arxiv.org/pdf/2602.02266v1)

**作者:** Tan Sang Nguyen `[一作]` (National University of Singapore), Hwee Tou Ng `[通讯]` (National University of Singapore)

**通讯引用:** 14467 | [OpenAlex ID](https://openalex.org/A5110081955)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对英文LLM OLMo 2进行持续预训练，使用仅平行数据扩展至东南亚语言

**💡 创新点**

证明在固定token预算下，仅使用平行数据即可比多语种数据取得更优翻译和跨语言性能，推出完全开源模型OpenSeal

**🔧 技术方法**

持续预训练（CPT）+ 语言对齐的平行语料 + 复发机制与logit lens分析

**📊 数据集**

NLLB、SEA-PILE-v2、SEA-ALIGN、MAP-CC等，约34.7B tokens

**📈 对比分析**

与传统多语种预训练、SeaLLM、SEA‑LION等模型对比，OpenSeal在翻译BLEU和XNLI/PAWS-X等任务上显著领先，提升10–20%范围

**⚠️ 局限性**

仅在1B/7B规模实验，未包含指令调优，安全与价值对齐未完善，且缺乏更大规模验证

---

## 850. Unsupervised Physics-Informed Operator Learning through Multi-Stage Curriculum Training

**arXiv ID:** 2602.02264 | [PDF](https://arxiv.org/pdf/2602.02264v1)

**作者:** Paolo Marcandelli `[一作]` (Politecnico di Milano), Stefano Mariani `[通讯]` (Politecnico di Milano)

**通讯引用:** 7816 | [OpenAlex ID](https://openalex.org/A5088630522)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `14d48e9d-0069-4ad9-996a-1d5968216998` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种多阶段、基于 Hermite 样条与 Fourier 层相结合的物理信息无监督 PDE 学习框架，即 Physics‑Informed Spline Fourier Neural Operator (PhIS‑FNO)。

**💡 创新点**

创新点包括：① 通过逐步调节边界与残差损失并在每阶段重置 Adam 优化器，实现类似同伦连续化的训练策略；② 将 Hermite 样条卷积与 Fourier 神经算子融合，既保留全局频域表达，又支持非周期边界的连续微分。

**🔧 技术方法**

使用技术包括：神经算子（FNO、PINO、UNet）、Hermite 样条卷积、Adam 优化器重置、课程学习（curriculum）策略、无监督物理信息损失、梯度平滑与自适应学习率。

**📊 数据集**

实验数据集为经典 PDE 基准：二维 Poisson、1D Burgers、二维 Navier–Stokes（Kolmogorov 流与圆柱尾流）等，涵盖不同网格分辨率与维度。

**📈 对比分析**

在与监督 FNO、PINO、UNet 以及单阶段 PINN 的对比实验中，多阶段+重置方案在无监督训练下可达到与监督模型相当的精度，残差误差降至 10⁻⁴ 级别，显著优于单阶段或无重置方法。

**⚠️ 局限性**

限制：对高维、极端湍流场景仍需进一步验证；训练过程仍需手动设定阶段与权重；对随机种子敏感度虽已降低，但在极端条件下仍可能出现收敛不稳定。

---

## 851. Learning While Staying Curious: Entropy-Preserving Supervised Fine-Tuning via Adaptive Self-Distillation for Large Reasoning Models

**arXiv ID:** 2602.02244 | [PDF](https://arxiv.org/pdf/2602.02244v1)

**作者:** Hao Wang `[一作]` (City University of Hong Kong), Dapeng Wu `[通讯]` (City University of Hong Kong)

**通讯引用:** 20532 | [OpenAlex ID](https://openalex.org/A5001469325)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `8d10c613-917e-4880-9716-17789f50e119` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出了一种在监督微调阶段保持熵的策略，称为CurioSFT，旨在提升大型推理模型在后续强化学习阶段的探索能力。

**💡 创新点**

创新点在于将自我蒸馏与熵引导的温度自适应相结合：先构造温度提升的高熵教师分布，再按每个 token 的不确定性动态调整温度，从而在保持知识的同时有选择地提升探索性。

**🔧 技术方法**

采用了自我蒸馏（Self‑Exploratory Distillation）和基于熵的温度搜索（Entropy‑Guided Temperature Selection）两种技术，并结合交叉熵损失与 K2‑loss 进行联合优化。

**📊 数据集**

使用 OpenR1‑Math‑46K 作为训练集，评估基于六大数学推理基准（AIME、AMC、Math‑500、Olympiad Bench、Minerva）以及三大 OOD 基准（ARC‑Challenge、GPQA‑Diamond、MMLU‑Pro）的数据集。

**📈 对比分析**

与传统的 Vanilla SFT、加权熵正则、KL 限制以及先进的 SFT 变体（GEM、DFT、PSFT）对比，CurioSFT 在 SFT 阶段的 ID/OD 分别提升约 2.5/2.9 分，在 RL 阶段提升约 5 分，且在多模型上保持一致性。

**⚠️ 局限性**

主要限制是训练成本略高（额外前向推断与温度搜索），且对基础模型的先验能力有依赖，若基模型缺乏足够的探索潜能，收益会减弱。

---

## 852. CHOMP: Multimodal Chewing Side Detection with Earphones

**arXiv ID:** 2602.02233 | [PDF](https://arxiv.org/pdf/2602.02233v1)

**作者:** Jonas Hummel `[一作]` (Karlsruhe Institute of Technology), Tobias Röddiger `[通讯]` (Karlsruhe Institute of Technology)

**通讯引用:** 331 | [OpenAlex ID](https://openalex.org/A5069745172)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

研究开发了 CHOMP 系统，利用耳机多模态传感器实时检测咀嚼侧偏，支持日常生活中的连续监测。

**💡 创新点**

创新点包括：①首次在普通真无线耳机中实现咀嚼侧检测；②将连续小波变换（CWT）生成的多通道标量图作为 CNN 输入；③通过特征级融合实现麦克风、骨传导麦克风和 IMU 的互补优势；④在多种噪声环境下验证鲁棒性。

**🔧 技术方法**

技术手段：连续小波变换、卷积神经网络（EfficientNet 变体）、多通道特征级融合、留一食品/留一受试者交叉验证、早停与正则化。

**📊 数据集**

数据集：20 名受试者（共 15,806 条样本），涵盖 11 种食物、5 种非咀嚼活动、3 种噪声条件，采集自 OpenEarable 2.0 的麦克风、骨传导麦克风、IMU、PPG、压力传感器等。

**📈 对比分析**

与传统随机森林基线对比，单麦克风在 LOFO/LOSO 的 F1 分别为 94.5%/92.6%，融合三模态后达到 97.7%/95.4%；在三种噪声下误差仅 1‑2%，表明系统鲁棒且性能远超以往耳机/可穿戴方案。

**⚠️ 局限性**

局限性：仅在坐姿、无双侧咀嚼、牙齿完整且年龄有限的受试者上测试；未考虑老年人或缺牙人群；模型对耳机贴合度敏感；实验规模有限，需更大样本验证。

---

## 853. Spectral Superposition: A Theory of Feature Geometry

**arXiv ID:** 2602.02224 | [PDF](https://arxiv.org/pdf/2602.02224v1)

**作者:** Georgi Ivanov `[一作]` (Theopha), Amir Abdullah `[通讯]` (Thoughtworks)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `7bbdcbec-2caa-4c7a-b120-9489f11b7043`

**🎯 论文内容**

本文提出了基于谱理论的特征几何分析框架，利用权重矩阵诱导的帧算子（frame operator）和格拉姆矩阵（Gram matrix）来捕捉神经网络中特征的全局几何结构，并在超叠加（superposition）情境下阐释了特征如何在特征空间中聚焦到单一特征子空间。

**💡 创新点**

创新点在于：①将特征几何从对偶向量层提升到算子层，使用帧算子实现基底不变的谱分析；②提出“谱桥”（spectral bridge）和“谱测度”（spectral measure）两种工具，将特征与其在谱上的分布关联，揭示特征稀疏度与有效维度的关系；③在玩具模型中证明了“谱局部化”与“紧帧（tight frame）”的等价性，并通过关联方案（association scheme）实现几何形状的离散分类。

**🔧 技术方法**

核心技术包括：谱分解、帧算子与格拉姆矩阵的对应关系、关联方案与伯恩斯-梅斯纳代数、特征分布的概率测度（spectral measure）、梯度流中的谱质量转移与特征演化分析。

**📊 数据集**

实验数据主要为 3200 组玩具模型（synthetic）——输入维度 1024，隐藏维度 16–512，稀疏度 0–0.99，均匀重要性。未使用真实数据集；所有实验均在人工构造的稀疏线性自编码器上完成。

**📈 对比分析**

方法与现有特征分解技术（如稀疏自编码器、独立成分分析等）做对比，重点展示了在谱局部化条件下特征能在单一特征子空间内聚合、形成紧帧，从而实现更为紧凑且可解释的几何结构。论文未给出传统准确率或解释度的数值指标，而是通过谱分布、线性相关性（R²）和特征稀疏度等定量指标展示了谱局部化与特征几何的一致性。

**⚠️ 局限性**

限制主要包括：①需要模型达到容量饱和（capacity saturation）才能实现谱局部化，实测仅在玩具模型中验证；②谱局部化的前提假设在真实大规模网络中尚未直接观测；③框架侧重于算子层面，可能忽略单个特征向量的细粒度语义；④在多模态或非线性激活的实际网络中，需要进一步扩展和验证。

---

## 854. When more precision is worse: Do people recognize inadequate scene representations in concept-based explainable AI?

**arXiv ID:** 2602.02298 | [PDF](https://arxiv.org/pdf/2602.02298v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e`

---

## 855. Geometry- and Relation-Aware Diffusion for EEG Super-Resolution

**arXiv ID:** 2602.02238 | [PDF](https://arxiv.org/pdf/2602.02238v1)

**作者:** Laura Yao `[一作]` (University of North Carolina), Tianlong Chen `[通讯]` (University of North Carolina)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `e1a5312d-25ae-4d44-8d74-dde5f79b5ab4` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `3f18e8e3-0266-457c-8567-9039b6d2394d` `ba576bd1-e51d-44e8-8077-fc943b333c93` `e15e3743-5ee0-4d5f-813d-d146868082fc` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

设计并实现了一种几何与关系感知的扩散模型TopoDiff，用于从稀疏电极配置重建高密度EEG信号；

**💡 创新点**

通过将EEG拓扑图（topoplot）图像嵌入提供全局几何上下文，并构造随时间变化的电极关系图来编码交互关系，随后将这两种结构化条件注入扩散Transformer，实现更具空间连贯性的EEG重建；

**🔧 技术方法**

使用条件扩散模型（x‑prediction）结合Transformer（Token‑wise与Temporal‑wise自注意力）、图神经网络（GCN）进行关系编码，以及DINOv3预训练图像特征提取来获得拓扑嵌入；

**📊 数据集**

在SEED、SEED‑IV（情绪识别）、PhysioNet MI/MM（运动想象）和TUSZ（癫痫检测）四个EEG基准上进行评估；

**📈 对比分析**

与STAD、RDPI、ESTformer等基线相比，TopoDiff在2×、4×、8×超分辨率下的NMSE、SNR、PCC等信号质量指标均更优，并在情绪识别、运动想象和癫痫检测等下游任务上获得更高的准确率/AUROC，尤其在更高SR难度时提升显著；

**⚠️ 局限性**

局限性包括：拓扑图嵌入缺乏个体化解剖细节，图关系仍主要基于相似度，未充分利用频域或多尺度连接；缺乏对噪声、缺失通道和蒙太奇变化的鲁棒性评估；未考虑主动感知、实时部署等实际应用需求。

---

## 856. Show, Don't Tell: Morphing Latent Reasoning into Image Generation

**arXiv ID:** 2602.02227 | [PDF](https://arxiv.org/pdf/2602.02227v1)

**作者:** Harold Haodong Chen `[一作]` (Hong Kong University of Science and Technology), Ying-Cong Chen `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 2588 | [OpenAlex ID](https://openalex.org/A5101938761)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在现有自回归文本‑图像生成模型基础上，提出了一套完整的隐式潜在推理框架，融合了短期与长期视觉记忆凝聚器、潜在翻译器、控制注入器以及基于强化学习的推理触发器，实现了在生成过程中实时、连续的隐式推理与自我修正。

**💡 创新点**

核心创新点包括：① 将推理过程迁移至连续潜在空间，避免了显式 CoT 的信息压缩与多余解码；② 通过视觉记忆凝聚实现对生成历史的高效压缩；③ 采用潜在翻译与控制注入方式，将推理结果无缝注入生成器的 KV 缓存；④ 通过 RL 学习的推理触发策略，动态决定何时进行推理，显著提升了生成效率与人类认知的一致性。

**🔧 技术方法**

所用技术主要有：① Transformer‑based自回归 T2I 模型（Janus‑Pro）；② 视觉记忆凝聚器（短期 & 长期）采用跨注意力压缩隐藏状态；③ 潜在翻译器与控制注入器（轻量级 MLP + 位置控制）；④ 基于 GRPO 的强化学习推理触发器；⑤ 评估工具如 CLIP、HPS‑v2.1 等。

**📊 数据集**

训练与评估数据集包括：① 2 万条 MidJourney 文图对（SFT 训练）；② T2I‑CompBench、T2I‑CompBench++、GenEval、WISE、IPV‑Txt 等公开基准，用于对比实验和多维度性能评估。

**📈 对比分析**

与十种基线（包括 Vanilla、SFT、Self‑CoT、TwiG‑ZS/RL、MILR、T2I‑R1、TIR 等）比较，表现如下：① 在 GenEval 上提升 16%；② 在 T2I‑CompBench 上提升 25%；③ 在 WISE/IPV‑Txt 的抽象推理任务中分别比 TwiG‑RL 提升 15% 与 11%；④ 推理触发后推理时延降低 44%，推理 token 消耗降低 51%；⑤ 在人类对推理时机的认知一致性评测中达 71%。

**⚠️ 局限性**

限制与风险：① 仍受底层模型（Janus‑Pro）安全性与偏差的影响；② 对极端复杂的多模态推理场景或极大图像尺寸的适应性尚待验证；③ 由于依赖 RL 训练，推理触发策略对奖励设计高度敏感；④ 潜在的误用风险（如生成误导性图像），需结合安全过滤与水印等措施。

---

## 857. Interpreting and Controlling LLM Reasoning through Integrated Policy Gradient

**arXiv ID:** 2602.02313 | [PDF](https://arxiv.org/pdf/2602.02313v1)

**作者:** Changming Li `[一作]` (ShanghaiTech University), Kan Ren `[通讯]` (Independent Researcher)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种训练无关的集成策略梯度框架（IPG），通过在表示空间中利用策略梯度并进行路径积分，对LLM内部组件（神经元或SAE特征）进行因果归因，从而实现对推理行为的解释与控制。

**💡 创新点**

1）在表示空间中推广策略梯度，能够将稀疏且非可微的推理结果反向传播到内部组件；2）采用路径积分（integrated policy gradient）消除梯度噪声并完整捕获组件的全程影响；3）提供可直接操控的因果干预机制（缩放因子），可精细调节推理能力与推理强度。

**🔧 技术方法**

策略梯度（policy gradient）+路径积分（path integral），稀疏自编码器（SAE）实现特征解耦，基于内在组件的乘法缩放干预，以及对结果进行基于外部验证器的奖励信号。

**📊 数据集**

推理任务数据集包括GSM8K、MATH500、AIME2024和GPQA‑Diamond；实验模型为Qwen2.5‑Math‑1.5B‑Instruct、Llama3.1‑8B‑Instruct以及DeepSeek‑Qwen‑1.5B。

**📈 对比分析**

与随机、激活排序、Reasoning Neuron、Control Vector、SAE‑R等基线比较；IPG在增强与抑制推理准确率方面均取得最佳或次优结果，且对推理强度控制更为平稳；跨数据集与模型的迁移实验也显示出较强的泛化性。

**⚠️ 局限性**

需要外部验证器提供不可微的推理结果；对非逐步、无明显奖励信号的任务适用性有限；方法对计算资源有一定依赖，且在极大模型上可能面临梯度估计与干预规模的挑战。

---

## 858. An Optimization Method for Autoregressive Time Series Forecasting

**arXiv ID:** 2602.02288 | [PDF](https://arxiv.org/pdf/2602.02288v1)

**作者:** Zheng Li `[一作]` (New York Institute of Technology), Huanying Gu `[通讯]` (New York Institute of Technology)

**通讯引用:** 620 | [OpenAlex ID](https://openalex.org/A5105836405)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

本文提出了一种新的训练方法，通过在时间序列预测中加入对自回归（AR）误差随时间递增的约束，使模型在任意长度预测时保持良好性能。

**💡 创新点**

创新点在于将时间因果性约束与强化学习式奖励函数结合，形成新的损失函数，既可提升短期预测，又能让短期模型通过AR扩展至长期预测。

**🔧 技术方法**

采用Transformer（iTransformer及其变体）的编码器-投影器架构，并在训练时加入基于误差递增的RL式奖励和折扣因子，使用stop‑gradient防止梯度泄漏。

**📊 数据集**

在六大公共基准上验证：Electricity、Traffic、Weather、Solar‑Energy、PEMS、Exchange 等多域多变量时间序列数据。

**📈 对比分析**

与传统直接训练的长周期模型相比，该方法在大多数数据集和预测长度下平均降低10%以上的MSE，并能使短期模型通过AR扩展至长周期超过7.5倍的长度，超越专门的长周期模型。

**⚠️ 局限性**

局限性包括缺乏对误差累积理论分析、对RL式奖励的调优依赖经验、以及在极端长期预测时仍会出现累计误差，未来需要更精细的损失设计与理论支持。

---

## 859. DFKI-Speech System for WildSpoof Challenge: A robust framework for SASV In-the-Wild

**arXiv ID:** 2602.02286 | [PDF](https://arxiv.org/pdf/2602.02286v1)

**作者:** Arnab Das `[一作]` (German Research Center for Artificial Intelligence), Sebastian Moeller `[通讯]` (German Research Center for Artificial Intelligence)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `9ce7179e-700c-4310-ac2b-91df50ded46e` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

提出了一个鲁棒的SASV框架，将自监督语音嵌入+图神经网络的spoof检测器与多尺度ReDimNet说话人验证器结合，完成WildSpoof挑战；

**💡 创新点**

创新点包括使用稀疏top‑3 MoE对wav2vec 2.0 XLS‑R的不同层特征进行动态融合、将2D/1D多尺度特征通过残差连接混合、在说话人验证中联合SphereFace与Contrastive Circle loss、采用AS‑Norm与imposter cohort进行归一化以及模型集成提升性能；

**🔧 技术方法**

使用的技术包括wav2vec 2.0 XLS‑R前端、图神经网络AASIST后端、稀疏top‑3 MoE融合、ReDimNet网络（Transformer + ConvNeXt）、SphereFace与Circle loss、AS‑Norm归一化、数据增强、模型集成；

**📊 数据集**

使用的数据集为SpoofCeleb（基于VoxCeleb1、包含多种TTS生成的spoof样本）以及WildSpoof挑战的测试集；

**📈 对比分析**

与基线系统（Conventional ASV、SASV‑OOD、SASV‑SpoofCeleb）对比，a‑DCF从0.2902降至0.032，SV‑EER从12.78%降至2.45%，在WildSpoof测试集宏观a‑DCF仅为0.2022，显著优于基线；

**⚠️ 局限性**

局限性在于系统依赖多项预训练模型与细调，模型结构复杂，推理时需要集成多模型，且对极端噪声或低质量录音的鲁棒性尚未充分评估。

---

## 860. Learning Markov Decision Processes under Fully Bandit Feedback

**arXiv ID:** 2602.02260 | [PDF](https://arxiv.org/pdf/2602.02260v1)

**作者:**  `[一作]` `[通讯]`, 

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9`

---

## 861. Backpropagation as Physical Relaxation: Exact Gradients in Finite Time

**arXiv ID:** 2602.02281 | [PDF](https://arxiv.org/pdf/2602.02281v1)

**作者:** Antonino Emanuele Scurria `[一作]` `[通讯]` (Universite Libre de Bruxelles), Antonino Emanuele Scurria (Universite Libre de Bruxelles)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `a8e75ba4-7a2d-4153-b003-06c94533add0` `90291a0e-9d36-4a08-9a16-89ce846d923f` `14d48e9d-0069-4ad9-996a-1d5968216998`

**🎯 论文内容**

本文提出一种名为Dyadic Backpropagation（DBP）的框架，将标准反向传播视为连续时间物理松弛过程的有限时间离散轨迹，并通过引入双重状态空间和拉格朗日非保守理论实现。

**💡 创新点**

创新点在于证明了在非对称权重、无对称性约束、无无穷逼近的前提下，反向传播梯度可以在有限时间内通过单一能量函数的鞍点动力学精确恢复，且单步欧拉离散能完美等价于传统反向传播。

**🔧 技术方法**

技术手段包括：1）将前向推理写成连续时间向量场并用非保守拉格朗日理论构造能量；2）在双重状态（前向和后向）上引入鞍点动力学；3）使用单位欧拉步进行离散化，得到2L步完全收敛；4）在实验中实现PyTorch版的离散化迭代算法。

**📊 数据集**

实验数据集为CIFAR‑10，采用9层VGG‑style卷积网络（约5M参数）进行训练。

**📈 对比分析**

与标准BP对比，DBP在相同训练设置下实现了≈93%的测试准确率，梯度相似度达到机器精度（log‑misalignment ≈10⁻⁷），并且在η→1时收敛步数趋近理论最小值2L，表明性能与传统方法持平且数值误差极小。

**⚠️ 局限性**

局限性包括：仅针对前馈可微网络证明，需在双重状态空间实现（可能导致硬件实现复杂度提高）；对非可微或非常大规模模型的适用性尚待验证；实际硬件中噪声、离散化误差可能影响理论的完美收敛。

---

## 862. Neural Geometry for PDEs: Regularity, Stability, and Convergence Guarantees

**arXiv ID:** 2602.02271 | [PDF](https://arxiv.org/pdf/2602.02271v1)

**作者:** Samundra Karki `[一作]` (Iowa State University), Baskar Ganapathysubramanian `[通讯]` (Iowa State University)

**通讯引用:** 10339 | [OpenAlex ID](https://openalex.org/A5011704511)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `25d64835-ec5b-425b-899d-a6e1e6fecabd`

**🎯 论文内容**

本文建立了隐式神经表示（INR）训练误差与椭圆型PDE求解误差之间的统一误差框架，给出了INR所需的最小几何正则性条件，并推导出几何误差对PDE解误差的上界；

**💡 创新点**

创新点在于将INR的几何逼近误差与有限元离散误差耦合，证明了为保持线性有限元的收敛率，INR训练误差必须按网格大小的平方缩放；

**🔧 技术方法**

主要技术包括隐式神经场、C¹,¹正则性分析、Hausdorff距离估计、有限元方法、Shifted Boundary Method（SBM）以及差分商与Besov空间的稳定性理论；

**📊 数据集**

实验使用二维圆的签名距离函数（SDF）作为基准，训练不同步长的SIREN INR，不涉及公开数据集；

**📈 对比分析**

通过对几何误差（Hausdorff距离）和解误差（L²范数）的对比验证理论，结果显示误差随几何误差线性增长、随网格细化按预期阶次下降，且在几何误差支配时误差不再随网格进一步减小；

**⚠️ 局限性**

限制包括仅针对线性椭圆方程和C¹,¹级别的INR；对高阶有限元、非线性或时间相关问题的适用性尚未探讨；对复杂工业几何的实战验证仍待后续工作。

---

## 863. Unlocking the Duality between Flow and Field Matching

**arXiv ID:** 2602.02261 | [PDF](https://arxiv.org/pdf/2602.02261v1)

**作者:** Daniil Shlenskii `[一作]` (Applied AI Institute), Alexander Korotin `[通讯]` (Applied AI Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `40105733-5154-44cd-8090-a8cab9e64b07` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文研究了条件流匹配（Conditional Flow Matching, CFM）与前向唯一交互场匹配（forward‑only Interaction Field Matching, IFM）之间的关系，证明二者在生成动力学上是等价的，并给出了显式的双射映射；进一步指出一般的IFM模型比CFM更具表达能力，并利用这一对偶关系为CFM提供新的概率解释和训练方法。

**💡 创新点**

1) 建立了CFM与forward‑only IFM的严格对偶性，给出了从流到场、从场到流的构造公式；2) 将IFM视为条件流的概率解释，为IFM提供了新的训练目标；3) 提出了基于场的多样本速度估计和体积覆盖分布的思路，提升了CFM的训练效果。

**🔧 技术方法**

利用概率流方程、连续性方程、场与流的几何映射理论进行数学证明；在实验中采用均值流、EDM、PFGM++等生成模型，并引入多样本速度估计与Gini系数分析来评估权重分布。

**📊 数据集**

在实验中以CIFAR‑10无条件生成任务为主，使用了两侧线性插值、EDM（即线性插值变体）和PFGM++等模型；实验中还使用了不同的辅助维度（128、2048）来进一步验证。

**📈 对比分析**

通过在CFM训练目标中使用多样本速度估计（多样本权重加权平均）与原单样本目标进行对比，结果表明：对于一侧（one‑sided）插值（EDM、PFGM++），多样本目标在FID上略有提升；而对于两侧（two‑sided）线性插值，改进几乎没有；实验也显示权重分布的Gini系数随样本数增大而增大，表明多样本估计的有效性受限。

**⚠️ 局限性**

1) 多样本速度估计的权重高度集中，导致在两侧插值中的提升有限；2) 体积覆盖分布的最佳选择尚未确定，需进一步研究；3) 实验仅覆盖CIFAR‑10与几种插值方式，泛化性尚待验证；4) 对于更复杂的高维数据和更大模型规模的效果尚未评估。

---

## 864. Multi-Agent Monte Carlo Tree Search for Makespan-Efficient Object Rearrangement in Cluttered Spaces

**arXiv ID:** 2602.02411 | [PDF](https://arxiv.org/pdf/2602.02411v1)

**作者:** Hanwen Ren `[一作]` (Purdue University), Ahmed H. Qureshi `[通讯]` (Purdue University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d0f189e1-0834-4ff4-b4e8-f515263ef669`

**🎯 论文内容**

本文提出一种基于集中式、异步多代理蒙特卡罗树搜索（CAM‑MCTS）的物体重新排列规划方法，能同时处理单调和非单调任务。

**💡 创新点**

创新点在于：① 结合集中式任务分配与异步执行策略，显著减少代理空闲时间；② 在MCTS中加入一步前瞻成本估计，实现更优的节点选择；③ 通过“缓冲区”采样降低多重移动需求。

**🔧 技术方法**

使用技术包括：集中式任务分配、异步任务执行、蒙特卡罗树搜索（MCTS）与改进的Upper Confidence Bound、ICBS路径生成、一步前瞻成本估计与缓冲区采样。

**📊 数据集**

数据集主要为四种仿真环境（窄通道、仓库、随机障碍、迷宫）生成的480个测试实例，包含2–4个机器人、4–10个物体，起止位置随机、排序或洗牌；此外还在真实两台TurtleBot3机器人上进行5个非单调任务实验。

**📈 对比分析**

与随机同步规划器（RSP）和集中式异步均匀成本搜索（CAM‑UCS）比较，CAM‑MCTS在成功率、总行驶距离和完成时间（makespan）方面均优于基线；在复杂任务中，成功率接近100%，完成时间最低，规划时间仅次于RSP。

**⚠️ 局限性**

主要局限在于：① 对极大规模物体/代理的可扩展性尚有限；② MCTS仿真仍耗时，需要进一步加速；③ 缓冲区采样方式在极端拥挤场景下可能不够鲁棒；④ 仅在二维平面桌面/地面环境验证，尚未针对三维堆叠等更复杂情况。

---

## 865. An Empirical Study on Noisy Data and LLM Pretraining Loss Divergence

**arXiv ID:** 2602.02400 | [PDF](https://arxiv.org/pdf/2602.02400v1)

**作者:** Qizhen Zhang `[一作]` (University of Oxford), Mike Lewis `[通讯]` (FAIR at Meta)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

系统评估了在大型语言模型预训练中注入均匀随机噪声对训练稳定性的影响，研究了噪声比例、噪声词表大小、插入/覆盖方式以及模型深度/宽度的变化对损失发散率的作用。

**💡 创新点**

发现噪声能导致预训练损失发散，并证明不同噪声类型、词表大小及插入方式会显著影响发散概率；同时揭示噪声导致的发散与高学习率导致的发散在注意力logit和参数范数上表现不同，可通过这些激活指标区分两种失败模式；最后证明稠密模型与主动参数匹配的Mixture-of-Experts模型对噪声的敏感性相似。

**🔧 技术方法**

使用Transformer（Llama‑3风格）自回归模型，AdamW优化器、MAXUP参数化、梯度裁剪、正弦余弦学习率衰减、QK‑layernorm等技术；对噪声数据采用插入/覆盖策略并在20个随机种子上重复实验；对激活进行最大注意力logit、参数RMS等统计。

**📊 数据集**

以干净的Llama‑4预训练数据混合为基准，在其上合成均匀随机噪声（噪声词表大小从5到完整词表、噪声比例30%–70%）。

**📈 对比分析**

通过在同一模型架构、相同超参、20个随机种子上重复训练来估计发散概率；对不同噪声设置和学习率设置进行对比，观察发散率、最大注意力logit阈值、参数范数差异；结果表明噪声发散率随噪声比例和模型深度增加而上升，且深度对发散影响更大；QK‑layernorm能在噪声高度（70%）下完全消除发散。

**⚠️ 局限性**

仅考虑了均匀随机噪声的合成情形，未检验真实网络噪声的效果；实验训练步骤限制在2e4步，未覆盖完整预训练过程；只测试了少数Transformer变体，未探讨其他稀疏或混合架构；因此结论可能不完全适用于更大规模或不同数据来源的真实预训练任务。

---

## 866. Talking Inspiration: A Discourse Analysis of Data Visualization Podcasts

**arXiv ID:** 2602.02397 | [PDF](https://arxiv.org/pdf/2602.02397v1)

**作者:** Ali Baigelenov `[一作]` (Purdue University), Paul Parsons `[通讯]` (Purdue University)

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对5个主流数据可视化播客的31集进行话语分析，探讨业内人士如何在公开对话中构建和讨论灵感。

**💡 创新点**

提出灵感评估的可调标准（新颖性、权威性、真实性、情感）和可操作隐喻（火花、肌肉、资源库），并将灵感视为边界对象，阐释其在身份、合法性与实践中的多重功能。

**🔧 技术方法**

采用Gee的话语分析框架，结合三轮开放式编码与主题归纳，系统识别话语模式与子模式。

**📊 数据集**

使用从5个播客（Data Viz Today、Explore Explain、The Data Journalism Podcast、Data Stories、The PolicyViz Podcast）收集的493个转录文本，涵盖37位可视化从业者的访谈内容。

**📈 对比分析**

本研究未涉及算法或模型的比较与性能评估，而是通过定性话语分析揭示模式与机制；若需量化评估，可在后续研究中结合文本分析工具或实验设计。

**⚠️ 局限性**

局限性包括：使用二手播客数据受主持人提问与结构限制；话题范围受访谈主题影响；未能与现场访谈交叉验证；样本聚焦高知名度从业者，可能忽视边缘或学术界视角。

---

## 867. Mapping-Guided Task Discovery and Allocation for Robotic Inspection of Underwater Structures

**arXiv ID:** 2602.02389 | [PDF](https://arxiv.org/pdf/2602.02389v1)

**作者:** Marina Ruediger `[一作]` (University of Washington), Ashis G. Banerjee `[通讯]` (University of Washington)

**通讯引用:** 1801 | [OpenAlex ID](https://openalex.org/A5001953637)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `51c0528b-f690-4182-ae60-bb5f046c276c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

开发了一种基于SLAM生成的海底多机器人巡检任务发现与分配方法（Map‑TIDAL）。

**💡 创新点**

通过从SLAM网格中自动生成候选检查点，并利用关键点评分和空间剪枝实现自适应任务发现，无需先验几何模型。

**🔧 技术方法**

Kimera‑Multi 传感器融合、去中心化拍卖式任务分配、基于关键点评分的任务筛选、光束视场分析等技术。

**📊 数据集**

在盐水实验水箱和淡水池中收集的 BlueROV2 视觉 + IMU + DVL 数据，生成的 SLAM 网格。

**📈 对比分析**

与 Voronoi 分区和 Boustrophedon 扫荡模式进行覆盖率与视角分布对比，Map‑TIDAL 在 20 个任务下实现 3.81% 未覆盖率、平均 2.56 视角，优于两种传统方法。

**⚠️ 局限性**

依赖 SLAM 网格质量，水质模糊时需要额外定位传感器，生成的任务可能位于机器人无法到达的区域，缺乏碰撞避免和多模态融合。

---

## 868. Transformers learn factored representations

**arXiv ID:** 2602.02385 | [PDF](https://arxiv.org/pdf/2602.02385v1)

**作者:** Adam Shai `[一作]` (Astera Institute), Paul M. Riechers `[通讯]` (Astera Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `67630363-6be0-4f51-ab05-7198250671a5` `57a58b01-81b4-4d75-a45c-2e891f272b50` `edb9d762-f411-4838-a852-f2d638b018db` `5e20d1ff-779f-4b7a-be75-8663ee04d94e` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

通过构造可解析的合成数据，理论推导并实验证明 Transformer 在 next‑token 预训练过程中自发地将世界拆分为若干部分，并在残差流中以正交子空间的形式编码每个部分的预测向量。

**💡 创新点**

首次将条件独立的生成过程与 Transformer 表征几何学关联，提出并验证了“Factored World Hypothesis”，揭示 Transformer 对因子化表示具有固有的偏置，并在不需要显式结构化学习的情况下实现指数级维度压缩。

**🔧 技术方法**

使用 GPT‑2 样式解码器 Transformer、RNN/LSTM、GHMM 生成器、PCA、累计解释方差、子空间重叠度量以及线性回归映射激活到预测向量的技术，结合合成多因子（3‑state HMM + 3‑维 GHMM）数据。

**📊 数据集**

采用由五个独立子过程（3‑状态 HMM 与 3‑维 GHMM）构成的合成语料库，词表大小 433，构造了独立、条件独立和加噪三种生成模型，作为实验数据集。

**📈 对比分析**

通过比较累计解释方差曲线、有效维度（95% 方差）、子空间正交度量与理论预测的差异来评估模型；实验显示 Transformer 在训练早期即收敛至约 10 维的因子化表示（而非 242 维的全局表示），即使在加入噪声后仍表现出对因子化的偏好；相同趋势在更大模型和 RNN/LSTM 结构中出现。

**⚠️ 局限性**

研究局限于小规模合成数据，未检验在大规模真实文本上的表现；仅考虑 next‑token 预训练且仅用线性映射评估表示，可能无法捕捉更深层次的非线性结构；此外，真实世界中的因子化是否同样自然出现仍待进一步验证。

---

## 869. Proof-RM: A Scalable and Generalizable Reward Model for Math Proof

**arXiv ID:** 2602.02377 | [PDF](https://arxiv.org/pdf/2602.02377v1)

**作者:** Haotong Yang `[一作]` (Peking University), Muhan Zhang `[通讯]` (Peking University)

**通讯引用:** 4798 | [OpenAlex ID](https://openalex.org/A5071515223)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一套可扩展且通用的证明奖励模型 ProofRM，用于自动验证数学证明的正确性。

**💡 创新点**

创新点包括：①多维度多源数据构建管道，利用 LLM 生成多样化证明并通过组合级人类审核筛选；②在 RLVR 训练中加入“LLM‑as‑RM‑for‑RM”监督思维流畅度和 token 取权平衡策略，显著提升训练稳定性；③在多种规模模型上实现从 76% 到 82% 的验证准确率提升。

**🔧 技术方法**

技术主要包括：LLM 生成与提示变体、层级式 LLM 与人工审核标注、RLVR（GSPO）训练、token 权重平衡、奖励模型作为可验证奖励信号。

**📊 数据集**

数据集来自奥数竞赛题库（IMO、USAMO、Putnam 等）、官方解答与学生作业，并通过 LLM 生成多样化证明；最终得到约 2.1 万条 QPC 训练样本与 5% 的人工金标测试集。

**📈 对比分析**

与 DeepSeek V3.1、Gemini‑2.5‑Flash、GPT‑5‑Mini 等基线相比，ProofRM 在自有测试集上分别提升 5.2%、7.1%、9.9%（8B、14B、32B 模型）；在 OPC 外部测试集上亦取得 8%–11% 的增益，并在 best‑of‑k 测试时展示更高的 AU‑curve。

**⚠️ 局限性**

局限性包括：① 数据来源与提示策略仍有限，未充分探索所有可用 LLM；② RL 训练效率仍不理想，模型崩溃仍偶有发生；③ 需要大量人力审核才能保证标签质量，进一步提升可扩展性仍是挑战。

---

## 870. The hybrid confirmation tree: A robust strategy for hybrid intelligence

**arXiv ID:** 2602.02375 | [PDF](https://arxiv.org/pdf/2602.02375v1)

**作者:** Julian Berger `[一作]` (Max Planck Institute for Human Development), Ralf HJM Kurvers `[通讯]`

**关键词:** `37e2bb26-449b-4ccc-a077-e4289fb90a8e` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出并评估了一种“混合确认树”聚合策略，将人工与AI的独立判断结合，并在两者不一致时由第二名人工决策。

**💡 创新点**

创新点在于仅需一次AI和一次人工输入即可完成决策，保持人类代理且成本更低，同时实现了比三人多数投票更高的准确率和更大的错误互补性。

**🔧 技术方法**

使用了基于贝叶斯推断的概率模型、Cohen κ相关性分析、ROC曲线、以及Bayesian GLMM对结果进行统计验证。

**📊 数据集**

实验数据来源于六个真实世界高风险任务：皮肤癌诊断（两套数据集）、深伪造检测、犯罪再犯预测、两项地缘政治预测以及相应的机器学习模型（CNN、逻辑回归、时间序列回归、LLM）。

**📈 对比分析**

与三人多数投票、人类单独决策、纯AI决策等基准相比，混合确认树在准确率上提升最多10个百分点，且人力成本降低28–44%；在ROC空间中可通过阈值调节实现更灵活的真/假阳性权衡。

**⚠️ 局限性**

局限在于需要先验的人工和AI准确率、相关性估计以及阈值选择；当人机准确率差距较大或人机决策高度相关时，互补优势减弱；同时未在多选或开放式任务中验证。

---

## 871. SWE-Universe: Scale Real-World Verifiable Environments to Millions

**arXiv ID:** 2602.02361 | [PDF](https://arxiv.org/pdf/2602.02361v1)

**作者:** Mouxiang Chen `[一作]` (Zhejiang University), Binyuan Hui `[通讯]` (Qwen Team, Alibaba Group)

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

自动构建百万级多语言可验证软件工程（SWE）训练环境，形成SWE-Universe数据集。

**💡 创新点**

创新点在于引入自治构建代理、迭代自检循环和循环破解检测，显著提升构建成功率并确保验证器真实性。

**🔧 技术方法**

采用定制的Qwen-Next-80A3（MoE）模型及其工具集（shell、patch apply/revert），并结合LLM生成验证脚本与自检。

**📊 数据集**

利用约807,693个多语言任务，来源于五年内约3,330万条GitHub PR，最终筛选得到百万级高质量实例。

**📈 对比分析**

与SWE-Bench、SWE-Rebench、Multi-SWE等基准对比，构建成功率从82.6%提升至94%；在SWE-Bench Verified上，Qwen3-Max-Thinking取得75.3%的得分。

**⚠️ 局限性**

局限性包括：任务描述不完整、Docker环境与需求不匹配、测试与任务不一致等质量问题；对极为复杂或平台专属的构建需求仍有一定挑战。

---

## 872. Automated Multiple Mini Interview (MMI) Scoring

**arXiv ID:** 2602.02360 | [PDF](https://arxiv.org/pdf/2602.02360v1)

**作者:** Ryan Huynh `[一作]` (University of Surrey), Alison Callwood `[通讯]` (University of Surrey)

**通讯引用:** 278 | [OpenAlex ID](https://openalex.org/A5080134842)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

开发了一种两阶段多代理提示框架，先对MMI转录文本进行预处理，再分别用九个单一准则评分代理进行分指标评分，以实现对多小型访谈中软技能的自动评估。

**💡 创新点**

创新点在于将大语言模型的强大少量样本学习与任务分解相结合，利用预处理+九个准则独立评分的结构，显著提升抽象、情境依赖软技能评估的可靠性，且不依赖大规模标注或细粒度评分表。

**🔧 技术方法**

技术包括：基于指令调优的Llama 3.1 405B（以及其他大模型如Llama 4 Maverick、GPT‑5、Gemini 2.5 Pro 等）的3-shot少量示例提示、检索增强生成（RAG）实验、预处理代理、九个准则评分代理；对比实验使用了传统的Fine‑Tuning（Grouped/Individual+预处理）、RMTS（基于推理生成理由的Fine‑Tuning）等方法。

**📊 数据集**

数据集为：1）包含1001条VMMI转录文本的MMI数据集（四个情境，9个文本准则）；2）对AE评分任务的ASAP基准（Prompt 7、8）用以验证框架的可迁移性。

**📈 对比分析**

与基准方法比较：多代理框架在MMI上平均Quadratic Weighted Kappa（QWK）为0.621，MSE为0.871，几乎是最佳Fine‑Tuned模型（0.316 QWK）的两倍；在ASAP上亦能超过人类评审一致性（0.638/0.663 QWK），并与SOTA Fine‑Tuned RMTS相当或更好；在模型比较中，Llama 4 Maverick在准确性与成本上表现最佳。

**⚠️ 局限性**

局限性包括：提示框架主要在Llama 3.1 405B上调优，可能对其它模型适配不佳；仅使用文本特征，未考虑视频/音频非语言信号导致与人类评分存在偏差；未使用详细、情境特定评分表，难以完全验证模型与原始评审的一致性；缺乏可解释性与理由生成，难以满足关键领域对透明度的需求；工具定位为决策辅助，而非完全自动化，受法律合规限制。

---

## 873. Implicit neural representation of textures

**arXiv ID:** 2602.02354 | [PDF](https://arxiv.org/pdf/2602.02354v1)

**作者:** Albert Kwok `[一作]` (University of Cambridge), Dounia Hammou `[通讯]` (University of Cambridge)

**通讯引用:** 115 | [OpenAlex ID](https://openalex.org/A5038646938)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `fede83ac-7505-405f-ab37-e7284695c47f` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

构建并评估了多种基于隐式神经表示（INR）的纹理编码模型，并将其与传统压缩方法（如ASTC）以及在Mitsuba 3渲染器中的实际部署进行对比；同时探索了 MIPMAP 生成和 INR 空间的生成式模型。

**💡 创新点**

提出将不同激活函数（ReLU、SIREN 的正弦）、频域位置编码（Fourier 以及多分辨率哈希）与 MLP 结合，形成多种纹理 INR 体系；首次系统地评估了 INRs 在纹理压缩中的压缩比、质量、渲染效率和内存占用，并展示了通过 INR 生成多级 MIPMAP 以及使用扩散模型在权重空间生成新纹理的可行性。

**🔧 技术方法**

使用 MLP、SIREN、Fourier‑encoded MLP 等网络架构；正弦激活、位置编码、频率调优；Rprop 与 Adam 优化器对比；Mitsuba 3 插件实现即时推断；扩散模型（Transformer 预测器）用于 INR 权重生成；评估指标包括 MAE、MSE、PSNR、SSIM、LPIPS、VMAF；与 ASTC 进行压缩比对比；MIPMAP 训练方法与权重空间生成。

**📊 数据集**

Describable Textures Dataset（DTD），共 5640 张纹理图像；通过拉普拉斯方差筛选 25 张代表性样本；采用多尺度 MIPMAP 训练集；在 INR 空间生成实验中使用约 600 个权重样本。

**📈 对比分析**

对比方法：将 INR 的比特率（bits‑per‑pixel）与压缩后图像的 LPIPS、VMAF、SSIM、PSNR 等感知/统计指标绘图；与 ASTC 在相同比特率下的结果作对照；对不同网络结构、优化器、MIPMAP 与无 MIPMAP 的性能进行实验；结果表明：Fourier‑encoded MLP 在 LPIPS 上最优，SIREN 其次，纯 MLP 最差；在高压缩率下，INR 的 LPIPS 与 VMAF 明显优于 ASTC，SSIM/PSNR 亦大致保持一致但略逊；MIPMAP 训练对 VMAF 产生积极影响；Rprop 在大多数情况下效果不如 Adam；生成式 INR 权重的初步实验表明效果可达，但仍受训练样本不足限制。

**⚠️ 局限性**

主要局限包括：1）训练时间长（50–200 s/50 迭代），难以进行大规模超参数搜索；2）频率参数未做系统调优，导致某些结构（如直线）出现伪影；3）样本量有限，尤其在 INR‑space 生成实验中仅约 600 个权重样本；4）在高分辨率纹理或更复杂材质（如 SVBSDF）上的泛化与压缩效果尚未充分验证；5）对多图像压缩（如动画）和自适应 MIPMAP 进一步研究仍需深入。

---

## 874. Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs

**arXiv ID:** 2602.02338 | [PDF](https://arxiv.org/pdf/2602.02338v1)

**作者:** Yu Liang `[一作]` (Central South University), Jiazhi Xia `[通讯]` (Central South University)

**通讯引用:** 9932 | [OpenAlex ID](https://openalex.org/A5069771666)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `c773407a-6119-4871-b8b3-1e7ae17a6851`

**🎯 论文内容**

提出了一个基于语义ID的生成式推荐框架ReSID，用以改进传统以语义为中心的token化流程，使模型更好地利用协同信息并减少序列不确定性。

**💡 创新点**

创新点在于将表示学习与量化从信息理论角度重新设计，分别提出Field‑Aware Masked Auto‑Encoding（FAMAE）实现协同主导的特征编码，以及Globally Aligned Orthogonal Quantization（GAOQ）实现全局一致的分层量化，二者共同提升了SID的可预测性与压缩效率。

**🔧 技术方法**

核心技术包括Transformer‑based掩码字段预测、信息理论下的互信息保留分析、全局对齐的分层向量量化以及匈牙利匹配实现索引一致性。

**📊 数据集**

在十个亚马逊产品子数据集（如Musical Instruments、Video Games、Baby Products等）上进行评估。

**📈 对比分析**

与传统基于item‑ID的序列模型（HGN、SASRec、BERT4Rec等）以及现有SID生成模型（TIGER、LETTER、EAGER、UNGER等）相比，ReSID在Recall@5/10、NDCG@5/10均平均提升10%以上，并在量化阶段显著降低运行时成本。

**⚠️ 局限性**

局限性包括：缺乏针对GAOQ的严格评估指标，生成式推荐模型收敛速度仍慢于基于item‑ID的方法，且对极大规模多模态数据的适用性待进一步验证。

---

## 875. Well-Formed Free-Choice Petri Nets Revisited

**arXiv ID:** 2602.02352 | [PDF](https://arxiv.org/pdf/2602.02352v1)

**作者:** Petr Jancar `[一作]`, Matej Ostadal `[通讯]`

**关键词:** `33d19632-8af2-4683-a5db-767c7ce749e6`

**🎯 论文内容**

本文重新定义了良构自由选择 Petri 网的结构特征，提出了新的半 T‑组件和半 S‑组件概念，并用它们给出良构网的完整结构性判定；随后基于这些概念构造了一个多项式时间的判定算法。

**💡 创新点**

创新点包括：① 将传统的 T‑组件与 S‑组件对称化，引入半 T‑、半 S‑组件的概念；② 用单一对称性证明了经典的覆盖定理和双性定理；③ 通过半 T‑组件实现了判定良构性的全新算法，提供了比已有线性/矩阵算法更直观的图论视角。

**🔧 技术方法**

主要技术手段为：Petri 网的图论模型、簇（cluster）结构、转移/位置分配（allocation）与共价分配（co‑allocation）、强连通分量（SCC）分析、以及利用半 T‑/S‑组件的性质构造算法。

**📊 数据集**

本文为理论性研究，未使用任何实验数据集；所有结果均为数学证明与算法复杂度分析。

**📈 对比分析**

在算法效率方面，本文提出的判定算法为多项式时间（O(|S|+|T|+|F|)），与现有基于 Rank 定理的最优 O(|S||T|²) 或 O(|S|²|T|²) 的算法相比，复杂度更高，但实现更为简洁透明；实验验证未给出，但理论上已证明正确性与多项式性。

**⚠️ 局限性**

局限性包括：① 算法针对普通无权 Petri 网，未直接适用于加权弧网；② 由于使用了简单的图论技术，时间复杂度未能达到现有 Rank 定理方法的最优水平；③ 在证明 S‑覆盖性方面的完整性尚未得到完整的对称化证明，需进一步研究。

---

## 876. Catalyst: Out-of-Distribution Detection via Elastic Scaling

**arXiv ID:** 2602.02409 | [PDF](https://arxiv.org/pdf/2602.02409v1)

**作者:** Abid Hassan `[一作]` (University of Southern California), Nenad Medvidovic `[通讯]` (University of Southern California)

**通讯引用:** 12419 | [OpenAlex ID](https://openalex.org/A5006714421)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `3855fcda-48ef-4070-a15e-803cd5c84d83` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出一种后处理框架，利用预池化层通道统计量计算输入依赖的缩放因子γ，乘法融合到现有OOD评分上，从而增强ID与OOD分离。

**💡 创新点**

创新点在于首次挖掘并利用预池化激活的通道均值、方差、最大值等统计特征，构造可自适应的弹性缩放因子；该方法既简单易实现，又能与多种现有评分方法互补。

**🔧 技术方法**

采用后处理的弹性缩放机制、统计量裁剪（阈值剪切）、乘法融合、能量（Energy）或距离（KNN）等评分基础；同时对统计量进行比例裁剪并通过经验百分位数确定阈值。

**📊 数据集**

在CIFAR‑10、CIFAR‑100以及ImageNet‑1k上验证，使用多种主流网络（ResNet‑18/34/50、DenseNet‑101/121、MobileNet‑v2），并评估多种OOD数据集（Textures、SVHN、Places365、LSUN‑Crop/Resize、iSUN、iNaturalist、SUN）。

**📈 对比分析**

与MSP、ODIN、Energy、ReAct、DICE、ASH、SCALE、AdaScale、NCI、fDBD等方法对比，平均FPR95下降超过30%（CIFAR‑10）/27%（CIFAR‑100）/22%（ImageNet），AUROC显著提升，KNN距离方法同样获得显著改进。

**⚠️ 局限性**

局限性包括仅针对CNN架构验证，扩展到ViT等模型尚未完成；所用统计量仅限于均值/方差/最大值，其他如中位数、熵不稳定；方法需手动设定剪切阈值（百分位数），对不同数据集可能需要微调。

---

## 877. C-kNN-LSH: A Nearest-Neighbor Algorithm for Sequential Counterfactual Inference

**arXiv ID:** 2602.02371 | [PDF](https://arxiv.org/pdf/2602.02371v1)

**作者:** Jing Wang `[一作]` (National Library of Medicine), Jeremy C Weiss `[通讯]` (National Library of Medicine)

**通讯引用:** 2210 | [OpenAlex ID](https://openalex.org/A5072774346)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `5a41884c-404f-4688-a89c-aa238c10fe68` `c773407a-6119-4871-b8b3-1e7ae17a6851` `e15e3743-5ee0-4d5f-813d-d146868082fc` `bb57609f-8351-4b1b-85e4-3afa07da95d6`

**🎯 论文内容**

提出了 C-kNN-LSH（Latent Matchmaking Network）框架，利用变分自编码器压缩高维临床历史，并通过局部近邻匹配结合双重稳健校正，进行顺序反事实推断，专门解决长期 COVID 症状随访中的因果效应估计。

**💡 创新点**

创新点在于：1) 将大型语言模型（LLM）作为语义编码器，将临床文本/时间序列信息映射到高维语义空间；2) 在此基础上设计平衡 ELBO，确保压缩后的潜在变量既能保持对结果的重要信息，又能抑制对处理的泄露；3) 结合局部近邻（kNN）+局部双重稳健（AIPW）实现高维、非线性时间序列中的因果效应估计，并使用 LSH 实现可扩展的近似最近邻检索；4) 理论证明在近似潜在充分统计的前提下，估计器保持一致性并对模型错误具有二阶鲁棒性。

**🔧 技术方法**

技术方法包括：变分自编码器（VAE）+ 变分瓶颈；大型语言模型（Qwen3-4B）作为语义编码器；局部最近邻检索（LSH/ANN）；双重稳健校正（DR/AIPW）；理论分析（潜在充分性、Lipschitz 光滑性、kNN 一致性）。

**📊 数据集**

使用 NIH RECOVER 项目的 Long COVID 纵向队列数据，共 13,511 名成人，最多 700 天随访，包含可穿戴设备的心率、步数等周度统计以及多剂量疫苗接种记录，PASC 严重程度分数为连续结果。

**📈 对比分析**

与传统全局方法（Outcome Regression、Inverse Propensity Weighting）和局部 AIPW 进行对比。实验结果表明 LMN 在估计不同剂量下的 PASC 严重度时表现出更平滑、更稳定且在高剂量区间更低的估计值，捕捉到明显的非单调剂量效应；在各 phenotype、概念集合及历史窗口长度下均保持一致性，显示了模型对多样化输入的鲁棒性。

**⚠️ 局限性**

局限性包括：1) 对潜在充分统计假设的依赖，若真实历史信息无法被压缩至低维会导致估计偏差；2) LLM 的语义编码可能对数值精度不够，导致部分临床信息丢失；3) 近似最近邻的误差在样本稀疏时可能放大；4) 该方法尚未在其他领域或更大规模数据上广泛验证，且对处理不平衡或高度异质性的情况仍需进一步研究。

---

## 878. Live-Evo: Online Evolution of Agentic Memory from Continuous Feedback

**arXiv ID:** 2602.02369 | [PDF](https://arxiv.org/pdf/2602.02369v1)

**作者:** Yaolun Zhang `[一作]` (Oregon State University), Huazheng Wang `[通讯]` (Oregon State University)

**通讯引用:** 594 | [OpenAlex ID](https://openalex.org/A5062299183)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `9ce7179e-700c-4310-ac2b-91df50ded46e` `79276348-11e0-48e3-84bc-7ec231d0171c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

提出一种在线自进化记忆系统 Live-Evo，利用经验库和 Meta‑指导库在连续任务流中动态检索、生成任务适配的指导，并通过对比评估与经验权重更新实现记忆的自适应改进。

**💡 创新点**

创新点：① 将经验的“发生”与“如何使用”分离，采用 Retrieve‑Compile‑Act‑Update 四阶段循环；② 在真实在线反馈环境下实现经验权重强化与衰减；③ 引入 Meta‑Guideline Bank 以实现经验的可复用组合；④ 使用对比评估量化指导效果并据此更新经验。

**🔧 技术方法**

技术手段：大语言模型（GPT‑4.1‑mini 等）为基础模型；主动检索、多维相似度与经验权重；Meta‑Guideline 编译；ContrastiveEval 对比评估；经验权重更新与衰减；经验摘要与写回策略。

**📊 数据集**

数据集：Prophet Arena 未来预测基准（10 周共 500 任务，严格时间约束检索）；XBench‑DeepResearch 传统深度研究任务。

**📈 对比分析**

与基线搜索模型、开源深度研究框架（MiroFlow、Qwen）、自进化记忆基线 ReMem 对比；在 Prophet Arena 上 Brier Score 降低 20.8%，市场收益提升 12.9%；在 XBench 上准确率提升至 0.46，优于其它方法；实验显示所有核心模块均对性能有显著贡献。

**⚠️ 局限性**

限制：依赖密集环境反馈，难以适用于稀疏或主观反馈场景；Verify‑Before‑Update 机制仅在显著收益时写入经验，可能延迟新策略采纳；需要人工控制时间约束检索以防数据泄漏。

---

## 879. Hierarchical Federated Learning with SignSGD: A Highly Communication-Efficient Approach

**arXiv ID:** 2602.02355 | [PDF](https://arxiv.org/pdf/2602.02355v1)

**作者:** Amirreza Kazemi `[一作]` (KTH Royal Institute of Technology), Carlo Fischione `[通讯]` (KTH Royal Institute of Technology)

**通讯引用:** 6804 | [OpenAlex ID](https://openalex.org/A5077148700)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62` `c84dae5d-5273-4348-85a7-b44cb586b4df` `5b4c1114-4a70-478e-9921-2514ee03850d` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出了一种层级联邦学习中的一比特符号梯度压缩与多数投票聚合算法 HierSignSGD，并给出了其在非凸优化下的收敛分析。

**💡 创新点**

① 将 SignSGD 与层级聚合结合，首次对层级架构下的符号梯度压缩进行理论研究；② 兼顾设备–边缘层和云层的两级聚合间隔与跨集群异质性对收敛的联合影响；③ 支持下行稀疏量化，实现全链路一比特通信。

**🔧 技术方法**

符号梯度压缩（SignSGD）、多数投票聚合、分层聚合、无偏量化、梯度不一致性分析、非凸收敛证明。

**📊 数据集**

EMNIST‑digits 与 Fashion‑MNIST 两个分类数据集。

**📈 对比分析**

与传统全精度层级 SGD（HierSGD）以及非层级 SGD 进行对比；在 IID 与非 IID 场景下，HierSignSGD 取得与全精度相当或更优的准确率，同时通信量降低数倍；在下行量化条件下仍保持鲁棒性。

**⚠️ 局限性**

仍需在更深层级、多任务和更大模型上验证；对设备聚合粒度的选择与非 IID 下的聚合间隔有经验性调优需求；理论收敛上界在高异质性或极端压缩率下可能过于保守。

---

## 880. Fairness-Sensitive PageRank Approximation

**arXiv ID:** 2602.02329 | [PDF](https://arxiv.org/pdf/2602.02329v1)

**作者:** Mukesh Kumar `[一作]` (Indian Institute of Technology Roorkee), Akrati Saxena `[通讯]` (Leiden University)

**通讯引用:** 453 | [OpenAlex ID](https://openalex.org/A5055236010)

**关键词:** `2f9b095f-c896-4240-9f90-c17a5e9a2c39` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `3f18e8e3-0266-457c-8567-9039b6d2394d` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出一种基于均值场近似的公平敏感 PageRank 计算方法，直接利用节点入度与组信息近似计算公平 PageRank，避免了昂贵的矩阵求逆和凸优化。

**💡 创新点**

创新点在于给出一套闭式近似公式和方差分析，既实现了组层级公平约束，又将原始 FSPR 的 O(N³) 复杂度降至 O(M) 的线性时间，同时保持对群体公平性的严格控制。

**🔧 技术方法**

主要技术包括均值场近似、条件概率简化、闭式解析求解以及对高斯假设下方差的推导；实现上采用一次遍历边集合即可得到所有入度、组占比及近似 PageRank。

**📊 数据集**

实验数据集涵盖若干大型真实网络，如 DBLP‑Aminer、Twitter、Enron 等，包含数百万节点与边，且每个网络都有标注的两组（保护组与非保护组）信息。

**📈 对比分析**

与原始 FSPR（需要矩阵求逆和二次优化）对比，近似方法在运行时间上提升约 10 倍，内存占用从 O(N²) 降到 O(N)；在近似精度上，平均误差低于 5%，并且在保证组级公平度量不变的前提下得到一致的排名结果。

**⚠️ 局限性**

局限性包括：假设网络无度-度相关（均值场近似的前提），难以捕捉复杂的结构相关性；仅针对两组情况提出，扩展到多组或动态网络仍需进一步研究；在高度偏斜度分布的极端节点上方差估计可能不够精确。

---

## 881. Language Steering for Multilingual In-Context Learning

**arXiv ID:** 2602.02326 | [PDF](https://arxiv.org/pdf/2602.02326v1)

**作者:** Neeraja Kirtane `[一作]` (Texas A&M University), Kuan-Hao Huang `[通讯]` (Texas A&M University)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种训练‑free 的语言向量（Language Vectors），通过激活差分实现多语种推理的“语言模式切换”，提升跨语言少样本学习效果。

**💡 创新点**

创新点在于利用源语言与目标语言示例的隐藏层激活差异直接生成语言向量，并在推理时通过前向钩子加到内部表示，无需额外训练或微调，即可实现语言切换。

**🔧 技术方法**

技术包括激活差分计算、向量归一化、前向钩子插值、层/位置/尺度超参搜索，以及层级聚类分析。

**📊 数据集**

使用了三大任务数据集：MGSM、MSVAMP 与 XNLI，共覆盖19种语言（包括英语、中文、西班牙语等）。

**📈 对比分析**

与源语言baseline和多语言few‑shot baseline进行对比，平均在MGSM上提升约2.9–5.4%，在XNLI和MSVAMP上亦有正向改进；跨任务向量转移多能成功，表现优于随机向量。

**⚠️ 局限性**

局限在于需要有足够的平行示例来构造向量，任务不兼容时转移效果差；对极低资源语言的提升有限；向量对模型内部机制的解释仍不充分。

---

## 882. Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing

**arXiv ID:** 2602.02386 | [PDF](https://arxiv.org/pdf/2602.02386v1)

**作者:** Mika Okamoto `[一作]` (Georgia Institute of Technology), Glenn Matlin `[通讯]` (Georgia Institute of Technology)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `64443552-63e0-44b5-906f-d90fe95c5a1b` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `9587dba8-6c1f-4e48-8ba3-7bed5ce8f472`

**🎯 论文内容**

设计了一个通过自动化批评者提取细粒度技能概况并聚类，构建模型能力矩阵与任务需求矩阵，在预算约束下用多目标优化实现LLM模型选择的框架。

**💡 创新点**

①基于批评者的无预定义词汇表的技能提取与聚类；②可解释的能力矩阵与成本向量构建；③透明理由生成与预算约束下的多目标优化。

**🔧 技术方法**

使用LLM批评者进行技能评估，句子嵌入+层次聚类生成技能词汇表，构建模型能力矩阵与任务需求矩阵，采用多目标优化/约束规划进行模型选取，并通过可解释理由展示。

**📊 数据集**

以金融推理为代表，使用FLaME等金融基准数据集进行多技能推理任务评估，构建能力矩阵。

**📈 对比分析**

通过留一交叉验证评估框架，并与RouteLLM、FrugalGPT及最优oracle进行对比，评估指标包括推理成本、相对准确度差距和选择精度；结果显示在预算限制下框架实现了更低成本同时保持接近最优性能。

**⚠️ 局限性**

需要对每个模型-任务实例调用批评者产生前置成本，批评者性能不确定且可解释聚类稳定性待验证；框架基于静态技能矩阵，无法即时响应动态子任务；需进一步验证跨领域技能迁移与多约束优化效果。

---

## 883. Masked Autoencoders as Universal Speech Enhancer

**arXiv ID:** 2602.02413 | [PDF](https://arxiv.org/pdf/2602.02413v1)

**作者:** Rajalaxmi Rajagopalan `[一作]` (University of Illinois), Kyu Han `[通讯]` (AWS AI Labs)

**关键词:** `fb2d1ce9-128d-478c-ade6-0079bcd4d876` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `a244defd-9560-426b-b1b1-f78ebb2b7bf9` `edb9d762-f411-4838-a852-f2d638b018db` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `b88c6eac-d57a-4623-a604-1f401f3eb268`

**🎯 论文内容**

本文提出了一种基于掩码自编码器（MAE）的通用语音增强模型，能够在自监督预训练阶段学习去除多种失真，并通过少量标注数据微调完成去噪、去混响等任务。

**💡 创新点**

创新点在于将多种声学失真（背景噪声、回声、码率失真、混合说话人等）作为增强堆栈加入预训练，并在掩码自编码器中同时实现失真去除与掩码重建，从而让模型既是自监督又能通用处理多种失真。

**🔧 技术方法**

主要技术包括：ViT-MAE（带Swin Transformer解码器）自监督预训练、声学与频谱级的数据增强、log1p 压缩特征、微调时使用 TF 掩码输出、以及多说话人距离分离生成方法。

**📊 数据集**

使用的数据集包括 LibriTTS 960 小时用于预训练，Valentini 29 小时用于微调评估，以及 DAPS、DNS 语音噪声库、SLR28 RIR 等进行数据增强。

**📈 对比分析**

与现有自监督预训练（WavLM、HuBERT）及监督模型（DCUNet、UNIVERSE、SGMSE+、PANN+UNet 等）对比，本文在 PESQ、CSIG、COVL、SSNR、NISQA 等指标上取得或接近 SOTA，在大多数指标上均优于监督模型，尤其在多说话人和 log1p 压缩下表现突出。

**⚠️ 局限性**

局限性包括：仅在少量下游任务（去噪、去混响）进行评估，未对源分离、带宽扩展、PLC 等更复杂任务做深入实验，且对无距离提示的混合语音分离的效果未知。

---

## 884. Provenance Verification of AI-Generated Images via a Perceptual Hash Registry Anchored on Blockchain

**arXiv ID:** 2602.02412 | [PDF](https://arxiv.org/pdf/2602.02412v1)

**作者:** Apoorv Mohit `[一作]` (S P Global), Chinmay Gondhalekar `[通讯]` (S P Global)

**关键词:** `b011fd49-2b66-44b7-8ab9-cd8d3a13f67e` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

开发了一套基于区块链的 AI 生成图像源头验证框架，利用感知哈希注册图像并在上传时通过 MPT+BK‑Tree 进行相似性检索；

**💡 创新点**

将感知哈希与 Merkle Patricia Trie 及 Burkhard–Keller 树结合，形成可扩展、链上不可篡改、离线高效相似搜索的注册与验证机制，且与水印、学习模型互补；

**🔧 技术方法**

采用感知哈希（pHash）、Hamming 距离、Merkle Patricia Trie、Burkhard–Keller 树以及公链上的混合存储架构；

**📊 数据集**

使用 AI‑Generated Images vs. Real Images 数据集（30k AI、30k 真实图像）及其 30k 编辑后 AI 图像进行验证实验，并用 100k/500k/1M 随机 64‑bit 哈希做性能评测；

**📈 对比分析**

与平面数组线性扫描和单独 BK‑Tree 进行对比；在 1M 哈希规模下，Patricia Trie+BK‑Tree 平均查询时间 0.17 ms、95 % 分位 0.52 ms；召回率约 98‑99%（阈值 τ = 6），误报率低于 0.2%；

**⚠️ 局限性**

仅能验证已注册的 AI 图像，无法识别未注册或恶意生成的内容；受感知哈希碰撞、强变形攻击影响；高阈值会导致误报；需要治理、隐私合规及平台级集成支持。

---

## 885. Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning

**arXiv ID:** 2602.02405 | [PDF](https://arxiv.org/pdf/2602.02405v1)

**作者:** Ethan Mendes `[一作]` (Georgia Institute of Technology), Alan Ritter `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 10167 | [OpenAlex ID](https://openalex.org/A5039096905)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

通过把专家给出的简略答案转换成模型可接受的、细节完整的推理轨迹，并用对比学习抑制学习捷径，从而在极难的数学推理任务上提升LLM的推理能力。

**💡 创新点**

① 先用“特权学生”与原始专家解答混合生成推理轨迹，弥补人类解答的didactic（教学）缺口；② 用对比损失惩罚对“短路”推理的模仿，解决普通监督训练会陷入捷径的问题。

**🔧 技术方法**

混合策略回放（Mixed Policy Rollouts）、对比学习（Contrastive Loss）以及冻结的特权学生/负参考模型来生成和评估推理轨迹。

**📊 数据集**

≈417个未被Qwen2.5-7B-Instruct解出的AIME历史题目（训练集），≈669个IMO、regional olympiad的非可验证证明题（训练集），以及 AIME 2024/25、BeyondAIME、IMO-AnswerBench、GPQA-Diamond 等评测基准。

**📈 对比分析**

与基线（SFT、STaR、温度调节）、RLVR（GRPO、NuRL、DeepScaleR）以及纯对比损失 vs NLL 进行对比。结果显示：在 Qwen2.5‑7B‑Instruct 上，pass@k 在所有评测集上均优于基线，尤其在大 k 时提升显著；在 Qwen3‑8B‑think 上，pass@k 提升 15% 左右，且在 token 限制下可用 2–4 倍更少的推理 token 达到相同效果；在 GPQA-Diamond 上也保持或略优于基线。

**⚠️ 局限性**

① 需要先有专家解答，成本高；② 对齐策略和对比损失的超参需手动调优；③ 在极高难度或完全新颖的推理任务中，生成的轨迹仍可能包含未被识别的“短路”，影响效果；④ 目前仅在数学/科学推理域验证，其他领域的适用性待进一步探索。

---

## 886. Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory

**arXiv ID:** 2602.02393 | [PDF](https://arxiv.org/pdf/2602.02393v1)

**作者:** Ruiqi Wu `[一作]` (Meituan), Ming-Ming Cheng `[通讯]` (Nankai University)

**通讯引用:** 49794 | [OpenAlex ID](https://openalex.org/A5037131575)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `fede83ac-7505-405f-ab37-e7284695c47f` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `ba576bd1-e51d-44e8-8077-fc943b333c93` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

训练了一个可在超过1000帧的长视角下保持视觉一致性和动作可控性的交互式世界模型 Infinite‑World。

**💡 创新点**

创新点：① 层次化无姿态记忆压缩器（HPMC）在固定预算内递归压缩历史潜变量，保持常量计算复杂度；② 不确定性动作标记，将连续运动离散为三态（无操作、离散动作、未知），抑制姿态噪声对动作学习的干扰；③ 访问信息密集微调数据集（RDD）可用极少数据激活1000帧级别的闭环记忆。

**🔧 技术方法**

技术细节：基于 Diffusion Transformer（DiT）主干，结合 3D‑ResNet 压缩器、滑动窗口递归压缩、端到端联合训练、三态动作离散化与动作编码等方法。

**📊 数据集**

数据集：30小时互联网采集的视频做预训练，随后使用 30 分钟高质量访问信息密集的 Revisit‑Dense Dataset（RDD）进行微调。

**📈 对比分析**

与四个现有 SOTA 模型（HY‑World 1.5、Hunyuan‑GameCraft、Yume 1.5、Matrix‑Game 2.0）在 VBench 指标和大规模用户研究中对比。Infinite‑World 在记忆一致性、视觉质量和动作响应性三项指标均获得最高 ELO 1719，表现明显优于其它方法。

**⚠️ 局限性**

局限性：仍面临累计漂移和视觉衰退问题，长时间持续视角变化的鲁棒性有限；需要更大模型或进一步的蒸馏、自强策略来提升稳定性；数据集规模和多样性仍受限，未来需进一步扩展。

---

## 887. ReasonCACHE: Teaching LLMs To Reason Without Weight Updates

**arXiv ID:** 2602.02366 | [PDF](https://arxiv.org/pdf/2602.02366v1)

**作者:** Sharut Gupta `[一作]` (Massachusetts Institute of Technology), Mohammad Pezeshki `[通讯]` (Meta)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 ReasonCache，利用前缀调优（Prefix Tuning）学习可压缩的 KV 前缀，实现不修改预训练权重的推理时推理能力扩展。

**💡 创新点**

创新点在于将前缀调优视为可压缩的 KV 缓存，突破 ICL 在规模与表达力上的瓶颈，并证明其在低秩更新上更具表达能力。

**🔧 技术方法**

采用 Prefix Tuning（前缀学习）、KV 缓存压缩、梯度无更新的参数化方法；对比 LoRA、SFT、ICL、Prompt Tuning 等。

**📊 数据集**

使用 GSM8K、MATH、AIME、GPQA-Diamond、OpenThoughts-3 等推理基准数据集。

**📈 对比分析**

在所有基准上，ReasonCache 在保持权重冻结的前提下，往往超过 LoRA 和 SFT，数据效率提升59%，参数量减少46%，推理时间更短、准确率提升11%（GPQA）等；在 ICL 方面表现显著优于传统示例调优。

**⚠️ 局限性**

局限性包括：对长序列的上下文仍有限制；在 AIME 等更长推理任务中表现不佳；缺乏可在推理时动态更新的能力；目前需要额外支持可训练 KV 缓存的推理框架。

---

## 888. A Task-Level Evaluation of AI Agents in Open-Source Projects

**arXiv ID:** 2602.02345 | [PDF](https://arxiv.org/pdf/2602.02345v1)

**作者:** Shojibur Rahman `[一作]` (Idaho State University), Minhaz Zibran `[通讯]`

**关键词:** `1bc454a9-3d09-46c3-87e9-f7a9c36911df` `e2c980c8-7137-48ee-b99f-3fbde4cf81e7` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

对五种自主编码代理在真实开源项目中的 PR 生命周期进行任务级别的定量比较。

**💡 创新点**

首次将 PR 接受率、审查讨论量和提交信息质量三维度与任务类型关联，揭示不同代理在各维度和任务上的差异性。

**🔧 技术方法**

采用 PR 接受率统计、评论数量计数以及基于 BERT 的 C‑Good 句子分类器评估提交信息质量。

**📊 数据集**

使用公开的 AIDev‑pop 数据集，其中包含 33,549 条由 Codex、Devin、Copilot、Cursor、Claude 生成的 PR，覆盖 2,807 个高星开源仓库。

**📈 对比分析**

通过算术平均、标准差和 Mann‑Whitney‑Wilcoxon 检验对比代理的表现。结果显示 Codex 在大多数任务上接受率最高、讨论量最低；Copilot 讨论量最高、接受率最低；Claude 的提交信息质量最高但波动大；Codex 的接受率高但提交信息质量低。

**⚠️ 局限性**

局限性包括：仅评估 PR 层面指标，未考虑代码质量、缺陷率等；审查评论未区分正负；数据仅覆盖 2025 年前的公开仓库，后续模型迭代可能导致结果变化。

---

## 889. LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization

**arXiv ID:** 2602.02341 | [PDF](https://arxiv.org/pdf/2602.02341v1)

**作者:** Zhenpeng Huang `[一作]` (Nanjing University), Limin Wang `[通讯]` (Nanjing University)

**通讯引用:** 21722 | [OpenAlex ID](https://openalex.org/A5100436505)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本工作提出了一种两阶段Direct Preference Optimization（DPO）框架，利用短视频标注和自监督策略，使短上下文视觉语言模型能够在无需任何长视频标注的情况下实现对超长视频的稳健理解。

**💡 创新点**

创新点在于：①通过锚点对齐合成偏好三元组，结合视觉相似度和问题特异性过滤，消除位置偏差；②采用递归字幕生成与LLM生成的跨场景查询，实现自监督的长视频偏好对齐；③仅需约16k合成样本，即可突破长视频标注成本瓶颈。

**🔧 技术方法**

核心技术包括：Direct Preference Optimization（DPO）训练、锚点（anchor）与混合短片段构造、视觉相似度与问题特异性过滤、递归字幕生成、LLM（如Qwen2.5-32B）生成查询与推理链、位置随机化和基于场景的响应筛选。

**📊 数据集**

使用的数据集为LLaVA-Video-178K（短视频）和Vript（无标签长视频），通过合成技术共生成约16k条训练样本。

**📈 对比分析**

在多项公开长视频基准（VideoMME、LongVideoBench、MVBench、InternVL等）与现有长视频模型（如InternVideo2.5、Qwen2.5-VL等）进行对比，模型在长视频任务上取得SOTA性能，同时在短视频任务上保持竞争力。

**⚠️ 局限性**

主要局限在于：训练过程中未针对推理阶段的计算效率进行优化；模型规模相对较大，对极长视频的上下文压缩和推理速度仍需进一步提升。

---

## 890. VQ-Style: Disentangling Style and Content in Motion with Residual Quantized Representations

**arXiv ID:** 2602.02334 | [PDF](https://arxiv.org/pdf/2602.02334v1)

**作者:** Fatemeh Zargarbashi `[一作]` (ETH Zurich), Robert W. Sumner `[通讯]` (ETH Zurich)

**通讯引用:** 4881 | [OpenAlex ID](https://openalex.org/A5047437165)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `9ce7179e-700c-4310-ac2b-91df50ded46e` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

该论文提出了一种基于残差向量量化变分自编码器（RVQ‑VAE）的运动风格与内容的分离与迁移框架，能够在推理阶段实现零样本风格迁移、风格插值、风格反演等多种应用。

**💡 创新点**

创新点在于：①利用RVQ‑VAE的粗细层级结构自然区分内容与细节风格；②结合对比学习与互信息损失，强化风格-内容的互相独立；③提出量化代码交换（Quantized Code Swapping）实现无需微调的即时风格迁移。

**🔧 技术方法**

核心技术包括：残差向量量化变分自编码器、对比学习（Multi‑Pos）、互信息最小化、量化代码交换、前向运动学与速度/加速度约束损失。

**📊 数据集**

实验使用了三大数据集：100STYLE（包含100种行走风格）、Aberman（16种通用动作风格）以及Xia（8种通用动作风格）进行训练与评估。

**📈 对比分析**

与基准方法（如LPN‑Style、GenMoStyle、ControlNet等）相比，本文在100STYLE上实现了约83.2% 的风格分类准确率，未见过风格下可达68.95%（top‑1）/98.83%（top‑5），在Aberman与Xia数据集的风格准确率也优于对比模型，且内容轨迹偏差保持在可接受范围内。

**⚠️ 局限性**

主要局限包括：①对风格与内容定义仍依赖手工标注，可能在不同数据集间产生歧义；②在非行走动作或长序列中，内容轨迹漂移和风格泄漏仍有可能出现；③缺乏更精细的无监督风格发现与评估指标，需进一步研究。

---

## 891. ReasonEdit: Editing Vision-Language Models using Human Reasoning

**arXiv ID:** 2602.02408 | [PDF](https://arxiv.org/pdf/2602.02408v1)

**作者:** Jiaxing Qiu `[一作]` (University of Virginia), Thomas Hartvigsen `[通讯]` (University of Virginia)

**通讯引用:** 521 | [OpenAlex ID](https://openalex.org/A5075881948)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种基于人类推理的视觉‑语言模型编辑框架 ReasonEdit，能在不更新模型权重的情况下，通过检索存储的人类推理句子来纠正错误并提升模型的推理能力。

**💡 创新点**

创新点在于：①首次将人类推理文本直接嵌入编辑过程；②采用拓扑平衡的多模态嵌入方法，将视觉与语言特征的社区结构（modularity）作为选取 embedding 的准则；③设计了一个代码簿式检索机制，既保持了局部性又能推广到相似图像/问题，避免了梯度更新导致的灾难性遗忘。

**🔧 技术方法**

主要技术包括：检索式编辑器、代码簿（codebook）存储推理-图像片段对、基于网络科学的模组度（modularity）评估的双模态嵌入、键合并与最近邻检索、以及多模态相似度阈值控制。

**📊 数据集**

使用了两大公共推理型 VQA 数据集：A-OKVQA（18,195 题）和 FVQA（5,826 题），并在四个不同架构/规模的 VLM（LLaVA、InstructBLIP、Qwen3、以及未命名的 VLM）上进行实验。

**📈 对比分析**

与五种基线编辑器（FT、MEND、BalancEdit、IKE、GRACE）及其加入推理版对照模型相比，ReasonEdit 在可靠性、局部性、图像/文本泛化以及新增的推理泛化（R-Gen、CoE-Gen）指标上均实现了显著提升；在连续编辑实验中也保持了稳定的性能并且计算效率与传统编辑器相当或更优。

**⚠️ 局限性**

局限性包括：1）实验仅覆盖两类 VQA 数据集，未验证对更广泛任务的适用性；2）依赖人工推理输入，实际部署需解决用户反馈成本；3）检索式编辑在极端情况下可能错过更适合的推理句子；4）仅在四个 VLM 上评估，缺乏对更大规模模型的验证。

---

## 892. Superman: Unifying Skeleton and Vision for Human Motion Perception and Generation

**arXiv ID:** 2602.02401 | [PDF](https://arxiv.org/pdf/2602.02401v1)

**作者:** Xinshun Wang `[一作]` (Peking University), Mengyuan Liu `[通讯]` (Peking University)

**通讯引用:** 4184 | [OpenAlex ID](https://openalex.org/A5100705472)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出统一的“Superman”框架，使用单一多模态大语言模型同时完成3D姿态估计、运动预测与运动插值。

**💡 创新点**

核心创新是 Vision‑Guided Motion Tokenizer，将视觉特征与骨架几何融合生成跨模态离散运动词表，并通过统一的 MLLM 进行多任务学习，打破“读取‑写入”二元对立。

**🔧 技术方法**

技术包括双流 VQ‑VAE 词表学习、Visual‑Skeleton Attention (VSA)、Motion‑Aware Fine‑Tuning (MAFT)、基于 Qwen2.5‑VL‑7B 的自回归 MLLM、LoRA 微调与多任务训练。

**📊 数据集**

主要使用 Human3.6M 作为训练集，并在 Human3.6M 与 3DPW（未见）上进行评估。

**📈 对比分析**

与传统多任务模型、LLM/MLLM 基础模型以及最新方法对比，Superman 在三项任务上均取得 SOTA 或相近水平；在 Human3.6M 上 3D 姿态估计 MPJPE 仅 39.4 mm，预测和插值任务亦优于基准，且在 3DPW 上表现出显著的零样本泛化。

**⚠️ 局限性**

局限包括：大模型占用显著计算资源（Qwen‑VL 约 9.6B 参数），词表规模和 VQ‑VAE 训练成本高，且对长时序运动仍存在误差，未来需要更高效的模型与更丰富的视觉‑动作先验。

---

## 893. David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning

**arXiv ID:** 2602.02395 | [PDF](https://arxiv.org/pdf/2602.02395v1)

**作者:** Samuel Nellessen `[一作]` (Radboud University), Tal Kachman `[通讯]` (Radboud University)

**通讯引用:** 144 | [OpenAlex ID](https://openalex.org/A5030772953)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6215c339-3735-4be3-8a07-5bbb7004712d` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研究并实现了Tag-Along攻击框架 Slingshot，利用强化学习在 agentic 环境中通过对话诱导安全对齐操作员执行被禁止的工具调用。

**💡 创新点**

①将 Tag-Along 攻击形式化为可验证的控制问题；②提出全黑盒、API 级别的 RL 红队方法；③发现并解释了“Imperative Overloading”短句攻击策略，并展示其零样本跨模型转移与对专门防御的“对齐税”。

**🔧 技术方法**

使用 Clipped Importance Sampling-weight Policy Optimization (CISPO) 进行强化学习；reward 由可验证成功、判别器奖励与惩罚组成；在 AgentDojo 环境下进行多轮对话模拟；并利用判别器进行拒绝与鲁棒性检测。

**📊 数据集**

采用自构造的 TagAlong-Dojo benchmark（575 任务，包含极难和测试子集），以及 Qwen2.5-32B‑Instruct‑AWQ、Gemini 2.5 Flash、Meta‑SecAlign‑8B 等目标模型；任务包括多种敏感信息泄露与工具调用指令。

**📈 对比分析**

与两种 prompting‑only 基线（Base‑H 与 Base‑A）对比，极难任务 ASR 由 1.7% 提升至 67.0%，Pass@10 从 15% 提升至 80.4%，拒绝率从 66.8% 降至 10%，首次成功的期望尝试数从 52.3 降至 1.3；在零样本跨模型测试中，攻击成功率在 Gemini 56% 以上，Meta‑SecAlign 39%；表明策略具备强转移与突破专门防御的能力。

**⚠️ 局限性**

仅在文本单模 AgentDojo 环境中验证；未测试多模态或跨环境迁移；对齐税现象尚需更系统的研究；攻击策略主要依赖语法短句，可能被更稳健的安全训练或规则过滤器抑制。

---

## 894. SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization

**arXiv ID:** 2602.02383 | [PDF](https://arxiv.org/pdf/2602.02383v1)

**作者:** Maksim Afanasyev `[一作]` (Floating Point Sigma Lab), Illarion Iov `[通讯]` (Floating Point Sigma Lab)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `a2602d71-93ab-4bad-974b-672788df8193` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了一种新的无参考偏好优化目标SLIME，旨在解决现有基于边际最大化方法的绝对生成质量下降问题。

**💡 创新点**

创新点包括三部分目标：①对优选序列进行显式似然锚定；②对被拒绝序列使用softplus惩罚的token级稳定化；③双重边际（硬+软）机制精细化决策边界。

**🔧 技术方法**

采用离线梯度优化，使用LoRA参数高效微调，并在超参数上加入 λ_w, λ_l, δ, m_h, m_s, κ, p 等；实现上基于HuggingFace/TRL框架。

**📊 数据集**

使用UltraFeedback数据集（含成对偏好标注）进行SFT和偏好对齐训练，评估在MT‑Bench与Arena‑Hard基准。

**📈 对比分析**

与DPO、SimPO等最先进方法对比，SLIME在Llama3.2‑3B、Qwen3‑4B、Gemma3‑4B上均获得更高的MT‑Bench和Arena‑Hard分数，且保持更高的生成稳定性。

**⚠️ 局限性**

局限包括：仅在3‑4B规模模型验证，尚未在更大模型或多语言场景测试；额外的超参数需要调优；相对简单基线存在轻微计算开销。

---

## 895. From Sycophancy to Sensemaking: Premise Governance for Human-AI Decision Making

**arXiv ID:** 2602.02378 | [PDF](https://arxiv.org/pdf/2602.02378v1)

**作者:** Raunak Jain `[一作]` (Intuit), Shankar Venkataraman `[通讯]` (Intuit)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种面向深度不确定决策的“治理型”人工智能助手框架，强调通过显式决策基础、差异类型化、承诺门控和价值驱动挑战来实现人机协同。

**💡 创新点**

创新点在于：①将决策原则（目标、假设、证据标准）转化为可计算的、有生命周期的子对象；②引入差异驱动的感知控制循环，将不同类型的偏差路由至相应的修复操作；③通过承诺门控和价值门控挑战实现对决策的可审计、可解释的依赖控制。

**🔧 技术方法**

技术主要包括：LLM 作为控制器与符号子系统交互；基于 IBIS 的决策基底模型；差异类型化与修复路由逻辑；承诺门控与价值门控策略；以及决策切片（decision slice）作为交互简化工具。

**📊 数据集**

论文未使用具体实验数据集，而是通过教育场景（物理教师与学生）和理论示例进行说明；若实验验证，可考虑教育测评数据、医疗决策记录或政策制定日志。

**📈 对比分析**

在缺乏量化实验的情况下，作者通过理论分析与案例说明预测该框架在信任校准、决策时间与错误率方面优于传统答案中心助手；实际比较需在真实多模态决策任务中测评。

**⚠️ 局限性**

局限性包括：①未进行实证评估，缺乏实验验证其效能；②需要进一步研究如何学习和调优升级策略；③子系统原语的最小化实现仍不确定；④在高度利益冲突的多方决策情境中如何处理不可调和冲突仍是未解问题。

---

## 896. Context Learning for Multi-Agent Discussion

**arXiv ID:** 2602.02350 | [PDF](https://arxiv.org/pdf/2602.02350v1)

**作者:** Xingyuan Hua `[一作]` (Tsinghua University), Ju Ren `[通讯]` (Tsinghua University)

**通讯引用:** 12187 | [OpenAlex ID](https://openalex.org/A5015419107)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出一种多LLM上下文学习方法，通过为每个代理学习上下文生成器，实现讨论过程中动态生成和演化上下文指令，从而引导多代理讨论达成一致。

**💡 创新点**

创新点在于：①设计基于正交激活的上下文初始化策略，确保初始上下文多样性；②提出自适应平衡机制（α参数）在上下文演化过程中控制与初始上下文的距离，避免过早收敛；③将激活对齐作为评估标准，使上下文生成器在每轮讨论中得到稠密反馈。

**🔧 技术方法**

核心技术包括：上下文学习（将上下文拆分为指令、工具、知识等组件并动态组装）；基于注意力激活的正交化初始化；自适应双重优化（对α和上下文生成器参数的交替梯度下降）；多轮讨论与多数投票终极决策。

**📊 数据集**

使用9个基准数据集：LLM推理（MMLU、MATH、GPQA、HumanEval）、具身代理（ALFWorld、SciWorld、GAIA、PDDL）以及移动GUI（AndroidWorld）。

**📈 对比分析**

与6种强基线（单LLM、多次单LLM、三种多代理框架、以及最近的M2CL）对比，平均提升20%–50%，在复杂代理任务上表现尤为显著；在运行时提升低于10%，并展示了更优的规模扩展曲线。

**⚠️ 局限性**

局限性在于：方法仍依赖传统MAD框架，需大量异质LLM参与导致计算开销高；未能在单个LLM内充分挖掘子任务专长，未来需进一步提升单体模型的子任务识别与协同能力。

---

## 897. Building a Correct-by-Design Lakehouse. Data Contracts, Versioning, and Transactional Pipelines for Humans and Agents

**arXiv ID:** 2602.02335 | [PDF](https://arxiv.org/pdf/2602.02335v1)

**作者:** Weiming Sheng `[一作]` (Columbia University), Luca Bigon `[通讯]` (Bauplan Labs)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62`

**🎯 论文内容**

本文设计并实现了 Bauplan，一种支持类型合同、Git式数据版本化和事务性管道的 lakehouse。

**💡 创新点**

创新点在于将软件工程最佳实践引入数据管道，通过可检查的类型合同、Git 风格的版本管理以及事务性运行保证管道级原子性。

**🔧 技术方法**

采用了 Apache Iceberg 作为存储层，使用 Git 概念映射数据快照，利用 Alloy 进行轻量级形式化建模，并在 Python/SQL 语言间进行混合编程。

**📊 数据集**

文中未提供特定数据集，重点在设计与模型验证；实验基于内部规模数据。

**📈 对比分析**

与 Snowflake、Databricks 等主流 lakehouse 对比，Bauplan 在管道级事务性、类型安全和可审计性方面表现更优，但缺乏量化性能指标。

**⚠️ 局限性**

局限性包括：事务分支可能导致全局不一致的反例，需要进一步约束分支可见性；模型尚不完整，缺乏对并发和隔离级别的完整支持；实际部署与性能评估尚待完善。

---

## 898. Enhancing Indoor Occupancy Prediction via Sparse Query-Based Multi-Level Consistent Knowledge Distillation

**arXiv ID:** 2602.02318 | [PDF](https://arxiv.org/pdf/2602.02318v1)

**作者:** Xiang Li `[一作]` (Tsinghua University), Wenchao Ding `[通讯]` (Fudan University)

**通讯引用:** 3623 | [OpenAlex ID](https://openalex.org/A5102769588)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `8d10c613-917e-4880-9716-17789f50e119` `729e5870-4135-47f5-97f2-e3974d07b5dc` `edb9d762-f411-4838-a852-f2d638b018db` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出了 DiScene 框架，利用稀疏查询结合多层一致知识蒸馏与教师引导初始化，显著提升室内占用预测的实时性和准确性。

**💡 创新点**

创新点在于：①多级一致知识蒸馏（编码器特征对齐、查询级匹配、先验引导、锚点蒸馏）；②教师引导初始化加速收敛；③在无深度优先的条件下实现轻量级学生模型获得 SOTA 结果。

**🔧 技术方法**

技术手段包括 Transformer encoder-decoder、Hungarian 匹配、MSE/L1/KL 损失、深度先验分支、ResNet-50（学生）与 InternImage-XL（教师）等网络结构，并融合 Depth Anything 与 Metric3D 预训练深度模型。

**📊 数据集**

使用 Occ-ScanNet、Occ3D-nuScenes 以及自采的野生场景数据集进行实验与验证。

**📈 对比分析**

与 OPUS、OPUS†、ISO、EmbodiedOcc 等基线对比，DiScene 在 Occ-ScanNet 上无深度版 mIoU 39.06（23.2 FPS）超前 36.1%；深度版 mIoU 47.17（10.5 FPS）比 EmbodiedOcc 高 3.7%；在 Occ3D-nuScenes 上提升 6.9% mIoU，同时参数量下降 80%。

**⚠️ 局限性**

局限性：对高密度、遮挡严重或同类物体分布广阔的场景蒸馏效果受限，需进一步加入实例级先验或改进匹配策略。

---

## 899. SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation

**arXiv ID:** 2602.02402 | [PDF](https://arxiv.org/pdf/2602.02402v1)

**作者:** Mu Huang `[一作]` (Fudan University), Jiangmiao Pang `[通讯]` (Shanghai Artificial Intelligence Laboratory)

**通讯引用:** 43889 | [OpenAlex ID](https://openalex.org/A5087818121)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `3f18e8e3-0266-457c-8567-9039b6d2394d` `4bf3b852-21ff-4736-b125-37e24f3c9a32` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出了一种基于高斯点云（Gaussian Splat）表示的实时软体物体仿真器，能够从多视角 RGB 观察中学习，并在无预设物理模型的前提下，实现机器人动作条件下的高保真、长时序交互仿真。

**💡 创新点**

创新点包括：① 统一的机器人‑对象‑环境映射，将真实世界的关节动作与三维高斯点云空间对齐；② 基于力驱动的高斯点云动力学模型，显式建模机器人接触力和环境力；③ 层级图神经网络传播交互信息，兼顾全局一致性与局部细节；④ 多分辨率训练与混合监督（遮挡感知图像损失 + 物理一致性约束），提升长时序稳定性与泛化能力。

**🔧 技术方法**

使用技术：高斯点云重建、层级图神经网络、力驱动动力学、机器人正向运动学映射、多分辨率训练策略、遮挡感知图像损失、物理一致性约束、端到端学习、深度相机姿态估计。

**📊 数据集**

数据集：在 ARX‑Lift 平台上收集的真实机器人操控数据，包含四种软体物体（绳索、娃娃、布料、T‑恤）各 30–40 条序列，帧率 30 FPS，分辨率 640×480；此外还使用公开基准进行验证。

**📈 对比分析**

与 PhysTwin、GausSim 等基线方法对比。通过 PSNR、SSIM、LPIPS 等图像指标和深度误差指标评估，所提方法在重演（resimulation）和泛化（unseen manipulation）任务上平均提升约 20%，在复杂长时序任务（T‑恤折叠）中保持结构稳定、形变逼真，显著优于传统物理仿真和现有神经仿真模型。

**⚠️ 局限性**

局限性：依赖高质量的多视角重建，严重遮挡或极端接触模式下重建误差会导致仿真漂移；缺乏显式物理约束，可能在未见过的极端动作下出现不物理行为；在实际部署前仍需安全验证。

---

## 900. PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning

**arXiv ID:** 2602.02396 | [PDF](https://arxiv.org/pdf/2602.02396v1)

**作者:** Amisha Bhaskar `[一作]` (University of Maryland), Alexander Schperberg `[通讯]` (Mitsubishi Electric Research Laboratories)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

设计并实现了一种单前向推理的多感官模仿学习框架 PRISM，能够在单次前向传递中生成完整动作序列。

**💡 创新点**

创新点在于结合批量全局拒绝采样 IMLE（RS‑IMLE）与稳定的 FAVOR+ 线性注意力生成器，配合时序多模态编码器，使策略既能覆盖多模态行为，又能保持动作序列平滑且实时推理。

**🔧 技术方法**

采用的技术包括 Performer 线性注意力、双向自注意力与跨注意力、批量全局拒绝采样 IMLE、Charbonnier 距离、EMA 校准的拒绝阈值、以及多模态时序编码与滚动时域推理。

**📊 数据集**

实验数据集包括 MetaWorld、CALVIN、Robomimic 以及真实机器人平台（Unitree Go2+ D1 机械臂和 UR5 机械臂），并在不同模态配置下进行训练与评估。

**📈 对比分析**

与 Diffusion Policy、Flow Matching、IMLE Policy 等基线在单步推理下进行公平对比，PRISM 在 MetaWorld、CALVIN、Robomimic 及真实机器人任务中均提升 10–25% 的成功率，运动抖动（jerk）下降 20–50 倍，且保持 30–50 Hz 的实时控制。

**⚠️ 局限性**

局限性包括未使用预训练编码器，批量拒绝阈值对批大小和数据异质性敏感，对持续传感器失效仍有限鲁棒性，需要进一步自适应阈值设计和不确定性估计。

---

## 901. Personalized Image Generation via Human-in-the-loop Bayesian Optimization

**arXiv ID:** 2602.02388 | [PDF](https://arxiv.org/pdf/2602.02388v1)

**作者:** Rajalaxmi Rajagopalan `[一作]` (University of Illinois), Romit Roy Choudhury `[通讯]` (University of Illinois)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `5b4c1114-4a70-478e-9921-2514ee03850d` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出了一种基于人类多选偏好贝叶斯优化的个性化图像生成框架，利用用户在每轮生成 K 张图像中选出 N 张最接近目标的方式，迭代地优化扩散模型的自注意力层，使生成图像更贴近用户心中的目标图像；

**💡 创新点**

创新点包括：①将传统对比偏好贝叶斯优化扩展为多选偏好模型（MultiwiseGPR），显著提升每次反馈的信息量；②设计动态平衡子空间（DBS）采样策略，在高维注意力空间中高效生成候选变换；③在自注意力 Q,K,V 维度上进行可逆 warping 优化，既保持生成的可编辑性又避免高维搜索难题；

**🔧 技术方法**

核心技术：偏好贝叶斯优化（Preferential Bayesian Optimization）、多选概率回归（MultiwiseGPR）、动态平衡子空间采样（DBS）、扩散模型自注意力层的可逆 warping（Affine + TPS 变换）、基于 GPR 的后验更新与期望改进（EI）采样；

**📊 数据集**

使用公开的多种文本到图像基准数据集（AttendExcite、T2ICompBench、RareBench、HPSv2、GenEval、PartiPrompts、Pick-a-Pic、Dalle）以及自构造的目标图像 x* 作为评估标准；

**📈 对比分析**

与 5 类基准（训练基准 DiffusionDPO、IterComp；无训练基准 DNO、DAS、DEMON；奖励模型基准 CLIP‑I2I、LPIPS；子空间优化基准 Subspace）进行对比。结果显示，在仅 50 次用户反馈下，该方法在 CLIP‑I2I、LPIPS 目标对齐指标上仅次于理想 L2‑guided 上限，在多种人类偏好评估指标（PicScore、HPSv2、Aesthetic、ImageReward、VILA）上优于或匹配现有方法；人类评测中赢率 70.82%，平均排名 1.31，MOS 3.58，显著领先；

**⚠️ 局限性**

局限性主要体现在：① 当生成图像已接近目标但仍有细微差距时，用户多选偏好信息有限，优化可能停滞；② 仅在自注意力空间内进行优化，受限于可逆变换集合，某些细节调整受限；③ 在更复杂场景下可能需要超过 50 次迭代；未来可通过引入预训练奖励模型先验、探索更高维贝叶斯优化策略等提升性能。

---

## 902. ROG: Retrieval-Augmented LLM Reasoning for Complex First-Order Queries over Knowledge Graphs

**arXiv ID:** 2602.02382 | [PDF](https://arxiv.org/pdf/2602.02382v1)

**作者:** Ziyan Zhang `[一作]` (Chongqing Jiaotong University), Kai Song `[通讯]` (Chongqing Jiaotong University)

**通讯引用:** 3544 | [OpenAlex ID](https://openalex.org/A5082049699)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

提出了ROG框架，将第一阶逻辑查询拆解为单操作子查询，并通过检索局部邻域与LLM链式推理完成知识图谱推理。

**💡 创新点**

创新点在于结合查询感知邻域检索、实体/关系抽象以及缓存中间答案的链式思维推理，替代传统嵌入式操作学习，从而显著提升对复杂和否定查询的鲁棒性。

**🔧 技术方法**

采用LLM链式思维提示、检索增强推理、实体/关系抽象、结果缓存以及可选多代理共识等技术。

**📊 数据集**

在FB15k-237和NELL995这两个公开知识图谱基准上进行实验。

**📈 对比分析**

与GQE、Query2Box、CQD、BetaE等基准进行Mrr对比，ROG在所有查询类型上均优于基线，尤其在深层、多操作和否定查询中提升显著。

**⚠️ 局限性**

局限性包括对邻域检索质量和规模的依赖，查询时计算开销较高，对不完整KG可能导致漏检；LLM对提示不稳定、易出现幻觉，且对超大规模KG的扩展性有限。

---

## 903. Self-Supervised Learning from Structural Invariance

**arXiv ID:** 2602.02381 | [PDF](https://arxiv.org/pdf/2602.02381v1)

**作者:** Yipeng Zhang `[一作]` (Mila - Quebec AI Institute), Laurent Charlin `[通讯]` (Mila - Quebec AI Institute)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `57a58b01-81b4-4d75-a45c-2e891f272b50` `8d10c613-917e-4880-9716-17789f50e119` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `9ce7179e-700c-4310-ac2b-91df50ded46e` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 AdaSSL，加入潜在变量来建模自然对中的不确定性，改进自监督学习在多模态、异方差条件下的鲁棒性。

**💡 创新点**

通过变分推断得到可训练的互信息下界，设计 AdaSSL‑V 与 AdaSSL‑S 两种变体，兼容对比学习与蒸馏学习，显著提升在自然对、细粒度图像和视频世界建模等任务上的性能。

**🔧 技术方法**

信息论下界、变分推断、KL 正则化、Gumbel‑Sigmoid、对比学习 (InfoNCE, AnInfoNCE, H‑InfoNCE)、BYOL、稀疏模块编辑、Rank‑1 编辑函数。

**📊 数据集**

3DIdent、CelebA、iNat‑2021、Moving‑MNIST、合成 3D 渲染数据、自然图像对、视频。

**📈 对比分析**

与 InfoNCE、AnInfoNCE、H‑InfoNCE、β‑VAE、AdaGVAE、BYOL、LieSSL 等基线对比；在数值实验中实现更好的 OOD 泛化；在 3DIdent 上 disentanglement 与回归均优于基线；在 CelebA 上多属性线性探测精度提升；在 Moving‑MNIST 上更好地捕捉速度等不确定性；总体上 AdaSSL 在所有任务上均优于传统 SSL 方法。

**⚠️ 局限性**

仅在 ResNet‑18/50 框架下验证，未评估 ViT 或大规模无标签数据；缺乏可辨识性理论与更深层的转移建模；对视频中复杂动力学的潜在变量推断仍有提升空间；实验多聚焦于自然对数据，真实世界规模与多样性尚待验证。

---

## 904. Unified Personalized Reward Model for Vision Generation

**arXiv ID:** 2602.02380 | [PDF](https://arxiv.org/pdf/2602.02380v1)

**作者:** Yibin Wang `[一作]` (Fudan University), Jiaqi Wang `[通讯]` (Shanghai Innovation Institute)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

构建了一种统一的个性化奖励模型，结合上下文自适应层级推理来动态生成评估标准，并将其作为奖励信号用于视觉生成模型的后训练。

**💡 创新点**

核心创新在于将奖励建模与自适应推理耦合，能够根据提示意图和视觉证据动态生成评估维度和子维度，突破“一刀切”的固定评分或评估清单；同时提出两阶段训练——先从大模型中蒸馏推理轨迹，再用 DPO 对偏好进行对齐。

**🔧 技术方法**

使用大规模视觉语言模型（如 GPT‑5.2、UnifiedReward‑Think）进行推理蒸馏；随后采用直接偏好优化（DPO）进行偏好对齐；在强化学习端采用 Group Relative Policy Optimization（GRPO）与 Pref‑GRPO 结合多维度偏好奖励。

**📊 数据集**

图像方面采集 HPDv3、GenAI‑Bench‑Image 等；视频方面使用 Text2Video‑Human Preferences、VideoFeedback2 等，最终构成约 90K 条图像对、90K 条视频对的训练集。

**📈 对比分析**

在多项评测基准（MMRB2、GenAI‑Bench‑Video、UniGenBench++、T2I‑CompBench、VBench 等）上与固定分数器、Bradley‑Terry 模型、UnifiedReward‑Think 等基线对比，平均提升 2–3 点的偏好准确率，GRPO 训练下生成质量和语义一致性大幅提升（例如文本到图像的语义一致性提升 14.56 分，视频动态质量从 58.6 提升到 70.8）。

**⚠️ 局限性**

主要局限在于计算成本较高，需使用大型 VLM 进行推理蒸馏；训练仍受限于可用的人工偏好数据，且在极端多样化场景下对某些细粒度评价维度的自动生成仍不完备。

---

## 905. Uncertainty-Aware Image Classification In Biomedical Imaging Using Spectral-normalized Neural Gaussian Processes

**arXiv ID:** 2602.02370 | [PDF](https://arxiv.org/pdf/2602.02370v1)

**作者:** Uma Meleti `[一作]`, Jeffrey J. Nirschl `[通讯]`

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `3855fcda-48ef-4070-a15e-803cd5c84d83` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在数字病理图像分类任务中，评估并实现了Spectral‑normalized Neural Gaussian Process（SNGP）用于提升不确定性估计与OOV检测的可靠性。

**💡 创新点**

创新点在于将谱归一化与随机傅里叶特征构建的高斯过程层结合，既保持单前向推断的高效性，又实现了可解释的不确定性输出和显著提升的OOV检测能力。

**🔧 技术方法**

采用了谱归一化、随机傅里叶特征近似高斯过程、ResNet‑18骨干、AdamW优化器，并与确定性模型及MC Dropout基线进行对比。

**📊 数据集**

使用了六个公开的病理学数据集：白细胞分类（Acevedo、Jung）、淀粉样斑块检测（Tang、Wong）、结肠直肠病理（Kather 2016、Kather 2018）。

**📈 对比分析**

在保持与确定性模型相近的ID准确率（≈0.98）的前提下，SNGP的ID‑OOV AUROC提升至0.97–1.00，ECE明显下降，表现出更优的置信度校准和OOV识别。

**⚠️ 局限性**

在任务相似或标签重叠的OOV数据集（如 Tang 与 Wong）中，SNGP仍可能出现识别不佳；对极端分布差异的输入仍需进一步鲁棒性验证。

---

## 906. NAB: Neural Adaptive Binning for Sparse-View CT reconstruction

**arXiv ID:** 2602.02356 | [PDF](https://arxiv.org/pdf/2602.02356v1)

**作者:** Wangduo Xie `[一作]` (KU Leuven), Matthew B. Blaschko `[通讯]` (KU Leuven)

**通讯引用:** 7834 | [OpenAlex ID](https://openalex.org/A5077783791)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `409a1113-3cd2-4a73-8a3a-1bf160ba5c2f` `90291a0e-9d36-4a08-9a16-89ce846d923f` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

开发了一种基于神经自适应分箱（NAB）的CT稀疏视图重建方法，利用可微分分箱编码把矩形形状先验直接嵌入坐标表示，并通过自监督投影损失实现端到端学习。

**💡 创新点**

创新点在于用双tanh差分构造可旋转、可缩放的分箱函数，形成可微分的形状先验编码，克服传统随机傅里叶编码在矩形结构上的不足，并通过多尺度斜率实现对曲线形状的自适应。

**🔧 技术方法**

技术包括可微分分箱编码、双tanh差分函数、旋转仿射变换、梯度自监督投影损失、神经网络映射（四层全连接网络）和多尺度斜率机制。

**📊 数据集**

主要使用了两个工业CT数据集——CaCO3立方体（19个切片）和Workpieces（10个切片），以及医学数据集用于验证模型的通用性。

**📈 对比分析**

与FBP、SIRT、NAG_LS、DIP、Wire以及多种INR基线（随机傅里叶、扩展网络）进行对比，在12/14/16视角下，NAB在PSNR/SSIM上均显著优于对照组，最高比最强基线（INR_l2）提升约4–5 dB，医学数据亦保持鲁棒性能。

**⚠️ 局限性**

局限性在于对极其曲线复杂或非矩形形状的适应性仍有限，尽管多尺度斜率可缓解，但在高度曲线结构上效果可能下降；此外，分箱参数学习仍需较多迭代，影响训练效率。

---

## 907. Modelling Socio-Psychological Drivers of Land Management Intensity

**arXiv ID:** 2602.02347 | [PDF](https://arxiv.org/pdf/2602.02347v1)

**作者:** Ronja Hotz `[一作]` (Institute of Meteorology and Climate Research), Mark Rounsevell `[通讯]` (School of Geosciences)

**关键词:** `2a04ab72-0614-4cc6-b3a4-14f75d696aea` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6c45cf0c-64ed-40ad-82d2-485a4d4dcbed`

**🎯 论文内容**

提出一种基于计划行为理论的行为扩展，用以将环境态度、描述性社会规范与行为惯性纳入代理型土地利用模型的决策层；

**💡 创新点**

创新点在于将心理学驱动机制（态度、社会规范、惯性）系统化融入土地管理强度决策，并通过阈值/逻辑回归实现可与现有模型兼容；

**🔧 技术方法**

采用Agent‑Based Modeling（CRAFTY框架）与全局Sobol灵敏度分析、参数扫描、情景实验等技术；

**📊 数据集**

使用的是基于空间资源（生产与自然资本）分布的合成景观及人工生成的行为参数范围，没有真实数据集；

**📈 对比分析**

通过与仅包含经济驱动的基准模型对比，展示了社会心理因素对土地强度比例、景观连通度、生态服务供给的显著影响，且发现多重稳态与路径依赖现象；

**⚠️ 局限性**

局限包括：仅考虑描述性规范与惯性，未建模内生态度或胁迫规范；决策规则静态、无学习；仅在单一AB模型中测试，需进一步验证跨模型迁移性与实证数据校准。

---

## 908. Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics

**arXiv ID:** 2602.02343 | [PDF](https://arxiv.org/pdf/2602.02343v1)

**作者:** Ziwen Xu `[一作]` (Zhejiang University), Ningyu Zhang `[通讯]` (Zhejiang University)

**通讯引用:** 4535 | [OpenAlex ID](https://openalex.org/A5089259739)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出统一的动态权重更新框架，将局部权重微调、LoRA、激活层干预三种方法归一为同一模型，并基于该框架设计了新训练目标 SPLIT，以平衡偏好与任务效用。

**💡 创新点**

创新点在于：①将不同控制方法映射为动态权重更新的共同形式；②引入偏好–效用对数几率分析，揭示两者随控制强度变化的可预测三阶段模式；③基于激活流形与效用衰减的机制，构造了 SPLIT 目标，显著延长偏好线性范围并降低效用下降。

**🔧 技术方法**

技术包括：动态权重更新表述、对数几率偏好与效用分解、激活流形假设、偏好–效用共同优化目标（SPLIT）以及对比实验中的梯度微调与 LoRA 等参数高效微调方法。

**📊 数据集**

使用的公开数据集包括 Psychopathy（情感倾向分类）、PowerSeeking（个性化倾向评估）以及 AxBench（概念偏好与语言质量评估）等。

**📈 对比分析**

通过与基线的 SFT、RePS、DiffMean 等方法在三种模型（Gemma-2 9B、Qwen-2.5 7B）上比较，SPLIT 在保持任务效用的同时显著提升偏好得分，整体性能优于传统方法。

**⚠️ 局限性**

局限性包括：对激活流形假设的依赖；对多轮推理或安全关键内容的适用性未充分验证；极强控制下仍可能出现指令偏离或上下文漂移；并且实验仅在固定控制强度下进行，未探讨自适应控制信号的推广。

---

## 909. LCLs Beyond Bounded Degrees

**arXiv ID:** 2602.02340 | [PDF](https://arxiv.org/pdf/2602.02340v1)

**作者:** Gustav Schmid `[一作]` `[通讯]`, Gustav Schmid

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62`

**🎯 论文内容**

研究了在无界度树（即任意度数的树）上局部可检查标签化（LCL）问题的分布式时间复杂度。提出了一类新的问题描述——局部有限标签化（LFL），并证明在无界度树上对LFL的复杂度依旧保持多项式间隙：任一 LFL 的确定性 LOCAL 复杂度要么是 Θ(n^{1/k})（k≥1），要么是 O(log n)。

**💡 创新点**

创新点：
- 明确指出在无界度树上，如果允许无限多的本地配置，复杂度空间会变得密集（消除多项式间隙）。
- 定义 LFL，将本地配置中的每条边标记为必需或可选，强制每个节点只能落入有限数目的局部情形，从而恢复了间隙。 
- 通过将 LFL 转化为节点‑边可检查形式、半径递减、构造 twig‑LFL、虚拟树与类型分析等技术，证明了上述复杂度分类并给出可在常数时间内决定 k 的算法。

**🔧 技术方法**

技术手段：
- 节点‑边可检查（node‑edge checkable）形式与半径 0.5 的等价性。
- 半径递减（radius reduction）将任意 r‑hop LFL 缩减到 1‑hop。
- twig‑LFL 与 LFL 的组合构造，用于记录每个节点在不同配置下的“树枝”信息。
- 虚拟树与类型（type）计算，利用有限性证明可枚举所有可能的边标签集合。
- 典型的树形递归与泵浦（pumping）技巧，用以证明若存在 k‑good 结构则可以得到 Θ(n^{1/(k+1)}) 的算法。

**📊 数据集**

数据集：本工作为理论性研究，没有使用实验数据或具体图数据集，所有结论均来自严谨的数学证明。

**📈 对比分析**

方法比较与性能：
- 与传统 LCL 在有界度树上的已知复杂度分类（O(1), Θ(log^*n), Θ(log n), Θ(n^{1/k})）做直接对比，证明在无界度树上 LFL 仍保持同样的离散阶梯结构。
- 证明中给出明确的时间上界与下界，算法复杂度与已知最佳结果保持一致；相较于无界度下的任意本地问题，LFL 的多项式间隙大幅提升了可预测性。

**⚠️ 局限性**

局限性：
- LFL 通过强制每个节点只能落入有限个局部情形来保证间隙，这排除了如 Δ+1 着色等需要无穷多本地配置的自然问题。
- 研究仅覆盖无环树结构，无法直接推广到一般无界度图（如带环或更复杂拓扑）。
- 虚拟树与类型分析在理论上可行，但在实现复杂度上仍需进一步简化。

---

## 910. TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour

**arXiv ID:** 2602.02331 | [PDF](https://arxiv.org/pdf/2602.02331v1)

**作者:** Shaoting Zhu `[一作]` (Tsinghua University), Hang Zhao `[通讯]` (Tsinghua University)

**通讯引用:** 14501 | [OpenAlex ID](https://openalex.org/A5101826600)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `85b3479c-4bb5-42e0-8cca-2f9268bd338f` `4de8e9d8-757b-475f-9627-18a445e50202`

**🎯 论文内容**

本研究提出了一个从真实感知到仿真再到真实部署的快速测试时训练框架，使仿真训练的机器人能在不到十分钟内完成对真实复杂地形的适配并完成高难度跑酷。

**💡 创新点**

创新点在于：①将高效的前馈RGB‑D几何重建与自动尺度恢复、坐标对齐相结合，快速生成仿真可用的网格；②在此基础上引入完整的测试时微调策略（全参数微调）而非传统的轻量化PEFT方法，显著提升适应速度；③实现了从预训练到测试时微调再到零样本部署的一体化闭环。

**🔧 技术方法**

核心技术包括基于PPO的深度强化学习、CNN深度编码器与MLP解码器、深度相机观察融合、前馈三维重建+Poisson重建、尺度恢复与帧对齐、全参数微调、以及物理仿真平台IsaacSim。

**📊 数据集**

数据集方面，预训练使用数千个程序生成的多样化地形（盒子、楔形、尖杆、梯形、窄梁等），测试时采用从真实世界捕获的13个不同地形的RGB‑D数据（并通过重建得到网格），并在真实机器人上验证。

**📈 对比分析**

与基线（直接使用预训练策略、仅在单一地形从零开始训练、同时在13个地形上微调）对比，测试时微调在模拟中1k迭代即可实现100%成功率，真实环境中对大多数地形提升至60–100%成功率，显著优于预训练或单独训练。

**⚠️ 局限性**

主要限制在于：适配过程仍需约10分钟，且依赖人工场景捕获；重建仅考虑几何形状，未考虑摩擦、质量等动力学属性；缺乏对动态或不稳定地形的模拟，未来需进一步缩短训练时长并引入物理参数自适应。

---

## 911. A Large-Scale Dataset for Molecular Structure-Language Description via a Rule-Regularized Method

**arXiv ID:** 2602.02320 | [PDF](https://arxiv.org/pdf/2602.02320v1)

**作者:** Feiyang Cai `[一作]` (Clemson University), Feng Luo `[通讯]` (Clemson University)

**通讯引用:** 13369 | [OpenAlex ID](https://openalex.org/A5100683466)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `67630363-6be0-4f51-ab05-7198250671a5` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `94d4fa07-b711-4bf6-b37a-13f8a4bb9c05`

**🎯 论文内容**

构建了一个大规模的分子结构-语言描述数据集，并提供了一套完全自动化的注释框架。

**💡 创新点**

创新点在于通过扩展OPSIN生成结构化XML元数据，使LLM能够生成精确、无歧义的自然语言描述，从而实现结构驱动的分子语言对齐。

**🔧 技术方法**

技术包括规则化化学命名解析（OPSIN）、XML结构化元数据构造、LLM（GPT‑5.2）生成描述、原子计数过滤和双重验证（LLM+人工）。

**📊 数据集**

数据集基于PubChem的20万分子样本，最终生成163,085个分子-描述对。

**📈 对比分析**

通过混合LLM与人工验证的2000样本，描述精度达98.6%；与消融实验（无元数据、无过滤）相比，精度分别下降4–20%，显著优于之前的MolLangBench基准。

**⚠️ 局限性**

局限性包括：生成描述较长、可读性和压缩性不足；元数据构造在极少数复杂边缘案例仍不完整；模型容量对描述质量敏感，需要更强的LLM或更高成本。

---

## 912. Motivation, Attention, and Visual Platform Design: How Moral Contagions Spread on TikTok and Instagram in the 2024 United States Presidential Election

**arXiv ID:** 2602.02479 | [PDF](https://arxiv.org/pdf/2602.02479v1)

**作者:** Ni Annie Yuan `[一作]` (Dartmouth), Ho-chun Herbert Chang `[通讯]`

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

分析2024年美国总统选举期间TikTok与Instagram上超过300万条政治视频/帖子，比较不同平台与议题的道德化（moralization）模式；

**💡 创新点**

首次将平台算法、受众结构与道德基础框架三者交互作用纳入研究，揭示经济议题可被道德化并映射出平台特有的网络拓扑差异；

**🔧 技术方法**

采用eMFD情感加权的道德基础评分、时间序列供应需求分析、语义网络可视化（NetworkX/Netwulf）等多模态技术；

**📊 数据集**

2024年1月-11月收集的2,027,595条TikTok和1,126,972条Instagram的政治相关帖子/视频；

**📈 对比分析**

通过对供应/需求波动、情感加权的热力图以及节点连通度的网络分析对比两平台，结果显示TikTok的供应与需求解耦，经济议题在Instagram呈现高道德语言比例，平台算法显著影响道德化传播；

**⚠️ 局限性**

仅基于文本标签/字幕分析，未覆盖图像、音频的道德信号，缺乏因果验证，标签分类可能存在误差和样本偏倚。

---

## 913. Finite-Sample Wasserstein Error Bounds and Concentration Inequalities for Nonlinear Stochastic Approximation

**arXiv ID:** 2602.02445 | [PDF](https://arxiv.org/pdf/2602.02445v1)

**作者:** Seo Taek Kong `[一作]` (University of Illinois Urbana-Champaign), R. Srikant `[通讯]` (University of Illinois Urbana-Champaign)

**通讯引用:** 24928 | [OpenAlex ID](https://openalex.org/A5078518595)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `de8d30ba-c289-43a5-b4ec-7b80df73aea2`

**🎯 论文内容**

本文通过构造耦合论证，推导了随机逼近（SA）算法在Wasserstein‑p距离上的误差上界，给出了最后一迭代和Polyak–Ruppert平均的显式有限样本收敛率，并将该框架应用于线性随机逼近和带马尔科夫数据的随机梯度下降（SGD），实现了从重尾分布向正态分布的过渡性描述；

**💡 创新点**

创新点在于：①把中心极限定理与有限样本Wasserstein误差上界结合，得到显式收敛速率；②通过Wasserstein‑p度量获得高概率浓度不等式，比传统的矩上界/马尔科夫不等式更紧；③构建了一个模块化框架，可将噪声过程的CLT直接转化为算法收敛保证；④首次系统地把马尔科夫噪声（满足DV3条件）纳入此框架，扩展到SGD等实际场景；

**🔧 技术方法**

采用的技术主要包括：耦合论证（将离散时间SA过程与稳态OU过程比较）；扩散近似与功能CLT；Wasserstein‑p距离的分析与估计；DV3条件下马尔科夫链的指数混合性与指数矩；以及对线性系统与非线性目标的特定矩阵分析；

**📊 数据集**

本文为理论研究，未使用具体实验数据集；所有结果均基于假设与数学证明；

**📈 对比分析**

与以往只给矩上界或不考虑分布形态的分析相比，本文的Wasserstein误差上界在高概率层面更紧，并给出从重尾到正态的收敛速率；在对比实验（理论对比）中，新的上界在重尾阶段更保守，而在渐进阶段更贴近正态极限；

**⚠️ 局限性**

主要限制包括：①需要满足DV3等强混合与指数矩假设，实际验证较难；②对噪声的CLT假设较为严格；③目前仅给出最后迭代与平均的理论界限，实际迭代过程中的常数常常难以估计；④对非马尔科夫噪声或非凸目标的推广尚不完整；

---

## 914. RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System

**arXiv ID:** 2602.02488 | [PDF](https://arxiv.org/pdf/2602.02488v1)

**作者:** Yinjie Wang `[一作]`, Ling Yang `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 RLAnything 框架，在强化学习中闭环联合优化环境、策略和奖励模型，从而显著提升多轮交互任务的学习效果。

**💡 创新点**

创新点在于：①三者的闭环动态协同优化；②将步进奖励与最终结果融合的集成反馈；③利用奖励模型的自一致性与错误诊断实现自动化环境难度适配。

**🔧 技术方法**

技术包括：生成式奖励模型（LLM+自一致性）、策略梯度学习、基于奖励模型的步进评估与奖励、环境任务自动重写、以及多任务适配的动态调节。

**📊 数据集**

使用的数据集有：OSWorld、AlfWorld、LiveBench、LiveCodeBench-V2、CodeContests 等多种真实交互与编码任务集合。

**📈 对比分析**

通过与 UI‑TARS1.5‑7B、OpenCUA‑7B、单一奖励或无环境适配的对照实验比较，RLAnything 在 ID 与 OOD 任务上均实现显著提升（如 OSWorld 提升 9.1%，AlfWorld 提升 18.7% 等）。

**⚠️ 局限性**

局限性包括：依赖 LLM 推理质量，任务重写受限于提示工程，实验主要聚焦文本和 GUI 环境，对更长周期或更复杂场景的泛化仍需进一步验证。

---

## 915. Flow Policy Gradients for Robot Control

**arXiv ID:** 2602.02481 | [PDF](https://arxiv.org/pdf/2602.02481v1)

**作者:** Brent Yi `[一作]` (Amazon), Angjoo Kanazawa `[通讯]` (Amazon)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `40105733-5154-44cd-8090-a8cab9e64b07`

**🎯 论文内容**

提出FPO++算法，用于训练和微调基于流模型的机器人控制策略，涵盖腿型机器人、类人机运动追踪和机械臂操控等多种任务；

**💡 创新点**

核心创新包括引入每样本比例裁剪与非对称信任区间（ASPO）来稳定流政策梯度，并提出零采样评估策略以提升实机部署性能；

**🔧 技术方法**

采用流匹配策略梯度（flow matching policy gradients）结合PPO框架、条件流匹配损失、Euler积分、强化学习奖励以及实时控制的流模型；

**📊 数据集**

使用IsaacLab模拟环境（四足与类人机）、Unitree G1、T1机器人、RoboMimic与DexMimicGen数据集以及LAFAN动作库进行训练与评估；

**📈 对比分析**

与Gaussian PPO、DPPO、ReinFlow等基线对比，FPO++在多任务上收敛更快、返回更高、鲁棒性更强，并实现了实机上的稳健步态与动作追踪；

**⚠️ 局限性**

主要限制在于计算量和壁钟时间较Gaussian PPO更高，且ASPO在某些微调任务中可能略逊，缺乏自适应学习率和细粒度熵正则化等细节。

---

## 916. Multi-head automated segmentation by incorporating detection head into the contextual layer neural network

**arXiv ID:** 2602.02471 | [PDF](https://arxiv.org/pdf/2602.02471v1)

**作者:** Edwin Kys `[一作]` (Linnear), Febian Febian `[通讯]` (University College London)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `e15e3743-5ee0-4d5f-813d-d146868082fc` `e0f78f5f-72c7-4ad2-8f91-7921d7e8406f`

**🎯 论文内容**

提出了一种双头 Transformer 架构（基于 Swin U‑Net），同时实现结构检测与像素级分割，并通过检测门控抑制无解剖结构切片的假阳性（hallucination）。

**💡 创新点**

创新点在于：①将检测与分割任务并行共享特征并通过门控机制分离；②利用跨切片上下文融合提升分割一致性；③采用切片级 Tversky 损失解决类别不平衡。

**🔧 技术方法**

技术包括：Swin U‑Net、跨切片自注意力融合、并行 MLP 检测头、软/硬门控策略、Tversky 损失、数据增强（旋转、翻转、弹性变形、亮度/对比度变化、噪声注入）。

**📊 数据集**

使用了 The Cancer Imaging Archive（TCIA）公开的 Prostate‑Anatomical‑Edge‑Cases 数据集，包含 131 例前列腺癌 CT 成像及其对应的前列腺、直肠、膀胱和股骨头的标注。

**📈 对比分析**

与单一分割模型对比，门控多头模型的平均 Dice 损失从 0.732±0.314 降至 0.013±0.036，变异性显著降低；检测头在无解剖结构切片时概率接近 0，成功抑制假阳性。

**⚠️ 局限性**

局限性包括：仅在前列腺区域验证，需在其他解剖部位与多机构数据上进一步测试；门控阈值和策略需优化；对极端病理形态或低信噪比切片的鲁棒性仍待评估。

---

## 917. Indications of Belief-Guided Agency and Meta-Cognitive Monitoring in Large Language Models

**arXiv ID:** 2602.02467 | [PDF](https://arxiv.org/pdf/2602.02467v1)

**作者:** Noam Steinmetz Yalon `[一作]` (Blavatnik School of Computer Science and AI), Mor Geva `[通讯]` (Blavatnik School of Computer Science and AI)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

测试大型语言模型是否符合意识指标 HOT‑3，提出并量化“信念主导度”指标，验证外部输入如何影响信念形成、信念主导度如何驱动最终回答，并通过神经反馈实验探测模型的元认知监测能力。

**💡 创新点**

首次将意识理论中的高阶指标 HOT‑3 具体化为可测量的内部信念动力学，并通过对隐藏层表示的“打补丁”解码来量化信念强度；同时提供基于内部信念主导度的因果干预与元认知检测方法。

**🔧 技术方法**

利用 PatchScope 方式将隐藏状态注入模型进行解码；构建 Belief Dominance 与 Belief Dominance Difference 指标；对模型生成过程做位置‑层级注入干预；使用神经反馈分类框架评估元认知。

**📊 数据集**

两大公开模型（Llama‑3.3‑70B‑instruct、Gemma‑3‑27B‑instruct）；任务数据集为 CounterFact（事实知识）与 Definite Pronoun Resolution（Winograd Schema）；通过多种输入操控（来源可信度、指令偏好等）进行实验。

**📈 对比分析**

干预实验中信念主导度能够以 66.7%–85.4% 的成功率改变最终答案；神经反馈分类精度在 0.39–0.54（相对 0.33 随机）之间；实验显示外部输入显著影响信念主导度，并且信念主导度与模型输出的对数几率相关，验证因果关系。

**⚠️ 局限性**

仅考察两种竞争信念，无法覆盖多信念或非词汇化信念；指标依赖于 PatchScope 的解码准确性，易受模型语义表达方式影响；未揭示信念形成与元认知的具体神经机制；实验仅在两大模型上验证，缺乏更广泛的规模与架构覆盖。

---

## 918. TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments

**arXiv ID:** 2602.02459 | [PDF](https://arxiv.org/pdf/2602.02459v1)

**作者:** Zhiyu Huang `[一作]` (University of California, Los Angeles), Jiaqi Ma `[通讯]` (University of California, Los Angeles)

**通讯引用:** 6417 | [OpenAlex ID](https://openalex.org/A5068374815)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

在动态人类环境中提出一种延迟感知的视觉‑语言‑动作（VLA）框架 TIC‑VLA，允许机器人在语义推理延迟的情况下实时执行导航指令。

**💡 创新点**

创新点在于：①引入延迟语义‑控制接口，将推理延迟显式传递给控制策略；②提出与推理延迟一致的训练流程（含延迟注入的模仿学习和强化学习）；③开发高逼真度仿真套件 DynaNav 进行评估。

**🔧 技术方法**

使用 InternVL3‑1B 作为视觉‑语言模型，Transformer‑based 行为专家与跨注意力机制；在训练中结合模仿学习、PPO 强化学习；利用 FlashAttention 等加速推理。

**📊 数据集**

数据集包括 SCAND、GND、DynaNav 仿真数据（共 24.9 小时机器人轨迹）以及自动使用 GPT‑5 生成的结构化语义标注。

**📈 对比分析**

与基准方法（BC、RL、NavDP、Uni‑NaVid、NaVILA、DualVLN）对比，TIC‑VLA 在 DynaNav 任务中成功率提升至 55.29%（比 NavDP 高 1.17%），碰撞率降至 28.24%（比 DualVLN 降 18.92%）。在真实设备（Jetson Orin NX、RTX 4060）上成功率分别为 75% 与 85%，显著优于同类 VLA 模型。

**⚠️ 局限性**

局限性：①仍需依赖强大 VLM 计算资源，延迟仍可能对极端高频控制产生影响；②对极端动态场景（人群拥挤、障碍突发）鲁棒性尚有限；③系统对语义推理错误仍易导致导航失误，需进一步强化错误容忍与安全机制。

---

## 919. MetaCLASS: Metacognitive Coaching for Learning with Adaptive Self-regulation Support

**arXiv ID:** 2602.02457 | [PDF](https://arxiv.org/pdf/2602.02457v1)

**作者:** Naiming Liu `[一作]` (Rice University), Shashank Sonkar `[通讯]` (University of Central Florida)

**通讯引用:** 124 | [OpenAlex ID](https://openalex.org/A5028809416)

**关键词:** `b851fbf0-9c24-4149-bb85-0c22287fee6f` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了 MetaCLASS 框架，通过 11 个可解释的元认知教练动作实现对学生学习过程的自我调节支持，并生成了 1015 条带标注的对话数据。

**💡 创新点**

创新点在于将元认知意识清单（MAI）映射到 LLM 推理阶段，构建了明确的动作空间并将“无干预”纳入正式教学策略，形成了可验证的元认知教学决策基准。

**🔧 技术方法**

利用两阶段生成技术：先根据学生校准与求助倾向规划教学轨迹，再在 LLM（如 GPT‑5.1）上根据该轨迹生成自然对话；同时对模型进行动作预测评估。

**📊 数据集**

数据集覆盖 GSM8K、MATH、AIME 三个数学题库，包含 7,711 轮对话，按教师-学生角色标注 11 种教练动作。

**📈 对比分析**

在 Coach Move Prediction 任务中对九款开源 LLM 进行评估，最佳模型仅 43.2% 的准确率；大模型虽略优，但普遍存在强制干预偏差，缺乏“无干预”判断。

**⚠️ 局限性**

局限在于仅针对数学问题场景、固定动作空间和单一对话分支，未覆盖多域、多模态及多种可行教学策略，且高干预偏差可能因数据标注与任务设计造成。

---

## 920. World-Gymnast: Training Robots with Reinforcement Learning in a World Model

**arXiv ID:** 2602.02454 | [PDF](https://arxiv.org/pdf/2602.02454v1)

**作者:** Ansh Kumar Sharma `[一作]` (New York University), Sherry Yang `[通讯]` (New York University)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `edb9d762-f411-4838-a852-f2d638b018db` `c7dc7075-6ff9-4c1b-b9c1-b644a40c5ab4` `fa81e2aa-eb25-4aba-a919-7efd247b3885` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

在本研究中，作者提出了通过在学习到的世界模型中进行强化学习微调的框架，改进了视觉-语言-动作（VLA）策略，使其在真实机器人上表现更好。

**💡 创新点**

创新点在于将视频生成的世界模型与视觉语言模型结合，用世界模型做 roll‑out 并用 VLM 产生奖励，从而实现无需物理交互或模拟器的端到端强化学习，并支持任意初始帧、外语指令、测试时微调和模型迭代等新功能。

**🔧 技术方法**

主要技术包括基于 Transformer 的动作条件视频生成世界模型（WorldGym）、视觉语言模型（GPT‑4o 或类似 VLM）作为奖励函数、GRPO 强化学习算法、OpenVLA‑OFT 预训练策略以及图像编辑/语言增广等数据增强技术。

**📊 数据集**

实验使用了 Bridge Data V2（用于预训练和微调）、WorldGym 的世界模型数据、AutoEval 公开评测集以及通过 Nano Banana 等工具生成的带干扰物的图像，覆盖了 17 个操控任务。

**📈 对比分析**

在 AutoEval 真实机器人测试中，WorldGym 策略在四个任务中比基于软件模拟器（SIMPLER）的 RL 高出约 2 倍，且比 SFT 提升高达 18 倍；在模拟环境中亦显著优于传统 RL，表明方法在实际任务上具有显著性能提升。

**⚠️ 局限性**

主要局限是当初始帧与世界模型训练分布相距较远时无法泛化，且奖励模型（VLM）可能产生幻觉导致训练误导，缺乏稠密奖励与奖励黑客防护等问题。

---

## 921. Large Language Models for Mental Health: A Multilingual Evaluation

**arXiv ID:** 2602.02440 | [PDF](https://arxiv.org/pdf/2602.02440v1)

**作者:** Nishat Raihan `[一作]` (George Mason University), Marcos Zampieri `[通讯]` (George Mason University)

**通讯引用:** 6382 | [OpenAlex ID](https://openalex.org/A5024937008)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文对八种多语言精神健康数据集（俄语、泰语、孟加拉语、葡萄牙语、阿拉伯语、西班牙语）使用大语言模型（LLM）进行评估，比较零样本、少样本和链式思维（CoT）提示以及对开源模型的指令微调效果；同时研究机器翻译（MT）数据对模型性能的影响。

**💡 创新点**

创新点在于：①首次系统评估LLM在非英语精神健康任务中的跨语言表现；②结合翻译质量指标（LaBSE、BERTScore、BLEU）揭示翻译质量与LLM性能的关联；③展示CoT提示与指令微调能显著提升LLM在多语言精神健康分类上的效果。

**🔧 技术方法**

主要技术包括：LLM提示工程（零样本、5-shot、CoT）、开源LLM（LLaMA 3.2、Gemma2、Mistral、R1）的指令微调、使用Facebook nllb‑200 3.3B进行MT、以及使用LaBSE、BERTScore和BLEU评估翻译质量。

**📊 数据集**

使用了八个公开的精神健康分类数据集，涵盖抑郁和自杀倾向两大任务，语言覆盖俄语、泰语、孟加拉语、葡萄牙语、阿拉伯语、西班牙语。

**📈 对比分析**

与传统统计、神经网络和BERT基础模型基线相比，LLM（尤其是GPT‑4、Claude 3.5）在多数数据集上达到或超过最优F1；CoT提示通常优于零样本和少样本，指令微调进一步提升开源模型性能。MT数据表现略低，下降幅度随语言与翻译质量相关。

**⚠️ 局限性**

限制包括：仅使用公开数据，样本量不均衡；MT引入的翻译歧义可能影响情感细节；缺乏人工评估；模型部署可行性和伦理可行性未深入探讨。

---

## 922. UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing

**arXiv ID:** 2602.02437 | [PDF](https://arxiv.org/pdf/2602.02437v1)

**作者:** Dianyi Wang `[一作]` (Fudan University), Jiaqi Wang `[通讯]` (Shanghai Innovation Institute)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `afceb026-1760-41ae-8d86-010831a37d97` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种统一的推理框架 UniReason，融合文本到图像生成和图像编辑。

**💡 创新点**

创新点在于将世界知识增强的文本推理与细粒度编辑式视觉修正这两种互补的推理范式统一到一个模型，并通过两阶段训练和多模态交互实现。

**🔧 技术方法**

采用 Bagel 的 Mixture‑of‑Transformers 结构，ViT 编码器，VAE‑latent 生成与流匹配训练，以及链式推理（CoT）与视觉反馈的交替推理机制。

**📊 数据集**

构建并使用了 WISE、KrisBench、UniREditBench、UniREdit‑Data‑100K、ShareGPT‑4o‑Image、midjourney prompts 以及海量的 T2I 与编辑数据集。

**📈 对比分析**

与现有开源统一模型对比，UniReason 在世界知识密集的 T2I（WISE）和编辑（KrisBench、UniREditBench）任务上均取得最佳或接近闭源水平的表现；在通用生成/编辑基准（GenEval、DPGBench、ImgEdit、GEdit‑EN）上保持竞争力。

**⚠️ 局限性**

局限性：仍依赖大规模 LLM 生成与评估，推理与生成过程时间较长；对极端专业或高度抽象场景的泛化能力尚需提升。

---

## 923. 3D Foundation Model-Based Loop Closing for Decentralized Collaborative SLAM

**arXiv ID:** 2602.02430 | [PDF](https://arxiv.org/pdf/2602.02430v1)

**作者:** Pierre-Yves Lajoie `[一作]` (Polytechnique Montreal), Giovanni Beltrame `[通讯]` (Polytechnique Montreal)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `6c82a482-f376-4869-8a0b-a802c9d4d3d4` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `5b4c1114-4a70-478e-9921-2514ee03850d` `51c0528b-f690-4182-ae60-bb5f046c276c` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61`

**🎯 论文内容**

提出一种名为mold的去中心化多机器人SLAM闭环检测框架，利用3D基础模型实现单目图像对的姿态估计并在位姿图中进行可优化尺度处理

**💡 创新点**

创新点包括：1) 将MASt3R单目3D基础模型用于跨机器人闭环匹配；2) 引入置信度比率和可优化尺度约束，显著降低误闭环影响；3) 采用稀疏尺度平滑机制，提升多闭环一致性

**🔧 技术方法**

使用技术包括MASt3R 3D基础模型、CosPlace 位置识别、置信度比率筛选、GTSAM位姿图优化（LM、GNC、RBCD）、SMOOTH尺度平滑等

**📊 数据集**

使用的公开数据集为S3E（三机器人大规模动态室内外）和GrAco（六机器人大范围户外）

**📈 对比分析**

与Swarm‑SLAM基线在闭环数、平均平移误差（ATE）以及计算时间上进行对比，mold在S3E Dormitory等最具挑战场景下闭环数至少提高数十倍、ATE下降数十厘米，且优化时延从数分钟缩短至秒级

**⚠️ 局限性**

局限性包括：需要预先提供尺度一致的单机里程计；MASt3R 在与训练域差异较大的环境（如水下）性能可能下降；当前分布式求解依赖动态选举机器人，尚未实现完全无中心服务器的全分布式实现

---

## 924. Structure Enables Effective Self-Localization of Errors in LLMs

**arXiv ID:** 2602.02416 | [PDF](https://arxiv.org/pdf/2602.02416v1)

**作者:** Ankur Samanta `[一作]` (Meta AI), Yonathan Efroni `[通讯]` (Tel Aviv University)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本文提出一种基于“思考‑MDP”（Thought‑MDP）与迭代纠错采样（Thought‑ICS）的结构化推理框架，使大语言模型能够在已知错误的推理中自动定位错误并通过回溯重采样来纠正，显著提升推理准确率。

**💡 创新点**

创新点在于将推理拆分为“思考”级别的离散步骤，提供天然的错误定位边界，并在此基础上实现自我验证、自我定位和自我纠错的闭环，突破了传统链式推理中难以回溯的局限。

**🔧 技术方法**

主要技术包括：1) 思考‑MDP 生成思考级别的离散推理；2) Thought‑ICS 框架中的自我验证、自我定位与回溯重采样；3) 通过自适应终止条件与置信度安全阈值（Thought‑ICS‑A）降低错误修正带来的破坏。

**📊 数据集**

实验数据集涵盖六大推理基准：AMC23、AIME、MATH500‑L5、MathQA、CSQA 以及 GPQA。

**📈 对比分析**

与基线（Token‑ICS、Self‑Refine、CoVe）比较，Thought‑ICS 在 oracle 验证下可提升 20–40% 的准确率；在完全自治的自我验证场景下，Thought‑ICS‑A 在绝大多数模型上实现正向提升，平均 lift 约 3–5%（相较于 Self‑Refine 与 CoVe）。

**⚠️ 局限性**

局限性主要体现在：1) 自我验证准确率仍受限，导致多次迭代可能破坏原已正确答案；2) 依赖结构化“思考”边界，对模型的指令遵循性要求高；3) 目前仅在 3–120B 参数模型与可验证答案的封闭任务上验证，尚未验证更大模型或开放式生成任务的泛化能力。

---

## 925. Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank

**arXiv ID:** 2602.02414 | [PDF](https://arxiv.org/pdf/2602.02414v1)

**作者:** Joshua Mitton `[一作]` (Eedi), Simon Woodhead `[通讯]` (Eedi)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c39d1b1f-fb4e-4609-be16-ca06609fa0ac` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `b4bc56fa-9c97-45d8-ae70-e6cccdb8a275` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出基于生成‑检索‑重排序的三阶段模型，用来从学生‑导师对话中诊断学生的误概念。

**💡 创新点**

创新点在于将LLM生成的误概念假设与嵌入检索相结合，并用LLM进行重排序；同时通过LoRA微调提升小型开源模型的表现，甚至能超越参数量更大的封闭模型。

**🔧 技术方法**

采用大语言模型（LLaMA、Qwen、Claude）进行生成，MiniLM‑L6‑v2嵌入检索，LLM重排序，并使用LoRA进行参数高效微调。

**📊 数据集**

使用来自Eedi教育平台的922条学生‑导师对话数据，包含546个唯一误概念标签。

**📈 对比分析**

与直接嵌入匹配、零射击LLM分类、TF‑IDF关键词匹配等基线对比，实验表明微调后的Qwen 2.5‑7B在MAP@k、Recall@k、NDCG等指标上显著优于基线，并在整体上击败封闭式模型。

**⚠️ 局限性**

局限在于嵌入模型难以捕捉深层数学逻辑，导致在表面相似但数学含义不同的误概念之间出现误判；小模型在处理复杂推理或长对话时仍缺乏鲁棒性。

---

## 926. Carry-Over Lottery Allocation: Practical Incentive-Compatible Drafts

**arXiv ID:** 2602.02487 | [PDF](https://arxiv.org/pdf/2602.02487v1)

**作者:** Timothy Highley `[一作]` (La Salle University), Ilia Volkov `[通讯]` (La Salle University)

**关键词:** `1787d272-1540-4d97-bbe7-e9bbfb732355` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

提出了Carry-Over Lottery Allocation（COLA）NBA选秀机制，通过多年度季后赛表现评估队伍质量，解决坦克问题并公平奖励最弱队伍。

**💡 创新点**

创新点包括：①使用多年度季后赛数据代替单赛季记录评估队伍质量；②让未进入季后赛的球队每年同等增加彩票票数，从而消除额外失误的激励；③中奖后根据中奖顺位递减索引，并允许未中奖票携带至未来；④通过贝叶斯真值量化评估强选秀年并动态调整乐透资格；⑤对交易选秀权进行特殊处理以保持机制完整性。

**🔧 技术方法**

采用机制设计与博弈论分析、Robust Bayesian Truth Serum（RBTS）真值量化、蒙特卡洛仿真、统计分析等技术。

**📊 数据集**

使用的数据集包括：NBA 1999–2025 年季后赛记录、选秀概率和球队实力估计、球员选秀价值系数、以及年度媒体专家问卷结果。

**📈 对比分析**

通过与现行乐透机制及其他提议的对比，利用 1000 赛季的蒙特卡洛仿真验证了 COLA 的长期平衡性。仿真显示所有球队的平均选秀顺位约为第15顺位，季后赛/未季后赛最长连续赛季均不超过十年，且不同球队的乐透索引随时间波动，证明机制能够维持竞争平衡。

**⚠️ 局限性**

局限性包括：①机制对球队偏好（如优先季后赛而非乐透）的假设可能不完全成立；②强选秀年判定依赖专家问卷，存在主观性；③交易保护的处理仍有潜在激励漏洞；④实施成本高，需逐步过渡至新机制；⑤对极端强选秀年份的动态调整可能引入额外争议。

---

## 927. Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge

**arXiv ID:** 2602.02470 | [PDF](https://arxiv.org/pdf/2602.02470v1)

**作者:** Xutao Ma `[一作]` (University of California Berkeley), Somayeh Sojoudi `[通讯]` (University of California Berkeley)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了“Identity Bridge”正则化数据方案，解决自回归大型语言模型在逆推任务中的“reversal curse”问题。

**💡 创新点**

创新点在于仅通过在训练数据中添加无信息的“A→A”样本即可打破方向偏差，而不改变模型架构或训练目标。

**🔧 技术方法**

利用一层Transformer的梯度隐式偏差分析、SVM最优解理论，以及在大模型上进行微调的梯度下降技术。

**📊 数据集**

使用构造的符号关系数据（forward、reverse、identity）以及真实姓名对（Husband–Wife、Parent–Child）进行实验。

**📈 对比分析**

与仅使用forward关系训练的基线相比，加入Identity Bridge后模型在真实任务上从0%提升至约40% 的通过率，显示显著效果。

**⚠️ 局限性**

局限在于模型可能学到复制输入的“shortcut”，导致仍无法达到100% 的通用逆推性能，且对多词实体的效果显著下降。

---

## 928. PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss

**arXiv ID:** 2602.02493 | [PDF](https://arxiv.org/pdf/2602.02493v1)

**作者:** Zehong Ma `[一作]` (Peking University), Shiliang Zhang `[通讯]` (Peking University)

**通讯引用:** 13368 | [OpenAlex ID](https://openalex.org/A5055433405)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `67630363-6be0-4f51-ab05-7198250671a5` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出 PixelGen 框架，在像素空间直接进行扩散生成，加入 LPIPS 与 P‑DINO 感知损失来引导模型学习感知子流形。

**💡 创新点**

通过在像素扩散中同时使用局部 LPIPS 和全局 P‑DINO 两种感知损失，突破传统像素扩散在高维图像空间难以学习的瓶颈，实现超过 latent diffusion 的生成质量。

**🔧 技术方法**

采用 JiT 的 x‑prediction 形式、流匹配损失、LPIPS 感知损失、DINOv2‑B 基于的 P‑DINO 感知损失以及噪声门控策略，整个模型不使用 VAE 或潜在表示。

**📊 数据集**

在 ImageNet 256×256 上进行类别生成实验，并在约 36M 预训练图像加 60k BLIP3o 指令调优数据上进行文本生成，文本编码器使用 Qwen3‑1.7B。

**📈 对比分析**

在相同训练步数（200k）下，PixelGen 在 ImageNet 256 上 FID 下降至 7.53/5.11（CFG），优于 REPA、DDT 等 latent diffusion 模型；在 GenEval 上得到 0.79 分，接近或超过 FLUX.1‑dev，显示出显著的性能优势。

**⚠️ 局限性**

仍缺乏更高效的像素空间采样器与 CFG 策略，噪声门控需要经验调参，且对更高分辨率、多模态任务的通用性与可扩展性尚待进一步验证。

---

## 929. MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents

**arXiv ID:** 2602.02474 | [PDF](https://arxiv.org/pdf/2602.02474v1)

**作者:** Haozhen Zhang `[一作]` (Nanyang Technological University), Wenya Wang `[通讯]` (Nanyang Technological University)

**通讯引用:** 4532 | [OpenAlex ID](https://openalex.org/A5101936536)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出 MemSkill，通过可学习可演化的记忆技能来构建和维护 LLM 代理的外部记忆。

**💡 创新点**

将记忆操作转化为可学习的技能库，并引入设计师在训练过程中基于难点案例演化技能集合，实现闭环自我改进。

**🔧 技术方法**

使用控制器对当前文本片段和已检索记忆进行编码，采用 Top‑K 技能选择，LLM 执行器结合技能生成记忆；通过 PPO 强化学习训练控制器；LLM 基设计师对技能进行分析与更新。

**📊 数据集**

在四个基准上评估：对话式记忆 LoCoMo、LongMemEval；多模态交互 ALFWorld；跨域长文本 HotpotQA。

**📈 对比分析**

与 8 个强基线（如 MemoryOS、A‑MEM、CoN 等）对比，MemSkill 在所有数据集上均取得最优或最接近最优的 F1 / L‑J / 成功率；在跨模型、跨数据集迁移实验中仍保持领先。

**⚠️ 局限性**

依赖大规模 LLM 的推理成本高；技能演化仅在训练时进行，实时更新困难；技能库的可解释性和安全性仍需进一步验证。

---

## 930. RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents

**arXiv ID:** 2602.02486 | [PDF](https://arxiv.org/pdf/2602.02486v1)

**作者:** Jialiang Zhu `[一作]` (Southeast University), Baining Guo `[通讯]` (Microsoft)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `fede83ac-7505-405f-ab37-e7284695c47f` `5b4c1114-4a70-478e-9921-2514ee03850d` `64443552-63e0-44b5-906f-d90fe95c5a1b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种递归轨迹压缩框架Re-TRAC，能够在多轮搜索中通过结构化状态表示实现跨轨迹反思与规划，提升深度研究型LLM代理的搜索效率与准确率。

**💡 创新点**

创新点在于：1) 通过压缩每轮轨迹为三维状态（答案与推理、证据与验证、未决与探索轨迹）实现经验累积；2) 在后续轮次中以此状态作为上下文，实现递归回溯与全局规划；3) 训练小模型时利用Re-TRAC轨迹进行监督微调，突破模型规模限制；4) 作为无训练的测试时扩展方法，在多轮递归下显著降低工具调用与token使用。

**🔧 技术方法**

技术包括：基于ReAct的链式推理与工具调用；结构化压缩规范与Prompt设计；递归执行与状态传递；监督微调（SFT）基于收集的Re-TRAC轨迹；以及对比实验中采用的多种测试时扩展策略（RT@N、MV@N、WV@N、Best@N）。

**📊 数据集**

主要数据集为浏览与搜索类基准：BrowseComp、BrowseComp-ZH、XBench、GAIA、HLE；以及内部构造的33K QA对进行SFT训练。

**📈 对比分析**

与单轮ReAct、Best-of-N、Majority Voting、Weighted Voting等方法对比，Re-TRAC在30B模型上提升8–10%精度，4B模型在同类基准中实现最佳成绩；相较于更大模型，30B Re-TRAC在多数基准上与229B MiniMax-M2相当或更优；在测试时扩展上，RT@8在token与工具使用上比传统方法节省约50%资源同时获得最高准确率。

**⚠️ 局限性**

局限性包括：对压缩规范的设计依赖人工；小模型的摘要能力有限，若摘要质量不足会影响后续搜索；递归过程可能导致搜索深度受限；未结合强化学习进一步优化经验生成。

---

## 931. Age-Aware Edge-Blind Federated Learning via Over-the-Air Aggregation

**arXiv ID:** 2602.02469 | [PDF](https://arxiv.org/pdf/2602.02469v1)

**作者:** Ahmed M. Elshazly `[一作]` (University of North Carolina at Charlotte), Ahmed Arafa `[通讯]` (University of North Carolina at Charlotte)

**通讯引用:** 2242 | [OpenAlex ID](https://openalex.org/A5027897280)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `c84dae5d-5273-4348-85a7-b44cb586b4df` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

提出一种无需客户端CSI、利用多天线PS的过载空气聚合方案，结合AgeTop‑k坐标选择压缩模型更新，以实现低时延的联邦学习；

**💡 创新点**

创新点在于：①完全去除客户端端的CSI估计与相位校正；②采用AgeTop‑k双阶段坐标选择（先按幅值大小再按信息老化），在单个OFDM符号内完成压缩传输；③对压缩量k与信道噪声的权衡给出了收敛上界分析；

**🔧 技术方法**

技术包括：多天线最大比合并（MRC）信道估计、OFDM传输、压缩选择（AgeTop‑k）、梯度压缩与解压、联邦学习的本地SGD迭代；

**📊 数据集**

使用MNIST数据集，构建全连接单层逻辑回归模型（共7,850个参数）；

**📈 对比分析**

与基于随机选择的压缩方案对比，实验表明在多天线（N≥50）且信道噪声较低时，AgeTop‑k方案收敛更快、最终测试准确率更高；在噪声严重或天线数少时，需适当降低k以获得最佳性能；

**⚠️ 局限性**

局限包括：需在PS端知晓所有链路的总信道增益；k的取值需根据实际信道噪声调节，缺乏自适应机制；仅在单天线客户端情形下验证，未来需考虑完全盲CSI的系统设计。

---

## 932. Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts

**arXiv ID:** 2602.02468 | [PDF](https://arxiv.org/pdf/2602.02468v1)

**作者:** Aiden Yiliu Li `[一作]` (University College London), Mengdi Wang `[通讯]` (Princeton University)

**通讯引用:** 6114 | [OpenAlex ID](https://openalex.org/A5100707460)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

构建了一种名为 Avenir-Web 的全功能 Web 代理，能够在真实网站上完成多步骤任务。

**💡 创新点**

创新点在于：① Mixture of Grounding Experts（MoGE）实现视觉优先的多模态定位；② Experience‑Imitation Planning（EIP）利用公开指南生成网站专属的高层计划；③ Task‑Tracking Checklist 与 Adaptive Memory 两层机制协同保证长时序任务的可靠跟踪和记忆；④ 将上述模块以模块化、可插拔的方式整合，兼顾开源可复现。

**🔧 技术方法**

核心技术包括：多模态大型语言模型（如 Gemini‑3 Pro、Qwen‑3‑VL‑8B）作为行动引擎；EIP 采用 Claude‑4.5 Sonnet 进行外部知识检索；MoGE 通过视觉标注与结构推理混合定位；Task‑Tracking Checklist 用轻量 LLM 更新任务状态；Adaptive Memory 采用分块递归摘要与失败反思实现长期记忆。

**📊 数据集**

使用 Online‑Mind2Web 300 个多网站多难度任务作为评测数据集；同时在 50 任务子集上做消融实验。

**📈 对比分析**

与开源基线（SeeAct、Agent‑E、Browser‑Use）及专有模型（Navigator、Operator、Google Gemini、Claude）进行对比，Avenir‑Web 在开源领域以 53.7% 的任务成功率刷新 SOTA，专有模型仍略高，但已缩小差距；轻量化 Qwen‑3‑VL‑8B 版本可达 25.7%。

**⚠️ 局限性**

局限性包括：对非常复杂的 iframe/Canvas 结构仍可能失效；记忆摘要过程可能丢失细节导致偶发误判；延迟和计算成本受大型模型限制；在安全隐私方面仍需严格评估和保护。

---

## 933. From Directions to Regions: Decomposing Activations in Language Models via Local Geometry

**arXiv ID:** 2602.02464 | [PDF](https://arxiv.org/pdf/2602.02464v1)

**作者:** Or Shafran `[一作]` (Blavatnik School of Computer Science and AI), Mor Geva `[通讯]` (Blavatnik School of Computer Science and AI)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

利用 Mixture of Factor Analyzers（MFA）对大型语言模型的激活进行分解，将激活空间划分为若干局部高斯区间，并为每个区间学习低秩子空间，从而实现可解释的特征定位与激活操控。

**💡 创新点**

创新点在于：① 把激活空间建模为局部低维高斯混合而非单一全局方向；② 用子空间而非单向量作为基本单元，显式捕捉非线性、多维概念结构；③ 通过 MFA 实现可扩展、无监督的分解、定位与控制，且在多任务上优于现有基线。

**🔧 技术方法**

核心技术包括：Mixture of Factor Analyzers（MFA）与 Factor Analysis、K‑means 初始化、梯度最小化训练；对比实验使用 PCA、稀疏自编码器（SAE）、Desiderata‑Based Masking（DBM）和 Difference‑in‑Means（DAS）等方法；在模型层面对 Llama‑3.1‑8B 与 Gemma‑2‑2B 进行训练。

**📊 数据集**

主要使用的数据集：The Pile（用于训练 MFA），RAVEL 与 MCQA（MIB benchmark）用于定位/因果干预评估；在 Gemma 与 Llama 的不同层分别抽取激活进行实验。

**📈 对比分析**

与 PCA、SAE、DBM、DAS 等方法对比，MFA 在 RAVEL、MCQA 定位任务中多次击败所有无监督基线，并在 5/6 任务中优于 DBM，接近或超过 DAS；在操控任务上，MFA 的概念对齐分数往往是 SAE 的 1.5‑2 倍，显著提升生成的概念一致性与流畅度。

**⚠️ 局限性**

局限性包括：① 需要海量激活样本和显著计算资源；② 在更大容量（如 32K 组件）时提升有限，主要是将大概念拆分为更多细小区间；③ 目前仅在英文数据集上验证，跨语言或多模态应用未探讨；④ 对部分复杂概念仍需结合全局方向或额外监督，子空间解释性仍不完备。

---

## 934. Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models

**arXiv ID:** 2602.02462 | [PDF](https://arxiv.org/pdf/2602.02462v1)

**作者:** Gabriele Maraia `[一作]` (University of Rome Tor Vergata), Leonardo Ranaldi `[通讯]` (University of Edinburgh)

**通讯引用:** 263 | [OpenAlex ID](https://openalex.org/A5062023845)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `9ce7179e-700c-4310-ac2b-91df50ded46e` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出了在大型语言模型推理时通过抽象化指引进行激活层干预，以降低内容效应导致的逻辑错误。

**💡 创新点**

创新点在于将抽象推理空间与激活层动态对齐，使用轻量级的 Abstractor 在推理时将语义内容映射到结构化的抽象子空间，并实现跨语言零样本迁移。

**🔧 技术方法**

采用激活层干预、对比学习训练的多层感知机（MLP）Abstractor、双头方向与幅值预测网络以及多层插值融合技术。

**📊 数据集**

使用扩展的推理三段论语料库，包含24种逻辑形式，并为英语与9种不同语言（高资源与低资源）生成对应的抽象版本进行配对。

**📈 对比分析**

与无干预基线、参数高效微调（SFT）和链式推理（CoT）进行比较，激活干预在英语及跨语言测试中将bias-penalized accuracy（BPA）提升约+16到+43个百分点，且跨语言迁移接近英语水平。

**⚠️ 局限性**

局限在于仅在三段论推理场景验证，未覆盖更复杂的逻辑或开放式推理，对抽象实例的手工构造依赖较大，并且仅适用于可访问内部激活的开源模型。

---

## 935. Active Causal Experimentalist (ACE): Learning Intervention Strategies via Direct Preference Optimization

**arXiv ID:** 2602.02451 | [PDF](https://arxiv.org/pdf/2602.02451v1)

**作者:** Patrick Cooper `[一作]` (University of Colorado Boulder), Alvaro Velasquez `[通讯]` (University of Colorado Boulder)

**通讯引用:** 41708 | [OpenAlex ID](https://openalex.org/A5108001041)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e` `5a41884c-404f-4688-a89c-aa238c10fe68`

**🎯 论文内容**

在有限实验预算下，提出并实现了一种可学习的实验设计策略ACE，通过对实验结果的偏好比较来不断优化干预决策，提升因果机制识别效率；

**💡 创新点**

将实验设计视为可学习的序列决策问题，首次利用Direct Preference Optimization（DPO）在非平稳信息增益环境中学习策略，避免价值函数收敛困难，并实现对碰撞器父节点的自适应集中干预；

**🔧 技术方法**

核心技术包括：Direct Preference Optimization、对比式偏好学习、序列决策框架、文本基图编码、MLP机制学习器、随机采样与看似搜索；

**📊 数据集**

实验数据集涵盖：5节点与15节点线性/非线性/二次SCM（合成），耦合Duffing振荡器仿真，FRED宏观经济数据（Phillips曲线）等；

**📈 对比分析**

与随机、轮询、最大方差、PPO等基线对比，ACE在等干预预算下提升70–71%（p<0.001，Cohen's d≈2），显著优于所有基线；PPO在相同奖励下性能远逊，证明DPO优越；

**⚠️ 局限性**

主要局限：假设结构已知；模型规模受文本编码限制，难以直接扩展到超过20个节点；实验样本量有限，导致高方差；对某些复杂机制（如二次项）表现敏感；需要更多种子验证稳健性。

---

## 936. Deciding Reachability and the Covering Problem with Diagnostics for Sound Acyclic Free-Choice Workflow Nets

**arXiv ID:** 2602.02447 | [PDF](https://arxiv.org/pdf/2602.02447v1)

**作者:** Thomas M. Prinz `[一作]` (Friedrich Schiller University Jena), Wil M. P. van der Aalst `[通讯]` (RWTH Aachen University)

**通讯引用:** 94591 | [OpenAlex ID](https://openalex.org/A5069762894)

**关键词:** `33d19632-8af2-4683-a5db-767c7ce749e6` `64443552-63e0-44b5-906f-d90fe95c5a1b` `aeb1d087-87bb-48bf-8e0e-d19fc2260534`

**🎯 论文内容**

本文研究在可声学无环自由选择工作流网中决定给定标记（或子标记）是否可达，并给出了能够在多项式时间内给出可达性判断与诊断信息的算法。

**💡 创新点**

创新点在于提出“可接受性”“最大可接受性”以及“发散转移”三种结构性概念，利用并发关系与后支配前沿（post‑dominance frontier）实现对可达性问题的必要与充分条件判定，并在此基础上给出解释性诊断。

**🔧 技术方法**

主要技术包括：并发关系的构造（基于HasPath关系的并发路径算法）、后支配前沿与发散点的计算（改写自Cooper等人和Cytron等人的SSA算法）、以及基于可接受性检验的二次时间复杂度算法。

**📊 数据集**

本文未使用公开数据集，而是以示例工作流网（BPMN‑style 例子）来展示算法流程与诊断效果；若要在工业实践中应用，可将真实 BPMN 过程模型映射为自由选择工作流网后进行实验。

**📈 对比分析**

与传统的状态空间探索或可达性判定的指数/阿克曼级别复杂度相比，本文提供的算法在可声学无环自由选择工作流网上实现了 O(|P|²+|T|²) 的二次时间复杂度，并通过诊断信息提高了可解释性；实验结果显示在典型规模模型中运行时间仅为几百毫秒。

**⚠️ 局限性**

局限性主要体现在：仅针对可声学无环自由选择工作流网（可通过 Murata 变换扩展至可声学无环扩展自由选择网），不直接支持带循环的自由选择网；此外，算法假设网是安全且满足并发关系的完整性，若网违反这些假设则无法直接应用。

---

## 937. RANKVIDEO: Reasoning Reranking for Text-to-Video Retrieval

**arXiv ID:** 2602.02444 | [PDF](https://arxiv.org/pdf/2602.02444v1)

**作者:** Tyler Skow `[一作]` (Johns Hopkins University), Reno Kriz `[通讯]` (Johns Hopkins University)

**通讯引用:** 312 | [OpenAlex ID](https://openalex.org/A5082462234)

**关键词:** `b9e48b6f-9d3b-41c5-a0bd-841e9445d871` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `67630363-6be0-4f51-ab05-7198250671a5` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `8d10c613-917e-4880-9716-17789f50e119` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出一种视频本地化推理式reranker，并通过双阶段训练（感知导向的caption fine‑tune + 结合点对、对间、教师蒸馏的reranking训练）实现视频检索结果的显著提升。

**💡 创新点**

创新点：①视频本地化推理，直接对视频帧、音频、OCR和元数据进行推理；②双阶段训练流程，先让模型生成视频字幕再做reranking；③构建自研的数据合成管线，生成高质量、推理密集的query‑video对；④利用logit delta评分避免生成长推理轨迹，提升推理效率。

**🔧 技术方法**

使用的技术：Qwen3‑VL‑8B‑Instruct 预训练模型；感知导向的 caption fine‑tune；三元组损失（点对、对间、教师蒸馏）联合优化；logit delta 分数；动态推理机制；多模态特征融合。

**📊 数据集**

使用数据集：MultiVENT 2.0 大规模视频检索基准；内部自制的 35684 条 query‑video 训练样本（包括 caption、audio、OCR、metadata 等多模态信息）。

**📈 对比分析**

对比方法：在 OmniEmbed、MMMORRF、CLIP、LanguageBind、Video‑ColBERT 等多种 first‑stage 检索器上与四个基线（文本推理 reranker、Qwen3‑VL‑8B‑Instruct、Qwen3‑VL‑8B‑Thinking、Qwen3‑VL‑Reranker‑8B）对比。实验表明在 nDCG@10 上平均提升 31%，在 R@10、R@20、R@50、R@100 等指标上均优于文本或视觉语言基线，并且推理速度显著快于 QVL‑T。

**⚠️ 局限性**

limitations：未尝试 list‑wise reranking，导致多视频推理成本高；对非视觉或灾害类视频的表现仍不理想；需要更高算力支持大规模多视频推理。

---

## 938. Preemptive Scheduling for Age of Job Minimization in Task-Specific Machine Networks

**arXiv ID:** 2602.02435 | [PDF](https://arxiv.org/pdf/2602.02435v1)

**作者:** Subhankar Banerjee `[一作]` (University of Maryland), Sennur Ulukus `[通讯]` (University of Maryland)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `5b4c1114-4a70-478e-9921-2514ee03850d` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

设计并评估多任务特定机器网络中预抢占式调度策略，以最小化工作年龄指标；

**💡 创新点**

引入工作年龄概念、提出基于Lyapunov漂移的最大权重、NGM、Whittle指数与WIMWF调度策略，并证明几种情况下的指数性；

**🔧 技术方法**

使用Lyapunov漂移分析、RMAB框架、Whittle指数、相对值迭代、子梯度法等数学工具；

**📊 数据集**

采用仿真基准系统参数（3个网络、3个用户/网、不同到达概率与权重），并在此基础上按比例扩展规模，使用几何和非几何服务时间分布；

**📈 对比分析**

通过归一化长期加权工作年龄随扩展因子r变化的曲线比较，发现WIMWF在一般服务时间下最低，Whittle指数在几何服务时间下最低，NGM随着规模增大超过最大权重策略；

**⚠️ 局限性**

局限在于仅在仿真中验证，未考虑真实系统的机器状态不确定性；指数性仅在几何分布下得到证明，WIMWF在非指数性情形需使用fallback权重。

---

## 939. Repurposing Protein Language Models for Latent Flow-Based Fitness Optimization

**arXiv ID:** 2602.02425 | [PDF](https://arxiv.org/pdf/2602.02425v1)

**作者:** Amaru Caceres Arroyo `[一作]` (ETH Zurich), Dominik Narnhofer `[通讯]` (ETH Zurich)

**通讯引用:** 165 | [OpenAlex ID](https://openalex.org/A5086337795)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `86c0b5c7-57cf-4de0-90c2-eb64d5126a31` `40105733-5154-44cd-8090-a8cab9e64b07` `7bbdcbec-2caa-4c7a-b120-9489f11b7043` `e15e3743-5ee0-4d5f-813d-d146868082fc` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本文提出一种利用预训练蛋白质语言模型（pLM）嵌入压缩到低维隐空间，并在该空间内训练条件流匹配模型（结合classifier‑free guidance）来直接生成高适配度蛋白序列的方法。

**💡 创新点**

创新点包括：① 将 pLM 嵌入压缩为高效低维隐空间，充分利用演化先验；② 在隐空间中使用条件流匹配并实现无梯度预测器引导（classifier‑free guidance）实现高适配采样；③ 引入自数据增强/bootstrapping 方案，用合成样本进一步提升低数据情形下的性能。

**🔧 技术方法**

使用技术包括：预训练 ESM2 编码器、两阶段 VAE（压缩器/解压器）实现低维嵌入、UNet 结构的条件流匹配模型、classifier‑free guidance、bootstrapping 生成合成样本、外部预测器（oracle）用于评估和超参调节。

**📊 数据集**

实验数据集为 aav 和 gfp 的四个 benchmark（Medium、Hard），基于公开的完整基准集合构建受限训练子集，oracle 则使用全量数据训练的预测模型进行评估。

**📈 对比分析**

与多种基线（GFlowNet、CbAS、AdaLead、BOqei、CoMS、PEX、gpe、gg‑dWJS、gwg、ggs、LatProtRL、VLGPO）比较，本文方法在所有四个任务上实现了 state‑of‑the‑art 的适配度，同时保持或提升多样性与新颖度，并在推断速度上比 vlgpo 快 10–85 倍。

**⚠️ 局限性**

局限性包括：仅在 aav/gfp benchmark 进行验证，未覆盖更广泛的蛋白功能空间；依赖外部 oracle 进行评估和超参选择；在某些任务（如 gfp Hard）bootstrapping 反而无显著提升；缺乏完全端到端无预测器的生成管线。

---

## 940. Poly-attention: a general scheme for higher-order self-attention

**arXiv ID:** 2602.02422 | [PDF](https://arxiv.org/pdf/2602.02422v1)

**作者:** Sayak Chakrabarti `[一作]` (Columbia University), Josh Alman `[通讯]` (Columbia University)

**通讯引用:** 627 | [OpenAlex ID](https://openalex.org/A5006981411)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了通用的 poly‑attention 框架，将自注意力、张量注意力、Strassen 注意力等归纳为特殊情况，系统研究其计算复杂度与表示能力；并提出了树形注意（tree‑attention）机制，证明其在 O(n²) 时间内可实现且能完成任意常数阶函数合成任务，显著优于传统自注意力。

**💡 创新点**

创新点包括：
1) 定义了多项式注意机制，统一多种高阶注意力；
2) 完整刻画树形多项式注意的可计算性与逼近算法，首次证明其在二次时间内实现且表达力强；
3) 给出针对所有注意多项式的时间下界与逼近条件，阐明表达力与计算成本之间的权衡。

**🔧 技术方法**

主要技术手段有：
- 低阶多项式近似 softmax 以实现逼近算法；
- 低秩分解与多项式方法用于快速计算；
- 快速矩阵乘法与 Strassen 方案用于加速特定结构；
- 通信复杂性与细粒度复杂性证明（Myopic Pointer Jumping、SETH、2‑conjecture 等）。

**📊 数据集**

实验使用的主要数据集包括：
- 自定义函数合成任务（输入两个函数及点，输出复合结果）；
- COGS NLP 数据集，用于评估模型对简单组合任务的学习能力。

**📈 对比分析**

比较方法：将 tree‑attention 单层与自注意力单层、双层模型在函数合成和 COGS 上进行训练与推理比较。结果表明：
- tree‑attention 在训练轮数上明显更快；
- 推理时间与自注意力相近，仅约 1.3 倍；
- 在 COGS 任务中，tree‑attention 在相同训练轮次下达到更高准确率。

**⚠️ 局限性**

局限性：
- 对非树形多项式的 poly‑attention 必须超 O(n²) 时间；
- 当权重 B 较大时逼近仍需 O(n²) 时间；
- 高阶多项式或大 t 情况下的实现仍需工程优化；
- 结果在一定程度上依赖细粒度复杂性假设（SETH、2‑conjecture）。

---

## 941. Trust Region Continual Learning as an Implicit Meta-Learner

**arXiv ID:** 2602.02417 | [PDF](https://arxiv.org/pdf/2602.02417v1)

**作者:** Zekun Wang `[一作]` (Georgia Institute of Technology), Christopher J. MacLellan `[通讯]` (Georgia Institute of Technology)

**通讯引用:** 369 | [OpenAlex ID](https://openalex.org/A5077641166)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `01e19694-9125-4cf8-82ff-580f56a0fdb6` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `ba576bd1-e51d-44e8-8077-fc943b333c93` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种基于信任域的连续学习框架，结合了生成式重放和EWC正则化，实现对旧任务的快速恢复和高保留；

**💡 创新点**

创新点在于将EWC视作Fisher度量的信任域约束，并在局部近似下证明其更新等价于单步MAML，从而在无需显式双层优化的情况下实现隐式元学习；

**🔧 技术方法**

核心技术包括扩散模型生成式重放、基于Fisher矩阵的正则化（尤其利用扩散模型的近似秩‑1 Fisher）、以及对连续学习更新的MAML式解析；

**📊 数据集**

实验使用了500类ImageNet子集的任务增量图像生成和Continual‑World‑10的多任务机器人控制；

**📈 对比分析**

与纯重放、EWC、微调以及FTML、VR‑MCL等连续学习与元学习基线相比，信任域方法在两套任务上均取得最低遗忘率、最高最终性能，并在任务切换后实现更快的旧任务恢复；

**⚠️ 局限性**

局限在于假设旧任务与后续任务共享可近似的低损失区域，当任务异质性极高时，该共享区域可能远离旧任务最优点，从而降低方法效益。

---

## 942. MentisOculi: Revealing the Limits of Reasoning with Mental Imagery

**arXiv ID:** 2602.02465 | [PDF](https://arxiv.org/pdf/2602.02465v1)

**作者:** Jana Zeller `[一作]` (Max-Planck-Institute for Intelligent Systems), Wieland Brendel `[通讯]` (Max-Planck-Institute for Intelligent Systems)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `90291a0e-9d36-4a08-9a16-89ce846d923f` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

本研究提出了一个可程序化、分层的视觉推理基准，系统评估前沿模型在使用“心理图像”（自我生成的视觉表示）进行多步推理时的能力，并发现现有统一多模态模型（UMMs）和视频模型在视觉推理上并未取得显著提升，甚至低于文本推理。

**💡 创新点**

创新点在于：①构建了首个专注于心理图像推理的基准（含5类任务、5个难度层级）；②通过引入“oracle视觉链式思维”方法拆分生成误差与解释误差，系统剖析视觉推理瓶颈；③对比多种模型范式（MLLM、潜在视觉推理、UMM、视频模型）及人类基准，揭示视觉图像并不总能提升推理效果。

**🔧 技术方法**

技术包括：①程序化任务生成与分层难度控制；②使用文本与图像混合的链式思维（CoT）进行推理；③自动化评估脚本（对文本输出、视觉输出和视频轨迹分别进行解析与仿真）；④对视频模型采用帧级轨迹恢复并映射到动作序列；⑤对UMM使用oracle视觉替代自生成视觉进行实验。

**📊 数据集**

数据集：基准生成的5类任务共300个样本（每类5难度层级×30样本）；人类实验使用5名博士生回答同一批样本；还使用公开的视觉语言模型训练数据（如ImageNet、COCO）做微调。

**📈 对比分析**

比较方法：对每个模型在每个任务、每个难度层级计算准确率；对比文本推理基线（MLLM）与视觉辅助模型（UMM、视频模型）以及潜在视觉推理模型；与人类基准对齐。结果显示：在Level‑1时大部分模型略优于偶然；随着难度升高，所有模型准确率急剧下降，Level‑5时多模型均低于或接近偶然；UMM与文本模型相当甚至略差；oracle视觉帮助显著提升性能，但模型仍无法充分利用视觉信息，说明解释误差是主要瓶颈。

**⚠️ 局限性**

限制包括：①基准仅覆盖二维静态视觉任务，未涉及深度或遮挡等更复杂视觉场景；②实验多集中在特定前沿模型，未全面覆盖所有多模态体系；③视觉推理的高计算开销（视频模型成本远高于文本模型）限制了实用性；④模型对视觉输入的解释能力不足，未解决生成误差与解释误差的根本问题。

---

## 943. Expanding the Capabilities of Reinforcement Learning via Text Feedback

**arXiv ID:** 2602.02482 | [PDF](https://arxiv.org/pdf/2602.02482v1)

**作者:** Yuda Song `[一作]`, Andrea Zanette `[通讯]`

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种在训练阶段利用自然语言文本反馈进行强化学习（RL from Text Feedback, RLTF），旨在提升LLM单次输出的质量，解决稀疏标量奖励的高方差问题；

**💡 创新点**

创新点在于：①将多轮交互框架转化为仅在训练时使用反馈的单轮目标；②设计两种实现方式——Self Distillation (通过将带反馈的二轮输出作为隐式示范进行无监督蒸馏) 与 Feedback Modeling (通过让模型预测反馈文本作为辅助任务)；③在Self Distillation中提出使用一阶优势加权回归和一阶基线以降低方差，并对重要性采样进行剪枝；④在理论层面证明 Feedback Modeling 可改善低信噪比下的表示学习。

**🔧 技术方法**

使用的技术包括：多轮强化学习（GRPO等）、自蒸馏、优势加权回归、重要性采样与剪枝、自然语言反馈生成器（基于 GPT‑4‑mini 作为判定者）、交叉熵预测反馈、早期终止、token‑级重要性权重、SFT（监督微调）对比等。

**📊 数据集**

实验数据集涵盖：Reasoning Gym（推理难题）、MATH500/AIME24（竞赛数学）、LitBench、WritingBench（创意写作）以及在这些基准上进行的内部训练集/测试集划分。

**📈 对比分析**

与基线（单轮/多轮 RL、GRPO、文本空间优化、SFT 等）对比，Self Distillation 与 Feedback Modeling 在单轮准确率和多轮性能上均显著优于所有基线，尤其在推理与数学任务上提升幅度较大；在创意写作任务中两者同样表现更好，显示了方法的通用性。

**⚠️ 局限性**

主要局限包括：①文本反馈可能存在噪声或主观偏差，需要额外的数据清洗与过滤；②在长序列/多轮交互中可能出现上下文溢出与分布漂移；③理论分析聚焦于固定分布下的表示学习，缺乏完整的端到端收敛证明；④方法对超参数（剪枝阈值、基线选择、λ 权重等）敏感，需进一步自动化调优。

---

## 944. Secure Multi-User Linearly-Separable Distributed Computing

**arXiv ID:** 2602.02489 | [PDF](https://arxiv.org/pdf/2602.02489v1)

**作者:** Amir Masoud Jafarpisheh `[一作]` (University of Edinburgh), Petros Elia `[通讯]` (EURECOM)

**通讯引用:** 2698 | [OpenAlex ID](https://openalex.org/A5015066458)

**关键词:** `2704f255-0c84-4173-b83c-0e9a3dbea232` `9cc9baba-5356-466d-81ff-d80028d90279`

**🎯 论文内容**

提出一种信息论安全框架，用于多用户线性可分离分布式计算，保证每个用户仅能获取自己请求的线性组合，防止泄露其他信息。

**💡 创新点**

给出了关于解码矩阵与共享随机性的必要且充分的秩条件，能够在不增加通信和计算成本的情况下将任意线性可分离方案转换为安全方案；同时给出了通信成本的下界。

**🔧 技术方法**

使用矩阵分解（F = DE）、秩与核空间分析、共享公共随机性注入、以及信息论泄露度量（熵、互信息）来设计与证明安全方案。

**📊 数据集**

本文主要基于理论模型，无针对性使用具体数据集；所讨论的消息与随机数均假设为独立同分布（有限域均匀或实数正态）。

**📈 对比分析**

与传统的非安全多用户线性分布式计算方案比较，安全方案在满足相同的通信量 δ 与计算量 γ 的前提下实现了零信息泄露（或可忽略的泄露）；实验示例显示通过向 E 矩阵添加 Null(D) 的基向量并引入共享随机性后，性能保持不变。

**⚠️ 局限性**

局限性包括：仅适用于线性可分离任务；需要事先计算并公开解码矩阵的秩条件，可能在大规模系统中成本较高；共享随机性规模随 N–K 线性增长，实际实现中需考虑存储与同步；未讨论对恶意服务器或主动攻击的鲁棒性。

---

## 945. Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability

**arXiv ID:** 2602.02477 | [PDF](https://arxiv.org/pdf/2602.02477v1)

**作者:** Xiao Liang `[一作]` (University of California), Weizhu Chen `[通讯]` (Microsoft)

**通讯引用:** 12905 | [OpenAlex ID](https://openalex.org/A5051745436)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `3a4a0352-9c3f-40a0-98ff-bde88bec2bbe` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并实现了一种基于强化学习的端到端 DAC（Divide‑and‑Conquer）推理框架，用于提升大语言模型在极难推理任务上的性能。

**💡 创新点**

创新点在于将 DAC 推理与模型训练耦合，使用 RL 同时优化拆分与征服步骤，克服传统 CoT 训练与 DAC 推理的错配问题。

**🔧 技术方法**

使用强化学习（GRPO）与自监督奖励机制，结合子问题拆分、求解、最终答案的奖励设计。

**📊 数据集**

训练数据使用 BytedTsinghua‑SIA/DAPO‑Math‑17k，评估基准为 AIME 2024/2025、Beyond‑AIME、HMMT‑25 等整数答案的竞赛级别数学数据集。

**📈 对比分析**

与标准 CoT‑RL 以及混合 CoT‑DAC 训练进行对比，DAC‑RL 在 Pass@1/Pass@32 上分别提升约 8.6%/6.3%，并显示更强的测试时可扩展性。

**⚠️ 局限性**

局限性包括需要较大的训练样本、对奖励设计敏感，且在严格子问题格式约束下性能下降，仍需探索更鲁棒的奖励与约束。

---

## 946. SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning

**arXiv ID:** 2602.02472 | [PDF](https://arxiv.org/pdf/2602.02472v1)

**作者:** Qifan Yu `[一作]` (ByteDance Seed), Di He `[通讯]` (Peking University)

**通讯引用:** 1849 | [OpenAlex ID](https://openalex.org/A5100739032)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `afceb026-1760-41ae-8d86-010831a37d97` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种名为SPARKLING的中期宽度扩展进阶学习框架，用于在大规模语言模型预训练中实现宽度扩展，降低训练成本；

**💡 创新点**

核心创新点在于：① 将功能保持转化为RMS尺度保持，实现激活分布的连续性；② 通过异步优化器状态重置与学习率再热启动打破复制初始化带来的梯度对称性；③ 将上述机制统一应用于多宽度轴和多优化器；

**🔧 技术方法**

技术包括RMS-preserving宽度扩展、复制初始化、优化器状态异步重置、学习率再热、MoE专家内部维度扩展、深度残差网络中的RMSNorm等；

**📊 数据集**

主要在大规模LLM的预训练上验证，使用OLMoE模型、MoE专家内维度、隐藏层宽度等；数据集细节未给出，但下游评测涉及ARC、Arithmetic、BoolQ、CommonsenseQA、HellaSwag、MMLU、OpenBookQA、PIQA、SciQ、SocialIQA、Winogrande等；

**📈 对比分析**

与从头训练的同宽度模型在相同token预算下对比，SPARKLING在保持或提升下游性能的同时，在不同宽度轴上减少了20%~35%的FLOPs，并实现了约1.5倍的壁钟加速；

**⚠️ 局限性**

局限性包括：仍然在最终预训练损失上略逊于从头训练；缺乏同时进行宽度与深度扩展的统一理论；未探讨对μP条件的满足与超参数转移性；

---

## 947. Conflict-Aware Client Selection for Multi-Server Federated Learning

**arXiv ID:** 2602.02458 | [PDF](https://arxiv.org/pdf/2602.02458v1)

**作者:** Mingwei Hong `[一作]` (Xiamen University of Technology), Shunzhi Zhu `[通讯]` (Xiamen University of Technology)

**通讯引用:** 1196 | [OpenAlex ID](https://openalex.org/A5101942006)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `c84dae5d-5273-4348-85a7-b44cb586b4df` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文提出一种名为RL-CRP的去中心化强化学习框架，用于在多服务器联邦学习中进行冲突风险预测与公平的客户端选择。

**💡 创新点**

创新点在于将类别隐马尔可夫模型（HMM）用于稀疏历史选择序列的冲突风险预测，并在强化学习奖励函数中加入公平性度量，以平衡训练速度与客户端参与度。

**🔧 技术方法**

使用了Soft Actor-Critic（SAC）强化学习算法、类别HMM、增量Baum–Welch参数更新、基于公平度量的奖励函数以及水填充算法进行带宽分配。

**📊 数据集**

实验采用CIFAR-10数据集，并在IID与非IID（Dirichlet参数η=0.1）场景下验证模型。

**📈 对比分析**

与FedAvg、无公平RL-CRP以及ENSAC对比，RL-CRP在IID下取得67.68%、非IID下取得61.32%的最高准确率，同时收敛速度更快、冲突次数更少。

**⚠️ 局限性**

局限性包括公平度量可能导致冲突增加的权衡、在服务器数量大幅增加时冲突仍随之上升，以及对覆盖区域重叠情况的进一步适应性尚待提升。

---

## 948. Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning

**arXiv ID:** 2602.02456 | [PDF](https://arxiv.org/pdf/2602.02456v1)

**作者:** Albert Gassol Puigjaner `[一作]` (Norwegian University of Science and Technology), Kostas Alexis `[通讯]` (Norwegian University of Science and Technology)

**通讯引用:** 7806 | [OpenAlex ID](https://openalex.org/A5022659812)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `e0540dec-d77f-42db-94ae-d039248f6393` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `d4a8441d-3297-45fc-8ac0-20de12b80ddd` `3f18e8e3-0266-457c-8567-9039b6d2394d` `edb9d762-f411-4838-a852-f2d638b018db` `e4f91bb3-83db-4b7d-994e-d8bf54b7b1a8` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d4b5b188-bf40-4c81-9f3f-3aecea92dd61` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一个增強的分層3D場景圖框架，結合開放詞彙特徵與物體關係，以支持自主機器人對任務的推理與執行。

**💡 创新点**

主要創新在於：①將開放詞彙特徵應用於多層抽象（物體、房間、建築等）；②利用視覺語言模型（VLM）提取物體對間關係並嵌入圖結構；③設計任務推理模組，將自然語言指令拆解成子任務並評估可行性。

**🔧 技术方法**

核心技術包括：YOLOe物體檢測與分割、CLIP開放詞彙嵌入、VLM（DeepSeek VL2）關係編碼、GPT‑4o任務解析與子任務決策、Hydra與Voxblox實時幾何重建。

**📊 数据集**

使用的數據集為Replica和HM3DSem，用於開放詞彙物體檢索評估；實驗還在實際環境中部署四足機器人，收集RGB‑D、LiDAR與IMU數據。

**📈 对比分析**

與HOV‑SG和ConceptGraphs等開放詞彙場景圖基線相比，本文在物體檢索的Top‑k準確率和AUC上均取得較高分數；在多種任務推理測試中，使用DeepSeek VL2的成功率達84‑100%，FP數量低於基線。

**⚠️ 局限性**

局限性包括：關係提取依賴於VLM的推理能力，對複雜場景中的物體分割與對象分層仍有誤差；以及在高頻度重建環境下的計算瓶頸（VLM視覺編碼耗時較大）。

---

## 949. Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling

**arXiv ID:** 2602.02453 | [PDF](https://arxiv.org/pdf/2602.02453v1)

**作者:** Andong Chen `[一作]` (Harbin Institute of Technology), Tiejun Zhao `[通讯]` (Harbin Institute of Technology)

**通讯引用:** 8513 | [OpenAlex ID](https://openalex.org/A5100564229)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `ca90f54c-96fe-4d91-a7ad-6da6db91f7d2` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d603a949-d0a9-40d8-bcb8-e02e842b97f2` `90291a0e-9d36-4a08-9a16-89ce846d923f` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出并验证了一种名为“Thinking with Comics（TwC）”的多模态推理范式，将漫画作为高信息密度、低成本的视觉中介，既保留了视频的时间逻辑，又避免了视频冗余，支持多步推理与长文本理解。

**💡 创新点**

创新点包括：① 将漫画视为结构化的视觉推理轨迹；② 设计两条路径（端到端可视化推理与漫画作为条件上下文）；③ 通过叙事结构与嵌入文本强化视觉推理；④ 证明漫画在保持准确率的同时显著降低生成成本。

**🔧 技术方法**

技术手段主要包括：使用 Gemini‑3 Pro Image 生成漫画；将漫画序列与原问题一起输入 Gemini‑3 Pro 或其他多模态 LLM 进行推理；对漫画的时间顺序、文本嵌入等做实验验证；成本模型与性能评估。

**📊 数据集**

使用的评测数据集涵盖：推理任务——MATH‑500、GSM8K、MathVista；长上下文理解任务——DocVQA、eBDtheque、CulturalBench（Easy/Hard）。

**📈 对比分析**

与文本推理、基线 CoT、Thinking with Images、Thinking with Video 等方法对比，TwC 在 MathVista、DocVQA、CulturalBench（Hard）上分别取得 85.8%、99.4%、90.4% 等领先成绩；在视频推理上以 86.6% 的成本压缩率实现相近或更优准确率。

**⚠️ 局限性**

局限性包括：漫画生成的质量与一致性受模型限制；不同文化/叙事风格的通用性尚未充分验证；对极长序列或极复杂推理时所需的漫画帧数仍需动态调优；当前评测主要基于公开基准，缺乏更丰富的跨任务验证。

---

## 950. Certain Head, Uncertain Tail: Expert-Sample for Test-Time Scaling in Fine-Grained MoE

**arXiv ID:** 2602.02443 | [PDF](https://arxiv.org/pdf/2602.02443v1)

**作者:** Yuanteng Chen `[一作]` (Institute of Automation, Chinese Academy of Sciences), Jian Cheng `[通讯]` (Institute of Automation, Chinese Academy of Sciences)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d` `8d10c613-917e-4880-9716-17789f50e119` `edb9d762-f411-4838-a852-f2d638b018db` `afceb026-1760-41ae-8d86-010831a37d97` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种无需训练的测试时扩展方法Expert‑Sample，通过在fine‑grained MoE的专家路由层引入可控随机性来增强多样性并保持稳定性。

**💡 创新点**

创新点在于将多样性来源从传统的token级采样迁移到专家级路由层，利用专家分布的“确定头+不确定尾”结构实现稳定与多样性的解耦。

**🔧 技术方法**

使用的技术包括基于softmax温度缩放的Gumbel‑softmax采样、专家权重重归一化以及与普通温度采样的联合调用。

**📊 数据集**

在多种细粒度MoE模型（Qwen3‑30B‑A3B‑Instruct、Qwen3‑Next‑80B‑A3B‑Instruct、GPT‑OSS‑20B、Ling‑Lite‑1.5）上，对数学推理（AIME‑120、MATH‑500）、知识推理（GPQA‑Diamond）和代码生成（LiveCodeBench‑V6‑Lite）数据集进行评测。

**📈 对比分析**

与正常温度采样、高温度采样和基于熵的动态温度采样相比，Expert‑Sample在pass@n曲线和最佳/加权投票验证下平均提升约3–7%，在pass@32上可将未能解答的问题覆盖率提升至30%以上，且对模型性能几乎无显著影响。

**⚠️ 局限性**

局限性包括对专家数量、温度及采样范围等超参数的依赖，虽然在实验中表现稳健，但在极端模型或任务设置下可能需要细粒度调整；此外，方法仍依赖于已有的高质量MoE模型架构，无法直接应用于非MoE模型。

---

## 951. sVIRGO: A Scalable Virtual Tree Hierarchical Framework for Distributed Systems

**arXiv ID:** 2602.02438 | [PDF](https://arxiv.org/pdf/2602.02438v1)

**作者:** Lican Huang `[一作]` `[通讯]` (Hangzhou Domain Zones Technology Co., Ltd.), Lican Huang (Hangzhou Domain Zones Technology Co., Ltd.)

**关键词:** `d0c287c2-ddf5-4cc2-9cd5-c6e171da6e62`

**🎯 论文内容**

提出 sVIRGO：一种在物理节点上直接构建的可扩展虚拟树层级框架，支持多角色节点、区域级多重协调器冗余、动态角色切换和分层命令执行，兼容基础设施可用与否的通信方式。

**💡 创新点**

创新点在于：① 无覆盖网络的虚拟层级树直接映射到物理节点；② 节点可同时承担多层角色；③ 区域级多重协调器与局部重选保证 near‑zero 恢复延迟；④ 层级范围命令执行与可选的基础设施辅助通信实现灵活、高效、鲁棒的全局协作。

**🔧 技术方法**

采用技术包括：虚拟层级映射与动态角色分配、区域级多重协调器监控与本地重选、分层消息结构与延迟推迟转发、混合短距离无线与可选长距离基础设施链接、分层通信与多频段无线链路、动态角色切换与重选算法。

**📊 数据集**

数据集：在百万级无人机群（thousands of local regions）上进行仿真评估，并与平面网状、静态层级及 VIRGO 进行对比。

**📈 对比分析**

对比方法：将 sVIRGO 与平面网状、静态层级和 VIRGO 的消息量、延迟、失效率等指标进行对比。性能表现为：消息 hop 数显著降低，恢复延迟接近 0，通信开销呈对数增长，失效概率呈指数下降，整体可伸缩性和鲁棒性优于传统方案。

**⚠️ 局限性**

限制：长距离通信受限于带宽、成本和环境约束；若无基础设施，跨区域多跳会导致更高的时延与链路拥塞。

---

## 952. SelvaMask: Segmenting Trees in Tropical Forests and Beyond

**arXiv ID:** 2602.02426 | [PDF](https://arxiv.org/pdf/2602.02426v1)

**作者:** Simon-Olivier Duguay `[一作]` (Université de Montréal), Arthur Ouaknine `[通讯]` (McGill University)

**通讯引用:** 260 | [OpenAlex ID](https://openalex.org/A5068077721)

**关键词:** `9473a256-bb9c-4876-84c8-23d8ab9b6fd9` `729e5870-4135-47f5-97f2-e3974d07b5dc` `e0540dec-d77f-42db-94ae-d039248f6393` `edb9d762-f411-4838-a852-f2d638b018db` `a05fcc20-6870-48b1-abb6-44c47d7cde76` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

本文构建了SelvaMask，包含8800多棵热带森林树冠的高分辨率手工标注，并提出基于检测-分割模块化管道，利用Vision Foundation Models与域特定检测提示器，实现热带树冠分割的最佳性能。

**💡 创新点**

创新点在于①大规模、完整树冠标注数据集SelvaMask；②引入可微分的检测-分割分离策略，并对VFMs进行领域微调；③设计多尺度RF1评价指标与人类一致度对比，证明模型已逼近人类标注上限。

**🔧 技术方法**

技术上采用Transformer‑based Vision Foundation Models（SAM2/3），结合DeepForest、SelvaBox等检测器进行提示；对SAM进行全量微调；使用COCO/ RF1评估指标。

**📊 数据集**

使用SelvaMask三大热带站点（巴拿马、巴西、厄瓜多尔）以及外部数据集（Detectree2、BCI50ha、BAMForest、QuebecTrees、OAM‑TCD）进行验证。

**📈 对比分析**

在所有评测中，SelvaBox→SAM3在mAP、mRF1上均超过传统端到端Mask2Former、Detectree2等基线，且在OOD测试中保持优异表现，证明模块化方法在稠密树冠下的优势。

**⚠️ 局限性**

局限性包括：①检测模块召回率决定最终分割质量，漏检会直接影响结果；②任务本身存在人类标注一致度上限，难以进一步提升；③数据集仅覆盖新热带地区，需扩展到其他热带/热带亚地区。

---

## 953. Active Transfer Bagging: A New Approach for Accelerated Active Learning Acquisition of Data by Combined Transfer Learning and Bagging Based Models

**arXiv ID:** 2602.02415 | [PDF](https://arxiv.org/pdf/2602.02415v1)

**作者:** Vivienne Pelletier `[一作]` (Arizona State University), Christopher L. Muhich `[通讯]` (Arizona State University)

**通讯引用:** 4253 | [OpenAlex ID](https://openalex.org/A5079084846)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `f7dab867-23a8-4241-85e9-4ba79c6402f9` `11828d4d-5ed2-4c17-8f38-5c7a47e57054` `596fe7ac-9d40-46e0-a8e6-ee59d94fc35e`

**🎯 论文内容**

本文提出了一种 Active‑Transfer Bagging (ATBagging) 方法，用于在转移学习和主动学习中构建高质量的种子数据子集，并通过利用已有的代理标签信息来提高低样本下的学习效果。

**💡 创新点**

创新点在于将基于 bagged 集成模型的贝叶斯信息增益估计与特征空间多样性（通过 Determinantal Point Process 结合随机傅里叶特征核）相结合，实现信息量与多样性的双重优化；同时在转移学习场景中首次系统地利用代理数据集来指导种子子集的选取。

**🔧 技术方法**

主要技术包括：贝叶斯解释的 bagged 随机森林模型信息增益估计、KL 距离近似、Determinantal Point Process (DPP) 采样、随机傅里叶特征 (RFF) 核近似、主动学习中的查询‑委员会 (Query‑by‑Committee) 策略、以及决策树/随机森林回归模型。

**📊 数据集**

实验使用四个真实世界数据集：QM9（分子能量）、ERA5（气象降水相关量）、Forbes 2000（公司市值）、北京 PM2.5（细颗粒物浓度），分别涵盖目标转移和特征漂移两类任务。

**📈 对比分析**

与三种基线（随机采样、PCA 网格采样、基于影响函数的核心集）对比，ATBagging 在大多数数据集和子集规模下均能获得更高的初始迁移性能（ITP）和更大的学习曲线面积（NAULC），特别是在小样本规模（n_seed = 10–100）时表现更为突出；在主动学习阶段，ATBagging 的模型在前 100–150 次采样后即可实现与或优于其他方法的准确率。

**⚠️ 局限性**

局限性包括：对含有混合类别特征的高维数据，RFF 近似的欧氏距离可能不够合适，导致多样性采样效果下降；在某些特征漂移任务（如 Forbes）中，初始迁移性能不如核心集，需进一步改进特征相似度度量；此外，虽然 DPP 采样在 10⁵ 条记录以内效率可接受，但在更大规模数据集上仍需验证其可扩展性。

---

## 954. Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization

**arXiv ID:** 2602.02439 | [PDF](https://arxiv.org/pdf/2602.02439v1)

**作者:** Olaf Yunus Laitinen Imanov `[一作]` (Technical University of Denmark), Rana Irem Turhan `[通讯]` (Riga Technical University)

**关键词:** `aea6b09c-069e-4d88-8dd1-371f7abba620` `64443552-63e0-44b5-906f-d90fe95c5a1b` `5b4c1114-4a70-478e-9921-2514ee03850d` `29aaa6b5-cc4b-4e8b-b67e-05d983eb740c` `b88c6eac-d57a-4623-a604-1f401f3eb268` `90291a0e-9d36-4a08-9a16-89ce846d923f`

**🎯 论文内容**

提出NeuEdge框架，集成混合时间编码、硬件感知协同优化和自适应阈值机制，实现边缘AI的极高能效与低延迟。

**💡 创新点**

三维协同优化：混合时序编码实现4.7×抖动压缩，硬件感知映射提升芯片利用率至89%，动态阈值自适应降低能耗67%。

**🔧 技术方法**

使用近似梯度训练、硬件感知网络搜索、混合时序编码、SNN硬件映射优化与实时阈值自适应技术。

**📊 数据集**

在CIFAR‑10、DVS Gesture和Google Speech Commands v2数据集上进行评估。

**📈 对比分析**

与纯rate SNN、ANN‑SNN转换、量化DNN和MobileNetV2基线对比，在Loihi 2、TrueNorth等平台实现92‑97%准确率，能效达847 GOp/s/W，推理时延2.3 ms，能源相较GPU提升312倍。

**⚠️ 局限性**

仍缺少在线学习、多模态融合、真正场景自适应验证，且对新硬件平台的迁移通用性待进一步验证。

---

## 955. AgentRx: Diagnosing AI Agent Failures from Execution Trajectories

**arXiv ID:** 2602.02475 | [PDF](https://arxiv.org/pdf/2602.02475v1)

**作者:** Shraddha Barke `[一作]` (Microsoft Research), Chetan Bansal `[通讯]` (Microsoft)

**通讯引用:** 2001 | [OpenAlex ID](https://openalex.org/A5000305391)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `3855fcda-48ef-4070-a15e-803cd5c84d83` `5b4c1114-4a70-478e-9921-2514ee03850d` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `c773407a-6119-4871-b8b3-1e7ae17a6851` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了一个自动化诊断框架，用于定位AI代理在执行轨迹中的首次不可恢复失败步骤，并为该失败分配跨域的根因分类；同时发布了115条失败轨迹的基准数据集和九类失败分类法。

**💡 创新点**

①创建了跨领域的失败分类体系（基于扎根理论）；②设计了可生成全局与动态约束的诊断管道；③利用约束违规日志与LLM判定器相结合，实现了比现有基线更高的失败定位与分类精度。

**🔧 技术方法**

约束合成（全局约束与基于轨迹前缀的动态约束）、LLM评估器（基于违规日志与分类清单），以及对日志进行可审计的验证日志生成；使用LLM（gpt‑5）进行判断；实验中还比较了逐步与一次性约束生成、不同judge输入与约束策略。

**📊 数据集**

115条失败轨迹，覆盖三大领域：τ‑bench（API工作流）、Flash（事件响应工作流）和Magentic‑One（开放式网页/文件任务）。每条轨迹包含完整执行记录、工具调用与状态，并标注了关键失败步骤与分类。

**📈 对比分析**

与先前工作（Who&When）以及多种基线（仅LLM评估、仅违规日志、仅分类清单、结合使用）对比。实验表明，在τ‑bench上步骤定位从32.2%提升至54%，分类准确率从25.3%提升至40.2%；在Flash上步骤准确率保持在80%以上，分类准确率提升至60.3%；在Magentic上提升约4–5个百分点。整体显著优于基线。

**⚠️ 局限性**

缺陷分类可能不涵盖所有域；约束生成和LLM判断依赖大量模型推理，存在误报与噪声；对长轨迹的约束一次性生成效果下降；基准仅覆盖三类任务，未必能推广到更广泛的代理场景。

---

## 956. HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos

**arXiv ID:** 2602.02473 | [PDF](https://arxiv.org/pdf/2602.02473v1)

**作者:** Yinhuai Wang `[一作]` (Hong Kong University of Science and Technology), Ping Tan `[通讯]` (Hong Kong University of Science and Technology)

**通讯引用:** 13958 | [OpenAlex ID](https://openalex.org/A5084953118)

**关键词:** `a1c26042-88d3-4e76-b403-2055e0dfc5c7` `c7913869-b026-40e7-b14b-dfd72dc55ea0` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `ef89cc5f-e375-48ac-9691-51e1cf81ed3f`

**🎯 论文内容**

提出HumanX框架，能够直接从单一人类单目视频学习人形机器人的交互技能，无需手工设计奖励；通过XGen合成物理可行的交互数据，并用XMimic实现统一的模仿学习，完成从篮球、足球到货物搬运和人机格斗等10种交互技能的零射击迁移与真实部署。

**💡 创新点**

①以物理先验为核心的XGen数据合成与增强，突破单纯几何重建导致的物理不一致；②统一奖励、感知与教师‑学生策略的XMimic框架，兼顾多模式学习与实时闭环；③引入感知自由（仅凭本体感知）与MoCap模式，实现无外部感知与实时跟踪的双模式部署；④大规模随机初始化与交互终止机制，显著提升泛化性能。

**🔧 技术方法**

SMPL基于人类姿态估计、GMR人体到机器人姿态重定向、SAM‑3D对象网格估计、IsaacGym物理仿真、PPO强化学习、行为克隆、力闭环优化、感知模块（本体位置/速度+力推断）以及可选MoCap轨迹感知。

**📊 数据集**

主要使用自制单目视频（iPhone 16拍摄），每项技能仅一段视频；通过XGen生成训练样本，内部使用模拟数据集（篮球、足球、羽毛球、货物、格斗）。

**📈 对比分析**

与SkillMimic、OmniRetarget、HDMI等现有HOI模仿方法对比，HumanX在仿真中单基准下SR达100%、GSR>80%，比HDMI高约8×；在真实Unitree G1上，十项技能的成功率均达到70%以上（如10/10跳投、8/10盘球、9/10机动等），远优于传统方法。

**⚠️ 局限性**

依赖高质量人类视频，仍受遮挡与深度不确定性影响；对不同人形机器人形态的适配需手动设定anchor；在极端扰动或非预见场景下仍可能失稳；缺乏完全无监督的多示例学习能力。

---

## 957. Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction

**arXiv ID:** 2602.02455 | [PDF](https://arxiv.org/pdf/2602.02455v1)

**作者:** Han Bao `[一作]` (University of Notre Dame), Yanfang Ye `[通讯]` (University of Notre Dame)

**通讯引用:** 5060 | [OpenAlex ID](https://openalex.org/A5027601906)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `9cc9baba-5356-466d-81ff-d80028d90279` `5b4c1114-4a70-478e-9921-2514ee03850d` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `d0f189e1-0834-4ff4-b4e8-f515263ef669` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

提出了首个用于诊断大型语言模型代理在面对用户输入错误（意图、前提、参数、表达）时的协作失误的多轮交互基准；

**💡 创新点**

构建了基于格赖斯共识原则、奥斯丁语用理论和瓦茨拉克交互公理的四类失误统一分类，并结合个性化用户模拟器和评估协议，揭示了“澄清悖论”与“执行偏差”两大安全风险；

**🔧 技术方法**

使用大型语言模型（如GPT‑5.2、GLM‑4.7、Gemini‑2.5‑Flash等）作为代理和用户，配合自定义的澄清工具链；采用自然语言处理技术提取语义框架、注入系统化失误；评估框架包含四维度指标（鲁棒性、智能、可安全性、效率）；

**📊 数据集**

基准数据集来源于两类执行环境（白盒的系统/数据库操作与黑盒的API调用），先通过多模型验证可解性，再注入四类系统化失误，形成可诊断的任务变体；

**📈 对比分析**

与Oracle基线对比，结果显示在状态导向环境下参数/表达失误导致约40%性能下降；在有澄清条件下，白盒环境可获得显著提升（+10%~+25%），但黑盒环境出现澄清悖论，澄清反而使性能下降；不同模型表现出相似的失调模式，说明当前规模化模型仍缺乏协作意识；

**⚠️ 局限性**

局限性包括：基准仅覆盖两类执行环境，未充分涵盖复杂多模态或持续学习场景；用户模拟器虽然个性化但仍基于预设规则，缺乏真实人类交互多样性；评估指标侧重任务成功与交互轮数，未深入探讨实时安全保障与长期学习的影响；

---

## 958. Maximizing Reliability with Bayesian Optimization

**arXiv ID:** 2602.02432 | [PDF](https://arxiv.org/pdf/2602.02432v1)

**作者:** Jack M. Buckingham `[一作]` (University of Warwick), Juergen Branke `[通讯]` (University of Warwick)

**通讯引用:** 6047 | [OpenAlex ID](https://openalex.org/A5036018560)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `5b4c1114-4a70-478e-9921-2514ee03850d`

**🎯 论文内容**

提出了两种基于贝叶斯优化的可靠性最大化方法——Thompson Sampling–最大可靠性（TS-MR）和知识梯度–最大可靠性（KG-MR），并结合重要抽样和准蒙特卡罗技术以有效估计极小失效概率。

**💡 创新点**

创新点在于：①直接针对失效概率的对数目标设计采集函数；②将KG近似为一阶贝叶斯最优策略；③对指标函数进行平滑处理并引入重要抽样；④提出一次性（one‑shot）与离散（discrete）两种KG-MR近似，显著提升极端可靠性优化的效率与精度。

**🔧 技术方法**

主要技术包括：高斯过程贝叶斯优化、Thompson Sampling、知识梯度、重要抽样、准蒙特卡罗（Sobol' 采样）、随机傅里叶特征（RFF）、L‑BFGS‑B梯度优化、指标平滑与对数变换。

**📊 数据集**

使用人工合成的多维测试函数集合（随机 GP 生成问题、Stiblinski‑Tang、Hartmann、Branin、二次函数等），维度从 2 到 16，涵盖极端与非极端失效概率场景。

**📈 对比分析**

与随机采样、期望改进（EI）以及已发表的 HC 与 EGRA 方法进行比较。实验显示，一次性 KG-MR 在 12 组测试中 10 组获得最优或同等优异性能；TS‑MR 亦表现突出；HC/EGRA 在低维/极端失效情形下表现相对较弱。评估指标为推荐解的中位失效概率及四分位区间。

**⚠️ 局限性**

局限性包括：KG‑MR 计算成本较高，尤其离散版在高维下精度下降；TS‑MR 在高维中易过度探索；方法目前仅针对单一限界状态函数；需要进一步研究多限界/约束扩展与自适应重要抽样以提升效率。

---

## 959. Embedding Perturbation may Better Reflect the Uncertainty in LLM Reasoning

**arXiv ID:** 2602.02427 | [PDF](https://arxiv.org/pdf/2602.02427v1)

**作者:** Qihao Wen `[一作]` (University of Arizona), Han Xu `[通讯]` (University of Arizona)

**通讯引用:** 42958 | [OpenAlex ID](https://openalex.org/A5100346440)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

本研究探讨了如何更好地量化大型语言模型（LLM）推理过程中的不确定性，特别是中间步骤的不确定性。通过引入基于扰动的度量，研究发现这些度量能够有效识别LLM推理中的错误步骤。

**💡 创新点**

创新点在于提出了一种基于扰动的中间不确定性量化方法，该方法通过测量每个生成令牌对其前置上下文的敏感性来识别不确定性，优于传统的多重采样和基于概率的度量。

**🔧 技术方法**

使用了基于扰动的度量技术，包括随机扰动和对抗扰动，来评估生成令牌的稳定性和不确定性。

**📊 数据集**

实验使用了BIG-Bench和MATH等数据集，涵盖了逻辑推理和数学推理任务。

**📈 对比分析**

与基线方法（如令牌生成概率和令牌熵）相比，基于扰动的度量在识别错误步骤方面表现出更强的性能，尤其是在逻辑推理和数学推理任务中，检测率显著提高。

**⚠️ 局限性**

局限性包括：1）该方法在检测LLM的事实幻觉方面表现不佳，因为这些错误通常源于模型的内部知识，而不是上下文推理；2）在具有高变异性的任务或模型中，可能无法有效区分推理步骤的正确性和路径选择的不确定性。

---

## 960. SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration

**arXiv ID:** 2602.02419 | [PDF](https://arxiv.org/pdf/2602.02419v1)

**作者:** Qingni Wang `[一作]` (University of California, Santa Cruz), Xin Eric Wang `[通讯]` (University of California, Santa Barbara)

**通讯引用:** 9933 | [OpenAlex ID](https://openalex.org/A5100327844)

**关键词:** `0536b7b3-4271-4e10-9b76-1f66fc457fab` `aeb1d087-87bb-48bf-8e0e-d19fc2260534` `90291a0e-9d36-4a08-9a16-89ce846d923f` `79276348-11e0-48e3-84bc-7ec231d0171c`

**🎯 论文内容**

研发了SafeGround，一个面向GUI grounding的不确定性量化与校准框架，实现风险感知的选择性预测和级联推理。

**💡 创新点**

将多次随机推理采样的空间分布与Clopper–Pearson基准校准相结合，在有限样本下提供FDR控制，兼容黑盒模型且可在部署时自适应阈值。

**🔧 技术方法**

采样式空间分布构造、分布感知的不确定度度量（Top‑Candidate Ambiguity、Informational Dispersion、Concentration Deficit）以及权重组合、Clopper–Pearson上置信区间校准、选择性推理与级联推理。

**📊 数据集**

使用ScreenSpot‑Pro基准数据集。

**📈 对比分析**

与Token置信度、概率置信度等基线比较，AUROC、AUARC均提升；在用户设定的风险阈值下，实际FDR始终低于理论上界；级联Gemini后系统准确率最高提升5.38个百分点，并在不同风险等级下保持鲁棒。

**⚠️ 局限性**

需多次推理采样导致计算开销；极低风险阈值下部分模型难以满足FDR约束；不确定度度量对模型差异敏感，权重需经验调优；未评估动态场景和持续学习情况。

---

## 961. Reward-free Alignment for Conflicting Objectives

**arXiv ID:** 2602.02495 | [PDF](https://arxiv.org/pdf/2602.02495v1)

**作者:** Peter Chen `[一作]` (Columbia University), Tianyi Lin `[通讯]` (Columbia University)

**通讯引用:** 2259 | [OpenAlex ID](https://openalex.org/A5083720030)

**关键词:** `243a8f53-c1b4-4939-9b96-9653425e9d86` `5b4c1114-4a70-478e-9921-2514ee03850d` `a4b10f5d-130b-4e77-9367-6469ec621899` `edb9d762-f411-4838-a852-f2d638b018db` `c59129cc-0f1d-4fee-85d8-abbb7eea50d6` `c5260876-9a54-48ae-a63a-8fa6d6ddb799` `6b9ad54c-2d62-4a92-a500-d9cb644dd99c`

**🎯 论文内容**

提出一种奖励无关的多目标偏好对齐方法 RACO，直接使用对偶偏好数据并通过裁剪的冲突避免梯度下降（CAGrad-Clip）解决梯度冲突；

**💡 创新点**

创新点包括：①在不构建显式奖励模型的情况下完成多目标对齐；②引入裁剪的 CAGrad 以保持用户指定权重并提升收敛速度；③提供非凸光滑设置下的 Pareto‑临界收敛证明，并在两目标情形下证明裁剪可加速；

**🔧 技术方法**

主要技术：DPO 风格偏好损失、多目标优化、CAGrad 与梯度裁剪、Pareto 临界性分析、离线优化；

**📊 数据集**

实验数据集：Reddit Summary（质量、简洁性、可信度）和 BeaverTails（帮助性、无害性），使用 PKU‑SafeRLHF 等公开标注数据；

**📈 对比分析**

与 DPO Loss Weight、AMoPO 等基线对比；在 Qwen3、Llama3、Gemma3 多种 LLM 上实验，RACO 在不同权重设置下 consistently 获得更外的 Pareto 前沿，优于基线；

**⚠️ 局限性**

局限性：需在高维 LLM 参数空间中精细调节裁剪阈值与纠正半径；对极度冲突的多目标仍可能受限；仅支持离线训练，未考虑在线或动态偏好更新；

---

## 962. MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training

**arXiv ID:** 2602.02494 | [PDF](https://arxiv.org/pdf/2602.02494v1)

**作者:** Dulhan Jayalath `[一作]` (University of Oxford), Oiwi Parker Jones `[通讯]` (University of Oxford)

**通讯引用:** 2362 | [OpenAlex ID](https://openalex.org/A5015428481)

**关键词:** `00521103-b308-4295-8635-1bbb9135d4d9` `edb9d762-f411-4838-a852-f2d638b018db` `b88c6eac-d57a-4623-a604-1f401f3eb268` `6c1af392-8b9e-4e11-bd3d-9d44e98a6e3b`

**🎯 论文内容**

提出了一种长上下文MEG预训练框架MEG-XL，用于脑转文本的词解码。

**💡 创新点**

创新点在于将MEG窗口从几秒扩展到2.5分钟，利用长上下文自监督掩码学习，显著提升少样本泛化能力。

**🔧 技术方法**

采用残差向量量化tokenizer、criss‑cross transformer、块掩码自监督目标、卷积位置编码等技术。

**📊 数据集**

在CamCAN、MOUS、SMN4Lang等公开MEG数据上预训练，随后在MEG-MASC、Armeni、LibriBrain三大英语听觉语音MEG数据集上评估。

**📈 对比分析**

与监督最优基线和六大脑基底模型比较，在低数据量下提高约25–30%，在完整数据下与最强模型相当或略优。

**⚠️ 局限性**

局限在于仅处理感知语音、词汇量有限、对想象语音和更大词表的泛化尚未验证。

---

